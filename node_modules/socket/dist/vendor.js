'use strict'

const fs$1 = require('node:fs')
const os$3 = require('node:os')
const path$1 = require('node:path')
const process$2 = require('node:process')
const fs$2 = require('node:fs/promises')
const require$$0$3 = require('node:buffer')
const require$$0$4 = require('node:util')
const require$$0$5 = require('node:path')
const require$$0$6 = require('node:fs')
const require$$0$7 = require('node:tty')
const require$$0$8 = require('node:https')
const require$$1$5 = require('node:http')
const require$$2$1 = require('node:url')
const require$$0$9 = require('node:process')
const require$$0$a = require('node:events')
const require$$2$2 = require('node:http')
const require$$3$2 = require('node:https')
const require$$5 = require('node:readline')
const require$$6$1 = require('../external/@socketsecurity/registry/lib/constants/abort-signal')
const util$3 = require('node:util')
const require$$0$b = require('node:url')
const require$$0$c = require('node:os')
const require$$1$6 = require('node:tty')
const require$$1$7 = require('node:fs/promises')
const childProcess = require('node:child_process')
const require$$1$8 = require('node:path/win32')
const require$$0$d = require('node:module')
const require$$0$e = require('node:crypto')
const require$$0$f = require('node:constants')
const require$$0$g = require('node:stream')
const require$$5$1 = require('node:assert')
const require$$1$9 = require('node:stream')
const require$$2$3 = require('node:string_decoder')
const require$$0$h = require('node:events')
const require$$2$4 = require('node:buffer')
const require$$1$a = require('node:string_decoder')
const require$$0$i = require('node:child_process')

const _documentCurrentScript =
  typeof document !== 'undefined' ? document.currentScript : null
/** @template [T=undefined] */
class ErrorWithCause extends Error {
  /**
   * @param {string} message
   * @param {{ cause?: T }} options
   */
  constructor(message, { cause } = {}) {
    super(message)

    /** @type {string} */
    this.name = ErrorWithCause.name
    if (cause) {
      /** @type {T} */
      this.cause = cause
    }
    /** @type {string} */
    this.message = message
  }
}

const errorWithCause = /*#__PURE__*/ Object.freeze({
  __proto__: null,
  ErrorWithCause: ErrorWithCause
})

/**
 * @template {Error} T
 * @param {unknown} err
 * @param {new(...args: any[]) => T} reference
 * @returns {T|undefined}
 */
const findCauseByReference = (err, reference) => {
  if (!err || !reference) {
    return
  }
  if (!(err instanceof Error)) {
    return
  }
  if (
    !(reference.prototype instanceof Error) &&
    // @ts-ignore
    reference !== Error
  ) {
    return
  }

  /**
   * Ensures we don't go circular
   *
   * @type {Set<Error>}
   */
  const seen = new Set()

  /** @type {Error|undefined} */
  let currentErr = err
  while (currentErr && !seen.has(currentErr)) {
    seen.add(currentErr)
    if (currentErr instanceof reference) {
      return currentErr
    }
    currentErr = getErrorCause(currentErr)
  }
}

/**
 * @param {Error|{ cause?: unknown|(()=>err)}} err
 * @returns {Error|undefined}
 */
const getErrorCause = err => {
  if (!err || typeof err !== 'object' || !('cause' in err)) {
    return
  }

  // VError / NError style causes
  if (typeof err.cause === 'function') {
    const causeResult = err.cause()
    return causeResult instanceof Error ? causeResult : undefined
  } else {
    return err.cause instanceof Error ? err.cause : undefined
  }
}

/**
 * Internal method that keeps a track of which error we have already added, to avoid circular recursion
 *
 * @private
 * @param {Error} err
 * @param {Set<Error>} seen
 * @returns {string}
 */
const _stackWithCauses = (err, seen) => {
  if (!(err instanceof Error)) {
    return ''
  }
  const stack = err.stack || ''

  // Ensure we don't go circular or crazily deep
  if (seen.has(err)) {
    return stack + '\ncauses have become circular...'
  }
  const cause = getErrorCause(err)

  // TODO: Follow up in https://github.com/nodejs/node/issues/38725#issuecomment-920309092 on how to log stuff

  if (cause) {
    seen.add(err)
    return stack + '\ncaused by: ' + _stackWithCauses(cause, seen)
  } else {
    return stack
  }
}

/**
 * @param {Error} err
 * @returns {string}
 */
const stackWithCauses = err => _stackWithCauses(err, new Set())

/**
 * Internal method that keeps a track of which error we have already added, to avoid circular recursion
 *
 * @private
 * @param {Error} err
 * @param {Set<Error>} seen
 * @param {boolean} [skip]
 * @returns {string}
 */
const _messageWithCauses = (err, seen, skip) => {
  if (!(err instanceof Error)) {
    return ''
  }
  const message = skip ? '' : err.message || ''

  // Ensure we don't go circular or crazily deep
  if (seen.has(err)) {
    return message + ': ...'
  }
  const cause = getErrorCause(err)
  if (cause) {
    seen.add(err)
    const skipIfVErrorStyleCause =
      'cause' in err && typeof err.cause === 'function'
    return (
      message +
      (skipIfVErrorStyleCause ? '' : ': ') +
      _messageWithCauses(cause, seen, skipIfVErrorStyleCause)
    )
  } else {
    return message
  }
}

/**
 * @param {Error} err
 * @returns {string}
 */
const messageWithCauses = err => _messageWithCauses(err, new Set())

const helpers$1 = /*#__PURE__*/ Object.freeze({
  __proto__: null,
  findCauseByReference: findCauseByReference,
  getErrorCause: getErrorCause,
  messageWithCauses: messageWithCauses,
  stackWithCauses: stackWithCauses
})

/* MAIN */
const attempt = (fn, fallback) => {
  try {
    return fn()
  } catch {
    return fallback
  }
}

/* IMPORT */
const __classPrivateFieldSet =
  (undefined && undefined.__classPrivateFieldSet) ||
  function (receiver, state, value, kind, f) {
    if (kind === 'm') {
      throw new TypeError('Private method is not writable')
    }
    if (kind === 'a' && !f) {
      throw new TypeError('Private accessor was defined without a setter')
    }
    if (
      typeof state === 'function'
        ? receiver !== state || !f
        : !state.has(receiver)
    ) {
      throw new TypeError(
        'Cannot write private member to an object whose class did not declare it'
      )
    }
    return (
      kind === 'a'
        ? f.call(receiver, value)
        : f
          ? (f.value = value)
          : state.set(receiver, value),
      value
    )
  }
const __classPrivateFieldGet =
  (undefined && undefined.__classPrivateFieldGet) ||
  function (receiver, state, kind, f) {
    if (kind === 'a' && !f) {
      throw new TypeError('Private accessor was defined without a getter')
    }
    if (
      typeof state === 'function'
        ? receiver !== state || !f
        : !state.has(receiver)
    ) {
      throw new TypeError(
        'Cannot read private member from an object whose class did not declare it'
      )
    }
    return kind === 'm'
      ? f
      : kind === 'a'
        ? f.call(receiver)
        : f
          ? f.value
          : state.get(receiver)
  }
let _AbstractStore_save
/* MAIN */
class AbstractStore extends Map {
  /* CONSTRUCTOR */
  constructor(options) {
    super()
    /* VARIABLES */
    _AbstractStore_save.set(this, void 0)
    const { id, backend } = options
    if (!/^[a-zA-Z0-9_-]+$/.test(id)) {
      throw new Error(`Invalid store id: "${id}"`)
    }
    const read = () => attempt(() => backend.read(id), [])
    const write = () => attempt(() => backend.write(id, this.entries()), null)
    for (const [key, value] of read()) {
      super.set(key, value)
    }
    __classPrivateFieldSet(this, _AbstractStore_save, write, 'f')
    return this
  }
  /* API */
  clear() {
    if (!this.size) {
      return
    }
    super.clear()
    __classPrivateFieldGet(this, _AbstractStore_save, 'f').call(this)
  }
  delete(key) {
    const deleted = super.delete(key)
    if (!deleted) {
      return false
    }
    __classPrivateFieldGet(this, _AbstractStore_save, 'f').call(this)
    return true
  }
  set(key, value) {
    const valuePrev = this.get(key)
    if (value === valuePrev) {
      return this
    }
    super.set(key, value)
    __classPrivateFieldGet(this, _AbstractStore_save, 'f').call(this)
    return this
  }
}
_AbstractStore_save = new WeakMap()

/* IMPORT */
/* MAIN */
class NodeStore extends AbstractStore {
  /* CONSTRUCTOR */
  constructor(id) {
    super({
      id,
      backend: {
        read: id => {
          const filePath = path$1.join(os$3.tmpdir(), `ionstore_${id}.json`)
          const content = fs$1.readFileSync(filePath, 'utf8')
          return JSON.parse(content)
        },
        write: (id, data) => {
          const filePath = path$1.join(os$3.tmpdir(), `ionstore_${id}.json`)
          const content = JSON.stringify(Array.from(data))
          return fs$1.writeFileSync(filePath, content)
        }
      }
    })
  }
}

/* MAIN */
const ENV = globalThis.process?.env || {}
const ARGV = globalThis.process?.argv || []
const IS_ENABLED =
  !('NO_COLOR' in ENV) &&
  ENV.TERM !== 'dumb' &&
  !ARGV.includes('--no-color') &&
  !ARGV.includes('--no-colors') &&
  (!globalThis.process?.stdout || globalThis.process?.stdout?.isTTY === true)

/* IMPORT */
/* HELPERS */
const chain = modifier => {
  return new Proxy(modifier, {
    get(target, prop) {
      if (prop in colors) {
        return chain(string => modifier(colors[prop](string)))
      } else {
        return target[prop]
      }
    }
  })
}
const wrap = (start, end) => {
  return chain(string => {
    if (!IS_ENABLED) {
      return string
    }
    return `\u001B[${start}m${string}\u001B[${end}m`
  })
}
/* MAIN */
const colors = {
  /* MODIFIERS */
  reset: wrap(0, 0),
  bold: wrap(1, 22),
  dim: wrap(2, 22),
  italic: wrap(3, 23),
  underline: wrap(4, 24),
  overline: wrap(53, 55),
  inverse: wrap(7, 27),
  hidden: wrap(8, 28),
  strikethrough: wrap(9, 29),
  /* FOREGOUND */
  black: wrap(30, 39),
  red: wrap(31, 39),
  green: wrap(32, 39),
  yellow: wrap(33, 39),
  blue: wrap(34, 39),
  magenta: wrap(35, 39),
  cyan: wrap(36, 39),
  white: wrap(37, 39),
  gray: wrap(90, 39),
  /* BACKGROUND */
  bgBlack: wrap(40, 49),
  bgRed: wrap(41, 49),
  bgGreen: wrap(42, 49),
  bgYellow: wrap(43, 49),
  bgBlue: wrap(44, 49),
  bgMagenta: wrap(45, 49),
  bgCyan: wrap(46, 49),
  bgWhite: wrap(47, 49),
  bgGray: wrap(100, 49)
}

/* IMPORT */
/* MAIN */
const IS_LINUX = process$2.platform === 'linux'
const IS_WINDOWS = process$2.platform === 'win32'

/* IMPORT */
/* MAIN */
//URL: https://github.com/tapjs/signal-exit/blob/03dd77a96caa309c6a02c59274d58c812a2dce45/signals.js
const Signals = ['SIGABRT', 'SIGALRM', 'SIGHUP', 'SIGINT', 'SIGTERM']
if (!IS_WINDOWS) {
  Signals.push(
    'SIGVTALRM',
    'SIGXCPU',
    'SIGXFSZ',
    'SIGUSR2',
    'SIGTRAP',
    'SIGSYS',
    'SIGQUIT',
    'SIGIOT'
  )
}
if (IS_LINUX) {
  Signals.push('SIGIO', 'SIGPOLL', 'SIGPWR', 'SIGSTKFLT', 'SIGUNUSED')
}

/* IMPORT */
/* MAIN */
class Interceptor {
  /* CONSTRUCTOR */
  constructor() {
    /* VARIABLES */
    this.callbacks = new Set()
    this.exited = false
    /* API */
    this.exit = signal => {
      if (this.exited) {
        return
      }
      this.exited = true
      for (const callback of this.callbacks) {
        callback()
      }
      if (signal) {
        if (
          IS_WINDOWS &&
          signal !== 'SIGINT' &&
          signal !== 'SIGTERM' &&
          signal !== 'SIGKILL'
        ) {
          // Windows doesn't support POSIX signals, but Node emulates these 3 signals for us
          process$2.kill(process$2.pid, 'SIGTERM')
        } else {
          process$2.kill(process$2.pid, signal)
        }
      }
    }
    this.hook = () => {
      process$2.once('exit', () => this.exit())
      for (const signal of Signals) {
        try {
          process$2.once(signal, () => this.exit(signal))
        } catch {
          // Sometimes "process.once" can throw...
        }
      }
    }
    this.register = callback => {
      this.callbacks.add(callback)
      return () => {
        this.callbacks.delete(callback)
      }
    }
    this.hook()
  }
}
/* EXPORT */
const Interceptor$1 = new Interceptor()

/* IMPORT */
/* MAIN */
const whenExit = Interceptor$1.register

/**
 * This software is released under the MIT license:
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy of
 * this software and associated documentation files (the "Software"), to deal in
 * the Software without restriction, including without limitation the rights to
 * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
 * the Software, and to permit persons to whom the Software is furnished to do so,
 * subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
 * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
 * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
 * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
/* MAIN */
// The following is just a slightly modified version of semver-compare
const compare = (a, b) => {
  const pa = a.split('.')
  const pb = b.split('.')
  for (let i = 0; i < 3; i++) {
    let na = Number(pa[i])
    let nb = Number(pb[i])
    if (na > nb) {
      return 1
    }
    if (nb > na) {
      return -1
    }
    if (!isNaN(na) && isNaN(nb)) {
      return 1
    }
    if (isNaN(na) && !isNaN(nb)) {
      return -1
    }
  }
  return 0
}

/* IMPORT */
/* MAIN */
const Utils = {
  /* API */
  fetch: async url => {
    const signal = Utils.getExitSignal()
    const request = await fetch(url, {
      signal
    })
    const json = await request.json()
    return json
  },
  getExitSignal: () => {
    const aborter = new AbortController()
    whenExit(() => aborter.abort())
    return aborter.signal
  },
  getLatestVersion: async name => {
    const latestUrl = `https://registry.npmjs.org/${name}/latest`
    const latest = await Utils.fetch(latestUrl)
    return latest.version
  },
  isNumber: value => {
    return typeof value === 'number'
  },
  isString: value => {
    return typeof value === 'string'
  },
  isUpdateAvailable: (current, latest) => {
    return compare(current, latest) === -1
  },
  noop: () => {
    return
  },
  notify: (name, version, latest) => {
    if (!globalThis.process?.stdout?.isTTY) {
      return
    } // Probably piping stdout
    const log = () =>
      console.log(
        `\n\n📦 Update available for ${colors.cyan(name)}: ${colors.gray(version)} → ${colors.green(latest)}`
      )
    whenExit(log)
  }
}

/* IMPORT */
/* MAIN */
class Store {
  constructor() {
    /* VARIABLES */
    this.store = new NodeStore('tiny-updater')
    /* API */
    this.get = name => {
      try {
        const recordRaw = this.store.get(name)
        if (!recordRaw) {
          return
        }
        const record = JSON.parse(recordRaw)
        if (!Utils.isNumber(record.timestampFetch)) {
          return
        }
        if (!Utils.isNumber(record.timestampNotification)) {
          return
        }
        if (!Utils.isString(record.version)) {
          return
        }
        return record
      } catch {
        return
      }
    }
    this.set = (name, record) => {
      this.store.set(name, JSON.stringify(record))
    }
  }
}
/* EXPORT */
const Store$1 = new Store()

/* IMPORT */
/* MAIN */
//TODO: Account for non-latest releases
const updater = async ({ name, version, ttl = 0 }) => {
  const record = Store$1.get(name)
  const timestamp = Date.now()
  const isFresh = !record || timestamp - record.timestampFetch >= ttl
  const latest = isFresh
    ? await Utils.getLatestVersion(name).catch(Utils.noop)
    : record?.version
  if (!latest) {
    return false
  }
  if (isFresh) {
    const record = {
      timestampFetch: timestamp,
      timestampNotification: timestamp,
      version: latest
    }
    Store$1.set(name, record)
  }
  if (!Utils.isUpdateAvailable(version, latest)) {
    return false
  }
  if (isFresh) {
    Utils.notify(name, version, latest)
  }
  return true
}

function getAugmentedNamespace(n) {
  if (Object.prototype.hasOwnProperty.call(n, '__esModule')) {
    return n
  }
  const f = n.default
  let a
  if (typeof f == 'function') {
    a = function a() {
      if (this instanceof a) {
        return Reflect.construct(f, arguments, this.constructor)
      }
      return f.apply(this, arguments)
    }
    a.prototype = f.prototype
  } else {
    a = {}
  }
  Object.defineProperty(a, '__esModule', { value: true })
  Object.keys(n).forEach(function (k) {
    const d = Object.getOwnPropertyDescriptor(n, k)
    Object.defineProperty(
      a,
      k,
      d.get
        ? d
        : {
            enumerable: true,
            get: function () {
              return n[k]
            }
          }
    )
  })
  return a
}

const ajv = { exports: {} }

const core$3 = {}

const validate$2 = {}

const boolSchema = {}

const errors$4 = {}

const codegen = {}

const code$1 = {}

let hasRequiredCode$1
function requireCode$1() {
  if (hasRequiredCode$1) {
    return code$1
  }
  hasRequiredCode$1 = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.regexpCode =
      exports.getEsmExportName =
      exports.getProperty =
      exports.safeStringify =
      exports.stringify =
      exports.strConcat =
      exports.addCodeArg =
      exports.str =
      exports._ =
      exports.nil =
      exports._Code =
      exports.Name =
      exports.IDENTIFIER =
      exports._CodeOrName =
        void 0
    // eslint-disable-next-line @typescript-eslint/no-extraneous-class
    class _CodeOrName {}
    exports._CodeOrName = _CodeOrName
    exports.IDENTIFIER = /^[a-z$_][a-z$_0-9]*$/i
    class Name extends _CodeOrName {
      constructor(s) {
        super()
        if (!exports.IDENTIFIER.test(s)) {
          throw new Error('CodeGen: name must be a valid identifier')
        }
        this.str = s
      }
      toString() {
        return this.str
      }
      emptyStr() {
        return false
      }
      get names() {
        return {
          [this.str]: 1
        }
      }
    }
    exports.Name = Name
    class _Code extends _CodeOrName {
      constructor(code) {
        super()
        this._items = typeof code === 'string' ? [code] : code
      }
      toString() {
        return this.str
      }
      emptyStr() {
        if (this._items.length > 1) {
          return false
        }
        const item = this._items[0]
        return item === '' || item === '""'
      }
      get str() {
        let _a
        return (_a = this._str) !== null && _a !== void 0
          ? _a
          : (this._str = this._items.reduce((s, c) => `${s}${c}`, ''))
      }
      get names() {
        let _a
        return (_a = this._names) !== null && _a !== void 0
          ? _a
          : (this._names = this._items.reduce((names, c) => {
              if (c instanceof Name) {
                names[c.str] = (names[c.str] || 0) + 1
              }
              return names
            }, {}))
      }
    }
    exports._Code = _Code
    exports.nil = new _Code('')
    function _(strs, ...args) {
      const code = [strs[0]]
      let i = 0
      while (i < args.length) {
        addCodeArg(code, args[i])
        code.push(strs[++i])
      }
      return new _Code(code)
    }
    exports._ = _
    const plus = new _Code('+')
    function str(strs, ...args) {
      const expr = [safeStringify(strs[0])]
      let i = 0
      while (i < args.length) {
        expr.push(plus)
        addCodeArg(expr, args[i])
        expr.push(plus, safeStringify(strs[++i]))
      }
      optimize(expr)
      return new _Code(expr)
    }
    exports.str = str
    function addCodeArg(code, arg) {
      if (arg instanceof _Code) {
        code.push(...arg._items)
      } else if (arg instanceof Name) {
        code.push(arg)
      } else {
        code.push(interpolate(arg))
      }
    }
    exports.addCodeArg = addCodeArg
    function optimize(expr) {
      let i = 1
      while (i < expr.length - 1) {
        if (expr[i] === plus) {
          const res = mergeExprItems(expr[i - 1], expr[i + 1])
          if (res !== undefined) {
            expr.splice(i - 1, 3, res)
            continue
          }
          expr[i++] = '+'
        }
        i++
      }
    }
    function mergeExprItems(a, b) {
      if (b === '""') {
        return a
      }
      if (a === '""') {
        return b
      }
      if (typeof a == 'string') {
        if (b instanceof Name || a[a.length - 1] !== '"') {
          return
        }
        if (typeof b != 'string') {
          return `${a.slice(0, -1)}${b}"`
        }
        if (b[0] === '"') {
          return a.slice(0, -1) + b.slice(1)
        }
        return
      }
      if (typeof b == 'string' && b[0] === '"' && !(a instanceof Name)) {
        return `"${a}${b.slice(1)}`
      }
      return
    }
    function strConcat(c1, c2) {
      return c2.emptyStr() ? c1 : c1.emptyStr() ? c2 : str`${c1}${c2}`
    }
    exports.strConcat = strConcat
    // TODO do not allow arrays here
    function interpolate(x) {
      return typeof x == 'number' || typeof x == 'boolean' || x === null
        ? x
        : safeStringify(Array.isArray(x) ? x.join(',') : x)
    }
    function stringify(x) {
      return new _Code(safeStringify(x))
    }
    exports.stringify = stringify
    function safeStringify(x) {
      return JSON.stringify(x)
        .replace(/\u2028/g, '\\u2028')
        .replace(/\u2029/g, '\\u2029')
    }
    exports.safeStringify = safeStringify
    function getProperty(key) {
      return typeof key == 'string' && exports.IDENTIFIER.test(key)
        ? new _Code(`.${key}`)
        : _`[${key}]`
    }
    exports.getProperty = getProperty
    //Does best effort to format the name properly
    function getEsmExportName(key) {
      if (typeof key == 'string' && exports.IDENTIFIER.test(key)) {
        return new _Code(`${key}`)
      }
      throw new Error(
        `CodeGen: invalid export name: ${key}, use explicit $id name mapping`
      )
    }
    exports.getEsmExportName = getEsmExportName
    function regexpCode(rx) {
      return new _Code(rx.toString())
    }
    exports.regexpCode = regexpCode
  })(code$1)
  return code$1
}

const scope = {}

let hasRequiredScope
function requireScope() {
  if (hasRequiredScope) {
    return scope
  }
  hasRequiredScope = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.ValueScope =
      exports.ValueScopeName =
      exports.Scope =
      exports.varKinds =
      exports.UsedValueState =
        void 0
    const code_1 = requireCode$1()
    class ValueError extends Error {
      constructor(name) {
        super(`CodeGen: "code" for ${name} not defined`)
        this.value = name.value
      }
    }
    let UsedValueState
    ;(function (UsedValueState) {
      UsedValueState[(UsedValueState['Started'] = 0)] = 'Started'
      UsedValueState[(UsedValueState['Completed'] = 1)] = 'Completed'
    })(UsedValueState || (exports.UsedValueState = UsedValueState = {}))
    exports.varKinds = {
      const: new code_1.Name('const'),
      let: new code_1.Name('let'),
      var: new code_1.Name('var')
    }
    class Scope {
      constructor({ prefixes, parent } = {}) {
        this._names = {}
        this._prefixes = prefixes
        this._parent = parent
      }
      toName(nameOrPrefix) {
        return nameOrPrefix instanceof code_1.Name
          ? nameOrPrefix
          : this.name(nameOrPrefix)
      }
      name(prefix) {
        return new code_1.Name(this._newName(prefix))
      }
      _newName(prefix) {
        const ng = this._names[prefix] || this._nameGroup(prefix)
        return `${prefix}${ng.index++}`
      }
      _nameGroup(prefix) {
        let _a, _b
        if (
          ((_b =
            (_a = this._parent) === null || _a === void 0
              ? void 0
              : _a._prefixes) === null || _b === void 0
            ? void 0
            : _b.has(prefix)) ||
          (this._prefixes && !this._prefixes.has(prefix))
        ) {
          throw new Error(
            `CodeGen: prefix "${prefix}" is not allowed in this scope`
          )
        }
        return (this._names[prefix] = {
          prefix,
          index: 0
        })
      }
    }
    exports.Scope = Scope
    class ValueScopeName extends code_1.Name {
      constructor(prefix, nameStr) {
        super(nameStr)
        this.prefix = prefix
      }
      setValue(value, { property, itemIndex }) {
        this.value = value
        this.scopePath = (0,
        code_1._)`.${new code_1.Name(property)}[${itemIndex}]`
      }
    }
    exports.ValueScopeName = ValueScopeName
    const line = (0, code_1._)`\n`
    class ValueScope extends Scope {
      constructor(opts) {
        super(opts)
        this._values = {}
        this._scope = opts.scope
        this.opts = {
          ...opts,
          _n: opts.lines ? line : code_1.nil
        }
      }
      get() {
        return this._scope
      }
      name(prefix) {
        return new ValueScopeName(prefix, this._newName(prefix))
      }
      value(nameOrPrefix, value) {
        let _a
        if (value.ref === undefined) {
          throw new Error('CodeGen: ref must be passed in value')
        }
        const name = this.toName(nameOrPrefix)
        const { prefix } = name
        const valueKey =
          (_a = value.key) !== null && _a !== void 0 ? _a : value.ref
        let vs = this._values[prefix]
        if (vs) {
          const _name = vs.get(valueKey)
          if (_name) {
            return _name
          }
        } else {
          vs = this._values[prefix] = new Map()
        }
        vs.set(valueKey, name)
        const s = this._scope[prefix] || (this._scope[prefix] = [])
        const itemIndex = s.length
        s[itemIndex] = value.ref
        name.setValue(value, {
          property: prefix,
          itemIndex
        })
        return name
      }
      getValue(prefix, keyOrRef) {
        const vs = this._values[prefix]
        if (!vs) {
          return
        }
        return vs.get(keyOrRef)
      }
      scopeRefs(scopeName, values = this._values) {
        return this._reduceValues(values, name => {
          if (name.scopePath === undefined) {
            throw new Error(`CodeGen: name "${name}" has no value`)
          }
          return (0, code_1._)`${scopeName}${name.scopePath}`
        })
      }
      scopeCode(values = this._values, usedValues, getCode) {
        return this._reduceValues(
          values,
          name => {
            if (name.value === undefined) {
              throw new Error(`CodeGen: name "${name}" has no value`)
            }
            return name.value.code
          },
          usedValues,
          getCode
        )
      }
      _reduceValues(values, valueCode, usedValues = {}, getCode) {
        let code = code_1.nil
        for (const prefix in values) {
          const vs = values[prefix]
          if (!vs) {
            continue
          }
          const nameSet = (usedValues[prefix] = usedValues[prefix] || new Map())
          vs.forEach(name => {
            if (nameSet.has(name)) {
              return
            }
            nameSet.set(name, UsedValueState.Started)
            let c = valueCode(name)
            if (c) {
              const def = this.opts.es5
                ? exports.varKinds.var
                : exports.varKinds.const
              code = (0, code_1._)`${code}${def} ${name} = ${c};${this.opts._n}`
            } else if (
              (c =
                getCode === null || getCode === void 0 ? void 0 : getCode(name))
            ) {
              code = (0, code_1._)`${code}${c}${this.opts._n}`
            } else {
              throw new ValueError(name)
            }
            nameSet.set(name, UsedValueState.Completed)
          })
        }
        return code
      }
    }
    exports.ValueScope = ValueScope
  })(scope)
  return scope
}

let hasRequiredCodegen
function requireCodegen() {
  if (hasRequiredCodegen) {
    return codegen
  }
  hasRequiredCodegen = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.or =
      exports.and =
      exports.not =
      exports.CodeGen =
      exports.operators =
      exports.varKinds =
      exports.ValueScopeName =
      exports.ValueScope =
      exports.Scope =
      exports.Name =
      exports.regexpCode =
      exports.stringify =
      exports.getProperty =
      exports.nil =
      exports.strConcat =
      exports.str =
      exports._ =
        void 0
    const code_1 = requireCode$1()
    const scope_1 = requireScope()
    const code_2 = requireCode$1()
    Object.defineProperty(exports, '_', {
      enumerable: true,
      get: function () {
        return code_2._
      }
    })
    Object.defineProperty(exports, 'str', {
      enumerable: true,
      get: function () {
        return code_2.str
      }
    })
    Object.defineProperty(exports, 'strConcat', {
      enumerable: true,
      get: function () {
        return code_2.strConcat
      }
    })
    Object.defineProperty(exports, 'nil', {
      enumerable: true,
      get: function () {
        return code_2.nil
      }
    })
    Object.defineProperty(exports, 'getProperty', {
      enumerable: true,
      get: function () {
        return code_2.getProperty
      }
    })
    Object.defineProperty(exports, 'stringify', {
      enumerable: true,
      get: function () {
        return code_2.stringify
      }
    })
    Object.defineProperty(exports, 'regexpCode', {
      enumerable: true,
      get: function () {
        return code_2.regexpCode
      }
    })
    Object.defineProperty(exports, 'Name', {
      enumerable: true,
      get: function () {
        return code_2.Name
      }
    })
    const scope_2 = requireScope()
    Object.defineProperty(exports, 'Scope', {
      enumerable: true,
      get: function () {
        return scope_2.Scope
      }
    })
    Object.defineProperty(exports, 'ValueScope', {
      enumerable: true,
      get: function () {
        return scope_2.ValueScope
      }
    })
    Object.defineProperty(exports, 'ValueScopeName', {
      enumerable: true,
      get: function () {
        return scope_2.ValueScopeName
      }
    })
    Object.defineProperty(exports, 'varKinds', {
      enumerable: true,
      get: function () {
        return scope_2.varKinds
      }
    })
    exports.operators = {
      GT: new code_1._Code('>'),
      GTE: new code_1._Code('>='),
      LT: new code_1._Code('<'),
      LTE: new code_1._Code('<='),
      EQ: new code_1._Code('==='),
      NEQ: new code_1._Code('!=='),
      NOT: new code_1._Code('!'),
      OR: new code_1._Code('||'),
      AND: new code_1._Code('&&'),
      ADD: new code_1._Code('+')
    }
    class Node {
      optimizeNodes() {
        return this
      }
      optimizeNames(_names, _constants) {
        return this
      }
    }
    class Def extends Node {
      constructor(varKind, name, rhs) {
        super()
        this.varKind = varKind
        this.name = name
        this.rhs = rhs
      }
      render({ es5, _n }) {
        const varKind = es5 ? scope_1.varKinds.var : this.varKind
        const rhs = this.rhs === undefined ? '' : ` = ${this.rhs}`
        return `${varKind} ${this.name}${rhs};` + _n
      }
      optimizeNames(names, constants) {
        if (!names[this.name.str]) {
          return
        }
        if (this.rhs) {
          this.rhs = optimizeExpr(this.rhs, names, constants)
        }
        return this
      }
      get names() {
        return this.rhs instanceof code_1._CodeOrName ? this.rhs.names : {}
      }
    }
    class Assign extends Node {
      constructor(lhs, rhs, sideEffects) {
        super()
        this.lhs = lhs
        this.rhs = rhs
        this.sideEffects = sideEffects
      }
      render({ _n }) {
        return `${this.lhs} = ${this.rhs};` + _n
      }
      optimizeNames(names, constants) {
        if (
          this.lhs instanceof code_1.Name &&
          !names[this.lhs.str] &&
          !this.sideEffects
        ) {
          return
        }
        this.rhs = optimizeExpr(this.rhs, names, constants)
        return this
      }
      get names() {
        const names =
          this.lhs instanceof code_1.Name
            ? {}
            : {
                ...this.lhs.names
              }
        return addExprNames(names, this.rhs)
      }
    }
    class AssignOp extends Assign {
      constructor(lhs, op, rhs, sideEffects) {
        super(lhs, rhs, sideEffects)
        this.op = op
      }
      render({ _n }) {
        return `${this.lhs} ${this.op}= ${this.rhs};` + _n
      }
    }
    class Label extends Node {
      constructor(label) {
        super()
        this.label = label
        this.names = {}
      }
      render({ _n }) {
        return `${this.label}:` + _n
      }
    }
    class Break extends Node {
      constructor(label) {
        super()
        this.label = label
        this.names = {}
      }
      render({ _n }) {
        const label = this.label ? ` ${this.label}` : ''
        return `break${label};` + _n
      }
    }
    class Throw extends Node {
      constructor(error) {
        super()
        this.error = error
      }
      render({ _n }) {
        return `throw ${this.error};` + _n
      }
      get names() {
        return this.error.names
      }
    }
    class AnyCode extends Node {
      constructor(code) {
        super()
        this.code = code
      }
      render({ _n }) {
        return `${this.code};` + _n
      }
      optimizeNodes() {
        return `${this.code}` ? this : undefined
      }
      optimizeNames(names, constants) {
        this.code = optimizeExpr(this.code, names, constants)
        return this
      }
      get names() {
        return this.code instanceof code_1._CodeOrName ? this.code.names : {}
      }
    }
    class ParentNode extends Node {
      constructor(nodes = []) {
        super()
        this.nodes = nodes
      }
      render(opts) {
        return this.nodes.reduce((code, n) => code + n.render(opts), '')
      }
      optimizeNodes() {
        const { nodes } = this
        let i = nodes.length
        while (i--) {
          const n = nodes[i].optimizeNodes()
          if (Array.isArray(n)) {
            nodes.splice(i, 1, ...n)
          } else if (n) {
            nodes[i] = n
          } else {
            nodes.splice(i, 1)
          }
        }
        return nodes.length > 0 ? this : undefined
      }
      optimizeNames(names, constants) {
        const { nodes } = this
        let i = nodes.length
        while (i--) {
          // iterating backwards improves 1-pass optimization
          const n = nodes[i]
          if (n.optimizeNames(names, constants)) {
            continue
          }
          subtractNames(names, n.names)
          nodes.splice(i, 1)
        }
        return nodes.length > 0 ? this : undefined
      }
      get names() {
        return this.nodes.reduce((names, n) => addNames(names, n.names), {})
      }
    }
    class BlockNode extends ParentNode {
      render(opts) {
        return '{' + opts._n + super.render(opts) + '}' + opts._n
      }
    }
    class Root extends ParentNode {}
    class Else extends BlockNode {}
    Else.kind = 'else'
    class If extends BlockNode {
      constructor(condition, nodes) {
        super(nodes)
        this.condition = condition
      }
      render(opts) {
        let code = `if(${this.condition})` + super.render(opts)
        if (this.else) {
          code += 'else ' + this.else.render(opts)
        }
        return code
      }
      optimizeNodes() {
        super.optimizeNodes()
        const cond = this.condition
        if (cond === true) {
          return this.nodes
        } // else is ignored here
        let e = this.else
        if (e) {
          const ns = e.optimizeNodes()
          e = this.else = Array.isArray(ns) ? new Else(ns) : ns
        }
        if (e) {
          if (cond === false) {
            return e instanceof If ? e : e.nodes
          }
          if (this.nodes.length) {
            return this
          }
          return new If(not(cond), e instanceof If ? [e] : e.nodes)
        }
        if (cond === false || !this.nodes.length) {
          return undefined
        }
        return this
      }
      optimizeNames(names, constants) {
        let _a
        this.else =
          (_a = this.else) === null || _a === void 0
            ? void 0
            : _a.optimizeNames(names, constants)
        if (!(super.optimizeNames(names, constants) || this.else)) {
          return
        }
        this.condition = optimizeExpr(this.condition, names, constants)
        return this
      }
      get names() {
        const names = super.names
        addExprNames(names, this.condition)
        if (this.else) {
          addNames(names, this.else.names)
        }
        return names
      }
    }
    If.kind = 'if'
    class For extends BlockNode {}
    For.kind = 'for'
    class ForLoop extends For {
      constructor(iteration) {
        super()
        this.iteration = iteration
      }
      render(opts) {
        return `for(${this.iteration})` + super.render(opts)
      }
      optimizeNames(names, constants) {
        if (!super.optimizeNames(names, constants)) {
          return
        }
        this.iteration = optimizeExpr(this.iteration, names, constants)
        return this
      }
      get names() {
        return addNames(super.names, this.iteration.names)
      }
    }
    class ForRange extends For {
      constructor(varKind, name, from, to) {
        super()
        this.varKind = varKind
        this.name = name
        this.from = from
        this.to = to
      }
      render(opts) {
        const varKind = opts.es5 ? scope_1.varKinds.var : this.varKind
        const { name, from, to } = this
        return (
          `for(${varKind} ${name}=${from}; ${name}<${to}; ${name}++)` +
          super.render(opts)
        )
      }
      get names() {
        const names = addExprNames(super.names, this.from)
        return addExprNames(names, this.to)
      }
    }
    class ForIter extends For {
      constructor(loop, varKind, name, iterable) {
        super()
        this.loop = loop
        this.varKind = varKind
        this.name = name
        this.iterable = iterable
      }
      render(opts) {
        return (
          `for(${this.varKind} ${this.name} ${this.loop} ${this.iterable})` +
          super.render(opts)
        )
      }
      optimizeNames(names, constants) {
        if (!super.optimizeNames(names, constants)) {
          return
        }
        this.iterable = optimizeExpr(this.iterable, names, constants)
        return this
      }
      get names() {
        return addNames(super.names, this.iterable.names)
      }
    }
    class Func extends BlockNode {
      constructor(name, args, async) {
        super()
        this.name = name
        this.args = args
        this.async = async
      }
      render(opts) {
        const _async = this.async ? 'async ' : ''
        return (
          `${_async}function ${this.name}(${this.args})` + super.render(opts)
        )
      }
    }
    Func.kind = 'func'
    class Return extends ParentNode {
      render(opts) {
        return 'return ' + super.render(opts)
      }
    }
    Return.kind = 'return'
    class Try extends BlockNode {
      render(opts) {
        let code = 'try' + super.render(opts)
        if (this.catch) {
          code += this.catch.render(opts)
        }
        if (this.finally) {
          code += this.finally.render(opts)
        }
        return code
      }
      optimizeNodes() {
        let _a, _b
        super.optimizeNodes()
        ;(_a = this.catch) === null || _a === void 0
          ? void 0
          : _a.optimizeNodes()
        ;(_b = this.finally) === null || _b === void 0
          ? void 0
          : _b.optimizeNodes()
        return this
      }
      optimizeNames(names, constants) {
        let _a, _b
        super.optimizeNames(names, constants)
        ;(_a = this.catch) === null || _a === void 0
          ? void 0
          : _a.optimizeNames(names, constants)
        ;(_b = this.finally) === null || _b === void 0
          ? void 0
          : _b.optimizeNames(names, constants)
        return this
      }
      get names() {
        const names = super.names
        if (this.catch) {
          addNames(names, this.catch.names)
        }
        if (this.finally) {
          addNames(names, this.finally.names)
        }
        return names
      }
    }
    class Catch extends BlockNode {
      constructor(error) {
        super()
        this.error = error
      }
      render(opts) {
        return `catch(${this.error})` + super.render(opts)
      }
    }
    Catch.kind = 'catch'
    class Finally extends BlockNode {
      render(opts) {
        return 'finally' + super.render(opts)
      }
    }
    Finally.kind = 'finally'
    class CodeGen {
      constructor(extScope, opts = {}) {
        this._values = {}
        this._blockStarts = []
        this._constants = {}
        this.opts = {
          ...opts,
          _n: opts.lines ? '\n' : ''
        }
        this._extScope = extScope
        this._scope = new scope_1.Scope({
          parent: extScope
        })
        this._nodes = [new Root()]
      }
      toString() {
        return this._root.render(this.opts)
      }
      // returns unique name in the internal scope
      name(prefix) {
        return this._scope.name(prefix)
      }
      // reserves unique name in the external scope
      scopeName(prefix) {
        return this._extScope.name(prefix)
      }
      // reserves unique name in the external scope and assigns value to it
      scopeValue(prefixOrName, value) {
        const name = this._extScope.value(prefixOrName, value)
        const vs =
          this._values[name.prefix] || (this._values[name.prefix] = new Set())
        vs.add(name)
        return name
      }
      getScopeValue(prefix, keyOrRef) {
        return this._extScope.getValue(prefix, keyOrRef)
      }
      // return code that assigns values in the external scope to the names that are used internally
      // (same names that were returned by gen.scopeName or gen.scopeValue)
      scopeRefs(scopeName) {
        return this._extScope.scopeRefs(scopeName, this._values)
      }
      scopeCode() {
        return this._extScope.scopeCode(this._values)
      }
      _def(varKind, nameOrPrefix, rhs, constant) {
        const name = this._scope.toName(nameOrPrefix)
        if (rhs !== undefined && constant) {
          this._constants[name.str] = rhs
        }
        this._leafNode(new Def(varKind, name, rhs))
        return name
      }
      // `const` declaration (`var` in es5 mode)
      const(nameOrPrefix, rhs, _constant) {
        return this._def(scope_1.varKinds.const, nameOrPrefix, rhs, _constant)
      }
      // `let` declaration with optional assignment (`var` in es5 mode)
      let(nameOrPrefix, rhs, _constant) {
        return this._def(scope_1.varKinds.let, nameOrPrefix, rhs, _constant)
      }
      // `var` declaration with optional assignment
      var(nameOrPrefix, rhs, _constant) {
        return this._def(scope_1.varKinds.var, nameOrPrefix, rhs, _constant)
      }
      // assignment code
      assign(lhs, rhs, sideEffects) {
        return this._leafNode(new Assign(lhs, rhs, sideEffects))
      }
      // `+=` code
      add(lhs, rhs) {
        return this._leafNode(new AssignOp(lhs, exports.operators.ADD, rhs))
      }
      // appends passed SafeExpr to code or executes Block
      code(c) {
        if (typeof c == 'function') {
          c()
        } else if (c !== code_1.nil) {
          this._leafNode(new AnyCode(c))
        }
        return this
      }
      // returns code for object literal for the passed argument list of key-value pairs
      object(...keyValues) {
        const code = ['{']
        for (const [key, value] of keyValues) {
          if (code.length > 1) {
            code.push(',')
          }
          code.push(key)
          if (key !== value || this.opts.es5) {
            code.push(':')
            ;(0, code_1.addCodeArg)(code, value)
          }
        }
        code.push('}')
        return new code_1._Code(code)
      }
      // `if` clause (or statement if `thenBody` and, optionally, `elseBody` are passed)
      if(condition, thenBody, elseBody) {
        this._blockNode(new If(condition))
        if (thenBody && elseBody) {
          this.code(thenBody).else().code(elseBody).endIf()
        } else if (thenBody) {
          this.code(thenBody).endIf()
        } else if (elseBody) {
          throw new Error('CodeGen: "else" body without "then" body')
        }
        return this
      }
      // `else if` clause - invalid without `if` or after `else` clauses
      elseIf(condition) {
        return this._elseNode(new If(condition))
      }
      // `else` clause - only valid after `if` or `else if` clauses
      else() {
        return this._elseNode(new Else())
      }
      // end `if` statement (needed if gen.if was used only with condition)
      endIf() {
        return this._endBlockNode(If, Else)
      }
      _for(node, forBody) {
        this._blockNode(node)
        if (forBody) {
          this.code(forBody).endFor()
        }
        return this
      }
      // a generic `for` clause (or statement if `forBody` is passed)
      for(iteration, forBody) {
        return this._for(new ForLoop(iteration), forBody)
      }
      // `for` statement for a range of values
      forRange(
        nameOrPrefix,
        from,
        to,
        forBody,
        varKind = this.opts.es5 ? scope_1.varKinds.var : scope_1.varKinds.let
      ) {
        const name = this._scope.toName(nameOrPrefix)
        return this._for(new ForRange(varKind, name, from, to), () =>
          forBody(name)
        )
      }
      // `for-of` statement (in es5 mode replace with a normal for loop)
      forOf(nameOrPrefix, iterable, forBody, varKind = scope_1.varKinds.const) {
        const name = this._scope.toName(nameOrPrefix)
        if (this.opts.es5) {
          const arr =
            iterable instanceof code_1.Name
              ? iterable
              : this.var('_arr', iterable)
          return this.forRange('_i', 0, (0, code_1._)`${arr}.length`, i => {
            this.var(name, (0, code_1._)`${arr}[${i}]`)
            forBody(name)
          })
        }
        return this._for(new ForIter('of', varKind, name, iterable), () =>
          forBody(name)
        )
      }
      // `for-in` statement.
      // With option `ownProperties` replaced with a `for-of` loop for object keys
      forIn(
        nameOrPrefix,
        obj,
        forBody,
        varKind = this.opts.es5 ? scope_1.varKinds.var : scope_1.varKinds.const
      ) {
        if (this.opts.ownProperties) {
          return this.forOf(
            nameOrPrefix,
            (0, code_1._)`Object.keys(${obj})`,
            forBody
          )
        }
        const name = this._scope.toName(nameOrPrefix)
        return this._for(new ForIter('in', varKind, name, obj), () =>
          forBody(name)
        )
      }
      // end `for` loop
      endFor() {
        return this._endBlockNode(For)
      }
      // `label` statement
      label(label) {
        return this._leafNode(new Label(label))
      }
      // `break` statement
      break(label) {
        return this._leafNode(new Break(label))
      }
      // `return` statement
      return(value) {
        const node = new Return()
        this._blockNode(node)
        this.code(value)
        if (node.nodes.length !== 1) {
          throw new Error('CodeGen: "return" should have one node')
        }
        return this._endBlockNode(Return)
      }
      // `try` statement
      try(tryBody, catchCode, finallyCode) {
        if (!catchCode && !finallyCode) {
          throw new Error('CodeGen: "try" without "catch" and "finally"')
        }
        const node = new Try()
        this._blockNode(node)
        this.code(tryBody)
        if (catchCode) {
          const error = this.name('e')
          this._currNode = node.catch = new Catch(error)
          catchCode(error)
        }
        if (finallyCode) {
          this._currNode = node.finally = new Finally()
          this.code(finallyCode)
        }
        return this._endBlockNode(Catch, Finally)
      }
      // `throw` statement
      throw(error) {
        return this._leafNode(new Throw(error))
      }
      // start self-balancing block
      block(body, nodeCount) {
        this._blockStarts.push(this._nodes.length)
        if (body) {
          this.code(body).endBlock(nodeCount)
        }
        return this
      }
      // end the current self-balancing block
      endBlock(nodeCount) {
        const len = this._blockStarts.pop()
        if (len === undefined) {
          throw new Error('CodeGen: not in self-balancing block')
        }
        const toClose = this._nodes.length - len
        if (toClose < 0 || (nodeCount !== undefined && toClose !== nodeCount)) {
          throw new Error(
            `CodeGen: wrong number of nodes: ${toClose} vs ${nodeCount} expected`
          )
        }
        this._nodes.length = len
        return this
      }
      // `function` heading (or definition if funcBody is passed)
      func(name, args = code_1.nil, async, funcBody) {
        this._blockNode(new Func(name, args, async))
        if (funcBody) {
          this.code(funcBody).endFunc()
        }
        return this
      }
      // end function definition
      endFunc() {
        return this._endBlockNode(Func)
      }
      optimize(n = 1) {
        while (n-- > 0) {
          this._root.optimizeNodes()
          this._root.optimizeNames(this._root.names, this._constants)
        }
      }
      _leafNode(node) {
        this._currNode.nodes.push(node)
        return this
      }
      _blockNode(node) {
        this._currNode.nodes.push(node)
        this._nodes.push(node)
      }
      _endBlockNode(N1, N2) {
        const n = this._currNode
        if (n instanceof N1 || (N2 && n instanceof N2)) {
          this._nodes.pop()
          return this
        }
        throw new Error(
          `CodeGen: not in block "${N2 ? `${N1.kind}/${N2.kind}` : N1.kind}"`
        )
      }
      _elseNode(node) {
        const n = this._currNode
        if (!(n instanceof If)) {
          throw new Error('CodeGen: "else" without "if"')
        }
        this._currNode = n.else = node
        return this
      }
      get _root() {
        return this._nodes[0]
      }
      get _currNode() {
        const ns = this._nodes
        return ns[ns.length - 1]
      }
      set _currNode(node) {
        const ns = this._nodes
        ns[ns.length - 1] = node
      }
    }
    exports.CodeGen = CodeGen
    function addNames(names, from) {
      for (const n in from) {
        names[n] = (names[n] || 0) + (from[n] || 0)
      }
      return names
    }
    function addExprNames(names, from) {
      return from instanceof code_1._CodeOrName
        ? addNames(names, from.names)
        : names
    }
    function optimizeExpr(expr, names, constants) {
      if (expr instanceof code_1.Name) {
        return replaceName(expr)
      }
      if (!canOptimize(expr)) {
        return expr
      }
      return new code_1._Code(
        expr._items.reduce((items, c) => {
          if (c instanceof code_1.Name) {
            c = replaceName(c)
          }
          if (c instanceof code_1._Code) {
            items.push(...c._items)
          } else {
            items.push(c)
          }
          return items
        }, [])
      )
      function replaceName(n) {
        const c = constants[n.str]
        if (c === undefined || names[n.str] !== 1) {
          return n
        }
        delete names[n.str]
        return c
      }
      function canOptimize(e) {
        return (
          e instanceof code_1._Code &&
          e._items.some(
            c =>
              c instanceof code_1.Name &&
              names[c.str] === 1 &&
              constants[c.str] !== undefined
          )
        )
      }
    }
    function subtractNames(names, from) {
      for (const n in from) {
        names[n] = (names[n] || 0) - (from[n] || 0)
      }
    }
    function not(x) {
      return typeof x == 'boolean' || typeof x == 'number' || x === null
        ? !x
        : (0, code_1._)`!${par(x)}`
    }
    exports.not = not
    const andCode = mappend(exports.operators.AND)
    // boolean AND (&&) expression with the passed arguments
    function and(...args) {
      return args.reduce(andCode)
    }
    exports.and = and
    const orCode = mappend(exports.operators.OR)
    // boolean OR (||) expression with the passed arguments
    function or(...args) {
      return args.reduce(orCode)
    }
    exports.or = or
    function mappend(op) {
      return (x, y) =>
        x === code_1.nil
          ? y
          : y === code_1.nil
            ? x
            : (0, code_1._)`${par(x)} ${op} ${par(y)}`
    }
    function par(x) {
      return x instanceof code_1.Name ? x : (0, code_1._)`(${x})`
    }
  })(codegen)
  return codegen
}

const util$2 = {}

let hasRequiredUtil
function requireUtil() {
  if (hasRequiredUtil) {
    return util$2
  }
  hasRequiredUtil = 1
  Object.defineProperty(util$2, '__esModule', {
    value: true
  })
  util$2.checkStrictMode =
    util$2.getErrorPath =
    util$2.Type =
    util$2.useFunc =
    util$2.setEvaluated =
    util$2.evaluatedPropsToName =
    util$2.mergeEvaluated =
    util$2.eachItem =
    util$2.unescapeJsonPointer =
    util$2.escapeJsonPointer =
    util$2.escapeFragment =
    util$2.unescapeFragment =
    util$2.schemaRefOrVal =
    util$2.schemaHasRulesButRef =
    util$2.schemaHasRules =
    util$2.checkUnknownRules =
    util$2.alwaysValidSchema =
    util$2.toHash =
      void 0
  const codegen_1 = requireCodegen()
  const code_1 = requireCode$1()
  // TODO refactor to use Set
  function toHash(arr) {
    const hash = {}
    for (const item of arr) {
      hash[item] = true
    }
    return hash
  }
  util$2.toHash = toHash
  function alwaysValidSchema(it, schema) {
    if (typeof schema == 'boolean') {
      return schema
    }
    if (Object.keys(schema).length === 0) {
      return true
    }
    checkUnknownRules(it, schema)
    return !schemaHasRules(schema, it.self.RULES.all)
  }
  util$2.alwaysValidSchema = alwaysValidSchema
  function checkUnknownRules(it, schema = it.schema) {
    const { opts, self } = it
    if (!opts.strictSchema) {
      return
    }
    if (typeof schema === 'boolean') {
      return
    }
    const rules = self.RULES.keywords
    for (const key in schema) {
      if (!rules[key]) {
        checkStrictMode(it, `unknown keyword: "${key}"`)
      }
    }
  }
  util$2.checkUnknownRules = checkUnknownRules
  function schemaHasRules(schema, rules) {
    if (typeof schema == 'boolean') {
      return !schema
    }
    for (const key in schema) {
      if (rules[key]) return true
    }
    return false
  }
  util$2.schemaHasRules = schemaHasRules
  function schemaHasRulesButRef(schema, RULES) {
    if (typeof schema == 'boolean') {
      return !schema
    }
    for (const key in schema) {
      if (key !== '$ref' && RULES.all[key]) return true
    }
    return false
  }
  util$2.schemaHasRulesButRef = schemaHasRulesButRef
  function schemaRefOrVal(
    { topSchemaRef, schemaPath },
    schema,
    keyword,
    $data
  ) {
    if (!$data) {
      if (typeof schema == 'number' || typeof schema == 'boolean') {
        return schema
      }
      if (typeof schema == 'string') {
        return (0, codegen_1._)`${schema}`
      }
    }
    return (0,
    codegen_1._)`${topSchemaRef}${schemaPath}${(0, codegen_1.getProperty)(keyword)}`
  }
  util$2.schemaRefOrVal = schemaRefOrVal
  function unescapeFragment(str) {
    return unescapeJsonPointer(decodeURIComponent(str))
  }
  util$2.unescapeFragment = unescapeFragment
  function escapeFragment(str) {
    return encodeURIComponent(escapeJsonPointer(str))
  }
  util$2.escapeFragment = escapeFragment
  function escapeJsonPointer(str) {
    if (typeof str == 'number') {
      return `${str}`
    }
    return str.replace(/~/g, '~0').replace(/\//g, '~1')
  }
  util$2.escapeJsonPointer = escapeJsonPointer
  function unescapeJsonPointer(str) {
    return str.replace(/~1/g, '/').replace(/~0/g, '~')
  }
  util$2.unescapeJsonPointer = unescapeJsonPointer
  function eachItem(xs, f) {
    if (Array.isArray(xs)) {
      for (const x of xs) {
        f(x)
      }
    } else {
      f(xs)
    }
  }
  util$2.eachItem = eachItem
  function makeMergeEvaluated({
    mergeNames,
    mergeToName,
    mergeValues,
    resultToName
  }) {
    return (gen, from, to, toName) => {
      const res =
        to === undefined
          ? from
          : to instanceof codegen_1.Name
            ? (from instanceof codegen_1.Name
                ? mergeNames(gen, from, to)
                : mergeToName(gen, from, to),
              to)
            : from instanceof codegen_1.Name
              ? (mergeToName(gen, to, from), from)
              : mergeValues(from, to)
      return toName === codegen_1.Name && !(res instanceof codegen_1.Name)
        ? resultToName(gen, res)
        : res
    }
  }
  util$2.mergeEvaluated = {
    props: makeMergeEvaluated({
      mergeNames: (gen, from, to) =>
        gen.if(
          (0, codegen_1._)`${to} !== true && ${from} !== undefined`,
          () => {
            gen.if(
              (0, codegen_1._)`${from} === true`,
              () => gen.assign(to, true),
              () =>
                gen
                  .assign(to, (0, codegen_1._)`${to} || {}`)
                  .code((0, codegen_1._)`Object.assign(${to}, ${from})`)
            )
          }
        ),
      mergeToName: (gen, from, to) =>
        gen.if((0, codegen_1._)`${to} !== true`, () => {
          if (from === true) {
            gen.assign(to, true)
          } else {
            gen.assign(to, (0, codegen_1._)`${to} || {}`)
            setEvaluated(gen, to, from)
          }
        }),
      mergeValues: (from, to) =>
        from === true
          ? true
          : {
              ...from,
              ...to
            },
      resultToName: evaluatedPropsToName
    }),
    items: makeMergeEvaluated({
      mergeNames: (gen, from, to) =>
        gen.if((0, codegen_1._)`${to} !== true && ${from} !== undefined`, () =>
          gen.assign(
            to,
            (0,
            codegen_1._)`${from} === true ? true : ${to} > ${from} ? ${to} : ${from}`
          )
        ),
      mergeToName: (gen, from, to) =>
        gen.if((0, codegen_1._)`${to} !== true`, () =>
          gen.assign(
            to,
            from === true
              ? true
              : (0, codegen_1._)`${to} > ${from} ? ${to} : ${from}`
          )
        ),
      mergeValues: (from, to) => (from === true ? true : Math.max(from, to)),
      resultToName: (gen, items) => gen.var('items', items)
    })
  }
  function evaluatedPropsToName(gen, ps) {
    if (ps === true) {
      return gen.var('props', true)
    }
    const props = gen.var('props', (0, codegen_1._)`{}`)
    if (ps !== undefined) {
      setEvaluated(gen, props, ps)
    }
    return props
  }
  util$2.evaluatedPropsToName = evaluatedPropsToName
  function setEvaluated(gen, props, ps) {
    Object.keys(ps).forEach(p =>
      gen.assign(
        (0, codegen_1._)`${props}${(0, codegen_1.getProperty)(p)}`,
        true
      )
    )
  }
  util$2.setEvaluated = setEvaluated
  const snippets = {}
  function useFunc(gen, f) {
    return gen.scopeValue('func', {
      ref: f,
      code: snippets[f.code] || (snippets[f.code] = new code_1._Code(f.code))
    })
  }
  util$2.useFunc = useFunc
  let Type
  ;(function (Type) {
    Type[(Type['Num'] = 0)] = 'Num'
    Type[(Type['Str'] = 1)] = 'Str'
  })(Type || (util$2.Type = Type = {}))
  function getErrorPath(dataProp, dataPropType, jsPropertySyntax) {
    // let path
    if (dataProp instanceof codegen_1.Name) {
      const isNumber = dataPropType === Type.Num
      return jsPropertySyntax
        ? isNumber
          ? (0, codegen_1._)`"[" + ${dataProp} + "]"`
          : (0, codegen_1._)`"['" + ${dataProp} + "']"`
        : isNumber
          ? (0, codegen_1._)`"/" + ${dataProp}`
          : (0,
            codegen_1._)`"/" + ${dataProp}.replace(/~/g, "~0").replace(/\\//g, "~1")` // TODO maybe use global escapePointer
    }
    return jsPropertySyntax
      ? (0, codegen_1.getProperty)(dataProp).toString()
      : '/' + escapeJsonPointer(dataProp)
  }
  util$2.getErrorPath = getErrorPath
  function checkStrictMode(it, msg, mode = it.opts.strictSchema) {
    if (!mode) {
      return
    }
    msg = `strict mode: ${msg}`
    if (mode === true) {
      throw new Error(msg)
    }
    it.self.logger.warn(msg)
  }
  util$2.checkStrictMode = checkStrictMode
  return util$2
}

const names = {}

let hasRequiredNames
function requireNames() {
  if (hasRequiredNames) {
    return names
  }
  hasRequiredNames = 1
  Object.defineProperty(names, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const names$1 = {
    // validation function arguments
    data: new codegen_1.Name('data'),
    // data passed to validation function
    // args passed from referencing schema
    valCxt: new codegen_1.Name('valCxt'),
    // validation/data context - should not be used directly, it is destructured to the names below
    instancePath: new codegen_1.Name('instancePath'),
    parentData: new codegen_1.Name('parentData'),
    parentDataProperty: new codegen_1.Name('parentDataProperty'),
    rootData: new codegen_1.Name('rootData'),
    // root data - same as the data passed to the first/top validation function
    dynamicAnchors: new codegen_1.Name('dynamicAnchors'),
    // used to support recursiveRef and dynamicRef
    // function scoped variables
    vErrors: new codegen_1.Name('vErrors'),
    // null or array of validation errors
    errors: new codegen_1.Name('errors'),
    // counter of validation errors
    this: new codegen_1.Name('this'),
    // "globals"
    self: new codegen_1.Name('self'),
    scope: new codegen_1.Name('scope'),
    // JTD serialize/parse name for JSON string and position
    json: new codegen_1.Name('json'),
    jsonPos: new codegen_1.Name('jsonPos'),
    jsonLen: new codegen_1.Name('jsonLen'),
    jsonPart: new codegen_1.Name('jsonPart')
  }
  names.default = names$1
  return names
}

let hasRequiredErrors$4
function requireErrors$4() {
  if (hasRequiredErrors$4) {
    return errors$4
  }
  hasRequiredErrors$4 = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.extendErrors =
      exports.resetErrorsCount =
      exports.reportExtraError =
      exports.reportError =
      exports.keyword$DataError =
      exports.keywordError =
        void 0
    const codegen_1 = requireCodegen()
    const util_1 = requireUtil()
    const names_1 = requireNames()
    exports.keywordError = {
      message: ({ keyword }) =>
        (0, codegen_1.str)`must pass "${keyword}" keyword validation`
    }
    exports.keyword$DataError = {
      message: ({ keyword, schemaType }) =>
        schemaType
          ? (0,
            codegen_1.str)`"${keyword}" keyword must be ${schemaType} ($data)`
          : (0, codegen_1.str)`"${keyword}" keyword is invalid ($data)`
    }
    function reportError(
      cxt,
      error = exports.keywordError,
      errorPaths,
      overrideAllErrors
    ) {
      const { it } = cxt
      const { gen, compositeRule, allErrors } = it
      const errObj = errorObjectCode(cxt, error, errorPaths)
      if (
        overrideAllErrors !== null && overrideAllErrors !== void 0
          ? overrideAllErrors
          : compositeRule || allErrors
      ) {
        addError(gen, errObj)
      } else {
        returnErrors(it, (0, codegen_1._)`[${errObj}]`)
      }
    }
    exports.reportError = reportError
    function reportExtraError(cxt, error = exports.keywordError, errorPaths) {
      const { it } = cxt
      const { gen, compositeRule, allErrors } = it
      const errObj = errorObjectCode(cxt, error, errorPaths)
      addError(gen, errObj)
      if (!(compositeRule || allErrors)) {
        returnErrors(it, names_1.default.vErrors)
      }
    }
    exports.reportExtraError = reportExtraError
    function resetErrorsCount(gen, errsCount) {
      gen.assign(names_1.default.errors, errsCount)
      gen.if((0, codegen_1._)`${names_1.default.vErrors} !== null`, () =>
        gen.if(
          errsCount,
          () =>
            gen.assign(
              (0, codegen_1._)`${names_1.default.vErrors}.length`,
              errsCount
            ),
          () => gen.assign(names_1.default.vErrors, null)
        )
      )
    }
    exports.resetErrorsCount = resetErrorsCount
    function extendErrors({ gen, keyword, schemaValue, data, errsCount, it }) {
      /* istanbul ignore if */
      if (errsCount === undefined) {
        throw new Error('ajv implementation error')
      }
      const err = gen.name('err')
      gen.forRange('i', errsCount, names_1.default.errors, i => {
        gen.const(err, (0, codegen_1._)`${names_1.default.vErrors}[${i}]`)
        gen.if((0, codegen_1._)`${err}.instancePath === undefined`, () =>
          gen.assign(
            (0, codegen_1._)`${err}.instancePath`,
            (0, codegen_1.strConcat)(names_1.default.instancePath, it.errorPath)
          )
        )
        gen.assign(
          (0, codegen_1._)`${err}.schemaPath`,
          (0, codegen_1.str)`${it.errSchemaPath}/${keyword}`
        )
        if (it.opts.verbose) {
          gen.assign((0, codegen_1._)`${err}.schema`, schemaValue)
          gen.assign((0, codegen_1._)`${err}.data`, data)
        }
      })
    }
    exports.extendErrors = extendErrors
    function addError(gen, errObj) {
      const err = gen.const('err', errObj)
      gen.if(
        (0, codegen_1._)`${names_1.default.vErrors} === null`,
        () => gen.assign(names_1.default.vErrors, (0, codegen_1._)`[${err}]`),
        (0, codegen_1._)`${names_1.default.vErrors}.push(${err})`
      )
      gen.code((0, codegen_1._)`${names_1.default.errors}++`)
    }
    function returnErrors(it, errs) {
      const { gen, validateName, schemaEnv } = it
      if (schemaEnv.$async) {
        gen.throw((0, codegen_1._)`new ${it.ValidationError}(${errs})`)
      } else {
        gen.assign((0, codegen_1._)`${validateName}.errors`, errs)
        gen.return(false)
      }
    }
    const E = {
      keyword: new codegen_1.Name('keyword'),
      schemaPath: new codegen_1.Name('schemaPath'),
      // also used in JTD errors
      params: new codegen_1.Name('params'),
      propertyName: new codegen_1.Name('propertyName'),
      message: new codegen_1.Name('message'),
      schema: new codegen_1.Name('schema'),
      parentSchema: new codegen_1.Name('parentSchema')
    }
    function errorObjectCode(cxt, error, errorPaths) {
      const { createErrors } = cxt.it
      if (createErrors === false) {
        return (0, codegen_1._)`{}`
      }
      return errorObject(cxt, error, errorPaths)
    }
    function errorObject(cxt, error, errorPaths = {}) {
      const { gen, it } = cxt
      const keyValues = [
        errorInstancePath(it, errorPaths),
        errorSchemaPath(cxt, errorPaths)
      ]
      extraErrorProps(cxt, error, keyValues)
      return gen.object(...keyValues)
    }
    function errorInstancePath({ errorPath }, { instancePath }) {
      const instPath = instancePath
        ? (0,
          codegen_1.str)`${errorPath}${(0, util_1.getErrorPath)(instancePath, util_1.Type.Str)}`
        : errorPath
      return [
        names_1.default.instancePath,
        (0, codegen_1.strConcat)(names_1.default.instancePath, instPath)
      ]
    }
    function errorSchemaPath(
      { keyword, it: { errSchemaPath } },
      { schemaPath, parentSchema }
    ) {
      let schPath = parentSchema
        ? errSchemaPath
        : (0, codegen_1.str)`${errSchemaPath}/${keyword}`
      if (schemaPath) {
        schPath = (0,
        codegen_1.str)`${schPath}${(0, util_1.getErrorPath)(schemaPath, util_1.Type.Str)}`
      }
      return [E.schemaPath, schPath]
    }
    function extraErrorProps(cxt, { params, message }, keyValues) {
      const { keyword, data, schemaValue, it } = cxt
      const { opts, propertyName, topSchemaRef, schemaPath } = it
      keyValues.push(
        [E.keyword, keyword],
        [
          E.params,
          typeof params == 'function'
            ? params(cxt)
            : params || (0, codegen_1._)`{}`
        ]
      )
      if (opts.messages) {
        keyValues.push([
          E.message,
          typeof message == 'function' ? message(cxt) : message
        ])
      }
      if (opts.verbose) {
        keyValues.push(
          [E.schema, schemaValue],
          [E.parentSchema, (0, codegen_1._)`${topSchemaRef}${schemaPath}`],
          [names_1.default.data, data]
        )
      }
      if (propertyName) {
        keyValues.push([E.propertyName, propertyName])
      }
    }
  })(errors$4)
  return errors$4
}

let hasRequiredBoolSchema
function requireBoolSchema() {
  if (hasRequiredBoolSchema) {
    return boolSchema
  }
  hasRequiredBoolSchema = 1
  Object.defineProperty(boolSchema, '__esModule', {
    value: true
  })
  boolSchema.boolOrEmptySchema = boolSchema.topBoolOrEmptySchema = void 0
  const errors_1 = requireErrors$4()
  const codegen_1 = requireCodegen()
  const names_1 = requireNames()
  const boolError = {
    message: 'boolean schema is false'
  }
  function topBoolOrEmptySchema(it) {
    const { gen, schema, validateName } = it
    if (schema === false) {
      falseSchemaError(it, false)
    } else if (typeof schema == 'object' && schema.$async === true) {
      gen.return(names_1.default.data)
    } else {
      gen.assign((0, codegen_1._)`${validateName}.errors`, null)
      gen.return(true)
    }
  }
  boolSchema.topBoolOrEmptySchema = topBoolOrEmptySchema
  function boolOrEmptySchema(it, valid) {
    const { gen, schema } = it
    if (schema === false) {
      gen.var(valid, false) // TODO var
      falseSchemaError(it)
    } else {
      gen.var(valid, true) // TODO var
    }
  }
  boolSchema.boolOrEmptySchema = boolOrEmptySchema
  function falseSchemaError(it, overrideAllErrors) {
    const { gen, data } = it
    // TODO maybe some other interface should be used for non-keyword validation errors...
    const cxt = {
      gen,
      keyword: 'false schema',
      data,
      schema: false,
      schemaCode: false,
      schemaValue: false,
      params: {},
      it
    }
    ;(0, errors_1.reportError)(cxt, boolError, undefined, overrideAllErrors)
  }
  return boolSchema
}

const dataType = {}

const rules = {}

let hasRequiredRules
function requireRules() {
  if (hasRequiredRules) {
    return rules
  }
  hasRequiredRules = 1
  Object.defineProperty(rules, '__esModule', {
    value: true
  })
  rules.getRules = rules.isJSONType = void 0
  const _jsonTypes = [
    'string',
    'number',
    'integer',
    'boolean',
    'null',
    'object',
    'array'
  ]
  const jsonTypes = new Set(_jsonTypes)
  function isJSONType(x) {
    return typeof x == 'string' && jsonTypes.has(x)
  }
  rules.isJSONType = isJSONType
  function getRules() {
    const groups = {
      number: {
        type: 'number',
        rules: []
      },
      string: {
        type: 'string',
        rules: []
      },
      array: {
        type: 'array',
        rules: []
      },
      object: {
        type: 'object',
        rules: []
      }
    }
    return {
      types: {
        ...groups,
        integer: true,
        boolean: true,
        null: true
      },
      rules: [
        {
          rules: []
        },
        groups.number,
        groups.string,
        groups.array,
        groups.object
      ],
      post: {
        rules: []
      },
      all: {},
      keywords: {}
    }
  }
  rules.getRules = getRules
  return rules
}

const applicability = {}

let hasRequiredApplicability
function requireApplicability() {
  if (hasRequiredApplicability) {
    return applicability
  }
  hasRequiredApplicability = 1
  Object.defineProperty(applicability, '__esModule', {
    value: true
  })
  applicability.shouldUseRule =
    applicability.shouldUseGroup =
    applicability.schemaHasRulesForType =
      void 0
  function schemaHasRulesForType({ schema, self }, type) {
    const group = self.RULES.types[type]
    return group && group !== true && shouldUseGroup(schema, group)
  }
  applicability.schemaHasRulesForType = schemaHasRulesForType
  function shouldUseGroup(schema, group) {
    return group.rules.some(rule => shouldUseRule(schema, rule))
  }
  applicability.shouldUseGroup = shouldUseGroup
  function shouldUseRule(schema, rule) {
    let _a
    return (
      schema[rule.keyword] !== undefined ||
      ((_a = rule.definition.implements) === null || _a === void 0
        ? void 0
        : _a.some(kwd => schema[kwd] !== undefined))
    )
  }
  applicability.shouldUseRule = shouldUseRule
  return applicability
}

let hasRequiredDataType
function requireDataType() {
  if (hasRequiredDataType) {
    return dataType
  }
  hasRequiredDataType = 1
  Object.defineProperty(dataType, '__esModule', {
    value: true
  })
  dataType.reportTypeError =
    dataType.checkDataTypes =
    dataType.checkDataType =
    dataType.coerceAndCheckDataType =
    dataType.getJSONTypes =
    dataType.getSchemaTypes =
    dataType.DataType =
      void 0
  const rules_1 = requireRules()
  const applicability_1 = requireApplicability()
  const errors_1 = requireErrors$4()
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  let DataType
  ;(function (DataType) {
    DataType[(DataType['Correct'] = 0)] = 'Correct'
    DataType[(DataType['Wrong'] = 1)] = 'Wrong'
  })(DataType || (dataType.DataType = DataType = {}))
  function getSchemaTypes(schema) {
    const types = getJSONTypes(schema.type)
    const hasNull = types.includes('null')
    if (hasNull) {
      if (schema.nullable === false) {
        throw new Error('type: null contradicts nullable: false')
      }
    } else {
      if (!types.length && schema.nullable !== undefined) {
        throw new Error('"nullable" cannot be used without "type"')
      }
      if (schema.nullable === true) {
        types.push('null')
      }
    }
    return types
  }
  dataType.getSchemaTypes = getSchemaTypes
  // eslint-disable-next-line @typescript-eslint/no-redundant-type-constituents
  function getJSONTypes(ts) {
    const types = Array.isArray(ts) ? ts : ts ? [ts] : []
    if (types.every(rules_1.isJSONType)) {
      return types
    }
    throw new Error('type must be JSONType or JSONType[]: ' + types.join(','))
  }
  dataType.getJSONTypes = getJSONTypes
  function coerceAndCheckDataType(it, types) {
    const { gen, data, opts } = it
    const coerceTo = coerceToTypes(types, opts.coerceTypes)
    const checkTypes =
      types.length > 0 &&
      !(
        coerceTo.length === 0 &&
        types.length === 1 &&
        (0, applicability_1.schemaHasRulesForType)(it, types[0])
      )
    if (checkTypes) {
      const wrongType = checkDataTypes(
        types,
        data,
        opts.strictNumbers,
        DataType.Wrong
      )
      gen.if(wrongType, () => {
        if (coerceTo.length) {
          coerceData(it, types, coerceTo)
        } else {
          reportTypeError(it)
        }
      })
    }
    return checkTypes
  }
  dataType.coerceAndCheckDataType = coerceAndCheckDataType
  const COERCIBLE = new Set(['string', 'number', 'integer', 'boolean', 'null'])
  function coerceToTypes(types, coerceTypes) {
    return coerceTypes
      ? types.filter(
          t => COERCIBLE.has(t) || (coerceTypes === 'array' && t === 'array')
        )
      : []
  }
  function coerceData(it, types, coerceTo) {
    const { gen, data, opts } = it
    const dataType = gen.let('dataType', (0, codegen_1._)`typeof ${data}`)
    const coerced = gen.let('coerced', (0, codegen_1._)`undefined`)
    if (opts.coerceTypes === 'array') {
      gen.if(
        (0,
        codegen_1._)`${dataType} == 'object' && Array.isArray(${data}) && ${data}.length == 1`,
        () =>
          gen
            .assign(data, (0, codegen_1._)`${data}[0]`)
            .assign(dataType, (0, codegen_1._)`typeof ${data}`)
            .if(checkDataTypes(types, data, opts.strictNumbers), () =>
              gen.assign(coerced, data)
            )
      )
    }
    gen.if((0, codegen_1._)`${coerced} !== undefined`)
    for (const t of coerceTo) {
      if (COERCIBLE.has(t) || (t === 'array' && opts.coerceTypes === 'array')) {
        coerceSpecificType(t)
      }
    }
    gen.else()
    reportTypeError(it)
    gen.endIf()
    gen.if((0, codegen_1._)`${coerced} !== undefined`, () => {
      gen.assign(data, coerced)
      assignParentData(it, coerced)
    })
    function coerceSpecificType(t) {
      switch (t) {
        case 'string':
          gen
            .elseIf(
              (0,
              codegen_1._)`${dataType} == "number" || ${dataType} == "boolean"`
            )
            .assign(coerced, (0, codegen_1._)`"" + ${data}`)
            .elseIf((0, codegen_1._)`${data} === null`)
            .assign(coerced, (0, codegen_1._)`""`)
          return
        case 'number':
          gen
            .elseIf((0,
            codegen_1._)`${dataType} == "boolean" || ${data} === null
              || (${dataType} == "string" && ${data} && ${data} == +${data})`)
            .assign(coerced, (0, codegen_1._)`+${data}`)
          return
        case 'integer':
          gen
            .elseIf((0,
            codegen_1._)`${dataType} === "boolean" || ${data} === null
              || (${dataType} === "string" && ${data} && ${data} == +${data} && !(${data} % 1))`)
            .assign(coerced, (0, codegen_1._)`+${data}`)
          return
        case 'boolean':
          gen
            .elseIf(
              (0,
              codegen_1._)`${data} === "false" || ${data} === 0 || ${data} === null`
            )
            .assign(coerced, false)
            .elseIf((0, codegen_1._)`${data} === "true" || ${data} === 1`)
            .assign(coerced, true)
          return
        case 'null':
          gen.elseIf(
            (0,
            codegen_1._)`${data} === "" || ${data} === 0 || ${data} === false`
          )
          gen.assign(coerced, null)
          return
        case 'array':
          gen
            .elseIf((0,
            codegen_1._)`${dataType} === "string" || ${dataType} === "number"
              || ${dataType} === "boolean" || ${data} === null`)
            .assign(coerced, (0, codegen_1._)`[${data}]`)
      }
    }
  }
  function assignParentData({ gen, parentData, parentDataProperty }, expr) {
    // TODO use gen.property
    gen.if((0, codegen_1._)`${parentData} !== undefined`, () =>
      gen.assign((0, codegen_1._)`${parentData}[${parentDataProperty}]`, expr)
    )
  }
  function checkDataType(
    dataType,
    data,
    strictNums,
    correct = DataType.Correct
  ) {
    const EQ =
      correct === DataType.Correct
        ? codegen_1.operators.EQ
        : codegen_1.operators.NEQ
    let cond
    switch (dataType) {
      case 'null':
        return (0, codegen_1._)`${data} ${EQ} null`
      case 'array':
        cond = (0, codegen_1._)`Array.isArray(${data})`
        break
      case 'object':
        cond = (0,
        codegen_1._)`${data} && typeof ${data} == "object" && !Array.isArray(${data})`
        break
      case 'integer':
        cond = numCond((0, codegen_1._)`!(${data} % 1) && !isNaN(${data})`)
        break
      case 'number':
        cond = numCond()
        break
      default:
        return (0, codegen_1._)`typeof ${data} ${EQ} ${dataType}`
    }
    return correct === DataType.Correct ? cond : (0, codegen_1.not)(cond)
    function numCond(_cond = codegen_1.nil) {
      return (0, codegen_1.and)(
        (0, codegen_1._)`typeof ${data} == "number"`,
        _cond,
        strictNums ? (0, codegen_1._)`isFinite(${data})` : codegen_1.nil
      )
    }
  }
  dataType.checkDataType = checkDataType
  function checkDataTypes(dataTypes, data, strictNums, correct) {
    if (dataTypes.length === 1) {
      return checkDataType(dataTypes[0], data, strictNums, correct)
    }
    let cond
    const types = (0, util_1.toHash)(dataTypes)
    if (types.array && types.object) {
      const notObj = (0, codegen_1._)`typeof ${data} != "object"`
      cond = types.null ? notObj : (0, codegen_1._)`!${data} || ${notObj}`
      delete types.null
      delete types.array
      delete types.object
    } else {
      cond = codegen_1.nil
    }
    if (types.number) {
      delete types.integer
    }
    for (const t in types) {
      cond = (0, codegen_1.and)(
        cond,
        checkDataType(t, data, strictNums, correct)
      )
    }
    return cond
  }
  dataType.checkDataTypes = checkDataTypes
  const typeError = {
    message: ({ schema }) => `must be ${schema}`,
    params: ({ schema, schemaValue }) =>
      typeof schema == 'string'
        ? (0, codegen_1._)`{type: ${schema}}`
        : (0, codegen_1._)`{type: ${schemaValue}}`
  }
  function reportTypeError(it) {
    const cxt = getTypeErrorContext(it)
    ;(0, errors_1.reportError)(cxt, typeError)
  }
  dataType.reportTypeError = reportTypeError
  function getTypeErrorContext(it) {
    const { gen, data, schema } = it
    const schemaCode = (0, util_1.schemaRefOrVal)(it, schema, 'type')
    return {
      gen,
      keyword: 'type',
      data,
      schema: schema.type,
      schemaCode,
      schemaValue: schemaCode,
      parentSchema: schema,
      params: {},
      it
    }
  }
  return dataType
}

const defaults$1 = {}

let hasRequiredDefaults
function requireDefaults() {
  if (hasRequiredDefaults) {
    return defaults$1
  }
  hasRequiredDefaults = 1
  Object.defineProperty(defaults$1, '__esModule', {
    value: true
  })
  defaults$1.assignDefaults = void 0
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  function assignDefaults(it, ty) {
    const { properties, items } = it.schema
    if (ty === 'object' && properties) {
      for (const key in properties) {
        assignDefault(it, key, properties[key].default)
      }
    } else if (ty === 'array' && Array.isArray(items)) {
      items.forEach((sch, i) => assignDefault(it, i, sch.default))
    }
  }
  defaults$1.assignDefaults = assignDefaults
  function assignDefault(it, prop, defaultValue) {
    const { gen, compositeRule, data, opts } = it
    if (defaultValue === undefined) {
      return
    }
    const childData = (0,
    codegen_1._)`${data}${(0, codegen_1.getProperty)(prop)}`
    if (compositeRule) {
      ;(0, util_1.checkStrictMode)(it, `default is ignored for: ${childData}`)
      return
    }
    let condition = (0, codegen_1._)`${childData} === undefined`
    if (opts.useDefaults === 'empty') {
      condition = (0,
      codegen_1._)`${condition} || ${childData} === null || ${childData} === ""`
    }
    // `${childData} === undefined` +
    // (opts.useDefaults === "empty" ? ` || ${childData} === null || ${childData} === ""` : "")
    gen.if(
      condition,
      (0, codegen_1._)`${childData} = ${(0, codegen_1.stringify)(defaultValue)}`
    )
  }
  return defaults$1
}

const keyword$1 = {}

const code = {}

let hasRequiredCode
function requireCode() {
  if (hasRequiredCode) {
    return code
  }
  hasRequiredCode = 1
  Object.defineProperty(code, '__esModule', {
    value: true
  })
  code.validateUnion =
    code.validateArray =
    code.usePattern =
    code.callValidateCode =
    code.schemaProperties =
    code.allSchemaProperties =
    code.noPropertyInData =
    code.propertyInData =
    code.isOwnProperty =
    code.hasPropFunc =
    code.reportMissingProp =
    code.checkMissingProp =
    code.checkReportMissingProp =
      void 0
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const names_1 = requireNames()
  const util_2 = requireUtil()
  function checkReportMissingProp(cxt, prop) {
    const { gen, data, it } = cxt
    gen.if(noPropertyInData(gen, data, prop, it.opts.ownProperties), () => {
      cxt.setParams(
        {
          missingProperty: (0, codegen_1._)`${prop}`
        },
        true
      )
      cxt.error()
    })
  }
  code.checkReportMissingProp = checkReportMissingProp
  function checkMissingProp({ gen, data, it: { opts } }, properties, missing) {
    return (0, codegen_1.or)(
      ...properties.map(prop =>
        (0, codegen_1.and)(
          noPropertyInData(gen, data, prop, opts.ownProperties),
          (0, codegen_1._)`${missing} = ${prop}`
        )
      )
    )
  }
  code.checkMissingProp = checkMissingProp
  function reportMissingProp(cxt, missing) {
    cxt.setParams(
      {
        missingProperty: missing
      },
      true
    )
    cxt.error()
  }
  code.reportMissingProp = reportMissingProp
  function hasPropFunc(gen) {
    return gen.scopeValue('func', {
      // eslint-disable-next-line @typescript-eslint/unbound-method
      ref: Object.prototype.hasOwnProperty,
      code: (0, codegen_1._)`Object.prototype.hasOwnProperty`
    })
  }
  code.hasPropFunc = hasPropFunc
  function isOwnProperty(gen, data, property) {
    return (0, codegen_1._)`${hasPropFunc(gen)}.call(${data}, ${property})`
  }
  code.isOwnProperty = isOwnProperty
  function propertyInData(gen, data, property, ownProperties) {
    const cond = (0,
    codegen_1._)`${data}${(0, codegen_1.getProperty)(property)} !== undefined`
    return ownProperties
      ? (0, codegen_1._)`${cond} && ${isOwnProperty(gen, data, property)}`
      : cond
  }
  code.propertyInData = propertyInData
  function noPropertyInData(gen, data, property, ownProperties) {
    const cond = (0,
    codegen_1._)`${data}${(0, codegen_1.getProperty)(property)} === undefined`
    return ownProperties
      ? (0, codegen_1.or)(
          cond,
          (0, codegen_1.not)(isOwnProperty(gen, data, property))
        )
      : cond
  }
  code.noPropertyInData = noPropertyInData
  function allSchemaProperties(schemaMap) {
    return schemaMap
      ? Object.keys(schemaMap).filter(p => p !== '__proto__')
      : []
  }
  code.allSchemaProperties = allSchemaProperties
  function schemaProperties(it, schemaMap) {
    return allSchemaProperties(schemaMap).filter(
      p => !(0, util_1.alwaysValidSchema)(it, schemaMap[p])
    )
  }
  code.schemaProperties = schemaProperties
  function callValidateCode(
    { schemaCode, data, it: { gen, topSchemaRef, schemaPath, errorPath }, it },
    func,
    context,
    passSchema
  ) {
    const dataAndSchema = passSchema
      ? (0, codegen_1._)`${schemaCode}, ${data}, ${topSchemaRef}${schemaPath}`
      : data
    const valCxt = [
      [
        names_1.default.instancePath,
        (0, codegen_1.strConcat)(names_1.default.instancePath, errorPath)
      ],
      [names_1.default.parentData, it.parentData],
      [names_1.default.parentDataProperty, it.parentDataProperty],
      [names_1.default.rootData, names_1.default.rootData]
    ]
    if (it.opts.dynamicRef) {
      valCxt.push([
        names_1.default.dynamicAnchors,
        names_1.default.dynamicAnchors
      ])
    }
    const args = (0, codegen_1._)`${dataAndSchema}, ${gen.object(...valCxt)}`
    return context !== codegen_1.nil
      ? (0, codegen_1._)`${func}.call(${context}, ${args})`
      : (0, codegen_1._)`${func}(${args})`
  }
  code.callValidateCode = callValidateCode
  const newRegExp = (0, codegen_1._)`new RegExp`
  function usePattern({ gen, it: { opts } }, pattern) {
    const u = opts.unicodeRegExp ? 'u' : ''
    const { regExp } = opts.code
    const rx = regExp(pattern, u)
    return gen.scopeValue('pattern', {
      key: rx.toString(),
      ref: rx,
      code: (0,
      codegen_1._)`${regExp.code === 'new RegExp' ? newRegExp : ((0, util_2.useFunc))(gen, regExp)}(${pattern}, ${u})`
    })
  }
  code.usePattern = usePattern
  function validateArray(cxt) {
    const { gen, data, keyword, it } = cxt
    const valid = gen.name('valid')
    if (it.allErrors) {
      const validArr = gen.let('valid', true)
      validateItems(() => gen.assign(validArr, false))
      return validArr
    }
    gen.var(valid, true)
    validateItems(() => gen.break())
    return valid
    function validateItems(notValid) {
      const len = gen.const('len', (0, codegen_1._)`${data}.length`)
      gen.forRange('i', 0, len, i => {
        cxt.subschema(
          {
            keyword,
            dataProp: i,
            dataPropType: util_1.Type.Num
          },
          valid
        )
        gen.if((0, codegen_1.not)(valid), notValid)
      })
    }
  }
  code.validateArray = validateArray
  function validateUnion(cxt) {
    const { gen, schema, keyword, it } = cxt
    /* istanbul ignore if */
    if (!Array.isArray(schema)) {
      throw new Error('ajv implementation error')
    }
    const alwaysValid = schema.some(sch =>
      (0, util_1.alwaysValidSchema)(it, sch)
    )
    if (alwaysValid && !it.opts.unevaluated) {
      return
    }
    const valid = gen.let('valid', false)
    const schValid = gen.name('_valid')
    gen.block(() =>
      schema.forEach((_sch, i) => {
        const schCxt = cxt.subschema(
          {
            keyword,
            schemaProp: i,
            compositeRule: true
          },
          schValid
        )
        gen.assign(valid, (0, codegen_1._)`${valid} || ${schValid}`)
        const merged = cxt.mergeValidEvaluated(schCxt, schValid)
        // can short-circuit if `unevaluatedProperties/Items` not supported (opts.unevaluated !== true)
        // or if all properties and items were evaluated (it.props === true && it.items === true)
        if (!merged) {
          gen.if((0, codegen_1.not)(valid))
        }
      })
    )
    cxt.result(
      valid,
      () => cxt.reset(),
      () => cxt.error(true)
    )
  }
  code.validateUnion = validateUnion
  return code
}

let hasRequiredKeyword
function requireKeyword() {
  if (hasRequiredKeyword) {
    return keyword$1
  }
  hasRequiredKeyword = 1
  Object.defineProperty(keyword$1, '__esModule', {
    value: true
  })
  keyword$1.validateKeywordUsage =
    keyword$1.validSchemaType =
    keyword$1.funcKeywordCode =
    keyword$1.macroKeywordCode =
      void 0
  const codegen_1 = requireCodegen()
  const names_1 = requireNames()
  const code_1 = requireCode()
  const errors_1 = requireErrors$4()
  function macroKeywordCode(cxt, def) {
    const { gen, keyword, schema, parentSchema, it } = cxt
    const macroSchema = def.macro.call(it.self, schema, parentSchema, it)
    const schemaRef = useKeyword(gen, keyword, macroSchema)
    if (it.opts.validateSchema !== false) {
      it.self.validateSchema(macroSchema, true)
    }
    const valid = gen.name('valid')
    cxt.subschema(
      {
        schema: macroSchema,
        schemaPath: codegen_1.nil,
        errSchemaPath: `${it.errSchemaPath}/${keyword}`,
        topSchemaRef: schemaRef,
        compositeRule: true
      },
      valid
    )
    cxt.pass(valid, () => cxt.error(true))
  }
  keyword$1.macroKeywordCode = macroKeywordCode
  function funcKeywordCode(cxt, def) {
    let _a
    const { gen, keyword, schema, parentSchema, $data, it } = cxt
    checkAsyncKeyword(it, def)
    const validate =
      !$data && def.compile
        ? def.compile.call(it.self, schema, parentSchema, it)
        : def.validate
    const validateRef = useKeyword(gen, keyword, validate)
    const valid = gen.let('valid')
    cxt.block$data(valid, validateKeyword)
    cxt.ok((_a = def.valid) !== null && _a !== void 0 ? _a : valid)
    function validateKeyword() {
      if (def.errors === false) {
        assignValid()
        if (def.modifying) {
          modifyData(cxt)
        }
        reportErrs(() => cxt.error())
      } else {
        const ruleErrs = def.async ? validateAsync() : validateSync()
        if (def.modifying) {
          modifyData(cxt)
        }
        reportErrs(() => addErrs(cxt, ruleErrs))
      }
    }
    function validateAsync() {
      const ruleErrs = gen.let('ruleErrs', null)
      gen.try(
        () => assignValid((0, codegen_1._)`await `),
        e =>
          gen.assign(valid, false).if(
            (0, codegen_1._)`${e} instanceof ${it.ValidationError}`,
            () => gen.assign(ruleErrs, (0, codegen_1._)`${e}.errors`),
            () => gen.throw(e)
          )
      )
      return ruleErrs
    }
    function validateSync() {
      const validateErrs = (0, codegen_1._)`${validateRef}.errors`
      gen.assign(validateErrs, null)
      assignValid(codegen_1.nil)
      return validateErrs
    }
    function assignValid(
      _await = def.async ? (0, codegen_1._)`await ` : codegen_1.nil
    ) {
      const passCxt = it.opts.passContext
        ? names_1.default.this
        : names_1.default.self
      const passSchema = !(('compile' in def && !$data) || def.schema === false)
      gen.assign(
        valid,
        (0,
        codegen_1._)`${_await}${(0, code_1.callValidateCode)(cxt, validateRef, passCxt, passSchema)}`,
        def.modifying
      )
    }
    function reportErrs(errors) {
      let _a
      gen.if(
        (0, codegen_1.not)(
          (_a = def.valid) !== null && _a !== void 0 ? _a : valid
        ),
        errors
      )
    }
  }
  keyword$1.funcKeywordCode = funcKeywordCode
  function modifyData(cxt) {
    const { gen, data, it } = cxt
    gen.if(it.parentData, () =>
      gen.assign(
        data,
        (0, codegen_1._)`${it.parentData}[${it.parentDataProperty}]`
      )
    )
  }
  function addErrs(cxt, errs) {
    const { gen } = cxt
    gen.if(
      (0, codegen_1._)`Array.isArray(${errs})`,
      () => {
        gen
          .assign(
            names_1.default.vErrors,
            (0,
            codegen_1._)`${names_1.default.vErrors} === null ? ${errs} : ${names_1.default.vErrors}.concat(${errs})`
          )
          .assign(
            names_1.default.errors,
            (0, codegen_1._)`${names_1.default.vErrors}.length`
          )
        ;(0, errors_1.extendErrors)(cxt)
      },
      () => cxt.error()
    )
  }
  function checkAsyncKeyword({ schemaEnv }, def) {
    if (def.async && !schemaEnv.$async) {
      throw new Error('async keyword in sync schema')
    }
  }
  function useKeyword(gen, keyword, result) {
    if (result === undefined) {
      throw new Error(`keyword "${keyword}" failed to compile`)
    }
    return gen.scopeValue(
      'keyword',
      typeof result == 'function'
        ? {
            ref: result
          }
        : {
            ref: result,
            code: (0, codegen_1.stringify)(result)
          }
    )
  }
  function validSchemaType(schema, schemaType, allowUndefined = false) {
    // TODO add tests
    return (
      !schemaType.length ||
      schemaType.some(st =>
        st === 'array'
          ? Array.isArray(schema)
          : st === 'object'
            ? schema && typeof schema == 'object' && !Array.isArray(schema)
            : typeof schema == st ||
              (allowUndefined && typeof schema == 'undefined')
      )
    )
  }
  keyword$1.validSchemaType = validSchemaType
  function validateKeywordUsage(
    { schema, opts, self, errSchemaPath },
    def,
    keyword
  ) {
    /* istanbul ignore if */
    if (
      Array.isArray(def.keyword)
        ? !def.keyword.includes(keyword)
        : def.keyword !== keyword
    ) {
      throw new Error('ajv implementation error')
    }
    const deps = def.dependencies
    if (
      deps === null || deps === void 0
        ? void 0
        : deps.some(kwd => !Object.prototype.hasOwnProperty.call(schema, kwd))
    ) {
      throw new Error(
        `parent schema must have dependencies of ${keyword}: ${deps.join(',')}`
      )
    }
    if (def.validateSchema) {
      const valid = def.validateSchema(schema[keyword])
      if (!valid) {
        const msg =
          `keyword "${keyword}" value is invalid at path "${errSchemaPath}": ` +
          self.errorsText(def.validateSchema.errors)
        if (opts.validateSchema === 'log') {
          self.logger.error(msg)
        } else {
          throw new Error(msg)
        }
      }
    }
  }
  keyword$1.validateKeywordUsage = validateKeywordUsage
  return keyword$1
}

const subschema = {}

let hasRequiredSubschema
function requireSubschema() {
  if (hasRequiredSubschema) {
    return subschema
  }
  hasRequiredSubschema = 1
  Object.defineProperty(subschema, '__esModule', {
    value: true
  })
  subschema.extendSubschemaMode =
    subschema.extendSubschemaData =
    subschema.getSubschema =
      void 0
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  function getSubschema(
    it,
    { keyword, schemaProp, schema, schemaPath, errSchemaPath, topSchemaRef }
  ) {
    if (keyword !== undefined && schema !== undefined) {
      throw new Error('both "keyword" and "schema" passed, only one allowed')
    }
    if (keyword !== undefined) {
      const sch = it.schema[keyword]
      return schemaProp === undefined
        ? {
            schema: sch,
            schemaPath: (0,
            codegen_1._)`${it.schemaPath}${(0, codegen_1.getProperty)(keyword)}`,
            errSchemaPath: `${it.errSchemaPath}/${keyword}`
          }
        : {
            schema: sch[schemaProp],
            schemaPath: (0,
            codegen_1._)`${it.schemaPath}${(0, codegen_1.getProperty)(keyword)}${(0, codegen_1.getProperty)(schemaProp)}`,
            errSchemaPath: `${it.errSchemaPath}/${keyword}/${(0, util_1.escapeFragment)(schemaProp)}`
          }
    }
    if (schema !== undefined) {
      if (
        schemaPath === undefined ||
        errSchemaPath === undefined ||
        topSchemaRef === undefined
      ) {
        throw new Error(
          '"schemaPath", "errSchemaPath" and "topSchemaRef" are required with "schema"'
        )
      }
      return {
        schema,
        schemaPath,
        topSchemaRef,
        errSchemaPath
      }
    }
    throw new Error('either "keyword" or "schema" must be passed')
  }
  subschema.getSubschema = getSubschema
  function extendSubschemaData(
    subschema,
    it,
    { dataProp, dataPropType: dpType, data, dataTypes, propertyName }
  ) {
    if (data !== undefined && dataProp !== undefined) {
      throw new Error('both "data" and "dataProp" passed, only one allowed')
    }
    const { gen } = it
    if (dataProp !== undefined) {
      const { errorPath, dataPathArr, opts } = it
      const nextData = gen.let(
        'data',
        (0, codegen_1._)`${it.data}${(0, codegen_1.getProperty)(dataProp)}`,
        true
      )
      dataContextProps(nextData)
      subschema.errorPath = (0,
      codegen_1.str)`${errorPath}${(0, util_1.getErrorPath)(dataProp, dpType, opts.jsPropertySyntax)}`
      subschema.parentDataProperty = (0, codegen_1._)`${dataProp}`
      subschema.dataPathArr = [...dataPathArr, subschema.parentDataProperty]
    }
    if (data !== undefined) {
      const nextData =
        data instanceof codegen_1.Name ? data : gen.let('data', data, true) // replaceable if used once?
      dataContextProps(nextData)
      if (propertyName !== undefined) {
        subschema.propertyName = propertyName
      }
      // TODO something is possibly wrong here with not changing parentDataProperty and not appending dataPathArr
    }
    if (dataTypes) {
      subschema.dataTypes = dataTypes
    }
    function dataContextProps(_nextData) {
      subschema.data = _nextData
      subschema.dataLevel = it.dataLevel + 1
      subschema.dataTypes = []
      it.definedProperties = new Set()
      subschema.parentData = it.data
      subschema.dataNames = [...it.dataNames, _nextData]
    }
  }
  subschema.extendSubschemaData = extendSubschemaData
  function extendSubschemaMode(
    subschema,
    { jtdDiscriminator, jtdMetadata, compositeRule, createErrors, allErrors }
  ) {
    if (compositeRule !== undefined) {
      subschema.compositeRule = compositeRule
    }
    if (createErrors !== undefined) {
      subschema.createErrors = createErrors
    }
    if (allErrors !== undefined) {
      subschema.allErrors = allErrors
    }
    subschema.jtdDiscriminator = jtdDiscriminator // not inherited
    subschema.jtdMetadata = jtdMetadata // not inherited
  }
  subschema.extendSubschemaMode = extendSubschemaMode
  return subschema
}

const resolve = {}

let fastDeepEqual
let hasRequiredFastDeepEqual
function requireFastDeepEqual() {
  if (hasRequiredFastDeepEqual) {
    return fastDeepEqual
  }
  hasRequiredFastDeepEqual = 1

  // do not edit .js files directly - edit src/index.jst

  fastDeepEqual = function equal(a, b) {
    if (a === b) {
      return true
    }
    if (a && b && typeof a == 'object' && typeof b == 'object') {
      if (a.constructor !== b.constructor) {
        return false
      }
      let length, i, keys
      if (Array.isArray(a)) {
        length = a.length
        if (length != b.length) {
          return false
        }
        for (i = length; i-- !== 0; ) {
          if (!equal(a[i], b[i])) return false
        }
        return true
      }
      if (a.constructor === RegExp) {
        return a.source === b.source && a.flags === b.flags
      }
      if (a.valueOf !== Object.prototype.valueOf) {
        return a.valueOf() === b.valueOf()
      }
      if (a.toString !== Object.prototype.toString) {
        return a.toString() === b.toString()
      }
      keys = Object.keys(a)
      length = keys.length
      if (length !== Object.keys(b).length) {
        return false
      }
      for (i = length; i-- !== 0; ) {
        if (!Object.prototype.hasOwnProperty.call(b, keys[i])) return false
      }
      for (i = length; i-- !== 0; ) {
        const key = keys[i]
        if (!equal(a[key], b[key])) {
          return false
        }
      }
      return true
    }

    // true if both NaN, false otherwise
    return a !== a && b !== b
  }
  return fastDeepEqual
}

const jsonSchemaTraverse = { exports: {} }

let hasRequiredJsonSchemaTraverse
function requireJsonSchemaTraverse() {
  if (hasRequiredJsonSchemaTraverse) {
    return jsonSchemaTraverse.exports
  }
  hasRequiredJsonSchemaTraverse = 1
  const traverse = (jsonSchemaTraverse.exports = function (schema, opts, cb) {
    // Legacy support for v0.3.1 and earlier.
    if (typeof opts == 'function') {
      cb = opts
      opts = {}
    }
    cb = opts.cb || cb
    const pre = typeof cb == 'function' ? cb : cb.pre || function () {}
    const post = cb.post || function () {}
    _traverse(opts, pre, post, schema, '', schema)
  })
  traverse.keywords = {
    additionalItems: true,
    items: true,
    contains: true,
    additionalProperties: true,
    propertyNames: true,
    not: true,
    if: true,
    then: true,
    else: true
  }
  traverse.arrayKeywords = {
    items: true,
    allOf: true,
    anyOf: true,
    oneOf: true
  }
  traverse.propsKeywords = {
    $defs: true,
    definitions: true,
    properties: true,
    patternProperties: true,
    dependencies: true
  }
  traverse.skipKeywords = {
    default: true,
    enum: true,
    const: true,
    required: true,
    maximum: true,
    minimum: true,
    exclusiveMaximum: true,
    exclusiveMinimum: true,
    multipleOf: true,
    maxLength: true,
    minLength: true,
    pattern: true,
    format: true,
    maxItems: true,
    minItems: true,
    uniqueItems: true,
    maxProperties: true,
    minProperties: true
  }
  function _traverse(
    opts,
    pre,
    post,
    schema,
    jsonPtr,
    rootSchema,
    parentJsonPtr,
    parentKeyword,
    parentSchema,
    keyIndex
  ) {
    if (schema && typeof schema == 'object' && !Array.isArray(schema)) {
      pre(
        schema,
        jsonPtr,
        rootSchema,
        parentJsonPtr,
        parentKeyword,
        parentSchema,
        keyIndex
      )
      for (const key in schema) {
        const sch = schema[key]
        if (Array.isArray(sch)) {
          if (key in traverse.arrayKeywords) {
            for (let i = 0; i < sch.length; i++) {
              _traverse(
                opts,
                pre,
                post,
                sch[i],
                jsonPtr + '/' + key + '/' + i,
                rootSchema,
                jsonPtr,
                key,
                schema,
                i
              )
            }
          }
        } else if (key in traverse.propsKeywords) {
          if (sch && typeof sch == 'object') {
            for (const prop in sch) {
              _traverse(
                opts,
                pre,
                post,
                sch[prop],
                jsonPtr + '/' + key + '/' + escapeJsonPtr(prop),
                rootSchema,
                jsonPtr,
                key,
                schema,
                prop
              )
            }
          }
        } else if (
          key in traverse.keywords ||
          (opts.allKeys && !(key in traverse.skipKeywords))
        ) {
          _traverse(
            opts,
            pre,
            post,
            sch,
            jsonPtr + '/' + key,
            rootSchema,
            jsonPtr,
            key,
            schema
          )
        }
      }
      post(
        schema,
        jsonPtr,
        rootSchema,
        parentJsonPtr,
        parentKeyword,
        parentSchema,
        keyIndex
      )
    }
  }
  function escapeJsonPtr(str) {
    return str.replace(/~/g, '~0').replace(/\//g, '~1')
  }
  return jsonSchemaTraverse.exports
}

let hasRequiredResolve
function requireResolve() {
  if (hasRequiredResolve) {
    return resolve
  }
  hasRequiredResolve = 1
  Object.defineProperty(resolve, '__esModule', {
    value: true
  })
  resolve.getSchemaRefs =
    resolve.resolveUrl =
    resolve.normalizeId =
    resolve._getFullPath =
    resolve.getFullPath =
    resolve.inlineRef =
      void 0
  const util_1 = requireUtil()
  const equal = requireFastDeepEqual()
  const traverse = requireJsonSchemaTraverse()
  // TODO refactor to use keyword definitions
  const SIMPLE_INLINED = new Set([
    'type',
    'format',
    'pattern',
    'maxLength',
    'minLength',
    'maxProperties',
    'minProperties',
    'maxItems',
    'minItems',
    'maximum',
    'minimum',
    'uniqueItems',
    'multipleOf',
    'required',
    'enum',
    'const'
  ])
  function inlineRef(schema, limit = true) {
    if (typeof schema == 'boolean') {
      return true
    }
    if (limit === true) {
      return !hasRef(schema)
    }
    if (!limit) {
      return false
    }
    return countKeys(schema) <= limit
  }
  resolve.inlineRef = inlineRef
  const REF_KEYWORDS = new Set([
    '$ref',
    '$recursiveRef',
    '$recursiveAnchor',
    '$dynamicRef',
    '$dynamicAnchor'
  ])
  function hasRef(schema) {
    for (const key in schema) {
      if (REF_KEYWORDS.has(key)) {
        return true
      }
      const sch = schema[key]
      if (Array.isArray(sch) && sch.some(hasRef)) {
        return true
      }
      if (typeof sch == 'object' && hasRef(sch)) {
        return true
      }
    }
    return false
  }
  function countKeys(schema) {
    let count = 0
    for (const key in schema) {
      if (key === '$ref') {
        return Infinity
      }
      count++
      if (SIMPLE_INLINED.has(key)) {
        continue
      }
      if (typeof schema[key] == 'object') {
        ;(0, util_1.eachItem)(schema[key], sch => (count += countKeys(sch)))
      }
      if (count === Infinity) {
        return Infinity
      }
    }
    return count
  }
  function getFullPath(resolver, id = '', normalize) {
    if (normalize !== false) {
      id = normalizeId(id)
    }
    const p = resolver.parse(id)
    return _getFullPath(resolver, p)
  }
  resolve.getFullPath = getFullPath
  function _getFullPath(resolver, p) {
    const serialized = resolver.serialize(p)
    return serialized.split('#')[0] + '#'
  }
  resolve._getFullPath = _getFullPath
  const TRAILING_SLASH_HASH = /#\/?$/
  function normalizeId(id) {
    return id ? id.replace(TRAILING_SLASH_HASH, '') : ''
  }
  resolve.normalizeId = normalizeId
  function resolveUrl(resolver, baseId, id) {
    id = normalizeId(id)
    return resolver.resolve(baseId, id)
  }
  resolve.resolveUrl = resolveUrl
  const ANCHOR = /^[a-z_][-a-z0-9._]*$/i
  function getSchemaRefs(schema, baseId) {
    if (typeof schema == 'boolean') {
      return {}
    }
    const { schemaId, uriResolver } = this.opts
    const schId = normalizeId(schema[schemaId] || baseId)
    const baseIds = {
      '': schId
    }
    const pathPrefix = getFullPath(uriResolver, schId, false)
    const localRefs = {}
    const schemaRefs = new Set()
    traverse(
      schema,
      {
        allKeys: true
      },
      (sch, jsonPtr, _, parentJsonPtr) => {
        if (parentJsonPtr === undefined) {
          return
        }
        const fullPath = pathPrefix + jsonPtr
        let innerBaseId = baseIds[parentJsonPtr]
        if (typeof sch[schemaId] == 'string') {
          innerBaseId = addRef.call(this, sch[schemaId])
        }
        addAnchor.call(this, sch.$anchor)
        addAnchor.call(this, sch.$dynamicAnchor)
        baseIds[jsonPtr] = innerBaseId
        function addRef(ref) {
          // eslint-disable-next-line @typescript-eslint/unbound-method
          const _resolve = this.opts.uriResolver.resolve
          ref = normalizeId(innerBaseId ? _resolve(innerBaseId, ref) : ref)
          if (schemaRefs.has(ref)) {
            throw ambiguos(ref)
          }
          schemaRefs.add(ref)
          let schOrRef = this.refs[ref]
          if (typeof schOrRef == 'string') {
            schOrRef = this.refs[schOrRef]
          }
          if (typeof schOrRef == 'object') {
            checkAmbiguosRef(sch, schOrRef.schema, ref)
          } else if (ref !== normalizeId(fullPath)) {
            if (ref[0] === '#') {
              checkAmbiguosRef(sch, localRefs[ref], ref)
              localRefs[ref] = sch
            } else {
              this.refs[ref] = fullPath
            }
          }
          return ref
        }
        function addAnchor(anchor) {
          if (typeof anchor == 'string') {
            if (!ANCHOR.test(anchor)) {
              throw new Error(`invalid anchor "${anchor}"`)
            }
            addRef.call(this, `#${anchor}`)
          }
        }
      }
    )
    return localRefs
    function checkAmbiguosRef(sch1, sch2, ref) {
      if (sch2 !== undefined && !equal(sch1, sch2)) {
        throw ambiguos(ref)
      }
    }
    function ambiguos(ref) {
      return new Error(`reference "${ref}" resolves to more than one schema`)
    }
  }
  resolve.getSchemaRefs = getSchemaRefs
  return resolve
}

let hasRequiredValidate$1
function requireValidate$1() {
  if (hasRequiredValidate$1) {
    return validate$2
  }
  hasRequiredValidate$1 = 1
  Object.defineProperty(validate$2, '__esModule', {
    value: true
  })
  validate$2.getData =
    validate$2.KeywordCxt =
    validate$2.validateFunctionCode =
      void 0
  const boolSchema_1 = requireBoolSchema()
  const dataType_1 = requireDataType()
  const applicability_1 = requireApplicability()
  const dataType_2 = requireDataType()
  const defaults_1 = requireDefaults()
  const keyword_1 = requireKeyword()
  const subschema_1 = requireSubschema()
  const codegen_1 = requireCodegen()
  const names_1 = requireNames()
  const resolve_1 = requireResolve()
  const util_1 = requireUtil()
  const errors_1 = requireErrors$4()
  // schema compilation - generates validation function, subschemaCode (below) is used for subschemas
  function validateFunctionCode(it) {
    if (isSchemaObj(it)) {
      checkKeywords(it)
      if (schemaCxtHasRules(it)) {
        topSchemaObjCode(it)
        return
      }
    }
    validateFunction(it, () => (0, boolSchema_1.topBoolOrEmptySchema)(it))
  }
  validate$2.validateFunctionCode = validateFunctionCode
  function validateFunction(
    { gen, validateName, schema, schemaEnv, opts },
    body
  ) {
    if (opts.code.es5) {
      gen.func(
        validateName,
        (0, codegen_1._)`${names_1.default.data}, ${names_1.default.valCxt}`,
        schemaEnv.$async,
        () => {
          gen.code(
            (0, codegen_1._)`"use strict"; ${funcSourceUrl(schema, opts)}`
          )
          destructureValCxtES5(gen, opts)
          gen.code(body)
        }
      )
    } else {
      gen.func(
        validateName,
        (0, codegen_1._)`${names_1.default.data}, ${destructureValCxt(opts)}`,
        schemaEnv.$async,
        () => gen.code(funcSourceUrl(schema, opts)).code(body)
      )
    }
  }
  function destructureValCxt(opts) {
    return (0,
    codegen_1._)`{${names_1.default.instancePath}="", ${names_1.default.parentData}, ${names_1.default.parentDataProperty}, ${names_1.default.rootData}=${names_1.default.data}${opts.dynamicRef ? ((0, codegen_1._))`, ${names_1.default.dynamicAnchors}={}` : codegen_1.nil}}={}`
  }
  function destructureValCxtES5(gen, opts) {
    gen.if(
      names_1.default.valCxt,
      () => {
        gen.var(
          names_1.default.instancePath,
          (0,
          codegen_1._)`${names_1.default.valCxt}.${names_1.default.instancePath}`
        )
        gen.var(
          names_1.default.parentData,
          (0,
          codegen_1._)`${names_1.default.valCxt}.${names_1.default.parentData}`
        )
        gen.var(
          names_1.default.parentDataProperty,
          (0,
          codegen_1._)`${names_1.default.valCxt}.${names_1.default.parentDataProperty}`
        )
        gen.var(
          names_1.default.rootData,
          (0,
          codegen_1._)`${names_1.default.valCxt}.${names_1.default.rootData}`
        )
        if (opts.dynamicRef) {
          gen.var(
            names_1.default.dynamicAnchors,
            (0,
            codegen_1._)`${names_1.default.valCxt}.${names_1.default.dynamicAnchors}`
          )
        }
      },
      () => {
        gen.var(names_1.default.instancePath, (0, codegen_1._)`""`)
        gen.var(names_1.default.parentData, (0, codegen_1._)`undefined`)
        gen.var(names_1.default.parentDataProperty, (0, codegen_1._)`undefined`)
        gen.var(names_1.default.rootData, names_1.default.data)
        if (opts.dynamicRef) {
          gen.var(names_1.default.dynamicAnchors, (0, codegen_1._)`{}`)
        }
      }
    )
  }
  function topSchemaObjCode(it) {
    const { schema, opts, gen } = it
    validateFunction(it, () => {
      if (opts.$comment && schema.$comment) {
        commentKeyword(it)
      }
      checkNoDefault(it)
      gen.let(names_1.default.vErrors, null)
      gen.let(names_1.default.errors, 0)
      if (opts.unevaluated) {
        resetEvaluated(it)
      }
      typeAndKeywords(it)
      returnResults(it)
    })
    return
  }
  function resetEvaluated(it) {
    // TODO maybe some hook to execute it in the end to check whether props/items are Name, as in assignEvaluated
    const { gen, validateName } = it
    it.evaluated = gen.const(
      'evaluated',
      (0, codegen_1._)`${validateName}.evaluated`
    )
    gen.if((0, codegen_1._)`${it.evaluated}.dynamicProps`, () =>
      gen.assign(
        (0, codegen_1._)`${it.evaluated}.props`,
        (0, codegen_1._)`undefined`
      )
    )
    gen.if((0, codegen_1._)`${it.evaluated}.dynamicItems`, () =>
      gen.assign(
        (0, codegen_1._)`${it.evaluated}.items`,
        (0, codegen_1._)`undefined`
      )
    )
  }
  function funcSourceUrl(schema, opts) {
    const schId = typeof schema == 'object' && schema[opts.schemaId]
    return schId && (opts.code.source || opts.code.process)
      ? (0, codegen_1._)`/*# sourceURL=${schId} */`
      : codegen_1.nil
  }
  // schema compilation - this function is used recursively to generate code for sub-schemas
  function subschemaCode(it, valid) {
    if (isSchemaObj(it)) {
      checkKeywords(it)
      if (schemaCxtHasRules(it)) {
        subSchemaObjCode(it, valid)
        return
      }
    }
    ;(0, boolSchema_1.boolOrEmptySchema)(it, valid)
  }
  function schemaCxtHasRules({ schema, self }) {
    if (typeof schema == 'boolean') {
      return !schema
    }
    for (const key in schema) {
      if (self.RULES.all[key]) return true
    }
    return false
  }
  function isSchemaObj(it) {
    return typeof it.schema != 'boolean'
  }
  function subSchemaObjCode(it, valid) {
    const { schema, gen, opts } = it
    if (opts.$comment && schema.$comment) {
      commentKeyword(it)
    }
    updateContext(it)
    checkAsyncSchema(it)
    const errsCount = gen.const('_errs', names_1.default.errors)
    typeAndKeywords(it, errsCount)
    // TODO var
    gen.var(valid, (0, codegen_1._)`${errsCount} === ${names_1.default.errors}`)
  }
  function checkKeywords(it) {
    ;(0, util_1.checkUnknownRules)(it)
    checkRefsAndKeywords(it)
  }
  function typeAndKeywords(it, errsCount) {
    if (it.opts.jtd) {
      return schemaKeywords(it, [], false, errsCount)
    }
    const types = (0, dataType_1.getSchemaTypes)(it.schema)
    const checkedTypes = (0, dataType_1.coerceAndCheckDataType)(it, types)
    schemaKeywords(it, types, !checkedTypes, errsCount)
  }
  function checkRefsAndKeywords(it) {
    const { schema, errSchemaPath, opts, self } = it
    if (
      schema.$ref &&
      opts.ignoreKeywordsWithRef &&
      (0, util_1.schemaHasRulesButRef)(schema, self.RULES)
    ) {
      self.logger.warn(
        `$ref: keywords ignored in schema at path "${errSchemaPath}"`
      )
    }
  }
  function checkNoDefault(it) {
    const { schema, opts } = it
    if (schema.default !== undefined && opts.useDefaults && opts.strictSchema) {
      ;(0, util_1.checkStrictMode)(it, 'default is ignored in the schema root')
    }
  }
  function updateContext(it) {
    const schId = it.schema[it.opts.schemaId]
    if (schId) {
      it.baseId = (0, resolve_1.resolveUrl)(
        it.opts.uriResolver,
        it.baseId,
        schId
      )
    }
  }
  function checkAsyncSchema(it) {
    if (it.schema.$async && !it.schemaEnv.$async) {
      throw new Error('async schema in sync schema')
    }
  }
  function commentKeyword({ gen, schemaEnv, schema, errSchemaPath, opts }) {
    const msg = schema.$comment
    if (opts.$comment === true) {
      gen.code((0, codegen_1._)`${names_1.default.self}.logger.log(${msg})`)
    } else if (typeof opts.$comment == 'function') {
      const schemaPath = (0, codegen_1.str)`${errSchemaPath}/$comment`
      const rootName = gen.scopeValue('root', {
        ref: schemaEnv.root
      })
      gen.code(
        (0,
        codegen_1._)`${names_1.default.self}.opts.$comment(${msg}, ${schemaPath}, ${rootName}.schema)`
      )
    }
  }
  function returnResults(it) {
    const { gen, schemaEnv, validateName, ValidationError, opts } = it
    if (schemaEnv.$async) {
      // TODO assign unevaluated
      gen.if(
        (0, codegen_1._)`${names_1.default.errors} === 0`,
        () => gen.return(names_1.default.data),
        () =>
          gen.throw(
            (0, codegen_1._)`new ${ValidationError}(${names_1.default.vErrors})`
          )
      )
    } else {
      gen.assign(
        (0, codegen_1._)`${validateName}.errors`,
        names_1.default.vErrors
      )
      if (opts.unevaluated) {
        assignEvaluated(it)
      }
      gen.return((0, codegen_1._)`${names_1.default.errors} === 0`)
    }
  }
  function assignEvaluated({ gen, evaluated, props, items }) {
    if (props instanceof codegen_1.Name) {
      gen.assign((0, codegen_1._)`${evaluated}.props`, props)
    }
    if (items instanceof codegen_1.Name) {
      gen.assign((0, codegen_1._)`${evaluated}.items`, items)
    }
  }
  function schemaKeywords(it, types, typeErrors, errsCount) {
    const { gen, schema, data, allErrors, opts, self } = it
    const { RULES } = self
    if (
      schema.$ref &&
      (opts.ignoreKeywordsWithRef ||
        !(0, util_1.schemaHasRulesButRef)(schema, RULES))
    ) {
      gen.block(() => keywordCode(it, '$ref', RULES.all.$ref.definition)) // TODO typecast
      return
    }
    if (!opts.jtd) {
      checkStrictTypes(it, types)
    }
    gen.block(() => {
      for (const group of RULES.rules) {
        groupKeywords(group)
      }
      groupKeywords(RULES.post)
    })
    function groupKeywords(group) {
      if (!(0, applicability_1.shouldUseGroup)(schema, group)) {
        return
      }
      if (group.type) {
        gen.if(
          (0, dataType_2.checkDataType)(group.type, data, opts.strictNumbers)
        )
        iterateKeywords(it, group)
        if (types.length === 1 && types[0] === group.type && typeErrors) {
          gen.else()
          ;(0, dataType_2.reportTypeError)(it)
        }
        gen.endIf()
      } else {
        iterateKeywords(it, group)
      }
      // TODO make it "ok" call?
      if (!allErrors) {
        gen.if(
          (0, codegen_1._)`${names_1.default.errors} === ${errsCount || 0}`
        )
      }
    }
  }
  function iterateKeywords(it, group) {
    const {
      gen,
      schema,
      opts: { useDefaults }
    } = it
    if (useDefaults) {
      ;(0, defaults_1.assignDefaults)(it, group.type)
    }
    gen.block(() => {
      for (const rule of group.rules) {
        if ((0, applicability_1.shouldUseRule)(schema, rule)) {
          keywordCode(it, rule.keyword, rule.definition, group.type)
        }
      }
    })
  }
  function checkStrictTypes(it, types) {
    if (it.schemaEnv.meta || !it.opts.strictTypes) {
      return
    }
    checkContextTypes(it, types)
    if (!it.opts.allowUnionTypes) {
      checkMultipleTypes(it, types)
    }
    checkKeywordTypes(it, it.dataTypes)
  }
  function checkContextTypes(it, types) {
    if (!types.length) {
      return
    }
    if (!it.dataTypes.length) {
      it.dataTypes = types
      return
    }
    types.forEach(t => {
      if (!includesType(it.dataTypes, t)) {
        strictTypesError(
          it,
          `type "${t}" not allowed by context "${it.dataTypes.join(',')}"`
        )
      }
    })
    narrowSchemaTypes(it, types)
  }
  function checkMultipleTypes(it, ts) {
    if (ts.length > 1 && !(ts.length === 2 && ts.includes('null'))) {
      strictTypesError(it, 'use allowUnionTypes to allow union type keyword')
    }
  }
  function checkKeywordTypes(it, ts) {
    const rules = it.self.RULES.all
    for (const keyword in rules) {
      const rule = rules[keyword]
      if (
        typeof rule == 'object' &&
        (0, applicability_1.shouldUseRule)(it.schema, rule)
      ) {
        const { type } = rule.definition
        if (type.length && !type.some(t => hasApplicableType(ts, t))) {
          strictTypesError(
            it,
            `missing type "${type.join(',')}" for keyword "${keyword}"`
          )
        }
      }
    }
  }
  function hasApplicableType(schTs, kwdT) {
    return (
      schTs.includes(kwdT) || (kwdT === 'number' && schTs.includes('integer'))
    )
  }
  function includesType(ts, t) {
    return ts.includes(t) || (t === 'integer' && ts.includes('number'))
  }
  function narrowSchemaTypes(it, withTypes) {
    const ts = []
    for (const t of it.dataTypes) {
      if (includesType(withTypes, t)) {
        ts.push(t)
      } else if (withTypes.includes('integer') && t === 'number') {
        ts.push('integer')
      }
    }
    it.dataTypes = ts
  }
  function strictTypesError(it, msg) {
    const schemaPath = it.schemaEnv.baseId + it.errSchemaPath
    msg += ` at "${schemaPath}" (strictTypes)`
    ;(0, util_1.checkStrictMode)(it, msg, it.opts.strictTypes)
  }
  class KeywordCxt {
    constructor(it, def, keyword) {
      ;(0, keyword_1.validateKeywordUsage)(it, def, keyword)
      this.gen = it.gen
      this.allErrors = it.allErrors
      this.keyword = keyword
      this.data = it.data
      this.schema = it.schema[keyword]
      this.$data =
        def.$data && it.opts.$data && this.schema && this.schema.$data
      this.schemaValue = (0, util_1.schemaRefOrVal)(
        it,
        this.schema,
        keyword,
        this.$data
      )
      this.schemaType = def.schemaType
      this.parentSchema = it.schema
      this.params = {}
      this.it = it
      this.def = def
      if (this.$data) {
        this.schemaCode = it.gen.const('vSchema', getData(this.$data, it))
      } else {
        this.schemaCode = this.schemaValue
        if (
          !(0, keyword_1.validSchemaType)(
            this.schema,
            def.schemaType,
            def.allowUndefined
          )
        ) {
          throw new Error(
            `${keyword} value must be ${JSON.stringify(def.schemaType)}`
          )
        }
      }
      if ('code' in def ? def.trackErrors : def.errors !== false) {
        this.errsCount = it.gen.const('_errs', names_1.default.errors)
      }
    }
    result(condition, successAction, failAction) {
      this.failResult((0, codegen_1.not)(condition), successAction, failAction)
    }
    failResult(condition, successAction, failAction) {
      this.gen.if(condition)
      if (failAction) {
        failAction()
      } else {
        this.error()
      }
      if (successAction) {
        this.gen.else()
        successAction()
        if (this.allErrors) {
          this.gen.endIf()
        }
      } else {
        if (this.allErrors) {
          this.gen.endIf()
        } else {
          this.gen.else()
        }
      }
    }
    pass(condition, failAction) {
      this.failResult((0, codegen_1.not)(condition), undefined, failAction)
    }
    fail(condition) {
      if (condition === undefined) {
        this.error()
        if (!this.allErrors) {
          this.gen.if(false)
        } // this branch will be removed by gen.optimize
        return
      }
      this.gen.if(condition)
      this.error()
      if (this.allErrors) {
        this.gen.endIf()
      } else {
        this.gen.else()
      }
    }
    fail$data(condition) {
      if (!this.$data) {
        return this.fail(condition)
      }
      const { schemaCode } = this
      this.fail(
        (0,
        codegen_1._)`${schemaCode} !== undefined && (${(0, codegen_1.or)(this.invalid$data(), condition)})`
      )
    }
    error(append, errorParams, errorPaths) {
      if (errorParams) {
        this.setParams(errorParams)
        this._error(append, errorPaths)
        this.setParams({})
        return
      }
      this._error(append, errorPaths)
    }
    _error(append, errorPaths) {
      ;(append ? errors_1.reportExtraError : errors_1.reportError)(
        this,
        this.def.error,
        errorPaths
      )
    }
    $dataError() {
      ;(0, errors_1.reportError)(
        this,
        this.def.$dataError || errors_1.keyword$DataError
      )
    }
    reset() {
      if (this.errsCount === undefined) {
        throw new Error('add "trackErrors" to keyword definition')
      }
      ;(0, errors_1.resetErrorsCount)(this.gen, this.errsCount)
    }
    ok(cond) {
      if (!this.allErrors) {
        this.gen.if(cond)
      }
    }
    setParams(obj, assign) {
      if (assign) {
        Object.assign(this.params, obj)
      } else {
        this.params = obj
      }
    }
    block$data(valid, codeBlock, $dataValid = codegen_1.nil) {
      this.gen.block(() => {
        this.check$data(valid, $dataValid)
        codeBlock()
      })
    }
    check$data(valid = codegen_1.nil, $dataValid = codegen_1.nil) {
      if (!this.$data) {
        return
      }
      const { gen, schemaCode, schemaType, def } = this
      gen.if(
        (0, codegen_1.or)(
          (0, codegen_1._)`${schemaCode} === undefined`,
          $dataValid
        )
      )
      if (valid !== codegen_1.nil) {
        gen.assign(valid, true)
      }
      if (schemaType.length || def.validateSchema) {
        gen.elseIf(this.invalid$data())
        this.$dataError()
        if (valid !== codegen_1.nil) {
          gen.assign(valid, false)
        }
      }
      gen.else()
    }
    invalid$data() {
      const { gen, schemaCode, schemaType, def, it } = this
      return (0, codegen_1.or)(wrong$DataType(), invalid$DataSchema())
      function wrong$DataType() {
        if (schemaType.length) {
          /* istanbul ignore if */
          if (!(schemaCode instanceof codegen_1.Name)) {
            throw new Error('ajv implementation error')
          }
          const st = Array.isArray(schemaType) ? schemaType : [schemaType]
          return (0,
          codegen_1._)`${(0, dataType_2.checkDataTypes)(st, schemaCode, it.opts.strictNumbers, dataType_2.DataType.Wrong)}`
        }
        return codegen_1.nil
      }
      function invalid$DataSchema() {
        if (def.validateSchema) {
          const validateSchemaRef = gen.scopeValue('validate$data', {
            ref: def.validateSchema
          }) // TODO value.code for standalone
          return (0, codegen_1._)`!${validateSchemaRef}(${schemaCode})`
        }
        return codegen_1.nil
      }
    }
    subschema(appl, valid) {
      const subschema = (0, subschema_1.getSubschema)(this.it, appl)
      ;(0, subschema_1.extendSubschemaData)(subschema, this.it, appl)
      ;(0, subschema_1.extendSubschemaMode)(subschema, appl)
      const nextContext = {
        ...this.it,
        ...subschema,
        items: undefined,
        props: undefined
      }
      subschemaCode(nextContext, valid)
      return nextContext
    }
    mergeEvaluated(schemaCxt, toName) {
      const { it, gen } = this
      if (!it.opts.unevaluated) {
        return
      }
      if (it.props !== true && schemaCxt.props !== undefined) {
        it.props = util_1.mergeEvaluated.props(
          gen,
          schemaCxt.props,
          it.props,
          toName
        )
      }
      if (it.items !== true && schemaCxt.items !== undefined) {
        it.items = util_1.mergeEvaluated.items(
          gen,
          schemaCxt.items,
          it.items,
          toName
        )
      }
    }
    mergeValidEvaluated(schemaCxt, valid) {
      const { it, gen } = this
      if (it.opts.unevaluated && (it.props !== true || it.items !== true)) {
        gen.if(valid, () => this.mergeEvaluated(schemaCxt, codegen_1.Name))
        return true
      }
    }
  }
  validate$2.KeywordCxt = KeywordCxt
  function keywordCode(it, keyword, def, ruleType) {
    const cxt = new KeywordCxt(it, def, keyword)
    if ('code' in def) {
      def.code(cxt, ruleType)
    } else if (cxt.$data && def.validate) {
      ;(0, keyword_1.funcKeywordCode)(cxt, def)
    } else if ('macro' in def) {
      ;(0, keyword_1.macroKeywordCode)(cxt, def)
    } else if (def.compile || def.validate) {
      ;(0, keyword_1.funcKeywordCode)(cxt, def)
    }
  }
  const JSON_POINTER = /^\/(?:[^~]|~0|~1)*$/
  const RELATIVE_JSON_POINTER = /^([0-9]+)(#|\/(?:[^~]|~0|~1)*)?$/
  function getData($data, { dataLevel, dataNames, dataPathArr }) {
    let jsonPointer
    let data
    if ($data === '') {
      return names_1.default.rootData
    }
    if ($data[0] === '/') {
      if (!JSON_POINTER.test($data)) {
        throw new Error(`Invalid JSON-pointer: ${$data}`)
      }
      jsonPointer = $data
      data = names_1.default.rootData
    } else {
      const matches = RELATIVE_JSON_POINTER.exec($data)
      if (!matches) {
        throw new Error(`Invalid JSON-pointer: ${$data}`)
      }
      const up = +matches[1]
      jsonPointer = matches[2]
      if (jsonPointer === '#') {
        if (up >= dataLevel) {
          throw new Error(errorMsg('property/index', up))
        }
        return dataPathArr[dataLevel - up]
      }
      if (up > dataLevel) {
        throw new Error(errorMsg('data', up))
      }
      data = dataNames[dataLevel - up]
      if (!jsonPointer) {
        return data
      }
    }
    let expr = data
    const segments = jsonPointer.split('/')
    for (const segment of segments) {
      if (segment) {
        data = (0,
        codegen_1._)`${data}${(0, codegen_1.getProperty)((0, util_1.unescapeJsonPointer)(segment))}`
        expr = (0, codegen_1._)`${expr} && ${data}`
      }
    }
    return expr
    function errorMsg(pointerType, up) {
      return `Cannot access ${pointerType} ${up} levels up, current level is ${dataLevel}`
    }
  }
  validate$2.getData = getData
  return validate$2
}

const validation_error = {}

let hasRequiredValidation_error
function requireValidation_error() {
  if (hasRequiredValidation_error) {
    return validation_error
  }
  hasRequiredValidation_error = 1
  Object.defineProperty(validation_error, '__esModule', {
    value: true
  })
  class ValidationError extends Error {
    constructor(errors) {
      super('validation failed')
      this.errors = errors
      this.ajv = this.validation = true
    }
  }
  validation_error.default = ValidationError
  return validation_error
}

const ref_error = {}

let hasRequiredRef_error
function requireRef_error() {
  if (hasRequiredRef_error) {
    return ref_error
  }
  hasRequiredRef_error = 1
  Object.defineProperty(ref_error, '__esModule', {
    value: true
  })
  const resolve_1 = requireResolve()
  class MissingRefError extends Error {
    constructor(resolver, baseId, ref, msg) {
      super(msg || `can't resolve reference ${ref} from id ${baseId}`)
      this.missingRef = (0, resolve_1.resolveUrl)(resolver, baseId, ref)
      this.missingSchema = (0, resolve_1.normalizeId)(
        (0, resolve_1.getFullPath)(resolver, this.missingRef)
      )
    }
  }
  ref_error.default = MissingRefError
  return ref_error
}

const compile = {}

let hasRequiredCompile$1
function requireCompile$1() {
  if (hasRequiredCompile$1) {
    return compile
  }
  hasRequiredCompile$1 = 1
  Object.defineProperty(compile, '__esModule', {
    value: true
  })
  compile.resolveSchema =
    compile.getCompilingSchema =
    compile.resolveRef =
    compile.compileSchema =
    compile.SchemaEnv =
      void 0
  const codegen_1 = requireCodegen()
  const validation_error_1 = requireValidation_error()
  const names_1 = requireNames()
  const resolve_1 = requireResolve()
  const util_1 = requireUtil()
  const validate_1 = requireValidate$1()
  class SchemaEnv {
    constructor(env) {
      let _a
      this.refs = {}
      this.dynamicAnchors = {}
      let schema
      if (typeof env.schema == 'object') {
        schema = env.schema
      }
      this.schema = env.schema
      this.schemaId = env.schemaId
      this.root = env.root || this
      this.baseId =
        (_a = env.baseId) !== null && _a !== void 0
          ? _a
          : (0, resolve_1.normalizeId)(
              schema === null || schema === void 0
                ? void 0
                : schema[env.schemaId || '$id']
            )
      this.schemaPath = env.schemaPath
      this.localRefs = env.localRefs
      this.meta = env.meta
      this.$async =
        schema === null || schema === void 0 ? void 0 : schema.$async
      this.refs = {}
    }
  }
  compile.SchemaEnv = SchemaEnv
  // let codeSize = 0
  // let nodeCount = 0
  // Compiles schema in SchemaEnv
  function compileSchema(sch) {
    // TODO refactor - remove compilations
    const _sch = getCompilingSchema.call(this, sch)
    if (_sch) {
      return _sch
    }
    const rootId = (0, resolve_1.getFullPath)(
      this.opts.uriResolver,
      sch.root.baseId
    ) // TODO if getFullPath removed 1 tests fails
    const { es5, lines } = this.opts.code
    const { ownProperties } = this.opts
    const gen = new codegen_1.CodeGen(this.scope, {
      es5,
      lines,
      ownProperties
    })
    let _ValidationError
    if (sch.$async) {
      _ValidationError = gen.scopeValue('Error', {
        ref: validation_error_1.default,
        code: (0,
        codegen_1._)`require("ajv/dist/runtime/validation_error").default`
      })
    }
    const validateName = gen.scopeName('validate')
    sch.validateName = validateName
    const schemaCxt = {
      gen,
      allErrors: this.opts.allErrors,
      data: names_1.default.data,
      parentData: names_1.default.parentData,
      parentDataProperty: names_1.default.parentDataProperty,
      dataNames: [names_1.default.data],
      dataPathArr: [codegen_1.nil],
      // TODO can its length be used as dataLevel if nil is removed?
      dataLevel: 0,
      dataTypes: [],
      definedProperties: new Set(),
      topSchemaRef: gen.scopeValue(
        'schema',
        this.opts.code.source === true
          ? {
              ref: sch.schema,
              code: (0, codegen_1.stringify)(sch.schema)
            }
          : {
              ref: sch.schema
            }
      ),
      validateName,
      ValidationError: _ValidationError,
      schema: sch.schema,
      schemaEnv: sch,
      rootId,
      baseId: sch.baseId || rootId,
      schemaPath: codegen_1.nil,
      errSchemaPath: sch.schemaPath || (this.opts.jtd ? '' : '#'),
      errorPath: (0, codegen_1._)`""`,
      opts: this.opts,
      self: this
    }
    let sourceCode
    try {
      this._compilations.add(sch)
      ;(0, validate_1.validateFunctionCode)(schemaCxt)
      gen.optimize(this.opts.code.optimize)
      // gen.optimize(1)
      const validateCode = gen.toString()
      sourceCode = `${gen.scopeRefs(names_1.default.scope)}return ${validateCode}`
      // console.log((codeSize += sourceCode.length), (nodeCount += gen.nodeCount))
      if (this.opts.code.process) {
        sourceCode = this.opts.code.process(sourceCode, sch)
      }
      // console.log("\n\n\n *** \n", sourceCode)
      const makeValidate = new Function(
        `${names_1.default.self}`,
        `${names_1.default.scope}`,
        sourceCode
      )
      const validate = makeValidate(this, this.scope.get())
      this.scope.value(validateName, {
        ref: validate
      })
      validate.errors = null
      validate.schema = sch.schema
      validate.schemaEnv = sch
      if (sch.$async) {
        validate.$async = true
      }
      if (this.opts.code.source === true) {
        validate.source = {
          validateName,
          validateCode,
          scopeValues: gen._values
        }
      }
      if (this.opts.unevaluated) {
        const { props, items } = schemaCxt
        validate.evaluated = {
          props: props instanceof codegen_1.Name ? undefined : props,
          items: items instanceof codegen_1.Name ? undefined : items,
          dynamicProps: props instanceof codegen_1.Name,
          dynamicItems: items instanceof codegen_1.Name
        }
        if (validate.source) {
          validate.source.evaluated = (0, codegen_1.stringify)(
            validate.evaluated
          )
        }
      }
      sch.validate = validate
      return sch
    } catch (e) {
      delete sch.validate
      delete sch.validateName
      if (sourceCode) {
        this.logger.error('Error compiling schema, function code:', sourceCode)
      }
      // console.log("\n\n\n *** \n", sourceCode, this.opts)
      throw e
    } finally {
      this._compilations.delete(sch)
    }
  }
  compile.compileSchema = compileSchema
  function resolveRef(root, baseId, ref) {
    let _a
    ref = (0, resolve_1.resolveUrl)(this.opts.uriResolver, baseId, ref)
    const schOrFunc = root.refs[ref]
    if (schOrFunc) {
      return schOrFunc
    }
    let _sch = resolve.call(this, root, ref)
    if (_sch === undefined) {
      const schema =
        (_a = root.localRefs) === null || _a === void 0 ? void 0 : _a[ref] // TODO maybe localRefs should hold SchemaEnv
      const { schemaId } = this.opts
      if (schema) {
        _sch = new SchemaEnv({
          schema,
          schemaId,
          root,
          baseId
        })
      }
    }
    if (_sch === undefined) {
      return
    }
    return (root.refs[ref] = inlineOrCompile.call(this, _sch))
  }
  compile.resolveRef = resolveRef
  function inlineOrCompile(sch) {
    if ((0, resolve_1.inlineRef)(sch.schema, this.opts.inlineRefs)) {
      return sch.schema
    }
    return sch.validate ? sch : compileSchema.call(this, sch)
  }
  // Index of schema compilation in the currently compiled list
  function getCompilingSchema(schEnv) {
    for (const sch of this._compilations) {
      if (sameSchemaEnv(sch, schEnv)) {
        return sch
      }
    }
  }
  compile.getCompilingSchema = getCompilingSchema
  function sameSchemaEnv(s1, s2) {
    return (
      s1.schema === s2.schema && s1.root === s2.root && s1.baseId === s2.baseId
    )
  }
  // resolve and compile the references ($ref)
  // TODO returns AnySchemaObject (if the schema can be inlined) or validation function
  function resolve(
    root,
    // information about the root schema for the current schema
    ref // reference to resolve
  ) {
    let sch
    while (typeof (sch = this.refs[ref]) == 'string') {
      ref = sch
    }
    return sch || this.schemas[ref] || resolveSchema.call(this, root, ref)
  }
  // Resolve schema, its root and baseId
  function resolveSchema(
    root,
    // root object with properties schema, refs TODO below SchemaEnv is assigned to it
    ref // reference to resolve
  ) {
    const p = this.opts.uriResolver.parse(ref)
    const refPath = (0, resolve_1._getFullPath)(this.opts.uriResolver, p)
    let baseId = (0, resolve_1.getFullPath)(
      this.opts.uriResolver,
      root.baseId,
      undefined
    )
    // TODO `Object.keys(root.schema).length > 0` should not be needed - but removing breaks 2 tests
    if (Object.keys(root.schema).length > 0 && refPath === baseId) {
      return getJsonPointer.call(this, p, root)
    }
    const id = (0, resolve_1.normalizeId)(refPath)
    const schOrRef = this.refs[id] || this.schemas[id]
    if (typeof schOrRef == 'string') {
      const sch = resolveSchema.call(this, root, schOrRef)
      if (
        typeof (sch === null || sch === void 0 ? void 0 : sch.schema) !==
        'object'
      ) {
        return
      }
      return getJsonPointer.call(this, p, sch)
    }
    if (
      typeof (schOrRef === null || schOrRef === void 0
        ? void 0
        : schOrRef.schema) !== 'object'
    ) {
      return
    }
    if (!schOrRef.validate) {
      compileSchema.call(this, schOrRef)
    }
    if (id === (0, resolve_1.normalizeId)(ref)) {
      const { schema } = schOrRef
      const { schemaId } = this.opts
      const schId = schema[schemaId]
      if (schId) {
        baseId = (0, resolve_1.resolveUrl)(this.opts.uriResolver, baseId, schId)
      }
      return new SchemaEnv({
        schema,
        schemaId,
        root,
        baseId
      })
    }
    return getJsonPointer.call(this, p, schOrRef)
  }
  compile.resolveSchema = resolveSchema
  const PREVENT_SCOPE_CHANGE = new Set([
    'properties',
    'patternProperties',
    'enum',
    'dependencies',
    'definitions'
  ])
  function getJsonPointer(parsedRef, { baseId, schema, root }) {
    let _a
    if (
      ((_a = parsedRef.fragment) === null || _a === void 0 ? void 0 : _a[0]) !==
      '/'
    ) {
      return
    }
    for (const part of parsedRef.fragment.slice(1).split('/')) {
      if (typeof schema === 'boolean') {
        return
      }
      const partSchema = schema[(0, util_1.unescapeFragment)(part)]
      if (partSchema === undefined) {
        return
      }
      schema = partSchema
      // TODO PREVENT_SCOPE_CHANGE could be defined in keyword def?
      const schId = typeof schema === 'object' && schema[this.opts.schemaId]
      if (!PREVENT_SCOPE_CHANGE.has(part) && schId) {
        baseId = (0, resolve_1.resolveUrl)(this.opts.uriResolver, baseId, schId)
      }
    }
    let env
    if (
      typeof schema != 'boolean' &&
      schema.$ref &&
      !(0, util_1.schemaHasRulesButRef)(schema, this.RULES)
    ) {
      const $ref = (0, resolve_1.resolveUrl)(
        this.opts.uriResolver,
        baseId,
        schema.$ref
      )
      env = resolveSchema.call(this, root, $ref)
    }
    // even though resolution failed we need to return SchemaEnv to throw exception
    // so that compileAsync loads missing schema.
    const { schemaId } = this.opts
    env =
      env ||
      new SchemaEnv({
        schema,
        schemaId,
        root,
        baseId
      })
    if (env.schema !== env.root.schema) {
      return env
    }
    return undefined
  }
  return compile
}

const $id$1 =
  'https://raw.githubusercontent.com/ajv-validator/ajv/master/lib/refs/data.json#'
const description$1 =
  'Meta-schema for $data reference (JSON AnySchema extension proposal)'
const type$3 = 'object'
const required$1 = ['$data']
const properties$2 = {
  $data: {
    type: 'string',
    anyOf: [
      {
        format: 'relative-json-pointer'
      },
      {
        format: 'json-pointer'
      }
    ]
  }
}
const additionalProperties$1 = false
const require$$9 = {
  $id: $id$1,
  description: description$1,
  type: type$3,
  required: required$1,
  properties: properties$2,
  additionalProperties: additionalProperties$1
}

const uri = {}

const fastUri = { exports: {} }

let scopedChars
let hasRequiredScopedChars
function requireScopedChars() {
  if (hasRequiredScopedChars) {
    return scopedChars
  }
  hasRequiredScopedChars = 1
  const HEX = {
    0: 0,
    1: 1,
    2: 2,
    3: 3,
    4: 4,
    5: 5,
    6: 6,
    7: 7,
    8: 8,
    9: 9,
    a: 10,
    A: 10,
    b: 11,
    B: 11,
    c: 12,
    C: 12,
    d: 13,
    D: 13,
    e: 14,
    E: 14,
    f: 15,
    F: 15
  }
  scopedChars = {
    HEX
  }
  return scopedChars
}

let utils$4
let hasRequiredUtils$4
function requireUtils$4() {
  if (hasRequiredUtils$4) {
    return utils$4
  }
  hasRequiredUtils$4 = 1
  const { HEX } = requireScopedChars()
  const IPV4_REG =
    /^(?:(?:25[0-5]|2[0-4]\d|1\d{2}|[1-9]\d|\d)\.){3}(?:25[0-5]|2[0-4]\d|1\d{2}|[1-9]\d|\d)$/u
  function normalizeIPv4(host) {
    if (findToken(host, '.') < 3) {
      return {
        host,
        isIPV4: false
      }
    }
    const matches = host.match(IPV4_REG) || []
    const [address] = matches
    if (address) {
      return {
        host: stripLeadingZeros(address, '.'),
        isIPV4: true
      }
    } else {
      return {
        host,
        isIPV4: false
      }
    }
  }

  /**
   * @param {string[]} input
   * @param {boolean} [keepZero=false]
   * @returns {string|undefined}
   */
  function stringArrayToHexStripped(input, keepZero = false) {
    let acc = ''
    let strip = true
    for (const c of input) {
      if (HEX[c] === undefined) {
        return undefined
      }
      if (c !== '0' && strip === true) {
        strip = false
      }
      if (!strip) {
        acc += c
      }
    }
    if (keepZero && acc.length === 0) {
      acc = '0'
    }
    return acc
  }
  function getIPV6(input) {
    let tokenCount = 0
    const output = {
      error: false,
      address: '',
      zone: ''
    }
    const address = []
    const buffer = []
    let isZone = false
    let endipv6Encountered = false
    let endIpv6 = false
    function consume() {
      if (buffer.length) {
        if (isZone === false) {
          const hex = stringArrayToHexStripped(buffer)
          if (hex !== undefined) {
            address.push(hex)
          } else {
            output.error = true
            return false
          }
        }
        buffer.length = 0
      }
      return true
    }
    for (let i = 0; i < input.length; i++) {
      const cursor = input[i]
      if (cursor === '[' || cursor === ']') {
        continue
      }
      if (cursor === ':') {
        if (endipv6Encountered === true) {
          endIpv6 = true
        }
        if (!consume()) {
          break
        }
        tokenCount++
        address.push(':')
        if (tokenCount > 7) {
          // not valid
          output.error = true
          break
        }
        if (i - 1 >= 0 && input[i - 1] === ':') {
          endipv6Encountered = true
        }
        continue
      } else if (cursor === '%') {
        if (!consume()) {
          break
        }
        // switch to zone detection
        isZone = true
      } else {
        buffer.push(cursor)
        continue
      }
    }
    if (buffer.length) {
      if (isZone) {
        output.zone = buffer.join('')
      } else if (endIpv6) {
        address.push(buffer.join(''))
      } else {
        address.push(stringArrayToHexStripped(buffer))
      }
    }
    output.address = address.join('')
    return output
  }
  function normalizeIPv6(host) {
    if (findToken(host, ':') < 2) {
      return {
        host,
        isIPV6: false
      }
    }
    const ipv6 = getIPV6(host)
    if (!ipv6.error) {
      let newHost = ipv6.address
      let escapedHost = ipv6.address
      if (ipv6.zone) {
        newHost += '%' + ipv6.zone
        escapedHost += '%25' + ipv6.zone
      }
      return {
        host: newHost,
        escapedHost,
        isIPV6: true
      }
    } else {
      return {
        host,
        isIPV6: false
      }
    }
  }
  function stripLeadingZeros(str, token) {
    let out = ''
    let skip = true
    const l = str.length
    for (let i = 0; i < l; i++) {
      const c = str[i]
      if (c === '0' && skip) {
        if ((i + 1 <= l && str[i + 1] === token) || i + 1 === l) {
          out += c
          skip = false
        }
      } else {
        if (c === token) {
          skip = true
        } else {
          skip = false
        }
        out += c
      }
    }
    return out
  }
  function findToken(str, token) {
    let ind = 0
    for (let i = 0; i < str.length; i++) {
      if (str[i] === token) {
        ind++
      }
    }
    return ind
  }
  const RDS1 = /^\.\.?\//u
  const RDS2 = /^\/\.(?:\/|$)/u
  const RDS3 = /^\/\.\.(?:\/|$)/u
  const RDS5 = /^\/?(?:.|\n)*?(?=\/|$)/u
  function removeDotSegments(input) {
    const output = []
    while (input.length) {
      if (input.match(RDS1)) {
        input = input.replace(RDS1, '')
      } else if (input.match(RDS2)) {
        input = input.replace(RDS2, '/')
      } else if (input.match(RDS3)) {
        input = input.replace(RDS3, '/')
        output.pop()
      } else if (input === '.' || input === '..') {
        input = ''
      } else {
        const im = input.match(RDS5)
        if (im) {
          const s = im[0]
          input = input.slice(s.length)
          output.push(s)
        } else {
          throw new Error('Unexpected dot segment condition')
        }
      }
    }
    return output.join('')
  }
  function normalizeComponentEncoding(components, esc) {
    const func = esc !== true ? escape : unescape
    if (components.scheme !== undefined) {
      components.scheme = func(components.scheme)
    }
    if (components.userinfo !== undefined) {
      components.userinfo = func(components.userinfo)
    }
    if (components.host !== undefined) {
      components.host = func(components.host)
    }
    if (components.path !== undefined) {
      components.path = func(components.path)
    }
    if (components.query !== undefined) {
      components.query = func(components.query)
    }
    if (components.fragment !== undefined) {
      components.fragment = func(components.fragment)
    }
    return components
  }
  function recomposeAuthority(components) {
    const uriTokens = []
    if (components.userinfo !== undefined) {
      uriTokens.push(components.userinfo)
      uriTokens.push('@')
    }
    if (components.host !== undefined) {
      let host = unescape(components.host)
      const ipV4res = normalizeIPv4(host)
      if (ipV4res.isIPV4) {
        host = ipV4res.host
      } else {
        const ipV6res = normalizeIPv6(ipV4res.host)
        if (ipV6res.isIPV6 === true) {
          host = `[${ipV6res.escapedHost}]`
        } else {
          host = components.host
        }
      }
      uriTokens.push(host)
    }
    if (
      typeof components.port === 'number' ||
      typeof components.port === 'string'
    ) {
      uriTokens.push(':')
      uriTokens.push(String(components.port))
    }
    return uriTokens.length ? uriTokens.join('') : undefined
  }
  utils$4 = {
    recomposeAuthority,
    normalizeComponentEncoding,
    removeDotSegments,
    normalizeIPv4,
    normalizeIPv6,
    stringArrayToHexStripped
  }
  return utils$4
}

let schemes
let hasRequiredSchemes
function requireSchemes() {
  if (hasRequiredSchemes) {
    return schemes
  }
  hasRequiredSchemes = 1
  const UUID_REG = /^[\da-f]{8}-[\da-f]{4}-[\da-f]{4}-[\da-f]{4}-[\da-f]{12}$/iu
  const URN_REG =
    /([\da-z][\d\-a-z]{0,31}):((?:[\w!$'()*+,\-.:;=@]|%[\da-f]{2})+)/iu
  function isSecure(wsComponents) {
    return typeof wsComponents.secure === 'boolean'
      ? wsComponents.secure
      : String(wsComponents.scheme).toLowerCase() === 'wss'
  }
  function httpParse(components) {
    if (!components.host) {
      components.error = components.error || 'HTTP URIs must have a host.'
    }
    return components
  }
  function httpSerialize(components) {
    const secure = String(components.scheme).toLowerCase() === 'https'

    // normalize the default port
    if (components.port === (secure ? 443 : 80) || components.port === '') {
      components.port = undefined
    }

    // normalize the empty path
    if (!components.path) {
      components.path = '/'
    }

    // NOTE: We do not parse query strings for HTTP URIs
    // as WWW Form Url Encoded query strings are part of the HTML4+ spec,
    // and not the HTTP spec.

    return components
  }
  function wsParse(wsComponents) {
    // indicate if the secure flag is set
    wsComponents.secure = isSecure(wsComponents)

    // construct resouce name
    wsComponents.resourceName =
      (wsComponents.path || '/') +
      (wsComponents.query ? '?' + wsComponents.query : '')
    wsComponents.path = undefined
    wsComponents.query = undefined
    return wsComponents
  }
  function wsSerialize(wsComponents) {
    // normalize the default port
    if (
      wsComponents.port === (isSecure(wsComponents) ? 443 : 80) ||
      wsComponents.port === ''
    ) {
      wsComponents.port = undefined
    }

    // ensure scheme matches secure flag
    if (typeof wsComponents.secure === 'boolean') {
      wsComponents.scheme = wsComponents.secure ? 'wss' : 'ws'
      wsComponents.secure = undefined
    }

    // reconstruct path from resource name
    if (wsComponents.resourceName) {
      const [path, query] = wsComponents.resourceName.split('?')
      wsComponents.path = path && path !== '/' ? path : undefined
      wsComponents.query = query
      wsComponents.resourceName = undefined
    }

    // forbid fragment component
    wsComponents.fragment = undefined
    return wsComponents
  }
  function urnParse(urnComponents, options) {
    if (!urnComponents.path) {
      urnComponents.error = 'URN can not be parsed'
      return urnComponents
    }
    const matches = urnComponents.path.match(URN_REG)
    if (matches) {
      const scheme = options.scheme || urnComponents.scheme || 'urn'
      urnComponents.nid = matches[1].toLowerCase()
      urnComponents.nss = matches[2]
      const urnScheme = `${scheme}:${options.nid || urnComponents.nid}`
      const schemeHandler = SCHEMES[urnScheme]
      urnComponents.path = undefined
      if (schemeHandler) {
        urnComponents = schemeHandler.parse(urnComponents, options)
      }
    } else {
      urnComponents.error = urnComponents.error || 'URN can not be parsed.'
    }
    return urnComponents
  }
  function urnSerialize(urnComponents, options) {
    const scheme = options.scheme || urnComponents.scheme || 'urn'
    const nid = urnComponents.nid.toLowerCase()
    const urnScheme = `${scheme}:${options.nid || nid}`
    const schemeHandler = SCHEMES[urnScheme]
    if (schemeHandler) {
      urnComponents = schemeHandler.serialize(urnComponents, options)
    }
    const uriComponents = urnComponents
    const nss = urnComponents.nss
    uriComponents.path = `${nid || options.nid}:${nss}`
    options.skipEscape = true
    return uriComponents
  }
  function urnuuidParse(urnComponents, options) {
    const uuidComponents = urnComponents
    uuidComponents.uuid = uuidComponents.nss
    uuidComponents.nss = undefined
    if (
      !options.tolerant &&
      (!uuidComponents.uuid || !UUID_REG.test(uuidComponents.uuid))
    ) {
      uuidComponents.error = uuidComponents.error || 'UUID is not valid.'
    }
    return uuidComponents
  }
  function urnuuidSerialize(uuidComponents) {
    const urnComponents = uuidComponents
    // normalize UUID
    urnComponents.nss = (uuidComponents.uuid || '').toLowerCase()
    return urnComponents
  }
  const http = {
    scheme: 'http',
    domainHost: true,
    parse: httpParse,
    serialize: httpSerialize
  }
  const https = {
    scheme: 'https',
    domainHost: http.domainHost,
    parse: httpParse,
    serialize: httpSerialize
  }
  const ws = {
    scheme: 'ws',
    domainHost: true,
    parse: wsParse,
    serialize: wsSerialize
  }
  const wss = {
    scheme: 'wss',
    domainHost: ws.domainHost,
    parse: ws.parse,
    serialize: ws.serialize
  }
  const urn = {
    scheme: 'urn',
    parse: urnParse,
    serialize: urnSerialize,
    skipNormalize: true
  }
  const urnuuid = {
    scheme: 'urn:uuid',
    parse: urnuuidParse,
    serialize: urnuuidSerialize,
    skipNormalize: true
  }
  const SCHEMES = {
    http,
    https,
    ws,
    wss,
    urn,
    'urn:uuid': urnuuid
  }
  schemes = SCHEMES
  return schemes
}

let hasRequiredFastUri
function requireFastUri() {
  if (hasRequiredFastUri) {
    return fastUri.exports
  }
  hasRequiredFastUri = 1
  const {
    normalizeIPv6,
    normalizeIPv4,
    removeDotSegments,
    recomposeAuthority,
    normalizeComponentEncoding
  } = requireUtils$4()
  const SCHEMES = requireSchemes()
  function normalize(uri, options) {
    if (typeof uri === 'string') {
      uri = serialize(parse(uri, options), options)
    } else if (typeof uri === 'object') {
      uri = parse(serialize(uri, options), options)
    }
    return uri
  }
  function resolve(baseURI, relativeURI, options) {
    const schemelessOptions = Object.assign(
      {
        scheme: 'null'
      },
      options
    )
    const resolved = resolveComponents(
      parse(baseURI, schemelessOptions),
      parse(relativeURI, schemelessOptions),
      schemelessOptions,
      true
    )
    return serialize(resolved, {
      ...schemelessOptions,
      skipEscape: true
    })
  }
  function resolveComponents(base, relative, options, skipNormalization) {
    const target = {}
    if (!skipNormalization) {
      base = parse(serialize(base, options), options) // normalize base components
      relative = parse(serialize(relative, options), options) // normalize relative components
    }
    options = options || {}
    if (!options.tolerant && relative.scheme) {
      target.scheme = relative.scheme
      // target.authority = relative.authority;
      target.userinfo = relative.userinfo
      target.host = relative.host
      target.port = relative.port
      target.path = removeDotSegments(relative.path || '')
      target.query = relative.query
    } else {
      if (
        relative.userinfo !== undefined ||
        relative.host !== undefined ||
        relative.port !== undefined
      ) {
        // target.authority = relative.authority;
        target.userinfo = relative.userinfo
        target.host = relative.host
        target.port = relative.port
        target.path = removeDotSegments(relative.path || '')
        target.query = relative.query
      } else {
        if (!relative.path) {
          target.path = base.path
          if (relative.query !== undefined) {
            target.query = relative.query
          } else {
            target.query = base.query
          }
        } else {
          if (relative.path.charAt(0) === '/') {
            target.path = removeDotSegments(relative.path)
          } else {
            if (
              (base.userinfo !== undefined ||
                base.host !== undefined ||
                base.port !== undefined) &&
              !base.path
            ) {
              target.path = '/' + relative.path
            } else if (!base.path) {
              target.path = relative.path
            } else {
              target.path =
                base.path.slice(0, base.path.lastIndexOf('/') + 1) +
                relative.path
            }
            target.path = removeDotSegments(target.path)
          }
          target.query = relative.query
        }
        // target.authority = base.authority;
        target.userinfo = base.userinfo
        target.host = base.host
        target.port = base.port
      }
      target.scheme = base.scheme
    }
    target.fragment = relative.fragment
    return target
  }
  function equal(uriA, uriB, options) {
    if (typeof uriA === 'string') {
      uriA = unescape(uriA)
      uriA = serialize(normalizeComponentEncoding(parse(uriA, options), true), {
        ...options,
        skipEscape: true
      })
    } else if (typeof uriA === 'object') {
      uriA = serialize(normalizeComponentEncoding(uriA, true), {
        ...options,
        skipEscape: true
      })
    }
    if (typeof uriB === 'string') {
      uriB = unescape(uriB)
      uriB = serialize(normalizeComponentEncoding(parse(uriB, options), true), {
        ...options,
        skipEscape: true
      })
    } else if (typeof uriB === 'object') {
      uriB = serialize(normalizeComponentEncoding(uriB, true), {
        ...options,
        skipEscape: true
      })
    }
    return uriA.toLowerCase() === uriB.toLowerCase()
  }
  function serialize(cmpts, opts) {
    const components = {
      host: cmpts.host,
      scheme: cmpts.scheme,
      userinfo: cmpts.userinfo,
      port: cmpts.port,
      path: cmpts.path,
      query: cmpts.query,
      nid: cmpts.nid,
      nss: cmpts.nss,
      uuid: cmpts.uuid,
      fragment: cmpts.fragment,
      reference: cmpts.reference,
      resourceName: cmpts.resourceName,
      secure: cmpts.secure,
      error: ''
    }
    const options = Object.assign({}, opts)
    const uriTokens = []

    // find scheme handler
    const schemeHandler =
      SCHEMES[(options.scheme || components.scheme || '').toLowerCase()]

    // perform scheme specific serialization
    if (schemeHandler && schemeHandler.serialize) {
      schemeHandler.serialize(components, options)
    }
    if (components.path !== undefined) {
      if (!options.skipEscape) {
        components.path = escape(components.path)
        if (components.scheme !== undefined) {
          components.path = components.path.split('%3A').join(':')
        }
      } else {
        components.path = unescape(components.path)
      }
    }
    if (options.reference !== 'suffix' && components.scheme) {
      uriTokens.push(components.scheme, ':')
    }
    const authority = recomposeAuthority(components)
    if (authority !== undefined) {
      if (options.reference !== 'suffix') {
        uriTokens.push('//')
      }
      uriTokens.push(authority)
      if (components.path && components.path.charAt(0) !== '/') {
        uriTokens.push('/')
      }
    }
    if (components.path !== undefined) {
      let s = components.path
      if (
        !options.absolutePath &&
        (!schemeHandler || !schemeHandler.absolutePath)
      ) {
        s = removeDotSegments(s)
      }
      if (authority === undefined) {
        s = s.replace(/^\/\//u, '/%2F') // don't allow the path to start with "//"
      }
      uriTokens.push(s)
    }
    if (components.query !== undefined) {
      uriTokens.push('?', components.query)
    }
    if (components.fragment !== undefined) {
      uriTokens.push('#', components.fragment)
    }
    return uriTokens.join('')
  }
  const hexLookUp = Array.from(
    {
      length: 127
    },
    (_v, k) => /[^!"$&'()*+,\-.;=_`a-z{}~]/u.test(String.fromCharCode(k))
  )
  function nonSimpleDomain(value) {
    let code = 0
    for (let i = 0, len = value.length; i < len; ++i) {
      code = value.charCodeAt(i)
      if (code > 126 || hexLookUp[code]) {
        return true
      }
    }
    return false
  }
  const URI_PARSE =
    /^(?:([^#/:?]+):)?(?:\/\/((?:([^#/?@]*)@)?(\[[^#/?\]]+\]|[^#/:?]*)(?::(\d*))?))?([^#?]*)(?:\?([^#]*))?(?:#((?:.|[\n\r])*))?/u
  function parse(uri, opts) {
    const options = Object.assign({}, opts)
    const parsed = {
      scheme: undefined,
      userinfo: undefined,
      host: '',
      port: undefined,
      path: '',
      query: undefined,
      fragment: undefined
    }
    const gotEncoding = uri.indexOf('%') !== -1
    let isIP = false
    if (options.reference === 'suffix') {
      uri = (options.scheme ? options.scheme + ':' : '') + '//' + uri
    }
    const matches = uri.match(URI_PARSE)
    if (matches) {
      // store each component
      parsed.scheme = matches[1]
      parsed.userinfo = matches[3]
      parsed.host = matches[4]
      parsed.port = parseInt(matches[5], 10)
      parsed.path = matches[6] || ''
      parsed.query = matches[7]
      parsed.fragment = matches[8]

      // fix port number
      if (isNaN(parsed.port)) {
        parsed.port = matches[5]
      }
      if (parsed.host) {
        const ipv4result = normalizeIPv4(parsed.host)
        if (ipv4result.isIPV4 === false) {
          const ipv6result = normalizeIPv6(ipv4result.host)
          parsed.host = ipv6result.host.toLowerCase()
          isIP = ipv6result.isIPV6
        } else {
          parsed.host = ipv4result.host
          isIP = true
        }
      }
      if (
        parsed.scheme === undefined &&
        parsed.userinfo === undefined &&
        parsed.host === undefined &&
        parsed.port === undefined &&
        parsed.query === undefined &&
        !parsed.path
      ) {
        parsed.reference = 'same-document'
      } else if (parsed.scheme === undefined) {
        parsed.reference = 'relative'
      } else if (parsed.fragment === undefined) {
        parsed.reference = 'absolute'
      } else {
        parsed.reference = 'uri'
      }

      // check for reference errors
      if (
        options.reference &&
        options.reference !== 'suffix' &&
        options.reference !== parsed.reference
      ) {
        parsed.error =
          parsed.error || 'URI is not a ' + options.reference + ' reference.'
      }

      // find scheme handler
      const schemeHandler =
        SCHEMES[(options.scheme || parsed.scheme || '').toLowerCase()]

      // check if scheme can't handle IRIs
      if (
        !options.unicodeSupport &&
        (!schemeHandler || !schemeHandler.unicodeSupport)
      ) {
        // if host component is a domain name
        if (
          parsed.host &&
          (options.domainHost || (schemeHandler && schemeHandler.domainHost)) &&
          isIP === false &&
          nonSimpleDomain(parsed.host)
        ) {
          // convert Unicode IDN -> ASCII IDN
          try {
            parsed.host = URL.domainToASCII(parsed.host.toLowerCase())
          } catch (e) {
            parsed.error =
              parsed.error ||
              "Host's domain name can not be converted to ASCII: " + e
          }
        }
        // convert IRI -> URI
      }
      if (!schemeHandler || (schemeHandler && !schemeHandler.skipNormalize)) {
        if (gotEncoding && parsed.scheme !== undefined) {
          parsed.scheme = unescape(parsed.scheme)
        }
        if (gotEncoding && parsed.host !== undefined) {
          parsed.host = unescape(parsed.host)
        }
        if (parsed.path) {
          parsed.path = escape(unescape(parsed.path))
        }
        if (parsed.fragment) {
          parsed.fragment = encodeURI(decodeURIComponent(parsed.fragment))
        }
      }

      // perform scheme specific parsing
      if (schemeHandler && schemeHandler.parse) {
        schemeHandler.parse(parsed, options)
      }
    } else {
      parsed.error = parsed.error || 'URI can not be parsed.'
    }
    return parsed
  }
  const fastUri$1 = {
    SCHEMES,
    normalize,
    resolve,
    resolveComponents,
    equal,
    serialize,
    parse
  }
  fastUri.exports = fastUri$1
  fastUri.exports.default = fastUri$1
  fastUri.exports.fastUri = fastUri$1
  return fastUri.exports
}

let hasRequiredUri
function requireUri() {
  if (hasRequiredUri) {
    return uri
  }
  hasRequiredUri = 1
  Object.defineProperty(uri, '__esModule', {
    value: true
  })
  const uri$1 = requireFastUri()
  uri$1.code = 'require("ajv/dist/runtime/uri").default'
  uri.default = uri$1
  return uri
}

let hasRequiredCore$3
function requireCore$3() {
  if (hasRequiredCore$3) {
    return core$3
  }
  hasRequiredCore$3 = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.CodeGen =
      exports.Name =
      exports.nil =
      exports.stringify =
      exports.str =
      exports._ =
      exports.KeywordCxt =
        void 0
    const validate_1 = requireValidate$1()
    Object.defineProperty(exports, 'KeywordCxt', {
      enumerable: true,
      get: function () {
        return validate_1.KeywordCxt
      }
    })
    const codegen_1 = requireCodegen()
    Object.defineProperty(exports, '_', {
      enumerable: true,
      get: function () {
        return codegen_1._
      }
    })
    Object.defineProperty(exports, 'str', {
      enumerable: true,
      get: function () {
        return codegen_1.str
      }
    })
    Object.defineProperty(exports, 'stringify', {
      enumerable: true,
      get: function () {
        return codegen_1.stringify
      }
    })
    Object.defineProperty(exports, 'nil', {
      enumerable: true,
      get: function () {
        return codegen_1.nil
      }
    })
    Object.defineProperty(exports, 'Name', {
      enumerable: true,
      get: function () {
        return codegen_1.Name
      }
    })
    Object.defineProperty(exports, 'CodeGen', {
      enumerable: true,
      get: function () {
        return codegen_1.CodeGen
      }
    })
    const validation_error_1 = requireValidation_error()
    const ref_error_1 = requireRef_error()
    const rules_1 = requireRules()
    const compile_1 = requireCompile$1()
    const codegen_2 = requireCodegen()
    const resolve_1 = requireResolve()
    const dataType_1 = requireDataType()
    const util_1 = requireUtil()
    const $dataRefSchema = require$$9
    const uri_1 = requireUri()
    const defaultRegExp = (str, flags) => new RegExp(str, flags)
    defaultRegExp.code = 'new RegExp'
    const META_IGNORE_OPTIONS = [
      'removeAdditional',
      'useDefaults',
      'coerceTypes'
    ]
    const EXT_SCOPE_NAMES = new Set([
      'validate',
      'serialize',
      'parse',
      'wrapper',
      'root',
      'schema',
      'keyword',
      'pattern',
      'formats',
      'validate$data',
      'func',
      'obj',
      'Error'
    ])
    const removedOptions = {
      errorDataPath: '',
      format: '`validateFormats: false` can be used instead.',
      nullable: '"nullable" keyword is supported by default.',
      jsonPointers: 'Deprecated jsPropertySyntax can be used instead.',
      extendRefs: 'Deprecated ignoreKeywordsWithRef can be used instead.',
      missingRefs:
        'Pass empty schema with $id that should be ignored to ajv.addSchema.',
      processCode:
        'Use option `code: {process: (code, schemaEnv: object) => string}`',
      sourceCode: 'Use option `code: {source: true}`',
      strictDefaults: 'It is default now, see option `strict`.',
      strictKeywords: 'It is default now, see option `strict`.',
      uniqueItems: '"uniqueItems" keyword is always validated.',
      unknownFormats:
        'Disable strict mode or pass `true` to `ajv.addFormat` (or `formats` option).',
      cache: 'Map is used as cache, schema object as key.',
      serialize: 'Map is used as cache, schema object as key.',
      ajvErrors: 'It is default now.'
    }
    const deprecatedOptions = {
      ignoreKeywordsWithRef: '',
      jsPropertySyntax: '',
      unicode:
        '"minLength"/"maxLength" account for unicode characters by default.'
    }
    const MAX_EXPRESSION = 200
    // eslint-disable-next-line complexity
    function requiredOptions(o) {
      let _a,
        _b,
        _c,
        _d,
        _e,
        _f,
        _g,
        _h,
        _j,
        _k,
        _l,
        _m,
        _o,
        _p,
        _q,
        _r,
        _s,
        _t,
        _u,
        _v,
        _w,
        _x,
        _y,
        _z,
        _0
      const s = o.strict
      const _optz =
        (_a = o.code) === null || _a === void 0 ? void 0 : _a.optimize
      const optimize = _optz === true || _optz === undefined ? 1 : _optz || 0
      const regExp =
        (_c = (_b = o.code) === null || _b === void 0 ? void 0 : _b.regExp) !==
          null && _c !== void 0
          ? _c
          : defaultRegExp
      const uriResolver =
        (_d = o.uriResolver) !== null && _d !== void 0 ? _d : uri_1.default
      return {
        strictSchema:
          (_f = (_e = o.strictSchema) !== null && _e !== void 0 ? _e : s) !==
            null && _f !== void 0
            ? _f
            : true,
        strictNumbers:
          (_h = (_g = o.strictNumbers) !== null && _g !== void 0 ? _g : s) !==
            null && _h !== void 0
            ? _h
            : true,
        strictTypes:
          (_k = (_j = o.strictTypes) !== null && _j !== void 0 ? _j : s) !==
            null && _k !== void 0
            ? _k
            : 'log',
        strictTuples:
          (_m = (_l = o.strictTuples) !== null && _l !== void 0 ? _l : s) !==
            null && _m !== void 0
            ? _m
            : 'log',
        strictRequired:
          (_p = (_o = o.strictRequired) !== null && _o !== void 0 ? _o : s) !==
            null && _p !== void 0
            ? _p
            : false,
        code: o.code
          ? {
              ...o.code,
              optimize,
              regExp
            }
          : {
              optimize,
              regExp
            },
        loopRequired:
          (_q = o.loopRequired) !== null && _q !== void 0 ? _q : MAX_EXPRESSION,
        loopEnum:
          (_r = o.loopEnum) !== null && _r !== void 0 ? _r : MAX_EXPRESSION,
        meta: (_s = o.meta) !== null && _s !== void 0 ? _s : true,
        messages: (_t = o.messages) !== null && _t !== void 0 ? _t : true,
        inlineRefs: (_u = o.inlineRefs) !== null && _u !== void 0 ? _u : true,
        schemaId: (_v = o.schemaId) !== null && _v !== void 0 ? _v : '$id',
        addUsedSchema:
          (_w = o.addUsedSchema) !== null && _w !== void 0 ? _w : true,
        validateSchema:
          (_x = o.validateSchema) !== null && _x !== void 0 ? _x : true,
        validateFormats:
          (_y = o.validateFormats) !== null && _y !== void 0 ? _y : true,
        unicodeRegExp:
          (_z = o.unicodeRegExp) !== null && _z !== void 0 ? _z : true,
        int32range: (_0 = o.int32range) !== null && _0 !== void 0 ? _0 : true,
        uriResolver: uriResolver
      }
    }
    class Ajv {
      constructor(opts = {}) {
        this.schemas = {}
        this.refs = {}
        this.formats = {}
        this._compilations = new Set()
        this._loading = {}
        this._cache = new Map()
        opts = this.opts = {
          ...opts,
          ...requiredOptions(opts)
        }
        const { es5, lines } = this.opts.code
        this.scope = new codegen_2.ValueScope({
          scope: {},
          prefixes: EXT_SCOPE_NAMES,
          es5,
          lines
        })
        this.logger = getLogger(opts.logger)
        const formatOpt = opts.validateFormats
        opts.validateFormats = false
        this.RULES = (0, rules_1.getRules)()
        checkOptions.call(this, removedOptions, opts, 'NOT SUPPORTED')
        checkOptions.call(this, deprecatedOptions, opts, 'DEPRECATED', 'warn')
        this._metaOpts = getMetaSchemaOptions.call(this)
        if (opts.formats) {
          addInitialFormats.call(this)
        }
        this._addVocabularies()
        this._addDefaultMetaSchema()
        if (opts.keywords) {
          addInitialKeywords.call(this, opts.keywords)
        }
        if (typeof opts.meta == 'object') {
          this.addMetaSchema(opts.meta)
        }
        addInitialSchemas.call(this)
        opts.validateFormats = formatOpt
      }
      _addVocabularies() {
        this.addKeyword('$async')
      }
      _addDefaultMetaSchema() {
        const { $data, meta, schemaId } = this.opts
        let _dataRefSchema = $dataRefSchema
        if (schemaId === 'id') {
          _dataRefSchema = {
            ...$dataRefSchema
          }
          _dataRefSchema.id = _dataRefSchema.$id
          delete _dataRefSchema.$id
        }
        if (meta && $data) {
          this.addMetaSchema(_dataRefSchema, _dataRefSchema[schemaId], false)
        }
      }
      defaultMeta() {
        const { meta, schemaId } = this.opts
        return (this.opts.defaultMeta =
          typeof meta == 'object' ? meta[schemaId] || meta : undefined)
      }
      validate(
        schemaKeyRef,
        // key, ref or schema object
        // eslint-disable-next-line @typescript-eslint/no-redundant-type-constituents
        data // to be validated
      ) {
        let v
        if (typeof schemaKeyRef == 'string') {
          v = this.getSchema(schemaKeyRef)
          if (!v) {
            throw new Error(`no schema with key or ref "${schemaKeyRef}"`)
          }
        } else {
          v = this.compile(schemaKeyRef)
        }
        const valid = v(data)
        if (!('$async' in v)) {
          this.errors = v.errors
        }
        return valid
      }
      compile(schema, _meta) {
        const sch = this._addSchema(schema, _meta)
        return sch.validate || this._compileSchemaEnv(sch)
      }
      compileAsync(schema, meta) {
        if (typeof this.opts.loadSchema != 'function') {
          throw new Error('options.loadSchema should be a function')
        }
        const { loadSchema } = this.opts
        return runCompileAsync.call(this, schema, meta)
        async function runCompileAsync(_schema, _meta) {
          await loadMetaSchema.call(this, _schema.$schema)
          const sch = this._addSchema(_schema, _meta)
          return sch.validate || _compileAsync.call(this, sch)
        }
        async function loadMetaSchema($ref) {
          if ($ref && !this.getSchema($ref)) {
            await runCompileAsync.call(
              this,
              {
                $ref
              },
              true
            )
          }
        }
        async function _compileAsync(sch) {
          try {
            return this._compileSchemaEnv(sch)
          } catch (e) {
            if (!(e instanceof ref_error_1.default)) {
              throw e
            }
            checkLoaded.call(this, e)
            await loadMissingSchema.call(this, e.missingSchema)
            return _compileAsync.call(this, sch)
          }
        }
        function checkLoaded({ missingSchema: ref, missingRef }) {
          if (this.refs[ref]) {
            throw new Error(
              `AnySchema ${ref} is loaded but ${missingRef} cannot be resolved`
            )
          }
        }
        async function loadMissingSchema(ref) {
          const _schema = await _loadSchema.call(this, ref)
          if (!this.refs[ref]) {
            await loadMetaSchema.call(this, _schema.$schema)
          }
          if (!this.refs[ref]) {
            this.addSchema(_schema, ref, meta)
          }
        }
        async function _loadSchema(ref) {
          const p = this._loading[ref]
          if (p) {
            return p
          }
          try {
            return await (this._loading[ref] = loadSchema(ref))
          } finally {
            delete this._loading[ref]
          }
        }
      }
      // Adds schema to the instance
      addSchema(
        schema,
        // If array is passed, `key` will be ignored
        key,
        // Optional schema key. Can be passed to `validate` method instead of schema object or id/ref. One schema per instance can have empty `id` and `key`.
        _meta,
        // true if schema is a meta-schema. Used internally, addMetaSchema should be used instead.
        _validateSchema = this.opts.validateSchema // false to skip schema validation. Used internally, option validateSchema should be used instead.
      ) {
        if (Array.isArray(schema)) {
          for (const sch of schema) {
            this.addSchema(sch, undefined, _meta, _validateSchema)
          }
          return this
        }
        let id
        if (typeof schema === 'object') {
          const { schemaId } = this.opts
          id = schema[schemaId]
          if (id !== undefined && typeof id != 'string') {
            throw new Error(`schema ${schemaId} must be string`)
          }
        }
        key = (0, resolve_1.normalizeId)(key || id)
        this._checkUnique(key)
        this.schemas[key] = this._addSchema(
          schema,
          _meta,
          key,
          _validateSchema,
          true
        )
        return this
      }
      // Add schema that will be used to validate other schemas
      // options in META_IGNORE_OPTIONS are alway set to false
      addMetaSchema(
        schema,
        key,
        // schema key
        _validateSchema = this.opts.validateSchema // false to skip schema validation, can be used to override validateSchema option for meta-schema
      ) {
        this.addSchema(schema, key, true, _validateSchema)
        return this
      }
      //  Validate schema against its meta-schema
      validateSchema(schema, throwOrLogError) {
        if (typeof schema == 'boolean') {
          return true
        }
        let $schema
        $schema = schema.$schema
        if ($schema !== undefined && typeof $schema != 'string') {
          throw new Error('$schema must be a string')
        }
        $schema = $schema || this.opts.defaultMeta || this.defaultMeta()
        if (!$schema) {
          this.logger.warn('meta-schema not available')
          this.errors = null
          return true
        }
        const valid = this.validate($schema, schema)
        if (!valid && throwOrLogError) {
          const message = 'schema is invalid: ' + this.errorsText()
          if (this.opts.validateSchema === 'log') {
            this.logger.error(message)
          } else {
            throw new Error(message)
          }
        }
        return valid
      }
      // Get compiled schema by `key` or `ref`.
      // (`key` that was passed to `addSchema` or full schema reference - `schema.$id` or resolved id)
      getSchema(keyRef) {
        let sch
        while (typeof (sch = getSchEnv.call(this, keyRef)) == 'string') {
          keyRef = sch
        }
        if (sch === undefined) {
          const { schemaId } = this.opts
          const root = new compile_1.SchemaEnv({
            schema: {},
            schemaId
          })
          sch = compile_1.resolveSchema.call(this, root, keyRef)
          if (!sch) {
            return
          }
          this.refs[keyRef] = sch
        }
        return sch.validate || this._compileSchemaEnv(sch)
      }
      // Remove cached schema(s).
      // If no parameter is passed all schemas but meta-schemas are removed.
      // If RegExp is passed all schemas with key/id matching pattern but meta-schemas are removed.
      // Even if schema is referenced by other schemas it still can be removed as other schemas have local references.
      removeSchema(schemaKeyRef) {
        if (schemaKeyRef instanceof RegExp) {
          this._removeAllSchemas(this.schemas, schemaKeyRef)
          this._removeAllSchemas(this.refs, schemaKeyRef)
          return this
        }
        switch (typeof schemaKeyRef) {
          case 'undefined':
            this._removeAllSchemas(this.schemas)
            this._removeAllSchemas(this.refs)
            this._cache.clear()
            return this
          case 'string': {
            const sch = getSchEnv.call(this, schemaKeyRef)
            if (typeof sch == 'object') {
              this._cache.delete(sch.schema)
            }
            delete this.schemas[schemaKeyRef]
            delete this.refs[schemaKeyRef]
            return this
          }
          case 'object': {
            const cacheKey = schemaKeyRef
            this._cache.delete(cacheKey)
            let id = schemaKeyRef[this.opts.schemaId]
            if (id) {
              id = (0, resolve_1.normalizeId)(id)
              delete this.schemas[id]
              delete this.refs[id]
            }
            return this
          }
          default:
            throw new Error('ajv.removeSchema: invalid parameter')
        }
      }
      // add "vocabulary" - a collection of keywords
      addVocabulary(definitions) {
        for (const def of definitions) {
          this.addKeyword(def)
        }
        return this
      }
      addKeyword(
        kwdOrDef,
        def // deprecated
      ) {
        let keyword
        if (typeof kwdOrDef == 'string') {
          keyword = kwdOrDef
          if (typeof def == 'object') {
            this.logger.warn(
              'these parameters are deprecated, see docs for addKeyword'
            )
            def.keyword = keyword
          }
        } else if (typeof kwdOrDef == 'object' && def === undefined) {
          def = kwdOrDef
          keyword = def.keyword
          if (Array.isArray(keyword) && !keyword.length) {
            throw new Error(
              'addKeywords: keyword must be string or non-empty array'
            )
          }
        } else {
          throw new Error('invalid addKeywords parameters')
        }
        checkKeyword.call(this, keyword, def)
        if (!def) {
          ;(0, util_1.eachItem)(keyword, kwd => addRule.call(this, kwd))
          return this
        }
        keywordMetaschema.call(this, def)
        const definition = {
          ...def,
          type: (0, dataType_1.getJSONTypes)(def.type),
          schemaType: (0, dataType_1.getJSONTypes)(def.schemaType)
        }
        ;(0, util_1.eachItem)(
          keyword,
          definition.type.length === 0
            ? k => addRule.call(this, k, definition)
            : k =>
                definition.type.forEach(t =>
                  addRule.call(this, k, definition, t)
                )
        )
        return this
      }
      getKeyword(keyword) {
        const rule = this.RULES.all[keyword]
        return typeof rule == 'object' ? rule.definition : !!rule
      }
      // Remove keyword
      removeKeyword(keyword) {
        // TODO return type should be Ajv
        const { RULES } = this
        delete RULES.keywords[keyword]
        delete RULES.all[keyword]
        for (const group of RULES.rules) {
          const i = group.rules.findIndex(rule => rule.keyword === keyword)
          if (i >= 0) {
            group.rules.splice(i, 1)
          }
        }
        return this
      }
      // Add format
      addFormat(name, format) {
        if (typeof format == 'string') {
          format = new RegExp(format)
        }
        this.formats[name] = format
        return this
      }
      errorsText(
        errors = this.errors,
        // optional array of validation errors
        { separator = ', ', dataVar = 'data' } = {} // optional options with properties `separator` and `dataVar`
      ) {
        if (!errors || errors.length === 0) {
          return 'No errors'
        }
        return errors
          .map(e => `${dataVar}${e.instancePath} ${e.message}`)
          .reduce((text, msg) => text + separator + msg)
      }
      $dataMetaSchema(metaSchema, keywordsJsonPointers) {
        const rules = this.RULES.all
        metaSchema = JSON.parse(JSON.stringify(metaSchema))
        for (const jsonPointer of keywordsJsonPointers) {
          const segments = jsonPointer.split('/').slice(1) // first segment is an empty string
          let keywords = metaSchema
          for (const seg of segments) {
            keywords = keywords[seg]
          }
          for (const key in rules) {
            const rule = rules[key]
            if (typeof rule != 'object') {
              continue
            }
            const { $data } = rule.definition
            const schema = keywords[key]
            if ($data && schema) {
              keywords[key] = schemaOrData(schema)
            }
          }
        }
        return metaSchema
      }
      _removeAllSchemas(schemas, regex) {
        for (const keyRef in schemas) {
          const sch = schemas[keyRef]
          if (!regex || regex.test(keyRef)) {
            if (typeof sch == 'string') {
              delete schemas[keyRef]
            } else if (sch && !sch.meta) {
              this._cache.delete(sch.schema)
              delete schemas[keyRef]
            }
          }
        }
      }
      _addSchema(
        schema,
        meta,
        baseId,
        validateSchema = this.opts.validateSchema,
        addSchema = this.opts.addUsedSchema
      ) {
        let id
        const { schemaId } = this.opts
        if (typeof schema == 'object') {
          id = schema[schemaId]
        } else {
          if (this.opts.jtd) {
            throw new Error('schema must be object')
          } else if (typeof schema != 'boolean') {
            throw new Error('schema must be object or boolean')
          }
        }
        let sch = this._cache.get(schema)
        if (sch !== undefined) {
          return sch
        }
        baseId = (0, resolve_1.normalizeId)(id || baseId)
        const localRefs = resolve_1.getSchemaRefs.call(this, schema, baseId)
        sch = new compile_1.SchemaEnv({
          schema,
          schemaId,
          meta,
          baseId,
          localRefs
        })
        this._cache.set(sch.schema, sch)
        if (addSchema && !baseId.startsWith('#')) {
          // TODO atm it is allowed to overwrite schemas without id (instead of not adding them)
          if (baseId) {
            this._checkUnique(baseId)
          }
          this.refs[baseId] = sch
        }
        if (validateSchema) {
          this.validateSchema(schema, true)
        }
        return sch
      }
      _checkUnique(id) {
        if (this.schemas[id] || this.refs[id]) {
          throw new Error(`schema with key or id "${id}" already exists`)
        }
      }
      _compileSchemaEnv(sch) {
        if (sch.meta) {
          this._compileMetaSchema(sch)
        } else {
          compile_1.compileSchema.call(this, sch)
        }
        /* istanbul ignore if */
        if (!sch.validate) {
          throw new Error('ajv implementation error')
        }
        return sch.validate
      }
      _compileMetaSchema(sch) {
        const currentOpts = this.opts
        this.opts = this._metaOpts
        try {
          compile_1.compileSchema.call(this, sch)
        } finally {
          this.opts = currentOpts
        }
      }
    }
    Ajv.ValidationError = validation_error_1.default
    Ajv.MissingRefError = ref_error_1.default
    exports.default = Ajv
    function checkOptions(checkOpts, options, msg, log = 'error') {
      for (const key in checkOpts) {
        const opt = key
        if (opt in options) {
          this.logger[log](`${msg}: option ${key}. ${checkOpts[opt]}`)
        }
      }
    }
    function getSchEnv(keyRef) {
      keyRef = (0, resolve_1.normalizeId)(keyRef) // TODO tests fail without this line
      return this.schemas[keyRef] || this.refs[keyRef]
    }
    function addInitialSchemas() {
      const optsSchemas = this.opts.schemas
      if (!optsSchemas) {
        return
      }
      if (Array.isArray(optsSchemas)) {
        this.addSchema(optsSchemas)
      } else {
        for (const key in optsSchemas) this.addSchema(optsSchemas[key], key)
      }
    }
    function addInitialFormats() {
      for (const name in this.opts.formats) {
        const format = this.opts.formats[name]
        if (format) {
          this.addFormat(name, format)
        }
      }
    }
    function addInitialKeywords(defs) {
      if (Array.isArray(defs)) {
        this.addVocabulary(defs)
        return
      }
      this.logger.warn('keywords option as map is deprecated, pass array')
      for (const keyword in defs) {
        const def = defs[keyword]
        if (!def.keyword) {
          def.keyword = keyword
        }
        this.addKeyword(def)
      }
    }
    function getMetaSchemaOptions() {
      const metaOpts = {
        ...this.opts
      }
      for (const opt of META_IGNORE_OPTIONS) {
        delete metaOpts[opt]
      }
      return metaOpts
    }
    const noLogs = {
      log() {},
      warn() {},
      error() {}
    }
    function getLogger(logger) {
      if (logger === false) {
        return noLogs
      }
      if (logger === undefined) {
        return console
      }
      if (logger.log && logger.warn && logger.error) {
        return logger
      }
      throw new Error('logger must implement log, warn and error methods')
    }
    const KEYWORD_NAME = /^[a-z_$][a-z0-9_$:-]*$/i
    function checkKeyword(keyword, def) {
      const { RULES } = this
      ;(0, util_1.eachItem)(keyword, kwd => {
        if (RULES.keywords[kwd]) {
          throw new Error(`Keyword ${kwd} is already defined`)
        }
        if (!KEYWORD_NAME.test(kwd)) {
          throw new Error(`Keyword ${kwd} has invalid name`)
        }
      })
      if (!def) {
        return
      }
      if (def.$data && !('code' in def || 'validate' in def)) {
        throw new Error('$data keyword must have "code" or "validate" function')
      }
    }
    function addRule(keyword, definition, dataType) {
      let _a
      const post =
        definition === null || definition === void 0 ? void 0 : definition.post
      if (dataType && post) {
        throw new Error('keyword with "post" flag cannot have "type"')
      }
      const { RULES } = this
      let ruleGroup = post
        ? RULES.post
        : RULES.rules.find(({ type: t }) => t === dataType)
      if (!ruleGroup) {
        ruleGroup = {
          type: dataType,
          rules: []
        }
        RULES.rules.push(ruleGroup)
      }
      RULES.keywords[keyword] = true
      if (!definition) {
        return
      }
      const rule = {
        keyword,
        definition: {
          ...definition,
          type: (0, dataType_1.getJSONTypes)(definition.type),
          schemaType: (0, dataType_1.getJSONTypes)(definition.schemaType)
        }
      }
      if (definition.before) {
        addBeforeRule.call(this, ruleGroup, rule, definition.before)
      } else {
        ruleGroup.rules.push(rule)
      }
      RULES.all[keyword] = rule
      ;(_a = definition.implements) === null || _a === void 0
        ? void 0
        : _a.forEach(kwd => this.addKeyword(kwd))
    }
    function addBeforeRule(ruleGroup, rule, before) {
      const i = ruleGroup.rules.findIndex(_rule => _rule.keyword === before)
      if (i >= 0) {
        ruleGroup.rules.splice(i, 0, rule)
      } else {
        ruleGroup.rules.push(rule)
        this.logger.warn(`rule ${before} is not defined`)
      }
    }
    function keywordMetaschema(def) {
      let { metaSchema } = def
      if (metaSchema === undefined) {
        return
      }
      if (def.$data && this.opts.$data) {
        metaSchema = schemaOrData(metaSchema)
      }
      def.validateSchema = this.compile(metaSchema, true)
    }
    const $dataRef = {
      $ref: 'https://raw.githubusercontent.com/ajv-validator/ajv/master/lib/refs/data.json#'
    }
    function schemaOrData(schema) {
      return {
        anyOf: [schema, $dataRef]
      }
    }
  })(core$3)
  return core$3
}

const draft7 = {}

const core$2 = {}

const id = {}

let hasRequiredId
function requireId() {
  if (hasRequiredId) {
    return id
  }
  hasRequiredId = 1
  Object.defineProperty(id, '__esModule', {
    value: true
  })
  const def = {
    keyword: 'id',
    code() {
      throw new Error('NOT SUPPORTED: keyword "id", use "$id" for schema ID')
    }
  }
  id.default = def
  return id
}

const ref = {}

let hasRequiredRef
function requireRef() {
  if (hasRequiredRef) {
    return ref
  }
  hasRequiredRef = 1
  Object.defineProperty(ref, '__esModule', {
    value: true
  })
  ref.callRef = ref.getValidate = void 0
  const ref_error_1 = requireRef_error()
  const code_1 = requireCode()
  const codegen_1 = requireCodegen()
  const names_1 = requireNames()
  const compile_1 = requireCompile$1()
  const util_1 = requireUtil()
  const def = {
    keyword: '$ref',
    schemaType: 'string',
    code(cxt) {
      const { gen, schema: $ref, it } = cxt
      const { baseId, schemaEnv: env, validateName, opts, self } = it
      const { root } = env
      if (($ref === '#' || $ref === '#/') && baseId === root.baseId) {
        return callRootRef()
      }
      const schOrEnv = compile_1.resolveRef.call(self, root, baseId, $ref)
      if (schOrEnv === undefined) {
        throw new ref_error_1.default(it.opts.uriResolver, baseId, $ref)
      }
      if (schOrEnv instanceof compile_1.SchemaEnv) {
        return callValidate(schOrEnv)
      }
      return inlineRefSchema(schOrEnv)
      function callRootRef() {
        if (env === root) {
          return callRef(cxt, validateName, env, env.$async)
        }
        const rootName = gen.scopeValue('root', {
          ref: root
        })
        return callRef(
          cxt,
          (0, codegen_1._)`${rootName}.validate`,
          root,
          root.$async
        )
      }
      function callValidate(sch) {
        const v = getValidate(cxt, sch)
        callRef(cxt, v, sch, sch.$async)
      }
      function inlineRefSchema(sch) {
        const schName = gen.scopeValue(
          'schema',
          opts.code.source === true
            ? {
                ref: sch,
                code: (0, codegen_1.stringify)(sch)
              }
            : {
                ref: sch
              }
        )
        const valid = gen.name('valid')
        const schCxt = cxt.subschema(
          {
            schema: sch,
            dataTypes: [],
            schemaPath: codegen_1.nil,
            topSchemaRef: schName,
            errSchemaPath: $ref
          },
          valid
        )
        cxt.mergeEvaluated(schCxt)
        cxt.ok(valid)
      }
    }
  }
  function getValidate(cxt, sch) {
    const { gen } = cxt
    return sch.validate
      ? gen.scopeValue('validate', {
          ref: sch.validate
        })
      : (0, codegen_1._)`${gen.scopeValue('wrapper', {
          ref: sch
        })}.validate`
  }
  ref.getValidate = getValidate
  function callRef(cxt, v, sch, $async) {
    const { gen, it } = cxt
    const { allErrors, schemaEnv: env, opts } = it
    const passCxt = opts.passContext ? names_1.default.this : codegen_1.nil
    if ($async) {
      callAsyncRef()
    } else {
      callSyncRef()
    }
    function callAsyncRef() {
      if (!env.$async) {
        throw new Error('async schema referenced by sync schema')
      }
      const valid = gen.let('valid')
      gen.try(
        () => {
          gen.code(
            (0,
            codegen_1._)`await ${(0, code_1.callValidateCode)(cxt, v, passCxt)}`
          )
          addEvaluatedFrom(v) // TODO will not work with async, it has to be returned with the result
          if (!allErrors) {
            gen.assign(valid, true)
          }
        },
        e => {
          gen.if(
            (0, codegen_1._)`!(${e} instanceof ${it.ValidationError})`,
            () => gen.throw(e)
          )
          addErrorsFrom(e)
          if (!allErrors) {
            gen.assign(valid, false)
          }
        }
      )
      cxt.ok(valid)
    }
    function callSyncRef() {
      cxt.result(
        (0, code_1.callValidateCode)(cxt, v, passCxt),
        () => addEvaluatedFrom(v),
        () => addErrorsFrom(v)
      )
    }
    function addErrorsFrom(source) {
      const errs = (0, codegen_1._)`${source}.errors`
      gen.assign(
        names_1.default.vErrors,
        (0,
        codegen_1._)`${names_1.default.vErrors} === null ? ${errs} : ${names_1.default.vErrors}.concat(${errs})`
      ) // TODO tagged
      gen.assign(
        names_1.default.errors,
        (0, codegen_1._)`${names_1.default.vErrors}.length`
      )
    }
    function addEvaluatedFrom(source) {
      let _a
      if (!it.opts.unevaluated) {
        return
      }
      const schEvaluated =
        (_a = sch === null || sch === void 0 ? void 0 : sch.validate) ===
          null || _a === void 0
          ? void 0
          : _a.evaluated
      // TODO refactor
      if (it.props !== true) {
        if (schEvaluated && !schEvaluated.dynamicProps) {
          if (schEvaluated.props !== undefined) {
            it.props = util_1.mergeEvaluated.props(
              gen,
              schEvaluated.props,
              it.props
            )
          }
        } else {
          const props = gen.var(
            'props',
            (0, codegen_1._)`${source}.evaluated.props`
          )
          it.props = util_1.mergeEvaluated.props(
            gen,
            props,
            it.props,
            codegen_1.Name
          )
        }
      }
      if (it.items !== true) {
        if (schEvaluated && !schEvaluated.dynamicItems) {
          if (schEvaluated.items !== undefined) {
            it.items = util_1.mergeEvaluated.items(
              gen,
              schEvaluated.items,
              it.items
            )
          }
        } else {
          const items = gen.var(
            'items',
            (0, codegen_1._)`${source}.evaluated.items`
          )
          it.items = util_1.mergeEvaluated.items(
            gen,
            items,
            it.items,
            codegen_1.Name
          )
        }
      }
    }
  }
  ref.callRef = callRef
  ref.default = def
  return ref
}

let hasRequiredCore$2
function requireCore$2() {
  if (hasRequiredCore$2) {
    return core$2
  }
  hasRequiredCore$2 = 1
  Object.defineProperty(core$2, '__esModule', {
    value: true
  })
  const id_1 = requireId()
  const ref_1 = requireRef()
  const core = [
    '$schema',
    '$id',
    '$defs',
    '$vocabulary',
    {
      keyword: '$comment'
    },
    'definitions',
    id_1.default,
    ref_1.default
  ]
  core$2.default = core
  return core$2
}

const validation = {}

const limitNumber = {}

let hasRequiredLimitNumber
function requireLimitNumber() {
  if (hasRequiredLimitNumber) {
    return limitNumber
  }
  hasRequiredLimitNumber = 1
  Object.defineProperty(limitNumber, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const ops = codegen_1.operators
  const KWDs = {
    maximum: {
      okStr: '<=',
      ok: ops.LTE,
      fail: ops.GT
    },
    minimum: {
      okStr: '>=',
      ok: ops.GTE,
      fail: ops.LT
    },
    exclusiveMaximum: {
      okStr: '<',
      ok: ops.LT,
      fail: ops.GTE
    },
    exclusiveMinimum: {
      okStr: '>',
      ok: ops.GT,
      fail: ops.LTE
    }
  }
  const error = {
    message: ({ keyword, schemaCode }) =>
      (0, codegen_1.str)`must be ${KWDs[keyword].okStr} ${schemaCode}`,
    params: ({ keyword, schemaCode }) =>
      (0,
      codegen_1._)`{comparison: ${KWDs[keyword].okStr}, limit: ${schemaCode}}`
  }
  const def = {
    keyword: Object.keys(KWDs),
    type: 'number',
    schemaType: 'number',
    $data: true,
    error,
    code(cxt) {
      const { keyword, data, schemaCode } = cxt
      cxt.fail$data(
        (0,
        codegen_1._)`${data} ${KWDs[keyword].fail} ${schemaCode} || isNaN(${data})`
      )
    }
  }
  limitNumber.default = def
  return limitNumber
}

const multipleOf = {}

let hasRequiredMultipleOf
function requireMultipleOf() {
  if (hasRequiredMultipleOf) {
    return multipleOf
  }
  hasRequiredMultipleOf = 1
  Object.defineProperty(multipleOf, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const error = {
    message: ({ schemaCode }) =>
      (0, codegen_1.str)`must be multiple of ${schemaCode}`,
    params: ({ schemaCode }) => (0, codegen_1._)`{multipleOf: ${schemaCode}}`
  }
  const def = {
    keyword: 'multipleOf',
    type: 'number',
    schemaType: 'number',
    $data: true,
    error,
    code(cxt) {
      const { gen, data, schemaCode, it } = cxt
      // const bdt = bad$DataType(schemaCode, <string>def.schemaType, $data)
      const prec = it.opts.multipleOfPrecision
      const res = gen.let('res')
      const invalid = prec
        ? (0, codegen_1._)`Math.abs(Math.round(${res}) - ${res}) > 1e-${prec}`
        : (0, codegen_1._)`${res} !== parseInt(${res})`
      cxt.fail$data(
        (0,
        codegen_1._)`(${schemaCode} === 0 || (${res} = ${data}/${schemaCode}, ${invalid}))`
      )
    }
  }
  multipleOf.default = def
  return multipleOf
}

const limitLength = {}

const ucs2length = {}

let hasRequiredUcs2length
function requireUcs2length() {
  if (hasRequiredUcs2length) {
    return ucs2length
  }
  hasRequiredUcs2length = 1
  Object.defineProperty(ucs2length, '__esModule', {
    value: true
  })
  // https://mathiasbynens.be/notes/javascript-encoding
  // https://github.com/bestiejs/punycode.js - punycode.ucs2.decode
  function ucs2length$1(str) {
    const len = str.length
    let length = 0
    let pos = 0
    let value
    while (pos < len) {
      length++
      value = str.charCodeAt(pos++)
      if (value >= 0xd800 && value <= 0xdbff && pos < len) {
        // high surrogate, and there is a next character
        value = str.charCodeAt(pos)
        if ((value & 0xfc00) === 0xdc00) {
          pos++
        } // low surrogate
      }
    }
    return length
  }
  ucs2length.default = ucs2length$1
  ucs2length$1.code = 'require("ajv/dist/runtime/ucs2length").default'
  return ucs2length
}

let hasRequiredLimitLength
function requireLimitLength() {
  if (hasRequiredLimitLength) {
    return limitLength
  }
  hasRequiredLimitLength = 1
  Object.defineProperty(limitLength, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const ucs2length_1 = requireUcs2length()
  const error = {
    message({ keyword, schemaCode }) {
      const comp = keyword === 'maxLength' ? 'more' : 'fewer'
      return (0,
      codegen_1.str)`must NOT have ${comp} than ${schemaCode} characters`
    },
    params: ({ schemaCode }) => (0, codegen_1._)`{limit: ${schemaCode}}`
  }
  const def = {
    keyword: ['maxLength', 'minLength'],
    type: 'string',
    schemaType: 'number',
    $data: true,
    error,
    code(cxt) {
      const { keyword, data, schemaCode, it } = cxt
      const op =
        keyword === 'maxLength'
          ? codegen_1.operators.GT
          : codegen_1.operators.LT
      const len =
        it.opts.unicode === false
          ? (0, codegen_1._)`${data}.length`
          : (0,
            codegen_1._)`${(0, util_1.useFunc)(cxt.gen, ucs2length_1.default)}(${data})`
      cxt.fail$data((0, codegen_1._)`${len} ${op} ${schemaCode}`)
    }
  }
  limitLength.default = def
  return limitLength
}

const pattern = {}

let hasRequiredPattern
function requirePattern() {
  if (hasRequiredPattern) {
    return pattern
  }
  hasRequiredPattern = 1
  Object.defineProperty(pattern, '__esModule', {
    value: true
  })
  const code_1 = requireCode()
  const codegen_1 = requireCodegen()
  const error = {
    message: ({ schemaCode }) =>
      (0, codegen_1.str)`must match pattern "${schemaCode}"`,
    params: ({ schemaCode }) => (0, codegen_1._)`{pattern: ${schemaCode}}`
  }
  const def = {
    keyword: 'pattern',
    type: 'string',
    schemaType: 'string',
    $data: true,
    error,
    code(cxt) {
      const { data, $data, schema, schemaCode, it } = cxt
      // TODO regexp should be wrapped in try/catchs
      const u = it.opts.unicodeRegExp ? 'u' : ''
      const regExp = $data
        ? (0, codegen_1._)`(new RegExp(${schemaCode}, ${u}))`
        : (0, code_1.usePattern)(cxt, schema)
      cxt.fail$data((0, codegen_1._)`!${regExp}.test(${data})`)
    }
  }
  pattern.default = def
  return pattern
}

const limitProperties = {}

let hasRequiredLimitProperties
function requireLimitProperties() {
  if (hasRequiredLimitProperties) {
    return limitProperties
  }
  hasRequiredLimitProperties = 1
  Object.defineProperty(limitProperties, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const error = {
    message({ keyword, schemaCode }) {
      const comp = keyword === 'maxProperties' ? 'more' : 'fewer'
      return (0,
      codegen_1.str)`must NOT have ${comp} than ${schemaCode} properties`
    },
    params: ({ schemaCode }) => (0, codegen_1._)`{limit: ${schemaCode}}`
  }
  const def = {
    keyword: ['maxProperties', 'minProperties'],
    type: 'object',
    schemaType: 'number',
    $data: true,
    error,
    code(cxt) {
      const { keyword, data, schemaCode } = cxt
      const op =
        keyword === 'maxProperties'
          ? codegen_1.operators.GT
          : codegen_1.operators.LT
      cxt.fail$data(
        (0, codegen_1._)`Object.keys(${data}).length ${op} ${schemaCode}`
      )
    }
  }
  limitProperties.default = def
  return limitProperties
}

const required = {}

let hasRequiredRequired
function requireRequired() {
  if (hasRequiredRequired) {
    return required
  }
  hasRequiredRequired = 1
  Object.defineProperty(required, '__esModule', {
    value: true
  })
  const code_1 = requireCode()
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const error = {
    message: ({ params: { missingProperty } }) =>
      (0, codegen_1.str)`must have required property '${missingProperty}'`,
    params: ({ params: { missingProperty } }) =>
      (0, codegen_1._)`{missingProperty: ${missingProperty}}`
  }
  const def = {
    keyword: 'required',
    type: 'object',
    schemaType: 'array',
    $data: true,
    error,
    code(cxt) {
      const { gen, schema, schemaCode, data, $data, it } = cxt
      const { opts } = it
      if (!$data && schema.length === 0) {
        return
      }
      const useLoop = schema.length >= opts.loopRequired
      if (it.allErrors) {
        allErrorsMode()
      } else {
        exitOnErrorMode()
      }
      if (opts.strictRequired) {
        const props = cxt.parentSchema.properties
        const { definedProperties } = cxt.it
        for (const requiredKey of schema) {
          if (
            (props === null || props === void 0
              ? void 0
              : props[requiredKey]) === undefined &&
            !definedProperties.has(requiredKey)
          ) {
            const schemaPath = it.schemaEnv.baseId + it.errSchemaPath
            const msg = `required property "${requiredKey}" is not defined at "${schemaPath}" (strictRequired)`
            ;(0, util_1.checkStrictMode)(it, msg, it.opts.strictRequired)
          }
        }
      }
      function allErrorsMode() {
        if (useLoop || $data) {
          cxt.block$data(codegen_1.nil, loopAllRequired)
        } else {
          for (const prop of schema) {
            ;(0, code_1.checkReportMissingProp)(cxt, prop)
          }
        }
      }
      function exitOnErrorMode() {
        const missing = gen.let('missing')
        if (useLoop || $data) {
          const valid = gen.let('valid', true)
          cxt.block$data(valid, () => loopUntilMissing(missing, valid))
          cxt.ok(valid)
        } else {
          gen.if((0, code_1.checkMissingProp)(cxt, schema, missing))
          ;(0, code_1.reportMissingProp)(cxt, missing)
          gen.else()
        }
      }
      function loopAllRequired() {
        gen.forOf('prop', schemaCode, prop => {
          cxt.setParams({
            missingProperty: prop
          })
          gen.if(
            (0, code_1.noPropertyInData)(gen, data, prop, opts.ownProperties),
            () => cxt.error()
          )
        })
      }
      function loopUntilMissing(missing, valid) {
        cxt.setParams({
          missingProperty: missing
        })
        gen.forOf(
          missing,
          schemaCode,
          () => {
            gen.assign(
              valid,
              (0, code_1.propertyInData)(gen, data, missing, opts.ownProperties)
            )
            gen.if((0, codegen_1.not)(valid), () => {
              cxt.error()
              gen.break()
            })
          },
          codegen_1.nil
        )
      }
    }
  }
  required.default = def
  return required
}

const limitItems = {}

let hasRequiredLimitItems
function requireLimitItems() {
  if (hasRequiredLimitItems) {
    return limitItems
  }
  hasRequiredLimitItems = 1
  Object.defineProperty(limitItems, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const error = {
    message({ keyword, schemaCode }) {
      const comp = keyword === 'maxItems' ? 'more' : 'fewer'
      return (0, codegen_1.str)`must NOT have ${comp} than ${schemaCode} items`
    },
    params: ({ schemaCode }) => (0, codegen_1._)`{limit: ${schemaCode}}`
  }
  const def = {
    keyword: ['maxItems', 'minItems'],
    type: 'array',
    schemaType: 'number',
    $data: true,
    error,
    code(cxt) {
      const { keyword, data, schemaCode } = cxt
      const op =
        keyword === 'maxItems' ? codegen_1.operators.GT : codegen_1.operators.LT
      cxt.fail$data((0, codegen_1._)`${data}.length ${op} ${schemaCode}`)
    }
  }
  limitItems.default = def
  return limitItems
}

const uniqueItems = {}

const equal = {}

let hasRequiredEqual
function requireEqual() {
  if (hasRequiredEqual) {
    return equal
  }
  hasRequiredEqual = 1
  Object.defineProperty(equal, '__esModule', {
    value: true
  })
  // https://github.com/ajv-validator/ajv/issues/889
  const equal$1 = requireFastDeepEqual()
  equal$1.code = 'require("ajv/dist/runtime/equal").default'
  equal.default = equal$1
  return equal
}

let hasRequiredUniqueItems
function requireUniqueItems() {
  if (hasRequiredUniqueItems) {
    return uniqueItems
  }
  hasRequiredUniqueItems = 1
  Object.defineProperty(uniqueItems, '__esModule', {
    value: true
  })
  const dataType_1 = requireDataType()
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const equal_1 = requireEqual()
  const error = {
    message: ({ params: { i, j } }) =>
      (0,
      codegen_1.str)`must NOT have duplicate items (items ## ${j} and ${i} are identical)`,
    params: ({ params: { i, j } }) => (0, codegen_1._)`{i: ${i}, j: ${j}}`
  }
  const def = {
    keyword: 'uniqueItems',
    type: 'array',
    schemaType: 'boolean',
    $data: true,
    error,
    code(cxt) {
      const { gen, data, $data, schema, parentSchema, schemaCode, it } = cxt
      if (!$data && !schema) {
        return
      }
      const valid = gen.let('valid')
      const itemTypes = parentSchema.items
        ? (0, dataType_1.getSchemaTypes)(parentSchema.items)
        : []
      cxt.block$data(
        valid,
        validateUniqueItems,
        (0, codegen_1._)`${schemaCode} === false`
      )
      cxt.ok(valid)
      function validateUniqueItems() {
        const i = gen.let('i', (0, codegen_1._)`${data}.length`)
        const j = gen.let('j')
        cxt.setParams({
          i,
          j
        })
        gen.assign(valid, true)
        gen.if((0, codegen_1._)`${i} > 1`, () =>
          (canOptimize() ? loopN : loopN2)(i, j)
        )
      }
      function canOptimize() {
        return (
          itemTypes.length > 0 &&
          !itemTypes.some(t => t === 'object' || t === 'array')
        )
      }
      function loopN(i, j) {
        const item = gen.name('item')
        const wrongType = (0, dataType_1.checkDataTypes)(
          itemTypes,
          item,
          it.opts.strictNumbers,
          dataType_1.DataType.Wrong
        )
        const indices = gen.const('indices', (0, codegen_1._)`{}`)
        gen.for((0, codegen_1._)`;${i}--;`, () => {
          gen.let(item, (0, codegen_1._)`${data}[${i}]`)
          gen.if(wrongType, (0, codegen_1._)`continue`)
          if (itemTypes.length > 1) {
            gen.if(
              (0, codegen_1._)`typeof ${item} == "string"`,
              (0, codegen_1._)`${item} += "_"`
            )
          }
          gen
            .if(
              (0, codegen_1._)`typeof ${indices}[${item}] == "number"`,
              () => {
                gen.assign(j, (0, codegen_1._)`${indices}[${item}]`)
                cxt.error()
                gen.assign(valid, false).break()
              }
            )
            .code((0, codegen_1._)`${indices}[${item}] = ${i}`)
        })
      }
      function loopN2(i, j) {
        const eql = (0, util_1.useFunc)(gen, equal_1.default)
        const outer = gen.name('outer')
        gen.label(outer).for((0, codegen_1._)`;${i}--;`, () =>
          gen.for((0, codegen_1._)`${j} = ${i}; ${j}--;`, () =>
            gen.if(
              (0, codegen_1._)`${eql}(${data}[${i}], ${data}[${j}])`,
              () => {
                cxt.error()
                gen.assign(valid, false).break(outer)
              }
            )
          )
        )
      }
    }
  }
  uniqueItems.default = def
  return uniqueItems
}

const _const = {}

let hasRequired_const
function require_const() {
  if (hasRequired_const) {
    return _const
  }
  hasRequired_const = 1
  Object.defineProperty(_const, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const equal_1 = requireEqual()
  const error = {
    message: 'must be equal to constant',
    params: ({ schemaCode }) => (0, codegen_1._)`{allowedValue: ${schemaCode}}`
  }
  const def = {
    keyword: 'const',
    $data: true,
    error,
    code(cxt) {
      const { gen, data, $data, schemaCode, schema } = cxt
      if ($data || (schema && typeof schema == 'object')) {
        cxt.fail$data(
          (0,
          codegen_1._)`!${(0, util_1.useFunc)(gen, equal_1.default)}(${data}, ${schemaCode})`
        )
      } else {
        cxt.fail((0, codegen_1._)`${schema} !== ${data}`)
      }
    }
  }
  _const.default = def
  return _const
}

const _enum = {}

let hasRequired_enum
function require_enum() {
  if (hasRequired_enum) {
    return _enum
  }
  hasRequired_enum = 1
  Object.defineProperty(_enum, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const equal_1 = requireEqual()
  const error = {
    message: 'must be equal to one of the allowed values',
    params: ({ schemaCode }) => (0, codegen_1._)`{allowedValues: ${schemaCode}}`
  }
  const def = {
    keyword: 'enum',
    schemaType: 'array',
    $data: true,
    error,
    code(cxt) {
      const { gen, data, $data, schema, schemaCode, it } = cxt
      if (!$data && schema.length === 0) {
        throw new Error('enum must have non-empty array')
      }
      const useLoop = schema.length >= it.opts.loopEnum
      let eql
      const getEql = () =>
        eql !== null && eql !== void 0
          ? eql
          : (eql = (0, util_1.useFunc)(gen, equal_1.default))
      let valid
      if (useLoop || $data) {
        valid = gen.let('valid')
        cxt.block$data(valid, loopEnum)
      } else {
        /* istanbul ignore if */
        if (!Array.isArray(schema)) {
          throw new Error('ajv implementation error')
        }
        const vSchema = gen.const('vSchema', schemaCode)
        valid = (0, codegen_1.or)(
          ...schema.map((_x, i) => equalCode(vSchema, i))
        )
      }
      cxt.pass(valid)
      function loopEnum() {
        gen.assign(valid, false)
        gen.forOf('v', schemaCode, v =>
          gen.if((0, codegen_1._)`${getEql()}(${data}, ${v})`, () =>
            gen.assign(valid, true).break()
          )
        )
      }
      function equalCode(vSchema, i) {
        const sch = schema[i]
        return typeof sch === 'object' && sch !== null
          ? (0, codegen_1._)`${getEql()}(${data}, ${vSchema}[${i}])`
          : (0, codegen_1._)`${data} === ${sch}`
      }
    }
  }
  _enum.default = def
  return _enum
}

let hasRequiredValidation
function requireValidation() {
  if (hasRequiredValidation) {
    return validation
  }
  hasRequiredValidation = 1
  Object.defineProperty(validation, '__esModule', {
    value: true
  })
  const limitNumber_1 = requireLimitNumber()
  const multipleOf_1 = requireMultipleOf()
  const limitLength_1 = requireLimitLength()
  const pattern_1 = requirePattern()
  const limitProperties_1 = requireLimitProperties()
  const required_1 = requireRequired()
  const limitItems_1 = requireLimitItems()
  const uniqueItems_1 = requireUniqueItems()
  const const_1 = require_const()
  const enum_1 = require_enum()
  const validation$1 = [
    // number
    limitNumber_1.default,
    multipleOf_1.default,
    // string
    limitLength_1.default,
    pattern_1.default,
    // object
    limitProperties_1.default,
    required_1.default,
    // array
    limitItems_1.default,
    uniqueItems_1.default,
    // any
    {
      keyword: 'type',
      schemaType: ['string', 'array']
    },
    {
      keyword: 'nullable',
      schemaType: 'boolean'
    },
    const_1.default,
    enum_1.default
  ]
  validation.default = validation$1
  return validation
}

const applicator = {}

const additionalItems = {}

let hasRequiredAdditionalItems
function requireAdditionalItems() {
  if (hasRequiredAdditionalItems) {
    return additionalItems
  }
  hasRequiredAdditionalItems = 1
  Object.defineProperty(additionalItems, '__esModule', {
    value: true
  })
  additionalItems.validateAdditionalItems = void 0
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const error = {
    message: ({ params: { len } }) =>
      (0, codegen_1.str)`must NOT have more than ${len} items`,
    params: ({ params: { len } }) => (0, codegen_1._)`{limit: ${len}}`
  }
  const def = {
    keyword: 'additionalItems',
    type: 'array',
    schemaType: ['boolean', 'object'],
    before: 'uniqueItems',
    error,
    code(cxt) {
      const { parentSchema, it } = cxt
      const { items } = parentSchema
      if (!Array.isArray(items)) {
        ;(0, util_1.checkStrictMode)(
          it,
          '"additionalItems" is ignored when "items" is not an array of schemas'
        )
        return
      }
      validateAdditionalItems(cxt, items)
    }
  }
  function validateAdditionalItems(cxt, items) {
    const { gen, schema, data, keyword, it } = cxt
    it.items = true
    const len = gen.const('len', (0, codegen_1._)`${data}.length`)
    if (schema === false) {
      cxt.setParams({
        len: items.length
      })
      cxt.pass((0, codegen_1._)`${len} <= ${items.length}`)
    } else if (
      typeof schema == 'object' &&
      !(0, util_1.alwaysValidSchema)(it, schema)
    ) {
      const valid = gen.var(
        'valid',
        (0, codegen_1._)`${len} <= ${items.length}`
      ) // TODO var
      gen.if((0, codegen_1.not)(valid), () => validateItems(valid))
      cxt.ok(valid)
    }
    function validateItems(valid) {
      gen.forRange('i', items.length, len, i => {
        cxt.subschema(
          {
            keyword,
            dataProp: i,
            dataPropType: util_1.Type.Num
          },
          valid
        )
        if (!it.allErrors) {
          gen.if((0, codegen_1.not)(valid), () => gen.break())
        }
      })
    }
  }
  additionalItems.validateAdditionalItems = validateAdditionalItems
  additionalItems.default = def
  return additionalItems
}

const prefixItems = {}

const items = {}

let hasRequiredItems
function requireItems() {
  if (hasRequiredItems) {
    return items
  }
  hasRequiredItems = 1
  Object.defineProperty(items, '__esModule', {
    value: true
  })
  items.validateTuple = void 0
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const code_1 = requireCode()
  const def = {
    keyword: 'items',
    type: 'array',
    schemaType: ['object', 'array', 'boolean'],
    before: 'uniqueItems',
    code(cxt) {
      const { schema, it } = cxt
      if (Array.isArray(schema)) {
        return validateTuple(cxt, 'additionalItems', schema)
      }
      it.items = true
      if ((0, util_1.alwaysValidSchema)(it, schema)) {
        return
      }
      cxt.ok((0, code_1.validateArray)(cxt))
    }
  }
  function validateTuple(cxt, extraItems, schArr = cxt.schema) {
    const { gen, parentSchema, data, keyword, it } = cxt
    checkStrictTuple(parentSchema)
    if (it.opts.unevaluated && schArr.length && it.items !== true) {
      it.items = util_1.mergeEvaluated.items(gen, schArr.length, it.items)
    }
    const valid = gen.name('valid')
    const len = gen.const('len', (0, codegen_1._)`${data}.length`)
    schArr.forEach((sch, i) => {
      if ((0, util_1.alwaysValidSchema)(it, sch)) {
        return
      }
      gen.if((0, codegen_1._)`${len} > ${i}`, () =>
        cxt.subschema(
          {
            keyword,
            schemaProp: i,
            dataProp: i
          },
          valid
        )
      )
      cxt.ok(valid)
    })
    function checkStrictTuple(sch) {
      const { opts, errSchemaPath } = it
      const l = schArr.length
      const fullTuple =
        l === sch.minItems && (l === sch.maxItems || sch[extraItems] === false)
      if (opts.strictTuples && !fullTuple) {
        const msg = `"${keyword}" is ${l}-tuple, but minItems or maxItems/${extraItems} are not specified or different at path "${errSchemaPath}"`
        ;(0, util_1.checkStrictMode)(it, msg, opts.strictTuples)
      }
    }
  }
  items.validateTuple = validateTuple
  items.default = def
  return items
}

let hasRequiredPrefixItems
function requirePrefixItems() {
  if (hasRequiredPrefixItems) {
    return prefixItems
  }
  hasRequiredPrefixItems = 1
  Object.defineProperty(prefixItems, '__esModule', {
    value: true
  })
  const items_1 = requireItems()
  const def = {
    keyword: 'prefixItems',
    type: 'array',
    schemaType: ['array'],
    before: 'uniqueItems',
    code: cxt => (0, items_1.validateTuple)(cxt, 'items')
  }
  prefixItems.default = def
  return prefixItems
}

const items2020 = {}

let hasRequiredItems2020
function requireItems2020() {
  if (hasRequiredItems2020) {
    return items2020
  }
  hasRequiredItems2020 = 1
  Object.defineProperty(items2020, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const code_1 = requireCode()
  const additionalItems_1 = requireAdditionalItems()
  const error = {
    message: ({ params: { len } }) =>
      (0, codegen_1.str)`must NOT have more than ${len} items`,
    params: ({ params: { len } }) => (0, codegen_1._)`{limit: ${len}}`
  }
  const def = {
    keyword: 'items',
    type: 'array',
    schemaType: ['object', 'boolean'],
    before: 'uniqueItems',
    error,
    code(cxt) {
      const { schema, parentSchema, it } = cxt
      const { prefixItems } = parentSchema
      it.items = true
      if ((0, util_1.alwaysValidSchema)(it, schema)) {
        return
      }
      if (prefixItems) {
        ;(0, additionalItems_1.validateAdditionalItems)(cxt, prefixItems)
      } else {
        cxt.ok((0, code_1.validateArray)(cxt))
      }
    }
  }
  items2020.default = def
  return items2020
}

const contains = {}

let hasRequiredContains
function requireContains() {
  if (hasRequiredContains) {
    return contains
  }
  hasRequiredContains = 1
  Object.defineProperty(contains, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const error = {
    message: ({ params: { min, max } }) =>
      max === undefined
        ? (0, codegen_1.str)`must contain at least ${min} valid item(s)`
        : (0,
          codegen_1.str)`must contain at least ${min} and no more than ${max} valid item(s)`,
    params: ({ params: { min, max } }) =>
      max === undefined
        ? (0, codegen_1._)`{minContains: ${min}}`
        : (0, codegen_1._)`{minContains: ${min}, maxContains: ${max}}`
  }
  const def = {
    keyword: 'contains',
    type: 'array',
    schemaType: ['object', 'boolean'],
    before: 'uniqueItems',
    trackErrors: true,
    error,
    code(cxt) {
      const { gen, schema, parentSchema, data, it } = cxt
      let min
      let max
      const { minContains, maxContains } = parentSchema
      if (it.opts.next) {
        min = minContains === undefined ? 1 : minContains
        max = maxContains
      } else {
        min = 1
      }
      const len = gen.const('len', (0, codegen_1._)`${data}.length`)
      cxt.setParams({
        min,
        max
      })
      if (max === undefined && min === 0) {
        ;(0, util_1.checkStrictMode)(
          it,
          `"minContains" == 0 without "maxContains": "contains" keyword ignored`
        )
        return
      }
      if (max !== undefined && min > max) {
        ;(0, util_1.checkStrictMode)(
          it,
          `"minContains" > "maxContains" is always invalid`
        )
        cxt.fail()
        return
      }
      if ((0, util_1.alwaysValidSchema)(it, schema)) {
        let cond = (0, codegen_1._)`${len} >= ${min}`
        if (max !== undefined) {
          cond = (0, codegen_1._)`${cond} && ${len} <= ${max}`
        }
        cxt.pass(cond)
        return
      }
      it.items = true
      const valid = gen.name('valid')
      if (max === undefined && min === 1) {
        validateItems(valid, () => gen.if(valid, () => gen.break()))
      } else if (min === 0) {
        gen.let(valid, true)
        if (max !== undefined) {
          gen.if((0, codegen_1._)`${data}.length > 0`, validateItemsWithCount)
        }
      } else {
        gen.let(valid, false)
        validateItemsWithCount()
      }
      cxt.result(valid, () => cxt.reset())
      function validateItemsWithCount() {
        const schValid = gen.name('_valid')
        const count = gen.let('count', 0)
        validateItems(schValid, () =>
          gen.if(schValid, () => checkLimits(count))
        )
      }
      function validateItems(_valid, block) {
        gen.forRange('i', 0, len, i => {
          cxt.subschema(
            {
              keyword: 'contains',
              dataProp: i,
              dataPropType: util_1.Type.Num,
              compositeRule: true
            },
            _valid
          )
          block()
        })
      }
      function checkLimits(count) {
        gen.code((0, codegen_1._)`${count}++`)
        if (max === undefined) {
          gen.if((0, codegen_1._)`${count} >= ${min}`, () =>
            gen.assign(valid, true).break()
          )
        } else {
          gen.if((0, codegen_1._)`${count} > ${max}`, () =>
            gen.assign(valid, false).break()
          )
          if (min === 1) {
            gen.assign(valid, true)
          } else {
            gen.if((0, codegen_1._)`${count} >= ${min}`, () =>
              gen.assign(valid, true)
            )
          }
        }
      }
    }
  }
  contains.default = def
  return contains
}

const dependencies$1 = {}

let hasRequiredDependencies
function requireDependencies() {
  if (hasRequiredDependencies) {
    return dependencies$1
  }
  hasRequiredDependencies = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.validateSchemaDeps =
      exports.validatePropertyDeps =
      exports.error =
        void 0
    const codegen_1 = requireCodegen()
    const util_1 = requireUtil()
    const code_1 = requireCode()
    exports.error = {
      message: ({ params: { property, depsCount, deps } }) => {
        const property_ies = depsCount === 1 ? 'property' : 'properties'
        return (0,
        codegen_1.str)`must have ${property_ies} ${deps} when property ${property} is present`
      },
      params: ({
        params: { property, depsCount, deps, missingProperty }
      }) => (0, codegen_1._)`{property: ${property},
    missingProperty: ${missingProperty},
    depsCount: ${depsCount},
    deps: ${deps}}` // TODO change to reference
    }
    const def = {
      keyword: 'dependencies',
      type: 'object',
      schemaType: 'object',
      error: exports.error,
      code(cxt) {
        const [propDeps, schDeps] = splitDependencies(cxt)
        validatePropertyDeps(cxt, propDeps)
        validateSchemaDeps(cxt, schDeps)
      }
    }
    function splitDependencies({ schema }) {
      const propertyDeps = {}
      const schemaDeps = {}
      for (const key in schema) {
        if (key === '__proto__') {
          continue
        }
        const deps = Array.isArray(schema[key]) ? propertyDeps : schemaDeps
        deps[key] = schema[key]
      }
      return [propertyDeps, schemaDeps]
    }
    function validatePropertyDeps(cxt, propertyDeps = cxt.schema) {
      const { gen, data, it } = cxt
      if (Object.keys(propertyDeps).length === 0) {
        return
      }
      const missing = gen.let('missing')
      for (const prop in propertyDeps) {
        const deps = propertyDeps[prop]
        if (deps.length === 0) {
          continue
        }
        const hasProperty = (0, code_1.propertyInData)(
          gen,
          data,
          prop,
          it.opts.ownProperties
        )
        cxt.setParams({
          property: prop,
          depsCount: deps.length,
          deps: deps.join(', ')
        })
        if (it.allErrors) {
          gen.if(hasProperty, () => {
            for (const depProp of deps) {
              ;(0, code_1.checkReportMissingProp)(cxt, depProp)
            }
          })
        } else {
          gen.if(
            (0,
            codegen_1._)`${hasProperty} && (${(0, code_1.checkMissingProp)(cxt, deps, missing)})`
          )
          ;(0, code_1.reportMissingProp)(cxt, missing)
          gen.else()
        }
      }
    }
    exports.validatePropertyDeps = validatePropertyDeps
    function validateSchemaDeps(cxt, schemaDeps = cxt.schema) {
      const { gen, data, keyword, it } = cxt
      const valid = gen.name('valid')
      for (const prop in schemaDeps) {
        if ((0, util_1.alwaysValidSchema)(it, schemaDeps[prop])) {
          continue
        }
        gen.if(
          (0, code_1.propertyInData)(gen, data, prop, it.opts.ownProperties),
          () => {
            const schCxt = cxt.subschema(
              {
                keyword,
                schemaProp: prop
              },
              valid
            )
            cxt.mergeValidEvaluated(schCxt, valid)
          },
          () => gen.var(valid, true) // TODO var
        )
        cxt.ok(valid)
      }
    }
    exports.validateSchemaDeps = validateSchemaDeps
    exports.default = def
  })(dependencies$1)
  return dependencies$1
}

const propertyNames = {}

let hasRequiredPropertyNames
function requirePropertyNames() {
  if (hasRequiredPropertyNames) {
    return propertyNames
  }
  hasRequiredPropertyNames = 1
  Object.defineProperty(propertyNames, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const error = {
    message: 'property name must be valid',
    params: ({ params }) =>
      (0, codegen_1._)`{propertyName: ${params.propertyName}}`
  }
  const def = {
    keyword: 'propertyNames',
    type: 'object',
    schemaType: ['object', 'boolean'],
    error,
    code(cxt) {
      const { gen, schema, data, it } = cxt
      if ((0, util_1.alwaysValidSchema)(it, schema)) {
        return
      }
      const valid = gen.name('valid')
      gen.forIn('key', data, key => {
        cxt.setParams({
          propertyName: key
        })
        cxt.subschema(
          {
            keyword: 'propertyNames',
            data: key,
            dataTypes: ['string'],
            propertyName: key,
            compositeRule: true
          },
          valid
        )
        gen.if((0, codegen_1.not)(valid), () => {
          cxt.error(true)
          if (!it.allErrors) {
            gen.break()
          }
        })
      })
      cxt.ok(valid)
    }
  }
  propertyNames.default = def
  return propertyNames
}

const additionalProperties = {}

let hasRequiredAdditionalProperties
function requireAdditionalProperties() {
  if (hasRequiredAdditionalProperties) {
    return additionalProperties
  }
  hasRequiredAdditionalProperties = 1
  Object.defineProperty(additionalProperties, '__esModule', {
    value: true
  })
  const code_1 = requireCode()
  const codegen_1 = requireCodegen()
  const names_1 = requireNames()
  const util_1 = requireUtil()
  const error = {
    message: 'must NOT have additional properties',
    params: ({ params }) =>
      (0, codegen_1._)`{additionalProperty: ${params.additionalProperty}}`
  }
  const def = {
    keyword: 'additionalProperties',
    type: ['object'],
    schemaType: ['boolean', 'object'],
    allowUndefined: true,
    trackErrors: true,
    error,
    code(cxt) {
      const { gen, schema, parentSchema, data, errsCount, it } = cxt
      /* istanbul ignore if */
      if (!errsCount) {
        throw new Error('ajv implementation error')
      }
      const { allErrors, opts } = it
      it.props = true
      if (
        opts.removeAdditional !== 'all' &&
        (0, util_1.alwaysValidSchema)(it, schema)
      ) {
        return
      }
      const props = (0, code_1.allSchemaProperties)(parentSchema.properties)
      const patProps = (0, code_1.allSchemaProperties)(
        parentSchema.patternProperties
      )
      checkAdditionalProperties()
      cxt.ok((0, codegen_1._)`${errsCount} === ${names_1.default.errors}`)
      function checkAdditionalProperties() {
        gen.forIn('key', data, key => {
          if (!props.length && !patProps.length) {
            additionalPropertyCode(key)
          } else {
            gen.if(isAdditional(key), () => additionalPropertyCode(key))
          }
        })
      }
      function isAdditional(key) {
        let definedProp
        if (props.length > 8) {
          // TODO maybe an option instead of hard-coded 8?
          const propsSchema = (0, util_1.schemaRefOrVal)(
            it,
            parentSchema.properties,
            'properties'
          )
          definedProp = (0, code_1.isOwnProperty)(gen, propsSchema, key)
        } else if (props.length) {
          definedProp = (0, codegen_1.or)(
            ...props.map(p => (0, codegen_1._)`${key} === ${p}`)
          )
        } else {
          definedProp = codegen_1.nil
        }
        if (patProps.length) {
          definedProp = (0, codegen_1.or)(
            definedProp,
            ...patProps.map(
              p =>
                (0, codegen_1._)`${(0, code_1.usePattern)(cxt, p)}.test(${key})`
            )
          )
        }
        return (0, codegen_1.not)(definedProp)
      }
      function deleteAdditional(key) {
        gen.code((0, codegen_1._)`delete ${data}[${key}]`)
      }
      function additionalPropertyCode(key) {
        if (
          opts.removeAdditional === 'all' ||
          (opts.removeAdditional && schema === false)
        ) {
          deleteAdditional(key)
          return
        }
        if (schema === false) {
          cxt.setParams({
            additionalProperty: key
          })
          cxt.error()
          if (!allErrors) {
            gen.break()
          }
          return
        }
        if (
          typeof schema == 'object' &&
          !(0, util_1.alwaysValidSchema)(it, schema)
        ) {
          const valid = gen.name('valid')
          if (opts.removeAdditional === 'failing') {
            applyAdditionalSchema(key, valid, false)
            gen.if((0, codegen_1.not)(valid), () => {
              cxt.reset()
              deleteAdditional(key)
            })
          } else {
            applyAdditionalSchema(key, valid)
            if (!allErrors) {
              gen.if((0, codegen_1.not)(valid), () => gen.break())
            }
          }
        }
      }
      function applyAdditionalSchema(key, valid, errors) {
        const subschema = {
          keyword: 'additionalProperties',
          dataProp: key,
          dataPropType: util_1.Type.Str
        }
        if (errors === false) {
          Object.assign(subschema, {
            compositeRule: true,
            createErrors: false,
            allErrors: false
          })
        }
        cxt.subschema(subschema, valid)
      }
    }
  }
  additionalProperties.default = def
  return additionalProperties
}

const properties$1 = {}

let hasRequiredProperties
function requireProperties() {
  if (hasRequiredProperties) {
    return properties$1
  }
  hasRequiredProperties = 1
  Object.defineProperty(properties$1, '__esModule', {
    value: true
  })
  const validate_1 = requireValidate$1()
  const code_1 = requireCode()
  const util_1 = requireUtil()
  const additionalProperties_1 = requireAdditionalProperties()
  const def = {
    keyword: 'properties',
    type: 'object',
    schemaType: 'object',
    code(cxt) {
      const { gen, schema, parentSchema, data, it } = cxt
      if (
        it.opts.removeAdditional === 'all' &&
        parentSchema.additionalProperties === undefined
      ) {
        additionalProperties_1.default.code(
          new validate_1.KeywordCxt(
            it,
            additionalProperties_1.default,
            'additionalProperties'
          )
        )
      }
      const allProps = (0, code_1.allSchemaProperties)(schema)
      for (const prop of allProps) {
        it.definedProperties.add(prop)
      }
      if (it.opts.unevaluated && allProps.length && it.props !== true) {
        it.props = util_1.mergeEvaluated.props(
          gen,
          (0, util_1.toHash)(allProps),
          it.props
        )
      }
      const properties = allProps.filter(
        p => !(0, util_1.alwaysValidSchema)(it, schema[p])
      )
      if (properties.length === 0) {
        return
      }
      const valid = gen.name('valid')
      for (const prop of properties) {
        if (hasDefault(prop)) {
          applyPropertySchema(prop)
        } else {
          gen.if(
            (0, code_1.propertyInData)(gen, data, prop, it.opts.ownProperties)
          )
          applyPropertySchema(prop)
          if (!it.allErrors) {
            gen.else().var(valid, true)
          }
          gen.endIf()
        }
        cxt.it.definedProperties.add(prop)
        cxt.ok(valid)
      }
      function hasDefault(prop) {
        return (
          it.opts.useDefaults &&
          !it.compositeRule &&
          schema[prop].default !== undefined
        )
      }
      function applyPropertySchema(prop) {
        cxt.subschema(
          {
            keyword: 'properties',
            schemaProp: prop,
            dataProp: prop
          },
          valid
        )
      }
    }
  }
  properties$1.default = def
  return properties$1
}

const patternProperties = {}

let hasRequiredPatternProperties
function requirePatternProperties() {
  if (hasRequiredPatternProperties) {
    return patternProperties
  }
  hasRequiredPatternProperties = 1
  Object.defineProperty(patternProperties, '__esModule', {
    value: true
  })
  const code_1 = requireCode()
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const util_2 = requireUtil()
  const def = {
    keyword: 'patternProperties',
    type: 'object',
    schemaType: 'object',
    code(cxt) {
      const { gen, schema, data, parentSchema, it } = cxt
      const { opts } = it
      const patterns = (0, code_1.allSchemaProperties)(schema)
      const alwaysValidPatterns = patterns.filter(p =>
        (0, util_1.alwaysValidSchema)(it, schema[p])
      )
      if (
        patterns.length === 0 ||
        (alwaysValidPatterns.length === patterns.length &&
          (!it.opts.unevaluated || it.props === true))
      ) {
        return
      }
      const checkProperties =
        opts.strictSchema &&
        !opts.allowMatchingProperties &&
        parentSchema.properties
      const valid = gen.name('valid')
      if (it.props !== true && !(it.props instanceof codegen_1.Name)) {
        it.props = (0, util_2.evaluatedPropsToName)(gen, it.props)
      }
      const { props } = it
      validatePatternProperties()
      function validatePatternProperties() {
        for (const pat of patterns) {
          if (checkProperties) {
            checkMatchingProperties(pat)
          }
          if (it.allErrors) {
            validateProperties(pat)
          } else {
            gen.var(valid, true) // TODO var
            validateProperties(pat)
            gen.if(valid)
          }
        }
      }
      function checkMatchingProperties(pat) {
        for (const prop in checkProperties) {
          if (new RegExp(pat).test(prop)) {
            ;(0, util_1.checkStrictMode)(
              it,
              `property ${prop} matches pattern ${pat} (use allowMatchingProperties)`
            )
          }
        }
      }
      function validateProperties(pat) {
        gen.forIn('key', data, key => {
          gen.if(
            (0, codegen_1._)`${(0, code_1.usePattern)(cxt, pat)}.test(${key})`,
            () => {
              const alwaysValid = alwaysValidPatterns.includes(pat)
              if (!alwaysValid) {
                cxt.subschema(
                  {
                    keyword: 'patternProperties',
                    schemaProp: pat,
                    dataProp: key,
                    dataPropType: util_2.Type.Str
                  },
                  valid
                )
              }
              if (it.opts.unevaluated && props !== true) {
                gen.assign((0, codegen_1._)`${props}[${key}]`, true)
              } else if (!alwaysValid && !it.allErrors) {
                // can short-circuit if `unevaluatedProperties` is not supported (opts.next === false)
                // or if all properties were evaluated (props === true)
                gen.if((0, codegen_1.not)(valid), () => gen.break())
              }
            }
          )
        })
      }
    }
  }
  patternProperties.default = def
  return patternProperties
}

const not = {}

let hasRequiredNot
function requireNot() {
  if (hasRequiredNot) {
    return not
  }
  hasRequiredNot = 1
  Object.defineProperty(not, '__esModule', {
    value: true
  })
  const util_1 = requireUtil()
  const def = {
    keyword: 'not',
    schemaType: ['object', 'boolean'],
    trackErrors: true,
    code(cxt) {
      const { gen, schema, it } = cxt
      if ((0, util_1.alwaysValidSchema)(it, schema)) {
        cxt.fail()
        return
      }
      const valid = gen.name('valid')
      cxt.subschema(
        {
          keyword: 'not',
          compositeRule: true,
          createErrors: false,
          allErrors: false
        },
        valid
      )
      cxt.failResult(
        valid,
        () => cxt.reset(),
        () => cxt.error()
      )
    },
    error: {
      message: 'must NOT be valid'
    }
  }
  not.default = def
  return not
}

const anyOf = {}

let hasRequiredAnyOf
function requireAnyOf() {
  if (hasRequiredAnyOf) {
    return anyOf
  }
  hasRequiredAnyOf = 1
  Object.defineProperty(anyOf, '__esModule', {
    value: true
  })
  const code_1 = requireCode()
  const def = {
    keyword: 'anyOf',
    schemaType: 'array',
    trackErrors: true,
    code: code_1.validateUnion,
    error: {
      message: 'must match a schema in anyOf'
    }
  }
  anyOf.default = def
  return anyOf
}

const oneOf = {}

let hasRequiredOneOf
function requireOneOf() {
  if (hasRequiredOneOf) {
    return oneOf
  }
  hasRequiredOneOf = 1
  Object.defineProperty(oneOf, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const error = {
    message: 'must match exactly one schema in oneOf',
    params: ({ params }) =>
      (0, codegen_1._)`{passingSchemas: ${params.passing}}`
  }
  const def = {
    keyword: 'oneOf',
    schemaType: 'array',
    trackErrors: true,
    error,
    code(cxt) {
      const { gen, schema, parentSchema, it } = cxt
      /* istanbul ignore if */
      if (!Array.isArray(schema)) {
        throw new Error('ajv implementation error')
      }
      if (it.opts.discriminator && parentSchema.discriminator) {
        return
      }
      const schArr = schema
      const valid = gen.let('valid', false)
      const passing = gen.let('passing', null)
      const schValid = gen.name('_valid')
      cxt.setParams({
        passing
      })
      // TODO possibly fail straight away (with warning or exception) if there are two empty always valid schemas
      gen.block(validateOneOf)
      cxt.result(
        valid,
        () => cxt.reset(),
        () => cxt.error(true)
      )
      function validateOneOf() {
        schArr.forEach((sch, i) => {
          let schCxt
          if ((0, util_1.alwaysValidSchema)(it, sch)) {
            gen.var(schValid, true)
          } else {
            schCxt = cxt.subschema(
              {
                keyword: 'oneOf',
                schemaProp: i,
                compositeRule: true
              },
              schValid
            )
          }
          if (i > 0) {
            gen
              .if((0, codegen_1._)`${schValid} && ${valid}`)
              .assign(valid, false)
              .assign(passing, (0, codegen_1._)`[${passing}, ${i}]`)
              .else()
          }
          gen.if(schValid, () => {
            gen.assign(valid, true)
            gen.assign(passing, i)
            if (schCxt) {
              cxt.mergeEvaluated(schCxt, codegen_1.Name)
            }
          })
        })
      }
    }
  }
  oneOf.default = def
  return oneOf
}

const allOf = {}

let hasRequiredAllOf
function requireAllOf() {
  if (hasRequiredAllOf) {
    return allOf
  }
  hasRequiredAllOf = 1
  Object.defineProperty(allOf, '__esModule', {
    value: true
  })
  const util_1 = requireUtil()
  const def = {
    keyword: 'allOf',
    schemaType: 'array',
    code(cxt) {
      const { gen, schema, it } = cxt
      /* istanbul ignore if */
      if (!Array.isArray(schema)) {
        throw new Error('ajv implementation error')
      }
      const valid = gen.name('valid')
      schema.forEach((sch, i) => {
        if ((0, util_1.alwaysValidSchema)(it, sch)) {
          return
        }
        const schCxt = cxt.subschema(
          {
            keyword: 'allOf',
            schemaProp: i
          },
          valid
        )
        cxt.ok(valid)
        cxt.mergeEvaluated(schCxt)
      })
    }
  }
  allOf.default = def
  return allOf
}

const _if = {}

let hasRequired_if
function require_if() {
  if (hasRequired_if) {
    return _if
  }
  hasRequired_if = 1
  Object.defineProperty(_if, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const util_1 = requireUtil()
  const error = {
    message: ({ params }) =>
      (0, codegen_1.str)`must match "${params.ifClause}" schema`,
    params: ({ params }) =>
      (0, codegen_1._)`{failingKeyword: ${params.ifClause}}`
  }
  const def = {
    keyword: 'if',
    schemaType: ['object', 'boolean'],
    trackErrors: true,
    error,
    code(cxt) {
      const { gen, parentSchema, it } = cxt
      if (parentSchema.then === undefined && parentSchema.else === undefined) {
        ;(0, util_1.checkStrictMode)(
          it,
          '"if" without "then" and "else" is ignored'
        )
      }
      const hasThen = hasSchema(it, 'then')
      const hasElse = hasSchema(it, 'else')
      if (!hasThen && !hasElse) {
        return
      }
      const valid = gen.let('valid', true)
      const schValid = gen.name('_valid')
      validateIf()
      cxt.reset()
      if (hasThen && hasElse) {
        const ifClause = gen.let('ifClause')
        cxt.setParams({
          ifClause
        })
        gen.if(
          schValid,
          validateClause('then', ifClause),
          validateClause('else', ifClause)
        )
      } else if (hasThen) {
        gen.if(schValid, validateClause('then'))
      } else {
        gen.if((0, codegen_1.not)(schValid), validateClause('else'))
      }
      cxt.pass(valid, () => cxt.error(true))
      function validateIf() {
        const schCxt = cxt.subschema(
          {
            keyword: 'if',
            compositeRule: true,
            createErrors: false,
            allErrors: false
          },
          schValid
        )
        cxt.mergeEvaluated(schCxt)
      }
      function validateClause(keyword, ifClause) {
        return () => {
          const schCxt = cxt.subschema(
            {
              keyword
            },
            schValid
          )
          gen.assign(valid, schValid)
          cxt.mergeValidEvaluated(schCxt, valid)
          if (ifClause) {
            gen.assign(ifClause, (0, codegen_1._)`${keyword}`)
          } else {
            cxt.setParams({
              ifClause: keyword
            })
          }
        }
      }
    }
  }
  function hasSchema(it, keyword) {
    const schema = it.schema[keyword]
    return schema !== undefined && !(0, util_1.alwaysValidSchema)(it, schema)
  }
  _if.default = def
  return _if
}

const thenElse = {}

let hasRequiredThenElse
function requireThenElse() {
  if (hasRequiredThenElse) {
    return thenElse
  }
  hasRequiredThenElse = 1
  Object.defineProperty(thenElse, '__esModule', {
    value: true
  })
  const util_1 = requireUtil()
  const def = {
    keyword: ['then', 'else'],
    schemaType: ['object', 'boolean'],
    code({ keyword, parentSchema, it }) {
      if (parentSchema.if === undefined) {
        ;(0, util_1.checkStrictMode)(it, `"${keyword}" without "if" is ignored`)
      }
    }
  }
  thenElse.default = def
  return thenElse
}

let hasRequiredApplicator
function requireApplicator() {
  if (hasRequiredApplicator) {
    return applicator
  }
  hasRequiredApplicator = 1
  Object.defineProperty(applicator, '__esModule', {
    value: true
  })
  const additionalItems_1 = requireAdditionalItems()
  const prefixItems_1 = requirePrefixItems()
  const items_1 = requireItems()
  const items2020_1 = requireItems2020()
  const contains_1 = requireContains()
  const dependencies_1 = requireDependencies()
  const propertyNames_1 = requirePropertyNames()
  const additionalProperties_1 = requireAdditionalProperties()
  const properties_1 = requireProperties()
  const patternProperties_1 = requirePatternProperties()
  const not_1 = requireNot()
  const anyOf_1 = requireAnyOf()
  const oneOf_1 = requireOneOf()
  const allOf_1 = requireAllOf()
  const if_1 = require_if()
  const thenElse_1 = requireThenElse()
  function getApplicator(draft2020 = false) {
    const applicator = [
      // any
      not_1.default,
      anyOf_1.default,
      oneOf_1.default,
      allOf_1.default,
      if_1.default,
      thenElse_1.default,
      // object
      propertyNames_1.default,
      additionalProperties_1.default,
      dependencies_1.default,
      properties_1.default,
      patternProperties_1.default
    ]
    // array
    if (draft2020) {
      applicator.push(prefixItems_1.default, items2020_1.default)
    } else {
      applicator.push(additionalItems_1.default, items_1.default)
    }
    applicator.push(contains_1.default)
    return applicator
  }
  applicator.default = getApplicator
  return applicator
}

const format$1 = {}

const format = {}

let hasRequiredFormat$2
function requireFormat$2() {
  if (hasRequiredFormat$2) {
    return format
  }
  hasRequiredFormat$2 = 1
  Object.defineProperty(format, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const error = {
    message: ({ schemaCode }) =>
      (0, codegen_1.str)`must match format "${schemaCode}"`,
    params: ({ schemaCode }) => (0, codegen_1._)`{format: ${schemaCode}}`
  }
  const def = {
    keyword: 'format',
    type: ['number', 'string'],
    schemaType: 'string',
    $data: true,
    error,
    code(cxt, ruleType) {
      const { gen, data, $data, schema, schemaCode, it } = cxt
      const { opts, errSchemaPath, schemaEnv, self } = it
      if (!opts.validateFormats) {
        return
      }
      if ($data) {
        validate$DataFormat()
      } else {
        validateFormat()
      }
      function validate$DataFormat() {
        const fmts = gen.scopeValue('formats', {
          ref: self.formats,
          code: opts.code.formats
        })
        const fDef = gen.const('fDef', (0, codegen_1._)`${fmts}[${schemaCode}]`)
        const fType = gen.let('fType')
        const format = gen.let('format')
        // TODO simplify
        gen.if(
          (0,
          codegen_1._)`typeof ${fDef} == "object" && !(${fDef} instanceof RegExp)`,
          () =>
            gen
              .assign(fType, (0, codegen_1._)`${fDef}.type || "string"`)
              .assign(format, (0, codegen_1._)`${fDef}.validate`),
          () =>
            gen.assign(fType, (0, codegen_1._)`"string"`).assign(format, fDef)
        )
        cxt.fail$data((0, codegen_1.or)(unknownFmt(), invalidFmt()))
        function unknownFmt() {
          if (opts.strictSchema === false) {
            return codegen_1.nil
          }
          return (0, codegen_1._)`${schemaCode} && !${format}`
        }
        function invalidFmt() {
          const callFormat = schemaEnv.$async
            ? (0,
              codegen_1._)`(${fDef}.async ? await ${format}(${data}) : ${format}(${data}))`
            : (0, codegen_1._)`${format}(${data})`
          const validData = (0,
          codegen_1._)`(typeof ${format} == "function" ? ${callFormat} : ${format}.test(${data}))`
          return (0,
          codegen_1._)`${format} && ${format} !== true && ${fType} === ${ruleType} && !${validData}`
        }
      }
      function validateFormat() {
        const formatDef = self.formats[schema]
        if (!formatDef) {
          unknownFormat()
          return
        }
        if (formatDef === true) {
          return
        }
        const [fmtType, format, fmtRef] = getFormat(formatDef)
        if (fmtType === ruleType) {
          cxt.pass(validCondition())
        }
        function unknownFormat() {
          if (opts.strictSchema === false) {
            self.logger.warn(unknownMsg())
            return
          }
          throw new Error(unknownMsg())
          function unknownMsg() {
            return `unknown format "${schema}" ignored in schema at path "${errSchemaPath}"`
          }
        }
        function getFormat(fmtDef) {
          const code =
            fmtDef instanceof RegExp
              ? (0, codegen_1.regexpCode)(fmtDef)
              : opts.code.formats
                ? (0,
                  codegen_1._)`${opts.code.formats}${(0, codegen_1.getProperty)(schema)}`
                : undefined
          const fmt = gen.scopeValue('formats', {
            key: schema,
            ref: fmtDef,
            code
          })
          if (typeof fmtDef == 'object' && !(fmtDef instanceof RegExp)) {
            return [
              fmtDef.type || 'string',
              fmtDef.validate,
              (0, codegen_1._)`${fmt}.validate`
            ]
          }
          return ['string', fmtDef, fmt]
        }
        function validCondition() {
          if (
            typeof formatDef == 'object' &&
            !(formatDef instanceof RegExp) &&
            formatDef.async
          ) {
            if (!schemaEnv.$async) {
              throw new Error('async format in sync schema')
            }
            return (0, codegen_1._)`await ${fmtRef}(${data})`
          }
          return typeof format == 'function'
            ? (0, codegen_1._)`${fmtRef}(${data})`
            : (0, codegen_1._)`${fmtRef}.test(${data})`
        }
      }
    }
  }
  format.default = def
  return format
}

let hasRequiredFormat$1
function requireFormat$1() {
  if (hasRequiredFormat$1) {
    return format$1
  }
  hasRequiredFormat$1 = 1
  Object.defineProperty(format$1, '__esModule', {
    value: true
  })
  const format_1 = requireFormat$2()
  const format = [format_1.default]
  format$1.default = format
  return format$1
}

const metadata = {}

let hasRequiredMetadata
function requireMetadata() {
  if (hasRequiredMetadata) {
    return metadata
  }
  hasRequiredMetadata = 1
  Object.defineProperty(metadata, '__esModule', {
    value: true
  })
  metadata.contentVocabulary = metadata.metadataVocabulary = void 0
  metadata.metadataVocabulary = [
    'title',
    'description',
    'default',
    'deprecated',
    'readOnly',
    'writeOnly',
    'examples'
  ]
  metadata.contentVocabulary = [
    'contentMediaType',
    'contentEncoding',
    'contentSchema'
  ]
  return metadata
}

let hasRequiredDraft7
function requireDraft7() {
  if (hasRequiredDraft7) {
    return draft7
  }
  hasRequiredDraft7 = 1
  Object.defineProperty(draft7, '__esModule', {
    value: true
  })
  const core_1 = requireCore$2()
  const validation_1 = requireValidation()
  const applicator_1 = requireApplicator()
  const format_1 = requireFormat$1()
  const metadata_1 = requireMetadata()
  const draft7Vocabularies = [
    core_1.default,
    validation_1.default,
    (0, applicator_1.default)(),
    format_1.default,
    metadata_1.metadataVocabulary,
    metadata_1.contentVocabulary
  ]
  draft7.default = draft7Vocabularies
  return draft7
}

const discriminator = {}

const types$1 = {}

let hasRequiredTypes$1
function requireTypes$1() {
  if (hasRequiredTypes$1) {
    return types$1
  }
  hasRequiredTypes$1 = 1
  Object.defineProperty(types$1, '__esModule', {
    value: true
  })
  types$1.DiscrError = void 0
  let DiscrError
  ;(function (DiscrError) {
    DiscrError['Tag'] = 'tag'
    DiscrError['Mapping'] = 'mapping'
  })(DiscrError || (types$1.DiscrError = DiscrError = {}))
  return types$1
}

let hasRequiredDiscriminator
function requireDiscriminator() {
  if (hasRequiredDiscriminator) {
    return discriminator
  }
  hasRequiredDiscriminator = 1
  Object.defineProperty(discriminator, '__esModule', {
    value: true
  })
  const codegen_1 = requireCodegen()
  const types_1 = requireTypes$1()
  const compile_1 = requireCompile$1()
  const ref_error_1 = requireRef_error()
  const util_1 = requireUtil()
  const error = {
    message: ({ params: { discrError, tagName } }) =>
      discrError === types_1.DiscrError.Tag
        ? `tag "${tagName}" must be string`
        : `value of tag "${tagName}" must be in oneOf`,
    params: ({ params: { discrError, tag, tagName } }) =>
      (0,
      codegen_1._)`{error: ${discrError}, tag: ${tagName}, tagValue: ${tag}}`
  }
  const def = {
    keyword: 'discriminator',
    type: 'object',
    schemaType: 'object',
    error,
    code(cxt) {
      const { gen, data, schema, parentSchema, it } = cxt
      const { oneOf } = parentSchema
      if (!it.opts.discriminator) {
        throw new Error('discriminator: requires discriminator option')
      }
      const tagName = schema.propertyName
      if (typeof tagName != 'string') {
        throw new Error('discriminator: requires propertyName')
      }
      if (schema.mapping) {
        throw new Error('discriminator: mapping is not supported')
      }
      if (!oneOf) {
        throw new Error('discriminator: requires oneOf keyword')
      }
      const valid = gen.let('valid', false)
      const tag = gen.const(
        'tag',
        (0, codegen_1._)`${data}${(0, codegen_1.getProperty)(tagName)}`
      )
      gen.if(
        (0, codegen_1._)`typeof ${tag} == "string"`,
        () => validateMapping(),
        () =>
          cxt.error(false, {
            discrError: types_1.DiscrError.Tag,
            tag,
            tagName
          })
      )
      cxt.ok(valid)
      function validateMapping() {
        const mapping = getMapping()
        gen.if(false)
        for (const tagValue in mapping) {
          gen.elseIf((0, codegen_1._)`${tag} === ${tagValue}`)
          gen.assign(valid, applyTagSchema(mapping[tagValue]))
        }
        gen.else()
        cxt.error(false, {
          discrError: types_1.DiscrError.Mapping,
          tag,
          tagName
        })
        gen.endIf()
      }
      function applyTagSchema(schemaProp) {
        const _valid = gen.name('valid')
        const schCxt = cxt.subschema(
          {
            keyword: 'oneOf',
            schemaProp
          },
          _valid
        )
        cxt.mergeEvaluated(schCxt, codegen_1.Name)
        return _valid
      }
      function getMapping() {
        let _a
        const oneOfMapping = {}
        const topRequired = hasRequired(parentSchema)
        let tagRequired = true
        for (let i = 0; i < oneOf.length; i++) {
          let sch = oneOf[i]
          if (
            (sch === null || sch === void 0 ? void 0 : sch.$ref) &&
            !(0, util_1.schemaHasRulesButRef)(sch, it.self.RULES)
          ) {
            const ref = sch.$ref
            sch = compile_1.resolveRef.call(
              it.self,
              it.schemaEnv.root,
              it.baseId,
              ref
            )
            if (sch instanceof compile_1.SchemaEnv) {
              sch = sch.schema
            }
            if (sch === undefined) {
              throw new ref_error_1.default(it.opts.uriResolver, it.baseId, ref)
            }
          }
          const propSch =
            (_a = sch === null || sch === void 0 ? void 0 : sch.properties) ===
              null || _a === void 0
              ? void 0
              : _a[tagName]
          if (typeof propSch != 'object') {
            throw new Error(
              `discriminator: oneOf subschemas (or referenced schemas) must have "properties/${tagName}"`
            )
          }
          tagRequired = tagRequired && (topRequired || hasRequired(sch))
          addMappings(propSch, i)
        }
        if (!tagRequired) {
          throw new Error(`discriminator: "${tagName}" must be required`)
        }
        return oneOfMapping
        function hasRequired({ required }) {
          return Array.isArray(required) && required.includes(tagName)
        }
        function addMappings(sch, i) {
          if (sch.const) {
            addMapping(sch.const, i)
          } else if (sch.enum) {
            for (const tagValue of sch.enum) {
              addMapping(tagValue, i)
            }
          } else {
            throw new Error(
              `discriminator: "properties/${tagName}" must have "const" or "enum"`
            )
          }
        }
        function addMapping(tagValue, i) {
          if (typeof tagValue != 'string' || tagValue in oneOfMapping) {
            throw new Error(
              `discriminator: "${tagName}" values must be unique strings`
            )
          }
          oneOfMapping[tagValue] = i
        }
      }
    }
  }
  discriminator.default = def
  return discriminator
}

const $schema = 'http://json-schema.org/draft-07/schema#'
const $id = 'http://json-schema.org/draft-07/schema#'
const title = 'Core schema meta-schema'
const definitions = {
  schemaArray: {
    type: 'array',
    minItems: 1,
    items: {
      $ref: '#'
    }
  },
  nonNegativeInteger: {
    type: 'integer',
    minimum: 0
  },
  nonNegativeIntegerDefault0: {
    allOf: [
      {
        $ref: '#/definitions/nonNegativeInteger'
      },
      {
        default: 0
      }
    ]
  },
  simpleTypes: {
    enum: ['array', 'boolean', 'integer', 'null', 'number', 'object', 'string']
  },
  stringArray: {
    type: 'array',
    items: {
      type: 'string'
    },
    uniqueItems: true,
    default: []
  }
}
const type$2 = ['object', 'boolean']
const properties = {
  $id: {
    type: 'string',
    format: 'uri-reference'
  },
  $schema: {
    type: 'string',
    format: 'uri'
  },
  $ref: {
    type: 'string',
    format: 'uri-reference'
  },
  $comment: {
    type: 'string'
  },
  title: {
    type: 'string'
  },
  description: {
    type: 'string'
  },
  default: true,
  readOnly: {
    type: 'boolean',
    default: false
  },
  examples: {
    type: 'array',
    items: true
  },
  multipleOf: {
    type: 'number',
    exclusiveMinimum: 0
  },
  maximum: {
    type: 'number'
  },
  exclusiveMaximum: {
    type: 'number'
  },
  minimum: {
    type: 'number'
  },
  exclusiveMinimum: {
    type: 'number'
  },
  maxLength: {
    $ref: '#/definitions/nonNegativeInteger'
  },
  minLength: {
    $ref: '#/definitions/nonNegativeIntegerDefault0'
  },
  pattern: {
    type: 'string',
    format: 'regex'
  },
  additionalItems: {
    $ref: '#'
  },
  items: {
    anyOf: [
      {
        $ref: '#'
      },
      {
        $ref: '#/definitions/schemaArray'
      }
    ],
    default: true
  },
  maxItems: {
    $ref: '#/definitions/nonNegativeInteger'
  },
  minItems: {
    $ref: '#/definitions/nonNegativeIntegerDefault0'
  },
  uniqueItems: {
    type: 'boolean',
    default: false
  },
  contains: {
    $ref: '#'
  },
  maxProperties: {
    $ref: '#/definitions/nonNegativeInteger'
  },
  minProperties: {
    $ref: '#/definitions/nonNegativeIntegerDefault0'
  },
  required: {
    $ref: '#/definitions/stringArray'
  },
  additionalProperties: {
    $ref: '#'
  },
  definitions: {
    type: 'object',
    additionalProperties: {
      $ref: '#'
    },
    default: {}
  },
  properties: {
    type: 'object',
    additionalProperties: {
      $ref: '#'
    },
    default: {}
  },
  patternProperties: {
    type: 'object',
    additionalProperties: {
      $ref: '#'
    },
    propertyNames: {
      format: 'regex'
    },
    default: {}
  },
  dependencies: {
    type: 'object',
    additionalProperties: {
      anyOf: [
        {
          $ref: '#'
        },
        {
          $ref: '#/definitions/stringArray'
        }
      ]
    }
  },
  propertyNames: {
    $ref: '#'
  },
  const: true,
  enum: {
    type: 'array',
    items: true,
    minItems: 1,
    uniqueItems: true
  },
  type: {
    anyOf: [
      {
        $ref: '#/definitions/simpleTypes'
      },
      {
        type: 'array',
        items: {
          $ref: '#/definitions/simpleTypes'
        },
        minItems: 1,
        uniqueItems: true
      }
    ]
  },
  format: {
    type: 'string'
  },
  contentMediaType: {
    type: 'string'
  },
  contentEncoding: {
    type: 'string'
  },
  if: {
    $ref: '#'
  },
  then: {
    $ref: '#'
  },
  else: {
    $ref: '#'
  },
  allOf: {
    $ref: '#/definitions/schemaArray'
  },
  anyOf: {
    $ref: '#/definitions/schemaArray'
  },
  oneOf: {
    $ref: '#/definitions/schemaArray'
  },
  not: {
    $ref: '#'
  }
}
const require$$3$1 = {
  $schema: $schema,
  $id: $id,
  title: title,
  definitions: definitions,
  type: type$2,
  properties: properties,
  default: true
}

let hasRequiredAjv
function requireAjv() {
  if (hasRequiredAjv) {
    return ajv.exports
  }
  hasRequiredAjv = 1
  ;(function (module, exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.MissingRefError =
      exports.ValidationError =
      exports.CodeGen =
      exports.Name =
      exports.nil =
      exports.stringify =
      exports.str =
      exports._ =
      exports.KeywordCxt =
      exports.Ajv =
        void 0
    const core_1 = requireCore$3()
    const draft7_1 = requireDraft7()
    const discriminator_1 = requireDiscriminator()
    const draft7MetaSchema = require$$3$1
    const META_SUPPORT_DATA = ['/properties']
    const META_SCHEMA_ID = 'http://json-schema.org/draft-07/schema'
    class Ajv extends core_1.default {
      _addVocabularies() {
        super._addVocabularies()
        draft7_1.default.forEach(v => this.addVocabulary(v))
        if (this.opts.discriminator) {
          this.addKeyword(discriminator_1.default)
        }
      }
      _addDefaultMetaSchema() {
        super._addDefaultMetaSchema()
        if (!this.opts.meta) {
          return
        }
        const metaSchema = this.opts.$data
          ? this.$dataMetaSchema(draft7MetaSchema, META_SUPPORT_DATA)
          : draft7MetaSchema
        this.addMetaSchema(metaSchema, META_SCHEMA_ID, false)
        this.refs['http://json-schema.org/schema'] = META_SCHEMA_ID
      }
      defaultMeta() {
        return (this.opts.defaultMeta =
          super.defaultMeta() ||
          (this.getSchema(META_SCHEMA_ID) ? META_SCHEMA_ID : undefined))
      }
    }
    exports.Ajv = Ajv
    module.exports = exports = Ajv
    module.exports.Ajv = Ajv
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.default = Ajv
    const validate_1 = requireValidate$1()
    Object.defineProperty(exports, 'KeywordCxt', {
      enumerable: true,
      get: function () {
        return validate_1.KeywordCxt
      }
    })
    const codegen_1 = requireCodegen()
    Object.defineProperty(exports, '_', {
      enumerable: true,
      get: function () {
        return codegen_1._
      }
    })
    Object.defineProperty(exports, 'str', {
      enumerable: true,
      get: function () {
        return codegen_1.str
      }
    })
    Object.defineProperty(exports, 'stringify', {
      enumerable: true,
      get: function () {
        return codegen_1.stringify
      }
    })
    Object.defineProperty(exports, 'nil', {
      enumerable: true,
      get: function () {
        return codegen_1.nil
      }
    })
    Object.defineProperty(exports, 'Name', {
      enumerable: true,
      get: function () {
        return codegen_1.Name
      }
    })
    Object.defineProperty(exports, 'CodeGen', {
      enumerable: true,
      get: function () {
        return codegen_1.CodeGen
      }
    })
    const validation_error_1 = requireValidation_error()
    Object.defineProperty(exports, 'ValidationError', {
      enumerable: true,
      get: function () {
        return validation_error_1.default
      }
    })
    const ref_error_1 = requireRef_error()
    Object.defineProperty(exports, 'MissingRefError', {
      enumerable: true,
      get: function () {
        return ref_error_1.default
      }
    })
  })(ajv, ajv.exports)
  return ajv.exports
}

const require$$0$2 = /*@__PURE__*/ getAugmentedNamespace(errorWithCause)

const require$$1$4 = /*@__PURE__*/ getAugmentedNamespace(helpers$1)

let ponyCause
let hasRequiredPonyCause
function requirePonyCause() {
  if (hasRequiredPonyCause) {
    return ponyCause
  }
  hasRequiredPonyCause = 1
  const { ErrorWithCause } = require$$0$2 // linemod-replace-with: export { ErrorWithCause } from './lib/error-with-cause.mjs';

  const {
    // linemod-replace-with: export {
    findCauseByReference,
    getErrorCause,
    messageWithCauses,
    stackWithCauses
  } = require$$1$4 // linemod-replace-with: } from './lib/helpers.mjs';

  ponyCause = {
    // linemod-remove
    ErrorWithCause,
    // linemod-remove
    findCauseByReference,
    // linemod-remove
    getErrorCause,
    // linemod-remove
    stackWithCauses,
    // linemod-remove
    messageWithCauses // linemod-remove
  } // linemod-remove
  return ponyCause
}

const dist$4 = {}

const composer = {}

const directives = {}

const identity = {}

let hasRequiredIdentity
function requireIdentity() {
  if (hasRequiredIdentity) {
    return identity
  }
  hasRequiredIdentity = 1
  const ALIAS = Symbol.for('yaml.alias')
  const DOC = Symbol.for('yaml.document')
  const MAP = Symbol.for('yaml.map')
  const PAIR = Symbol.for('yaml.pair')
  const SCALAR = Symbol.for('yaml.scalar')
  const SEQ = Symbol.for('yaml.seq')
  const NODE_TYPE = Symbol.for('yaml.node.type')
  const isAlias = node =>
    !!node && typeof node === 'object' && node[NODE_TYPE] === ALIAS
  const isDocument = node =>
    !!node && typeof node === 'object' && node[NODE_TYPE] === DOC
  const isMap = node =>
    !!node && typeof node === 'object' && node[NODE_TYPE] === MAP
  const isPair = node =>
    !!node && typeof node === 'object' && node[NODE_TYPE] === PAIR
  const isScalar = node =>
    !!node && typeof node === 'object' && node[NODE_TYPE] === SCALAR
  const isSeq = node =>
    !!node && typeof node === 'object' && node[NODE_TYPE] === SEQ
  function isCollection(node) {
    if (node && typeof node === 'object') {
      switch (node[NODE_TYPE]) {
        case MAP:
        case SEQ:
          return true
      }
    }
    return false
  }
  function isNode(node) {
    if (node && typeof node === 'object') {
      switch (node[NODE_TYPE]) {
        case ALIAS:
        case MAP:
        case SCALAR:
        case SEQ:
          return true
      }
    }
    return false
  }
  const hasAnchor = node =>
    (isScalar(node) || isCollection(node)) && !!node.anchor
  identity.ALIAS = ALIAS
  identity.DOC = DOC
  identity.MAP = MAP
  identity.NODE_TYPE = NODE_TYPE
  identity.PAIR = PAIR
  identity.SCALAR = SCALAR
  identity.SEQ = SEQ
  identity.hasAnchor = hasAnchor
  identity.isAlias = isAlias
  identity.isCollection = isCollection
  identity.isDocument = isDocument
  identity.isMap = isMap
  identity.isNode = isNode
  identity.isPair = isPair
  identity.isScalar = isScalar
  identity.isSeq = isSeq
  return identity
}

const visit = {}

let hasRequiredVisit
function requireVisit() {
  if (hasRequiredVisit) {
    return visit
  }
  hasRequiredVisit = 1
  const identity = requireIdentity()
  const BREAK = Symbol('break visit')
  const SKIP = Symbol('skip children')
  const REMOVE = Symbol('remove node')
  /**
   * Apply a visitor to an AST node or document.
   *
   * Walks through the tree (depth-first) starting from `node`, calling a
   * `visitor` function with three arguments:
   *   - `key`: For sequence values and map `Pair`, the node's index in the
   *     collection. Within a `Pair`, `'key'` or `'value'`, correspondingly.
   *     `null` for the root node.
   *   - `node`: The current node.
   *   - `path`: The ancestry of the current node.
   *
   * The return value of the visitor may be used to control the traversal:
   *   - `undefined` (default): Do nothing and continue
   *   - `visit.SKIP`: Do not visit the children of this node, continue with next
   *     sibling
   *   - `visit.BREAK`: Terminate traversal completely
   *   - `visit.REMOVE`: Remove the current node, then continue with the next one
   *   - `Node`: Replace the current node, then continue by visiting it
   *   - `number`: While iterating the items of a sequence or map, set the index
   *     of the next step. This is useful especially if the index of the current
   *     node has changed.
   *
   * If `visitor` is a single function, it will be called with all values
   * encountered in the tree, including e.g. `null` values. Alternatively,
   * separate visitor functions may be defined for each `Map`, `Pair`, `Seq`,
   * `Alias` and `Scalar` node. To define the same visitor function for more than
   * one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar)
   * and `Node` (alias, map, seq & scalar) targets. Of all these, only the most
   * specific defined one will be used for each node.
   */
  function visit$1(node, visitor) {
    const visitor_ = initVisitor(visitor)
    if (identity.isDocument(node)) {
      const cd = visit_(null, node.contents, visitor_, Object.freeze([node]))
      if (cd === REMOVE) {
        node.contents = null
      }
    } else {
      visit_(null, node, visitor_, Object.freeze([]))
    }
  }
  // Without the `as symbol` casts, TS declares these in the `visit`
  // namespace using `var`, but then complains about that because
  // `unique symbol` must be `const`.
  /** Terminate visit traversal completely */
  visit$1.BREAK = BREAK
  /** Do not visit the children of the current node */
  visit$1.SKIP = SKIP
  /** Remove the current node */
  visit$1.REMOVE = REMOVE
  function visit_(key, node, visitor, path) {
    const ctrl = callVisitor(key, node, visitor, path)
    if (identity.isNode(ctrl) || identity.isPair(ctrl)) {
      replaceNode(key, path, ctrl)
      return visit_(key, ctrl, visitor, path)
    }
    if (typeof ctrl !== 'symbol') {
      if (identity.isCollection(node)) {
        path = Object.freeze(path.concat(node))
        for (let i = 0; i < node.items.length; ++i) {
          const ci = visit_(i, node.items[i], visitor, path)
          if (typeof ci === 'number') {
            i = ci - 1
          } else if (ci === BREAK) {
            return BREAK
          } else if (ci === REMOVE) {
            node.items.splice(i, 1)
            i -= 1
          }
        }
      } else if (identity.isPair(node)) {
        path = Object.freeze(path.concat(node))
        const ck = visit_('key', node.key, visitor, path)
        if (ck === BREAK) {
          return BREAK
        } else if (ck === REMOVE) {
          node.key = null
        }
        const cv = visit_('value', node.value, visitor, path)
        if (cv === BREAK) {
          return BREAK
        } else if (cv === REMOVE) {
          node.value = null
        }
      }
    }
    return ctrl
  }
  /**
   * Apply an async visitor to an AST node or document.
   *
   * Walks through the tree (depth-first) starting from `node`, calling a
   * `visitor` function with three arguments:
   *   - `key`: For sequence values and map `Pair`, the node's index in the
   *     collection. Within a `Pair`, `'key'` or `'value'`, correspondingly.
   *     `null` for the root node.
   *   - `node`: The current node.
   *   - `path`: The ancestry of the current node.
   *
   * The return value of the visitor may be used to control the traversal:
   *   - `Promise`: Must resolve to one of the following values
   *   - `undefined` (default): Do nothing and continue
   *   - `visit.SKIP`: Do not visit the children of this node, continue with next
   *     sibling
   *   - `visit.BREAK`: Terminate traversal completely
   *   - `visit.REMOVE`: Remove the current node, then continue with the next one
   *   - `Node`: Replace the current node, then continue by visiting it
   *   - `number`: While iterating the items of a sequence or map, set the index
   *     of the next step. This is useful especially if the index of the current
   *     node has changed.
   *
   * If `visitor` is a single function, it will be called with all values
   * encountered in the tree, including e.g. `null` values. Alternatively,
   * separate visitor functions may be defined for each `Map`, `Pair`, `Seq`,
   * `Alias` and `Scalar` node. To define the same visitor function for more than
   * one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar)
   * and `Node` (alias, map, seq & scalar) targets. Of all these, only the most
   * specific defined one will be used for each node.
   */
  async function visitAsync(node, visitor) {
    const visitor_ = initVisitor(visitor)
    if (identity.isDocument(node)) {
      const cd = await visitAsync_(
        null,
        node.contents,
        visitor_,
        Object.freeze([node])
      )
      if (cd === REMOVE) {
        node.contents = null
      }
    } else {
      await visitAsync_(null, node, visitor_, Object.freeze([]))
    }
  }
  // Without the `as symbol` casts, TS declares these in the `visit`
  // namespace using `var`, but then complains about that because
  // `unique symbol` must be `const`.
  /** Terminate visit traversal completely */
  visitAsync.BREAK = BREAK
  /** Do not visit the children of the current node */
  visitAsync.SKIP = SKIP
  /** Remove the current node */
  visitAsync.REMOVE = REMOVE
  async function visitAsync_(key, node, visitor, path) {
    const ctrl = await callVisitor(key, node, visitor, path)
    if (identity.isNode(ctrl) || identity.isPair(ctrl)) {
      replaceNode(key, path, ctrl)
      return visitAsync_(key, ctrl, visitor, path)
    }
    if (typeof ctrl !== 'symbol') {
      if (identity.isCollection(node)) {
        path = Object.freeze(path.concat(node))
        for (let i = 0; i < node.items.length; ++i) {
          const ci = await visitAsync_(i, node.items[i], visitor, path)
          if (typeof ci === 'number') {
            i = ci - 1
          } else if (ci === BREAK) {
            return BREAK
          } else if (ci === REMOVE) {
            node.items.splice(i, 1)
            i -= 1
          }
        }
      } else if (identity.isPair(node)) {
        path = Object.freeze(path.concat(node))
        const ck = await visitAsync_('key', node.key, visitor, path)
        if (ck === BREAK) {
          return BREAK
        } else if (ck === REMOVE) {
          node.key = null
        }
        const cv = await visitAsync_('value', node.value, visitor, path)
        if (cv === BREAK) {
          return BREAK
        } else if (cv === REMOVE) {
          node.value = null
        }
      }
    }
    return ctrl
  }
  function initVisitor(visitor) {
    if (
      typeof visitor === 'object' &&
      (visitor.Collection || visitor.Node || visitor.Value)
    ) {
      return Object.assign(
        {
          Alias: visitor.Node,
          Map: visitor.Node,
          Scalar: visitor.Node,
          Seq: visitor.Node
        },
        visitor.Value && {
          Map: visitor.Value,
          Scalar: visitor.Value,
          Seq: visitor.Value
        },
        visitor.Collection && {
          Map: visitor.Collection,
          Seq: visitor.Collection
        },
        visitor
      )
    }
    return visitor
  }
  function callVisitor(key, node, visitor, path) {
    if (typeof visitor === 'function') {
      return visitor(key, node, path)
    }
    if (identity.isMap(node)) {
      return visitor.Map?.(key, node, path)
    }
    if (identity.isSeq(node)) {
      return visitor.Seq?.(key, node, path)
    }
    if (identity.isPair(node)) {
      return visitor.Pair?.(key, node, path)
    }
    if (identity.isScalar(node)) {
      return visitor.Scalar?.(key, node, path)
    }
    if (identity.isAlias(node)) {
      return visitor.Alias?.(key, node, path)
    }
    return undefined
  }
  function replaceNode(key, path, node) {
    const parent = path[path.length - 1]
    if (identity.isCollection(parent)) {
      parent.items[key] = node
    } else if (identity.isPair(parent)) {
      if (key === 'key') {
        parent.key = node
      } else {
        parent.value = node
      }
    } else if (identity.isDocument(parent)) {
      parent.contents = node
    } else {
      const pt = identity.isAlias(parent) ? 'alias' : 'scalar'
      throw new Error(`Cannot replace node with ${pt} parent`)
    }
  }
  visit.visit = visit$1
  visit.visitAsync = visitAsync
  return visit
}

let hasRequiredDirectives
function requireDirectives() {
  if (hasRequiredDirectives) {
    return directives
  }
  hasRequiredDirectives = 1
  const identity = requireIdentity()
  const visit = requireVisit()
  const escapeChars = {
    '!': '%21',
    ',': '%2C',
    '[': '%5B',
    ']': '%5D',
    '{': '%7B',
    '}': '%7D'
  }
  const escapeTagName = tn => tn.replace(/[!,[\]{}]/g, ch => escapeChars[ch])
  class Directives {
    constructor(yaml, tags) {
      /**
       * The directives-end/doc-start marker `---`. If `null`, a marker may still be
       * included in the document's stringified representation.
       */
      this.docStart = null
      /** The doc-end marker `...`.  */
      this.docEnd = false
      this.yaml = Object.assign({}, Directives.defaultYaml, yaml)
      this.tags = Object.assign({}, Directives.defaultTags, tags)
    }
    clone() {
      const copy = new Directives(this.yaml, this.tags)
      copy.docStart = this.docStart
      return copy
    }
    /**
     * During parsing, get a Directives instance for the current document and
     * update the stream state according to the current version's spec.
     */
    atDocument() {
      const res = new Directives(this.yaml, this.tags)
      switch (this.yaml.version) {
        case '1.1':
          this.atNextDocument = true
          break
        case '1.2':
          this.atNextDocument = false
          this.yaml = {
            explicit: Directives.defaultYaml.explicit,
            version: '1.2'
          }
          this.tags = Object.assign({}, Directives.defaultTags)
          break
      }
      return res
    }
    /**
     * @param onError - May be called even if the action was successful
     * @returns `true` on success
     */
    add(line, onError) {
      if (this.atNextDocument) {
        this.yaml = {
          explicit: Directives.defaultYaml.explicit,
          version: '1.1'
        }
        this.tags = Object.assign({}, Directives.defaultTags)
        this.atNextDocument = false
      }
      const parts = line.trim().split(/[ \t]+/)
      const name = parts.shift()
      switch (name) {
        case '%TAG': {
          if (parts.length !== 2) {
            onError(0, '%TAG directive should contain exactly two parts')
            if (parts.length < 2) {
              return false
            }
          }
          const [handle, prefix] = parts
          this.tags[handle] = prefix
          return true
        }
        case '%YAML': {
          this.yaml.explicit = true
          if (parts.length !== 1) {
            onError(0, '%YAML directive should contain exactly one part')
            return false
          }
          const [version] = parts
          if (version === '1.1' || version === '1.2') {
            this.yaml.version = version
            return true
          } else {
            const isValid = /^\d+\.\d+$/.test(version)
            onError(6, `Unsupported YAML version ${version}`, isValid)
            return false
          }
        }
        default:
          onError(0, `Unknown directive ${name}`, true)
          return false
      }
    }
    /**
     * Resolves a tag, matching handles to those defined in %TAG directives.
     *
     * @returns Resolved tag, which may also be the non-specific tag `'!'` or a
     *   `'!local'` tag, or `null` if unresolvable.
     */
    tagName(source, onError) {
      if (source === '!') {
        return '!'
      } // non-specific tag
      if (source[0] !== '!') {
        onError(`Not a valid tag: ${source}`)
        return null
      }
      if (source[1] === '<') {
        const verbatim = source.slice(2, -1)
        if (verbatim === '!' || verbatim === '!!') {
          onError(`Verbatim tags aren't resolved, so ${source} is invalid.`)
          return null
        }
        if (source[source.length - 1] !== '>') {
          onError('Verbatim tags must end with a >')
        }
        return verbatim
      }
      const [, handle, suffix] = source.match(/^(.*!)([^!]*)$/s)
      if (!suffix) {
        onError(`The ${source} tag has no suffix`)
      }
      const prefix = this.tags[handle]
      if (prefix) {
        try {
          return prefix + decodeURIComponent(suffix)
        } catch (error) {
          onError(String(error))
          return null
        }
      }
      if (handle === '!') {
        return source
      } // local tag
      onError(`Could not resolve tag: ${source}`)
      return null
    }
    /**
     * Given a fully resolved tag, returns its printable string form,
     * taking into account current tag prefixes and defaults.
     */
    tagString(tag) {
      for (const [handle, prefix] of Object.entries(this.tags)) {
        if (tag.startsWith(prefix)) {
          return handle + escapeTagName(tag.substring(prefix.length))
        }
      }
      return tag[0] === '!' ? tag : `!<${tag}>`
    }
    toString(doc) {
      const lines = this.yaml.explicit
        ? [`%YAML ${this.yaml.version || '1.2'}`]
        : []
      const tagEntries = Object.entries(this.tags)
      let tagNames
      if (doc && tagEntries.length > 0 && identity.isNode(doc.contents)) {
        const tags = {}
        visit.visit(doc.contents, (_key, node) => {
          if (identity.isNode(node) && node.tag) {
            tags[node.tag] = true
          }
        })
        tagNames = Object.keys(tags)
      } else {
        tagNames = []
      }
      for (const [handle, prefix] of tagEntries) {
        if (handle === '!!' && prefix === 'tag:yaml.org,2002:') {
          continue
        }
        if (!doc || tagNames.some(tn => tn.startsWith(prefix))) {
          lines.push(`%TAG ${handle} ${prefix}`)
        }
      }
      return lines.join('\n')
    }
  }
  Directives.defaultYaml = {
    explicit: false,
    version: '1.2'
  }
  Directives.defaultTags = {
    '!!': 'tag:yaml.org,2002:'
  }
  directives.Directives = Directives
  return directives
}

const Document = {}

const Alias = {}

const anchors = {}

let hasRequiredAnchors
function requireAnchors() {
  if (hasRequiredAnchors) {
    return anchors
  }
  hasRequiredAnchors = 1
  const identity = requireIdentity()
  const visit = requireVisit()

  /**
   * Verify that the input string is a valid anchor.
   *
   * Will throw on errors.
   */
  function anchorIsValid(anchor) {
    if (/[\x00-\x19\s,[\]{}]/.test(anchor)) {
      const sa = JSON.stringify(anchor)
      const msg = `Anchor must not contain whitespace or control characters: ${sa}`
      throw new Error(msg)
    }
    return true
  }
  function anchorNames(root) {
    const anchors = new Set()
    visit.visit(root, {
      Value(_key, node) {
        if (node.anchor) {
          anchors.add(node.anchor)
        }
      }
    })
    return anchors
  }
  /** Find a new anchor name with the given `prefix` and a one-indexed suffix. */
  function findNewAnchor(prefix, exclude) {
    for (let i = 1; true; ++i) {
      const name = `${prefix}${i}`
      if (!exclude.has(name)) {
        return name
      }
    }
  }
  function createNodeAnchors(doc, prefix) {
    const aliasObjects = []
    const sourceObjects = new Map()
    let prevAnchors = null
    return {
      onAnchor: source => {
        aliasObjects.push(source)
        if (!prevAnchors) {
          prevAnchors = anchorNames(doc)
        }
        const anchor = findNewAnchor(prefix, prevAnchors)
        prevAnchors.add(anchor)
        return anchor
      },
      /**
       * With circular references, the source node is only resolved after all
       * of its child nodes are. This is why anchors are set only after all of
       * the nodes have been created.
       */
      setAnchors: () => {
        for (const source of aliasObjects) {
          const ref = sourceObjects.get(source)
          if (
            typeof ref === 'object' &&
            ref.anchor &&
            (identity.isScalar(ref.node) || identity.isCollection(ref.node))
          ) {
            ref.node.anchor = ref.anchor
          } else {
            const error = new Error(
              'Failed to resolve repeated object (this should not happen)'
            )
            error.source = source
            throw error
          }
        }
      },
      sourceObjects
    }
  }
  anchors.anchorIsValid = anchorIsValid
  anchors.anchorNames = anchorNames
  anchors.createNodeAnchors = createNodeAnchors
  anchors.findNewAnchor = findNewAnchor
  return anchors
}

const Node = {}

const applyReviver = {}

let hasRequiredApplyReviver
function requireApplyReviver() {
  if (hasRequiredApplyReviver) {
    return applyReviver
  }
  hasRequiredApplyReviver = 1

  /**
   * Applies the JSON.parse reviver algorithm as defined in the ECMA-262 spec,
   * in section 24.5.1.1 "Runtime Semantics: InternalizeJSONProperty" of the
   * 2021 edition: https://tc39.es/ecma262/#sec-json.parse
   *
   * Includes extensions for handling Map and Set objects.
   */
  function applyReviver$1(reviver, obj, key, val) {
    if (val && typeof val === 'object') {
      if (Array.isArray(val)) {
        for (let i = 0, len = val.length; i < len; ++i) {
          const v0 = val[i]
          const v1 = applyReviver$1(reviver, val, String(i), v0)
          // eslint-disable-next-line @typescript-eslint/no-array-delete
          if (v1 === undefined) {
            delete val[i]
          } else if (v1 !== v0) {
            val[i] = v1
          }
        }
      } else if (val instanceof Map) {
        for (const k of Array.from(val.keys())) {
          const v0 = val.get(k)
          const v1 = applyReviver$1(reviver, val, k, v0)
          if (v1 === undefined) {
            val.delete(k)
          } else if (v1 !== v0) {
            val.set(k, v1)
          }
        }
      } else if (val instanceof Set) {
        for (const v0 of Array.from(val)) {
          const v1 = applyReviver$1(reviver, val, v0, v0)
          if (v1 === undefined) {
            val.delete(v0)
          } else if (v1 !== v0) {
            val.delete(v0)
            val.add(v1)
          }
        }
      } else {
        for (const [k, v0] of Object.entries(val)) {
          const v1 = applyReviver$1(reviver, val, k, v0)
          if (v1 === undefined) {
            delete val[k]
          } else if (v1 !== v0) {
            val[k] = v1
          }
        }
      }
    }
    return reviver.call(obj, key, val)
  }
  applyReviver.applyReviver = applyReviver$1
  return applyReviver
}

const toJS = {}

let hasRequiredToJS
function requireToJS() {
  if (hasRequiredToJS) {
    return toJS
  }
  hasRequiredToJS = 1
  const identity = requireIdentity()

  /**
   * Recursively convert any node or its contents to native JavaScript
   *
   * @param value - The input value
   * @param arg - If `value` defines a `toJSON()` method, use this
   *   as its first argument
   * @param ctx - Conversion context, originally set in Document#toJS(). If
   *   `{ keep: true }` is not set, output should be suitable for JSON
   *   stringification.
   */
  function toJS$1(value, arg, ctx) {
    // eslint-disable-next-line @typescript-eslint/no-unsafe-return
    if (Array.isArray(value)) {
      return value.map((v, i) => toJS$1(v, String(i), ctx))
    }
    if (value && typeof value.toJSON === 'function') {
      // eslint-disable-next-line @typescript-eslint/no-unsafe-call
      if (!ctx || !identity.hasAnchor(value)) {
        return value.toJSON(arg, ctx)
      }
      const data = {
        aliasCount: 0,
        count: 1,
        res: undefined
      }
      ctx.anchors.set(value, data)
      ctx.onCreate = res => {
        data.res = res
        delete ctx.onCreate
      }
      const res = value.toJSON(arg, ctx)
      if (ctx.onCreate) {
        ctx.onCreate(res)
      }
      return res
    }
    if (typeof value === 'bigint' && !ctx?.keep) {
      return Number(value)
    }
    return value
  }
  toJS.toJS = toJS$1
  return toJS
}

let hasRequiredNode$2
function requireNode$2() {
  if (hasRequiredNode$2) {
    return Node
  }
  hasRequiredNode$2 = 1
  const applyReviver = requireApplyReviver()
  const identity = requireIdentity()
  const toJS = requireToJS()
  class NodeBase {
    constructor(type) {
      Object.defineProperty(this, identity.NODE_TYPE, {
        value: type
      })
    }
    /** Create a copy of this node.  */
    clone() {
      const copy = Object.create(
        Object.getPrototypeOf(this),
        Object.getOwnPropertyDescriptors(this)
      )
      if (this.range) {
        copy.range = this.range.slice()
      }
      return copy
    }
    /** A plain JavaScript representation of this node. */
    toJS(doc, { mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {
      if (!identity.isDocument(doc)) {
        throw new TypeError('A document argument is required')
      }
      const ctx = {
        anchors: new Map(),
        doc,
        keep: true,
        mapAsMap: mapAsMap === true,
        mapKeyWarned: false,
        maxAliasCount: typeof maxAliasCount === 'number' ? maxAliasCount : 100
      }
      const res = toJS.toJS(this, '', ctx)
      if (typeof onAnchor === 'function') {
        for (const { count, res } of ctx.anchors.values()) onAnchor(res, count)
      }
      return typeof reviver === 'function'
        ? applyReviver.applyReviver(
            reviver,
            {
              '': res
            },
            '',
            res
          )
        : res
    }
  }
  Node.NodeBase = NodeBase
  return Node
}

let hasRequiredAlias
function requireAlias() {
  if (hasRequiredAlias) {
    return Alias
  }
  hasRequiredAlias = 1
  const anchors = requireAnchors()
  const visit = requireVisit()
  const identity = requireIdentity()
  const Node = requireNode$2()
  const toJS = requireToJS()
  let Alias$1 = class Alias extends Node.NodeBase {
    constructor(source) {
      super(identity.ALIAS)
      this.source = source
      Object.defineProperty(this, 'tag', {
        set() {
          throw new Error('Alias nodes cannot have tags')
        }
      })
    }
    /**
     * Resolve the value of this alias within `doc`, finding the last
     * instance of the `source` anchor before this node.
     */
    resolve(doc) {
      let found = undefined
      visit.visit(doc, {
        Node: (_key, node) => {
          if (node === this) {
            return visit.visit.BREAK
          }
          if (node.anchor === this.source) {
            found = node
          }
        }
      })
      return found
    }
    toJSON(_arg, ctx) {
      if (!ctx) {
        return {
          source: this.source
        }
      }
      const { anchors, doc, maxAliasCount } = ctx
      const source = this.resolve(doc)
      if (!source) {
        const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`
        throw new ReferenceError(msg)
      }
      let data = anchors.get(source)
      if (!data) {
        // Resolve anchors for Node.prototype.toJS()
        toJS.toJS(source, null, ctx)
        data = anchors.get(source)
      }
      /* istanbul ignore if */
      if (!data || data.res === undefined) {
        const msg = 'This should not happen: Alias anchor was not resolved?'
        throw new ReferenceError(msg)
      }
      if (maxAliasCount >= 0) {
        data.count += 1
        if (data.aliasCount === 0) {
          data.aliasCount = getAliasCount(doc, source, anchors)
        }
        if (data.count * data.aliasCount > maxAliasCount) {
          const msg =
            'Excessive alias count indicates a resource exhaustion attack'
          throw new ReferenceError(msg)
        }
      }
      return data.res
    }
    toString(ctx, _onComment, _onChompKeep) {
      const src = `*${this.source}`
      if (ctx) {
        anchors.anchorIsValid(this.source)
        if (ctx.options.verifyAliasOrder && !ctx.anchors.has(this.source)) {
          const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`
          throw new Error(msg)
        }
        if (ctx.implicitKey) {
          return `${src} `
        }
      }
      return src
    }
  }
  function getAliasCount(doc, node, anchors) {
    if (identity.isAlias(node)) {
      const source = node.resolve(doc)
      const anchor = anchors && source && anchors.get(source)
      return anchor ? anchor.count * anchor.aliasCount : 0
    } else if (identity.isCollection(node)) {
      let count = 0
      for (const item of node.items) {
        const c = getAliasCount(doc, item, anchors)
        if (c > count) {
          count = c
        }
      }
      return count
    } else if (identity.isPair(node)) {
      const kc = getAliasCount(doc, node.key, anchors)
      const vc = getAliasCount(doc, node.value, anchors)
      return Math.max(kc, vc)
    }
    return 1
  }
  Alias.Alias = Alias$1
  return Alias
}

const Collection$1 = {}

const createNode = {}

const Scalar = {}

let hasRequiredScalar
function requireScalar() {
  if (hasRequiredScalar) {
    return Scalar
  }
  hasRequiredScalar = 1
  const identity = requireIdentity()
  const Node = requireNode$2()
  const toJS = requireToJS()
  const isScalarValue = value =>
    !value || (typeof value !== 'function' && typeof value !== 'object')
  let Scalar$1 = class Scalar extends Node.NodeBase {
    constructor(value) {
      super(identity.SCALAR)
      this.value = value
    }
    toJSON(arg, ctx) {
      return ctx?.keep ? this.value : toJS.toJS(this.value, arg, ctx)
    }
    toString() {
      return String(this.value)
    }
  }
  Scalar$1.BLOCK_FOLDED = 'BLOCK_FOLDED'
  Scalar$1.BLOCK_LITERAL = 'BLOCK_LITERAL'
  Scalar$1.PLAIN = 'PLAIN'
  Scalar$1.QUOTE_DOUBLE = 'QUOTE_DOUBLE'
  Scalar$1.QUOTE_SINGLE = 'QUOTE_SINGLE'
  Scalar.Scalar = Scalar$1
  Scalar.isScalarValue = isScalarValue
  return Scalar
}

let hasRequiredCreateNode
function requireCreateNode() {
  if (hasRequiredCreateNode) {
    return createNode
  }
  hasRequiredCreateNode = 1
  const Alias = requireAlias()
  const identity = requireIdentity()
  const Scalar = requireScalar()
  const defaultTagPrefix = 'tag:yaml.org,2002:'
  function findTagObject(value, tagName, tags) {
    if (tagName) {
      const match = tags.filter(t => t.tag === tagName)
      const tagObj = match.find(t => !t.format) ?? match[0]
      if (!tagObj) {
        throw new Error(`Tag ${tagName} not found`)
      }
      return tagObj
    }
    return tags.find(t => t.identify?.(value) && !t.format)
  }
  function createNode$1(value, tagName, ctx) {
    if (identity.isDocument(value)) {
      value = value.contents
    }
    if (identity.isNode(value)) {
      return value
    }
    if (identity.isPair(value)) {
      const map = ctx.schema[identity.MAP].createNode?.(ctx.schema, null, ctx)
      map.items.push(value)
      return map
    }
    if (
      value instanceof String ||
      value instanceof Number ||
      value instanceof Boolean ||
      (typeof BigInt !== 'undefined' && value instanceof BigInt) // not supported everywhere
    ) {
      // https://tc39.es/ecma262/#sec-serializejsonproperty
      value = value.valueOf()
    }
    const { aliasDuplicateObjects, onAnchor, onTagObj, schema, sourceObjects } =
      ctx
    // Detect duplicate references to the same object & use Alias nodes for all
    // after first. The `ref` wrapper allows for circular references to resolve.
    let ref = undefined
    if (aliasDuplicateObjects && value && typeof value === 'object') {
      ref = sourceObjects.get(value)
      if (ref) {
        if (!ref.anchor) {
          ref.anchor = onAnchor(value)
        }
        return new Alias.Alias(ref.anchor)
      } else {
        ref = {
          anchor: null,
          node: null
        }
        sourceObjects.set(value, ref)
      }
    }
    if (tagName?.startsWith('!!')) {
      tagName = defaultTagPrefix + tagName.slice(2)
    }
    let tagObj = findTagObject(value, tagName, schema.tags)
    if (!tagObj) {
      if (value && typeof value.toJSON === 'function') {
        // eslint-disable-next-line @typescript-eslint/no-unsafe-call
        value = value.toJSON()
      }
      if (!value || typeof value !== 'object') {
        const node = new Scalar.Scalar(value)
        if (ref) {
          ref.node = node
        }
        return node
      }
      tagObj =
        value instanceof Map
          ? schema[identity.MAP]
          : Symbol.iterator in Object(value)
            ? schema[identity.SEQ]
            : schema[identity.MAP]
    }
    if (onTagObj) {
      onTagObj(tagObj)
      delete ctx.onTagObj
    }
    const node = tagObj?.createNode
      ? tagObj.createNode(ctx.schema, value, ctx)
      : typeof tagObj?.nodeClass?.from === 'function'
        ? tagObj.nodeClass.from(ctx.schema, value, ctx)
        : new Scalar.Scalar(value)
    if (tagName) {
      node.tag = tagName
    } else if (!tagObj.default) {
      node.tag = tagObj.tag
    }
    if (ref) {
      ref.node = node
    }
    return node
  }
  createNode.createNode = createNode$1
  return createNode
}

let hasRequiredCollection
function requireCollection() {
  if (hasRequiredCollection) {
    return Collection$1
  }
  hasRequiredCollection = 1
  const createNode = requireCreateNode()
  const identity = requireIdentity()
  const Node = requireNode$2()
  function collectionFromPath(schema, path, value) {
    let v = value
    for (let i = path.length - 1; i >= 0; --i) {
      const k = path[i]
      if (typeof k === 'number' && Number.isInteger(k) && k >= 0) {
        const a = []
        a[k] = v
        v = a
      } else {
        v = new Map([[k, v]])
      }
    }
    return createNode.createNode(v, undefined, {
      aliasDuplicateObjects: false,
      keepUndefined: false,
      onAnchor: () => {
        throw new Error('This should not happen, please report a bug.')
      },
      schema,
      sourceObjects: new Map()
    })
  }
  // Type guard is intentionally a little wrong so as to be more useful,
  // as it does not cover untypable empty non-string iterables (e.g. []).
  const isEmptyPath = path =>
    path == null ||
    (typeof path === 'object' && !!path[Symbol.iterator]().next().done)
  class Collection extends Node.NodeBase {
    constructor(type, schema) {
      super(type)
      Object.defineProperty(this, 'schema', {
        value: schema,
        configurable: true,
        enumerable: false,
        writable: true
      })
    }
    /**
     * Create a copy of this collection.
     *
     * @param schema - If defined, overwrites the original's schema
     */
    clone(schema) {
      const copy = Object.create(
        Object.getPrototypeOf(this),
        Object.getOwnPropertyDescriptors(this)
      )
      if (schema) {
        copy.schema = schema
      }
      copy.items = copy.items.map(it =>
        identity.isNode(it) || identity.isPair(it) ? it.clone(schema) : it
      )
      if (this.range) {
        copy.range = this.range.slice()
      }
      return copy
    }
    /**
     * Adds a value to the collection. For `!!map` and `!!omap` the value must
     * be a Pair instance or a `{ key, value }` object, which may not have a key
     * that already exists in the map.
     */
    addIn(path, value) {
      if (isEmptyPath(path)) {
        this.add(value)
      } else {
        const [key, ...rest] = path
        const node = this.get(key, true)
        if (identity.isCollection(node)) {
          node.addIn(rest, value)
        } else if (node === undefined && this.schema) {
          this.set(key, collectionFromPath(this.schema, rest, value))
        } else {
          throw new Error(
            `Expected YAML collection at ${key}. Remaining path: ${rest}`
          )
        }
      }
    }
    /**
     * Removes a value from the collection.
     * @returns `true` if the item was found and removed.
     */
    deleteIn(path) {
      const [key, ...rest] = path
      if (rest.length === 0) {
        return this.delete(key)
      }
      const node = this.get(key, true)
      if (identity.isCollection(node)) {
        return node.deleteIn(rest)
      } else {
        throw new Error(
          `Expected YAML collection at ${key}. Remaining path: ${rest}`
        )
      }
    }
    /**
     * Returns item at `key`, or `undefined` if not found. By default unwraps
     * scalar values from their surrounding node; to disable set `keepScalar` to
     * `true` (collections are always returned intact).
     */
    getIn(path, keepScalar) {
      const [key, ...rest] = path
      const node = this.get(key, true)
      if (rest.length === 0) {
        return !keepScalar && identity.isScalar(node) ? node.value : node
      } else {
        return identity.isCollection(node)
          ? node.getIn(rest, keepScalar)
          : undefined
      }
    }
    hasAllNullValues(allowScalar) {
      return this.items.every(node => {
        if (!identity.isPair(node)) {
          return false
        }
        const n = node.value
        return (
          n == null ||
          (allowScalar &&
            identity.isScalar(n) &&
            n.value == null &&
            !n.commentBefore &&
            !n.comment &&
            !n.tag)
        )
      })
    }
    /**
     * Checks if the collection includes a value with the key `key`.
     */
    hasIn(path) {
      const [key, ...rest] = path
      if (rest.length === 0) {
        return this.has(key)
      }
      const node = this.get(key, true)
      return identity.isCollection(node) ? node.hasIn(rest) : false
    }
    /**
     * Sets a value in this collection. For `!!set`, `value` needs to be a
     * boolean to add/remove the item from the set.
     */
    setIn(path, value) {
      const [key, ...rest] = path
      if (rest.length === 0) {
        this.set(key, value)
      } else {
        const node = this.get(key, true)
        if (identity.isCollection(node)) {
          node.setIn(rest, value)
        } else if (node === undefined && this.schema) {
          this.set(key, collectionFromPath(this.schema, rest, value))
        } else {
          throw new Error(
            `Expected YAML collection at ${key}. Remaining path: ${rest}`
          )
        }
      }
    }
  }
  Collection$1.Collection = Collection
  Collection$1.collectionFromPath = collectionFromPath
  Collection$1.isEmptyPath = isEmptyPath
  return Collection$1
}

const Pair = {}

const stringifyPair = {}

const stringify$2 = {}

const stringifyComment = {}

let hasRequiredStringifyComment
function requireStringifyComment() {
  if (hasRequiredStringifyComment) {
    return stringifyComment
  }
  hasRequiredStringifyComment = 1

  /**
   * Stringifies a comment.
   *
   * Empty comment lines are left empty,
   * lines consisting of a single space are replaced by `#`,
   * and all other lines are prefixed with a `#`.
   */
  const stringifyComment$1 = str => str.replace(/^(?!$)(?: $)?/gm, '#')
  function indentComment(comment, indent) {
    if (/^\n+$/.test(comment)) {
      return comment.substring(1)
    }
    return indent ? comment.replace(/^(?! *$)/gm, indent) : comment
  }
  const lineComment = (str, indent, comment) =>
    str.endsWith('\n')
      ? indentComment(comment, indent)
      : comment.includes('\n')
        ? '\n' + indentComment(comment, indent)
        : (str.endsWith(' ') ? '' : ' ') + comment
  stringifyComment.indentComment = indentComment
  stringifyComment.lineComment = lineComment
  stringifyComment.stringifyComment = stringifyComment$1
  return stringifyComment
}

const stringifyString = {}

const foldFlowLines = {}

let hasRequiredFoldFlowLines
function requireFoldFlowLines() {
  if (hasRequiredFoldFlowLines) {
    return foldFlowLines
  }
  hasRequiredFoldFlowLines = 1
  const FOLD_FLOW = 'flow'
  const FOLD_BLOCK = 'block'
  const FOLD_QUOTED = 'quoted'
  /**
   * Tries to keep input at up to `lineWidth` characters, splitting only on spaces
   * not followed by newlines or spaces unless `mode` is `'quoted'`. Lines are
   * terminated with `\n` and started with `indent`.
   */
  function foldFlowLines$1(
    text,
    indent,
    mode = 'flow',
    {
      indentAtStart,
      lineWidth = 80,
      minContentWidth = 20,
      onFold,
      onOverflow
    } = {}
  ) {
    if (!lineWidth || lineWidth < 0) {
      return text
    }
    if (lineWidth < minContentWidth) {
      minContentWidth = 0
    }
    const endStep = Math.max(1 + minContentWidth, 1 + lineWidth - indent.length)
    if (text.length <= endStep) {
      return text
    }
    const folds = []
    const escapedFolds = {}
    let end = lineWidth - indent.length
    if (typeof indentAtStart === 'number') {
      if (indentAtStart > lineWidth - Math.max(2, minContentWidth)) {
        folds.push(0)
      } else {
        end = lineWidth - indentAtStart
      }
    }
    let split = undefined
    let prev = undefined
    let overflow = false
    let i = -1
    let escStart = -1
    let escEnd = -1
    if (mode === FOLD_BLOCK) {
      i = consumeMoreIndentedLines(text, i, indent.length)
      if (i !== -1) {
        end = i + endStep
      }
    }
    for (let ch; (ch = text[(i += 1)]); ) {
      if (mode === FOLD_QUOTED && ch === '\\') {
        escStart = i
        switch (text[i + 1]) {
          case 'x':
            i += 3
            break
          case 'u':
            i += 5
            break
          case 'U':
            i += 9
            break
          default:
            i += 1
        }
        escEnd = i
      }
      if (ch === '\n') {
        if (mode === FOLD_BLOCK) {
          i = consumeMoreIndentedLines(text, i, indent.length)
        }
        end = i + indent.length + endStep
        split = undefined
      } else {
        if (
          ch === ' ' &&
          prev &&
          prev !== ' ' &&
          prev !== '\n' &&
          prev !== '\t'
        ) {
          // space surrounded by non-space can be replaced with newline + indent
          const next = text[i + 1]
          if (next && next !== ' ' && next !== '\n' && next !== '\t') {
            split = i
          }
        }
        if (i >= end) {
          if (split) {
            folds.push(split)
            end = split + endStep
            split = undefined
          } else if (mode === FOLD_QUOTED) {
            // white-space collected at end may stretch past lineWidth
            while (prev === ' ' || prev === '\t') {
              prev = ch
              ch = text[(i += 1)]
              overflow = true
            }
            // Account for newline escape, but don't break preceding escape
            const j = i > escEnd + 1 ? i - 2 : escStart - 1
            // Bail out if lineWidth & minContentWidth are shorter than an escape string
            if (escapedFolds[j]) {
              return text
            }
            folds.push(j)
            escapedFolds[j] = true
            end = j + endStep
            split = undefined
          } else {
            overflow = true
          }
        }
      }
      prev = ch
    }
    if (overflow && onOverflow) {
      onOverflow()
    }
    if (folds.length === 0) {
      return text
    }
    if (onFold) {
      onFold()
    }
    let res = text.slice(0, folds[0])
    for (let i = 0; i < folds.length; ++i) {
      const fold = folds[i]
      const end = folds[i + 1] || text.length
      if (fold === 0) {
        res = `\n${indent}${text.slice(0, end)}`
      } else {
        if (mode === FOLD_QUOTED && escapedFolds[fold]) {
          res += `${text[fold]}\\`
        }
        res += `\n${indent}${text.slice(fold + 1, end)}`
      }
    }
    return res
  }
  /**
   * Presumes `i + 1` is at the start of a line
   * @returns index of last newline in more-indented block
   */
  function consumeMoreIndentedLines(text, i, indent) {
    let end = i
    let start = i + 1
    let ch = text[start]
    while (ch === ' ' || ch === '\t') {
      if (i < start + indent) {
        ch = text[++i]
      } else {
        do {
          ch = text[++i]
        } while (ch && ch !== '\n')
        end = i
        start = i + 1
        ch = text[start]
      }
    }
    return end
  }
  foldFlowLines.FOLD_BLOCK = FOLD_BLOCK
  foldFlowLines.FOLD_FLOW = FOLD_FLOW
  foldFlowLines.FOLD_QUOTED = FOLD_QUOTED
  foldFlowLines.foldFlowLines = foldFlowLines$1
  return foldFlowLines
}

let hasRequiredStringifyString
function requireStringifyString() {
  if (hasRequiredStringifyString) {
    return stringifyString
  }
  hasRequiredStringifyString = 1
  const Scalar = requireScalar()
  const foldFlowLines = requireFoldFlowLines()
  const getFoldOptions = (ctx, isBlock) => ({
    indentAtStart: isBlock ? ctx.indent.length : ctx.indentAtStart,
    lineWidth: ctx.options.lineWidth,
    minContentWidth: ctx.options.minContentWidth
  })
  // Also checks for lines starting with %, as parsing the output as YAML 1.1 will
  // presume that's starting a new document.
  const containsDocumentMarker = str => /^(%|---|\.\.\.)/m.test(str)
  function lineLengthOverLimit(str, lineWidth, indentLength) {
    if (!lineWidth || lineWidth < 0) {
      return false
    }
    const limit = lineWidth - indentLength
    const strLen = str.length
    if (strLen <= limit) {
      return false
    }
    for (let i = 0, start = 0; i < strLen; ++i) {
      if (str[i] === '\n') {
        if (i - start > limit) {
          return true
        }
        start = i + 1
        if (strLen - start <= limit) {
          return false
        }
      }
    }
    return true
  }
  function doubleQuotedString(value, ctx) {
    const json = JSON.stringify(value)
    if (ctx.options.doubleQuotedAsJSON) {
      return json
    }
    const { implicitKey } = ctx
    const minMultiLineLength = ctx.options.doubleQuotedMinMultiLineLength
    const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '')
    let str = ''
    let start = 0
    for (let i = 0, ch = json[i]; ch; ch = json[++i]) {
      if (ch === ' ' && json[i + 1] === '\\' && json[i + 2] === 'n') {
        // space before newline needs to be escaped to not be folded
        str += json.slice(start, i) + '\\ '
        i += 1
        start = i
        ch = '\\'
      }
      if (ch === '\\') {
        switch (json[i + 1]) {
          case 'u':
            {
              str += json.slice(start, i)
              const code = json.substr(i + 2, 4)
              switch (code) {
                case '0000':
                  str += '\\0'
                  break
                case '0007':
                  str += '\\a'
                  break
                case '000b':
                  str += '\\v'
                  break
                case '001b':
                  str += '\\e'
                  break
                case '0085':
                  str += '\\N'
                  break
                case '00a0':
                  str += '\\_'
                  break
                case '2028':
                  str += '\\L'
                  break
                case '2029':
                  str += '\\P'
                  break
                default:
                  if (code.substr(0, 2) === '00') str += '\\x' + code.substr(2)
                  else str += json.substr(i, 6)
              }
              i += 5
              start = i + 1
            }
            break
          case 'n':
            if (
              implicitKey ||
              json[i + 2] === '"' ||
              json.length < minMultiLineLength
            ) {
              i += 1
            } else {
              // folding will eat first newline
              str += json.slice(start, i) + '\n\n'
              while (
                json[i + 2] === '\\' &&
                json[i + 3] === 'n' &&
                json[i + 4] !== '"'
              ) {
                str += '\n'
                i += 2
              }
              str += indent
              // space after newline needs to be escaped to not be folded
              if (json[i + 2] === ' ') str += '\\'
              i += 1
              start = i + 1
            }
            break
          default:
            i += 1
        }
      }
    }
    str = start ? str + json.slice(start) : json
    return implicitKey
      ? str
      : foldFlowLines.foldFlowLines(
          str,
          indent,
          foldFlowLines.FOLD_QUOTED,
          getFoldOptions(ctx, false)
        )
  }
  function singleQuotedString(value, ctx) {
    if (
      ctx.options.singleQuote === false ||
      (ctx.implicitKey && value.includes('\n')) ||
      /[ \t]\n|\n[ \t]/.test(value) // single quoted string can't have leading or trailing whitespace around newline
    ) {
      return doubleQuotedString(value, ctx)
    }
    const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '')
    const res =
      "'" + value.replace(/'/g, "''").replace(/\n+/g, `$&\n${indent}`) + "'"
    return ctx.implicitKey
      ? res
      : foldFlowLines.foldFlowLines(
          res,
          indent,
          foldFlowLines.FOLD_FLOW,
          getFoldOptions(ctx, false)
        )
  }
  function quotedString(value, ctx) {
    const { singleQuote } = ctx.options
    let qs
    if (singleQuote === false) {
      qs = doubleQuotedString
    } else {
      const hasDouble = value.includes('"')
      const hasSingle = value.includes("'")
      if (hasDouble && !hasSingle) {
        qs = singleQuotedString
      } else if (hasSingle && !hasDouble) {
        qs = doubleQuotedString
      } else {
        qs = singleQuote ? singleQuotedString : doubleQuotedString
      }
    }
    return qs(value, ctx)
  }
  // The negative lookbehind avoids a polynomial search,
  // but isn't supported yet on Safari: https://caniuse.com/js-regexp-lookbehind
  let blockEndNewlines
  try {
    blockEndNewlines = new RegExp('(^|(?<!\n))\n+(?!\n|$)', 'g')
  } catch {
    blockEndNewlines = /\n+(?!\n|$)/g
  }
  function blockString({ comment, type, value }, ctx, onComment, onChompKeep) {
    const { blockQuote, commentString, lineWidth } = ctx.options
    // 1. Block can't end in whitespace unless the last line is non-empty.
    // 2. Strings consisting of only whitespace are best rendered explicitly.
    if (!blockQuote || /\n[\t ]+$/.test(value) || /^\s*$/.test(value)) {
      return quotedString(value, ctx)
    }
    const indent =
      ctx.indent ||
      (ctx.forceBlockIndent || containsDocumentMarker(value) ? '  ' : '')
    const literal =
      blockQuote === 'literal'
        ? true
        : blockQuote === 'folded' || type === Scalar.Scalar.BLOCK_FOLDED
          ? false
          : type === Scalar.Scalar.BLOCK_LITERAL
            ? true
            : !lineLengthOverLimit(value, lineWidth, indent.length)
    if (!value) {
      return literal ? '|\n' : '>\n'
    }
    // determine chomping from whitespace at value end
    let chomp
    let endStart
    for (endStart = value.length; endStart > 0; --endStart) {
      const ch = value[endStart - 1]
      if (ch !== '\n' && ch !== '\t' && ch !== ' ') {
        break
      }
    }
    let end = value.substring(endStart)
    const endNlPos = end.indexOf('\n')
    if (endNlPos === -1) {
      chomp = '-' // strip
    } else if (value === end || endNlPos !== end.length - 1) {
      chomp = '+' // keep
      if (onChompKeep) {
        onChompKeep()
      }
    } else {
      chomp = '' // clip
    }
    if (end) {
      value = value.slice(0, -end.length)
      if (end[end.length - 1] === '\n') {
        end = end.slice(0, -1)
      }
      end = end.replace(blockEndNewlines, `$&${indent}`)
    }
    // determine indent indicator from whitespace at value start
    let startWithSpace = false
    let startEnd
    let startNlPos = -1
    for (startEnd = 0; startEnd < value.length; ++startEnd) {
      const ch = value[startEnd]
      if (ch === ' ') {
        startWithSpace = true
      } else if (ch === '\n') {
        startNlPos = startEnd
      } else {
        break
      }
    }
    let start = value.substring(
      0,
      startNlPos < startEnd ? startNlPos + 1 : startEnd
    )
    if (start) {
      value = value.substring(start.length)
      start = start.replace(/\n+/g, `$&${indent}`)
    }
    const indentSize = indent ? '2' : '1' // root is at -1
    // Leading | or > is added later
    let header = (startWithSpace ? indentSize : '') + chomp
    if (comment) {
      header += ' ' + commentString(comment.replace(/ ?[\r\n]+/g, ' '))
      if (onComment) {
        onComment()
      }
    }
    if (!literal) {
      const foldedValue = value
        .replace(/\n+/g, '\n$&')
        .replace(/(?:^|\n)([\t ].*)(?:([\n\t ]*)\n(?![\n\t ]))?/g, '$1$2') // more-indented lines aren't folded
        //                ^ more-ind. ^ empty     ^ capture next empty lines only at end of indent
        .replace(/\n+/g, `$&${indent}`)
      let literalFallback = false
      const foldOptions = getFoldOptions(ctx, true)
      if (blockQuote !== 'folded' && type !== Scalar.Scalar.BLOCK_FOLDED) {
        foldOptions.onOverflow = () => {
          literalFallback = true
        }
      }
      const body = foldFlowLines.foldFlowLines(
        `${start}${foldedValue}${end}`,
        indent,
        foldFlowLines.FOLD_BLOCK,
        foldOptions
      )
      if (!literalFallback) {
        return `>${header}\n${indent}${body}`
      }
    }
    value = value.replace(/\n+/g, `$&${indent}`)
    return `|${header}\n${indent}${start}${value}${end}`
  }
  function plainString(item, ctx, onComment, onChompKeep) {
    const { type, value } = item
    const { actualString, implicitKey, indent, indentStep, inFlow } = ctx
    if (
      (implicitKey && value.includes('\n')) ||
      (inFlow && /[[\]{},]/.test(value))
    ) {
      return quotedString(value, ctx)
    }
    if (
      !value ||
      /^[\n\t ,[\]{}#&*!|>'"%@`]|^[?-]$|^[?-][ \t]|[\n:][ \t]|[ \t]\n|[\n\t ]#|[\n\t :]$/.test(
        value
      )
    ) {
      // not allowed:
      // - empty string, '-' or '?'
      // - start with an indicator character (except [?:-]) or /[?-] /
      // - '\n ', ': ' or ' \n' anywhere
      // - '#' not preceded by a non-space char
      // - end with ' ' or ':'
      return implicitKey || inFlow || !value.includes('\n')
        ? quotedString(value, ctx)
        : blockString(item, ctx, onComment, onChompKeep)
    }
    if (
      !implicitKey &&
      !inFlow &&
      type !== Scalar.Scalar.PLAIN &&
      value.includes('\n')
    ) {
      // Where allowed & type not set explicitly, prefer block style for multiline strings
      return blockString(item, ctx, onComment, onChompKeep)
    }
    if (containsDocumentMarker(value)) {
      if (indent === '') {
        ctx.forceBlockIndent = true
        return blockString(item, ctx, onComment, onChompKeep)
      } else if (implicitKey && indent === indentStep) {
        return quotedString(value, ctx)
      }
    }
    const str = value.replace(/\n+/g, `$&\n${indent}`)
    // Verify that output will be parsed as a string, as e.g. plain numbers and
    // booleans get parsed with those types in v1.2 (e.g. '42', 'true' & '0.9e-3'),
    // and others in v1.1.
    if (actualString) {
      const test = tag =>
        tag.default &&
        tag.tag !== 'tag:yaml.org,2002:str' &&
        tag.test?.test(str)
      const { compat, tags } = ctx.doc.schema
      if (tags.some(test) || compat?.some(test)) {
        return quotedString(value, ctx)
      }
    }
    return implicitKey
      ? str
      : foldFlowLines.foldFlowLines(
          str,
          indent,
          foldFlowLines.FOLD_FLOW,
          getFoldOptions(ctx, false)
        )
  }
  function stringifyString$1(item, ctx, onComment, onChompKeep) {
    const { implicitKey, inFlow } = ctx
    const ss =
      typeof item.value === 'string'
        ? item
        : Object.assign({}, item, {
            value: String(item.value)
          })
    let { type } = item
    if (type !== Scalar.Scalar.QUOTE_DOUBLE) {
      // force double quotes on control characters & unpaired surrogates
      if (/[\x00-\x08\x0b-\x1f\x7f-\x9f\u{D800}-\u{DFFF}]/u.test(ss.value)) {
        type = Scalar.Scalar.QUOTE_DOUBLE
      }
    }
    const _stringify = _type => {
      switch (_type) {
        case Scalar.Scalar.BLOCK_FOLDED:
        case Scalar.Scalar.BLOCK_LITERAL:
          return implicitKey || inFlow
            ? quotedString(ss.value, ctx) // blocks are not valid inside flow containers
            : blockString(ss, ctx, onComment, onChompKeep)
        case Scalar.Scalar.QUOTE_DOUBLE:
          return doubleQuotedString(ss.value, ctx)
        case Scalar.Scalar.QUOTE_SINGLE:
          return singleQuotedString(ss.value, ctx)
        case Scalar.Scalar.PLAIN:
          return plainString(ss, ctx, onComment, onChompKeep)
        default:
          return null
      }
    }
    let res = _stringify(type)
    if (res === null) {
      const { defaultKeyType, defaultStringType } = ctx.options
      const t = (implicitKey && defaultKeyType) || defaultStringType
      res = _stringify(t)
      if (res === null) {
        throw new Error(`Unsupported default string type ${t}`)
      }
    }
    return res
  }
  stringifyString.stringifyString = stringifyString$1
  return stringifyString
}

let hasRequiredStringify$2
function requireStringify$2() {
  if (hasRequiredStringify$2) {
    return stringify$2
  }
  hasRequiredStringify$2 = 1
  const anchors = requireAnchors()
  const identity = requireIdentity()
  const stringifyComment = requireStringifyComment()
  const stringifyString = requireStringifyString()
  function createStringifyContext(doc, options) {
    const opt = Object.assign(
      {
        blockQuote: true,
        commentString: stringifyComment.stringifyComment,
        defaultKeyType: null,
        defaultStringType: 'PLAIN',
        directives: null,
        doubleQuotedAsJSON: false,
        doubleQuotedMinMultiLineLength: 40,
        falseStr: 'false',
        flowCollectionPadding: true,
        indentSeq: true,
        lineWidth: 80,
        minContentWidth: 20,
        nullStr: 'null',
        simpleKeys: false,
        singleQuote: null,
        trueStr: 'true',
        verifyAliasOrder: true
      },
      doc.schema.toStringOptions,
      options
    )
    let inFlow
    switch (opt.collectionStyle) {
      case 'block':
        inFlow = false
        break
      case 'flow':
        inFlow = true
        break
      default:
        inFlow = null
    }
    return {
      anchors: new Set(),
      doc,
      flowCollectionPadding: opt.flowCollectionPadding ? ' ' : '',
      indent: '',
      indentStep:
        typeof opt.indent === 'number' ? ' '.repeat(opt.indent) : '  ',
      inFlow,
      options: opt
    }
  }
  function getTagObject(tags, item) {
    if (item.tag) {
      const match = tags.filter(t => t.tag === item.tag)
      if (match.length > 0) {
        return match.find(t => t.format === item.format) ?? match[0]
      }
    }
    let tagObj = undefined
    let obj
    if (identity.isScalar(item)) {
      obj = item.value
      let match = tags.filter(t => t.identify?.(obj))
      if (match.length > 1) {
        const testMatch = match.filter(t => t.test)
        if (testMatch.length > 0) {
          match = testMatch
        }
      }
      tagObj =
        match.find(t => t.format === item.format) ?? match.find(t => !t.format)
    } else {
      obj = item
      tagObj = tags.find(t => t.nodeClass && obj instanceof t.nodeClass)
    }
    if (!tagObj) {
      const name = obj?.constructor?.name ?? typeof obj
      throw new Error(`Tag not resolved for ${name} value`)
    }
    return tagObj
  }
  // needs to be called before value stringifier to allow for circular anchor refs
  function stringifyProps(node, tagObj, { anchors: anchors$1, doc }) {
    if (!doc.directives) {
      return ''
    }
    const props = []
    const anchor =
      (identity.isScalar(node) || identity.isCollection(node)) && node.anchor
    if (anchor && anchors.anchorIsValid(anchor)) {
      anchors$1.add(anchor)
      props.push(`&${anchor}`)
    }
    const tag = node.tag ? node.tag : tagObj.default ? null : tagObj.tag
    if (tag) {
      props.push(doc.directives.tagString(tag))
    }
    return props.join(' ')
  }
  function stringify(item, ctx, onComment, onChompKeep) {
    if (identity.isPair(item)) {
      return item.toString(ctx, onComment, onChompKeep)
    }
    if (identity.isAlias(item)) {
      if (ctx.doc.directives) {
        return item.toString(ctx)
      }
      if (ctx.resolvedAliases?.has(item)) {
        throw new TypeError(
          `Cannot stringify circular structure without alias nodes`
        )
      } else {
        if (ctx.resolvedAliases) {
          ctx.resolvedAliases.add(item)
        } else {
          ctx.resolvedAliases = new Set([item])
        }
        item = item.resolve(ctx.doc)
      }
    }
    let tagObj = undefined
    const node = identity.isNode(item)
      ? item
      : ctx.doc.createNode(item, {
          onTagObj: o => (tagObj = o)
        })
    if (!tagObj) {
      tagObj = getTagObject(ctx.doc.schema.tags, node)
    }
    const props = stringifyProps(node, tagObj, ctx)
    if (props.length > 0) {
      ctx.indentAtStart = (ctx.indentAtStart ?? 0) + props.length + 1
    }
    const str =
      typeof tagObj.stringify === 'function'
        ? tagObj.stringify(node, ctx, onComment, onChompKeep)
        : identity.isScalar(node)
          ? stringifyString.stringifyString(node, ctx, onComment, onChompKeep)
          : node.toString(ctx, onComment, onChompKeep)
    if (!props) {
      return str
    }
    return identity.isScalar(node) || str[0] === '{' || str[0] === '['
      ? `${props} ${str}`
      : `${props}\n${ctx.indent}${str}`
  }
  stringify$2.createStringifyContext = createStringifyContext
  stringify$2.stringify = stringify
  return stringify$2
}

let hasRequiredStringifyPair
function requireStringifyPair() {
  if (hasRequiredStringifyPair) {
    return stringifyPair
  }
  hasRequiredStringifyPair = 1
  const identity = requireIdentity()
  const Scalar = requireScalar()
  const stringify = requireStringify$2()
  const stringifyComment = requireStringifyComment()
  function stringifyPair$1({ key, value }, ctx, onComment, onChompKeep) {
    const {
      allNullValues,
      doc,
      indent,
      indentStep,
      options: { commentString, indentSeq, simpleKeys }
    } = ctx
    let keyComment = (identity.isNode(key) && key.comment) || null
    if (simpleKeys) {
      if (keyComment) {
        throw new Error('With simple keys, key nodes cannot have comments')
      }
      if (
        identity.isCollection(key) ||
        (!identity.isNode(key) && typeof key === 'object')
      ) {
        const msg = 'With simple keys, collection cannot be used as a key value'
        throw new Error(msg)
      }
    }
    let explicitKey =
      !simpleKeys &&
      (!key ||
        (keyComment && value == null && !ctx.inFlow) ||
        identity.isCollection(key) ||
        (identity.isScalar(key)
          ? key.type === Scalar.Scalar.BLOCK_FOLDED ||
            key.type === Scalar.Scalar.BLOCK_LITERAL
          : typeof key === 'object'))
    ctx = Object.assign({}, ctx, {
      allNullValues: false,
      implicitKey: !explicitKey && (simpleKeys || !allNullValues),
      indent: indent + indentStep
    })
    let keyCommentDone = false
    let chompKeep = false
    let str = stringify.stringify(
      key,
      ctx,
      () => (keyCommentDone = true),
      () => (chompKeep = true)
    )
    if (!explicitKey && !ctx.inFlow && str.length > 1024) {
      if (simpleKeys) {
        throw new Error(
          'With simple keys, single line scalar must not span more than 1024 characters'
        )
      }
      explicitKey = true
    }
    if (ctx.inFlow) {
      if (allNullValues || value == null) {
        if (keyCommentDone && onComment) {
          onComment()
        }
        return str === '' ? '?' : explicitKey ? `? ${str}` : str
      }
    } else if (
      (allNullValues && !simpleKeys) ||
      (value == null && explicitKey)
    ) {
      str = `? ${str}`
      if (keyComment && !keyCommentDone) {
        str += stringifyComment.lineComment(
          str,
          ctx.indent,
          commentString(keyComment)
        )
      } else if (chompKeep && onChompKeep) {
        onChompKeep()
      }
      return str
    }
    if (keyCommentDone) {
      keyComment = null
    }
    if (explicitKey) {
      if (keyComment) {
        str += stringifyComment.lineComment(
          str,
          ctx.indent,
          commentString(keyComment)
        )
      }
      str = `? ${str}\n${indent}:`
    } else {
      str = `${str}:`
      if (keyComment) {
        str += stringifyComment.lineComment(
          str,
          ctx.indent,
          commentString(keyComment)
        )
      }
    }
    let vsb, vcb, valueComment
    if (identity.isNode(value)) {
      vsb = !!value.spaceBefore
      vcb = value.commentBefore
      valueComment = value.comment
    } else {
      vsb = false
      vcb = null
      valueComment = null
      if (value && typeof value === 'object') {
        value = doc.createNode(value)
      }
    }
    ctx.implicitKey = false
    if (!explicitKey && !keyComment && identity.isScalar(value)) {
      ctx.indentAtStart = str.length + 1
    }
    chompKeep = false
    if (
      !indentSeq &&
      indentStep.length >= 2 &&
      !ctx.inFlow &&
      !explicitKey &&
      identity.isSeq(value) &&
      !value.flow &&
      !value.tag &&
      !value.anchor
    ) {
      // If indentSeq === false, consider '- ' as part of indentation where possible
      ctx.indent = ctx.indent.substring(2)
    }
    let valueCommentDone = false
    const valueStr = stringify.stringify(
      value,
      ctx,
      () => (valueCommentDone = true),
      () => (chompKeep = true)
    )
    let ws = ' '
    if (keyComment || vsb || vcb) {
      ws = vsb ? '\n' : ''
      if (vcb) {
        const cs = commentString(vcb)
        ws += `\n${stringifyComment.indentComment(cs, ctx.indent)}`
      }
      if (valueStr === '' && !ctx.inFlow) {
        if (ws === '\n') {
          ws = '\n\n'
        }
      } else {
        ws += `\n${ctx.indent}`
      }
    } else if (!explicitKey && identity.isCollection(value)) {
      const vs0 = valueStr[0]
      const nl0 = valueStr.indexOf('\n')
      const hasNewline = nl0 !== -1
      const flow = ctx.inFlow ?? value.flow ?? value.items.length === 0
      if (hasNewline || !flow) {
        let hasPropsLine = false
        if (hasNewline && (vs0 === '&' || vs0 === '!')) {
          let sp0 = valueStr.indexOf(' ')
          if (
            vs0 === '&' &&
            sp0 !== -1 &&
            sp0 < nl0 &&
            valueStr[sp0 + 1] === '!'
          ) {
            sp0 = valueStr.indexOf(' ', sp0 + 1)
          }
          if (sp0 === -1 || nl0 < sp0) {
            hasPropsLine = true
          }
        }
        if (!hasPropsLine) {
          ws = `\n${ctx.indent}`
        }
      }
    } else if (valueStr === '' || valueStr[0] === '\n') {
      ws = ''
    }
    str += ws + valueStr
    if (ctx.inFlow) {
      if (valueCommentDone && onComment) {
        onComment()
      }
    } else if (valueComment && !valueCommentDone) {
      str += stringifyComment.lineComment(
        str,
        ctx.indent,
        commentString(valueComment)
      )
    } else if (chompKeep && onChompKeep) {
      onChompKeep()
    }
    return str
  }
  stringifyPair.stringifyPair = stringifyPair$1
  return stringifyPair
}

const addPairToJSMap = {}

const log = {}

let hasRequiredLog
function requireLog() {
  if (hasRequiredLog) {
    return log
  }
  hasRequiredLog = 1
  const node_process = process$2
  function debug(logLevel, ...messages) {
    if (logLevel === 'debug') {
      console.log(...messages)
    }
  }
  function warn(logLevel, warning) {
    if (logLevel === 'debug' || logLevel === 'warn') {
      if (typeof node_process.emitWarning === 'function') {
        node_process.emitWarning(warning)
      } else {
        console.warn(warning)
      }
    }
  }
  log.debug = debug
  log.warn = warn
  return log
}

const merge$2 = {}

let hasRequiredMerge$1
function requireMerge$1() {
  if (hasRequiredMerge$1) {
    return merge$2
  }
  hasRequiredMerge$1 = 1
  const identity = requireIdentity()
  const Scalar = requireScalar()

  // If the value associated with a merge key is a single mapping node, each of
  // its key/value pairs is inserted into the current mapping, unless the key
  // already exists in it. If the value associated with the merge key is a
  // sequence, then this sequence is expected to contain mapping nodes and each
  // of these nodes is merged in turn according to its order in the sequence.
  // Keys in mapping nodes earlier in the sequence override keys specified in
  // later mapping nodes. -- http://yaml.org/type/merge.html
  const MERGE_KEY = '<<'
  const merge = {
    identify: value =>
      value === MERGE_KEY ||
      (typeof value === 'symbol' && value.description === MERGE_KEY),
    default: 'key',
    tag: 'tag:yaml.org,2002:merge',
    test: /^<<$/,
    resolve: () =>
      Object.assign(new Scalar.Scalar(Symbol(MERGE_KEY)), {
        addToJSMap: addMergeToJSMap
      }),
    stringify: () => MERGE_KEY
  }
  const isMergeKey = (ctx, key) =>
    (merge.identify(key) ||
      (identity.isScalar(key) &&
        (!key.type || key.type === Scalar.Scalar.PLAIN) &&
        merge.identify(key.value))) &&
    ctx?.doc.schema.tags.some(tag => tag.tag === merge.tag && tag.default)
  function addMergeToJSMap(ctx, map, value) {
    value = ctx && identity.isAlias(value) ? value.resolve(ctx.doc) : value
    if (identity.isSeq(value)) {
      for (const it of value.items) mergeValue(ctx, map, it)
    } else if (Array.isArray(value)) {
      for (const it of value) mergeValue(ctx, map, it)
    } else {
      mergeValue(ctx, map, value)
    }
  }
  function mergeValue(ctx, map, value) {
    const source =
      ctx && identity.isAlias(value) ? value.resolve(ctx.doc) : value
    if (!identity.isMap(source)) {
      throw new Error('Merge sources must be maps or map aliases')
    }
    const srcMap = source.toJSON(null, ctx, Map)
    for (const [key, value] of srcMap) {
      if (map instanceof Map) {
        if (!map.has(key)) {
          map.set(key, value)
        }
      } else if (map instanceof Set) {
        map.add(key)
      } else if (!Object.prototype.hasOwnProperty.call(map, key)) {
        Object.defineProperty(map, key, {
          value,
          writable: true,
          enumerable: true,
          configurable: true
        })
      }
    }
    return map
  }
  merge$2.addMergeToJSMap = addMergeToJSMap
  merge$2.isMergeKey = isMergeKey
  merge$2.merge = merge
  return merge$2
}

let hasRequiredAddPairToJSMap
function requireAddPairToJSMap() {
  if (hasRequiredAddPairToJSMap) {
    return addPairToJSMap
  }
  hasRequiredAddPairToJSMap = 1
  const log = requireLog()
  const merge = requireMerge$1()
  const stringify = requireStringify$2()
  const identity = requireIdentity()
  const toJS = requireToJS()
  function addPairToJSMap$1(ctx, map, { key, value }) {
    if (identity.isNode(key) && key.addToJSMap) {
      key.addToJSMap(ctx, map, value)
    }
    // TODO: Should drop this special case for bare << handling
    else if (merge.isMergeKey(ctx, key)) {
      merge.addMergeToJSMap(ctx, map, value)
    } else {
      const jsKey = toJS.toJS(key, '', ctx)
      if (map instanceof Map) {
        map.set(jsKey, toJS.toJS(value, jsKey, ctx))
      } else if (map instanceof Set) {
        map.add(jsKey)
      } else {
        const stringKey = stringifyKey(key, jsKey, ctx)
        const jsValue = toJS.toJS(value, stringKey, ctx)
        if (stringKey in map) {
          Object.defineProperty(map, stringKey, {
            value: jsValue,
            writable: true,
            enumerable: true,
            configurable: true
          })
        } else {
          map[stringKey] = jsValue
        }
      }
    }
    return map
  }
  function stringifyKey(key, jsKey, ctx) {
    if (jsKey === null) {
      return ''
    }
    if (typeof jsKey !== 'object') {
      return String(jsKey)
    }
    if (identity.isNode(key) && ctx?.doc) {
      const strCtx = stringify.createStringifyContext(ctx.doc, {})
      strCtx.anchors = new Set()
      for (const node of ctx.anchors.keys()) {
        strCtx.anchors.add(node.anchor)
      }
      strCtx.inFlow = true
      strCtx.inStringifyKey = true
      const strKey = key.toString(strCtx)
      if (!ctx.mapKeyWarned) {
        let jsonStr = JSON.stringify(strKey)
        if (jsonStr.length > 40) {
          jsonStr = jsonStr.substring(0, 36) + '..."'
        }
        log.warn(
          ctx.doc.options.logLevel,
          `Keys with collection values will be stringified due to JS Object restrictions: ${jsonStr}. Set mapAsMap: true to use object keys.`
        )
        ctx.mapKeyWarned = true
      }
      return strKey
    }
    return JSON.stringify(jsKey)
  }
  addPairToJSMap.addPairToJSMap = addPairToJSMap$1
  return addPairToJSMap
}

let hasRequiredPair
function requirePair() {
  if (hasRequiredPair) {
    return Pair
  }
  hasRequiredPair = 1
  const createNode = requireCreateNode()
  const stringifyPair = requireStringifyPair()
  const addPairToJSMap = requireAddPairToJSMap()
  const identity = requireIdentity()
  function createPair(key, value, ctx) {
    const k = createNode.createNode(key, undefined, ctx)
    const v = createNode.createNode(value, undefined, ctx)
    return new Pair$1(k, v)
  }
  let Pair$1 = class Pair {
    constructor(key, value = null) {
      Object.defineProperty(this, identity.NODE_TYPE, {
        value: identity.PAIR
      })
      this.key = key
      this.value = value
    }
    clone(schema) {
      let { key, value } = this
      if (identity.isNode(key)) {
        key = key.clone(schema)
      }
      if (identity.isNode(value)) {
        value = value.clone(schema)
      }
      return new Pair(key, value)
    }
    toJSON(_, ctx) {
      const pair = ctx?.mapAsMap ? new Map() : {}
      return addPairToJSMap.addPairToJSMap(ctx, pair, this)
    }
    toString(ctx, onComment, onChompKeep) {
      return ctx?.doc
        ? stringifyPair.stringifyPair(this, ctx, onComment, onChompKeep)
        : JSON.stringify(this)
    }
  }
  Pair.Pair = Pair$1
  Pair.createPair = createPair
  return Pair
}

const Schema = {}

const map$1 = {}

const YAMLMap = {}

const stringifyCollection = {}

let hasRequiredStringifyCollection
function requireStringifyCollection() {
  if (hasRequiredStringifyCollection) {
    return stringifyCollection
  }
  hasRequiredStringifyCollection = 1
  const identity = requireIdentity()
  const stringify = requireStringify$2()
  const stringifyComment = requireStringifyComment()
  function stringifyCollection$1(collection, ctx, options) {
    const flow = ctx.inFlow ?? collection.flow
    const stringify = flow ? stringifyFlowCollection : stringifyBlockCollection
    return stringify(collection, ctx, options)
  }
  function stringifyBlockCollection(
    { comment, items },
    ctx,
    { blockItemPrefix, flowChars, itemIndent, onChompKeep, onComment }
  ) {
    const {
      indent,
      options: { commentString }
    } = ctx
    const itemCtx = Object.assign({}, ctx, {
      indent: itemIndent,
      type: null
    })
    let chompKeep = false // flag for the preceding node's status
    const lines = []
    for (let i = 0; i < items.length; ++i) {
      const item = items[i]
      let comment = null
      if (identity.isNode(item)) {
        if (!chompKeep && item.spaceBefore) {
          lines.push('')
        }
        addCommentBefore(ctx, lines, item.commentBefore, chompKeep)
        if (item.comment) {
          comment = item.comment
        }
      } else if (identity.isPair(item)) {
        const ik = identity.isNode(item.key) ? item.key : null
        if (ik) {
          if (!chompKeep && ik.spaceBefore) {
            lines.push('')
          }
          addCommentBefore(ctx, lines, ik.commentBefore, chompKeep)
        }
      }
      chompKeep = false
      let str = stringify.stringify(
        item,
        itemCtx,
        () => (comment = null),
        () => (chompKeep = true)
      )
      if (comment) {
        str += stringifyComment.lineComment(
          str,
          itemIndent,
          commentString(comment)
        )
      }
      if (chompKeep && comment) {
        chompKeep = false
      }
      lines.push(blockItemPrefix + str)
    }
    let str
    if (lines.length === 0) {
      str = flowChars.start + flowChars.end
    } else {
      str = lines[0]
      for (let i = 1; i < lines.length; ++i) {
        const line = lines[i]
        str += line ? `\n${indent}${line}` : '\n'
      }
    }
    if (comment) {
      str +=
        '\n' + stringifyComment.indentComment(commentString(comment), indent)
      if (onComment) {
        onComment()
      }
    } else if (chompKeep && onChompKeep) {
      onChompKeep()
    }
    return str
  }
  function stringifyFlowCollection({ items }, ctx, { flowChars, itemIndent }) {
    const {
      indent,
      indentStep,
      flowCollectionPadding: fcPadding,
      options: { commentString }
    } = ctx
    itemIndent += indentStep
    const itemCtx = Object.assign({}, ctx, {
      indent: itemIndent,
      inFlow: true,
      type: null
    })
    let reqNewline = false
    let linesAtValue = 0
    const lines = []
    for (let i = 0; i < items.length; ++i) {
      const item = items[i]
      let comment = null
      if (identity.isNode(item)) {
        if (item.spaceBefore) {
          lines.push('')
        }
        addCommentBefore(ctx, lines, item.commentBefore, false)
        if (item.comment) {
          comment = item.comment
        }
      } else if (identity.isPair(item)) {
        const ik = identity.isNode(item.key) ? item.key : null
        if (ik) {
          if (ik.spaceBefore) {
            lines.push('')
          }
          addCommentBefore(ctx, lines, ik.commentBefore, false)
          if (ik.comment) {
            reqNewline = true
          }
        }
        const iv = identity.isNode(item.value) ? item.value : null
        if (iv) {
          if (iv.comment) {
            comment = iv.comment
          }
          if (iv.commentBefore) {
            reqNewline = true
          }
        } else if (item.value == null && ik?.comment) {
          comment = ik.comment
        }
      }
      if (comment) {
        reqNewline = true
      }
      let str = stringify.stringify(item, itemCtx, () => (comment = null))
      if (i < items.length - 1) {
        str += ','
      }
      if (comment) {
        str += stringifyComment.lineComment(
          str,
          itemIndent,
          commentString(comment)
        )
      }
      if (!reqNewline && (lines.length > linesAtValue || str.includes('\n'))) {
        reqNewline = true
      }
      lines.push(str)
      linesAtValue = lines.length
    }
    const { start, end } = flowChars
    if (lines.length === 0) {
      return start + end
    } else {
      if (!reqNewline) {
        const len = lines.reduce((sum, line) => sum + line.length + 2, 2)
        reqNewline = ctx.options.lineWidth > 0 && len > ctx.options.lineWidth
      }
      if (reqNewline) {
        let str = start
        for (const line of lines) {
          str += line ? `\n${indentStep}${indent}${line}` : '\n'
        }
        return `${str}\n${indent}${end}`
      } else {
        return `${start}${fcPadding}${lines.join(' ')}${fcPadding}${end}`
      }
    }
  }
  function addCommentBefore(
    { indent, options: { commentString } },
    lines,
    comment,
    chompKeep
  ) {
    if (comment && chompKeep) {
      comment = comment.replace(/^\n+/, '')
    }
    if (comment) {
      const ic = stringifyComment.indentComment(commentString(comment), indent)
      lines.push(ic.trimStart()) // Avoid double indent on first line
    }
  }
  stringifyCollection.stringifyCollection = stringifyCollection$1
  return stringifyCollection
}

let hasRequiredYAMLMap
function requireYAMLMap() {
  if (hasRequiredYAMLMap) {
    return YAMLMap
  }
  hasRequiredYAMLMap = 1
  const stringifyCollection = requireStringifyCollection()
  const addPairToJSMap = requireAddPairToJSMap()
  const Collection = requireCollection()
  const identity = requireIdentity()
  const Pair = requirePair()
  const Scalar = requireScalar()
  function findPair(items, key) {
    const k = identity.isScalar(key) ? key.value : key
    for (const it of items) {
      if (identity.isPair(it)) {
        if (it.key === key || it.key === k) {
          return it
        }
        if (identity.isScalar(it.key) && it.key.value === k) {
          return it
        }
      }
    }
    return undefined
  }
  let YAMLMap$1 = class YAMLMap extends Collection.Collection {
    static get tagName() {
      return 'tag:yaml.org,2002:map'
    }
    constructor(schema) {
      super(identity.MAP, schema)
      this.items = []
    }
    /**
     * A generic collection parsing method that can be extended
     * to other node classes that inherit from YAMLMap
     */
    static from(schema, obj, ctx) {
      const { keepUndefined, replacer } = ctx
      const map = new this(schema)
      const add = (key, value) => {
        if (typeof replacer === 'function') {
          value = replacer.call(obj, key, value)
        } else if (Array.isArray(replacer) && !replacer.includes(key)) {
          return
        }
        if (value !== undefined || keepUndefined) {
          map.items.push(Pair.createPair(key, value, ctx))
        }
      }
      if (obj instanceof Map) {
        for (const [key, value] of obj) {
          add(key, value)
        }
      } else if (obj && typeof obj === 'object') {
        for (const key of Object.keys(obj)) {
          add(key, obj[key])
        }
      }
      if (typeof schema.sortMapEntries === 'function') {
        map.items.sort(schema.sortMapEntries)
      }
      return map
    }
    /**
     * Adds a value to the collection.
     *
     * @param overwrite - If not set `true`, using a key that is already in the
     *   collection will throw. Otherwise, overwrites the previous value.
     */
    add(pair, overwrite) {
      let _pair
      if (identity.isPair(pair)) {
        _pair = pair
      } else if (!pair || typeof pair !== 'object' || !('key' in pair)) {
        // In TypeScript, this never happens.
        _pair = new Pair.Pair(pair, pair?.value)
      } else {
        _pair = new Pair.Pair(pair.key, pair.value)
      }
      const prev = findPair(this.items, _pair.key)
      const sortEntries = this.schema?.sortMapEntries
      if (prev) {
        if (!overwrite) {
          throw new Error(`Key ${_pair.key} already set`)
        }
        // For scalars, keep the old node & its comments and anchors
        if (
          identity.isScalar(prev.value) &&
          Scalar.isScalarValue(_pair.value)
        ) {
          prev.value.value = _pair.value
        } else {
          prev.value = _pair.value
        }
      } else if (sortEntries) {
        const i = this.items.findIndex(item => sortEntries(_pair, item) < 0)
        if (i === -1) {
          this.items.push(_pair)
        } else {
          this.items.splice(i, 0, _pair)
        }
      } else {
        this.items.push(_pair)
      }
    }
    delete(key) {
      const it = findPair(this.items, key)
      if (!it) {
        return false
      }
      const del = this.items.splice(this.items.indexOf(it), 1)
      return del.length > 0
    }
    get(key, keepScalar) {
      const it = findPair(this.items, key)
      const node = it?.value
      return (
        (!keepScalar && identity.isScalar(node) ? node.value : node) ??
        undefined
      )
    }
    has(key) {
      return !!findPair(this.items, key)
    }
    set(key, value) {
      this.add(new Pair.Pair(key, value), true)
    }
    /**
     * @param ctx - Conversion context, originally set in Document#toJS()
     * @param {Class} Type - If set, forces the returned collection type
     * @returns Instance of Type, Map, or Object
     */
    toJSON(_, ctx, Type) {
      const map = Type ? new Type() : ctx?.mapAsMap ? new Map() : {}
      if (ctx?.onCreate) {
        ctx.onCreate(map)
      }
      for (const item of this.items) {
        addPairToJSMap.addPairToJSMap(ctx, map, item)
      }
      return map
    }
    toString(ctx, onComment, onChompKeep) {
      if (!ctx) {
        return JSON.stringify(this)
      }
      for (const item of this.items) {
        if (!identity.isPair(item)) {
          throw new Error(
            `Map items must all be pairs; found ${JSON.stringify(item)} instead`
          )
        }
      }
      if (!ctx.allNullValues && this.hasAllNullValues(false)) {
        ctx = Object.assign({}, ctx, {
          allNullValues: true
        })
      }
      return stringifyCollection.stringifyCollection(this, ctx, {
        blockItemPrefix: '',
        flowChars: {
          start: '{',
          end: '}'
        },
        itemIndent: ctx.indent || '',
        onChompKeep,
        onComment
      })
    }
  }
  YAMLMap.YAMLMap = YAMLMap$1
  YAMLMap.findPair = findPair
  return YAMLMap
}

let hasRequiredMap$2
function requireMap$2() {
  if (hasRequiredMap$2) {
    return map$1
  }
  hasRequiredMap$2 = 1
  const identity = requireIdentity()
  const YAMLMap = requireYAMLMap()
  const map = {
    collection: 'map',
    default: true,
    nodeClass: YAMLMap.YAMLMap,
    tag: 'tag:yaml.org,2002:map',
    resolve(map, onError) {
      if (!identity.isMap(map)) {
        onError('Expected a mapping for this tag')
      }
      return map
    },
    createNode: (schema, obj, ctx) => YAMLMap.YAMLMap.from(schema, obj, ctx)
  }
  map$1.map = map
  return map$1
}

const seq$1 = {}

const YAMLSeq = {}

let hasRequiredYAMLSeq
function requireYAMLSeq() {
  if (hasRequiredYAMLSeq) {
    return YAMLSeq
  }
  hasRequiredYAMLSeq = 1
  const createNode = requireCreateNode()
  const stringifyCollection = requireStringifyCollection()
  const Collection = requireCollection()
  const identity = requireIdentity()
  const Scalar = requireScalar()
  const toJS = requireToJS()
  let YAMLSeq$1 = class YAMLSeq extends Collection.Collection {
    static get tagName() {
      return 'tag:yaml.org,2002:seq'
    }
    constructor(schema) {
      super(identity.SEQ, schema)
      this.items = []
    }
    add(value) {
      this.items.push(value)
    }
    /**
     * Removes a value from the collection.
     *
     * `key` must contain a representation of an integer for this to succeed.
     * It may be wrapped in a `Scalar`.
     *
     * @returns `true` if the item was found and removed.
     */
    delete(key) {
      const idx = asItemIndex(key)
      if (typeof idx !== 'number') {
        return false
      }
      const del = this.items.splice(idx, 1)
      return del.length > 0
    }
    get(key, keepScalar) {
      const idx = asItemIndex(key)
      if (typeof idx !== 'number') {
        return undefined
      }
      const it = this.items[idx]
      return !keepScalar && identity.isScalar(it) ? it.value : it
    }
    /**
     * Checks if the collection includes a value with the key `key`.
     *
     * `key` must contain a representation of an integer for this to succeed.
     * It may be wrapped in a `Scalar`.
     */
    has(key) {
      const idx = asItemIndex(key)
      return typeof idx === 'number' && idx < this.items.length
    }
    /**
     * Sets a value in this collection. For `!!set`, `value` needs to be a
     * boolean to add/remove the item from the set.
     *
     * If `key` does not contain a representation of an integer, this will throw.
     * It may be wrapped in a `Scalar`.
     */
    set(key, value) {
      const idx = asItemIndex(key)
      if (typeof idx !== 'number') {
        throw new Error(`Expected a valid index, not ${key}.`)
      }
      const prev = this.items[idx]
      if (identity.isScalar(prev) && Scalar.isScalarValue(value)) {
        prev.value = value
      } else {
        this.items[idx] = value
      }
    }
    toJSON(_, ctx) {
      const seq = []
      if (ctx?.onCreate) {
        ctx.onCreate(seq)
      }
      let i = 0
      for (const item of this.items) {
        seq.push(toJS.toJS(item, String(i++), ctx))
      }
      return seq
    }
    toString(ctx, onComment, onChompKeep) {
      if (!ctx) {
        return JSON.stringify(this)
      }
      return stringifyCollection.stringifyCollection(this, ctx, {
        blockItemPrefix: '- ',
        flowChars: {
          start: '[',
          end: ']'
        },
        itemIndent: (ctx.indent || '') + '  ',
        onChompKeep,
        onComment
      })
    }
    static from(schema, obj, ctx) {
      const { replacer } = ctx
      const seq = new this(schema)
      if (obj && Symbol.iterator in Object(obj)) {
        let i = 0
        for (let it of obj) {
          if (typeof replacer === 'function') {
            const key = obj instanceof Set ? it : String(i++)
            it = replacer.call(obj, key, it)
          }
          seq.items.push(createNode.createNode(it, undefined, ctx))
        }
      }
      return seq
    }
  }
  function asItemIndex(key) {
    let idx = identity.isScalar(key) ? key.value : key
    if (idx && typeof idx === 'string') {
      idx = Number(idx)
    }
    return typeof idx === 'number' && Number.isInteger(idx) && idx >= 0
      ? idx
      : null
  }
  YAMLSeq.YAMLSeq = YAMLSeq$1
  return YAMLSeq
}

let hasRequiredSeq$1
function requireSeq$1() {
  if (hasRequiredSeq$1) {
    return seq$1
  }
  hasRequiredSeq$1 = 1
  const identity = requireIdentity()
  const YAMLSeq = requireYAMLSeq()
  const seq = {
    collection: 'seq',
    default: true,
    nodeClass: YAMLSeq.YAMLSeq,
    tag: 'tag:yaml.org,2002:seq',
    resolve(seq, onError) {
      if (!identity.isSeq(seq)) {
        onError('Expected a sequence for this tag')
      }
      return seq
    },
    createNode: (schema, obj, ctx) => YAMLSeq.YAMLSeq.from(schema, obj, ctx)
  }
  seq$1.seq = seq
  return seq$1
}

const string = {}

let hasRequiredString
function requireString() {
  if (hasRequiredString) {
    return string
  }
  hasRequiredString = 1
  const stringifyString = requireStringifyString()
  const string$1 = {
    identify: value => typeof value === 'string',
    default: true,
    tag: 'tag:yaml.org,2002:str',
    resolve: str => str,
    stringify(item, ctx, onComment, onChompKeep) {
      ctx = Object.assign(
        {
          actualString: true
        },
        ctx
      )
      return stringifyString.stringifyString(item, ctx, onComment, onChompKeep)
    }
  }
  string.string = string$1
  return string
}

const tags = {}

const _null$1 = {}

let hasRequired_null$1
function require_null$1() {
  if (hasRequired_null$1) {
    return _null$1
  }
  hasRequired_null$1 = 1
  const Scalar = requireScalar()
  const nullTag = {
    identify: value => value == null,
    createNode: () => new Scalar.Scalar(null),
    default: true,
    tag: 'tag:yaml.org,2002:null',
    test: /^(?:~|[Nn]ull|NULL)?$/,
    resolve: () => new Scalar.Scalar(null),
    stringify: ({ source }, ctx) =>
      typeof source === 'string' && nullTag.test.test(source)
        ? source
        : ctx.options.nullStr
  }
  _null$1.nullTag = nullTag
  return _null$1
}

const bool$2 = {}

let hasRequiredBool$2
function requireBool$2() {
  if (hasRequiredBool$2) {
    return bool$2
  }
  hasRequiredBool$2 = 1
  const Scalar = requireScalar()
  const boolTag = {
    identify: value => typeof value === 'boolean',
    default: true,
    tag: 'tag:yaml.org,2002:bool',
    test: /^(?:[Tt]rue|TRUE|[Ff]alse|FALSE)$/,
    resolve: str => new Scalar.Scalar(str[0] === 't' || str[0] === 'T'),
    stringify({ source, value }, ctx) {
      if (source && boolTag.test.test(source)) {
        const sv = source[0] === 't' || source[0] === 'T'
        if (value === sv) {
          return source
        }
      }
      return value ? ctx.options.trueStr : ctx.options.falseStr
    }
  }
  bool$2.boolTag = boolTag
  return bool$2
}

const float$2 = {}

const stringifyNumber = {}

let hasRequiredStringifyNumber
function requireStringifyNumber() {
  if (hasRequiredStringifyNumber) {
    return stringifyNumber
  }
  hasRequiredStringifyNumber = 1
  function stringifyNumber$1({ format, minFractionDigits, tag, value }) {
    if (typeof value === 'bigint') {
      return String(value)
    }
    const num = typeof value === 'number' ? value : Number(value)
    if (!isFinite(num)) {
      return isNaN(num) ? '.nan' : num < 0 ? '-.inf' : '.inf'
    }
    let n = JSON.stringify(value)
    if (
      !format &&
      minFractionDigits &&
      (!tag || tag === 'tag:yaml.org,2002:float') &&
      /^\d/.test(n)
    ) {
      let i = n.indexOf('.')
      if (i < 0) {
        i = n.length
        n += '.'
      }
      let d = minFractionDigits - (n.length - i - 1)
      while (d-- > 0) {
        n += '0'
      }
    }
    return n
  }
  stringifyNumber.stringifyNumber = stringifyNumber$1
  return stringifyNumber
}

let hasRequiredFloat$2
function requireFloat$2() {
  if (hasRequiredFloat$2) {
    return float$2
  }
  hasRequiredFloat$2 = 1
  const Scalar = requireScalar()
  const stringifyNumber = requireStringifyNumber()
  const floatNaN = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    test: /^(?:[-+]?\.(?:inf|Inf|INF)|\.nan|\.NaN|\.NAN)$/,
    resolve: str =>
      str.slice(-3).toLowerCase() === 'nan'
        ? NaN
        : str[0] === '-'
          ? Number.NEGATIVE_INFINITY
          : Number.POSITIVE_INFINITY,
    stringify: stringifyNumber.stringifyNumber
  }
  const floatExp = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    format: 'EXP',
    test: /^[-+]?(?:\.[0-9]+|[0-9]+(?:\.[0-9]*)?)[eE][-+]?[0-9]+$/,
    resolve: str => parseFloat(str),
    stringify(node) {
      const num = Number(node.value)
      return isFinite(num)
        ? num.toExponential()
        : stringifyNumber.stringifyNumber(node)
    }
  }
  const float = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    test: /^[-+]?(?:\.[0-9]+|[0-9]+\.[0-9]*)$/,
    resolve(str) {
      const node = new Scalar.Scalar(parseFloat(str))
      const dot = str.indexOf('.')
      if (dot !== -1 && str[str.length - 1] === '0') {
        node.minFractionDigits = str.length - dot - 1
      }
      return node
    },
    stringify: stringifyNumber.stringifyNumber
  }
  float$2.float = float
  float$2.floatExp = floatExp
  float$2.floatNaN = floatNaN
  return float$2
}

const int$2 = {}

let hasRequiredInt$2
function requireInt$2() {
  if (hasRequiredInt$2) {
    return int$2
  }
  hasRequiredInt$2 = 1
  const stringifyNumber = requireStringifyNumber()
  const intIdentify = value =>
    typeof value === 'bigint' || Number.isInteger(value)
  const intResolve = (str, offset, radix, { intAsBigInt }) =>
    intAsBigInt ? BigInt(str) : parseInt(str.substring(offset), radix)
  function intStringify(node, radix, prefix) {
    const { value } = node
    if (intIdentify(value) && value >= 0) {
      return prefix + value.toString(radix)
    }
    return stringifyNumber.stringifyNumber(node)
  }
  const intOct = {
    identify: value => intIdentify(value) && value >= 0,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'OCT',
    test: /^0o[0-7]+$/,
    resolve: (str, _onError, opt) => intResolve(str, 2, 8, opt),
    stringify: node => intStringify(node, 8, '0o')
  }
  const int = {
    identify: intIdentify,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    test: /^[-+]?[0-9]+$/,
    resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),
    stringify: stringifyNumber.stringifyNumber
  }
  const intHex = {
    identify: value => intIdentify(value) && value >= 0,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'HEX',
    test: /^0x[0-9a-fA-F]+$/,
    resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),
    stringify: node => intStringify(node, 16, '0x')
  }
  int$2.int = int
  int$2.intHex = intHex
  int$2.intOct = intOct
  return int$2
}

const schema$3 = {}

let hasRequiredSchema$4
function requireSchema$4() {
  if (hasRequiredSchema$4) {
    return schema$3
  }
  hasRequiredSchema$4 = 1
  const map = requireMap$2()
  const _null = require_null$1()
  const seq = requireSeq$1()
  const string = requireString()
  const bool = requireBool$2()
  const float = requireFloat$2()
  const int = requireInt$2()
  const schema = [
    map.map,
    seq.seq,
    string.string,
    _null.nullTag,
    bool.boolTag,
    int.intOct,
    int.int,
    int.intHex,
    float.floatNaN,
    float.floatExp,
    float.float
  ]
  schema$3.schema = schema
  return schema$3
}

const schema$2 = {}

let hasRequiredSchema$3
function requireSchema$3() {
  if (hasRequiredSchema$3) {
    return schema$2
  }
  hasRequiredSchema$3 = 1
  const Scalar = requireScalar()
  const map = requireMap$2()
  const seq = requireSeq$1()
  function intIdentify(value) {
    return typeof value === 'bigint' || Number.isInteger(value)
  }
  const stringifyJSON = ({ value }) => JSON.stringify(value)
  const jsonScalars = [
    {
      identify: value => typeof value === 'string',
      default: true,
      tag: 'tag:yaml.org,2002:str',
      resolve: str => str,
      stringify: stringifyJSON
    },
    {
      identify: value => value == null,
      createNode: () => new Scalar.Scalar(null),
      default: true,
      tag: 'tag:yaml.org,2002:null',
      test: /^null$/,
      resolve: () => null,
      stringify: stringifyJSON
    },
    {
      identify: value => typeof value === 'boolean',
      default: true,
      tag: 'tag:yaml.org,2002:bool',
      test: /^true$|^false$/,
      resolve: str => str === 'true',
      stringify: stringifyJSON
    },
    {
      identify: intIdentify,
      default: true,
      tag: 'tag:yaml.org,2002:int',
      test: /^-?(?:0|[1-9][0-9]*)$/,
      resolve: (str, _onError, { intAsBigInt }) =>
        intAsBigInt ? BigInt(str) : parseInt(str, 10),
      stringify: ({ value }) =>
        intIdentify(value) ? value.toString() : JSON.stringify(value)
    },
    {
      identify: value => typeof value === 'number',
      default: true,
      tag: 'tag:yaml.org,2002:float',
      test: /^-?(?:0|[1-9][0-9]*)(?:\.[0-9]*)?(?:[eE][-+]?[0-9]+)?$/,
      resolve: str => parseFloat(str),
      stringify: stringifyJSON
    }
  ]
  const jsonError = {
    default: true,
    tag: '',
    test: /^/,
    resolve(str, onError) {
      onError(`Unresolved plain scalar ${JSON.stringify(str)}`)
      return str
    }
  }
  const schema = [map.map, seq.seq].concat(jsonScalars, jsonError)
  schema$2.schema = schema
  return schema$2
}

const binary$1 = {}

let hasRequiredBinary$1
function requireBinary$1() {
  if (hasRequiredBinary$1) {
    return binary$1
  }
  hasRequiredBinary$1 = 1
  const node_buffer = require$$0$3
  const Scalar = requireScalar()
  const stringifyString = requireStringifyString()
  const binary = {
    identify: value => value instanceof Uint8Array,
    // Buffer inherits from Uint8Array
    default: false,
    tag: 'tag:yaml.org,2002:binary',
    /**
     * Returns a Buffer in node and an Uint8Array in browsers
     *
     * To use the resulting buffer as an image, you'll want to do something like:
     *
     *   const blob = new Blob([buffer], { type: 'image/jpeg' })
     *   document.querySelector('#photo').src = URL.createObjectURL(blob)
     */
    resolve(src, onError) {
      if (typeof node_buffer.Buffer === 'function') {
        return node_buffer.Buffer.from(src, 'base64')
      } else if (typeof atob === 'function') {
        // On IE 11, atob() can't handle newlines
        const str = atob(src.replace(/[\n\r]/g, ''))
        const buffer = new Uint8Array(str.length)
        for (let i = 0; i < str.length; ++i) {
          buffer[i] = str.charCodeAt(i)
        }
        return buffer
      } else {
        onError(
          'This environment does not support reading binary tags; either Buffer or atob is required'
        )
        return src
      }
    },
    stringify({ comment, type, value }, ctx, onComment, onChompKeep) {
      if (!value) {
        return ''
      }
      const buf = value // checked earlier by binary.identify()
      let str
      if (typeof node_buffer.Buffer === 'function') {
        str =
          buf instanceof node_buffer.Buffer
            ? buf.toString('base64')
            : node_buffer.Buffer.from(buf.buffer).toString('base64')
      } else if (typeof btoa === 'function') {
        let s = ''
        for (let i = 0; i < buf.length; ++i) {
          s += String.fromCharCode(buf[i])
        }
        str = btoa(s)
      } else {
        throw new Error(
          'This environment does not support writing binary tags; either Buffer or btoa is required'
        )
      }
      if (!type) {
        type = Scalar.Scalar.BLOCK_LITERAL
      }
      if (type !== Scalar.Scalar.QUOTE_DOUBLE) {
        const lineWidth = Math.max(
          ctx.options.lineWidth - ctx.indent.length,
          ctx.options.minContentWidth
        )
        const n = Math.ceil(str.length / lineWidth)
        const lines = new Array(n)
        for (let i = 0, o = 0; i < n; ++i, o += lineWidth) {
          lines[i] = str.substr(o, lineWidth)
        }
        str = lines.join(type === Scalar.Scalar.BLOCK_LITERAL ? '\n' : ' ')
      }
      return stringifyString.stringifyString(
        {
          comment,
          type,
          value: str
        },
        ctx,
        onComment,
        onChompKeep
      )
    }
  }
  binary$1.binary = binary
  return binary$1
}

const omap$1 = {}

const pairs$1 = {}

let hasRequiredPairs$1
function requirePairs$1() {
  if (hasRequiredPairs$1) {
    return pairs$1
  }
  hasRequiredPairs$1 = 1
  const identity = requireIdentity()
  const Pair = requirePair()
  const Scalar = requireScalar()
  const YAMLSeq = requireYAMLSeq()
  function resolvePairs(seq, onError) {
    if (identity.isSeq(seq)) {
      for (let i = 0; i < seq.items.length; ++i) {
        let item = seq.items[i]
        if (identity.isPair(item)) {
          continue
        } else if (identity.isMap(item)) {
          if (item.items.length > 1) {
            onError('Each pair must have its own sequence indicator')
          }
          const pair = item.items[0] || new Pair.Pair(new Scalar.Scalar(null))
          if (item.commentBefore) {
            pair.key.commentBefore = pair.key.commentBefore
              ? `${item.commentBefore}\n${pair.key.commentBefore}`
              : item.commentBefore
          }
          if (item.comment) {
            const cn = pair.value ?? pair.key
            cn.comment = cn.comment
              ? `${item.comment}\n${cn.comment}`
              : item.comment
          }
          item = pair
        }
        seq.items[i] = identity.isPair(item) ? item : new Pair.Pair(item)
      }
    } else {
      onError('Expected a sequence for this tag')
    }
    return seq
  }
  function createPairs(schema, iterable, ctx) {
    const { replacer } = ctx
    const pairs = new YAMLSeq.YAMLSeq(schema)
    pairs.tag = 'tag:yaml.org,2002:pairs'
    let i = 0
    if (iterable && Symbol.iterator in Object(iterable)) {
      for (let it of iterable) {
        if (typeof replacer === 'function')
          it = replacer.call(iterable, String(i++), it)
        let key, value
        if (Array.isArray(it)) {
          if (it.length === 2) {
            key = it[0]
            value = it[1]
          } else throw new TypeError(`Expected [key, value] tuple: ${it}`)
        } else if (it && it instanceof Object) {
          const keys = Object.keys(it)
          if (keys.length === 1) {
            key = keys[0]
            value = it[key]
          } else {
            throw new TypeError(
              `Expected tuple with one key, not ${keys.length} keys`
            )
          }
        } else {
          key = it
        }
        pairs.items.push(Pair.createPair(key, value, ctx))
      }
    }
    return pairs
  }
  const pairs = {
    collection: 'seq',
    default: false,
    tag: 'tag:yaml.org,2002:pairs',
    resolve: resolvePairs,
    createNode: createPairs
  }
  pairs$1.createPairs = createPairs
  pairs$1.pairs = pairs
  pairs$1.resolvePairs = resolvePairs
  return pairs$1
}

let hasRequiredOmap$1
function requireOmap$1() {
  if (hasRequiredOmap$1) {
    return omap$1
  }
  hasRequiredOmap$1 = 1
  const identity = requireIdentity()
  const toJS = requireToJS()
  const YAMLMap = requireYAMLMap()
  const YAMLSeq = requireYAMLSeq()
  const pairs = requirePairs$1()
  class YAMLOMap extends YAMLSeq.YAMLSeq {
    constructor() {
      super()
      this.add = YAMLMap.YAMLMap.prototype.add.bind(this)
      this.delete = YAMLMap.YAMLMap.prototype.delete.bind(this)
      this.get = YAMLMap.YAMLMap.prototype.get.bind(this)
      this.has = YAMLMap.YAMLMap.prototype.has.bind(this)
      this.set = YAMLMap.YAMLMap.prototype.set.bind(this)
      this.tag = YAMLOMap.tag
    }
    /**
     * If `ctx` is given, the return type is actually `Map<unknown, unknown>`,
     * but TypeScript won't allow widening the signature of a child method.
     */
    toJSON(_, ctx) {
      if (!ctx) {
        return super.toJSON(_)
      }
      const map = new Map()
      if (ctx?.onCreate) {
        ctx.onCreate(map)
      }
      for (const pair of this.items) {
        let key, value
        if (identity.isPair(pair)) {
          key = toJS.toJS(pair.key, '', ctx)
          value = toJS.toJS(pair.value, key, ctx)
        } else {
          key = toJS.toJS(pair, '', ctx)
        }
        if (map.has(key)) {
          throw new Error('Ordered maps must not include duplicate keys')
        }
        map.set(key, value)
      }
      return map
    }
    static from(schema, iterable, ctx) {
      const pairs$1 = pairs.createPairs(schema, iterable, ctx)
      const omap = new this()
      omap.items = pairs$1.items
      return omap
    }
  }
  YAMLOMap.tag = 'tag:yaml.org,2002:omap'
  const omap = {
    collection: 'seq',
    identify: value => value instanceof Map,
    nodeClass: YAMLOMap,
    default: false,
    tag: 'tag:yaml.org,2002:omap',
    resolve(seq, onError) {
      const pairs$1 = pairs.resolvePairs(seq, onError)
      const seenKeys = []
      for (const { key } of pairs$1.items) {
        if (identity.isScalar(key)) {
          if (seenKeys.includes(key.value)) {
            onError(
              `Ordered maps must not include duplicate keys: ${key.value}`
            )
          } else {
            seenKeys.push(key.value)
          }
        }
      }
      return Object.assign(new YAMLOMap(), pairs$1)
    },
    createNode: (schema, iterable, ctx) => YAMLOMap.from(schema, iterable, ctx)
  }
  omap$1.YAMLOMap = YAMLOMap
  omap$1.omap = omap
  return omap$1
}

const schema$1 = {}

const bool$1 = {}

let hasRequiredBool$1
function requireBool$1() {
  if (hasRequiredBool$1) {
    return bool$1
  }
  hasRequiredBool$1 = 1
  const Scalar = requireScalar()
  function boolStringify({ value, source }, ctx) {
    const boolObj = value ? trueTag : falseTag
    if (source && boolObj.test.test(source)) {
      return source
    }
    return value ? ctx.options.trueStr : ctx.options.falseStr
  }
  const trueTag = {
    identify: value => value === true,
    default: true,
    tag: 'tag:yaml.org,2002:bool',
    test: /^(?:Y|y|[Yy]es|YES|[Tt]rue|TRUE|[Oo]n|ON)$/,
    resolve: () => new Scalar.Scalar(true),
    stringify: boolStringify
  }
  const falseTag = {
    identify: value => value === false,
    default: true,
    tag: 'tag:yaml.org,2002:bool',
    test: /^(?:N|n|[Nn]o|NO|[Ff]alse|FALSE|[Oo]ff|OFF)$/,
    resolve: () => new Scalar.Scalar(false),
    stringify: boolStringify
  }
  bool$1.falseTag = falseTag
  bool$1.trueTag = trueTag
  return bool$1
}

const float$1 = {}

let hasRequiredFloat$1
function requireFloat$1() {
  if (hasRequiredFloat$1) {
    return float$1
  }
  hasRequiredFloat$1 = 1
  const Scalar = requireScalar()
  const stringifyNumber = requireStringifyNumber()
  const floatNaN = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    test: /^(?:[-+]?\.(?:inf|Inf|INF)|\.nan|\.NaN|\.NAN)$/,
    resolve: str =>
      str.slice(-3).toLowerCase() === 'nan'
        ? NaN
        : str[0] === '-'
          ? Number.NEGATIVE_INFINITY
          : Number.POSITIVE_INFINITY,
    stringify: stringifyNumber.stringifyNumber
  }
  const floatExp = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    format: 'EXP',
    test: /^[-+]?(?:[0-9][0-9_]*)?(?:\.[0-9_]*)?[eE][-+]?[0-9]+$/,
    resolve: str => parseFloat(str.replace(/_/g, '')),
    stringify(node) {
      const num = Number(node.value)
      return isFinite(num)
        ? num.toExponential()
        : stringifyNumber.stringifyNumber(node)
    }
  }
  const float = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    test: /^[-+]?(?:[0-9][0-9_]*)?\.[0-9_]*$/,
    resolve(str) {
      const node = new Scalar.Scalar(parseFloat(str.replace(/_/g, '')))
      const dot = str.indexOf('.')
      if (dot !== -1) {
        const f = str.substring(dot + 1).replace(/_/g, '')
        if (f[f.length - 1] === '0') {
          node.minFractionDigits = f.length
        }
      }
      return node
    },
    stringify: stringifyNumber.stringifyNumber
  }
  float$1.float = float
  float$1.floatExp = floatExp
  float$1.floatNaN = floatNaN
  return float$1
}

const int$1 = {}

let hasRequiredInt$1
function requireInt$1() {
  if (hasRequiredInt$1) {
    return int$1
  }
  hasRequiredInt$1 = 1
  const stringifyNumber = requireStringifyNumber()
  const intIdentify = value =>
    typeof value === 'bigint' || Number.isInteger(value)
  function intResolve(str, offset, radix, { intAsBigInt }) {
    const sign = str[0]
    if (sign === '-' || sign === '+') {
      offset += 1
    }
    str = str.substring(offset).replace(/_/g, '')
    if (intAsBigInt) {
      switch (radix) {
        case 2:
          str = `0b${str}`
          break
        case 8:
          str = `0o${str}`
          break
        case 16:
          str = `0x${str}`
          break
      }
      const n = BigInt(str)
      return sign === '-' ? BigInt(-1) * n : n
    }
    const n = parseInt(str, radix)
    return sign === '-' ? -1 * n : n
  }
  function intStringify(node, radix, prefix) {
    const { value } = node
    if (intIdentify(value)) {
      const str = value.toString(radix)
      return value < 0 ? '-' + prefix + str.substr(1) : prefix + str
    }
    return stringifyNumber.stringifyNumber(node)
  }
  const intBin = {
    identify: intIdentify,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'BIN',
    test: /^[-+]?0b[0-1_]+$/,
    resolve: (str, _onError, opt) => intResolve(str, 2, 2, opt),
    stringify: node => intStringify(node, 2, '0b')
  }
  const intOct = {
    identify: intIdentify,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'OCT',
    test: /^[-+]?0[0-7_]+$/,
    resolve: (str, _onError, opt) => intResolve(str, 1, 8, opt),
    stringify: node => intStringify(node, 8, '0')
  }
  const int = {
    identify: intIdentify,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    test: /^[-+]?[0-9][0-9_]*$/,
    resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),
    stringify: stringifyNumber.stringifyNumber
  }
  const intHex = {
    identify: intIdentify,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'HEX',
    test: /^[-+]?0x[0-9a-fA-F_]+$/,
    resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),
    stringify: node => intStringify(node, 16, '0x')
  }
  int$1.int = int
  int$1.intBin = intBin
  int$1.intHex = intHex
  int$1.intOct = intOct
  return int$1
}

const set$1 = {}

let hasRequiredSet$1
function requireSet$1() {
  if (hasRequiredSet$1) {
    return set$1
  }
  hasRequiredSet$1 = 1
  const identity = requireIdentity()
  const Pair = requirePair()
  const YAMLMap = requireYAMLMap()
  class YAMLSet extends YAMLMap.YAMLMap {
    constructor(schema) {
      super(schema)
      this.tag = YAMLSet.tag
    }
    add(key) {
      let pair
      if (identity.isPair(key)) {
        pair = key
      } else if (
        key &&
        typeof key === 'object' &&
        'key' in key &&
        'value' in key &&
        key.value === null
      ) {
        pair = new Pair.Pair(key.key, null)
      } else {
        pair = new Pair.Pair(key, null)
      }
      const prev = YAMLMap.findPair(this.items, pair.key)
      if (!prev) {
        this.items.push(pair)
      }
    }
    /**
     * If `keepPair` is `true`, returns the Pair matching `key`.
     * Otherwise, returns the value of that Pair's key.
     */
    get(key, keepPair) {
      const pair = YAMLMap.findPair(this.items, key)
      return !keepPair && identity.isPair(pair)
        ? identity.isScalar(pair.key)
          ? pair.key.value
          : pair.key
        : pair
    }
    set(key, value) {
      if (typeof value !== 'boolean') {
        throw new Error(
          `Expected boolean value for set(key, value) in a YAML set, not ${typeof value}`
        )
      }
      const prev = YAMLMap.findPair(this.items, key)
      if (prev && !value) {
        this.items.splice(this.items.indexOf(prev), 1)
      } else if (!prev && value) {
        this.items.push(new Pair.Pair(key))
      }
    }
    toJSON(_, ctx) {
      return super.toJSON(_, ctx, Set)
    }
    toString(ctx, onComment, onChompKeep) {
      if (!ctx) {
        return JSON.stringify(this)
      }
      if (this.hasAllNullValues(true)) {
        return super.toString(
          Object.assign({}, ctx, {
            allNullValues: true
          }),
          onComment,
          onChompKeep
        )
      } else {
        throw new Error('Set items must all have null values')
      }
    }
    static from(schema, iterable, ctx) {
      const { replacer } = ctx
      const set = new this(schema)
      if (iterable && Symbol.iterator in Object(iterable)) {
        for (let value of iterable) {
          if (typeof replacer === 'function')
            value = replacer.call(iterable, value, value)
          set.items.push(Pair.createPair(value, null, ctx))
        }
      }
      return set
    }
  }
  YAMLSet.tag = 'tag:yaml.org,2002:set'
  const set = {
    collection: 'map',
    identify: value => value instanceof Set,
    nodeClass: YAMLSet,
    default: false,
    tag: 'tag:yaml.org,2002:set',
    createNode: (schema, iterable, ctx) => YAMLSet.from(schema, iterable, ctx),
    resolve(map, onError) {
      if (identity.isMap(map)) {
        if (map.hasAllNullValues(true)) {
          return Object.assign(new YAMLSet(), map)
        } else {
          onError('Set items must all have null values')
        }
      } else {
        onError('Expected a mapping for this tag')
      }
      return map
    }
  }
  set$1.YAMLSet = YAMLSet
  set$1.set = set
  return set$1
}

const timestamp$1 = {}

let hasRequiredTimestamp$1
function requireTimestamp$1() {
  if (hasRequiredTimestamp$1) {
    return timestamp$1
  }
  hasRequiredTimestamp$1 = 1
  const stringifyNumber = requireStringifyNumber()

  /** Internal types handle bigint as number, because TS can't figure it out. */
  function parseSexagesimal(str, asBigInt) {
    const sign = str[0]
    const parts = sign === '-' || sign === '+' ? str.substring(1) : str
    const num = n => (asBigInt ? BigInt(n) : Number(n))
    const res = parts
      .replace(/_/g, '')
      .split(':')
      .reduce((res, p) => res * num(60) + num(p), num(0))
    return sign === '-' ? num(-1) * res : res
  }
  /**
   * hhhh:mm:ss.sss
   *
   * Internal types handle bigint as number, because TS can't figure it out.
   */
  function stringifySexagesimal(node) {
    let { value } = node
    let num = n => n
    if (typeof value === 'bigint') {
      num = n => BigInt(n)
    } else if (isNaN(value) || !isFinite(value)) {
      return stringifyNumber.stringifyNumber(node)
    }
    let sign = ''
    if (value < 0) {
      sign = '-'
      value *= num(-1)
    }
    const _60 = num(60)
    const parts = [value % _60] // seconds, including ms
    if (value < 60) {
      parts.unshift(0) // at least one : is required
    } else {
      value = (value - parts[0]) / _60
      parts.unshift(value % _60) // minutes
      if (value >= 60) {
        value = (value - parts[0]) / _60
        parts.unshift(value) // hours
      }
    }
    return (
      sign +
      parts
        .map(n => String(n).padStart(2, '0'))
        .join(':')
        .replace(/000000\d*$/, '') // % 60 may introduce error
    )
  }
  const intTime = {
    identify: value => typeof value === 'bigint' || Number.isInteger(value),
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'TIME',
    test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+$/,
    resolve: (str, _onError, { intAsBigInt }) =>
      parseSexagesimal(str, intAsBigInt),
    stringify: stringifySexagesimal
  }
  const floatTime = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    format: 'TIME',
    test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\.[0-9_]*$/,
    resolve: str => parseSexagesimal(str, false),
    stringify: stringifySexagesimal
  }
  const timestamp = {
    identify: value => value instanceof Date,
    default: true,
    tag: 'tag:yaml.org,2002:timestamp',
    // If the time zone is omitted, the timestamp is assumed to be specified in UTC. The time part
    // may be omitted altogether, resulting in a date format. In such a case, the time part is
    // assumed to be 00:00:00Z (start of day, UTC).
    test: RegExp(
      '^([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})' +
        // YYYY-Mm-Dd
        '(?:' +
        // time is optional
        '(?:t|T|[ \\t]+)' +
        // t | T | whitespace
        '([0-9]{1,2}):([0-9]{1,2}):([0-9]{1,2}(\\.[0-9]+)?)' +
        // Hh:Mm:Ss(.ss)?
        '(?:[ \\t]*(Z|[-+][012]?[0-9](?::[0-9]{2})?))?' +
        // Z | +5 | -03:30
        ')?$'
    ),
    resolve(str) {
      const match = str.match(timestamp.test)
      if (!match) {
        throw new Error('!!timestamp expects a date, starting with yyyy-mm-dd')
      }
      const [, year, month, day, hour, minute, second] = match.map(Number)
      const millisec = match[7] ? Number((match[7] + '00').substr(1, 3)) : 0
      let date = Date.UTC(
        year,
        month - 1,
        day,
        hour || 0,
        minute || 0,
        second || 0,
        millisec
      )
      const tz = match[8]
      if (tz && tz !== 'Z') {
        let d = parseSexagesimal(tz, false)
        if (Math.abs(d) < 30) {
          d *= 60
        }
        date -= 60000 * d
      }
      return new Date(date)
    },
    stringify: ({ value }) =>
      value?.toISOString().replace(/(T00:00:00)?\.000Z$/, '') ?? ''
  }
  timestamp$1.floatTime = floatTime
  timestamp$1.intTime = intTime
  timestamp$1.timestamp = timestamp
  return timestamp$1
}

let hasRequiredSchema$2
function requireSchema$2() {
  if (hasRequiredSchema$2) {
    return schema$1
  }
  hasRequiredSchema$2 = 1
  const map = requireMap$2()
  const _null = require_null$1()
  const seq = requireSeq$1()
  const string = requireString()
  const binary = requireBinary$1()
  const bool = requireBool$1()
  const float = requireFloat$1()
  const int = requireInt$1()
  const merge = requireMerge$1()
  const omap = requireOmap$1()
  const pairs = requirePairs$1()
  const set = requireSet$1()
  const timestamp = requireTimestamp$1()
  const schema = [
    map.map,
    seq.seq,
    string.string,
    _null.nullTag,
    bool.trueTag,
    bool.falseTag,
    int.intBin,
    int.intOct,
    int.int,
    int.intHex,
    float.floatNaN,
    float.floatExp,
    float.float,
    binary.binary,
    merge.merge,
    omap.omap,
    pairs.pairs,
    set.set,
    timestamp.intTime,
    timestamp.floatTime,
    timestamp.timestamp
  ]
  schema$1.schema = schema
  return schema$1
}

let hasRequiredTags
function requireTags() {
  if (hasRequiredTags) {
    return tags
  }
  hasRequiredTags = 1
  const map = requireMap$2()
  const _null = require_null$1()
  const seq = requireSeq$1()
  const string = requireString()
  const bool = requireBool$2()
  const float = requireFloat$2()
  const int = requireInt$2()
  const schema = requireSchema$4()
  const schema$1 = requireSchema$3()
  const binary = requireBinary$1()
  const merge = requireMerge$1()
  const omap = requireOmap$1()
  const pairs = requirePairs$1()
  const schema$2 = requireSchema$2()
  const set = requireSet$1()
  const timestamp = requireTimestamp$1()
  const schemas = new Map([
    ['core', schema.schema],
    ['failsafe', [map.map, seq.seq, string.string]],
    ['json', schema$1.schema],
    ['yaml11', schema$2.schema],
    ['yaml-1.1', schema$2.schema]
  ])
  const tagsByName = {
    binary: binary.binary,
    bool: bool.boolTag,
    float: float.float,
    floatExp: float.floatExp,
    floatNaN: float.floatNaN,
    floatTime: timestamp.floatTime,
    int: int.int,
    intHex: int.intHex,
    intOct: int.intOct,
    intTime: timestamp.intTime,
    map: map.map,
    merge: merge.merge,
    null: _null.nullTag,
    omap: omap.omap,
    pairs: pairs.pairs,
    seq: seq.seq,
    set: set.set,
    timestamp: timestamp.timestamp
  }
  const coreKnownTags = {
    'tag:yaml.org,2002:binary': binary.binary,
    'tag:yaml.org,2002:merge': merge.merge,
    'tag:yaml.org,2002:omap': omap.omap,
    'tag:yaml.org,2002:pairs': pairs.pairs,
    'tag:yaml.org,2002:set': set.set,
    'tag:yaml.org,2002:timestamp': timestamp.timestamp
  }
  function getTags(customTags, schemaName, addMergeTag) {
    const schemaTags = schemas.get(schemaName)
    if (schemaTags && !customTags) {
      return addMergeTag && !schemaTags.includes(merge.merge)
        ? schemaTags.concat(merge.merge)
        : schemaTags.slice()
    }
    let tags = schemaTags
    if (!tags) {
      if (Array.isArray(customTags)) {
        tags = []
      } else {
        const keys = Array.from(schemas.keys())
          .filter(key => key !== 'yaml11')
          .map(key => JSON.stringify(key))
          .join(', ')
        throw new Error(
          `Unknown schema "${schemaName}"; use one of ${keys} or define customTags array`
        )
      }
    }
    if (Array.isArray(customTags)) {
      for (const tag of customTags) {
        tags = tags.concat(tag)
      }
    } else if (typeof customTags === 'function') {
      tags = customTags(tags.slice())
    }
    if (addMergeTag) {
      tags = tags.concat(merge.merge)
    }
    return tags.reduce((tags, tag) => {
      const tagObj = typeof tag === 'string' ? tagsByName[tag] : tag
      if (!tagObj) {
        const tagName = JSON.stringify(tag)
        const keys = Object.keys(tagsByName)
          .map(key => JSON.stringify(key))
          .join(', ')
        throw new Error(`Unknown custom tag ${tagName}; use one of ${keys}`)
      }
      if (!tags.includes(tagObj)) {
        tags.push(tagObj)
      }
      return tags
    }, [])
  }
  tags.coreKnownTags = coreKnownTags
  tags.getTags = getTags
  return tags
}

let hasRequiredSchema$1
function requireSchema$1() {
  if (hasRequiredSchema$1) {
    return Schema
  }
  hasRequiredSchema$1 = 1
  const identity = requireIdentity()
  const map = requireMap$2()
  const seq = requireSeq$1()
  const string = requireString()
  const tags = requireTags()
  const sortMapEntriesByKey = (a, b) =>
    a.key < b.key ? -1 : a.key > b.key ? 1 : 0
  let Schema$1 = class Schema {
    constructor({
      compat,
      customTags,
      merge,
      resolveKnownTags,
      schema,
      sortMapEntries,
      toStringDefaults
    }) {
      this.compat = Array.isArray(compat)
        ? tags.getTags(compat, 'compat')
        : compat
          ? tags.getTags(null, compat)
          : null
      this.name = (typeof schema === 'string' && schema) || 'core'
      this.knownTags = resolveKnownTags ? tags.coreKnownTags : {}
      this.tags = tags.getTags(customTags, this.name, merge)
      this.toStringOptions = toStringDefaults ?? null
      Object.defineProperty(this, identity.MAP, {
        value: map.map
      })
      Object.defineProperty(this, identity.SCALAR, {
        value: string.string
      })
      Object.defineProperty(this, identity.SEQ, {
        value: seq.seq
      })
      // Used by createMap()
      this.sortMapEntries =
        typeof sortMapEntries === 'function'
          ? sortMapEntries
          : sortMapEntries === true
            ? sortMapEntriesByKey
            : null
    }
    clone() {
      const copy = Object.create(
        Schema.prototype,
        Object.getOwnPropertyDescriptors(this)
      )
      copy.tags = this.tags.slice()
      return copy
    }
  }
  Schema.Schema = Schema$1
  return Schema
}

const stringifyDocument = {}

let hasRequiredStringifyDocument
function requireStringifyDocument() {
  if (hasRequiredStringifyDocument) {
    return stringifyDocument
  }
  hasRequiredStringifyDocument = 1
  const identity = requireIdentity()
  const stringify = requireStringify$2()
  const stringifyComment = requireStringifyComment()
  function stringifyDocument$1(doc, options) {
    const lines = []
    let hasDirectives = options.directives === true
    if (options.directives !== false && doc.directives) {
      const dir = doc.directives.toString(doc)
      if (dir) {
        lines.push(dir)
        hasDirectives = true
      } else if (doc.directives.docStart) {
        hasDirectives = true
      }
    }
    if (hasDirectives) {
      lines.push('---')
    }
    const ctx = stringify.createStringifyContext(doc, options)
    const { commentString } = ctx.options
    if (doc.commentBefore) {
      if (lines.length !== 1) {
        lines.unshift('')
      }
      const cs = commentString(doc.commentBefore)
      lines.unshift(stringifyComment.indentComment(cs, ''))
    }
    let chompKeep = false
    let contentComment = null
    if (doc.contents) {
      if (identity.isNode(doc.contents)) {
        if (doc.contents.spaceBefore && hasDirectives) {
          lines.push('')
        }
        if (doc.contents.commentBefore) {
          const cs = commentString(doc.contents.commentBefore)
          lines.push(stringifyComment.indentComment(cs, ''))
        }
        // top-level block scalars need to be indented if followed by a comment
        ctx.forceBlockIndent = !!doc.comment
        contentComment = doc.contents.comment
      }
      const onChompKeep = contentComment ? undefined : () => (chompKeep = true)
      let body = stringify.stringify(
        doc.contents,
        ctx,
        () => (contentComment = null),
        onChompKeep
      )
      if (contentComment) {
        body += stringifyComment.lineComment(
          body,
          '',
          commentString(contentComment)
        )
      }
      if (
        (body[0] === '|' || body[0] === '>') &&
        lines[lines.length - 1] === '---'
      ) {
        // Top-level block scalars with a preceding doc marker ought to use the
        // same line for their header.
        lines[lines.length - 1] = `--- ${body}`
      } else {
        lines.push(body)
      }
    } else {
      lines.push(stringify.stringify(doc.contents, ctx))
    }
    if (doc.directives?.docEnd) {
      if (doc.comment) {
        const cs = commentString(doc.comment)
        if (cs.includes('\n')) {
          lines.push('...')
          lines.push(stringifyComment.indentComment(cs, ''))
        } else {
          lines.push(`... ${cs}`)
        }
      } else {
        lines.push('...')
      }
    } else {
      let dc = doc.comment
      if (dc && chompKeep) {
        dc = dc.replace(/^\n+/, '')
      }
      if (dc) {
        if ((!chompKeep || contentComment) && lines[lines.length - 1] !== '') {
          lines.push('')
        }
        lines.push(stringifyComment.indentComment(commentString(dc), ''))
      }
    }
    return lines.join('\n') + '\n'
  }
  stringifyDocument.stringifyDocument = stringifyDocument$1
  return stringifyDocument
}

let hasRequiredDocument
function requireDocument() {
  if (hasRequiredDocument) {
    return Document
  }
  hasRequiredDocument = 1
  const Alias = requireAlias()
  const Collection = requireCollection()
  const identity = requireIdentity()
  const Pair = requirePair()
  const toJS = requireToJS()
  const Schema = requireSchema$1()
  const stringifyDocument = requireStringifyDocument()
  const anchors = requireAnchors()
  const applyReviver = requireApplyReviver()
  const createNode = requireCreateNode()
  const directives = requireDirectives()
  let Document$1 = class Document {
    constructor(value, replacer, options) {
      /** A comment before this Document */
      this.commentBefore = null
      /** A comment immediately after this Document */
      this.comment = null
      /** Errors encountered during parsing. */
      this.errors = []
      /** Warnings encountered during parsing. */
      this.warnings = []
      Object.defineProperty(this, identity.NODE_TYPE, {
        value: identity.DOC
      })
      let _replacer = null
      if (typeof replacer === 'function' || Array.isArray(replacer)) {
        _replacer = replacer
      } else if (options === undefined && replacer) {
        options = replacer
        replacer = undefined
      }
      const opt = Object.assign(
        {
          intAsBigInt: false,
          keepSourceTokens: false,
          logLevel: 'warn',
          prettyErrors: true,
          strict: true,
          stringKeys: false,
          uniqueKeys: true,
          version: '1.2'
        },
        options
      )
      this.options = opt
      let { version } = opt
      if (options?._directives) {
        this.directives = options._directives.atDocument()
        if (this.directives.yaml.explicit) {
          version = this.directives.yaml.version
        }
      } else {
        this.directives = new directives.Directives({
          version
        })
      }
      this.setSchema(version, options)
      // @ts-expect-error We can't really know that this matches Contents.
      this.contents =
        value === undefined ? null : this.createNode(value, _replacer, options)
    }
    /**
     * Create a deep copy of this Document and its contents.
     *
     * Custom Node values that inherit from `Object` still refer to their original instances.
     */
    clone() {
      const copy = Object.create(Document.prototype, {
        [identity.NODE_TYPE]: {
          value: identity.DOC
        }
      })
      copy.commentBefore = this.commentBefore
      copy.comment = this.comment
      copy.errors = this.errors.slice()
      copy.warnings = this.warnings.slice()
      copy.options = Object.assign({}, this.options)
      if (this.directives) {
        copy.directives = this.directives.clone()
      }
      copy.schema = this.schema.clone()
      // @ts-expect-error We can't really know that this matches Contents.
      copy.contents = identity.isNode(this.contents)
        ? this.contents.clone(copy.schema)
        : this.contents
      if (this.range) {
        copy.range = this.range.slice()
      }
      return copy
    }
    /** Adds a value to the document. */
    add(value) {
      if (assertCollection(this.contents)) {
        this.contents.add(value)
      }
    }
    /** Adds a value to the document. */
    addIn(path, value) {
      if (assertCollection(this.contents)) {
        this.contents.addIn(path, value)
      }
    }
    /**
     * Create a new `Alias` node, ensuring that the target `node` has the required anchor.
     *
     * If `node` already has an anchor, `name` is ignored.
     * Otherwise, the `node.anchor` value will be set to `name`,
     * or if an anchor with that name is already present in the document,
     * `name` will be used as a prefix for a new unique anchor.
     * If `name` is undefined, the generated anchor will use 'a' as a prefix.
     */
    createAlias(node, name) {
      if (!node.anchor) {
        const prev = anchors.anchorNames(this)
        node.anchor =
          // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing
          !name || prev.has(name)
            ? anchors.findNewAnchor(name || 'a', prev)
            : name
      }
      return new Alias.Alias(node.anchor)
    }
    createNode(value, replacer, options) {
      let _replacer = undefined
      if (typeof replacer === 'function') {
        value = replacer.call(
          {
            '': value
          },
          '',
          value
        )
        _replacer = replacer
      } else if (Array.isArray(replacer)) {
        const keyToStr = v =>
          typeof v === 'number' || v instanceof String || v instanceof Number
        const asStr = replacer.filter(keyToStr).map(String)
        if (asStr.length > 0) {
          replacer = replacer.concat(asStr)
        }
        _replacer = replacer
      } else if (options === undefined && replacer) {
        options = replacer
        replacer = undefined
      }
      const {
        aliasDuplicateObjects,
        anchorPrefix,
        flow,
        keepUndefined,
        onTagObj,
        tag
      } = options ?? {}
      const { onAnchor, setAnchors, sourceObjects } = anchors.createNodeAnchors(
        this,
        // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing
        anchorPrefix || 'a'
      )
      const ctx = {
        aliasDuplicateObjects: aliasDuplicateObjects ?? true,
        keepUndefined: keepUndefined ?? false,
        onAnchor,
        onTagObj,
        replacer: _replacer,
        schema: this.schema,
        sourceObjects
      }
      const node = createNode.createNode(value, tag, ctx)
      if (flow && identity.isCollection(node)) {
        node.flow = true
      }
      setAnchors()
      return node
    }
    /**
     * Convert a key and a value into a `Pair` using the current schema,
     * recursively wrapping all values as `Scalar` or `Collection` nodes.
     */
    createPair(key, value, options = {}) {
      const k = this.createNode(key, null, options)
      const v = this.createNode(value, null, options)
      return new Pair.Pair(k, v)
    }
    /**
     * Removes a value from the document.
     * @returns `true` if the item was found and removed.
     */
    delete(key) {
      return assertCollection(this.contents) ? this.contents.delete(key) : false
    }
    /**
     * Removes a value from the document.
     * @returns `true` if the item was found and removed.
     */
    deleteIn(path) {
      if (Collection.isEmptyPath(path)) {
        if (this.contents == null) {
          return false
        }
        // @ts-expect-error Presumed impossible if Strict extends false
        this.contents = null
        return true
      }
      return assertCollection(this.contents)
        ? this.contents.deleteIn(path)
        : false
    }
    /**
     * Returns item at `key`, or `undefined` if not found. By default unwraps
     * scalar values from their surrounding node; to disable set `keepScalar` to
     * `true` (collections are always returned intact).
     */
    get(key, keepScalar) {
      return identity.isCollection(this.contents)
        ? this.contents.get(key, keepScalar)
        : undefined
    }
    /**
     * Returns item at `path`, or `undefined` if not found. By default unwraps
     * scalar values from their surrounding node; to disable set `keepScalar` to
     * `true` (collections are always returned intact).
     */
    getIn(path, keepScalar) {
      if (Collection.isEmptyPath(path)) {
        return !keepScalar && identity.isScalar(this.contents)
          ? this.contents.value
          : this.contents
      }
      return identity.isCollection(this.contents)
        ? this.contents.getIn(path, keepScalar)
        : undefined
    }
    /**
     * Checks if the document includes a value with the key `key`.
     */
    has(key) {
      return identity.isCollection(this.contents)
        ? this.contents.has(key)
        : false
    }
    /**
     * Checks if the document includes a value at `path`.
     */
    hasIn(path) {
      if (Collection.isEmptyPath(path)) {
        return this.contents !== undefined
      }
      return identity.isCollection(this.contents)
        ? this.contents.hasIn(path)
        : false
    }
    /**
     * Sets a value in this document. For `!!set`, `value` needs to be a
     * boolean to add/remove the item from the set.
     */
    set(key, value) {
      if (this.contents == null) {
        // @ts-expect-error We can't really know that this matches Contents.
        this.contents = Collection.collectionFromPath(this.schema, [key], value)
      } else if (assertCollection(this.contents)) {
        this.contents.set(key, value)
      }
    }
    /**
     * Sets a value in this document. For `!!set`, `value` needs to be a
     * boolean to add/remove the item from the set.
     */
    setIn(path, value) {
      if (Collection.isEmptyPath(path)) {
        // @ts-expect-error We can't really know that this matches Contents.
        this.contents = value
      } else if (this.contents == null) {
        // @ts-expect-error We can't really know that this matches Contents.
        this.contents = Collection.collectionFromPath(
          this.schema,
          Array.from(path),
          value
        )
      } else if (assertCollection(this.contents)) {
        this.contents.setIn(path, value)
      }
    }
    /**
     * Change the YAML version and schema used by the document.
     * A `null` version disables support for directives, explicit tags, anchors, and aliases.
     * It also requires the `schema` option to be given as a `Schema` instance value.
     *
     * Overrides all previously set schema options.
     */
    setSchema(version, options = {}) {
      if (typeof version === 'number') {
        version = String(version)
      }
      let opt
      switch (version) {
        case '1.1':
          if (this.directives) {
            this.directives.yaml.version = '1.1'
          } else {
            this.directives = new directives.Directives({
              version: '1.1'
            })
          }
          opt = {
            resolveKnownTags: false,
            schema: 'yaml-1.1'
          }
          break
        case '1.2':
        case 'next':
          if (this.directives) {
            this.directives.yaml.version = version
          } else {
            this.directives = new directives.Directives({
              version
            })
          }
          opt = {
            resolveKnownTags: true,
            schema: 'core'
          }
          break
        case null:
          if (this.directives) {
            delete this.directives
          }
          opt = null
          break
        default: {
          const sv = JSON.stringify(version)
          throw new Error(
            `Expected '1.1', '1.2' or null as first argument, but found: ${sv}`
          )
        }
      }
      // Not using `instanceof Schema` to allow for duck typing
      if (options.schema instanceof Object) {
        this.schema = options.schema
      } else if (opt) {
        this.schema = new Schema.Schema(Object.assign(opt, options))
      } else {
        throw new Error(
          `With a null YAML version, the { schema: Schema } option is required`
        )
      }
    }
    // json & jsonArg are only used from toJSON()
    toJS({ json, jsonArg, mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {
      const ctx = {
        anchors: new Map(),
        doc: this,
        keep: !json,
        mapAsMap: mapAsMap === true,
        mapKeyWarned: false,
        maxAliasCount: typeof maxAliasCount === 'number' ? maxAliasCount : 100
      }
      const res = toJS.toJS(this.contents, jsonArg ?? '', ctx)
      if (typeof onAnchor === 'function') {
        for (const { count, res } of ctx.anchors.values()) onAnchor(res, count)
      }
      return typeof reviver === 'function'
        ? applyReviver.applyReviver(
            reviver,
            {
              '': res
            },
            '',
            res
          )
        : res
    }
    /**
     * A JSON representation of the document `contents`.
     *
     * @param jsonArg Used by `JSON.stringify` to indicate the array index or
     *   property name.
     */
    toJSON(jsonArg, onAnchor) {
      return this.toJS({
        json: true,
        jsonArg,
        mapAsMap: false,
        onAnchor
      })
    }
    /** A YAML representation of the document. */
    toString(options = {}) {
      if (this.errors.length > 0) {
        throw new Error('Document with errors cannot be stringified')
      }
      if (
        'indent' in options &&
        (!Number.isInteger(options.indent) || Number(options.indent) <= 0)
      ) {
        const s = JSON.stringify(options.indent)
        throw new Error(`"indent" option must be a positive integer, not ${s}`)
      }
      return stringifyDocument.stringifyDocument(this, options)
    }
  }
  function assertCollection(contents) {
    if (identity.isCollection(contents)) {
      return true
    }
    throw new Error('Expected a YAML collection as document contents')
  }
  Document.Document = Document$1
  return Document
}

const errors$3 = {}

let hasRequiredErrors$3
function requireErrors$3() {
  if (hasRequiredErrors$3) {
    return errors$3
  }
  hasRequiredErrors$3 = 1
  class YAMLError extends Error {
    constructor(name, pos, code, message) {
      super()
      this.name = name
      this.code = code
      this.message = message
      this.pos = pos
    }
  }
  class YAMLParseError extends YAMLError {
    constructor(pos, code, message) {
      super('YAMLParseError', pos, code, message)
    }
  }
  class YAMLWarning extends YAMLError {
    constructor(pos, code, message) {
      super('YAMLWarning', pos, code, message)
    }
  }
  const prettifyError = (src, lc) => error => {
    if (error.pos[0] === -1) {
      return
    }
    error.linePos = error.pos.map(pos => lc.linePos(pos))
    const { line, col } = error.linePos[0]
    error.message += ` at line ${line}, column ${col}`
    let ci = col - 1
    let lineStr = src
      .substring(lc.lineStarts[line - 1], lc.lineStarts[line])
      .replace(/[\n\r]+$/, '')
    // Trim to max 80 chars, keeping col position near the middle
    if (ci >= 60 && lineStr.length > 80) {
      const trimStart = Math.min(ci - 39, lineStr.length - 79)
      lineStr = '…' + lineStr.substring(trimStart)
      ci -= trimStart - 1
    }
    if (lineStr.length > 80) {
      lineStr = lineStr.substring(0, 79) + '…'
    }
    // Include previous line in context if pointing at line start
    if (line > 1 && /^ *$/.test(lineStr.substring(0, ci))) {
      // Regexp won't match if start is trimmed
      let prev = src.substring(lc.lineStarts[line - 2], lc.lineStarts[line - 1])
      if (prev.length > 80) {
        prev = prev.substring(0, 79) + '…\n'
      }
      lineStr = prev + lineStr
    }
    if (/[^ ]/.test(lineStr)) {
      let count = 1
      const end = error.linePos[1]
      if (end && end.line === line && end.col > col) {
        count = Math.max(1, Math.min(end.col - col, 80 - ci))
      }
      const pointer = ' '.repeat(ci) + '^'.repeat(count)
      error.message += `:\n\n${lineStr}\n${pointer}\n`
    }
  }
  errors$3.YAMLError = YAMLError
  errors$3.YAMLParseError = YAMLParseError
  errors$3.YAMLWarning = YAMLWarning
  errors$3.prettifyError = prettifyError
  return errors$3
}

const composeDoc = {}

const composeNode = {}

const composeCollection = {}

const resolveBlockMap = {}

const resolveProps = {}

let hasRequiredResolveProps
function requireResolveProps() {
  if (hasRequiredResolveProps) {
    return resolveProps
  }
  hasRequiredResolveProps = 1
  function resolveProps$1(
    tokens,
    { flow, indicator, next, offset, onError, parentIndent, startOnNewline }
  ) {
    let spaceBefore = false
    let atNewline = startOnNewline
    let hasSpace = startOnNewline
    let comment = ''
    let commentSep = ''
    let hasNewline = false
    let reqSpace = false
    let tab = null
    let anchor = null
    let tag = null
    let newlineAfterProp = null
    let comma = null
    let found = null
    let start = null
    for (const token of tokens) {
      if (reqSpace) {
        if (
          token.type !== 'space' &&
          token.type !== 'newline' &&
          token.type !== 'comma'
        ) {
          onError(
            token.offset,
            'MISSING_CHAR',
            'Tags and anchors must be separated from the next token by white space'
          )
        }
        reqSpace = false
      }
      if (tab) {
        if (atNewline && token.type !== 'comment' && token.type !== 'newline') {
          onError(tab, 'TAB_AS_INDENT', 'Tabs are not allowed as indentation')
        }
        tab = null
      }
      switch (token.type) {
        case 'space':
          // At the doc level, tabs at line start may be parsed
          // as leading white space rather than indentation.
          // In a flow collection, only the parser handles indent.
          if (
            !flow &&
            (indicator !== 'doc-start' || next?.type !== 'flow-collection') &&
            token.source.includes('\t')
          ) {
            tab = token
          }
          hasSpace = true
          break
        case 'comment': {
          if (!hasSpace) {
            onError(
              token,
              'MISSING_CHAR',
              'Comments must be separated from other tokens by white space characters'
            )
          }
          const cb = token.source.substring(1) || ' '
          if (!comment) {
            comment = cb
          } else {
            comment += commentSep + cb
          }
          commentSep = ''
          atNewline = false
          break
        }
        case 'newline':
          if (atNewline) {
            if (comment) {
              comment += token.source
            } else if (!found || indicator !== 'seq-item-ind') {
              spaceBefore = true
            }
          } else {
            commentSep += token.source
          }
          atNewline = true
          hasNewline = true
          if (anchor || tag) {
            newlineAfterProp = token
          }
          hasSpace = true
          break
        case 'anchor':
          if (anchor) {
            onError(
              token,
              'MULTIPLE_ANCHORS',
              'A node can have at most one anchor'
            )
          }
          if (token.source.endsWith(':')) {
            onError(
              token.offset + token.source.length - 1,
              'BAD_ALIAS',
              'Anchor ending in : is ambiguous',
              true
            )
          }
          anchor = token
          if (start === null) {
            start = token.offset
          }
          atNewline = false
          hasSpace = false
          reqSpace = true
          break
        case 'tag': {
          if (tag) {
            onError(token, 'MULTIPLE_TAGS', 'A node can have at most one tag')
          }
          tag = token
          if (start === null) {
            start = token.offset
          }
          atNewline = false
          hasSpace = false
          reqSpace = true
          break
        }
        case indicator:
          // Could here handle preceding comments differently
          if (anchor || tag) {
            onError(
              token,
              'BAD_PROP_ORDER',
              `Anchors and tags must be after the ${token.source} indicator`
            )
          }
          if (found) {
            onError(
              token,
              'UNEXPECTED_TOKEN',
              `Unexpected ${token.source} in ${flow ?? 'collection'}`
            )
          }
          found = token
          atNewline =
            indicator === 'seq-item-ind' || indicator === 'explicit-key-ind'
          hasSpace = false
          break
        case 'comma':
          if (flow) {
            if (comma) {
              onError(token, 'UNEXPECTED_TOKEN', `Unexpected , in ${flow}`)
            }
            comma = token
            atNewline = false
            hasSpace = false
            break
          }
        // else fallthrough
        default:
          onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${token.type} token`)
          atNewline = false
          hasSpace = false
      }
    }
    const last = tokens[tokens.length - 1]
    const end = last ? last.offset + last.source.length : offset
    if (
      reqSpace &&
      next &&
      next.type !== 'space' &&
      next.type !== 'newline' &&
      next.type !== 'comma' &&
      (next.type !== 'scalar' || next.source !== '')
    ) {
      onError(
        next.offset,
        'MISSING_CHAR',
        'Tags and anchors must be separated from the next token by white space'
      )
    }
    if (
      tab &&
      ((atNewline && tab.indent <= parentIndent) ||
        next?.type === 'block-map' ||
        next?.type === 'block-seq')
    ) {
      onError(tab, 'TAB_AS_INDENT', 'Tabs are not allowed as indentation')
    }
    return {
      comma,
      found,
      spaceBefore,
      comment,
      hasNewline,
      anchor,
      tag,
      newlineAfterProp,
      end,
      start: start ?? end
    }
  }
  resolveProps.resolveProps = resolveProps$1
  return resolveProps
}

const utilContainsNewline = {}

let hasRequiredUtilContainsNewline
function requireUtilContainsNewline() {
  if (hasRequiredUtilContainsNewline) {
    return utilContainsNewline
  }
  hasRequiredUtilContainsNewline = 1
  function containsNewline(key) {
    if (!key) {
      return null
    }
    switch (key.type) {
      case 'alias':
      case 'scalar':
      case 'double-quoted-scalar':
      case 'single-quoted-scalar':
        if (key.source.includes('\n')) {
          return true
        }
        if (key.end) {
          for (const st of key.end) if (st.type === 'newline') return true
        }
        return false
      case 'flow-collection':
        for (const it of key.items) {
          for (const st of it.start) {
            if (st.type === 'newline') return true
          }
          if (it.sep) {
            for (const st of it.sep) if (st.type === 'newline') return true
          }
          if (containsNewline(it.key) || containsNewline(it.value)) {
            return true
          }
        }
        return false
      default:
        return true
    }
  }
  utilContainsNewline.containsNewline = containsNewline
  return utilContainsNewline
}

const utilFlowIndentCheck = {}

let hasRequiredUtilFlowIndentCheck
function requireUtilFlowIndentCheck() {
  if (hasRequiredUtilFlowIndentCheck) {
    return utilFlowIndentCheck
  }
  hasRequiredUtilFlowIndentCheck = 1
  const utilContainsNewline = requireUtilContainsNewline()
  function flowIndentCheck(indent, fc, onError) {
    if (fc?.type === 'flow-collection') {
      const end = fc.end[0]
      if (
        end.indent === indent &&
        (end.source === ']' || end.source === '}') &&
        utilContainsNewline.containsNewline(fc)
      ) {
        const msg = 'Flow end indicator should be more indented than parent'
        onError(end, 'BAD_INDENT', msg, true)
      }
    }
  }
  utilFlowIndentCheck.flowIndentCheck = flowIndentCheck
  return utilFlowIndentCheck
}

const utilMapIncludes = {}

let hasRequiredUtilMapIncludes
function requireUtilMapIncludes() {
  if (hasRequiredUtilMapIncludes) {
    return utilMapIncludes
  }
  hasRequiredUtilMapIncludes = 1
  const identity = requireIdentity()
  function mapIncludes(ctx, items, search) {
    const { uniqueKeys } = ctx.options
    if (uniqueKeys === false) {
      return false
    }
    const isEqual =
      typeof uniqueKeys === 'function'
        ? uniqueKeys
        : (a, b) =>
            a === b ||
            (identity.isScalar(a) &&
              identity.isScalar(b) &&
              a.value === b.value)
    return items.some(pair => isEqual(pair.key, search))
  }
  utilMapIncludes.mapIncludes = mapIncludes
  return utilMapIncludes
}

let hasRequiredResolveBlockMap
function requireResolveBlockMap() {
  if (hasRequiredResolveBlockMap) {
    return resolveBlockMap
  }
  hasRequiredResolveBlockMap = 1
  const Pair = requirePair()
  const YAMLMap = requireYAMLMap()
  const resolveProps = requireResolveProps()
  const utilContainsNewline = requireUtilContainsNewline()
  const utilFlowIndentCheck = requireUtilFlowIndentCheck()
  const utilMapIncludes = requireUtilMapIncludes()
  const startColMsg = 'All mapping items must start at the same column'
  function resolveBlockMap$1(
    { composeNode, composeEmptyNode },
    ctx,
    bm,
    onError,
    tag
  ) {
    const NodeClass = tag?.nodeClass ?? YAMLMap.YAMLMap
    const map = new NodeClass(ctx.schema)
    if (ctx.atRoot) {
      ctx.atRoot = false
    }
    let offset = bm.offset
    let commentEnd = null
    for (const collItem of bm.items) {
      const { start, key, sep, value } = collItem
      // key properties
      const keyProps = resolveProps.resolveProps(start, {
        indicator: 'explicit-key-ind',
        next: key ?? sep?.[0],
        offset,
        onError,
        parentIndent: bm.indent,
        startOnNewline: true
      })
      const implicitKey = !keyProps.found
      if (implicitKey) {
        if (key) {
          if (key.type === 'block-seq') {
            onError(
              offset,
              'BLOCK_AS_IMPLICIT_KEY',
              'A block sequence may not be used as an implicit map key'
            )
          } else if ('indent' in key && key.indent !== bm.indent) {
            onError(offset, 'BAD_INDENT', startColMsg)
          }
        }
        if (!keyProps.anchor && !keyProps.tag && !sep) {
          commentEnd = keyProps.end
          if (keyProps.comment) {
            if (map.comment) {
              map.comment += '\n' + keyProps.comment
            } else {
              map.comment = keyProps.comment
            }
          }
          continue
        }
        if (
          keyProps.newlineAfterProp ||
          utilContainsNewline.containsNewline(key)
        ) {
          onError(
            key ?? start[start.length - 1],
            'MULTILINE_IMPLICIT_KEY',
            'Implicit keys need to be on a single line'
          )
        }
      } else if (keyProps.found?.indent !== bm.indent) {
        onError(offset, 'BAD_INDENT', startColMsg)
      }
      // key value
      ctx.atKey = true
      const keyStart = keyProps.end
      const keyNode = key
        ? composeNode(ctx, key, keyProps, onError)
        : composeEmptyNode(ctx, keyStart, start, null, keyProps, onError)
      if (ctx.schema.compat) {
        utilFlowIndentCheck.flowIndentCheck(bm.indent, key, onError)
      }
      ctx.atKey = false
      if (utilMapIncludes.mapIncludes(ctx, map.items, keyNode)) {
        onError(keyStart, 'DUPLICATE_KEY', 'Map keys must be unique')
      }
      // value properties
      const valueProps = resolveProps.resolveProps(sep ?? [], {
        indicator: 'map-value-ind',
        next: value,
        offset: keyNode.range[2],
        onError,
        parentIndent: bm.indent,
        startOnNewline: !key || key.type === 'block-scalar'
      })
      offset = valueProps.end
      if (valueProps.found) {
        if (implicitKey) {
          if (value?.type === 'block-map' && !valueProps.hasNewline) {
            onError(
              offset,
              'BLOCK_AS_IMPLICIT_KEY',
              'Nested mappings are not allowed in compact mappings'
            )
          }
          if (
            ctx.options.strict &&
            keyProps.start < valueProps.found.offset - 1024
          ) {
            onError(
              keyNode.range,
              'KEY_OVER_1024_CHARS',
              'The : indicator must be at most 1024 chars after the start of an implicit block mapping key'
            )
          }
        }
        // value value
        const valueNode = value
          ? composeNode(ctx, value, valueProps, onError)
          : composeEmptyNode(ctx, offset, sep, null, valueProps, onError)
        if (ctx.schema.compat) {
          utilFlowIndentCheck.flowIndentCheck(bm.indent, value, onError)
        }
        offset = valueNode.range[2]
        const pair = new Pair.Pair(keyNode, valueNode)
        if (ctx.options.keepSourceTokens) {
          pair.srcToken = collItem
        }
        map.items.push(pair)
      } else {
        // key with no value
        if (implicitKey) {
          onError(
            keyNode.range,
            'MISSING_CHAR',
            'Implicit map keys need to be followed by map values'
          )
        }
        if (valueProps.comment) {
          if (keyNode.comment) {
            keyNode.comment += '\n' + valueProps.comment
          } else {
            keyNode.comment = valueProps.comment
          }
        }
        const pair = new Pair.Pair(keyNode)
        if (ctx.options.keepSourceTokens) {
          pair.srcToken = collItem
        }
        map.items.push(pair)
      }
    }
    if (commentEnd && commentEnd < offset) {
      onError(commentEnd, 'IMPOSSIBLE', 'Map comment with trailing content')
    }
    map.range = [bm.offset, offset, commentEnd ?? offset]
    return map
  }
  resolveBlockMap.resolveBlockMap = resolveBlockMap$1
  return resolveBlockMap
}

const resolveBlockSeq = {}

let hasRequiredResolveBlockSeq
function requireResolveBlockSeq() {
  if (hasRequiredResolveBlockSeq) {
    return resolveBlockSeq
  }
  hasRequiredResolveBlockSeq = 1
  const YAMLSeq = requireYAMLSeq()
  const resolveProps = requireResolveProps()
  const utilFlowIndentCheck = requireUtilFlowIndentCheck()
  function resolveBlockSeq$1(
    { composeNode, composeEmptyNode },
    ctx,
    bs,
    onError,
    tag
  ) {
    const NodeClass = tag?.nodeClass ?? YAMLSeq.YAMLSeq
    const seq = new NodeClass(ctx.schema)
    if (ctx.atRoot) {
      ctx.atRoot = false
    }
    if (ctx.atKey) {
      ctx.atKey = false
    }
    let offset = bs.offset
    let commentEnd = null
    for (const { start, value } of bs.items) {
      const props = resolveProps.resolveProps(start, {
        indicator: 'seq-item-ind',
        next: value,
        offset,
        onError,
        parentIndent: bs.indent,
        startOnNewline: true
      })
      if (!props.found) {
        if (props.anchor || props.tag || value) {
          if (value && value.type === 'block-seq') {
            onError(
              props.end,
              'BAD_INDENT',
              'All sequence items must start at the same column'
            )
          } else {
            onError(offset, 'MISSING_CHAR', 'Sequence item without - indicator')
          }
        } else {
          commentEnd = props.end
          if (props.comment) {
            seq.comment = props.comment
          }
          continue
        }
      }
      const node = value
        ? composeNode(ctx, value, props, onError)
        : composeEmptyNode(ctx, props.end, start, null, props, onError)
      if (ctx.schema.compat) {
        utilFlowIndentCheck.flowIndentCheck(bs.indent, value, onError)
      }
      offset = node.range[2]
      seq.items.push(node)
    }
    seq.range = [bs.offset, offset, commentEnd ?? offset]
    return seq
  }
  resolveBlockSeq.resolveBlockSeq = resolveBlockSeq$1
  return resolveBlockSeq
}

const resolveFlowCollection = {}

const resolveEnd = {}

let hasRequiredResolveEnd
function requireResolveEnd() {
  if (hasRequiredResolveEnd) {
    return resolveEnd
  }
  hasRequiredResolveEnd = 1
  function resolveEnd$1(end, offset, reqSpace, onError) {
    let comment = ''
    if (end) {
      let hasSpace = false
      let sep = ''
      for (const token of end) {
        const { source, type } = token
        switch (type) {
          case 'space':
            hasSpace = true
            break
          case 'comment': {
            if (reqSpace && !hasSpace) {
              onError(
                token,
                'MISSING_CHAR',
                'Comments must be separated from other tokens by white space characters'
              )
            }
            const cb = source.substring(1) || ' '
            if (!comment) {
              comment = cb
            } else {
              comment += sep + cb
            }
            sep = ''
            break
          }
          case 'newline':
            if (comment) {
              sep += source
            }
            hasSpace = true
            break
          default:
            onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${type} at node end`)
        }
        offset += source.length
      }
    }
    return {
      comment,
      offset
    }
  }
  resolveEnd.resolveEnd = resolveEnd$1
  return resolveEnd
}

let hasRequiredResolveFlowCollection
function requireResolveFlowCollection() {
  if (hasRequiredResolveFlowCollection) {
    return resolveFlowCollection
  }
  hasRequiredResolveFlowCollection = 1
  const identity = requireIdentity()
  const Pair = requirePair()
  const YAMLMap = requireYAMLMap()
  const YAMLSeq = requireYAMLSeq()
  const resolveEnd = requireResolveEnd()
  const resolveProps = requireResolveProps()
  const utilContainsNewline = requireUtilContainsNewline()
  const utilMapIncludes = requireUtilMapIncludes()
  const blockMsg = 'Block collections are not allowed within flow collections'
  const isBlock = token =>
    token && (token.type === 'block-map' || token.type === 'block-seq')
  function resolveFlowCollection$1(
    { composeNode, composeEmptyNode },
    ctx,
    fc,
    onError,
    tag
  ) {
    const isMap = fc.start.source === '{'
    const fcName = isMap ? 'flow map' : 'flow sequence'
    const NodeClass =
      tag?.nodeClass ?? (isMap ? YAMLMap.YAMLMap : YAMLSeq.YAMLSeq)
    const coll = new NodeClass(ctx.schema)
    coll.flow = true
    const atRoot = ctx.atRoot
    if (atRoot) {
      ctx.atRoot = false
    }
    if (ctx.atKey) {
      ctx.atKey = false
    }
    let offset = fc.offset + fc.start.source.length
    for (let i = 0; i < fc.items.length; ++i) {
      const collItem = fc.items[i]
      const { start, key, sep, value } = collItem
      const props = resolveProps.resolveProps(start, {
        flow: fcName,
        indicator: 'explicit-key-ind',
        next: key ?? sep?.[0],
        offset,
        onError,
        parentIndent: fc.indent,
        startOnNewline: false
      })
      if (!props.found) {
        if (!props.anchor && !props.tag && !sep && !value) {
          if (i === 0 && props.comma) {
            onError(
              props.comma,
              'UNEXPECTED_TOKEN',
              `Unexpected , in ${fcName}`
            )
          } else if (i < fc.items.length - 1) {
            onError(
              props.start,
              'UNEXPECTED_TOKEN',
              `Unexpected empty item in ${fcName}`
            )
          }
          if (props.comment) {
            if (coll.comment) {
              coll.comment += '\n' + props.comment
            } else {
              coll.comment = props.comment
            }
          }
          offset = props.end
          continue
        }
        if (
          !isMap &&
          ctx.options.strict &&
          utilContainsNewline.containsNewline(key)
        ) {
          onError(
            key,
            // checked by containsNewline()
            'MULTILINE_IMPLICIT_KEY',
            'Implicit keys of flow sequence pairs need to be on a single line'
          )
        }
      }
      if (i === 0) {
        if (props.comma) {
          onError(props.comma, 'UNEXPECTED_TOKEN', `Unexpected , in ${fcName}`)
        }
      } else {
        if (!props.comma) {
          onError(
            props.start,
            'MISSING_CHAR',
            `Missing , between ${fcName} items`
          )
        }
        if (props.comment) {
          let prevItemComment = ''
          loop: for (const st of start) {
            switch (st.type) {
              case 'comma':
              case 'space':
                break
              case 'comment':
                prevItemComment = st.source.substring(1)
                break loop
              default:
                break loop
            }
          }
          if (prevItemComment) {
            let prev = coll.items[coll.items.length - 1]
            if (identity.isPair(prev)) {
              prev = prev.value ?? prev.key
            }
            if (prev.comment) {
              prev.comment += '\n' + prevItemComment
            } else {
              prev.comment = prevItemComment
            }
            props.comment = props.comment.substring(prevItemComment.length + 1)
          }
        }
      }
      if (!isMap && !sep && !props.found) {
        // item is a value in a seq
        // → key & sep are empty, start does not include ? or :
        const valueNode = value
          ? composeNode(ctx, value, props, onError)
          : composeEmptyNode(ctx, props.end, sep, null, props, onError)
        coll.items.push(valueNode)
        offset = valueNode.range[2]
        if (isBlock(value)) {
          onError(valueNode.range, 'BLOCK_IN_FLOW', blockMsg)
        }
      } else {
        // item is a key+value pair
        // key value
        ctx.atKey = true
        const keyStart = props.end
        const keyNode = key
          ? composeNode(ctx, key, props, onError)
          : composeEmptyNode(ctx, keyStart, start, null, props, onError)
        if (isBlock(key)) {
          onError(keyNode.range, 'BLOCK_IN_FLOW', blockMsg)
        }
        ctx.atKey = false
        // value properties
        const valueProps = resolveProps.resolveProps(sep ?? [], {
          flow: fcName,
          indicator: 'map-value-ind',
          next: value,
          offset: keyNode.range[2],
          onError,
          parentIndent: fc.indent,
          startOnNewline: false
        })
        if (valueProps.found) {
          if (!isMap && !props.found && ctx.options.strict) {
            if (sep) {
              for (const st of sep) {
                if (st === valueProps.found) break
                if (st.type === 'newline') {
                  onError(
                    st,
                    'MULTILINE_IMPLICIT_KEY',
                    'Implicit keys of flow sequence pairs need to be on a single line'
                  )
                  break
                }
              }
            }
            if (props.start < valueProps.found.offset - 1024) {
              onError(
                valueProps.found,
                'KEY_OVER_1024_CHARS',
                'The : indicator must be at most 1024 chars after the start of an implicit flow sequence key'
              )
            }
          }
        } else if (value) {
          if ('source' in value && value.source && value.source[0] === ':') {
            onError(value, 'MISSING_CHAR', `Missing space after : in ${fcName}`)
          } else {
            onError(
              valueProps.start,
              'MISSING_CHAR',
              `Missing , or : between ${fcName} items`
            )
          }
        }
        // value value
        const valueNode = value
          ? composeNode(ctx, value, valueProps, onError)
          : valueProps.found
            ? composeEmptyNode(
                ctx,
                valueProps.end,
                sep,
                null,
                valueProps,
                onError
              )
            : null
        if (valueNode) {
          if (isBlock(value)) {
            onError(valueNode.range, 'BLOCK_IN_FLOW', blockMsg)
          }
        } else if (valueProps.comment) {
          if (keyNode.comment) {
            keyNode.comment += '\n' + valueProps.comment
          } else {
            keyNode.comment = valueProps.comment
          }
        }
        const pair = new Pair.Pair(keyNode, valueNode)
        if (ctx.options.keepSourceTokens) {
          pair.srcToken = collItem
        }
        if (isMap) {
          const map = coll
          if (utilMapIncludes.mapIncludes(ctx, map.items, keyNode)) {
            onError(keyStart, 'DUPLICATE_KEY', 'Map keys must be unique')
          }
          map.items.push(pair)
        } else {
          const map = new YAMLMap.YAMLMap(ctx.schema)
          map.flow = true
          map.items.push(pair)
          const endRange = (valueNode ?? keyNode).range
          map.range = [keyNode.range[0], endRange[1], endRange[2]]
          coll.items.push(map)
        }
        offset = valueNode ? valueNode.range[2] : valueProps.end
      }
    }
    const expectedEnd = isMap ? '}' : ']'
    const [ce, ...ee] = fc.end
    let cePos = offset
    if (ce && ce.source === expectedEnd) {
      cePos = ce.offset + ce.source.length
    } else {
      const name = fcName[0].toUpperCase() + fcName.substring(1)
      const msg = atRoot
        ? `${name} must end with a ${expectedEnd}`
        : `${name} in block collection must be sufficiently indented and end with a ${expectedEnd}`
      onError(offset, atRoot ? 'MISSING_CHAR' : 'BAD_INDENT', msg)
      if (ce && ce.source.length !== 1) {
        ee.unshift(ce)
      }
    }
    if (ee.length > 0) {
      const end = resolveEnd.resolveEnd(ee, cePos, ctx.options.strict, onError)
      if (end.comment) {
        if (coll.comment) {
          coll.comment += '\n' + end.comment
        } else {
          coll.comment = end.comment
        }
      }
      coll.range = [fc.offset, cePos, end.offset]
    } else {
      coll.range = [fc.offset, cePos, cePos]
    }
    return coll
  }
  resolveFlowCollection.resolveFlowCollection = resolveFlowCollection$1
  return resolveFlowCollection
}

let hasRequiredComposeCollection
function requireComposeCollection() {
  if (hasRequiredComposeCollection) {
    return composeCollection
  }
  hasRequiredComposeCollection = 1
  const identity = requireIdentity()
  const Scalar = requireScalar()
  const YAMLMap = requireYAMLMap()
  const YAMLSeq = requireYAMLSeq()
  const resolveBlockMap = requireResolveBlockMap()
  const resolveBlockSeq = requireResolveBlockSeq()
  const resolveFlowCollection = requireResolveFlowCollection()
  function resolveCollection(CN, ctx, token, onError, tagName, tag) {
    const coll =
      token.type === 'block-map'
        ? resolveBlockMap.resolveBlockMap(CN, ctx, token, onError, tag)
        : token.type === 'block-seq'
          ? resolveBlockSeq.resolveBlockSeq(CN, ctx, token, onError, tag)
          : resolveFlowCollection.resolveFlowCollection(
              CN,
              ctx,
              token,
              onError,
              tag
            )
    const Coll = coll.constructor
    // If we got a tagName matching the class, or the tag name is '!',
    // then use the tagName from the node class used to create it.
    if (tagName === '!' || tagName === Coll.tagName) {
      coll.tag = Coll.tagName
      return coll
    }
    if (tagName) {
      coll.tag = tagName
    }
    return coll
  }
  function composeCollection$1(CN, ctx, token, props, onError) {
    const tagToken = props.tag
    const tagName = !tagToken
      ? null
      : ctx.directives.tagName(tagToken.source, msg =>
          onError(tagToken, 'TAG_RESOLVE_FAILED', msg)
        )
    if (token.type === 'block-seq') {
      const { anchor, newlineAfterProp: nl } = props
      const lastProp =
        anchor && tagToken
          ? anchor.offset > tagToken.offset
            ? anchor
            : tagToken
          : (anchor ?? tagToken)
      if (lastProp && (!nl || nl.offset < lastProp.offset)) {
        const message = 'Missing newline after block sequence props'
        onError(lastProp, 'MISSING_CHAR', message)
      }
    }
    const expType =
      token.type === 'block-map'
        ? 'map'
        : token.type === 'block-seq'
          ? 'seq'
          : token.start.source === '{'
            ? 'map'
            : 'seq'
    // shortcut: check if it's a generic YAMLMap or YAMLSeq
    // before jumping into the custom tag logic.
    if (
      !tagToken ||
      !tagName ||
      tagName === '!' ||
      (tagName === YAMLMap.YAMLMap.tagName && expType === 'map') ||
      (tagName === YAMLSeq.YAMLSeq.tagName && expType === 'seq')
    ) {
      return resolveCollection(CN, ctx, token, onError, tagName)
    }
    let tag = ctx.schema.tags.find(
      t => t.tag === tagName && t.collection === expType
    )
    if (!tag) {
      const kt = ctx.schema.knownTags[tagName]
      if (kt && kt.collection === expType) {
        ctx.schema.tags.push(
          Object.assign({}, kt, {
            default: false
          })
        )
        tag = kt
      } else {
        if (kt) {
          onError(
            tagToken,
            'BAD_COLLECTION_TYPE',
            `${kt.tag} used for ${expType} collection, but expects ${kt.collection ?? 'scalar'}`,
            true
          )
        } else {
          onError(
            tagToken,
            'TAG_RESOLVE_FAILED',
            `Unresolved tag: ${tagName}`,
            true
          )
        }
        return resolveCollection(CN, ctx, token, onError, tagName)
      }
    }
    const coll = resolveCollection(CN, ctx, token, onError, tagName, tag)
    const res =
      tag.resolve?.(
        coll,
        msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg),
        ctx.options
      ) ?? coll
    const node = identity.isNode(res) ? res : new Scalar.Scalar(res)
    node.range = coll.range
    node.tag = tagName
    if (tag?.format) {
      node.format = tag.format
    }
    return node
  }
  composeCollection.composeCollection = composeCollection$1
  return composeCollection
}

const composeScalar = {}

const resolveBlockScalar = {}

let hasRequiredResolveBlockScalar
function requireResolveBlockScalar() {
  if (hasRequiredResolveBlockScalar) {
    return resolveBlockScalar
  }
  hasRequiredResolveBlockScalar = 1
  const Scalar = requireScalar()
  function resolveBlockScalar$1(ctx, scalar, onError) {
    const start = scalar.offset
    const header = parseBlockScalarHeader(scalar, ctx.options.strict, onError)
    if (!header) {
      return {
        value: '',
        type: null,
        comment: '',
        range: [start, start, start]
      }
    }
    const type =
      header.mode === '>'
        ? Scalar.Scalar.BLOCK_FOLDED
        : Scalar.Scalar.BLOCK_LITERAL
    const lines = scalar.source ? splitLines(scalar.source) : []
    // determine the end of content & start of chomping
    let chompStart = lines.length
    for (let i = lines.length - 1; i >= 0; --i) {
      const content = lines[i][1]
      if (content === '' || content === '\r') {
        chompStart = i
      } else {
        break
      }
    }
    // shortcut for empty contents
    if (chompStart === 0) {
      const value =
        header.chomp === '+' && lines.length > 0
          ? '\n'.repeat(Math.max(1, lines.length - 1))
          : ''
      let end = start + header.length
      if (scalar.source) {
        end += scalar.source.length
      }
      return {
        value,
        type,
        comment: header.comment,
        range: [start, end, end]
      }
    }
    // find the indentation level to trim from start
    let trimIndent = scalar.indent + header.indent
    let offset = scalar.offset + header.length
    let contentStart = 0
    for (let i = 0; i < chompStart; ++i) {
      const [indent, content] = lines[i]
      if (content === '' || content === '\r') {
        if (header.indent === 0 && indent.length > trimIndent) {
          trimIndent = indent.length
        }
      } else {
        if (indent.length < trimIndent) {
          const message =
            'Block scalars with more-indented leading empty lines must use an explicit indentation indicator'
          onError(offset + indent.length, 'MISSING_CHAR', message)
        }
        if (header.indent === 0) {
          trimIndent = indent.length
        }
        contentStart = i
        if (trimIndent === 0 && !ctx.atRoot) {
          const message = 'Block scalar values in collections must be indented'
          onError(offset, 'BAD_INDENT', message)
        }
        break
      }
      offset += indent.length + content.length + 1
    }
    // include trailing more-indented empty lines in content
    for (let i = lines.length - 1; i >= chompStart; --i) {
      if (lines[i][0].length > trimIndent) {
        chompStart = i + 1
      }
    }
    let value = ''
    let sep = ''
    let prevMoreIndented = false
    // leading whitespace is kept intact
    for (let i = 0; i < contentStart; ++i) {
      value += lines[i][0].slice(trimIndent) + '\n'
    }
    for (let i = contentStart; i < chompStart; ++i) {
      let [indent, content] = lines[i]
      offset += indent.length + content.length + 1
      const crlf = content[content.length - 1] === '\r'
      if (crlf) {
        content = content.slice(0, -1)
      }
      /* istanbul ignore if already caught in lexer */
      if (content && indent.length < trimIndent) {
        const src = header.indent
          ? 'explicit indentation indicator'
          : 'first line'
        const message = `Block scalar lines must not be less indented than their ${src}`
        onError(offset - content.length - (crlf ? 2 : 1), 'BAD_INDENT', message)
        indent = ''
      }
      if (type === Scalar.Scalar.BLOCK_LITERAL) {
        value += sep + indent.slice(trimIndent) + content
        sep = '\n'
      } else if (indent.length > trimIndent || content[0] === '\t') {
        // more-indented content within a folded block
        if (sep === ' ') {
          sep = '\n'
        } else if (!prevMoreIndented && sep === '\n') {
          sep = '\n\n'
        }
        value += sep + indent.slice(trimIndent) + content
        sep = '\n'
        prevMoreIndented = true
      } else if (content === '') {
        // empty line
        if (sep === '\n') {
          value += '\n'
        } else {
          sep = '\n'
        }
      } else {
        value += sep + content
        sep = ' '
        prevMoreIndented = false
      }
    }
    switch (header.chomp) {
      case '-':
        break
      case '+':
        for (let i = chompStart; i < lines.length; ++i) {
          value += '\n' + lines[i][0].slice(trimIndent)
        }
        if (value[value.length - 1] !== '\n') {
          value += '\n'
        }
        break
      default:
        value += '\n'
    }
    const end = start + header.length + scalar.source.length
    return {
      value,
      type,
      comment: header.comment,
      range: [start, end, end]
    }
  }
  function parseBlockScalarHeader({ offset, props }, strict, onError) {
    /* istanbul ignore if should not happen */
    if (props[0].type !== 'block-scalar-header') {
      onError(props[0], 'IMPOSSIBLE', 'Block scalar header not found')
      return null
    }
    const { source } = props[0]
    const mode = source[0]
    let indent = 0
    let chomp = ''
    let error = -1
    for (let i = 1; i < source.length; ++i) {
      const ch = source[i]
      if (!chomp && (ch === '-' || ch === '+')) {
        chomp = ch
      } else {
        const n = Number(ch)
        if (!indent && n) {
          indent = n
        } else if (error === -1) {
          error = offset + i
        }
      }
    }
    if (error !== -1) {
      onError(
        error,
        'UNEXPECTED_TOKEN',
        `Block scalar header includes extra characters: ${source}`
      )
    }
    let hasSpace = false
    let comment = ''
    let length = source.length
    for (let i = 1; i < props.length; ++i) {
      const token = props[i]
      switch (token.type) {
        case 'space':
          hasSpace = true
        // fallthrough
        case 'newline':
          length += token.source.length
          break
        case 'comment':
          if (strict && !hasSpace) {
            const message =
              'Comments must be separated from other tokens by white space characters'
            onError(token, 'MISSING_CHAR', message)
          }
          length += token.source.length
          comment = token.source.substring(1)
          break
        case 'error':
          onError(token, 'UNEXPECTED_TOKEN', token.message)
          length += token.source.length
          break
        /* istanbul ignore next should not happen */
        default: {
          const message = `Unexpected token in block scalar header: ${token.type}`
          onError(token, 'UNEXPECTED_TOKEN', message)
          const ts = token.source
          if (ts && typeof ts === 'string') {
            length += ts.length
          }
        }
      }
    }
    return {
      mode,
      indent,
      chomp,
      comment,
      length
    }
  }
  /** @returns Array of lines split up as `[indent, content]` */
  function splitLines(source) {
    const split = source.split(/\n( *)/)
    const first = split[0]
    const m = first.match(/^( *)/)
    const line0 = m?.[1] ? [m[1], first.slice(m[1].length)] : ['', first]
    const lines = [line0]
    for (let i = 1; i < split.length; i += 2) {
      lines.push([split[i], split[i + 1]])
    }
    return lines
  }
  resolveBlockScalar.resolveBlockScalar = resolveBlockScalar$1
  return resolveBlockScalar
}

const resolveFlowScalar = {}

let hasRequiredResolveFlowScalar
function requireResolveFlowScalar() {
  if (hasRequiredResolveFlowScalar) {
    return resolveFlowScalar
  }
  hasRequiredResolveFlowScalar = 1
  const Scalar = requireScalar()
  const resolveEnd = requireResolveEnd()
  function resolveFlowScalar$1(scalar, strict, onError) {
    const { offset, type, source, end } = scalar
    let _type
    let value
    const _onError = (rel, code, msg) => onError(offset + rel, code, msg)
    switch (type) {
      case 'scalar':
        _type = Scalar.Scalar.PLAIN
        value = plainValue(source, _onError)
        break
      case 'single-quoted-scalar':
        _type = Scalar.Scalar.QUOTE_SINGLE
        value = singleQuotedValue(source, _onError)
        break
      case 'double-quoted-scalar':
        _type = Scalar.Scalar.QUOTE_DOUBLE
        value = doubleQuotedValue(source, _onError)
        break
      /* istanbul ignore next should not happen */
      default:
        onError(
          scalar,
          'UNEXPECTED_TOKEN',
          `Expected a flow scalar value, but found: ${type}`
        )
        return {
          value: '',
          type: null,
          comment: '',
          range: [offset, offset + source.length, offset + source.length]
        }
    }
    const valueEnd = offset + source.length
    const re = resolveEnd.resolveEnd(end, valueEnd, strict, onError)
    return {
      value,
      type: _type,
      comment: re.comment,
      range: [offset, valueEnd, re.offset]
    }
  }
  function plainValue(source, onError) {
    let badChar = ''
    switch (source[0]) {
      /* istanbul ignore next should not happen */
      case '\t':
        badChar = 'a tab character'
        break
      case ',':
        badChar = 'flow indicator character ,'
        break
      case '%':
        badChar = 'directive indicator character %'
        break
      case '|':
      case '>': {
        badChar = `block scalar indicator ${source[0]}`
        break
      }
      case '@':
      case '`': {
        badChar = `reserved character ${source[0]}`
        break
      }
    }
    if (badChar) {
      onError(0, 'BAD_SCALAR_START', `Plain value cannot start with ${badChar}`)
    }
    return foldLines(source)
  }
  function singleQuotedValue(source, onError) {
    if (source[source.length - 1] !== "'" || source.length === 1) {
      onError(source.length, 'MISSING_CHAR', "Missing closing 'quote")
    }
    return foldLines(source.slice(1, -1)).replace(/''/g, "'")
  }
  function foldLines(source) {
    /**
     * The negative lookbehind here and in the `re` RegExp is to
     * prevent causing a polynomial search time in certain cases.
     *
     * The try-catch is for Safari, which doesn't support this yet:
     * https://caniuse.com/js-regexp-lookbehind
     */
    let first, line
    try {
      first = new RegExp('(.*?)(?<![ \t])[ \t]*\r?\n', 'sy')
      line = new RegExp('[ \t]*(.*?)(?:(?<![ \t])[ \t]*)?\r?\n', 'sy')
    } catch {
      first = /(.*?)[ \t]*\r?\n/sy
      line = /[ \t]*(.*?)[ \t]*\r?\n/sy
    }
    let match = first.exec(source)
    if (!match) {
      return source
    }
    let res = match[1]
    let sep = ' '
    let pos = first.lastIndex
    line.lastIndex = pos
    while ((match = line.exec(source))) {
      if (match[1] === '') {
        if (sep === '\n') {
          res += sep
        } else {
          sep = '\n'
        }
      } else {
        res += sep + match[1]
        sep = ' '
      }
      pos = line.lastIndex
    }
    const last = /[ \t]*(.*)/sy
    last.lastIndex = pos
    match = last.exec(source)
    return res + sep + (match?.[1] ?? '')
  }
  function doubleQuotedValue(source, onError) {
    let res = ''
    for (let i = 1; i < source.length - 1; ++i) {
      const ch = source[i]
      if (ch === '\r' && source[i + 1] === '\n') {
        continue
      }
      if (ch === '\n') {
        const { fold, offset } = foldNewline(source, i)
        res += fold
        i = offset
      } else if (ch === '\\') {
        let next = source[++i]
        const cc = escapeCodes[next]
        if (cc) {
          res += cc
        } else if (next === '\n') {
          // skip escaped newlines, but still trim the following line
          next = source[i + 1]
          while (next === ' ' || next === '\t') {
            next = source[++i + 1]
          }
        } else if (next === '\r' && source[i + 1] === '\n') {
          // skip escaped CRLF newlines, but still trim the following line
          next = source[++i + 1]
          while (next === ' ' || next === '\t') {
            next = source[++i + 1]
          }
        } else if (next === 'x' || next === 'u' || next === 'U') {
          const length = {
            x: 2,
            u: 4,
            U: 8
          }[next]
          res += parseCharCode(source, i + 1, length, onError)
          i += length
        } else {
          const raw = source.substr(i - 1, 2)
          onError(i - 1, 'BAD_DQ_ESCAPE', `Invalid escape sequence ${raw}`)
          res += raw
        }
      } else if (ch === ' ' || ch === '\t') {
        // trim trailing whitespace
        const wsStart = i
        let next = source[i + 1]
        while (next === ' ' || next === '\t') {
          next = source[++i + 1]
        }
        if (next !== '\n' && !(next === '\r' && source[i + 2] === '\n')) {
          res += i > wsStart ? source.slice(wsStart, i + 1) : ch
        }
      } else {
        res += ch
      }
    }
    if (source[source.length - 1] !== '"' || source.length === 1) {
      onError(source.length, 'MISSING_CHAR', 'Missing closing "quote')
    }
    return res
  }
  /**
   * Fold a single newline into a space, multiple newlines to N - 1 newlines.
   * Presumes `source[offset] === '\n'`
   */
  function foldNewline(source, offset) {
    let fold = ''
    let ch = source[offset + 1]
    while (ch === ' ' || ch === '\t' || ch === '\n' || ch === '\r') {
      if (ch === '\r' && source[offset + 2] !== '\n') {
        break
      }
      if (ch === '\n') {
        fold += '\n'
      }
      offset += 1
      ch = source[offset + 1]
    }
    if (!fold) {
      fold = ' '
    }
    return {
      fold,
      offset
    }
  }
  const escapeCodes = {
    0: '\0',
    // null character
    a: '\x07',
    // bell character
    b: '\b',
    // backspace
    e: '\x1b',
    // escape character
    f: '\f',
    // form feed
    n: '\n',
    // line feed
    r: '\r',
    // carriage return
    t: '\t',
    // horizontal tab
    v: '\v',
    // vertical tab
    N: '\u0085',
    // Unicode next line
    _: '\u00a0',
    // Unicode non-breaking space
    L: '\u2028',
    // Unicode line separator
    P: '\u2029',
    // Unicode paragraph separator
    ' ': ' ',
    '"': '"',
    '/': '/',
    '\\': '\\',
    '\t': '\t'
  }
  function parseCharCode(source, offset, length, onError) {
    const cc = source.substr(offset, length)
    const ok = cc.length === length && /^[0-9a-fA-F]+$/.test(cc)
    const code = ok ? parseInt(cc, 16) : NaN
    if (isNaN(code)) {
      const raw = source.substr(offset - 2, length + 2)
      onError(offset - 2, 'BAD_DQ_ESCAPE', `Invalid escape sequence ${raw}`)
      return raw
    }
    return String.fromCodePoint(code)
  }
  resolveFlowScalar.resolveFlowScalar = resolveFlowScalar$1
  return resolveFlowScalar
}

let hasRequiredComposeScalar
function requireComposeScalar() {
  if (hasRequiredComposeScalar) {
    return composeScalar
  }
  hasRequiredComposeScalar = 1
  const identity = requireIdentity()
  const Scalar = requireScalar()
  const resolveBlockScalar = requireResolveBlockScalar()
  const resolveFlowScalar = requireResolveFlowScalar()
  function composeScalar$1(ctx, token, tagToken, onError) {
    const { value, type, comment, range } =
      token.type === 'block-scalar'
        ? resolveBlockScalar.resolveBlockScalar(ctx, token, onError)
        : resolveFlowScalar.resolveFlowScalar(
            token,
            ctx.options.strict,
            onError
          )
    const tagName = tagToken
      ? ctx.directives.tagName(tagToken.source, msg =>
          onError(tagToken, 'TAG_RESOLVE_FAILED', msg)
        )
      : null
    let tag
    if (ctx.options.stringKeys && ctx.atKey) {
      tag = ctx.schema[identity.SCALAR]
    } else if (tagName) {
      tag = findScalarTagByName(ctx.schema, value, tagName, tagToken, onError)
    } else if (token.type === 'scalar') {
      tag = findScalarTagByTest(ctx, value, token, onError)
    } else {
      tag = ctx.schema[identity.SCALAR]
    }
    let scalar
    try {
      const res = tag.resolve(
        value,
        msg => onError(tagToken ?? token, 'TAG_RESOLVE_FAILED', msg),
        ctx.options
      )
      scalar = identity.isScalar(res) ? res : new Scalar.Scalar(res)
    } catch (error) {
      const msg = error instanceof Error ? error.message : String(error)
      onError(tagToken ?? token, 'TAG_RESOLVE_FAILED', msg)
      scalar = new Scalar.Scalar(value)
    }
    scalar.range = range
    scalar.source = value
    if (type) {
      scalar.type = type
    }
    if (tagName) {
      scalar.tag = tagName
    }
    if (tag.format) {
      scalar.format = tag.format
    }
    if (comment) {
      scalar.comment = comment
    }
    return scalar
  }
  function findScalarTagByName(schema, value, tagName, tagToken, onError) {
    if (tagName === '!') {
      return schema[identity.SCALAR]
    } // non-specific tag
    const matchWithTest = []
    for (const tag of schema.tags) {
      if (!tag.collection && tag.tag === tagName) {
        if (tag.default && tag.test) {
          matchWithTest.push(tag)
        } else {
          return tag
        }
      }
    }
    for (const tag of matchWithTest) {
      if (tag.test?.test(value)) return tag
    }
    const kt = schema.knownTags[tagName]
    if (kt && !kt.collection) {
      // Ensure that the known tag is available for stringifying,
      // but does not get used by default.
      schema.tags.push(
        Object.assign({}, kt, {
          default: false,
          test: undefined
        })
      )
      return kt
    }
    onError(
      tagToken,
      'TAG_RESOLVE_FAILED',
      `Unresolved tag: ${tagName}`,
      tagName !== 'tag:yaml.org,2002:str'
    )
    return schema[identity.SCALAR]
  }
  function findScalarTagByTest(
    { atKey, directives, schema },
    value,
    token,
    onError
  ) {
    const tag =
      schema.tags.find(
        tag =>
          (tag.default === true || (atKey && tag.default === 'key')) &&
          tag.test?.test(value)
      ) || schema[identity.SCALAR]
    if (schema.compat) {
      const compat =
        schema.compat.find(tag => tag.default && tag.test?.test(value)) ??
        schema[identity.SCALAR]
      if (tag.tag !== compat.tag) {
        const ts = directives.tagString(tag.tag)
        const cs = directives.tagString(compat.tag)
        const msg = `Value may be parsed as either ${ts} or ${cs}`
        onError(token, 'TAG_RESOLVE_FAILED', msg, true)
      }
    }
    return tag
  }
  composeScalar.composeScalar = composeScalar$1
  return composeScalar
}

const utilEmptyScalarPosition = {}

let hasRequiredUtilEmptyScalarPosition
function requireUtilEmptyScalarPosition() {
  if (hasRequiredUtilEmptyScalarPosition) {
    return utilEmptyScalarPosition
  }
  hasRequiredUtilEmptyScalarPosition = 1
  function emptyScalarPosition(offset, before, pos) {
    if (before) {
      if (pos === null) {
        pos = before.length
      }
      for (let i = pos - 1; i >= 0; --i) {
        let st = before[i]
        switch (st.type) {
          case 'space':
          case 'comment':
          case 'newline':
            offset -= st.source.length
            continue
        }
        // Technically, an empty scalar is immediately after the last non-empty
        // node, but it's more useful to place it after any whitespace.
        st = before[++i]
        while (st?.type === 'space') {
          offset += st.source.length
          st = before[++i]
        }
        break
      }
    }
    return offset
  }
  utilEmptyScalarPosition.emptyScalarPosition = emptyScalarPosition
  return utilEmptyScalarPosition
}

let hasRequiredComposeNode
function requireComposeNode() {
  if (hasRequiredComposeNode) {
    return composeNode
  }
  hasRequiredComposeNode = 1
  const Alias = requireAlias()
  const identity = requireIdentity()
  const composeCollection = requireComposeCollection()
  const composeScalar = requireComposeScalar()
  const resolveEnd = requireResolveEnd()
  const utilEmptyScalarPosition = requireUtilEmptyScalarPosition()
  const CN = {
    composeNode: composeNode$1,
    composeEmptyNode
  }
  function composeNode$1(ctx, token, props, onError) {
    const atKey = ctx.atKey
    const { spaceBefore, comment, anchor, tag } = props
    let node
    let isSrcToken = true
    switch (token.type) {
      case 'alias':
        node = composeAlias(ctx, token, onError)
        if (anchor || tag) {
          onError(
            token,
            'ALIAS_PROPS',
            'An alias node must not specify any properties'
          )
        }
        break
      case 'scalar':
      case 'single-quoted-scalar':
      case 'double-quoted-scalar':
      case 'block-scalar':
        node = composeScalar.composeScalar(ctx, token, tag, onError)
        if (anchor) {
          node.anchor = anchor.source.substring(1)
        }
        break
      case 'block-map':
      case 'block-seq':
      case 'flow-collection':
        node = composeCollection.composeCollection(
          CN,
          ctx,
          token,
          props,
          onError
        )
        if (anchor) {
          node.anchor = anchor.source.substring(1)
        }
        break
      default: {
        const message =
          token.type === 'error'
            ? token.message
            : `Unsupported token (type: ${token.type})`
        onError(token, 'UNEXPECTED_TOKEN', message)
        node = composeEmptyNode(
          ctx,
          token.offset,
          undefined,
          null,
          props,
          onError
        )
        isSrcToken = false
      }
    }
    if (anchor && node.anchor === '') {
      onError(anchor, 'BAD_ALIAS', 'Anchor cannot be an empty string')
    }
    if (
      atKey &&
      ctx.options.stringKeys &&
      (!identity.isScalar(node) ||
        typeof node.value !== 'string' ||
        (node.tag && node.tag !== 'tag:yaml.org,2002:str'))
    ) {
      const msg = 'With stringKeys, all keys must be strings'
      onError(tag ?? token, 'NON_STRING_KEY', msg)
    }
    if (spaceBefore) {
      node.spaceBefore = true
    }
    if (comment) {
      if (token.type === 'scalar' && token.source === '') {
        node.comment = comment
      } else {
        node.commentBefore = comment
      }
    }
    // @ts-expect-error Type checking misses meaning of isSrcToken
    if (ctx.options.keepSourceTokens && isSrcToken) {
      node.srcToken = token
    }
    return node
  }
  function composeEmptyNode(
    ctx,
    offset,
    before,
    pos,
    { spaceBefore, comment, anchor, tag, end },
    onError
  ) {
    const token = {
      type: 'scalar',
      offset: utilEmptyScalarPosition.emptyScalarPosition(offset, before, pos),
      indent: -1,
      source: ''
    }
    const node = composeScalar.composeScalar(ctx, token, tag, onError)
    if (anchor) {
      node.anchor = anchor.source.substring(1)
      if (node.anchor === '') {
        onError(anchor, 'BAD_ALIAS', 'Anchor cannot be an empty string')
      }
    }
    if (spaceBefore) {
      node.spaceBefore = true
    }
    if (comment) {
      node.comment = comment
      node.range[2] = end
    }
    return node
  }
  function composeAlias({ options }, { offset, source, end }, onError) {
    const alias = new Alias.Alias(source.substring(1))
    if (alias.source === '') {
      onError(offset, 'BAD_ALIAS', 'Alias cannot be an empty string')
    }
    if (alias.source.endsWith(':')) {
      onError(
        offset + source.length - 1,
        'BAD_ALIAS',
        'Alias ending in : is ambiguous',
        true
      )
    }
    const valueEnd = offset + source.length
    const re = resolveEnd.resolveEnd(end, valueEnd, options.strict, onError)
    alias.range = [offset, valueEnd, re.offset]
    if (re.comment) {
      alias.comment = re.comment
    }
    return alias
  }
  composeNode.composeEmptyNode = composeEmptyNode
  composeNode.composeNode = composeNode$1
  return composeNode
}

let hasRequiredComposeDoc
function requireComposeDoc() {
  if (hasRequiredComposeDoc) {
    return composeDoc
  }
  hasRequiredComposeDoc = 1
  const Document = requireDocument()
  const composeNode = requireComposeNode()
  const resolveEnd = requireResolveEnd()
  const resolveProps = requireResolveProps()
  function composeDoc$1(
    options,
    directives,
    { offset, start, value, end },
    onError
  ) {
    const opts = Object.assign(
      {
        _directives: directives
      },
      options
    )
    const doc = new Document.Document(undefined, opts)
    const ctx = {
      atKey: false,
      atRoot: true,
      directives: doc.directives,
      options: doc.options,
      schema: doc.schema
    }
    const props = resolveProps.resolveProps(start, {
      indicator: 'doc-start',
      next: value ?? end?.[0],
      offset,
      onError,
      parentIndent: 0,
      startOnNewline: true
    })
    if (props.found) {
      doc.directives.docStart = true
      if (
        value &&
        (value.type === 'block-map' || value.type === 'block-seq') &&
        !props.hasNewline
      ) {
        onError(
          props.end,
          'MISSING_CHAR',
          'Block collection cannot start on same line with directives-end marker'
        )
      }
    }
    // @ts-expect-error If Contents is set, let's trust the user
    doc.contents = value
      ? composeNode.composeNode(ctx, value, props, onError)
      : composeNode.composeEmptyNode(
          ctx,
          props.end,
          start,
          null,
          props,
          onError
        )
    const contentEnd = doc.contents.range[2]
    const re = resolveEnd.resolveEnd(end, contentEnd, false, onError)
    if (re.comment) {
      doc.comment = re.comment
    }
    doc.range = [offset, contentEnd, re.offset]
    return doc
  }
  composeDoc.composeDoc = composeDoc$1
  return composeDoc
}

let hasRequiredComposer
function requireComposer() {
  if (hasRequiredComposer) {
    return composer
  }
  hasRequiredComposer = 1
  const node_process = process$2
  const directives = requireDirectives()
  const Document = requireDocument()
  const errors = requireErrors$3()
  const identity = requireIdentity()
  const composeDoc = requireComposeDoc()
  const resolveEnd = requireResolveEnd()
  function getErrorPos(src) {
    if (typeof src === 'number') {
      return [src, src + 1]
    }
    if (Array.isArray(src)) {
      return src.length === 2 ? src : [src[0], src[1]]
    }
    const { offset, source } = src
    return [offset, offset + (typeof source === 'string' ? source.length : 1)]
  }
  function parsePrelude(prelude) {
    let comment = ''
    let atComment = false
    let afterEmptyLine = false
    for (let i = 0; i < prelude.length; ++i) {
      const source = prelude[i]
      switch (source[0]) {
        case '#':
          comment +=
            (comment === '' ? '' : afterEmptyLine ? '\n\n' : '\n') +
            (source.substring(1) || ' ')
          atComment = true
          afterEmptyLine = false
          break
        case '%':
          if (prelude[i + 1]?.[0] !== '#') {
            i += 1
          }
          atComment = false
          break
        default:
          // This may be wrong after doc-end, but in that case it doesn't matter
          if (!atComment) {
            afterEmptyLine = true
          }
          atComment = false
      }
    }
    return {
      comment,
      afterEmptyLine
    }
  }
  /**
   * Compose a stream of CST nodes into a stream of YAML Documents.
   *
   * ```ts
   * import { Composer, Parser } from 'yaml'
   *
   * const src: string = ...
   * const tokens = new Parser().parse(src)
   * const docs = new Composer().compose(tokens)
   * ```
   */
  class Composer {
    constructor(options = {}) {
      this.doc = null
      this.atDirectives = false
      this.prelude = []
      this.errors = []
      this.warnings = []
      this.onError = (source, code, message, warning) => {
        const pos = getErrorPos(source)
        if (warning) {
          this.warnings.push(new errors.YAMLWarning(pos, code, message))
        } else {
          this.errors.push(new errors.YAMLParseError(pos, code, message))
        }
      }
      // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing
      this.directives = new directives.Directives({
        version: options.version || '1.2'
      })
      this.options = options
    }
    decorate(doc, afterDoc) {
      const { comment, afterEmptyLine } = parsePrelude(this.prelude)
      //console.log({ dc: doc.comment, prelude, comment })
      if (comment) {
        const dc = doc.contents
        if (afterDoc) {
          doc.comment = doc.comment ? `${doc.comment}\n${comment}` : comment
        } else if (afterEmptyLine || doc.directives.docStart || !dc) {
          doc.commentBefore = comment
        } else if (
          identity.isCollection(dc) &&
          !dc.flow &&
          dc.items.length > 0
        ) {
          let it = dc.items[0]
          if (identity.isPair(it)) {
            it = it.key
          }
          const cb = it.commentBefore
          it.commentBefore = cb ? `${comment}\n${cb}` : comment
        } else {
          const cb = dc.commentBefore
          dc.commentBefore = cb ? `${comment}\n${cb}` : comment
        }
      }
      if (afterDoc) {
        Array.prototype.push.apply(doc.errors, this.errors)
        Array.prototype.push.apply(doc.warnings, this.warnings)
      } else {
        doc.errors = this.errors
        doc.warnings = this.warnings
      }
      this.prelude = []
      this.errors = []
      this.warnings = []
    }
    /**
     * Current stream status information.
     *
     * Mostly useful at the end of input for an empty stream.
     */
    streamInfo() {
      return {
        comment: parsePrelude(this.prelude).comment,
        directives: this.directives,
        errors: this.errors,
        warnings: this.warnings
      }
    }
    /**
     * Compose tokens into documents.
     *
     * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.
     * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.
     */
    *compose(tokens, forceDoc = false, endOffset = -1) {
      for (const token of tokens) {
        yield* this.next(token)
      }
      yield* this.end(forceDoc, endOffset)
    }
    /** Advance the composer by one CST token. */
    *next(token) {
      if (node_process.env.LOG_STREAM) {
        console.dir(token, {
          depth: null
        })
      }
      switch (token.type) {
        case 'directive':
          this.directives.add(token.source, (offset, message, warning) => {
            const pos = getErrorPos(token)
            pos[0] += offset
            this.onError(pos, 'BAD_DIRECTIVE', message, warning)
          })
          this.prelude.push(token.source)
          this.atDirectives = true
          break
        case 'document': {
          const doc = composeDoc.composeDoc(
            this.options,
            this.directives,
            token,
            this.onError
          )
          if (this.atDirectives && !doc.directives.docStart) {
            this.onError(
              token,
              'MISSING_CHAR',
              'Missing directives-end/doc-start indicator line'
            )
          }
          this.decorate(doc, false)
          if (this.doc) {
            yield this.doc
          }
          this.doc = doc
          this.atDirectives = false
          break
        }
        case 'byte-order-mark':
        case 'space':
          break
        case 'comment':
        case 'newline':
          this.prelude.push(token.source)
          break
        case 'error': {
          const msg = token.source
            ? `${token.message}: ${JSON.stringify(token.source)}`
            : token.message
          const error = new errors.YAMLParseError(
            getErrorPos(token),
            'UNEXPECTED_TOKEN',
            msg
          )
          if (this.atDirectives || !this.doc) {
            this.errors.push(error)
          } else {
            this.doc.errors.push(error)
          }
          break
        }
        case 'doc-end': {
          if (!this.doc) {
            const msg = 'Unexpected doc-end without preceding document'
            this.errors.push(
              new errors.YAMLParseError(
                getErrorPos(token),
                'UNEXPECTED_TOKEN',
                msg
              )
            )
            break
          }
          this.doc.directives.docEnd = true
          const end = resolveEnd.resolveEnd(
            token.end,
            token.offset + token.source.length,
            this.doc.options.strict,
            this.onError
          )
          this.decorate(this.doc, true)
          if (end.comment) {
            const dc = this.doc.comment
            this.doc.comment = dc ? `${dc}\n${end.comment}` : end.comment
          }
          this.doc.range[2] = end.offset
          break
        }
        default:
          this.errors.push(
            new errors.YAMLParseError(
              getErrorPos(token),
              'UNEXPECTED_TOKEN',
              `Unsupported token ${token.type}`
            )
          )
      }
    }
    /**
     * Call at end of input to yield any remaining document.
     *
     * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.
     * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.
     */
    *end(forceDoc = false, endOffset = -1) {
      if (this.doc) {
        this.decorate(this.doc, true)
        yield this.doc
        this.doc = null
      } else if (forceDoc) {
        const opts = Object.assign(
          {
            _directives: this.directives
          },
          this.options
        )
        const doc = new Document.Document(undefined, opts)
        if (this.atDirectives) {
          this.onError(
            endOffset,
            'MISSING_CHAR',
            'Missing directives-end indicator line'
          )
        }
        doc.range = [0, endOffset, endOffset]
        this.decorate(doc, false)
        yield doc
      }
    }
  }
  composer.Composer = Composer
  return composer
}

const cst = {}

const cstScalar = {}

let hasRequiredCstScalar
function requireCstScalar() {
  if (hasRequiredCstScalar) {
    return cstScalar
  }
  hasRequiredCstScalar = 1
  const resolveBlockScalar = requireResolveBlockScalar()
  const resolveFlowScalar = requireResolveFlowScalar()
  const errors = requireErrors$3()
  const stringifyString = requireStringifyString()
  function resolveAsScalar(token, strict = true, onError) {
    if (token) {
      const _onError = (pos, code, message) => {
        const offset =
          typeof pos === 'number'
            ? pos
            : Array.isArray(pos)
              ? pos[0]
              : pos.offset
        if (onError) {
          onError(offset, code, message)
        } else {
          throw new errors.YAMLParseError([offset, offset + 1], code, message)
        }
      }
      switch (token.type) {
        case 'scalar':
        case 'single-quoted-scalar':
        case 'double-quoted-scalar':
          return resolveFlowScalar.resolveFlowScalar(token, strict, _onError)
        case 'block-scalar':
          return resolveBlockScalar.resolveBlockScalar(
            {
              options: {
                strict
              }
            },
            token,
            _onError
          )
      }
    }
    return null
  }
  /**
   * Create a new scalar token with `value`
   *
   * Values that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`,
   * as this function does not support any schema operations and won't check for such conflicts.
   *
   * @param value The string representation of the value, which will have its content properly indented.
   * @param context.end Comments and whitespace after the end of the value, or after the block scalar header. If undefined, a newline will be added.
   * @param context.implicitKey Being within an implicit key may affect the resolved type of the token's value.
   * @param context.indent The indent level of the token.
   * @param context.inFlow Is this scalar within a flow collection? This may affect the resolved type of the token's value.
   * @param context.offset The offset position of the token.
   * @param context.type The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.
   */
  function createScalarToken(value, context) {
    const {
      implicitKey = false,
      indent,
      inFlow = false,
      offset = -1,
      type = 'PLAIN'
    } = context
    const source = stringifyString.stringifyString(
      {
        type,
        value
      },
      {
        implicitKey,
        indent: indent > 0 ? ' '.repeat(indent) : '',
        inFlow,
        options: {
          blockQuote: true,
          lineWidth: -1
        }
      }
    )
    const end = context.end ?? [
      {
        type: 'newline',
        offset: -1,
        indent,
        source: '\n'
      }
    ]
    switch (source[0]) {
      case '|':
      case '>': {
        const he = source.indexOf('\n')
        const head = source.substring(0, he)
        const body = source.substring(he + 1) + '\n'
        const props = [
          {
            type: 'block-scalar-header',
            offset,
            indent,
            source: head
          }
        ]
        if (!addEndtoBlockProps(props, end)) {
          props.push({
            type: 'newline',
            offset: -1,
            indent,
            source: '\n'
          })
        }
        return {
          type: 'block-scalar',
          offset,
          indent,
          props,
          source: body
        }
      }
      case '"':
        return {
          type: 'double-quoted-scalar',
          offset,
          indent,
          source,
          end
        }
      case "'":
        return {
          type: 'single-quoted-scalar',
          offset,
          indent,
          source,
          end
        }
      default:
        return {
          type: 'scalar',
          offset,
          indent,
          source,
          end
        }
    }
  }
  /**
   * Set the value of `token` to the given string `value`, overwriting any previous contents and type that it may have.
   *
   * Best efforts are made to retain any comments previously associated with the `token`,
   * though all contents within a collection's `items` will be overwritten.
   *
   * Values that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`,
   * as this function does not support any schema operations and won't check for such conflicts.
   *
   * @param token Any token. If it does not include an `indent` value, the value will be stringified as if it were an implicit key.
   * @param value The string representation of the value, which will have its content properly indented.
   * @param context.afterKey In most cases, values after a key should have an additional level of indentation.
   * @param context.implicitKey Being within an implicit key may affect the resolved type of the token's value.
   * @param context.inFlow Being within a flow collection may affect the resolved type of the token's value.
   * @param context.type The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.
   */
  function setScalarValue(token, value, context = {}) {
    let {
      afterKey = false,
      implicitKey = false,
      inFlow = false,
      type
    } = context
    let indent = 'indent' in token ? token.indent : null
    if (afterKey && typeof indent === 'number') {
      indent += 2
    }
    if (!type) {
      switch (token.type) {
        case 'single-quoted-scalar':
          type = 'QUOTE_SINGLE'
          break
        case 'double-quoted-scalar':
          type = 'QUOTE_DOUBLE'
          break
        case 'block-scalar': {
          const header = token.props[0]
          if (header.type !== 'block-scalar-header')
            throw new Error('Invalid block scalar header')
          type = header.source[0] === '>' ? 'BLOCK_FOLDED' : 'BLOCK_LITERAL'
          break
        }
        default:
          type = 'PLAIN'
      }
    }
    const source = stringifyString.stringifyString(
      {
        type,
        value
      },
      {
        implicitKey: implicitKey || indent === null,
        indent: indent !== null && indent > 0 ? ' '.repeat(indent) : '',
        inFlow,
        options: {
          blockQuote: true,
          lineWidth: -1
        }
      }
    )
    switch (source[0]) {
      case '|':
      case '>':
        setBlockScalarValue(token, source)
        break
      case '"':
        setFlowScalarValue(token, source, 'double-quoted-scalar')
        break
      case "'":
        setFlowScalarValue(token, source, 'single-quoted-scalar')
        break
      default:
        setFlowScalarValue(token, source, 'scalar')
    }
  }
  function setBlockScalarValue(token, source) {
    const he = source.indexOf('\n')
    const head = source.substring(0, he)
    const body = source.substring(he + 1) + '\n'
    if (token.type === 'block-scalar') {
      const header = token.props[0]
      if (header.type !== 'block-scalar-header') {
        throw new Error('Invalid block scalar header')
      }
      header.source = head
      token.source = body
    } else {
      const { offset } = token
      const indent = 'indent' in token ? token.indent : -1
      const props = [
        {
          type: 'block-scalar-header',
          offset,
          indent,
          source: head
        }
      ]
      if (!addEndtoBlockProps(props, 'end' in token ? token.end : undefined)) {
        props.push({
          type: 'newline',
          offset: -1,
          indent,
          source: '\n'
        })
      }
      for (const key of Object.keys(token)) {
        if (key !== 'type' && key !== 'offset') delete token[key]
      }
      Object.assign(token, {
        type: 'block-scalar',
        indent,
        props,
        source: body
      })
    }
  }
  /** @returns `true` if last token is a newline */
  function addEndtoBlockProps(props, end) {
    if (end) {
      for (const st of end)
        switch (st.type) {
          case 'space':
          case 'comment':
            props.push(st)
            break
          case 'newline':
            props.push(st)
            return true
        }
    }
    return false
  }
  function setFlowScalarValue(token, source, type) {
    switch (token.type) {
      case 'scalar':
      case 'double-quoted-scalar':
      case 'single-quoted-scalar':
        token.type = type
        token.source = source
        break
      case 'block-scalar': {
        const end = token.props.slice(1)
        let oa = source.length
        if (token.props[0].type === 'block-scalar-header') {
          oa -= token.props[0].source.length
        }
        for (const tok of end) {
          tok.offset += oa
        }
        delete token.props
        Object.assign(token, {
          type,
          source,
          end
        })
        break
      }
      case 'block-map':
      case 'block-seq': {
        const offset = token.offset + source.length
        const nl = {
          type: 'newline',
          offset,
          indent: token.indent,
          source: '\n'
        }
        delete token.items
        Object.assign(token, {
          type,
          source,
          end: [nl]
        })
        break
      }
      default: {
        const indent = 'indent' in token ? token.indent : -1
        const end =
          'end' in token && Array.isArray(token.end)
            ? token.end.filter(
                st =>
                  st.type === 'space' ||
                  st.type === 'comment' ||
                  st.type === 'newline'
              )
            : []
        for (const key of Object.keys(token)) {
          if (key !== 'type' && key !== 'offset') delete token[key]
        }
        Object.assign(token, {
          type,
          indent,
          source,
          end
        })
      }
    }
  }
  cstScalar.createScalarToken = createScalarToken
  cstScalar.resolveAsScalar = resolveAsScalar
  cstScalar.setScalarValue = setScalarValue
  return cstScalar
}

const cstStringify = {}

let hasRequiredCstStringify
function requireCstStringify() {
  if (hasRequiredCstStringify) {
    return cstStringify
  }
  hasRequiredCstStringify = 1

  /**
   * Stringify a CST document, token, or collection item
   *
   * Fair warning: This applies no validation whatsoever, and
   * simply concatenates the sources in their logical order.
   */
  const stringify = cst =>
    'type' in cst ? stringifyToken(cst) : stringifyItem(cst)
  function stringifyToken(token) {
    switch (token.type) {
      case 'block-scalar': {
        let res = ''
        for (const tok of token.props) {
          res += stringifyToken(tok)
        }
        return res + token.source
      }
      case 'block-map':
      case 'block-seq': {
        let res = ''
        for (const item of token.items) {
          res += stringifyItem(item)
        }
        return res
      }
      case 'flow-collection': {
        let res = token.start.source
        for (const item of token.items) {
          res += stringifyItem(item)
        }
        for (const st of token.end) {
          res += st.source
        }
        return res
      }
      case 'document': {
        let res = stringifyItem(token)
        if (token.end) {
          for (const st of token.end) res += st.source
        }
        return res
      }
      default: {
        let res = token.source
        if ('end' in token && token.end) {
          for (const st of token.end) res += st.source
        }
        return res
      }
    }
  }
  function stringifyItem({ start, key, sep, value }) {
    let res = ''
    for (const st of start) {
      res += st.source
    }
    if (key) {
      res += stringifyToken(key)
    }
    if (sep) {
      for (const st of sep) res += st.source
    }
    if (value) {
      res += stringifyToken(value)
    }
    return res
  }
  cstStringify.stringify = stringify
  return cstStringify
}

const cstVisit = {}

let hasRequiredCstVisit
function requireCstVisit() {
  if (hasRequiredCstVisit) {
    return cstVisit
  }
  hasRequiredCstVisit = 1
  const BREAK = Symbol('break visit')
  const SKIP = Symbol('skip children')
  const REMOVE = Symbol('remove item')
  /**
   * Apply a visitor to a CST document or item.
   *
   * Walks through the tree (depth-first) starting from the root, calling a
   * `visitor` function with two arguments when entering each item:
   *   - `item`: The current item, which included the following members:
   *     - `start: SourceToken[]` – Source tokens before the key or value,
   *       possibly including its anchor or tag.
   *     - `key?: Token | null` – Set for pair values. May then be `null`, if
   *       the key before the `:` separator is empty.
   *     - `sep?: SourceToken[]` – Source tokens between the key and the value,
   *       which should include the `:` map value indicator if `value` is set.
   *     - `value?: Token` – The value of a sequence item, or of a map pair.
   *   - `path`: The steps from the root to the current node, as an array of
   *     `['key' | 'value', number]` tuples.
   *
   * The return value of the visitor may be used to control the traversal:
   *   - `undefined` (default): Do nothing and continue
   *   - `visit.SKIP`: Do not visit the children of this token, continue with
   *      next sibling
   *   - `visit.BREAK`: Terminate traversal completely
   *   - `visit.REMOVE`: Remove the current item, then continue with the next one
   *   - `number`: Set the index of the next step. This is useful especially if
   *     the index of the current token has changed.
   *   - `function`: Define the next visitor for this item. After the original
   *     visitor is called on item entry, next visitors are called after handling
   *     a non-empty `key` and when exiting the item.
   */
  function visit(cst, visitor) {
    if ('type' in cst && cst.type === 'document') {
      cst = {
        start: cst.start,
        value: cst.value
      }
    }
    _visit(Object.freeze([]), cst, visitor)
  }
  // Without the `as symbol` casts, TS declares these in the `visit`
  // namespace using `var`, but then complains about that because
  // `unique symbol` must be `const`.
  /** Terminate visit traversal completely */
  visit.BREAK = BREAK
  /** Do not visit the children of the current item */
  visit.SKIP = SKIP
  /** Remove the current item */
  visit.REMOVE = REMOVE
  /** Find the item at `path` from `cst` as the root */
  visit.itemAtPath = (cst, path) => {
    let item = cst
    for (const [field, index] of path) {
      const tok = item?.[field]
      if (tok && 'items' in tok) {
        item = tok.items[index]
      } else {
        return undefined
      }
    }
    return item
  }
  /**
   * Get the immediate parent collection of the item at `path` from `cst` as the root.
   *
   * Throws an error if the collection is not found, which should never happen if the item itself exists.
   */
  visit.parentCollection = (cst, path) => {
    const parent = visit.itemAtPath(cst, path.slice(0, -1))
    const field = path[path.length - 1][0]
    const coll = parent?.[field]
    if (coll && 'items' in coll) {
      return coll
    }
    throw new Error('Parent collection not found')
  }
  function _visit(path, item, visitor) {
    let ctrl = visitor(item, path)
    if (typeof ctrl === 'symbol') {
      return ctrl
    }
    for (const field of ['key', 'value']) {
      const token = item[field]
      if (token && 'items' in token) {
        for (let i = 0; i < token.items.length; ++i) {
          const ci = _visit(
            Object.freeze(path.concat([[field, i]])),
            token.items[i],
            visitor
          )
          if (typeof ci === 'number') {
            i = ci - 1
          } else if (ci === BREAK) {
            return BREAK
          } else if (ci === REMOVE) {
            token.items.splice(i, 1)
            i -= 1
          }
        }
        if (typeof ctrl === 'function' && field === 'key') {
          ctrl = ctrl(item, path)
        }
      }
    }
    return typeof ctrl === 'function' ? ctrl(item, path) : ctrl
  }
  cstVisit.visit = visit
  return cstVisit
}

let hasRequiredCst
function requireCst() {
  if (hasRequiredCst) {
    return cst
  }
  hasRequiredCst = 1
  const cstScalar = requireCstScalar()
  const cstStringify = requireCstStringify()
  const cstVisit = requireCstVisit()

  /** The byte order mark */
  const BOM = '\u{FEFF}'
  /** Start of doc-mode */
  const DOCUMENT = '\x02' // C0: Start of Text
  /** Unexpected end of flow-mode */
  const FLOW_END = '\x18' // C0: Cancel
  /** Next token is a scalar value */
  const SCALAR = '\x1f' // C0: Unit Separator
  /** @returns `true` if `token` is a flow or block collection */
  const isCollection = token => !!token && 'items' in token
  /** @returns `true` if `token` is a flow or block scalar; not an alias */
  const isScalar = token =>
    !!token &&
    (token.type === 'scalar' ||
      token.type === 'single-quoted-scalar' ||
      token.type === 'double-quoted-scalar' ||
      token.type === 'block-scalar')
  /* istanbul ignore next */
  /** Get a printable representation of a lexer token */
  function prettyToken(token) {
    switch (token) {
      case BOM:
        return '<BOM>'
      case DOCUMENT:
        return '<DOC>'
      case FLOW_END:
        return '<FLOW_END>'
      case SCALAR:
        return '<SCALAR>'
      default:
        return JSON.stringify(token)
    }
  }
  /** Identify the type of a lexer token. May return `null` for unknown tokens. */
  function tokenType(source) {
    switch (source) {
      case BOM:
        return 'byte-order-mark'
      case DOCUMENT:
        return 'doc-mode'
      case FLOW_END:
        return 'flow-error-end'
      case SCALAR:
        return 'scalar'
      case '---':
        return 'doc-start'
      case '...':
        return 'doc-end'
      case '':
      case '\n':
      case '\r\n':
        return 'newline'
      case '-':
        return 'seq-item-ind'
      case '?':
        return 'explicit-key-ind'
      case ':':
        return 'map-value-ind'
      case '{':
        return 'flow-map-start'
      case '}':
        return 'flow-map-end'
      case '[':
        return 'flow-seq-start'
      case ']':
        return 'flow-seq-end'
      case ',':
        return 'comma'
    }
    switch (source[0]) {
      case ' ':
      case '\t':
        return 'space'
      case '#':
        return 'comment'
      case '%':
        return 'directive-line'
      case '*':
        return 'alias'
      case '&':
        return 'anchor'
      case '!':
        return 'tag'
      case "'":
        return 'single-quoted-scalar'
      case '"':
        return 'double-quoted-scalar'
      case '|':
      case '>':
        return 'block-scalar-header'
    }
    return null
  }
  cst.createScalarToken = cstScalar.createScalarToken
  cst.resolveAsScalar = cstScalar.resolveAsScalar
  cst.setScalarValue = cstScalar.setScalarValue
  cst.stringify = cstStringify.stringify
  cst.visit = cstVisit.visit
  cst.BOM = BOM
  cst.DOCUMENT = DOCUMENT
  cst.FLOW_END = FLOW_END
  cst.SCALAR = SCALAR
  cst.isCollection = isCollection
  cst.isScalar = isScalar
  cst.prettyToken = prettyToken
  cst.tokenType = tokenType
  return cst
}

const lexer = {}

let hasRequiredLexer
function requireLexer() {
  if (hasRequiredLexer) {
    return lexer
  }
  hasRequiredLexer = 1
  const cst = requireCst()

  /*
  START -> stream
  	stream
    directive -> line-end -> stream
    indent + line-end -> stream
    [else] -> line-start
  	line-end
    comment -> line-end
    newline -> .
    input-end -> END
  	line-start
    doc-start -> doc
    doc-end -> stream
    [else] -> indent -> block-start
  	block-start
    seq-item-start -> block-start
    explicit-key-start -> block-start
    map-value-start -> block-start
    [else] -> doc
  	doc
    line-end -> line-start
    spaces -> doc
    anchor -> doc
    tag -> doc
    flow-start -> flow -> doc
    flow-end -> error -> doc
    seq-item-start -> error -> doc
    explicit-key-start -> error -> doc
    map-value-start -> doc
    alias -> doc
    quote-start -> quoted-scalar -> doc
    block-scalar-header -> line-end -> block-scalar(min) -> line-start
    [else] -> plain-scalar(false, min) -> doc
  	flow
    line-end -> flow
    spaces -> flow
    anchor -> flow
    tag -> flow
    flow-start -> flow -> flow
    flow-end -> .
    seq-item-start -> error -> flow
    explicit-key-start -> flow
    map-value-start -> flow
    alias -> flow
    quote-start -> quoted-scalar -> flow
    comma -> flow
    [else] -> plain-scalar(true, 0) -> flow
  	quoted-scalar
    quote-end -> .
    [else] -> quoted-scalar
  	block-scalar(min)
    newline + peek(indent < min) -> .
    [else] -> block-scalar(min)
  	plain-scalar(is-flow, min)
    scalar-end(is-flow) -> .
    peek(newline + (indent < min)) -> .
    [else] -> plain-scalar(min)
  */
  function isEmpty(ch) {
    switch (ch) {
      case undefined:
      case ' ':
      case '\n':
      case '\r':
      case '\t':
        return true
      default:
        return false
    }
  }
  const hexDigits = new Set('0123456789ABCDEFabcdef')
  const tagChars = new Set(
    "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-#;/?:@&=+$_.!~*'()"
  )
  const flowIndicatorChars = new Set(',[]{}')
  const invalidAnchorChars = new Set(' ,[]{}\n\r\t')
  const isNotAnchorChar = ch => !ch || invalidAnchorChars.has(ch)
  /**
   * Splits an input string into lexical tokens, i.e. smaller strings that are
   * easily identifiable by `tokens.tokenType()`.
   *
   * Lexing starts always in a "stream" context. Incomplete input may be buffered
   * until a complete token can be emitted.
   *
   * In addition to slices of the original input, the following control characters
   * may also be emitted:
   *
   * - `\x02` (Start of Text): A document starts with the next token
   * - `\x18` (Cancel): Unexpected end of flow-mode (indicates an error)
   * - `\x1f` (Unit Separator): Next token is a scalar value
   * - `\u{FEFF}` (Byte order mark): Emitted separately outside documents
   */
  class Lexer {
    constructor() {
      /**
       * Flag indicating whether the end of the current buffer marks the end of
       * all input
       */
      this.atEnd = false
      /**
       * Explicit indent set in block scalar header, as an offset from the current
       * minimum indent, so e.g. set to 1 from a header `|2+`. Set to -1 if not
       * explicitly set.
       */
      this.blockScalarIndent = -1
      /**
       * Block scalars that include a + (keep) chomping indicator in their header
       * include trailing empty lines, which are otherwise excluded from the
       * scalar's contents.
       */
      this.blockScalarKeep = false
      /** Current input */
      this.buffer = ''
      /**
       * Flag noting whether the map value indicator : can immediately follow this
       * node within a flow context.
       */
      this.flowKey = false
      /** Count of surrounding flow collection levels. */
      this.flowLevel = 0
      /**
       * Minimum level of indentation required for next lines to be parsed as a
       * part of the current scalar value.
       */
      this.indentNext = 0
      /** Indentation level of the current line. */
      this.indentValue = 0
      /** Position of the next \n character. */
      this.lineEndPos = null
      /** Stores the state of the lexer if reaching the end of incpomplete input */
      this.next = null
      /** A pointer to `buffer`; the current position of the lexer. */
      this.pos = 0
    }
    /**
     * Generate YAML tokens from the `source` string. If `incomplete`,
     * a part of the last line may be left as a buffer for the next call.
     *
     * @returns A generator of lexical tokens
     */
    *lex(source, incomplete = false) {
      if (source) {
        if (typeof source !== 'string') {
          throw TypeError('source is not a string')
        }
        this.buffer = this.buffer ? this.buffer + source : source
        this.lineEndPos = null
      }
      this.atEnd = !incomplete
      let next = this.next ?? 'stream'
      while (next && (incomplete || this.hasChars(1))) {
        next = yield* this.parseNext(next)
      }
    }
    atLineEnd() {
      let i = this.pos
      let ch = this.buffer[i]
      while (ch === ' ' || ch === '\t') {
        ch = this.buffer[++i]
      }
      if (!ch || ch === '#' || ch === '\n') {
        return true
      }
      if (ch === '\r') {
        return this.buffer[i + 1] === '\n'
      }
      return false
    }
    charAt(n) {
      return this.buffer[this.pos + n]
    }
    continueScalar(offset) {
      let ch = this.buffer[offset]
      if (this.indentNext > 0) {
        let indent = 0
        while (ch === ' ') {
          ch = this.buffer[++indent + offset]
        }
        if (ch === '\r') {
          const next = this.buffer[indent + offset + 1]
          if (next === '\n' || (!next && !this.atEnd)) {
            return offset + indent + 1
          }
        }
        return ch === '\n' || indent >= this.indentNext || (!ch && !this.atEnd)
          ? offset + indent
          : -1
      }
      if (ch === '-' || ch === '.') {
        const dt = this.buffer.substr(offset, 3)
        if (
          (dt === '---' || dt === '...') &&
          isEmpty(this.buffer[offset + 3])
        ) {
          return -1
        }
      }
      return offset
    }
    getLine() {
      let end = this.lineEndPos
      if (typeof end !== 'number' || (end !== -1 && end < this.pos)) {
        end = this.buffer.indexOf('\n', this.pos)
        this.lineEndPos = end
      }
      if (end === -1) {
        return this.atEnd ? this.buffer.substring(this.pos) : null
      }
      if (this.buffer[end - 1] === '\r') {
        end -= 1
      }
      return this.buffer.substring(this.pos, end)
    }
    hasChars(n) {
      return this.pos + n <= this.buffer.length
    }
    setNext(state) {
      this.buffer = this.buffer.substring(this.pos)
      this.pos = 0
      this.lineEndPos = null
      this.next = state
      return null
    }
    peek(n) {
      return this.buffer.substr(this.pos, n)
    }
    *parseNext(next) {
      switch (next) {
        case 'stream':
          return yield* this.parseStream()
        case 'line-start':
          return yield* this.parseLineStart()
        case 'block-start':
          return yield* this.parseBlockStart()
        case 'doc':
          return yield* this.parseDocument()
        case 'flow':
          return yield* this.parseFlowCollection()
        case 'quoted-scalar':
          return yield* this.parseQuotedScalar()
        case 'block-scalar':
          return yield* this.parseBlockScalar()
        case 'plain-scalar':
          return yield* this.parsePlainScalar()
      }
    }
    *parseStream() {
      let line = this.getLine()
      if (line === null) {
        return this.setNext('stream')
      }
      if (line[0] === cst.BOM) {
        yield* this.pushCount(1)
        line = line.substring(1)
      }
      if (line[0] === '%') {
        let dirEnd = line.length
        let cs = line.indexOf('#')
        while (cs !== -1) {
          const ch = line[cs - 1]
          if (ch === ' ' || ch === '\t') {
            dirEnd = cs - 1
            break
          } else {
            cs = line.indexOf('#', cs + 1)
          }
        }
        while (true) {
          const ch = line[dirEnd - 1]
          if (ch === ' ' || ch === '\t') {
            dirEnd -= 1
          } else {
            break
          }
        }
        const n =
          (yield* this.pushCount(dirEnd)) + (yield* this.pushSpaces(true))
        yield* this.pushCount(line.length - n) // possible comment
        this.pushNewline()
        return 'stream'
      }
      if (this.atLineEnd()) {
        const sp = yield* this.pushSpaces(true)
        yield* this.pushCount(line.length - sp)
        yield* this.pushNewline()
        return 'stream'
      }
      yield cst.DOCUMENT
      return yield* this.parseLineStart()
    }
    *parseLineStart() {
      const ch = this.charAt(0)
      if (!ch && !this.atEnd) {
        return this.setNext('line-start')
      }
      if (ch === '-' || ch === '.') {
        if (!this.atEnd && !this.hasChars(4)) {
          return this.setNext('line-start')
        }
        const s = this.peek(3)
        if ((s === '---' || s === '...') && isEmpty(this.charAt(3))) {
          yield* this.pushCount(3)
          this.indentValue = 0
          this.indentNext = 0
          return s === '---' ? 'doc' : 'stream'
        }
      }
      this.indentValue = yield* this.pushSpaces(false)
      if (this.indentNext > this.indentValue && !isEmpty(this.charAt(1))) {
        this.indentNext = this.indentValue
      }
      return yield* this.parseBlockStart()
    }
    *parseBlockStart() {
      const [ch0, ch1] = this.peek(2)
      if (!ch1 && !this.atEnd) {
        return this.setNext('block-start')
      }
      if ((ch0 === '-' || ch0 === '?' || ch0 === ':') && isEmpty(ch1)) {
        const n = (yield* this.pushCount(1)) + (yield* this.pushSpaces(true))
        this.indentNext = this.indentValue + 1
        this.indentValue += n
        return yield* this.parseBlockStart()
      }
      return 'doc'
    }
    *parseDocument() {
      yield* this.pushSpaces(true)
      const line = this.getLine()
      if (line === null) {
        return this.setNext('doc')
      }
      let n = yield* this.pushIndicators()
      switch (line[n]) {
        case '#':
          yield* this.pushCount(line.length - n)
        // fallthrough
        case undefined:
          yield* this.pushNewline()
          return yield* this.parseLineStart()
        case '{':
        case '[':
          yield* this.pushCount(1)
          this.flowKey = false
          this.flowLevel = 1
          return 'flow'
        case '}':
        case ']':
          // this is an error
          yield* this.pushCount(1)
          return 'doc'
        case '*':
          yield* this.pushUntil(isNotAnchorChar)
          return 'doc'
        case '"':
        case "'":
          return yield* this.parseQuotedScalar()
        case '|':
        case '>':
          n += yield* this.parseBlockScalarHeader()
          n += yield* this.pushSpaces(true)
          yield* this.pushCount(line.length - n)
          yield* this.pushNewline()
          return yield* this.parseBlockScalar()
        default:
          return yield* this.parsePlainScalar()
      }
    }
    *parseFlowCollection() {
      let nl, sp
      let indent = -1
      do {
        nl = yield* this.pushNewline()
        if (nl > 0) {
          sp = yield* this.pushSpaces(false)
          this.indentValue = indent = sp
        } else {
          sp = 0
        }
        sp += yield* this.pushSpaces(true)
      } while (nl + sp > 0)
      const line = this.getLine()
      if (line === null) {
        return this.setNext('flow')
      }
      if (
        (indent !== -1 && indent < this.indentNext && line[0] !== '#') ||
        (indent === 0 &&
          (line.startsWith('---') || line.startsWith('...')) &&
          isEmpty(line[3]))
      ) {
        // Allowing for the terminal ] or } at the same (rather than greater)
        // indent level as the initial [ or { is technically invalid, but
        // failing here would be surprising to users.
        const atFlowEndMarker =
          indent === this.indentNext - 1 &&
          this.flowLevel === 1 &&
          (line[0] === ']' || line[0] === '}')
        if (!atFlowEndMarker) {
          // this is an error
          this.flowLevel = 0
          yield cst.FLOW_END
          return yield* this.parseLineStart()
        }
      }
      let n = 0
      while (line[n] === ',') {
        n += yield* this.pushCount(1)
        n += yield* this.pushSpaces(true)
        this.flowKey = false
      }
      n += yield* this.pushIndicators()
      switch (line[n]) {
        case undefined:
          return 'flow'
        case '#':
          yield* this.pushCount(line.length - n)
          return 'flow'
        case '{':
        case '[':
          yield* this.pushCount(1)
          this.flowKey = false
          this.flowLevel += 1
          return 'flow'
        case '}':
        case ']':
          yield* this.pushCount(1)
          this.flowKey = true
          this.flowLevel -= 1
          return this.flowLevel ? 'flow' : 'doc'
        case '*':
          yield* this.pushUntil(isNotAnchorChar)
          return 'flow'
        case '"':
        case "'":
          this.flowKey = true
          return yield* this.parseQuotedScalar()
        case ':': {
          const next = this.charAt(1)
          if (this.flowKey || isEmpty(next) || next === ',') {
            this.flowKey = false
            yield* this.pushCount(1)
            yield* this.pushSpaces(true)
            return 'flow'
          }
        }
        // fallthrough
        default:
          this.flowKey = false
          return yield* this.parsePlainScalar()
      }
    }
    *parseQuotedScalar() {
      const quote = this.charAt(0)
      let end = this.buffer.indexOf(quote, this.pos + 1)
      if (quote === "'") {
        while (end !== -1 && this.buffer[end + 1] === "'") {
          end = this.buffer.indexOf("'", end + 2)
        }
      } else {
        // double-quote
        while (end !== -1) {
          let n = 0
          while (this.buffer[end - 1 - n] === '\\') {
            n += 1
          }
          if (n % 2 === 0) {
            break
          }
          end = this.buffer.indexOf('"', end + 1)
        }
      }
      // Only looking for newlines within the quotes
      const qb = this.buffer.substring(0, end)
      let nl = qb.indexOf('\n', this.pos)
      if (nl !== -1) {
        while (nl !== -1) {
          const cs = this.continueScalar(nl + 1)
          if (cs === -1) {
            break
          }
          nl = qb.indexOf('\n', cs)
        }
        if (nl !== -1) {
          // this is an error caused by an unexpected unindent
          end = nl - (qb[nl - 1] === '\r' ? 2 : 1)
        }
      }
      if (end === -1) {
        if (!this.atEnd) {
          return this.setNext('quoted-scalar')
        }
        end = this.buffer.length
      }
      yield* this.pushToIndex(end + 1, false)
      return this.flowLevel ? 'flow' : 'doc'
    }
    *parseBlockScalarHeader() {
      this.blockScalarIndent = -1
      this.blockScalarKeep = false
      let i = this.pos
      while (true) {
        const ch = this.buffer[++i]
        if (ch === '+') {
          this.blockScalarKeep = true
        } else if (ch > '0' && ch <= '9') {
          this.blockScalarIndent = Number(ch) - 1
        } else if (ch !== '-') {
          break
        }
      }
      return yield* this.pushUntil(ch => isEmpty(ch) || ch === '#')
    }
    *parseBlockScalar() {
      let nl = this.pos - 1 // may be -1 if this.pos === 0
      let indent = 0
      let ch
      loop: for (let i = this.pos; (ch = this.buffer[i]); ++i) {
        switch (ch) {
          case ' ':
            indent += 1
            break
          case '\n':
            nl = i
            indent = 0
            break
          case '\r': {
            const next = this.buffer[i + 1]
            if (!next && !this.atEnd) {
              return this.setNext('block-scalar')
            }
            if (next === '\n') {
              break
            }
          }
          // fallthrough
          default:
            break loop
        }
      }
      if (!ch && !this.atEnd) {
        return this.setNext('block-scalar')
      }
      if (indent >= this.indentNext) {
        if (this.blockScalarIndent === -1) {
          this.indentNext = indent
        } else {
          this.indentNext =
            this.blockScalarIndent +
            (this.indentNext === 0 ? 1 : this.indentNext)
        }
        do {
          const cs = this.continueScalar(nl + 1)
          if (cs === -1) {
            break
          }
          nl = this.buffer.indexOf('\n', cs)
        } while (nl !== -1)
        if (nl === -1) {
          if (!this.atEnd) {
            return this.setNext('block-scalar')
          }
          nl = this.buffer.length
        }
      }
      // Trailing insufficiently indented tabs are invalid.
      // To catch that during parsing, we include them in the block scalar value.
      let i = nl + 1
      ch = this.buffer[i]
      while (ch === ' ') {
        ch = this.buffer[++i]
      }
      if (ch === '\t') {
        while (ch === '\t' || ch === ' ' || ch === '\r' || ch === '\n') {
          ch = this.buffer[++i]
        }
        nl = i - 1
      } else if (!this.blockScalarKeep) {
        do {
          let i = nl - 1
          let ch = this.buffer[i]
          if (ch === '\r') {
            ch = this.buffer[--i]
          }
          const lastChar = i // Drop the line if last char not more indented
          while (ch === ' ') {
            ch = this.buffer[--i]
          }
          if (ch === '\n' && i >= this.pos && i + 1 + indent > lastChar) {
            nl = i
          } else {
            break
          }
        } while (true)
      }
      yield cst.SCALAR
      yield* this.pushToIndex(nl + 1, true)
      return yield* this.parseLineStart()
    }
    *parsePlainScalar() {
      const inFlow = this.flowLevel > 0
      let end = this.pos - 1
      let i = this.pos - 1
      let ch
      while ((ch = this.buffer[++i])) {
        if (ch === ':') {
          const next = this.buffer[i + 1]
          if (isEmpty(next) || (inFlow && flowIndicatorChars.has(next))) {
            break
          }
          end = i
        } else if (isEmpty(ch)) {
          let next = this.buffer[i + 1]
          if (ch === '\r') {
            if (next === '\n') {
              i += 1
              ch = '\n'
              next = this.buffer[i + 1]
            } else {
              end = i
            }
          }
          if (next === '#' || (inFlow && flowIndicatorChars.has(next))) {
            break
          }
          if (ch === '\n') {
            const cs = this.continueScalar(i + 1)
            if (cs === -1) {
              break
            }
            i = Math.max(i, cs - 2) // to advance, but still account for ' #'
          }
        } else {
          if (inFlow && flowIndicatorChars.has(ch)) {
            break
          }
          end = i
        }
      }
      if (!ch && !this.atEnd) {
        return this.setNext('plain-scalar')
      }
      yield cst.SCALAR
      yield* this.pushToIndex(end + 1, true)
      return inFlow ? 'flow' : 'doc'
    }
    *pushCount(n) {
      if (n > 0) {
        yield this.buffer.substr(this.pos, n)
        this.pos += n
        return n
      }
      return 0
    }
    *pushToIndex(i, allowEmpty) {
      const s = this.buffer.slice(this.pos, i)
      if (s) {
        yield s
        this.pos += s.length
        return s.length
      } else if (allowEmpty) {
        yield ''
      }
      return 0
    }
    *pushIndicators() {
      switch (this.charAt(0)) {
        case '!':
          return (
            (yield* this.pushTag()) +
            (yield* this.pushSpaces(true)) +
            (yield* this.pushIndicators())
          )
        case '&':
          return (
            (yield* this.pushUntil(isNotAnchorChar)) +
            (yield* this.pushSpaces(true)) +
            (yield* this.pushIndicators())
          )
        case '-': // this is an error
        case '?': // this is an error outside flow collections
        case ':': {
          const inFlow = this.flowLevel > 0
          const ch1 = this.charAt(1)
          if (isEmpty(ch1) || (inFlow && flowIndicatorChars.has(ch1))) {
            if (!inFlow) {
              this.indentNext = this.indentValue + 1
            } else if (this.flowKey) {
              this.flowKey = false
            }
            return (
              (yield* this.pushCount(1)) +
              (yield* this.pushSpaces(true)) +
              (yield* this.pushIndicators())
            )
          }
        }
      }
      return 0
    }
    *pushTag() {
      if (this.charAt(1) === '<') {
        let i = this.pos + 2
        let ch = this.buffer[i]
        while (!isEmpty(ch) && ch !== '>') {
          ch = this.buffer[++i]
        }
        return yield* this.pushToIndex(ch === '>' ? i + 1 : i, false)
      } else {
        let i = this.pos + 1
        let ch = this.buffer[i]
        while (ch) {
          if (tagChars.has(ch)) {
            ch = this.buffer[++i]
          } else if (
            ch === '%' &&
            hexDigits.has(this.buffer[i + 1]) &&
            hexDigits.has(this.buffer[i + 2])
          ) {
            ch = this.buffer[(i += 3)]
          } else {
            break
          }
        }
        return yield* this.pushToIndex(i, false)
      }
    }
    *pushNewline() {
      const ch = this.buffer[this.pos]
      if (ch === '\n') {
        return yield* this.pushCount(1)
      } else if (ch === '\r' && this.charAt(1) === '\n') {
        return yield* this.pushCount(2)
      } else {
        return 0
      }
    }
    *pushSpaces(allowTabs) {
      let i = this.pos - 1
      let ch
      do {
        ch = this.buffer[++i]
      } while (ch === ' ' || (allowTabs && ch === '\t'))
      const n = i - this.pos
      if (n > 0) {
        yield this.buffer.substr(this.pos, n)
        this.pos = i
      }
      return n
    }
    *pushUntil(test) {
      let i = this.pos
      let ch = this.buffer[i]
      while (!test(ch)) {
        ch = this.buffer[++i]
      }
      return yield* this.pushToIndex(i, false)
    }
  }
  lexer.Lexer = Lexer
  return lexer
}

const lineCounter = {}

let hasRequiredLineCounter
function requireLineCounter() {
  if (hasRequiredLineCounter) {
    return lineCounter
  }
  hasRequiredLineCounter = 1

  /**
   * Tracks newlines during parsing in order to provide an efficient API for
   * determining the one-indexed `{ line, col }` position for any offset
   * within the input.
   */
  class LineCounter {
    constructor() {
      this.lineStarts = []
      /**
       * Should be called in ascending order. Otherwise, call
       * `lineCounter.lineStarts.sort()` before calling `linePos()`.
       */
      this.addNewLine = offset => this.lineStarts.push(offset)
      /**
       * Performs a binary search and returns the 1-indexed { line, col }
       * position of `offset`. If `line === 0`, `addNewLine` has never been
       * called or `offset` is before the first known newline.
       */
      this.linePos = offset => {
        let low = 0
        let high = this.lineStarts.length
        while (low < high) {
          const mid = (low + high) >> 1 // Math.floor((low + high) / 2)
          if (this.lineStarts[mid] < offset) {
            low = mid + 1
          } else {
            high = mid
          }
        }
        if (this.lineStarts[low] === offset) {
          return {
            line: low + 1,
            col: 1
          }
        }
        if (low === 0) {
          return {
            line: 0,
            col: offset
          }
        }
        const start = this.lineStarts[low - 1]
        return {
          line: low,
          col: offset - start + 1
        }
      }
    }
  }
  lineCounter.LineCounter = LineCounter
  return lineCounter
}

const parser$2 = {}

let hasRequiredParser
function requireParser() {
  if (hasRequiredParser) {
    return parser$2
  }
  hasRequiredParser = 1
  const node_process = process$2
  const cst = requireCst()
  const lexer = requireLexer()
  function includesToken(list, type) {
    for (let i = 0; i < list.length; ++i) {
      if (list[i].type === type) return true
    }
    return false
  }
  function findNonEmptyIndex(list) {
    for (let i = 0; i < list.length; ++i) {
      switch (list[i].type) {
        case 'space':
        case 'comment':
        case 'newline':
          break
        default:
          return i
      }
    }
    return -1
  }
  function isFlowToken(token) {
    switch (token?.type) {
      case 'alias':
      case 'scalar':
      case 'single-quoted-scalar':
      case 'double-quoted-scalar':
      case 'flow-collection':
        return true
      default:
        return false
    }
  }
  function getPrevProps(parent) {
    switch (parent.type) {
      case 'document':
        return parent.start
      case 'block-map': {
        const it = parent.items[parent.items.length - 1]
        return it.sep ?? it.start
      }
      case 'block-seq':
        return parent.items[parent.items.length - 1].start
      /* istanbul ignore next should not happen */
      default:
        return []
    }
  }
  /** Note: May modify input array */
  function getFirstKeyStartProps(prev) {
    if (prev.length === 0) {
      return []
    }
    let i = prev.length
    loop: while (--i >= 0) {
      switch (prev[i].type) {
        case 'doc-start':
        case 'explicit-key-ind':
        case 'map-value-ind':
        case 'seq-item-ind':
        case 'newline':
          break loop
      }
    }
    while (prev[++i]?.type === 'space') {
      /* loop */
    }
    return prev.splice(i, prev.length)
  }
  function fixFlowSeqItems(fc) {
    if (fc.start.type === 'flow-seq-start') {
      for (const it of fc.items) {
        if (
          it.sep &&
          !it.value &&
          !includesToken(it.start, 'explicit-key-ind') &&
          !includesToken(it.sep, 'map-value-ind')
        ) {
          if (it.key) {
            it.value = it.key
          }
          delete it.key
          if (isFlowToken(it.value)) {
            if (it.value.end) {
              Array.prototype.push.apply(it.value.end, it.sep)
            } else {
              it.value.end = it.sep
            }
          } else {
            Array.prototype.push.apply(it.start, it.sep)
          }
          delete it.sep
        }
      }
    }
  }
  /**
   * A YAML concrete syntax tree (CST) parser
   *
   * ```ts
   * const src: string = ...
   * for (const token of new Parser().parse(src)) {
   *   // token: Token
   * }
   * ```
   *
   * To use the parser with a user-provided lexer:
   *
   * ```ts
   * function* parse(source: string, lexer: Lexer) {
   *   const parser = new Parser()
   *   for (const lexeme of lexer.lex(source))
   *     yield* parser.next(lexeme)
   *   yield* parser.end()
   * }
   *
   * const src: string = ...
   * const lexer = new Lexer()
   * for (const token of parse(src, lexer)) {
   *   // token: Token
   * }
   * ```
   */
  class Parser {
    /**
     * @param onNewLine - If defined, called separately with the start position of
     *   each new line (in `parse()`, including the start of input).
     */
    constructor(onNewLine) {
      /** If true, space and sequence indicators count as indentation */
      this.atNewLine = true
      /** If true, next token is a scalar value */
      this.atScalar = false
      /** Current indentation level */
      this.indent = 0
      /** Current offset since the start of parsing */
      this.offset = 0
      /** On the same line with a block map key */
      this.onKeyLine = false
      /** Top indicates the node that's currently being built */
      this.stack = []
      /** The source of the current token, set in parse() */
      this.source = ''
      /** The type of the current token, set in parse() */
      this.type = ''
      // Must be defined after `next()`
      this.lexer = new lexer.Lexer()
      this.onNewLine = onNewLine
    }
    /**
     * Parse `source` as a YAML stream.
     * If `incomplete`, a part of the last line may be left as a buffer for the next call.
     *
     * Errors are not thrown, but yielded as `{ type: 'error', message }` tokens.
     *
     * @returns A generator of tokens representing each directive, document, and other structure.
     */
    *parse(source, incomplete = false) {
      if (this.onNewLine && this.offset === 0) {
        this.onNewLine(0)
      }
      for (const lexeme of this.lexer.lex(source, incomplete)) {
        yield* this.next(lexeme)
      }
      if (!incomplete) {
        yield* this.end()
      }
    }
    /**
     * Advance the parser by the `source` of one lexical token.
     */
    *next(source) {
      this.source = source
      if (node_process.env.LOG_TOKENS) {
        console.log('|', cst.prettyToken(source))
      }
      if (this.atScalar) {
        this.atScalar = false
        yield* this.step()
        this.offset += source.length
        return
      }
      const type = cst.tokenType(source)
      if (!type) {
        const message = `Not a YAML token: ${source}`
        yield* this.pop({
          type: 'error',
          offset: this.offset,
          message,
          source
        })
        this.offset += source.length
      } else if (type === 'scalar') {
        this.atNewLine = false
        this.atScalar = true
        this.type = 'scalar'
      } else {
        this.type = type
        yield* this.step()
        switch (type) {
          case 'newline':
            this.atNewLine = true
            this.indent = 0
            if (this.onNewLine) {
              this.onNewLine(this.offset + source.length)
            }
            break
          case 'space':
            if (this.atNewLine && source[0] === ' ') {
              this.indent += source.length
            }
            break
          case 'explicit-key-ind':
          case 'map-value-ind':
          case 'seq-item-ind':
            if (this.atNewLine) {
              this.indent += source.length
            }
            break
          case 'doc-mode':
          case 'flow-error-end':
            return
          default:
            this.atNewLine = false
        }
        this.offset += source.length
      }
    }
    /** Call at end of input to push out any remaining constructions */
    *end() {
      while (this.stack.length > 0) {
        yield* this.pop()
      }
    }
    get sourceToken() {
      const st = {
        type: this.type,
        offset: this.offset,
        indent: this.indent,
        source: this.source
      }
      return st
    }
    *step() {
      const top = this.peek(1)
      if (this.type === 'doc-end' && (!top || top.type !== 'doc-end')) {
        while (this.stack.length > 0) {
          yield* this.pop()
        }
        this.stack.push({
          type: 'doc-end',
          offset: this.offset,
          source: this.source
        })
        return
      }
      if (!top) {
        return yield* this.stream()
      }
      switch (top.type) {
        case 'document':
          return yield* this.document(top)
        case 'alias':
        case 'scalar':
        case 'single-quoted-scalar':
        case 'double-quoted-scalar':
          return yield* this.scalar(top)
        case 'block-scalar':
          return yield* this.blockScalar(top)
        case 'block-map':
          return yield* this.blockMap(top)
        case 'block-seq':
          return yield* this.blockSequence(top)
        case 'flow-collection':
          return yield* this.flowCollection(top)
        case 'doc-end':
          return yield* this.documentEnd(top)
      }
      /* istanbul ignore next should not happen */
      yield* this.pop()
    }
    peek(n) {
      return this.stack[this.stack.length - n]
    }
    *pop(error) {
      const token = error ?? this.stack.pop()
      /* istanbul ignore if should not happen */
      if (!token) {
        const message = 'Tried to pop an empty stack'
        yield {
          type: 'error',
          offset: this.offset,
          source: '',
          message
        }
      } else if (this.stack.length === 0) {
        yield token
      } else {
        const top = this.peek(1)
        if (token.type === 'block-scalar') {
          // Block scalars use their parent rather than header indent
          token.indent = 'indent' in top ? top.indent : 0
        } else if (
          token.type === 'flow-collection' &&
          top.type === 'document'
        ) {
          // Ignore all indent for top-level flow collections
          token.indent = 0
        }
        if (token.type === 'flow-collection') {
          fixFlowSeqItems(token)
        }
        switch (top.type) {
          case 'document':
            top.value = token
            break
          case 'block-scalar':
            top.props.push(token) // error
            break
          case 'block-map': {
            const it = top.items[top.items.length - 1]
            if (it.value) {
              top.items.push({
                start: [],
                key: token,
                sep: []
              })
              this.onKeyLine = true
              return
            } else if (it.sep) {
              it.value = token
            } else {
              Object.assign(it, {
                key: token,
                sep: []
              })
              this.onKeyLine = !it.explicitKey
              return
            }
            break
          }
          case 'block-seq': {
            const it = top.items[top.items.length - 1]
            if (it.value) {
              top.items.push({
                start: [],
                value: token
              })
            } else {
              it.value = token
            }
            break
          }
          case 'flow-collection': {
            const it = top.items[top.items.length - 1]
            if (!it || it.value) {
              top.items.push({
                start: [],
                key: token,
                sep: []
              })
            } else if (it.sep) {
              it.value = token
            } else {
              Object.assign(it, {
                key: token,
                sep: []
              })
            }
            return
          }
          /* istanbul ignore next should not happen */
          default:
            yield* this.pop()
            yield* this.pop(token)
        }
        if (
          (top.type === 'document' ||
            top.type === 'block-map' ||
            top.type === 'block-seq') &&
          (token.type === 'block-map' || token.type === 'block-seq')
        ) {
          const last = token.items[token.items.length - 1]
          if (
            last &&
            !last.sep &&
            !last.value &&
            last.start.length > 0 &&
            findNonEmptyIndex(last.start) === -1 &&
            (token.indent === 0 ||
              last.start.every(
                st => st.type !== 'comment' || st.indent < token.indent
              ))
          ) {
            if (top.type === 'document') {
              top.end = last.start
            } else {
              top.items.push({
                start: last.start
              })
            }
            token.items.splice(-1, 1)
          }
        }
      }
    }
    *stream() {
      switch (this.type) {
        case 'directive-line':
          yield {
            type: 'directive',
            offset: this.offset,
            source: this.source
          }
          return
        case 'byte-order-mark':
        case 'space':
        case 'comment':
        case 'newline':
          yield this.sourceToken
          return
        case 'doc-mode':
        case 'doc-start': {
          const doc = {
            type: 'document',
            offset: this.offset,
            start: []
          }
          if (this.type === 'doc-start') {
            doc.start.push(this.sourceToken)
          }
          this.stack.push(doc)
          return
        }
      }
      yield {
        type: 'error',
        offset: this.offset,
        message: `Unexpected ${this.type} token in YAML stream`,
        source: this.source
      }
    }
    *document(doc) {
      if (doc.value) {
        return yield* this.lineEnd(doc)
      }
      switch (this.type) {
        case 'doc-start': {
          if (findNonEmptyIndex(doc.start) !== -1) {
            yield* this.pop()
            yield* this.step()
          } else {
            doc.start.push(this.sourceToken)
          }
          return
        }
        case 'anchor':
        case 'tag':
        case 'space':
        case 'comment':
        case 'newline':
          doc.start.push(this.sourceToken)
          return
      }
      const bv = this.startBlockValue(doc)
      if (bv) {
        this.stack.push(bv)
      } else {
        yield {
          type: 'error',
          offset: this.offset,
          message: `Unexpected ${this.type} token in YAML document`,
          source: this.source
        }
      }
    }
    *scalar(scalar) {
      if (this.type === 'map-value-ind') {
        const prev = getPrevProps(this.peek(2))
        const start = getFirstKeyStartProps(prev)
        let sep
        if (scalar.end) {
          sep = scalar.end
          sep.push(this.sourceToken)
          delete scalar.end
        } else {
          sep = [this.sourceToken]
        }
        const map = {
          type: 'block-map',
          offset: scalar.offset,
          indent: scalar.indent,
          items: [
            {
              start,
              key: scalar,
              sep
            }
          ]
        }
        this.onKeyLine = true
        this.stack[this.stack.length - 1] = map
      } else {
        yield* this.lineEnd(scalar)
      }
    }
    *blockScalar(scalar) {
      switch (this.type) {
        case 'space':
        case 'comment':
        case 'newline':
          scalar.props.push(this.sourceToken)
          return
        case 'scalar':
          scalar.source = this.source
          // block-scalar source includes trailing newline
          this.atNewLine = true
          this.indent = 0
          if (this.onNewLine) {
            let nl = this.source.indexOf('\n') + 1
            while (nl !== 0) {
              this.onNewLine(this.offset + nl)
              nl = this.source.indexOf('\n', nl) + 1
            }
          }
          yield* this.pop()
          break
        /* istanbul ignore next should not happen */
        default:
          yield* this.pop()
          yield* this.step()
      }
    }
    *blockMap(map) {
      const it = map.items[map.items.length - 1]
      // it.sep is true-ish if pair already has key or : separator
      switch (this.type) {
        case 'newline':
          this.onKeyLine = false
          if (it.value) {
            const end = 'end' in it.value ? it.value.end : undefined
            const last = Array.isArray(end) ? end[end.length - 1] : undefined
            if (last?.type === 'comment') {
              end?.push(this.sourceToken)
            } else {
              map.items.push({
                start: [this.sourceToken]
              })
            }
          } else if (it.sep) {
            it.sep.push(this.sourceToken)
          } else {
            it.start.push(this.sourceToken)
          }
          return
        case 'space':
        case 'comment':
          if (it.value) {
            map.items.push({
              start: [this.sourceToken]
            })
          } else if (it.sep) {
            it.sep.push(this.sourceToken)
          } else {
            if (this.atIndentedComment(it.start, map.indent)) {
              const prev = map.items[map.items.length - 2]
              const end = prev?.value?.end
              if (Array.isArray(end)) {
                Array.prototype.push.apply(end, it.start)
                end.push(this.sourceToken)
                map.items.pop()
                return
              }
            }
            it.start.push(this.sourceToken)
          }
          return
      }
      if (this.indent >= map.indent) {
        const atMapIndent = !this.onKeyLine && this.indent === map.indent
        const atNextItem =
          atMapIndent &&
          (it.sep || it.explicitKey) &&
          this.type !== 'seq-item-ind'
        // For empty nodes, assign newline-separated not indented empty tokens to following node
        let start = []
        if (atNextItem && it.sep && !it.value) {
          const nl = []
          for (let i = 0; i < it.sep.length; ++i) {
            const st = it.sep[i]
            switch (st.type) {
              case 'newline':
                nl.push(i)
                break
              case 'space':
                break
              case 'comment':
                if (st.indent > map.indent) {
                  nl.length = 0
                }
                break
              default:
                nl.length = 0
            }
          }
          if (nl.length >= 2) {
            start = it.sep.splice(nl[1])
          }
        }
        switch (this.type) {
          case 'anchor':
          case 'tag':
            if (atNextItem || it.value) {
              start.push(this.sourceToken)
              map.items.push({
                start
              })
              this.onKeyLine = true
            } else if (it.sep) {
              it.sep.push(this.sourceToken)
            } else {
              it.start.push(this.sourceToken)
            }
            return
          case 'explicit-key-ind':
            if (!it.sep && !it.explicitKey) {
              it.start.push(this.sourceToken)
              it.explicitKey = true
            } else if (atNextItem || it.value) {
              start.push(this.sourceToken)
              map.items.push({
                start,
                explicitKey: true
              })
            } else {
              this.stack.push({
                type: 'block-map',
                offset: this.offset,
                indent: this.indent,
                items: [
                  {
                    start: [this.sourceToken],
                    explicitKey: true
                  }
                ]
              })
            }
            this.onKeyLine = true
            return
          case 'map-value-ind':
            if (it.explicitKey) {
              if (!it.sep) {
                if (includesToken(it.start, 'newline')) {
                  Object.assign(it, {
                    key: null,
                    sep: [this.sourceToken]
                  })
                } else {
                  const start = getFirstKeyStartProps(it.start)
                  this.stack.push({
                    type: 'block-map',
                    offset: this.offset,
                    indent: this.indent,
                    items: [
                      {
                        start,
                        key: null,
                        sep: [this.sourceToken]
                      }
                    ]
                  })
                }
              } else if (it.value) {
                map.items.push({
                  start: [],
                  key: null,
                  sep: [this.sourceToken]
                })
              } else if (includesToken(it.sep, 'map-value-ind')) {
                this.stack.push({
                  type: 'block-map',
                  offset: this.offset,
                  indent: this.indent,
                  items: [
                    {
                      start,
                      key: null,
                      sep: [this.sourceToken]
                    }
                  ]
                })
              } else if (
                isFlowToken(it.key) &&
                !includesToken(it.sep, 'newline')
              ) {
                const start = getFirstKeyStartProps(it.start)
                const key = it.key
                const sep = it.sep
                sep.push(this.sourceToken)
                // @ts-expect-error type guard is wrong here
                delete it.key
                // @ts-expect-error type guard is wrong here
                delete it.sep
                this.stack.push({
                  type: 'block-map',
                  offset: this.offset,
                  indent: this.indent,
                  items: [
                    {
                      start,
                      key,
                      sep
                    }
                  ]
                })
              } else if (start.length > 0) {
                // Not actually at next item
                it.sep = it.sep.concat(start, this.sourceToken)
              } else {
                it.sep.push(this.sourceToken)
              }
            } else {
              if (!it.sep) {
                Object.assign(it, {
                  key: null,
                  sep: [this.sourceToken]
                })
              } else if (it.value || atNextItem) {
                map.items.push({
                  start,
                  key: null,
                  sep: [this.sourceToken]
                })
              } else if (includesToken(it.sep, 'map-value-ind')) {
                this.stack.push({
                  type: 'block-map',
                  offset: this.offset,
                  indent: this.indent,
                  items: [
                    {
                      start: [],
                      key: null,
                      sep: [this.sourceToken]
                    }
                  ]
                })
              } else {
                it.sep.push(this.sourceToken)
              }
            }
            this.onKeyLine = true
            return
          case 'alias':
          case 'scalar':
          case 'single-quoted-scalar':
          case 'double-quoted-scalar': {
            const fs = this.flowScalar(this.type)
            if (atNextItem || it.value) {
              map.items.push({
                start,
                key: fs,
                sep: []
              })
              this.onKeyLine = true
            } else if (it.sep) {
              this.stack.push(fs)
            } else {
              Object.assign(it, {
                key: fs,
                sep: []
              })
              this.onKeyLine = true
            }
            return
          }
          default: {
            const bv = this.startBlockValue(map)
            if (bv) {
              if (bv.type === 'block-seq') {
                if (
                  !it.explicitKey &&
                  it.sep &&
                  !includesToken(it.sep, 'newline')
                ) {
                  yield* this.pop({
                    type: 'error',
                    offset: this.offset,
                    message: 'Unexpected block-seq-ind on same line with key',
                    source: this.source
                  })
                  return
                }
              } else if (atMapIndent) {
                map.items.push({
                  start
                })
              }
              this.stack.push(bv)
              return
            }
          }
        }
      }
      yield* this.pop()
      yield* this.step()
    }
    *blockSequence(seq) {
      const it = seq.items[seq.items.length - 1]
      switch (this.type) {
        case 'newline':
          if (it.value) {
            const end = 'end' in it.value ? it.value.end : undefined
            const last = Array.isArray(end) ? end[end.length - 1] : undefined
            if (last?.type === 'comment') {
              end?.push(this.sourceToken)
            } else {
              seq.items.push({
                start: [this.sourceToken]
              })
            }
          } else {
            it.start.push(this.sourceToken)
          }
          return
        case 'space':
        case 'comment':
          if (it.value) {
            seq.items.push({
              start: [this.sourceToken]
            })
          } else {
            if (this.atIndentedComment(it.start, seq.indent)) {
              const prev = seq.items[seq.items.length - 2]
              const end = prev?.value?.end
              if (Array.isArray(end)) {
                Array.prototype.push.apply(end, it.start)
                end.push(this.sourceToken)
                seq.items.pop()
                return
              }
            }
            it.start.push(this.sourceToken)
          }
          return
        case 'anchor':
        case 'tag':
          if (it.value || this.indent <= seq.indent) {
            break
          }
          it.start.push(this.sourceToken)
          return
        case 'seq-item-ind':
          if (this.indent !== seq.indent) {
            break
          }
          if (it.value || includesToken(it.start, 'seq-item-ind')) {
            seq.items.push({
              start: [this.sourceToken]
            })
          } else {
            it.start.push(this.sourceToken)
          }
          return
      }
      if (this.indent > seq.indent) {
        const bv = this.startBlockValue(seq)
        if (bv) {
          this.stack.push(bv)
          return
        }
      }
      yield* this.pop()
      yield* this.step()
    }
    *flowCollection(fc) {
      const it = fc.items[fc.items.length - 1]
      if (this.type === 'flow-error-end') {
        let top
        do {
          yield* this.pop()
          top = this.peek(1)
        } while (top && top.type === 'flow-collection')
      } else if (fc.end.length === 0) {
        switch (this.type) {
          case 'comma':
          case 'explicit-key-ind':
            if (!it || it.sep) {
              fc.items.push({
                start: [this.sourceToken]
              })
            } else {
              it.start.push(this.sourceToken)
            }
            return
          case 'map-value-ind':
            if (!it || it.value) {
              fc.items.push({
                start: [],
                key: null,
                sep: [this.sourceToken]
              })
            } else if (it.sep) {
              it.sep.push(this.sourceToken)
            } else {
              Object.assign(it, {
                key: null,
                sep: [this.sourceToken]
              })
            }
            return
          case 'space':
          case 'comment':
          case 'newline':
          case 'anchor':
          case 'tag':
            if (!it || it.value) {
              fc.items.push({
                start: [this.sourceToken]
              })
            } else if (it.sep) {
              it.sep.push(this.sourceToken)
            } else {
              it.start.push(this.sourceToken)
            }
            return
          case 'alias':
          case 'scalar':
          case 'single-quoted-scalar':
          case 'double-quoted-scalar': {
            const fs = this.flowScalar(this.type)
            if (!it || it.value) {
              fc.items.push({
                start: [],
                key: fs,
                sep: []
              })
            } else if (it.sep) {
              this.stack.push(fs)
            } else {
              Object.assign(it, {
                key: fs,
                sep: []
              })
            }
            return
          }
          case 'flow-map-end':
          case 'flow-seq-end':
            fc.end.push(this.sourceToken)
            return
        }
        const bv = this.startBlockValue(fc)
        /* istanbul ignore else should not happen */
        if (bv) {
          this.stack.push(bv)
        } else {
          yield* this.pop()
          yield* this.step()
        }
      } else {
        const parent = this.peek(2)
        if (
          parent.type === 'block-map' &&
          ((this.type === 'map-value-ind' && parent.indent === fc.indent) ||
            (this.type === 'newline' &&
              !parent.items[parent.items.length - 1].sep))
        ) {
          yield* this.pop()
          yield* this.step()
        } else if (
          this.type === 'map-value-ind' &&
          parent.type !== 'flow-collection'
        ) {
          const prev = getPrevProps(parent)
          const start = getFirstKeyStartProps(prev)
          fixFlowSeqItems(fc)
          const sep = fc.end.splice(1, fc.end.length)
          sep.push(this.sourceToken)
          const map = {
            type: 'block-map',
            offset: fc.offset,
            indent: fc.indent,
            items: [
              {
                start,
                key: fc,
                sep
              }
            ]
          }
          this.onKeyLine = true
          this.stack[this.stack.length - 1] = map
        } else {
          yield* this.lineEnd(fc)
        }
      }
    }
    flowScalar(type) {
      if (this.onNewLine) {
        let nl = this.source.indexOf('\n') + 1
        while (nl !== 0) {
          this.onNewLine(this.offset + nl)
          nl = this.source.indexOf('\n', nl) + 1
        }
      }
      return {
        type,
        offset: this.offset,
        indent: this.indent,
        source: this.source
      }
    }
    startBlockValue(parent) {
      switch (this.type) {
        case 'alias':
        case 'scalar':
        case 'single-quoted-scalar':
        case 'double-quoted-scalar':
          return this.flowScalar(this.type)
        case 'block-scalar-header':
          return {
            type: 'block-scalar',
            offset: this.offset,
            indent: this.indent,
            props: [this.sourceToken],
            source: ''
          }
        case 'flow-map-start':
        case 'flow-seq-start':
          return {
            type: 'flow-collection',
            offset: this.offset,
            indent: this.indent,
            start: this.sourceToken,
            items: [],
            end: []
          }
        case 'seq-item-ind':
          return {
            type: 'block-seq',
            offset: this.offset,
            indent: this.indent,
            items: [
              {
                start: [this.sourceToken]
              }
            ]
          }
        case 'explicit-key-ind': {
          this.onKeyLine = true
          const prev = getPrevProps(parent)
          const start = getFirstKeyStartProps(prev)
          start.push(this.sourceToken)
          return {
            type: 'block-map',
            offset: this.offset,
            indent: this.indent,
            items: [
              {
                start,
                explicitKey: true
              }
            ]
          }
        }
        case 'map-value-ind': {
          this.onKeyLine = true
          const prev = getPrevProps(parent)
          const start = getFirstKeyStartProps(prev)
          return {
            type: 'block-map',
            offset: this.offset,
            indent: this.indent,
            items: [
              {
                start,
                key: null,
                sep: [this.sourceToken]
              }
            ]
          }
        }
      }
      return null
    }
    atIndentedComment(start, indent) {
      if (this.type !== 'comment') {
        return false
      }
      if (this.indent <= indent) {
        return false
      }
      return start.every(st => st.type === 'newline' || st.type === 'space')
    }
    *documentEnd(docEnd) {
      if (this.type !== 'doc-mode') {
        if (docEnd.end) {
          docEnd.end.push(this.sourceToken)
        } else {
          docEnd.end = [this.sourceToken]
        }
        if (this.type === 'newline') {
          yield* this.pop()
        }
      }
    }
    *lineEnd(token) {
      switch (this.type) {
        case 'comma':
        case 'doc-start':
        case 'doc-end':
        case 'flow-seq-end':
        case 'flow-map-end':
        case 'map-value-ind':
          yield* this.pop()
          yield* this.step()
          break
        case 'newline':
          this.onKeyLine = false
        // fallthrough
        case 'space':
        case 'comment':
        default:
          // all other values are errors
          if (token.end) {
            token.end.push(this.sourceToken)
          } else {
            token.end = [this.sourceToken]
          }
          if (this.type === 'newline') {
            yield* this.pop()
          }
      }
    }
  }
  parser$2.Parser = Parser
  return parser$2
}

const publicApi = {}

let hasRequiredPublicApi
function requirePublicApi() {
  if (hasRequiredPublicApi) {
    return publicApi
  }
  hasRequiredPublicApi = 1
  const composer = requireComposer()
  const Document = requireDocument()
  const errors = requireErrors$3()
  const log = requireLog()
  const identity = requireIdentity()
  const lineCounter = requireLineCounter()
  const parser = requireParser()
  function parseOptions(options) {
    const prettyErrors = options.prettyErrors !== false
    const lineCounter$1 =
      options.lineCounter ||
      (prettyErrors && new lineCounter.LineCounter()) ||
      null
    return {
      lineCounter: lineCounter$1,
      prettyErrors
    }
  }
  /**
   * Parse the input as a stream of YAML documents.
   *
   * Documents should be separated from each other by `...` or `---` marker lines.
   *
   * @returns If an empty `docs` array is returned, it will be of type
   *   EmptyStream and contain additional stream information. In
   *   TypeScript, you should use `'empty' in docs` as a type guard for it.
   */
  function parseAllDocuments(source, options = {}) {
    const { lineCounter, prettyErrors } = parseOptions(options)
    const parser$1 = new parser.Parser(lineCounter?.addNewLine)
    const composer$1 = new composer.Composer(options)
    const docs = Array.from(composer$1.compose(parser$1.parse(source)))
    if (prettyErrors && lineCounter) {
      for (const doc of docs) {
        doc.errors.forEach(errors.prettifyError(source, lineCounter))
        doc.warnings.forEach(errors.prettifyError(source, lineCounter))
      }
    }
    if (docs.length > 0) {
      return docs
    }
    return Object.assign(
      [],
      {
        empty: true
      },
      composer$1.streamInfo()
    )
  }
  /** Parse an input string into a single YAML.Document */
  function parseDocument(source, options = {}) {
    const { lineCounter, prettyErrors } = parseOptions(options)
    const parser$1 = new parser.Parser(lineCounter?.addNewLine)
    const composer$1 = new composer.Composer(options)
    // `doc` is always set by compose.end(true) at the very latest
    let doc = null
    for (const _doc of composer$1.compose(
      parser$1.parse(source),
      true,
      source.length
    )) {
      if (!doc) {
        doc = _doc
      } else if (doc.options.logLevel !== 'silent') {
        doc.errors.push(
          new errors.YAMLParseError(
            _doc.range.slice(0, 2),
            'MULTIPLE_DOCS',
            'Source contains multiple documents; please use YAML.parseAllDocuments()'
          )
        )
        break
      }
    }
    if (prettyErrors && lineCounter) {
      doc.errors.forEach(errors.prettifyError(source, lineCounter))
      doc.warnings.forEach(errors.prettifyError(source, lineCounter))
    }
    return doc
  }
  function parse(src, reviver, options) {
    let _reviver = undefined
    if (typeof reviver === 'function') {
      _reviver = reviver
    } else if (
      options === undefined &&
      reviver &&
      typeof reviver === 'object'
    ) {
      options = reviver
    }
    const doc = parseDocument(src, options)
    if (!doc) {
      return null
    }
    doc.warnings.forEach(warning => log.warn(doc.options.logLevel, warning))
    if (doc.errors.length > 0) {
      if (doc.options.logLevel !== 'silent') {
        throw doc.errors[0]
      } else {
        doc.errors = []
      }
    }
    return doc.toJS(
      Object.assign(
        {
          reviver: _reviver
        },
        options
      )
    )
  }
  function stringify(value, replacer, options) {
    let _replacer = null
    if (typeof replacer === 'function' || Array.isArray(replacer)) {
      _replacer = replacer
    } else if (options === undefined && replacer) {
      options = replacer
    }
    if (typeof options === 'string') {
      options = options.length
    }
    if (typeof options === 'number') {
      const indent = Math.round(options)
      options =
        indent < 1
          ? undefined
          : indent > 8
            ? {
                indent: 8
              }
            : {
                indent
              }
    }
    if (value === undefined) {
      const { keepUndefined } = options ?? replacer ?? {}
      if (!keepUndefined) {
        return undefined
      }
    }
    if (identity.isDocument(value) && !_replacer) {
      return value.toString(options)
    }
    return new Document.Document(value, _replacer, options).toString(options)
  }
  publicApi.parse = parse
  publicApi.parseAllDocuments = parseAllDocuments
  publicApi.parseDocument = parseDocument
  publicApi.stringify = stringify
  return publicApi
}

let hasRequiredDist$4
function requireDist$4() {
  if (hasRequiredDist$4) {
    return dist$4
  }
  hasRequiredDist$4 = 1
  const composer = requireComposer()
  const Document = requireDocument()
  const Schema = requireSchema$1()
  const errors = requireErrors$3()
  const Alias = requireAlias()
  const identity = requireIdentity()
  const Pair = requirePair()
  const Scalar = requireScalar()
  const YAMLMap = requireYAMLMap()
  const YAMLSeq = requireYAMLSeq()
  const cst = requireCst()
  const lexer = requireLexer()
  const lineCounter = requireLineCounter()
  const parser = requireParser()
  const publicApi = requirePublicApi()
  const visit = requireVisit()
  dist$4.Composer = composer.Composer
  dist$4.Document = Document.Document
  dist$4.Schema = Schema.Schema
  dist$4.YAMLError = errors.YAMLError
  dist$4.YAMLParseError = errors.YAMLParseError
  dist$4.YAMLWarning = errors.YAMLWarning
  dist$4.Alias = Alias.Alias
  dist$4.isAlias = identity.isAlias
  dist$4.isCollection = identity.isCollection
  dist$4.isDocument = identity.isDocument
  dist$4.isMap = identity.isMap
  dist$4.isNode = identity.isNode
  dist$4.isPair = identity.isPair
  dist$4.isScalar = identity.isScalar
  dist$4.isSeq = identity.isSeq
  dist$4.Pair = Pair.Pair
  dist$4.Scalar = Scalar.Scalar
  dist$4.YAMLMap = YAMLMap.YAMLMap
  dist$4.YAMLSeq = YAMLSeq.YAMLSeq
  dist$4.CST = cst
  dist$4.Lexer = lexer.Lexer
  dist$4.LineCounter = lineCounter.LineCounter
  dist$4.Parser = parser.Parser
  dist$4.parse = publicApi.parse
  dist$4.parseAllDocuments = publicApi.parseAllDocuments
  dist$4.parseDocument = publicApi.parseDocument
  dist$4.stringify = publicApi.stringify
  dist$4.visit = visit.visit
  dist$4.visitAsync = visit.visitAsync
  return dist$4
}

let v1
let hasRequiredV1
function requireV1() {
  if (hasRequiredV1) {
    return v1
  }
  hasRequiredV1 = 1

  /**
   * @typedef SocketYmlV1
   * @property {string[]} [ignore]
   * @property {{ [issueName: string]: boolean }} [issues]
   * @property {boolean} [beta] unused v1 option
   * @property {boolean} [enabled] enable/disable the Socket.dev GitHub app entirely
   * @property {boolean} [projectReportsEnabled] enable/disable Github app project report checks
   * @property {boolean} [pullRequestAlertsEnabled] enable/disable GitHub app pull request alert checks
   */

  /** @type {import('ajv').JSONSchemaType<SocketYmlV1>} */
  const socketYmlSchemaV1 = {
    $schema: 'http://json-schema.org/draft-07/schema#',
    type: 'object',
    properties: {
      ignore: {
        type: 'array',
        items: {
          type: 'string'
        },
        nullable: true
      },
      issues: {
        type: 'object',
        nullable: true,
        required: [],
        additionalProperties: {
          type: 'boolean'
        }
      },
      beta: {
        type: 'boolean',
        nullable: true,
        default: true
      },
      enabled: {
        type: 'boolean',
        nullable: true,
        default: true
      },
      projectReportsEnabled: {
        type: 'boolean',
        nullable: true,
        default: true
      },
      pullRequestAlertsEnabled: {
        type: 'boolean',
        nullable: true,
        default: true
      }
    },
    minProperties: 1,
    additionalProperties: false
  }
  v1 = {
    socketYmlSchemaV1
  }
  return v1
}

let config
let hasRequiredConfig
function requireConfig() {
  if (hasRequiredConfig) {
    return config
  }
  hasRequiredConfig = 1
  const { readFile } = fs$2
  const { default: Ajv } = requireAjv()
  const { ErrorWithCause } = requirePonyCause()
  const { parse: yamlParse } = requireDist$4()
  const { socketYmlSchemaV1 } = requireV1()

  /**
   * @typedef SocketYmlGitHub
   * @property {boolean} [enabled] enable/disable the Socket.dev GitHub app entirely
   * @property {string[]} [ignoreUsers] list of GitHub usernames to ignore when creating reports
   * @property {boolean} [projectReportsEnabled] enable/disable Github app project report checks
   * @property {boolean} [pullRequestAlertsEnabled] enable/disable GitHub app pull request alert checks
   * @property {boolean} [dependencyOverviewEnabled] enable/disable Pull request comments with details about changed dependencies
   * @property {boolean} [authenticatedProjectReports] enable/disable authenticated project report URLs
   */

  /**
   * @typedef SocketYml
   * @property {2} version
   * @property {string[]} projectIgnorePaths
   * @property {{ [issueName: string]: boolean }} issueRules
   * @property {SocketYmlGitHub} githubApp
   */

  /** @type {import('ajv').JSONSchemaType<SocketYml>} */
  const socketYmlSchema = {
    $schema: 'http://json-schema.org/draft-07/schema#',
    type: 'object',
    properties: {
      version: {
        type: 'integer'
      },
      projectIgnorePaths: {
        type: 'array',
        items: {
          type: 'string'
        },
        default: []
      },
      issueRules: {
        type: 'object',
        required: [],
        additionalProperties: {
          type: 'boolean'
        },
        default: {}
      },
      githubApp: {
        type: 'object',
        properties: {
          enabled: {
            type: 'boolean',
            nullable: true
          },
          ignoreUsers: {
            type: 'array',
            items: {
              type: 'string'
            },
            nullable: true
          },
          projectReportsEnabled: {
            type: 'boolean',
            nullable: true
          },
          pullRequestAlertsEnabled: {
            type: 'boolean',
            nullable: true
          },
          dependencyOverviewEnabled: {
            type: 'boolean',
            nullable: true
          },
          authenticatedProjectReports: {
            type: 'boolean',
            nullable: true
          }
        },
        required: [],
        additionalProperties: false,
        default: {}
      }
    },
    required: ['version'],
    additionalProperties: false
  }
  const ajvOptions = /** @type {const} */ {
    allErrors: true,
    coerceTypes: 'array',
    logger: false,
    useDefaults: true
  }
  const ajv = new Ajv({
    ...ajvOptions,
    removeAdditional: 'failing'
  })
  const validate = ajv.compile(socketYmlSchema)

  // We want to be strict and fail rather than removeAdditional when we parse a possible v1 config – only fallback to it when it actually matches well
  const ajvV1 = new Ajv({
    ...ajvOptions
  })
  const validateV1 = ajvV1.compile(socketYmlSchemaV1)

  /**
   * @param {string} filePath
   * @returns {Promise<SocketYml|undefined>}
   * @throws {SocketValidationError}
   */
  async function readSocketConfig(filePath) {
    /** @type {string} */
    let fileContent
    try {
      fileContent = await readFile(filePath, 'utf8')
    } catch (err) {
      if (isErrnoException(err) && err.code === 'ENOENT') {
        return
      }
      throw new ErrorWithCause('Error when reading socket.yml config file', {
        cause: err
      })
    }
    return parseSocketConfig(fileContent)
  }

  /**
   * @param {string} fileContent
   * @returns {SocketYml}
   * @throws {SocketValidationError}
   */
  function parseSocketConfig(fileContent) {
    /** @type {unknown} */
    let parsedContent
    try {
      parsedContent = yamlParse(fileContent)
    } catch (err) {
      throw new ErrorWithCause('Error when parsing socket.yml config', {
        cause: err
      })
    }
    if (
      parsedContent &&
      typeof parsedContent === 'object' &&
      !('version' in parsedContent)
    ) {
      const parsedV1 = parseV1SocketConfig(parsedContent)
      if (parsedV1) {
        return parsedV1
      }
    }
    if (!validate(parsedContent)) {
      throw new SocketValidationError(
        'Invalid config definition',
        validate.errors || [],
        parsedContent
      )
    }
    return parsedContent
  }

  /**
   * @param {unknown} value
   * @returns {value is NodeJS.ErrnoException}
   */
  function isErrnoException(value) {
    if (!(value instanceof Error)) {
      return false
    }
    const errnoException = /** @type NodeJS.ErrnoException} */ value
    return errnoException.code !== undefined
  }
  class SocketValidationError extends Error {
    /**
     * @param {string} message
     * @param {import('ajv').ErrorObject[]} validationErrors
     * @param {unknown} parsedContent
     */
    constructor(message, validationErrors, parsedContent) {
      super(message)

      /** @type {unknown} */
      this.data = parsedContent

      /** @type {import('ajv').JSONSchemaType<SocketYml>} */
      this.schema = socketYmlSchema

      /** @type {import('ajv').ErrorObject[]} */
      this.validationErrors = validationErrors
    }
  }

  /**
   * @param {object} parsedV1Content
   * @returns {SocketYml | undefined}
   */
  function parseV1SocketConfig(parsedV1Content) {
    if (!validateV1(parsedV1Content)) {
      return
    }

    /** @type {SocketYml} */
    const v2 = {
      version: 2,
      projectIgnorePaths: parsedV1Content?.ignore ?? [],
      issueRules: parsedV1Content?.issues ?? {},
      githubApp: {
        ...('enabled' in parsedV1Content
          ? {
              enabled: parsedV1Content.enabled
            }
          : {}),
        ...('pullRequestAlertsEnabled' in parsedV1Content
          ? {
              pullRequestAlertsEnabled: parsedV1Content.pullRequestAlertsEnabled
            }
          : {}),
        ...('projectReportsEnabled' in parsedV1Content
          ? {
              projectReportsEnabled: parsedV1Content.projectReportsEnabled
            }
          : {})
      }
    }
    return v2
  }

  /** @returns {SocketYml} */
  function getDefaultConfig() {
    const config = {
      version: 2
    }
    if (!validate(config)) {
      throw new Error('Unexpectedly invalid default config')
    }
    return config
  }
  config = {
    getDefaultConfig,
    parseSocketConfig,
    readSocketConfig,
    SocketValidationError,
    socketYmlSchema
  }
  return config
}

const configExports = requireConfig()

const ignore = { exports: {} }

let hasRequiredIgnore
function requireIgnore() {
  if (hasRequiredIgnore) {
    return ignore.exports
  }
  hasRequiredIgnore = 1
  // A simple implementation of make-array
  function makeArray(subject) {
    return Array.isArray(subject) ? subject : [subject]
  }
  const UNDEFINED = undefined
  const EMPTY = ''
  const SPACE = ' '
  const ESCAPE = '\\'
  const REGEX_TEST_BLANK_LINE = /^\s+$/
  const REGEX_INVALID_TRAILING_BACKSLASH = /(?:[^\\]|^)\\$/
  const REGEX_REPLACE_LEADING_EXCAPED_EXCLAMATION = /^\\!/
  const REGEX_REPLACE_LEADING_EXCAPED_HASH = /^\\#/
  const REGEX_SPLITALL_CRLF = /\r?\n/g

  // Invalid:
  // - /foo,
  // - ./foo,
  // - ../foo,
  // - .
  // - ..
  // Valid:
  // - .foo
  const REGEX_TEST_INVALID_PATH = /^\.{0,2}\/|^\.{1,2}$/
  const REGEX_TEST_TRAILING_SLASH = /\/$/
  const SLASH = '/'

  // Do not use ternary expression here, since "istanbul ignore next" is buggy
  let TMP_KEY_IGNORE = 'node-ignore'
  /* istanbul ignore else */
  if (typeof Symbol !== 'undefined') {
    TMP_KEY_IGNORE = Symbol.for('node-ignore')
  }
  const KEY_IGNORE = TMP_KEY_IGNORE
  const define = (object, key, value) => {
    Object.defineProperty(object, key, {
      value
    })
    return value
  }
  const REGEX_REGEXP_RANGE = /([0-z])-([0-z])/g
  const RETURN_FALSE = () => false

  // Sanitize the range of a regular expression
  // The cases are complicated, see test cases for details
  const sanitizeRange = range =>
    range.replace(REGEX_REGEXP_RANGE, (match, from, to) =>
      from.charCodeAt(0) <= to.charCodeAt(0)
        ? match
        : // Invalid range (out of order) which is ok for gitignore rules but
          //   fatal for JavaScript regular expression, so eliminate it.
          EMPTY
    )

  // See fixtures #59
  const cleanRangeBackSlash = slashes => {
    const { length } = slashes
    return slashes.slice(0, length - (length % 2))
  }

  // > If the pattern ends with a slash,
  // > it is removed for the purpose of the following description,
  // > but it would only find a match with a directory.
  // > In other words, foo/ will match a directory foo and paths underneath it,
  // > but will not match a regular file or a symbolic link foo
  // >  (this is consistent with the way how pathspec works in general in Git).
  // '`foo/`' will not match regular file '`foo`' or symbolic link '`foo`'
  // -> ignore-rules will not deal with it, because it costs extra `fs.stat` call
  //      you could use option `mark: true` with `glob`

  // '`foo/`' should not continue with the '`..`'
  const REPLACERS = [
    [
      // Remove BOM
      // TODO:
      // Other similar zero-width characters?
      /^\uFEFF/,
      () => EMPTY
    ],
    // > Trailing spaces are ignored unless they are quoted with backslash ("\")
    [
      // (a\ ) -> (a )
      // (a  ) -> (a)
      // (a ) -> (a)
      // (a \ ) -> (a  )
      /((?:\\\\)*?)(\\?\s+)$/,
      (_, m1, m2) => m1 + (m2.indexOf('\\') === 0 ? SPACE : EMPTY)
    ],
    // Replace (\ ) with ' '
    // (\ ) -> ' '
    // (\\ ) -> '\\ '
    // (\\\ ) -> '\\ '
    [
      /(\\+?)\s/g,
      (_, m1) => {
        const { length } = m1
        return m1.slice(0, length - (length % 2)) + SPACE
      }
    ],
    // Escape metacharacters
    // which is written down by users but means special for regular expressions.

    // > There are 12 characters with special meanings:
    // > - the backslash \,
    // > - the caret ^,
    // > - the dollar sign $,
    // > - the period or dot .,
    // > - the vertical bar or pipe symbol |,
    // > - the question mark ?,
    // > - the asterisk or star *,
    // > - the plus sign +,
    // > - the opening parenthesis (,
    // > - the closing parenthesis ),
    // > - and the opening square bracket [,
    // > - the opening curly brace {,
    // > These special characters are often called "metacharacters".
    [/[\\$.|*+(){^]/g, match => `\\${match}`],
    [
      // > a question mark (?) matches a single character
      /(?!\\)\?/g,
      () => '[^/]'
    ],
    // leading slash
    [
      // > A leading slash matches the beginning of the pathname.
      // > For example, "/*.c" matches "cat-file.c" but not "mozilla-sha1/sha1.c".
      // A leading slash matches the beginning of the pathname
      /^\//,
      () => '^'
    ],
    // replace special metacharacter slash after the leading slash
    [/\//g, () => '\\/'],
    [
      // > A leading "**" followed by a slash means match in all directories.
      // > For example, "**/foo" matches file or directory "foo" anywhere,
      // > the same as pattern "foo".
      // > "**/foo/bar" matches file or directory "bar" anywhere that is directly
      // >   under directory "foo".
      // Notice that the '*'s have been replaced as '\\*'
      /^\^*\\\*\\\*\\\//,
      // '**/foo' <-> 'foo'
      () => '^(?:.*\\/)?'
    ],
    // starting
    [
      // there will be no leading '/'
      //   (which has been replaced by section "leading slash")
      // If starts with '**', adding a '^' to the regular expression also works
      /^(?=[^^])/,
      function startingReplacer() {
        // If has a slash `/` at the beginning or middle
        return !/\/(?!$)/.test(this)
          ? // > Prior to 2.22.1
            // > If the pattern does not contain a slash /,
            // >   Git treats it as a shell glob pattern
            // Actually, if there is only a trailing slash,
            //   git also treats it as a shell glob pattern

            // After 2.22.1 (compatible but clearer)
            // > If there is a separator at the beginning or middle (or both)
            // > of the pattern, then the pattern is relative to the directory
            // > level of the particular .gitignore file itself.
            // > Otherwise the pattern may also match at any level below
            // > the .gitignore level.
            '(?:^|\\/)'
          : // > Otherwise, Git treats the pattern as a shell glob suitable for
            // >   consumption by fnmatch(3)
            '^'
      }
    ],
    // two globstars
    [
      // Use lookahead assertions so that we could match more than one `'/**'`
      /\\\/\\\*\\\*(?=\\\/|$)/g,
      // Zero, one or several directories
      // should not use '*', or it will be replaced by the next replacer

      // Check if it is not the last `'/**'`
      (_, index, str) =>
        index + 6 < str.length
          ? // case: /**/
            // > A slash followed by two consecutive asterisks then a slash matches
            // >   zero or more directories.
            // > For example, "a/**/b" matches "a/b", "a/x/b", "a/x/y/b" and so on.
            // '/**/'
            '(?:\\/[^\\/]+)*'
          : // case: /**
            // > A trailing `"/**"` matches everything inside.

            // #21: everything inside but it should not include the current folder
            '\\/.+'
    ],
    // normal intermediate wildcards
    [
      // Never replace escaped '*'
      // ignore rule '\*' will match the path '*'

      // 'abc.*/' -> go
      // 'abc.*'  -> skip this rule,
      //    coz trailing single wildcard will be handed by [trailing wildcard]
      /(^|[^\\]+)(\\\*)+(?=.+)/g,
      // '*.js' matches '.js'
      // '*.js' doesn't match 'abc'
      (_, p1, p2) => {
        // 1.
        // > An asterisk "*" matches anything except a slash.
        // 2.
        // > Other consecutive asterisks are considered regular asterisks
        // > and will match according to the previous rules.
        const unescaped = p2.replace(/\\\*/g, '[^\\/]*')
        return p1 + unescaped
      }
    ],
    [
      // unescape, revert step 3 except for back slash
      // For example, if a user escape a '\\*',
      // after step 3, the result will be '\\\\\\*'
      /\\\\\\(?=[$.|*+(){^])/g,
      () => ESCAPE
    ],
    [
      // '\\\\' -> '\\'
      /\\\\/g,
      () => ESCAPE
    ],
    [
      // > The range notation, e.g. [a-zA-Z],
      // > can be used to match one of the characters in a range.

      // `\` is escaped by step 3
      /(\\)?\[([^\]/]*?)(\\*)($|\])/g,
      (match, leadEscape, range, endEscape, close) =>
        leadEscape === ESCAPE
          ? // '\\[bar]' -> '\\\\[bar\\]'
            `\\[${range}${cleanRangeBackSlash(endEscape)}${close}`
          : close === ']'
            ? endEscape.length % 2 === 0
              ? // A normal case, and it is a range notation
                // '[bar]'
                // '[bar\\\\]'
                `[${sanitizeRange(range)}${endEscape}]`
              : // Invalid range notaton
                // '[bar\\]' -> '[bar\\\\]'
                '[]'
            : '[]'
    ],
    // ending
    [
      // 'js' will not match 'js.'
      // 'ab' will not match 'abc'
      /(?:[^*])$/,
      // WTF!
      // https://git-scm.com/docs/gitignore
      // changes in [2.22.1](https://git-scm.com/docs/gitignore/2.22.1)
      // which re-fixes #24, #38

      // > If there is a separator at the end of the pattern then the pattern
      // > will only match directories, otherwise the pattern can match both
      // > files and directories.

      // 'js*' will not match 'a.js'
      // 'js/' will not match 'a.js'
      // 'js' will match 'a.js' and 'a.js/'
      match =>
        /\/$/.test(match)
          ? // foo/ will not match 'foo'
            `${match}$`
          : // foo matches 'foo' and 'foo/'
            `${match}(?=$|\\/$)`
    ]
  ]
  const REGEX_REPLACE_TRAILING_WILDCARD = /(^|\\\/)?\\\*$/
  const MODE_IGNORE = 'regex'
  const MODE_CHECK_IGNORE = 'checkRegex'
  const UNDERSCORE = '_'
  const TRAILING_WILD_CARD_REPLACERS = {
    [MODE_IGNORE](_, p1) {
      const prefix = p1
        ? // '\^':
          // '/*' does not match EMPTY
          // '/*' does not match everything

          // '\\\/':
          // 'abc/*' does not match 'abc/'
          `${p1}[^/]+`
        : // 'a*' matches 'a'
          // 'a*' matches 'aa'
          '[^/]*'
      return `${prefix}(?=$|\\/$)`
    },
    [MODE_CHECK_IGNORE](_, p1) {
      // When doing `git check-ignore`
      const prefix = p1
        ? // '\\\/':
          // 'abc/*' DOES match 'abc/' !
          `${p1}[^/]*`
        : // 'a*' matches 'a'
          // 'a*' matches 'aa'
          '[^/]*'
      return `${prefix}(?=$|\\/$)`
    }
  }

  // @param {pattern}
  const makeRegexPrefix = pattern =>
    REPLACERS.reduce(
      (prev, [matcher, replacer]) =>
        prev.replace(matcher, replacer.bind(pattern)),
      pattern
    )
  const isString = subject => typeof subject === 'string'

  // > A blank line matches no files, so it can serve as a separator for readability.
  const checkPattern = pattern =>
    pattern &&
    isString(pattern) &&
    !REGEX_TEST_BLANK_LINE.test(pattern) &&
    !REGEX_INVALID_TRAILING_BACKSLASH.test(pattern) &&
    // > A line starting with # serves as a comment.
    pattern.indexOf('#') !== 0
  const splitPattern = pattern =>
    pattern.split(REGEX_SPLITALL_CRLF).filter(Boolean)
  class IgnoreRule {
    constructor(pattern, mark, body, ignoreCase, negative, prefix) {
      this.pattern = pattern
      this.mark = mark
      this.negative = negative
      define(this, 'body', body)
      define(this, 'ignoreCase', ignoreCase)
      define(this, 'regexPrefix', prefix)
    }
    get regex() {
      const key = UNDERSCORE + MODE_IGNORE
      if (this[key]) {
        return this[key]
      }
      return this._make(MODE_IGNORE, key)
    }
    get checkRegex() {
      const key = UNDERSCORE + MODE_CHECK_IGNORE
      if (this[key]) {
        return this[key]
      }
      return this._make(MODE_CHECK_IGNORE, key)
    }
    _make(mode, key) {
      const str = this.regexPrefix.replace(
        REGEX_REPLACE_TRAILING_WILDCARD,
        // It does not need to bind pattern
        TRAILING_WILD_CARD_REPLACERS[mode]
      )
      const regex = this.ignoreCase ? new RegExp(str, 'i') : new RegExp(str)
      return define(this, key, regex)
    }
  }
  const createRule = ({ pattern, mark }, ignoreCase) => {
    let negative = false
    let body = pattern

    // > An optional prefix "!" which negates the pattern;
    if (body.indexOf('!') === 0) {
      negative = true
      body = body.substr(1)
    }
    body = body
      // > Put a backslash ("\") in front of the first "!" for patterns that
      // >   begin with a literal "!", for example, `"\!important!.txt"`.
      .replace(REGEX_REPLACE_LEADING_EXCAPED_EXCLAMATION, '!')
      // > Put a backslash ("\") in front of the first hash for patterns that
      // >   begin with a hash.
      .replace(REGEX_REPLACE_LEADING_EXCAPED_HASH, '#')
    const regexPrefix = makeRegexPrefix(body)
    return new IgnoreRule(
      pattern,
      mark,
      body,
      ignoreCase,
      negative,
      regexPrefix
    )
  }
  class RuleManager {
    constructor(ignoreCase) {
      this._ignoreCase = ignoreCase
      this._rules = []
    }
    _add(pattern) {
      // #32
      if (pattern && pattern[KEY_IGNORE]) {
        this._rules = this._rules.concat(pattern._rules._rules)
        this._added = true
        return
      }
      if (isString(pattern)) {
        pattern = {
          pattern
        }
      }
      if (checkPattern(pattern.pattern)) {
        const rule = createRule(pattern, this._ignoreCase)
        this._added = true
        this._rules.push(rule)
      }
    }

    // @param {Array<string> | string | Ignore} pattern
    add(pattern) {
      this._added = false
      makeArray(isString(pattern) ? splitPattern(pattern) : pattern).forEach(
        this._add,
        this
      )
      return this._added
    }

    // Test one single path without recursively checking parent directories
    //
    // - checkUnignored `boolean` whether should check if the path is unignored,
    //   setting `checkUnignored` to `false` could reduce additional
    //   path matching.
    // - check `string` either `MODE_IGNORE` or `MODE_CHECK_IGNORE`

    // @returns {TestResult} true if a file is ignored
    test(path, checkUnignored, mode) {
      let ignored = false
      let unignored = false
      let matchedRule
      this._rules.forEach(rule => {
        const { negative } = rule

        //          |           ignored : unignored
        // -------- | ---------------------------------------
        // negative |   0:0   |   0:1   |   1:0   |   1:1
        // -------- | ------- | ------- | ------- | --------
        //     0    |  TEST   |  TEST   |  SKIP   |    X
        //     1    |  TESTIF |  SKIP   |  TEST   |    X

        // - SKIP: always skip
        // - TEST: always test
        // - TESTIF: only test if checkUnignored
        // - X: that never happen
        if (
          (unignored === negative && ignored !== unignored) ||
          (negative && !ignored && !unignored && !checkUnignored)
        ) {
          return
        }
        const matched = rule[mode].test(path)
        if (!matched) {
          return
        }
        ignored = !negative
        unignored = negative
        matchedRule = negative ? UNDEFINED : rule
      })
      const ret = {
        ignored,
        unignored
      }
      if (matchedRule) {
        ret.rule = matchedRule
      }
      return ret
    }
  }
  const throwError = (message, Ctor) => {
    throw new Ctor(message)
  }
  const checkPath = (path, originalPath, doThrow) => {
    if (!isString(path)) {
      return doThrow(
        `path must be a string, but got \`${originalPath}\``,
        TypeError
      )
    }

    // We don't know if we should ignore EMPTY, so throw
    if (!path) {
      return doThrow(`path must not be empty`, TypeError)
    }

    // Check if it is a relative path
    if (checkPath.isNotRelative(path)) {
      const r = '`path.relative()`d'
      return doThrow(
        `path should be a ${r} string, but got "${originalPath}"`,
        RangeError
      )
    }
    return true
  }
  const isNotRelative = path => REGEX_TEST_INVALID_PATH.test(path)
  checkPath.isNotRelative = isNotRelative

  // On windows, the following function will be replaced
  /* istanbul ignore next */
  checkPath.convert = p => p
  class Ignore {
    constructor({
      ignorecase = true,
      ignoreCase = ignorecase,
      allowRelativePaths = false
    } = {}) {
      define(this, KEY_IGNORE, true)
      this._rules = new RuleManager(ignoreCase)
      this._strictPathCheck = !allowRelativePaths
      this._initCache()
    }
    _initCache() {
      // A cache for the result of `.ignores()`
      this._ignoreCache = Object.create(null)

      // A cache for the result of `.test()`
      this._testCache = Object.create(null)
    }
    add(pattern) {
      if (this._rules.add(pattern)) {
        // Some rules have just added to the ignore,
        //   making the behavior changed,
        //   so we need to re-initialize the result cache
        this._initCache()
      }
      return this
    }

    // legacy
    addPattern(pattern) {
      return this.add(pattern)
    }

    // @returns {TestResult}
    _test(originalPath, cache, checkUnignored, slices) {
      const path =
        originalPath &&
        // Supports nullable path
        checkPath.convert(originalPath)
      checkPath(
        path,
        originalPath,
        this._strictPathCheck ? throwError : RETURN_FALSE
      )
      return this._t(path, cache, checkUnignored, slices)
    }
    checkIgnore(path) {
      // If the path doest not end with a slash, `.ignores()` is much equivalent
      //   to `git check-ignore`
      if (!REGEX_TEST_TRAILING_SLASH.test(path)) {
        return this.test(path)
      }
      const slices = path.split(SLASH).filter(Boolean)
      slices.pop()
      if (slices.length) {
        const parent = this._t(
          slices.join(SLASH) + SLASH,
          this._testCache,
          true,
          slices
        )
        if (parent.ignored) {
          return parent
        }
      }
      return this._rules.test(path, false, MODE_CHECK_IGNORE)
    }
    _t(
      // The path to be tested
      path,
      // The cache for the result of a certain checking
      cache,
      // Whether should check if the path is unignored
      checkUnignored,
      // The path slices
      slices
    ) {
      if (path in cache) {
        return cache[path]
      }
      if (!slices) {
        // path/to/a.js
        // ['path', 'to', 'a.js']
        slices = path.split(SLASH).filter(Boolean)
      }
      slices.pop()

      // If the path has no parent directory, just test it
      if (!slices.length) {
        return (cache[path] = this._rules.test(
          path,
          checkUnignored,
          MODE_IGNORE
        ))
      }
      const parent = this._t(
        slices.join(SLASH) + SLASH,
        cache,
        checkUnignored,
        slices
      )

      // If the path contains a parent directory, check the parent first
      return (cache[path] = parent.ignored
        ? // > It is not possible to re-include a file if a parent directory of
          // >   that file is excluded.
          parent
        : this._rules.test(path, checkUnignored, MODE_IGNORE))
    }
    ignores(path) {
      return this._test(path, this._ignoreCache, false).ignored
    }
    createFilter() {
      return path => !this.ignores(path)
    }
    filter(paths) {
      return makeArray(paths).filter(this.createFilter())
    }

    // @returns {TestResult}
    test(path) {
      return this._test(path, this._testCache, true)
    }
  }
  const factory = options => new Ignore(options)
  const isPathValid = path =>
    checkPath(path && checkPath.convert(path), path, RETURN_FALSE)

  // Windows
  // --------------------------------------------------------------
  /* istanbul ignore next */
  if (
    // Detect `process` so that it can run in browsers.
    typeof process !== 'undefined' &&
    ((process.env && process.env.IGNORE_TEST_WIN32) ||
      process.platform === 'win32')
  ) {
    /* eslint no-control-regex: "off" */
    const makePosix = str =>
      /^\\\\\?\\/.test(str) || /["<>|\u0000-\u001F]+/u.test(str)
        ? str
        : str.replace(/\\/g, '/')
    checkPath.convert = makePosix

    // 'C:\\foo'     <- 'C:\\foo' has been converted to 'C:/'
    // 'd:\\foo'
    const REGEX_TEST_WINDOWS_PATH_ABSOLUTE = /^[a-z]:\//i
    checkPath.isNotRelative = path =>
      REGEX_TEST_WINDOWS_PATH_ABSOLUTE.test(path) || isNotRelative(path)
  }

  // COMMONJS_EXPORTS ////////////////////////////////////////////////////////////

  ignore.exports = factory

  // Although it is an anti-pattern,
  //   it is still widely misused by a lot of libraries in github
  // Ref: https://github.com/search?q=ignore.default%28%29&type=code
  factory.default = factory
  ignore.exports.isPathValid = isPathValid
  return ignore.exports
}

const ignoreExports = requireIgnore()

const utils$3 = {}

let hasRequiredUtils$3
function requireUtils$3() {
  if (hasRequiredUtils$3) {
    return utils$3
  }
  hasRequiredUtils$3 = 1
  ;(function (exports) {
    exports.isInteger = num => {
      if (typeof num === 'number') {
        return Number.isInteger(num)
      }
      if (typeof num === 'string' && num.trim() !== '') {
        return Number.isInteger(Number(num))
      }
      return false
    }

    /**
     * Find a node of the given type
     */

    exports.find = (node, type) => node.nodes.find(node => node.type === type)

    /**
     * Find a node of the given type
     */

    exports.exceedsLimit = (min, max, step = 1, limit) => {
      if (limit === false) {
        return false
      }
      if (!exports.isInteger(min) || !exports.isInteger(max)) {
        return false
      }
      return (Number(max) - Number(min)) / Number(step) >= limit
    }

    /**
     * Escape the given node with '\\' before node.value
     */

    exports.escapeNode = (block, n = 0, type) => {
      const node = block.nodes[n]
      if (!node) {
        return
      }
      if (
        (type && node.type === type) ||
        node.type === 'open' ||
        node.type === 'close'
      ) {
        if (node.escaped !== true) {
          node.value = '\\' + node.value
          node.escaped = true
        }
      }
    }

    /**
     * Returns true if the given brace node should be enclosed in literal braces
     */

    exports.encloseBrace = node => {
      if (node.type !== 'brace') {
        return false
      }
      if ((node.commas >> (0 + node.ranges)) >> 0 === 0) {
        node.invalid = true
        return true
      }
      return false
    }

    /**
     * Returns true if a brace node is invalid.
     */

    exports.isInvalidBrace = block => {
      if (block.type !== 'brace') {
        return false
      }
      if (block.invalid === true || block.dollar) {
        return true
      }
      if ((block.commas >> (0 + block.ranges)) >> 0 === 0) {
        block.invalid = true
        return true
      }
      if (block.open !== true || block.close !== true) {
        block.invalid = true
        return true
      }
      return false
    }

    /**
     * Returns true if a node is an open or close node
     */

    exports.isOpenOrClose = node => {
      if (node.type === 'open' || node.type === 'close') {
        return true
      }
      return node.open === true || node.close === true
    }

    /**
     * Reduce an array of text nodes.
     */

    exports.reduce = nodes =>
      nodes.reduce((acc, node) => {
        if (node.type === 'text') {
          acc.push(node.value)
        }
        if (node.type === 'range') {
          node.type = 'text'
        }
        return acc
      }, [])

    /**
     * Flatten an array
     */

    exports.flatten = (...args) => {
      const result = []
      const flat = arr => {
        for (let i = 0; i < arr.length; i++) {
          const ele = arr[i]
          if (Array.isArray(ele)) {
            flat(ele)
            continue
          }
          if (ele !== undefined) {
            result.push(ele)
          }
        }
        return result
      }
      flat(args)
      return result
    }
  })(utils$3)
  return utils$3
}

let stringify$1
let hasRequiredStringify$1
function requireStringify$1() {
  if (hasRequiredStringify$1) {
    return stringify$1
  }
  hasRequiredStringify$1 = 1
  const utils = requireUtils$3()
  stringify$1 = (ast, options = {}) => {
    const stringify = (node, parent = {}) => {
      const invalidBlock = options.escapeInvalid && utils.isInvalidBrace(parent)
      const invalidNode =
        node.invalid === true && options.escapeInvalid === true
      let output = ''
      if (node.value) {
        if ((invalidBlock || invalidNode) && utils.isOpenOrClose(node)) {
          return '\\' + node.value
        }
        return node.value
      }
      if (node.value) {
        return node.value
      }
      if (node.nodes) {
        for (const child of node.nodes) {
          output += stringify(child)
        }
      }
      return output
    }
    return stringify(ast)
  }
  return stringify$1
}

const virtual_purgePolyfills_isNumber = v => typeof v === 'number'

const virtual_purgePolyfills_isNumber$1 = /*#__PURE__*/ Object.freeze({
  __proto__: null,
  default: virtual_purgePolyfills_isNumber
})

const require$$0$1 = /*@__PURE__*/ getAugmentedNamespace(
  virtual_purgePolyfills_isNumber$1
)

/*!
 * to-regex-range <https://github.com/micromatch/to-regex-range>
 *
 * Copyright (c) 2015-present, Jon Schlinkert.
 * Released under the MIT License.
 */
let toRegexRange_1
let hasRequiredToRegexRange
function requireToRegexRange() {
  if (hasRequiredToRegexRange) {
    return toRegexRange_1
  }
  hasRequiredToRegexRange = 1
  const isNumber = require$$0$1
  const toRegexRange = (min, max, options) => {
    if (isNumber(min) === false) {
      throw new TypeError(
        'toRegexRange: expected the first argument to be a number'
      )
    }
    if (max === void 0 || min === max) {
      return String(min)
    }
    if (isNumber(max) === false) {
      throw new TypeError(
        'toRegexRange: expected the second argument to be a number.'
      )
    }
    let opts = {
      relaxZeros: true,
      ...options
    }
    if (typeof opts.strictZeros === 'boolean') {
      opts.relaxZeros = opts.strictZeros === false
    }
    let relax = String(opts.relaxZeros)
    let shorthand = String(opts.shorthand)
    let capture = String(opts.capture)
    let wrap = String(opts.wrap)
    let cacheKey = min + ':' + max + '=' + relax + shorthand + capture + wrap
    if (toRegexRange.cache.hasOwnProperty(cacheKey)) {
      return toRegexRange.cache[cacheKey].result
    }
    let a = Math.min(min, max)
    let b = Math.max(min, max)
    if (Math.abs(a - b) === 1) {
      let result = min + '|' + max
      if (opts.capture) {
        return `(${result})`
      }
      if (opts.wrap === false) {
        return result
      }
      return `(?:${result})`
    }
    let isPadded = hasPadding(min) || hasPadding(max)
    let state = {
      min,
      max,
      a,
      b
    }
    let positives = []
    let negatives = []
    if (isPadded) {
      state.isPadded = isPadded
      state.maxLen = String(state.max).length
    }
    if (a < 0) {
      let newMin = b < 0 ? Math.abs(b) : 1
      negatives = splitToPatterns(newMin, Math.abs(a), state, opts)
      a = state.a = 0
    }
    if (b >= 0) {
      positives = splitToPatterns(a, b, state, opts)
    }
    state.negatives = negatives
    state.positives = positives
    state.result = collatePatterns(negatives, positives)
    if (opts.capture === true) {
      state.result = `(${state.result})`
    } else if (opts.wrap !== false && positives.length + negatives.length > 1) {
      state.result = `(?:${state.result})`
    }
    toRegexRange.cache[cacheKey] = state
    return state.result
  }
  function collatePatterns(neg, pos, options) {
    let onlyNegative = filterPatterns(neg, pos, '-', false) || []
    let onlyPositive = filterPatterns(pos, neg, '', false) || []
    let intersected = filterPatterns(neg, pos, '-?', true) || []
    let subpatterns = onlyNegative.concat(intersected).concat(onlyPositive)
    return subpatterns.join('|')
  }
  function splitToRanges(min, max) {
    let nines = 1
    let zeros = 1
    let stop = countNines(min, nines)
    let stops = new Set([max])
    while (min <= stop && stop <= max) {
      stops.add(stop)
      nines += 1
      stop = countNines(min, nines)
    }
    stop = countZeros(max + 1, zeros) - 1
    while (min < stop && stop <= max) {
      stops.add(stop)
      zeros += 1
      stop = countZeros(max + 1, zeros) - 1
    }
    stops = [...stops]
    stops.sort(compare)
    return stops
  }

  /**
   * Convert a range to a regex pattern
   * @param {Number} `start`
   * @param {Number} `stop`
   * @return {String}
   */

  function rangeToPattern(start, stop, options) {
    if (start === stop) {
      return {
        pattern: start,
        count: [],
        digits: 0
      }
    }
    let zipped = zip(start, stop)
    let digits = zipped.length
    let pattern = ''
    let count = 0
    for (let i = 0; i < digits; i++) {
      let [startDigit, stopDigit] = zipped[i]
      if (startDigit === stopDigit) {
        pattern += startDigit
      } else if (startDigit !== '0' || stopDigit !== '9') {
        pattern += toCharacterClass(startDigit, stopDigit)
      } else {
        count++
      }
    }
    if (count) {
      pattern += options.shorthand === true ? '\\d' : '[0-9]'
    }
    return {
      pattern,
      count: [count],
      digits
    }
  }
  function splitToPatterns(min, max, tok, options) {
    let ranges = splitToRanges(min, max)
    let tokens = []
    let start = min
    let prev
    for (let i = 0; i < ranges.length; i++) {
      let max = ranges[i]
      let obj = rangeToPattern(String(start), String(max), options)
      let zeros = ''
      if (!tok.isPadded && prev && prev.pattern === obj.pattern) {
        if (prev.count.length > 1) {
          prev.count.pop()
        }
        prev.count.push(obj.count[0])
        prev.string = prev.pattern + toQuantifier(prev.count)
        start = max + 1
        continue
      }
      if (tok.isPadded) {
        zeros = padZeros(max, tok, options)
      }
      obj.string = zeros + obj.pattern + toQuantifier(obj.count)
      tokens.push(obj)
      start = max + 1
      prev = obj
    }
    return tokens
  }
  function filterPatterns(arr, comparison, prefix, intersection, options) {
    let result = []
    for (let ele of arr) {
      let { string } = ele

      // only push if _both_ are negative...
      if (!intersection && !contains(comparison, 'string', string)) {
        result.push(prefix + string)
      }

      // or _both_ are positive
      if (intersection && contains(comparison, 'string', string)) {
        result.push(prefix + string)
      }
    }
    return result
  }

  /**
   * Zip strings
   */

  function zip(a, b) {
    let arr = []
    for (let i = 0; i < a.length; i++) {
      arr.push([a[i], b[i]])
    }
    return arr
  }
  function compare(a, b) {
    return a > b ? 1 : b > a ? -1 : 0
  }
  function contains(arr, key, val) {
    return arr.some(ele => ele[key] === val)
  }
  function countNines(min, len) {
    return Number(String(min).slice(0, -len) + '9'.repeat(len))
  }
  function countZeros(integer, zeros) {
    return integer - (integer % Math.pow(10, zeros))
  }
  function toQuantifier(digits) {
    let [start = 0, stop = ''] = digits
    if (stop || start > 1) {
      return `{${start + (stop ? ',' + stop : '')}}`
    }
    return ''
  }
  function toCharacterClass(a, b, options) {
    return `[${a}${b - a === 1 ? '' : '-'}${b}]`
  }
  function hasPadding(str) {
    return /^-?(0+)\d/.test(str)
  }
  function padZeros(value, tok, options) {
    if (!tok.isPadded) {
      return value
    }
    let diff = Math.abs(tok.maxLen - String(value).length)
    let relax = options.relaxZeros !== false
    switch (diff) {
      case 0:
        return ''
      case 1:
        return relax ? '0?' : '0'
      case 2:
        return relax ? '0{0,2}' : '00'
      default: {
        return relax ? `0{0,${diff}}` : `0{${diff}}`
      }
    }
  }

  /**
   * Cache
   */

  toRegexRange.cache = {}
  toRegexRange.clearCache = () => (toRegexRange.cache = {})

  /**
   * Expose `toRegexRange`
   */

  toRegexRange_1 = toRegexRange
  return toRegexRange_1
}

/*!
 * fill-range <https://github.com/jonschlinkert/fill-range>
 *
 * Copyright (c) 2014-present, Jon Schlinkert.
 * Licensed under the MIT License.
 */
let fillRange
let hasRequiredFillRange
function requireFillRange() {
  if (hasRequiredFillRange) {
    return fillRange
  }
  hasRequiredFillRange = 1
  const util = require$$0$4
  const toRegexRange = requireToRegexRange()
  const isObject = val =>
    val !== null && typeof val === 'object' && !Array.isArray(val)
  const transform = toNumber => {
    return value => (toNumber === true ? Number(value) : String(value))
  }
  const isValidValue = value => {
    return (
      typeof value === 'number' || (typeof value === 'string' && value !== '')
    )
  }
  const isNumber = num => Number.isInteger(+num)
  const zeros = input => {
    let value = `${input}`
    let index = -1
    if (value[0] === '-') {
      value = value.slice(1)
    }
    if (value === '0') {
      return false
    }
    while (value[++index] === '0') {}
    return index > 0
  }
  const stringify = (start, end, options) => {
    if (typeof start === 'string' || typeof end === 'string') {
      return true
    }
    return options.stringify === true
  }
  const pad = (input, maxLength, toNumber) => {
    if (maxLength > 0) {
      let dash = input[0] === '-' ? '-' : ''
      if (dash) {
        input = input.slice(1)
      }
      input = dash + input.padStart(dash ? maxLength - 1 : maxLength, '0')
    }
    if (toNumber === false) {
      return String(input)
    }
    return input
  }
  const toMaxLen = (input, maxLength) => {
    let negative = input[0] === '-' ? '-' : ''
    if (negative) {
      input = input.slice(1)
      maxLength--
    }
    while (input.length < maxLength) {
      input = '0' + input
    }
    return negative ? '-' + input : input
  }
  const toSequence = (parts, options, maxLen) => {
    parts.negatives.sort((a, b) => (a < b ? -1 : a > b ? 1 : 0))
    parts.positives.sort((a, b) => (a < b ? -1 : a > b ? 1 : 0))
    let prefix = options.capture ? '' : '?:'
    let positives = ''
    let negatives = ''
    let result
    if (parts.positives.length) {
      positives = parts.positives
        .map(v => toMaxLen(String(v), maxLen))
        .join('|')
    }
    if (parts.negatives.length) {
      negatives = `-(${prefix}${parts.negatives.map(v => toMaxLen(String(v), maxLen)).join('|')})`
    }
    if (positives && negatives) {
      result = `${positives}|${negatives}`
    } else {
      result = positives || negatives
    }
    if (options.wrap) {
      return `(${prefix}${result})`
    }
    return result
  }
  const toRange = (a, b, isNumbers, options) => {
    if (isNumbers) {
      return toRegexRange(a, b, {
        wrap: false,
        ...options
      })
    }
    let start = String.fromCharCode(a)
    if (a === b) {
      return start
    }
    let stop = String.fromCharCode(b)
    return `[${start}-${stop}]`
  }
  const toRegex = (start, end, options) => {
    if (Array.isArray(start)) {
      let wrap = options.wrap === true
      let prefix = options.capture ? '' : '?:'
      return wrap ? `(${prefix}${start.join('|')})` : start.join('|')
    }
    return toRegexRange(start, end, options)
  }
  const rangeError = (...args) => {
    return new RangeError('Invalid range arguments: ' + util.inspect(...args))
  }
  const invalidRange = (start, end, options) => {
    if (options.strictRanges === true) {
      throw rangeError([start, end])
    }
    return []
  }
  const invalidStep = (step, options) => {
    if (options.strictRanges === true) {
      throw new TypeError(`Expected step "${step}" to be a number`)
    }
    return []
  }
  const fillNumbers = (start, end, step = 1, options = {}) => {
    let a = Number(start)
    let b = Number(end)
    if (!Number.isInteger(a) || !Number.isInteger(b)) {
      if (options.strictRanges === true) {
        throw rangeError([start, end])
      }
      return []
    }

    // fix negative zero
    if (a === 0) {
      a = 0
    }
    if (b === 0) {
      b = 0
    }
    let descending = a > b
    let startString = String(start)
    let endString = String(end)
    let stepString = String(step)
    step = Math.max(Math.abs(step), 1)
    let padded = zeros(startString) || zeros(endString) || zeros(stepString)
    let maxLen = padded
      ? Math.max(startString.length, endString.length, stepString.length)
      : 0
    let toNumber = padded === false && stringify(start, end, options) === false
    let format = options.transform || transform(toNumber)
    if (options.toRegex && step === 1) {
      return toRange(
        toMaxLen(start, maxLen),
        toMaxLen(end, maxLen),
        true,
        options
      )
    }
    let parts = {
      negatives: [],
      positives: []
    }
    let push = num =>
      parts[num < 0 ? 'negatives' : 'positives'].push(Math.abs(num))
    let range = []
    let index = 0
    while (descending ? a >= b : a <= b) {
      if (options.toRegex === true && step > 1) {
        push(a)
      } else {
        range.push(pad(format(a, index), maxLen, toNumber))
      }
      a = descending ? a - step : a + step
      index++
    }
    if (options.toRegex === true) {
      return step > 1
        ? toSequence(parts, options, maxLen)
        : toRegex(range, null, {
            wrap: false,
            ...options
          })
    }
    return range
  }
  const fillLetters = (start, end, step = 1, options = {}) => {
    if (
      (!isNumber(start) && start.length > 1) ||
      (!isNumber(end) && end.length > 1)
    ) {
      return invalidRange(start, end, options)
    }
    let format = options.transform || (val => String.fromCharCode(val))
    let a = `${start}`.charCodeAt(0)
    let b = `${end}`.charCodeAt(0)
    let descending = a > b
    let min = Math.min(a, b)
    let max = Math.max(a, b)
    if (options.toRegex && step === 1) {
      return toRange(min, max, false, options)
    }
    let range = []
    let index = 0
    while (descending ? a >= b : a <= b) {
      range.push(format(a, index))
      a = descending ? a - step : a + step
      index++
    }
    if (options.toRegex === true) {
      return toRegex(range, null, {
        wrap: false,
        options
      })
    }
    return range
  }
  const fill = (start, end, step, options = {}) => {
    if (end == null && isValidValue(start)) {
      return [start]
    }
    if (!isValidValue(start) || !isValidValue(end)) {
      return invalidRange(start, end, options)
    }
    if (typeof step === 'function') {
      return fill(start, end, 1, {
        transform: step
      })
    }
    if (isObject(step)) {
      return fill(start, end, 0, step)
    }
    let opts = {
      ...options
    }
    if (opts.capture === true) {
      opts.wrap = true
    }
    step = step || opts.step || 1
    if (!isNumber(step)) {
      if (step != null && !isObject(step)) {
        return invalidStep(step, opts)
      }
      return fill(start, end, 1, step)
    }
    if (isNumber(start) && isNumber(end)) {
      return fillNumbers(start, end, step, opts)
    }
    return fillLetters(start, end, Math.max(Math.abs(step), 1), opts)
  }
  fillRange = fill
  return fillRange
}

let compile_1
let hasRequiredCompile
function requireCompile() {
  if (hasRequiredCompile) {
    return compile_1
  }
  hasRequiredCompile = 1
  const fill = requireFillRange()
  const utils = requireUtils$3()
  const compile = (ast, options = {}) => {
    const walk = (node, parent = {}) => {
      const invalidBlock = utils.isInvalidBrace(parent)
      const invalidNode =
        node.invalid === true && options.escapeInvalid === true
      const invalid = invalidBlock === true || invalidNode === true
      const prefix = options.escapeInvalid === true ? '\\' : ''
      let output = ''
      if (node.isOpen === true) {
        return prefix + node.value
      }
      if (node.isClose === true) {
        console.log('node.isClose', prefix, node.value)
        return prefix + node.value
      }
      if (node.type === 'open') {
        return invalid ? prefix + node.value : '('
      }
      if (node.type === 'close') {
        return invalid ? prefix + node.value : ')'
      }
      if (node.type === 'comma') {
        return node.prev.type === 'comma' ? '' : invalid ? node.value : '|'
      }
      if (node.value) {
        return node.value
      }
      if (node.nodes && node.ranges > 0) {
        const args = utils.reduce(node.nodes)
        const range = fill(...args, {
          ...options,
          wrap: false,
          toRegex: true,
          strictZeros: true
        })
        if (range.length !== 0) {
          return args.length > 1 && range.length > 1 ? `(${range})` : range
        }
      }
      if (node.nodes) {
        for (const child of node.nodes) {
          output += walk(child, node)
        }
      }
      return output
    }
    return walk(ast)
  }
  compile_1 = compile
  return compile_1
}

let expand_1
let hasRequiredExpand
function requireExpand() {
  if (hasRequiredExpand) {
    return expand_1
  }
  hasRequiredExpand = 1
  const fill = requireFillRange()
  const stringify = requireStringify$1()
  const utils = requireUtils$3()
  const append = (queue = '', stash = '', enclose = false) => {
    const result = []
    queue = [].concat(queue)
    stash = [].concat(stash)
    if (!stash.length) {
      return queue
    }
    if (!queue.length) {
      return enclose ? utils.flatten(stash).map(ele => `{${ele}}`) : stash
    }
    for (const item of queue) {
      if (Array.isArray(item)) {
        for (const value of item) {
          result.push(append(value, stash, enclose))
        }
      } else {
        for (let ele of stash) {
          if (enclose === true && typeof ele === 'string') {
            ele = `{${ele}}`
          }
          result.push(
            Array.isArray(ele) ? append(item, ele, enclose) : item + ele
          )
        }
      }
    }
    return utils.flatten(result)
  }
  const expand = (ast, options = {}) => {
    const rangeLimit =
      options.rangeLimit === undefined ? 1000 : options.rangeLimit
    const walk = (node, parent = {}) => {
      node.queue = []
      let p = parent
      let q = parent.queue
      while (p.type !== 'brace' && p.type !== 'root' && p.parent) {
        p = p.parent
        q = p.queue
      }
      if (node.invalid || node.dollar) {
        q.push(append(q.pop(), stringify(node, options)))
        return
      }
      if (
        node.type === 'brace' &&
        node.invalid !== true &&
        node.nodes.length === 2
      ) {
        q.push(append(q.pop(), ['{}']))
        return
      }
      if (node.nodes && node.ranges > 0) {
        const args = utils.reduce(node.nodes)
        if (utils.exceedsLimit(...args, options.step, rangeLimit)) {
          throw new RangeError(
            'expanded array length exceeds range limit. Use options.rangeLimit to increase or disable the limit.'
          )
        }
        let range = fill(...args, options)
        if (range.length === 0) {
          range = stringify(node, options)
        }
        q.push(append(q.pop(), range))
        node.nodes = []
        return
      }
      const enclose = utils.encloseBrace(node)
      let queue = node.queue
      let block = node
      while (block.type !== 'brace' && block.type !== 'root' && block.parent) {
        block = block.parent
        queue = block.queue
      }
      for (let i = 0; i < node.nodes.length; i++) {
        const child = node.nodes[i]
        if (child.type === 'comma' && node.type === 'brace') {
          if (i === 1) {
            queue.push('')
          }
          queue.push('')
          continue
        }
        if (child.type === 'close') {
          q.push(append(q.pop(), queue, enclose))
          continue
        }
        if (child.value && child.type !== 'open') {
          queue.push(append(queue.pop(), child.value))
          continue
        }
        if (child.nodes) {
          walk(child, node)
        }
      }
      return queue
    }
    return utils.flatten(walk(ast))
  }
  expand_1 = expand
  return expand_1
}

let constants$5
let hasRequiredConstants$4
function requireConstants$4() {
  if (hasRequiredConstants$4) {
    return constants$5
  }
  hasRequiredConstants$4 = 1
  constants$5 = {
    MAX_LENGTH: 10000,
    // Digits
    CHAR_0: '0',
    /* 0 */
    CHAR_9: '9',
    /* 9 */

    // Alphabet chars.
    CHAR_UPPERCASE_A: 'A',
    /* A */
    CHAR_LOWERCASE_A: 'a',
    /* a */
    CHAR_UPPERCASE_Z: 'Z',
    /* Z */
    CHAR_LOWERCASE_Z: 'z',
    /* z */

    CHAR_LEFT_PARENTHESES: '(',
    /* ( */
    CHAR_RIGHT_PARENTHESES: ')',
    /* ) */

    CHAR_ASTERISK: '*',
    /* * */

    // Non-alphabetic chars.
    CHAR_AMPERSAND: '&',
    /* & */
    CHAR_AT: '@',
    /* @ */
    CHAR_BACKSLASH: '\\',
    /* \ */
    CHAR_BACKTICK: '`',
    /* ` */
    CHAR_CARRIAGE_RETURN: '\r',
    /* \r */
    CHAR_CIRCUMFLEX_ACCENT: '^',
    /* ^ */
    CHAR_COLON: ':',
    /* : */
    CHAR_COMMA: ',',
    /* , */
    CHAR_DOLLAR: '$',
    /* . */
    CHAR_DOT: '.',
    /* . */
    CHAR_DOUBLE_QUOTE: '"',
    /* " */
    CHAR_EQUAL: '=',
    /* = */
    CHAR_EXCLAMATION_MARK: '!',
    /* ! */
    CHAR_FORM_FEED: '\f',
    /* \f */
    CHAR_FORWARD_SLASH: '/',
    /* / */
    CHAR_HASH: '#',
    /* # */
    CHAR_HYPHEN_MINUS: '-',
    /* - */
    CHAR_LEFT_ANGLE_BRACKET: '<',
    /* < */
    CHAR_LEFT_CURLY_BRACE: '{',
    /* { */
    CHAR_LEFT_SQUARE_BRACKET: '[',
    /* [ */
    CHAR_LINE_FEED: '\n',
    /* \n */
    CHAR_NO_BREAK_SPACE: '\u00A0',
    /* \u00A0 */
    CHAR_PERCENT: '%',
    /* % */
    CHAR_PLUS: '+',
    /* + */
    CHAR_QUESTION_MARK: '?',
    /* ? */
    CHAR_RIGHT_ANGLE_BRACKET: '>',
    /* > */
    CHAR_RIGHT_CURLY_BRACE: '}',
    /* } */
    CHAR_RIGHT_SQUARE_BRACKET: ']',
    /* ] */
    CHAR_SEMICOLON: ';',
    /* ; */
    CHAR_SINGLE_QUOTE: "'",
    /* ' */
    CHAR_SPACE: ' ',
    /*   */
    CHAR_TAB: '\t',
    /* \t */
    CHAR_UNDERSCORE: '_',
    /* _ */
    CHAR_VERTICAL_LINE: '|',
    /* | */
    CHAR_ZERO_WIDTH_NOBREAK_SPACE: '\uFEFF' /* \uFEFF */
  }
  return constants$5
}

let parse_1$5
let hasRequiredParse$5
function requireParse$5() {
  if (hasRequiredParse$5) {
    return parse_1$5
  }
  hasRequiredParse$5 = 1
  const stringify = requireStringify$1()

  /**
   * Constants
   */

  const {
    MAX_LENGTH,
    CHAR_BACKSLASH,
    /* \ */
    CHAR_BACKTICK,
    /* ` */
    CHAR_COMMA,
    /* , */
    CHAR_DOT,
    /* . */
    CHAR_LEFT_PARENTHESES,
    /* ( */
    CHAR_RIGHT_PARENTHESES,
    /* ) */
    CHAR_LEFT_CURLY_BRACE,
    /* { */
    CHAR_RIGHT_CURLY_BRACE,
    /* } */
    CHAR_LEFT_SQUARE_BRACKET,
    /* [ */
    CHAR_RIGHT_SQUARE_BRACKET,
    /* ] */
    CHAR_DOUBLE_QUOTE,
    /* " */
    CHAR_SINGLE_QUOTE,
    /* ' */
    CHAR_NO_BREAK_SPACE,
    CHAR_ZERO_WIDTH_NOBREAK_SPACE
  } = requireConstants$4()

  /**
   * parse
   */

  const parse = (input, options = {}) => {
    if (typeof input !== 'string') {
      throw new TypeError('Expected a string')
    }
    const opts = options || {}
    const max =
      typeof opts.maxLength === 'number'
        ? Math.min(MAX_LENGTH, opts.maxLength)
        : MAX_LENGTH
    if (input.length > max) {
      throw new SyntaxError(
        `Input length (${input.length}), exceeds max characters (${max})`
      )
    }
    const ast = {
      type: 'root',
      input,
      nodes: []
    }
    const stack = [ast]
    let block = ast
    let prev = ast
    let brackets = 0
    const length = input.length
    let index = 0
    let depth = 0
    let value

    /**
     * Helpers
     */

    const advance = () => input[index++]
    const push = node => {
      if (node.type === 'text' && prev.type === 'dot') {
        prev.type = 'text'
      }
      if (prev && prev.type === 'text' && node.type === 'text') {
        prev.value += node.value
        return
      }
      block.nodes.push(node)
      node.parent = block
      node.prev = prev
      prev = node
      return node
    }
    push({
      type: 'bos'
    })
    while (index < length) {
      block = stack[stack.length - 1]
      value = advance()

      /**
       * Invalid chars
       */

      if (
        value === CHAR_ZERO_WIDTH_NOBREAK_SPACE ||
        value === CHAR_NO_BREAK_SPACE
      ) {
        continue
      }

      /**
       * Escaped chars
       */

      if (value === CHAR_BACKSLASH) {
        push({
          type: 'text',
          value: (options.keepEscaping ? value : '') + advance()
        })
        continue
      }

      /**
       * Right square bracket (literal): ']'
       */

      if (value === CHAR_RIGHT_SQUARE_BRACKET) {
        push({
          type: 'text',
          value: '\\' + value
        })
        continue
      }

      /**
       * Left square bracket: '['
       */

      if (value === CHAR_LEFT_SQUARE_BRACKET) {
        brackets++
        let next
        while (index < length && (next = advance())) {
          value += next
          if (next === CHAR_LEFT_SQUARE_BRACKET) {
            brackets++
            continue
          }
          if (next === CHAR_BACKSLASH) {
            value += advance()
            continue
          }
          if (next === CHAR_RIGHT_SQUARE_BRACKET) {
            brackets--
            if (brackets === 0) {
              break
            }
          }
        }
        push({
          type: 'text',
          value
        })
        continue
      }

      /**
       * Parentheses
       */

      if (value === CHAR_LEFT_PARENTHESES) {
        block = push({
          type: 'paren',
          nodes: []
        })
        stack.push(block)
        push({
          type: 'text',
          value
        })
        continue
      }
      if (value === CHAR_RIGHT_PARENTHESES) {
        if (block.type !== 'paren') {
          push({
            type: 'text',
            value
          })
          continue
        }
        block = stack.pop()
        push({
          type: 'text',
          value
        })
        block = stack[stack.length - 1]
        continue
      }

      /**
       * Quotes: '|"|`
       */

      if (
        value === CHAR_DOUBLE_QUOTE ||
        value === CHAR_SINGLE_QUOTE ||
        value === CHAR_BACKTICK
      ) {
        const open = value
        let next
        if (options.keepQuotes !== true) {
          value = ''
        }
        while (index < length && (next = advance())) {
          if (next === CHAR_BACKSLASH) {
            value += next + advance()
            continue
          }
          if (next === open) {
            if (options.keepQuotes === true) {
              value += next
            }
            break
          }
          value += next
        }
        push({
          type: 'text',
          value
        })
        continue
      }

      /**
       * Left curly brace: '{'
       */

      if (value === CHAR_LEFT_CURLY_BRACE) {
        depth++
        const dollar =
          (prev.value && prev.value.slice(-1) === '$') || block.dollar === true
        const brace = {
          type: 'brace',
          open: true,
          close: false,
          dollar,
          depth,
          commas: 0,
          ranges: 0,
          nodes: []
        }
        block = push(brace)
        stack.push(block)
        push({
          type: 'open',
          value
        })
        continue
      }

      /**
       * Right curly brace: '}'
       */

      if (value === CHAR_RIGHT_CURLY_BRACE) {
        if (block.type !== 'brace') {
          push({
            type: 'text',
            value
          })
          continue
        }
        const type = 'close'
        block = stack.pop()
        block.close = true
        push({
          type,
          value
        })
        depth--
        block = stack[stack.length - 1]
        continue
      }

      /**
       * Comma: ','
       */

      if (value === CHAR_COMMA && depth > 0) {
        if (block.ranges > 0) {
          block.ranges = 0
          const open = block.nodes.shift()
          block.nodes = [
            open,
            {
              type: 'text',
              value: stringify(block)
            }
          ]
        }
        push({
          type: 'comma',
          value
        })
        block.commas++
        continue
      }

      /**
       * Dot: '.'
       */

      if (value === CHAR_DOT && depth > 0 && block.commas === 0) {
        const siblings = block.nodes
        if (depth === 0 || siblings.length === 0) {
          push({
            type: 'text',
            value
          })
          continue
        }
        if (prev.type === 'dot') {
          block.range = []
          prev.value += value
          prev.type = 'range'
          if (block.nodes.length !== 3 && block.nodes.length !== 5) {
            block.invalid = true
            block.ranges = 0
            prev.type = 'text'
            continue
          }
          block.ranges++
          block.args = []
          continue
        }
        if (prev.type === 'range') {
          siblings.pop()
          const before = siblings[siblings.length - 1]
          before.value += prev.value + value
          prev = before
          block.ranges--
          continue
        }
        push({
          type: 'dot',
          value
        })
        continue
      }

      /**
       * Text
       */

      push({
        type: 'text',
        value
      })
    }

    // Mark imbalanced braces and brackets as invalid
    do {
      block = stack.pop()
      if (block.type !== 'root') {
        block.nodes.forEach(node => {
          if (!node.nodes) {
            if (node.type === 'open') {
              node.isOpen = true
            }
            if (node.type === 'close') {
              node.isClose = true
            }
            if (!node.nodes) {
              node.type = 'text'
            }
            node.invalid = true
          }
        })

        // get the location of the block on parent.nodes (block's siblings)
        const parent = stack[stack.length - 1]
        const index = parent.nodes.indexOf(block)
        // replace the (invalid) block with it's nodes
        parent.nodes.splice(index, 1, ...block.nodes)
      }
    } while (stack.length > 0)
    push({
      type: 'eos'
    })
    return ast
  }
  parse_1$5 = parse
  return parse_1$5
}

let braces_1
let hasRequiredBraces
function requireBraces() {
  if (hasRequiredBraces) {
    return braces_1
  }
  hasRequiredBraces = 1
  const stringify = requireStringify$1()
  const compile = requireCompile()
  const expand = requireExpand()
  const parse = requireParse$5()

  /**
   * Expand the given pattern or create a regex-compatible string.
   *
   * ```js
   * const braces = require('braces');
   * console.log(braces('{a,b,c}', { compile: true })); //=> ['(a|b|c)']
   * console.log(braces('{a,b,c}')); //=> ['a', 'b', 'c']
   * ```
   * @param {String} `str`
   * @param {Object} `options`
   * @return {String}
   * @api public
   */

  const braces = (input, options = {}) => {
    let output = []
    if (Array.isArray(input)) {
      for (const pattern of input) {
        const result = braces.create(pattern, options)
        if (Array.isArray(result)) {
          output.push(...result)
        } else {
          output.push(result)
        }
      }
    } else {
      output = [].concat(braces.create(input, options))
    }
    if (options && options.expand === true && options.nodupes === true) {
      output = [...new Set(output)]
    }
    return output
  }

  /**
   * Parse the given `str` with the given `options`.
   *
   * ```js
   * // braces.parse(pattern, [, options]);
   * const ast = braces.parse('a/{b,c}/d');
   * console.log(ast);
   * ```
   * @param {String} pattern Brace pattern to parse
   * @param {Object} options
   * @return {Object} Returns an AST
   * @api public
   */

  braces.parse = (input, options = {}) => parse(input, options)

  /**
   * Creates a braces string from an AST, or an AST node.
   *
   * ```js
   * const braces = require('braces');
   * let ast = braces.parse('foo/{a,b}/bar');
   * console.log(stringify(ast.nodes[2])); //=> '{a,b}'
   * ```
   * @param {String} `input` Brace pattern or AST.
   * @param {Object} `options`
   * @return {Array} Returns an array of expanded values.
   * @api public
   */

  braces.stringify = (input, options = {}) => {
    if (typeof input === 'string') {
      return stringify(braces.parse(input, options), options)
    }
    return stringify(input, options)
  }

  /**
   * Compiles a brace pattern into a regex-compatible, optimized string.
   * This method is called by the main [braces](#braces) function by default.
   *
   * ```js
   * const braces = require('braces');
   * console.log(braces.compile('a/{b,c}/d'));
   * //=> ['a/(b|c)/d']
   * ```
   * @param {String} `input` Brace pattern or AST.
   * @param {Object} `options`
   * @return {Array} Returns an array of expanded values.
   * @api public
   */

  braces.compile = (input, options = {}) => {
    if (typeof input === 'string') {
      input = braces.parse(input, options)
    }
    return compile(input, options)
  }

  /**
   * Expands a brace pattern into an array. This method is called by the
   * main [braces](#braces) function when `options.expand` is true. Before
   * using this method it's recommended that you read the [performance notes](#performance))
   * and advantages of using [.compile](#compile) instead.
   *
   * ```js
   * const braces = require('braces');
   * console.log(braces.expand('a/{b,c}/d'));
   * //=> ['a/b/d', 'a/c/d'];
   * ```
   * @param {String} `pattern` Brace pattern
   * @param {Object} `options`
   * @return {Array} Returns an array of expanded values.
   * @api public
   */

  braces.expand = (input, options = {}) => {
    if (typeof input === 'string') {
      input = braces.parse(input, options)
    }
    let result = expand(input, options)

    // filter out empty strings if specified
    if (options.noempty === true) {
      result = result.filter(Boolean)
    }

    // filter out duplicates if specified
    if (options.nodupes === true) {
      result = [...new Set(result)]
    }
    return result
  }

  /**
   * Processes a brace pattern and returns either an expanded array
   * (if `options.expand` is true), a highly optimized regex-compatible string.
   * This method is called by the main [braces](#braces) function.
   *
   * ```js
   * const braces = require('braces');
   * console.log(braces.create('user-{200..300}/project-{a,b,c}-{1..10}'))
   * //=> 'user-(20[0-9]|2[1-9][0-9]|300)/project-(a|b|c)-([1-9]|10)'
   * ```
   * @param {String} `pattern` Brace pattern
   * @param {Object} `options`
   * @return {Array} Returns an array of expanded values.
   * @api public
   */

  braces.create = (input, options = {}) => {
    if (input === '' || input.length < 3) {
      return [input]
    }
    return options.expand !== true
      ? braces.compile(input, options)
      : braces.expand(input, options)
  }

  /**
   * Expose "braces"
   */

  braces_1 = braces
  return braces_1
}

const utils$2 = {}

let constants$4
let hasRequiredConstants$3
function requireConstants$3() {
  if (hasRequiredConstants$3) {
    return constants$4
  }
  hasRequiredConstants$3 = 1
  const path = require$$0$5
  const WIN_SLASH = '\\\\/'
  const WIN_NO_SLASH = `[^${WIN_SLASH}]`

  /**
   * Posix glob regex
   */

  const DOT_LITERAL = '\\.'
  const PLUS_LITERAL = '\\+'
  const QMARK_LITERAL = '\\?'
  const SLASH_LITERAL = '\\/'
  const ONE_CHAR = '(?=.)'
  const QMARK = '[^/]'
  const END_ANCHOR = `(?:${SLASH_LITERAL}|$)`
  const START_ANCHOR = `(?:^|${SLASH_LITERAL})`
  const DOTS_SLASH = `${DOT_LITERAL}{1,2}${END_ANCHOR}`
  const NO_DOT = `(?!${DOT_LITERAL})`
  const NO_DOTS = `(?!${START_ANCHOR}${DOTS_SLASH})`
  const NO_DOT_SLASH = `(?!${DOT_LITERAL}{0,1}${END_ANCHOR})`
  const NO_DOTS_SLASH = `(?!${DOTS_SLASH})`
  const QMARK_NO_DOT = `[^.${SLASH_LITERAL}]`
  const STAR = `${QMARK}*?`
  const POSIX_CHARS = {
    DOT_LITERAL,
    PLUS_LITERAL,
    QMARK_LITERAL,
    SLASH_LITERAL,
    ONE_CHAR,
    QMARK,
    END_ANCHOR,
    DOTS_SLASH,
    NO_DOT,
    NO_DOTS,
    NO_DOT_SLASH,
    NO_DOTS_SLASH,
    QMARK_NO_DOT,
    STAR,
    START_ANCHOR
  }

  /**
   * Windows glob regex
   */

  const WINDOWS_CHARS = {
    ...POSIX_CHARS,
    SLASH_LITERAL: `[${WIN_SLASH}]`,
    QMARK: WIN_NO_SLASH,
    STAR: `${WIN_NO_SLASH}*?`,
    DOTS_SLASH: `${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$)`,
    NO_DOT: `(?!${DOT_LITERAL})`,
    NO_DOTS: `(?!(?:^|[${WIN_SLASH}])${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$))`,
    NO_DOT_SLASH: `(?!${DOT_LITERAL}{0,1}(?:[${WIN_SLASH}]|$))`,
    NO_DOTS_SLASH: `(?!${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$))`,
    QMARK_NO_DOT: `[^.${WIN_SLASH}]`,
    START_ANCHOR: `(?:^|[${WIN_SLASH}])`,
    END_ANCHOR: `(?:[${WIN_SLASH}]|$)`
  }

  /**
   * POSIX Bracket Regex
   */

  const POSIX_REGEX_SOURCE = {
    alnum: 'a-zA-Z0-9',
    alpha: 'a-zA-Z',
    ascii: '\\x00-\\x7F',
    blank: ' \\t',
    cntrl: '\\x00-\\x1F\\x7F',
    digit: '0-9',
    graph: '\\x21-\\x7E',
    lower: 'a-z',
    print: '\\x20-\\x7E ',
    punct: '\\-!"#$%&\'()\\*+,./:;<=>?@[\\]^_`{|}~',
    space: ' \\t\\r\\n\\v\\f',
    upper: 'A-Z',
    word: 'A-Za-z0-9_',
    xdigit: 'A-Fa-f0-9'
  }
  constants$4 = {
    MAX_LENGTH: 1024 * 64,
    POSIX_REGEX_SOURCE,
    // regular expressions
    REGEX_BACKSLASH: /\\(?![*+?^${}(|)[\]])/g,
    REGEX_NON_SPECIAL_CHARS: /^[^@![\].,$*+?^{}()|\\/]+/,
    REGEX_SPECIAL_CHARS: /[-*+?.^${}(|)[\]]/,
    REGEX_SPECIAL_CHARS_BACKREF: /(\\?)((\W)(\3*))/g,
    REGEX_SPECIAL_CHARS_GLOBAL: /([-*+?.^${}(|)[\]])/g,
    REGEX_REMOVE_BACKSLASH: /(?:\[.*?[^\\]\]|\\(?=.))/g,
    // Replace globs with equivalent patterns to reduce parsing time.
    REPLACEMENTS: {
      '***': '*',
      '**/**': '**',
      '**/**/**': '**'
    },
    // Digits
    CHAR_0: 48,
    /* 0 */
    CHAR_9: 57,
    /* 9 */

    // Alphabet chars.
    CHAR_UPPERCASE_A: 65,
    /* A */
    CHAR_LOWERCASE_A: 97,
    /* a */
    CHAR_UPPERCASE_Z: 90,
    /* Z */
    CHAR_LOWERCASE_Z: 122,
    /* z */

    CHAR_LEFT_PARENTHESES: 40,
    /* ( */
    CHAR_RIGHT_PARENTHESES: 41,
    /* ) */

    CHAR_ASTERISK: 42,
    /* * */

    // Non-alphabetic chars.
    CHAR_AMPERSAND: 38,
    /* & */
    CHAR_AT: 64,
    /* @ */
    CHAR_BACKWARD_SLASH: 92,
    /* \ */
    CHAR_CARRIAGE_RETURN: 13,
    /* \r */
    CHAR_CIRCUMFLEX_ACCENT: 94,
    /* ^ */
    CHAR_COLON: 58,
    /* : */
    CHAR_COMMA: 44,
    /* , */
    CHAR_DOT: 46,
    /* . */
    CHAR_DOUBLE_QUOTE: 34,
    /* " */
    CHAR_EQUAL: 61,
    /* = */
    CHAR_EXCLAMATION_MARK: 33,
    /* ! */
    CHAR_FORM_FEED: 12,
    /* \f */
    CHAR_FORWARD_SLASH: 47,
    /* / */
    CHAR_GRAVE_ACCENT: 96,
    /* ` */
    CHAR_HASH: 35,
    /* # */
    CHAR_HYPHEN_MINUS: 45,
    /* - */
    CHAR_LEFT_ANGLE_BRACKET: 60,
    /* < */
    CHAR_LEFT_CURLY_BRACE: 123,
    /* { */
    CHAR_LEFT_SQUARE_BRACKET: 91,
    /* [ */
    CHAR_LINE_FEED: 10,
    /* \n */
    CHAR_NO_BREAK_SPACE: 160,
    /* \u00A0 */
    CHAR_PERCENT: 37,
    /* % */
    CHAR_PLUS: 43,
    /* + */
    CHAR_QUESTION_MARK: 63,
    /* ? */
    CHAR_RIGHT_ANGLE_BRACKET: 62,
    /* > */
    CHAR_RIGHT_CURLY_BRACE: 125,
    /* } */
    CHAR_RIGHT_SQUARE_BRACKET: 93,
    /* ] */
    CHAR_SEMICOLON: 59,
    /* ; */
    CHAR_SINGLE_QUOTE: 39,
    /* ' */
    CHAR_SPACE: 32,
    /*   */
    CHAR_TAB: 9,
    /* \t */
    CHAR_UNDERSCORE: 95,
    /* _ */
    CHAR_VERTICAL_LINE: 124,
    /* | */
    CHAR_ZERO_WIDTH_NOBREAK_SPACE: 65279,
    /* \uFEFF */

    SEP: path.sep,
    /**
     * Create EXTGLOB_CHARS
     */

    extglobChars(chars) {
      return {
        '!': {
          type: 'negate',
          open: '(?:(?!(?:',
          close: `))${chars.STAR})`
        },
        '?': {
          type: 'qmark',
          open: '(?:',
          close: ')?'
        },
        '+': {
          type: 'plus',
          open: '(?:',
          close: ')+'
        },
        '*': {
          type: 'star',
          open: '(?:',
          close: ')*'
        },
        '@': {
          type: 'at',
          open: '(?:',
          close: ')'
        }
      }
    },
    /**
     * Create GLOB_CHARS
     */

    globChars(win32) {
      return win32 === true ? WINDOWS_CHARS : POSIX_CHARS
    }
  }
  return constants$4
}

let hasRequiredUtils$2
function requireUtils$2() {
  if (hasRequiredUtils$2) {
    return utils$2
  }
  hasRequiredUtils$2 = 1
  ;(function (exports) {
    const path = require$$0$5
    const win32 = process.platform === 'win32'
    const {
      REGEX_BACKSLASH,
      REGEX_REMOVE_BACKSLASH,
      REGEX_SPECIAL_CHARS,
      REGEX_SPECIAL_CHARS_GLOBAL
    } = requireConstants$3()
    exports.isObject = val =>
      val !== null && typeof val === 'object' && !Array.isArray(val)
    exports.hasRegexChars = str => REGEX_SPECIAL_CHARS.test(str)
    exports.isRegexChar = str => str.length === 1 && exports.hasRegexChars(str)
    exports.escapeRegex = str => str.replace(REGEX_SPECIAL_CHARS_GLOBAL, '\\$1')
    exports.toPosixSlashes = str => str.replace(REGEX_BACKSLASH, '/')
    exports.removeBackslashes = str => {
      return str.replace(REGEX_REMOVE_BACKSLASH, match => {
        return match === '\\' ? '' : match
      })
    }
    exports.supportsLookbehinds = () => {
      const segs = process.version.slice(1).split('.').map(Number)
      if (
        (segs.length === 3 && segs[0] >= 9) ||
        (segs[0] === 8 && segs[1] >= 10)
      ) {
        return true
      }
      return false
    }
    exports.isWindows = options => {
      if (options && typeof options.windows === 'boolean') {
        return options.windows
      }
      return win32 === true || path.sep === '\\'
    }
    exports.escapeLast = (input, char, lastIdx) => {
      const idx = input.lastIndexOf(char, lastIdx)
      if (idx === -1) {
        return input
      }
      if (input[idx - 1] === '\\') {
        return exports.escapeLast(input, char, idx - 1)
      }
      return `${input.slice(0, idx)}\\${input.slice(idx)}`
    }
    exports.removePrefix = (input, state = {}) => {
      let output = input
      if (output.startsWith('./')) {
        output = output.slice(2)
        state.prefix = './'
      }
      return output
    }
    exports.wrapOutput = (input, state = {}, options = {}) => {
      const prepend = options.contains ? '' : '^'
      const append = options.contains ? '' : '$'
      let output = `${prepend}(?:${input})${append}`
      if (state.negated === true) {
        output = `(?:^(?!${output}).*$)`
      }
      return output
    }
  })(utils$2)
  return utils$2
}

let scan_1$1
let hasRequiredScan$1
function requireScan$1() {
  if (hasRequiredScan$1) {
    return scan_1$1
  }
  hasRequiredScan$1 = 1
  const utils = requireUtils$2()
  const {
    CHAR_ASTERISK,
    /* * */
    CHAR_AT,
    /* @ */
    CHAR_BACKWARD_SLASH,
    /* \ */
    CHAR_COMMA,
    /* , */
    CHAR_DOT,
    /* . */
    CHAR_EXCLAMATION_MARK,
    /* ! */
    CHAR_FORWARD_SLASH,
    /* / */
    CHAR_LEFT_CURLY_BRACE,
    /* { */
    CHAR_LEFT_PARENTHESES,
    /* ( */
    CHAR_LEFT_SQUARE_BRACKET,
    /* [ */
    CHAR_PLUS,
    /* + */
    CHAR_QUESTION_MARK,
    /* ? */
    CHAR_RIGHT_CURLY_BRACE,
    /* } */
    CHAR_RIGHT_PARENTHESES,
    /* ) */
    CHAR_RIGHT_SQUARE_BRACKET /* ] */
  } = requireConstants$3()
  const isPathSeparator = code => {
    return code === CHAR_FORWARD_SLASH || code === CHAR_BACKWARD_SLASH
  }
  const depth = token => {
    if (token.isPrefix !== true) {
      token.depth = token.isGlobstar ? Infinity : 1
    }
  }

  /**
   * Quickly scans a glob pattern and returns an object with a handful of
   * useful properties, like `isGlob`, `path` (the leading non-glob, if it exists),
   * `glob` (the actual pattern), `negated` (true if the path starts with `!` but not
   * with `!(`) and `negatedExtglob` (true if the path starts with `!(`).
   *
   * ```js
   * const pm = require('picomatch');
   * console.log(pm.scan('foo/bar/*.js'));
   * { isGlob: true, input: 'foo/bar/*.js', base: 'foo/bar', glob: '*.js' }
   * ```
   * @param {String} `str`
   * @param {Object} `options`
   * @return {Object} Returns an object with tokens and regex source string.
   * @api public
   */

  const scan = (input, options) => {
    const opts = options || {}
    const length = input.length - 1
    const scanToEnd = opts.parts === true || opts.scanToEnd === true
    const slashes = []
    const tokens = []
    const parts = []
    let str = input
    let index = -1
    let start = 0
    let lastIndex = 0
    let isBrace = false
    let isBracket = false
    let isGlob = false
    let isExtglob = false
    let isGlobstar = false
    let braceEscaped = false
    let backslashes = false
    let negated = false
    let negatedExtglob = false
    let finished = false
    let braces = 0
    let prev
    let code
    let token = {
      value: '',
      depth: 0,
      isGlob: false
    }
    const eos = () => index >= length
    const peek = () => str.charCodeAt(index + 1)
    const advance = () => {
      prev = code
      return str.charCodeAt(++index)
    }
    while (index < length) {
      code = advance()
      let next
      if (code === CHAR_BACKWARD_SLASH) {
        backslashes = token.backslashes = true
        code = advance()
        if (code === CHAR_LEFT_CURLY_BRACE) {
          braceEscaped = true
        }
        continue
      }
      if (braceEscaped === true || code === CHAR_LEFT_CURLY_BRACE) {
        braces++
        while (eos() !== true && (code = advance())) {
          if (code === CHAR_BACKWARD_SLASH) {
            backslashes = token.backslashes = true
            advance()
            continue
          }
          if (code === CHAR_LEFT_CURLY_BRACE) {
            braces++
            continue
          }
          if (
            braceEscaped !== true &&
            code === CHAR_DOT &&
            (code = advance()) === CHAR_DOT
          ) {
            isBrace = token.isBrace = true
            isGlob = token.isGlob = true
            finished = true
            if (scanToEnd === true) {
              continue
            }
            break
          }
          if (braceEscaped !== true && code === CHAR_COMMA) {
            isBrace = token.isBrace = true
            isGlob = token.isGlob = true
            finished = true
            if (scanToEnd === true) {
              continue
            }
            break
          }
          if (code === CHAR_RIGHT_CURLY_BRACE) {
            braces--
            if (braces === 0) {
              braceEscaped = false
              isBrace = token.isBrace = true
              finished = true
              break
            }
          }
        }
        if (scanToEnd === true) {
          continue
        }
        break
      }
      if (code === CHAR_FORWARD_SLASH) {
        slashes.push(index)
        tokens.push(token)
        token = {
          value: '',
          depth: 0,
          isGlob: false
        }
        if (finished === true) {
          continue
        }
        if (prev === CHAR_DOT && index === start + 1) {
          start += 2
          continue
        }
        lastIndex = index + 1
        continue
      }
      if (opts.noext !== true) {
        const isExtglobChar =
          code === CHAR_PLUS ||
          code === CHAR_AT ||
          code === CHAR_ASTERISK ||
          code === CHAR_QUESTION_MARK ||
          code === CHAR_EXCLAMATION_MARK
        if (isExtglobChar === true && peek() === CHAR_LEFT_PARENTHESES) {
          isGlob = token.isGlob = true
          isExtglob = token.isExtglob = true
          finished = true
          if (code === CHAR_EXCLAMATION_MARK && index === start) {
            negatedExtglob = true
          }
          if (scanToEnd === true) {
            while (eos() !== true && (code = advance())) {
              if (code === CHAR_BACKWARD_SLASH) {
                backslashes = token.backslashes = true
                code = advance()
                continue
              }
              if (code === CHAR_RIGHT_PARENTHESES) {
                isGlob = token.isGlob = true
                finished = true
                break
              }
            }
            continue
          }
          break
        }
      }
      if (code === CHAR_ASTERISK) {
        if (prev === CHAR_ASTERISK) {
          isGlobstar = token.isGlobstar = true
        }
        isGlob = token.isGlob = true
        finished = true
        if (scanToEnd === true) {
          continue
        }
        break
      }
      if (code === CHAR_QUESTION_MARK) {
        isGlob = token.isGlob = true
        finished = true
        if (scanToEnd === true) {
          continue
        }
        break
      }
      if (code === CHAR_LEFT_SQUARE_BRACKET) {
        while (eos() !== true && (next = advance())) {
          if (next === CHAR_BACKWARD_SLASH) {
            backslashes = token.backslashes = true
            advance()
            continue
          }
          if (next === CHAR_RIGHT_SQUARE_BRACKET) {
            isBracket = token.isBracket = true
            isGlob = token.isGlob = true
            finished = true
            break
          }
        }
        if (scanToEnd === true) {
          continue
        }
        break
      }
      if (
        opts.nonegate !== true &&
        code === CHAR_EXCLAMATION_MARK &&
        index === start
      ) {
        negated = token.negated = true
        start++
        continue
      }
      if (opts.noparen !== true && code === CHAR_LEFT_PARENTHESES) {
        isGlob = token.isGlob = true
        if (scanToEnd === true) {
          while (eos() !== true && (code = advance())) {
            if (code === CHAR_LEFT_PARENTHESES) {
              backslashes = token.backslashes = true
              code = advance()
              continue
            }
            if (code === CHAR_RIGHT_PARENTHESES) {
              finished = true
              break
            }
          }
          continue
        }
        break
      }
      if (isGlob === true) {
        finished = true
        if (scanToEnd === true) {
          continue
        }
        break
      }
    }
    if (opts.noext === true) {
      isExtglob = false
      isGlob = false
    }
    let base = str
    let prefix = ''
    let glob = ''
    if (start > 0) {
      prefix = str.slice(0, start)
      str = str.slice(start)
      lastIndex -= start
    }
    if (base && isGlob === true && lastIndex > 0) {
      base = str.slice(0, lastIndex)
      glob = str.slice(lastIndex)
    } else if (isGlob === true) {
      base = ''
      glob = str
    } else {
      base = str
    }
    if (base && base !== '' && base !== '/' && base !== str) {
      if (isPathSeparator(base.charCodeAt(base.length - 1))) {
        base = base.slice(0, -1)
      }
    }
    if (opts.unescape === true) {
      if (glob) {
        glob = utils.removeBackslashes(glob)
      }
      if (base && backslashes === true) {
        base = utils.removeBackslashes(base)
      }
    }
    const state = {
      prefix,
      input,
      start,
      base,
      glob,
      isBrace,
      isBracket,
      isGlob,
      isExtglob,
      isGlobstar,
      negated,
      negatedExtglob
    }
    if (opts.tokens === true) {
      state.maxDepth = 0
      if (!isPathSeparator(code)) {
        tokens.push(token)
      }
      state.tokens = tokens
    }
    if (opts.parts === true || opts.tokens === true) {
      let prevIndex
      for (let idx = 0; idx < slashes.length; idx++) {
        const n = prevIndex ? prevIndex + 1 : start
        const i = slashes[idx]
        const value = input.slice(n, i)
        if (opts.tokens) {
          if (idx === 0 && start !== 0) {
            tokens[idx].isPrefix = true
            tokens[idx].value = prefix
          } else {
            tokens[idx].value = value
          }
          depth(tokens[idx])
          state.maxDepth += tokens[idx].depth
        }
        if (idx !== 0 || value !== '') {
          parts.push(value)
        }
        prevIndex = i
      }
      if (prevIndex && prevIndex + 1 < input.length) {
        const value = input.slice(prevIndex + 1)
        parts.push(value)
        if (opts.tokens) {
          tokens[tokens.length - 1].value = value
          depth(tokens[tokens.length - 1])
          state.maxDepth += tokens[tokens.length - 1].depth
        }
      }
      state.slashes = slashes
      state.parts = parts
    }
    return state
  }
  scan_1$1 = scan
  return scan_1$1
}

let parse_1$4
let hasRequiredParse$4
function requireParse$4() {
  if (hasRequiredParse$4) {
    return parse_1$4
  }
  hasRequiredParse$4 = 1
  const constants = requireConstants$3()
  const utils = requireUtils$2()

  /**
   * Constants
   */

  const {
    MAX_LENGTH,
    POSIX_REGEX_SOURCE,
    REGEX_NON_SPECIAL_CHARS,
    REGEX_SPECIAL_CHARS_BACKREF,
    REPLACEMENTS
  } = constants

  /**
   * Helpers
   */

  const expandRange = (args, options) => {
    if (typeof options.expandRange === 'function') {
      return options.expandRange(...args, options)
    }
    args.sort()
    const value = `[${args.join('-')}]`
    try {
      /* eslint-disable-next-line no-new */
      new RegExp(value)
    } catch (ex) {
      return args.map(v => utils.escapeRegex(v)).join('..')
    }
    return value
  }

  /**
   * Create the message for a syntax error
   */

  const syntaxError = (type, char) => {
    return `Missing ${type}: "${char}" - use "\\\\${char}" to match literal characters`
  }

  /**
   * Parse the given input string.
   * @param {String} input
   * @param {Object} options
   * @return {Object}
   */

  const parse = (input, options) => {
    if (typeof input !== 'string') {
      throw new TypeError('Expected a string')
    }
    input = REPLACEMENTS[input] || input
    const opts = {
      ...options
    }
    const max =
      typeof opts.maxLength === 'number'
        ? Math.min(MAX_LENGTH, opts.maxLength)
        : MAX_LENGTH
    let len = input.length
    if (len > max) {
      throw new SyntaxError(
        `Input length: ${len}, exceeds maximum allowed length: ${max}`
      )
    }
    const bos = {
      type: 'bos',
      value: '',
      output: opts.prepend || ''
    }
    const tokens = [bos]
    const capture = opts.capture ? '' : '?:'
    const win32 = utils.isWindows(options)

    // create constants based on platform, for windows or posix
    const PLATFORM_CHARS = constants.globChars(win32)
    const EXTGLOB_CHARS = constants.extglobChars(PLATFORM_CHARS)
    const {
      DOT_LITERAL,
      PLUS_LITERAL,
      SLASH_LITERAL,
      ONE_CHAR,
      DOTS_SLASH,
      NO_DOT,
      NO_DOT_SLASH,
      NO_DOTS_SLASH,
      QMARK,
      QMARK_NO_DOT,
      STAR,
      START_ANCHOR
    } = PLATFORM_CHARS
    const globstar = opts => {
      return `(${capture}(?:(?!${START_ANCHOR}${opts.dot ? DOTS_SLASH : DOT_LITERAL}).)*?)`
    }
    const nodot = opts.dot ? '' : NO_DOT
    const qmarkNoDot = opts.dot ? QMARK : QMARK_NO_DOT
    let star = opts.bash === true ? globstar(opts) : STAR
    if (opts.capture) {
      star = `(${star})`
    }

    // minimatch options support
    if (typeof opts.noext === 'boolean') {
      opts.noextglob = opts.noext
    }
    const state = {
      input,
      index: -1,
      start: 0,
      dot: opts.dot === true,
      consumed: '',
      output: '',
      prefix: '',
      backtrack: false,
      negated: false,
      brackets: 0,
      braces: 0,
      parens: 0,
      quotes: 0,
      globstar: false,
      tokens
    }
    input = utils.removePrefix(input, state)
    len = input.length
    const extglobs = []
    const braces = []
    const stack = []
    let prev = bos
    let value

    /**
     * Tokenizing helpers
     */

    const eos = () => state.index === len - 1
    const peek = (state.peek = (n = 1) => input[state.index + n])
    const advance = (state.advance = () => input[++state.index] || '')
    const remaining = () => input.slice(state.index + 1)
    const consume = (value = '', num = 0) => {
      state.consumed += value
      state.index += num
    }
    const append = token => {
      state.output += token.output != null ? token.output : token.value
      consume(token.value)
    }
    const negate = () => {
      let count = 1
      while (peek() === '!' && (peek(2) !== '(' || peek(3) === '?')) {
        advance()
        state.start++
        count++
      }
      if (count % 2 === 0) {
        return false
      }
      state.negated = true
      state.start++
      return true
    }
    const increment = type => {
      state[type]++
      stack.push(type)
    }
    const decrement = type => {
      state[type]--
      stack.pop()
    }

    /**
     * Push tokens onto the tokens array. This helper speeds up
     * tokenizing by 1) helping us avoid backtracking as much as possible,
     * and 2) helping us avoid creating extra tokens when consecutive
     * characters are plain text. This improves performance and simplifies
     * lookbehinds.
     */

    const push = tok => {
      if (prev.type === 'globstar') {
        const isBrace =
          state.braces > 0 && (tok.type === 'comma' || tok.type === 'brace')
        const isExtglob =
          tok.extglob === true ||
          (extglobs.length && (tok.type === 'pipe' || tok.type === 'paren'))
        if (
          tok.type !== 'slash' &&
          tok.type !== 'paren' &&
          !isBrace &&
          !isExtglob
        ) {
          state.output = state.output.slice(0, -prev.output.length)
          prev.type = 'star'
          prev.value = '*'
          prev.output = star
          state.output += prev.output
        }
      }
      if (extglobs.length && tok.type !== 'paren') {
        extglobs[extglobs.length - 1].inner += tok.value
      }
      if (tok.value || tok.output) {
        append(tok)
      }
      if (prev && prev.type === 'text' && tok.type === 'text') {
        prev.value += tok.value
        prev.output = (prev.output || '') + tok.value
        return
      }
      tok.prev = prev
      tokens.push(tok)
      prev = tok
    }
    const extglobOpen = (type, value) => {
      const token = {
        ...EXTGLOB_CHARS[value],
        conditions: 1,
        inner: ''
      }
      token.prev = prev
      token.parens = state.parens
      token.output = state.output
      const output = (opts.capture ? '(' : '') + token.open
      increment('parens')
      push({
        type,
        value,
        output: state.output ? '' : ONE_CHAR
      })
      push({
        type: 'paren',
        extglob: true,
        value: advance(),
        output
      })
      extglobs.push(token)
    }
    const extglobClose = token => {
      let output = token.close + (opts.capture ? ')' : '')
      let rest
      if (token.type === 'negate') {
        let extglobStar = star
        if (
          token.inner &&
          token.inner.length > 1 &&
          token.inner.includes('/')
        ) {
          extglobStar = globstar(opts)
        }
        if (extglobStar !== star || eos() || /^\)+$/.test(remaining())) {
          output = token.close = `)$))${extglobStar}`
        }
        if (
          token.inner.includes('*') &&
          (rest = remaining()) &&
          /^\.[^\\/.]+$/.test(rest)
        ) {
          // Any non-magical string (`.ts`) or even nested expression (`.{ts,tsx}`) can follow after the closing parenthesis.
          // In this case, we need to parse the string and use it in the output of the original pattern.
          // Suitable patterns: `/!(*.d).ts`, `/!(*.d).{ts,tsx}`, `**/!(*-dbg).@(js)`.
          //
          // Disabling the `fastpaths` option due to a problem with parsing strings as `.ts` in the pattern like `**/!(*.d).ts`.
          const expression = parse(rest, {
            ...options,
            fastpaths: false
          }).output
          output = token.close = `)${expression})${extglobStar})`
        }
        if (token.prev.type === 'bos') {
          state.negatedExtglob = true
        }
      }
      push({
        type: 'paren',
        extglob: true,
        value,
        output
      })
      decrement('parens')
    }

    /**
     * Fast paths
     */

    if (opts.fastpaths !== false && !/(^[*!]|[/()[\]{}"])/.test(input)) {
      let backslashes = false
      let output = input.replace(
        REGEX_SPECIAL_CHARS_BACKREF,
        (m, esc, chars, first, rest, index) => {
          if (first === '\\') {
            backslashes = true
            return m
          }
          if (first === '?') {
            if (esc) {
              return esc + first + (rest ? QMARK.repeat(rest.length) : '')
            }
            if (index === 0) {
              return qmarkNoDot + (rest ? QMARK.repeat(rest.length) : '')
            }
            return QMARK.repeat(chars.length)
          }
          if (first === '.') {
            return DOT_LITERAL.repeat(chars.length)
          }
          if (first === '*') {
            if (esc) {
              return esc + first + (rest ? star : '')
            }
            return star
          }
          return esc ? m : `\\${m}`
        }
      )
      if (backslashes === true) {
        if (opts.unescape === true) {
          output = output.replace(/\\/g, '')
        } else {
          output = output.replace(/\\+/g, m => {
            return m.length % 2 === 0 ? '\\\\' : m ? '\\' : ''
          })
        }
      }
      if (output === input && opts.contains === true) {
        state.output = input
        return state
      }
      state.output = utils.wrapOutput(output, state, options)
      return state
    }

    /**
     * Tokenize input until we reach end-of-string
     */

    while (!eos()) {
      value = advance()
      if (value === '\u0000') {
        continue
      }

      /**
       * Escaped characters
       */

      if (value === '\\') {
        const next = peek()
        if (next === '/' && opts.bash !== true) {
          continue
        }
        if (next === '.' || next === ';') {
          continue
        }
        if (!next) {
          value += '\\'
          push({
            type: 'text',
            value
          })
          continue
        }

        // collapse slashes to reduce potential for exploits
        const match = /^\\+/.exec(remaining())
        let slashes = 0
        if (match && match[0].length > 2) {
          slashes = match[0].length
          state.index += slashes
          if (slashes % 2 !== 0) {
            value += '\\'
          }
        }
        if (opts.unescape === true) {
          value = advance()
        } else {
          value += advance()
        }
        if (state.brackets === 0) {
          push({
            type: 'text',
            value
          })
          continue
        }
      }

      /**
       * If we're inside a regex character class, continue
       * until we reach the closing bracket.
       */

      if (
        state.brackets > 0 &&
        (value !== ']' || prev.value === '[' || prev.value === '[^')
      ) {
        if (opts.posix !== false && value === ':') {
          const inner = new Set(prev.value.slice(1))
          if (inner.has('[')) {
            prev.posix = true
            if (inner.has(':')) {
              const idx = prev.value.lastIndexOf('[')
              const pre = prev.value.slice(0, idx)
              const rest = prev.value.slice(idx + 2)
              const posix = POSIX_REGEX_SOURCE[rest]
              if (posix) {
                prev.value = pre + posix
                state.backtrack = true
                advance()
                if (!bos.output && tokens.indexOf(prev) === 1) {
                  bos.output = ONE_CHAR
                }
                continue
              }
            }
          }
        }
        if (
          (value === '[' && peek() !== ':') ||
          (value === '-' && peek() === ']')
        ) {
          value = `\\${value}`
        }
        if (value === ']' && (prev.value === '[' || prev.value === '[^')) {
          value = `\\${value}`
        }
        if (opts.posix === true && value === '!' && prev.value === '[') {
          value = '^'
        }
        prev.value += value
        append({
          value
        })
        continue
      }

      /**
       * If we're inside a quoted string, continue
       * until we reach the closing double quote.
       */

      if (state.quotes === 1 && value !== '"') {
        value = utils.escapeRegex(value)
        prev.value += value
        append({
          value
        })
        continue
      }

      /**
       * Double quotes
       */

      if (value === '"') {
        state.quotes = state.quotes === 1 ? 0 : 1
        if (opts.keepQuotes === true) {
          push({
            type: 'text',
            value
          })
        }
        continue
      }

      /**
       * Parentheses
       */

      if (value === '(') {
        increment('parens')
        push({
          type: 'paren',
          value
        })
        continue
      }
      if (value === ')') {
        if (state.parens === 0 && opts.strictBrackets === true) {
          throw new SyntaxError(syntaxError('opening', '('))
        }
        const extglob = extglobs[extglobs.length - 1]
        if (extglob && state.parens === extglob.parens + 1) {
          extglobClose(extglobs.pop())
          continue
        }
        push({
          type: 'paren',
          value,
          output: state.parens ? ')' : '\\)'
        })
        decrement('parens')
        continue
      }

      /**
       * Square brackets
       */

      if (value === '[') {
        if (opts.nobracket === true || !remaining().includes(']')) {
          if (opts.nobracket !== true && opts.strictBrackets === true) {
            throw new SyntaxError(syntaxError('closing', ']'))
          }
          value = `\\${value}`
        } else {
          increment('brackets')
        }
        push({
          type: 'bracket',
          value
        })
        continue
      }
      if (value === ']') {
        if (
          opts.nobracket === true ||
          (prev && prev.type === 'bracket' && prev.value.length === 1)
        ) {
          push({
            type: 'text',
            value,
            output: `\\${value}`
          })
          continue
        }
        if (state.brackets === 0) {
          if (opts.strictBrackets === true) {
            throw new SyntaxError(syntaxError('opening', '['))
          }
          push({
            type: 'text',
            value,
            output: `\\${value}`
          })
          continue
        }
        decrement('brackets')
        const prevValue = prev.value.slice(1)
        if (
          prev.posix !== true &&
          prevValue[0] === '^' &&
          !prevValue.includes('/')
        ) {
          value = `/${value}`
        }
        prev.value += value
        append({
          value
        })

        // when literal brackets are explicitly disabled
        // assume we should match with a regex character class
        if (opts.literalBrackets === false || utils.hasRegexChars(prevValue)) {
          continue
        }
        const escaped = utils.escapeRegex(prev.value)
        state.output = state.output.slice(0, -prev.value.length)

        // when literal brackets are explicitly enabled
        // assume we should escape the brackets to match literal characters
        if (opts.literalBrackets === true) {
          state.output += escaped
          prev.value = escaped
          continue
        }

        // when the user specifies nothing, try to match both
        prev.value = `(${capture}${escaped}|${prev.value})`
        state.output += prev.value
        continue
      }

      /**
       * Braces
       */

      if (value === '{' && opts.nobrace !== true) {
        increment('braces')
        const open = {
          type: 'brace',
          value,
          output: '(',
          outputIndex: state.output.length,
          tokensIndex: state.tokens.length
        }
        braces.push(open)
        push(open)
        continue
      }
      if (value === '}') {
        const brace = braces[braces.length - 1]
        if (opts.nobrace === true || !brace) {
          push({
            type: 'text',
            value,
            output: value
          })
          continue
        }
        let output = ')'
        if (brace.dots === true) {
          const arr = tokens.slice()
          const range = []
          for (let i = arr.length - 1; i >= 0; i--) {
            tokens.pop()
            if (arr[i].type === 'brace') {
              break
            }
            if (arr[i].type !== 'dots') {
              range.unshift(arr[i].value)
            }
          }
          output = expandRange(range, opts)
          state.backtrack = true
        }
        if (brace.comma !== true && brace.dots !== true) {
          const out = state.output.slice(0, brace.outputIndex)
          const toks = state.tokens.slice(brace.tokensIndex)
          brace.value = brace.output = '\\{'
          value = output = '\\}'
          state.output = out
          for (const t of toks) {
            state.output += t.output || t.value
          }
        }
        push({
          type: 'brace',
          value,
          output
        })
        decrement('braces')
        braces.pop()
        continue
      }

      /**
       * Pipes
       */

      if (value === '|') {
        if (extglobs.length > 0) {
          extglobs[extglobs.length - 1].conditions++
        }
        push({
          type: 'text',
          value
        })
        continue
      }

      /**
       * Commas
       */

      if (value === ',') {
        let output = value
        const brace = braces[braces.length - 1]
        if (brace && stack[stack.length - 1] === 'braces') {
          brace.comma = true
          output = '|'
        }
        push({
          type: 'comma',
          value,
          output
        })
        continue
      }

      /**
       * Slashes
       */

      if (value === '/') {
        // if the beginning of the glob is "./", advance the start
        // to the current index, and don't add the "./" characters
        // to the state. This greatly simplifies lookbehinds when
        // checking for BOS characters like "!" and "." (not "./")
        if (prev.type === 'dot' && state.index === state.start + 1) {
          state.start = state.index + 1
          state.consumed = ''
          state.output = ''
          tokens.pop()
          prev = bos // reset "prev" to the first token
          continue
        }
        push({
          type: 'slash',
          value,
          output: SLASH_LITERAL
        })
        continue
      }

      /**
       * Dots
       */

      if (value === '.') {
        if (state.braces > 0 && prev.type === 'dot') {
          if (prev.value === '.') {
            prev.output = DOT_LITERAL
          }
          const brace = braces[braces.length - 1]
          prev.type = 'dots'
          prev.output += value
          prev.value += value
          brace.dots = true
          continue
        }
        if (
          state.braces + state.parens === 0 &&
          prev.type !== 'bos' &&
          prev.type !== 'slash'
        ) {
          push({
            type: 'text',
            value,
            output: DOT_LITERAL
          })
          continue
        }
        push({
          type: 'dot',
          value,
          output: DOT_LITERAL
        })
        continue
      }

      /**
       * Question marks
       */

      if (value === '?') {
        const isGroup = prev && prev.value === '('
        if (
          !isGroup &&
          opts.noextglob !== true &&
          peek() === '(' &&
          peek(2) !== '?'
        ) {
          extglobOpen('qmark', value)
          continue
        }
        if (prev && prev.type === 'paren') {
          const next = peek()
          let output = value
          if (next === '<' && !utils.supportsLookbehinds()) {
            throw new Error(
              'Node.js v10 or higher is required for regex lookbehinds'
            )
          }
          if (
            (prev.value === '(' && !/[!=<:]/.test(next)) ||
            (next === '<' && !/<([!=]|\w+>)/.test(remaining()))
          ) {
            output = `\\${value}`
          }
          push({
            type: 'text',
            value,
            output
          })
          continue
        }
        if (
          opts.dot !== true &&
          (prev.type === 'slash' || prev.type === 'bos')
        ) {
          push({
            type: 'qmark',
            value,
            output: QMARK_NO_DOT
          })
          continue
        }
        push({
          type: 'qmark',
          value,
          output: QMARK
        })
        continue
      }

      /**
       * Exclamation
       */

      if (value === '!') {
        if (opts.noextglob !== true && peek() === '(') {
          if (peek(2) !== '?' || !/[!=<:]/.test(peek(3))) {
            extglobOpen('negate', value)
            continue
          }
        }
        if (opts.nonegate !== true && state.index === 0) {
          negate()
          continue
        }
      }

      /**
       * Plus
       */

      if (value === '+') {
        if (opts.noextglob !== true && peek() === '(' && peek(2) !== '?') {
          extglobOpen('plus', value)
          continue
        }
        if ((prev && prev.value === '(') || opts.regex === false) {
          push({
            type: 'plus',
            value,
            output: PLUS_LITERAL
          })
          continue
        }
        if (
          (prev &&
            (prev.type === 'bracket' ||
              prev.type === 'paren' ||
              prev.type === 'brace')) ||
          state.parens > 0
        ) {
          push({
            type: 'plus',
            value
          })
          continue
        }
        push({
          type: 'plus',
          value: PLUS_LITERAL
        })
        continue
      }

      /**
       * Plain text
       */

      if (value === '@') {
        if (opts.noextglob !== true && peek() === '(' && peek(2) !== '?') {
          push({
            type: 'at',
            extglob: true,
            value,
            output: ''
          })
          continue
        }
        push({
          type: 'text',
          value
        })
        continue
      }

      /**
       * Plain text
       */

      if (value !== '*') {
        if (value === '$' || value === '^') {
          value = `\\${value}`
        }
        const match = REGEX_NON_SPECIAL_CHARS.exec(remaining())
        if (match) {
          value += match[0]
          state.index += match[0].length
        }
        push({
          type: 'text',
          value
        })
        continue
      }

      /**
       * Stars
       */

      if (prev && (prev.type === 'globstar' || prev.star === true)) {
        prev.type = 'star'
        prev.star = true
        prev.value += value
        prev.output = star
        state.backtrack = true
        state.globstar = true
        consume(value)
        continue
      }
      let rest = remaining()
      if (opts.noextglob !== true && /^\([^?]/.test(rest)) {
        extglobOpen('star', value)
        continue
      }
      if (prev.type === 'star') {
        if (opts.noglobstar === true) {
          consume(value)
          continue
        }
        const prior = prev.prev
        const before = prior.prev
        const isStart = prior.type === 'slash' || prior.type === 'bos'
        const afterStar =
          before && (before.type === 'star' || before.type === 'globstar')
        if (opts.bash === true && (!isStart || (rest[0] && rest[0] !== '/'))) {
          push({
            type: 'star',
            value,
            output: ''
          })
          continue
        }
        const isBrace =
          state.braces > 0 && (prior.type === 'comma' || prior.type === 'brace')
        const isExtglob =
          extglobs.length && (prior.type === 'pipe' || prior.type === 'paren')
        if (!isStart && prior.type !== 'paren' && !isBrace && !isExtglob) {
          push({
            type: 'star',
            value,
            output: ''
          })
          continue
        }

        // strip consecutive `/**/`
        while (rest.slice(0, 3) === '/**') {
          const after = input[state.index + 4]
          if (after && after !== '/') {
            break
          }
          rest = rest.slice(3)
          consume('/**', 3)
        }
        if (prior.type === 'bos' && eos()) {
          prev.type = 'globstar'
          prev.value += value
          prev.output = globstar(opts)
          state.output = prev.output
          state.globstar = true
          consume(value)
          continue
        }
        if (
          prior.type === 'slash' &&
          prior.prev.type !== 'bos' &&
          !afterStar &&
          eos()
        ) {
          state.output = state.output.slice(
            0,
            -(prior.output + prev.output).length
          )
          prior.output = `(?:${prior.output}`
          prev.type = 'globstar'
          prev.output = globstar(opts) + (opts.strictSlashes ? ')' : '|$)')
          prev.value += value
          state.globstar = true
          state.output += prior.output + prev.output
          consume(value)
          continue
        }
        if (
          prior.type === 'slash' &&
          prior.prev.type !== 'bos' &&
          rest[0] === '/'
        ) {
          const end = rest[1] !== void 0 ? '|$' : ''
          state.output = state.output.slice(
            0,
            -(prior.output + prev.output).length
          )
          prior.output = `(?:${prior.output}`
          prev.type = 'globstar'
          prev.output = `${globstar(opts)}${SLASH_LITERAL}|${SLASH_LITERAL}${end})`
          prev.value += value
          state.output += prior.output + prev.output
          state.globstar = true
          consume(value + advance())
          push({
            type: 'slash',
            value: '/',
            output: ''
          })
          continue
        }
        if (prior.type === 'bos' && rest[0] === '/') {
          prev.type = 'globstar'
          prev.value += value
          prev.output = `(?:^|${SLASH_LITERAL}|${globstar(opts)}${SLASH_LITERAL})`
          state.output = prev.output
          state.globstar = true
          consume(value + advance())
          push({
            type: 'slash',
            value: '/',
            output: ''
          })
          continue
        }

        // remove single star from output
        state.output = state.output.slice(0, -prev.output.length)

        // reset previous token to globstar
        prev.type = 'globstar'
        prev.output = globstar(opts)
        prev.value += value

        // reset output with globstar
        state.output += prev.output
        state.globstar = true
        consume(value)
        continue
      }
      const token = {
        type: 'star',
        value,
        output: star
      }
      if (opts.bash === true) {
        token.output = '.*?'
        if (prev.type === 'bos' || prev.type === 'slash') {
          token.output = nodot + token.output
        }
        push(token)
        continue
      }
      if (
        prev &&
        (prev.type === 'bracket' || prev.type === 'paren') &&
        opts.regex === true
      ) {
        token.output = value
        push(token)
        continue
      }
      if (
        state.index === state.start ||
        prev.type === 'slash' ||
        prev.type === 'dot'
      ) {
        if (prev.type === 'dot') {
          state.output += NO_DOT_SLASH
          prev.output += NO_DOT_SLASH
        } else if (opts.dot === true) {
          state.output += NO_DOTS_SLASH
          prev.output += NO_DOTS_SLASH
        } else {
          state.output += nodot
          prev.output += nodot
        }
        if (peek() !== '*') {
          state.output += ONE_CHAR
          prev.output += ONE_CHAR
        }
      }
      push(token)
    }
    while (state.brackets > 0) {
      if (opts.strictBrackets === true) {
        throw new SyntaxError(syntaxError('closing', ']'))
      }
      state.output = utils.escapeLast(state.output, '[')
      decrement('brackets')
    }
    while (state.parens > 0) {
      if (opts.strictBrackets === true) {
        throw new SyntaxError(syntaxError('closing', ')'))
      }
      state.output = utils.escapeLast(state.output, '(')
      decrement('parens')
    }
    while (state.braces > 0) {
      if (opts.strictBrackets === true) {
        throw new SyntaxError(syntaxError('closing', '}'))
      }
      state.output = utils.escapeLast(state.output, '{')
      decrement('braces')
    }
    if (
      opts.strictSlashes !== true &&
      (prev.type === 'star' || prev.type === 'bracket')
    ) {
      push({
        type: 'maybe_slash',
        value: '',
        output: `${SLASH_LITERAL}?`
      })
    }

    // rebuild the output if we had to backtrack at any point
    if (state.backtrack === true) {
      state.output = ''
      for (const token of state.tokens) {
        state.output += token.output != null ? token.output : token.value
        if (token.suffix) {
          state.output += token.suffix
        }
      }
    }
    return state
  }

  /**
   * Fast paths for creating regular expressions for common glob patterns.
   * This can significantly speed up processing and has very little downside
   * impact when none of the fast paths match.
   */

  parse.fastpaths = (input, options) => {
    const opts = {
      ...options
    }
    const max =
      typeof opts.maxLength === 'number'
        ? Math.min(MAX_LENGTH, opts.maxLength)
        : MAX_LENGTH
    const len = input.length
    if (len > max) {
      throw new SyntaxError(
        `Input length: ${len}, exceeds maximum allowed length: ${max}`
      )
    }
    input = REPLACEMENTS[input] || input
    const win32 = utils.isWindows(options)

    // create constants based on platform, for windows or posix
    const {
      DOT_LITERAL,
      SLASH_LITERAL,
      ONE_CHAR,
      DOTS_SLASH,
      NO_DOT,
      NO_DOTS,
      NO_DOTS_SLASH,
      STAR,
      START_ANCHOR
    } = constants.globChars(win32)
    const nodot = opts.dot ? NO_DOTS : NO_DOT
    const slashDot = opts.dot ? NO_DOTS_SLASH : NO_DOT
    const capture = opts.capture ? '' : '?:'
    const state = {
      negated: false,
      prefix: ''
    }
    let star = opts.bash === true ? '.*?' : STAR
    if (opts.capture) {
      star = `(${star})`
    }
    const globstar = opts => {
      if (opts.noglobstar === true) {
        return star
      }
      return `(${capture}(?:(?!${START_ANCHOR}${opts.dot ? DOTS_SLASH : DOT_LITERAL}).)*?)`
    }
    const create = str => {
      switch (str) {
        case '*':
          return `${nodot}${ONE_CHAR}${star}`
        case '.*':
          return `${DOT_LITERAL}${ONE_CHAR}${star}`
        case '*.*':
          return `${nodot}${star}${DOT_LITERAL}${ONE_CHAR}${star}`
        case '*/*':
          return `${nodot}${star}${SLASH_LITERAL}${ONE_CHAR}${slashDot}${star}`
        case '**':
          return nodot + globstar(opts)
        case '**/*':
          return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${slashDot}${ONE_CHAR}${star}`
        case '**/*.*':
          return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${slashDot}${star}${DOT_LITERAL}${ONE_CHAR}${star}`
        case '**/.*':
          return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${DOT_LITERAL}${ONE_CHAR}${star}`
        default: {
          const match = /^(.*?)\.(\w+)$/.exec(str)
          if (!match) {
            return
          }
          const source = create(match[1])
          if (!source) {
            return
          }
          return source + DOT_LITERAL + match[2]
        }
      }
    }
    const output = utils.removePrefix(input, state)
    let source = create(output)
    if (source && opts.strictSlashes !== true) {
      source += `${SLASH_LITERAL}?`
    }
    return source
  }
  parse_1$4 = parse
  return parse_1$4
}

let picomatch_1$2
let hasRequiredPicomatch$3
function requirePicomatch$3() {
  if (hasRequiredPicomatch$3) {
    return picomatch_1$2
  }
  hasRequiredPicomatch$3 = 1
  const path = require$$0$5
  const scan = requireScan$1()
  const parse = requireParse$4()
  const utils = requireUtils$2()
  const constants = requireConstants$3()
  const isObject = val => val && typeof val === 'object' && !Array.isArray(val)

  /**
   * Creates a matcher function from one or more glob patterns. The
   * returned function takes a string to match as its first argument,
   * and returns true if the string is a match. The returned matcher
   * function also takes a boolean as the second argument that, when true,
   * returns an object with additional information.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch(glob[, options]);
   *
   * const isMatch = picomatch('*.!(*a)');
   * console.log(isMatch('a.a')); //=> false
   * console.log(isMatch('a.b')); //=> true
   * ```
   * @name picomatch
   * @param {String|Array} `globs` One or more glob patterns.
   * @param {Object=} `options`
   * @return {Function=} Returns a matcher function.
   * @api public
   */

  const picomatch = (glob, options, returnState = false) => {
    if (Array.isArray(glob)) {
      const fns = glob.map(input => picomatch(input, options, returnState))
      const arrayMatcher = str => {
        for (const isMatch of fns) {
          const state = isMatch(str)
          if (state) {
            return state
          }
        }
        return false
      }
      return arrayMatcher
    }
    const isState = isObject(glob) && glob.tokens && glob.input
    if (glob === '' || (typeof glob !== 'string' && !isState)) {
      throw new TypeError('Expected pattern to be a non-empty string')
    }
    const opts = options || {}
    const posix = utils.isWindows(options)
    const regex = isState
      ? picomatch.compileRe(glob, options)
      : picomatch.makeRe(glob, options, false, true)
    const state = regex.state
    delete regex.state
    let isIgnored = () => false
    if (opts.ignore) {
      const ignoreOpts = {
        ...options,
        ignore: null,
        onMatch: null,
        onResult: null
      }
      isIgnored = picomatch(opts.ignore, ignoreOpts, returnState)
    }
    const matcher = (input, returnObject = false) => {
      const { isMatch, match, output } = picomatch.test(input, regex, options, {
        glob,
        posix
      })
      const result = {
        glob,
        state,
        regex,
        posix,
        input,
        output,
        match,
        isMatch
      }
      if (typeof opts.onResult === 'function') {
        opts.onResult(result)
      }
      if (isMatch === false) {
        result.isMatch = false
        return returnObject ? result : false
      }
      if (isIgnored(input)) {
        if (typeof opts.onIgnore === 'function') {
          opts.onIgnore(result)
        }
        result.isMatch = false
        return returnObject ? result : false
      }
      if (typeof opts.onMatch === 'function') {
        opts.onMatch(result)
      }
      return returnObject ? result : true
    }
    if (returnState) {
      matcher.state = state
    }
    return matcher
  }

  /**
   * Test `input` with the given `regex`. This is used by the main
   * `picomatch()` function to test the input string.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch.test(input, regex[, options]);
   *
   * console.log(picomatch.test('foo/bar', /^(?:([^/]*?)\/([^/]*?))$/));
   * // { isMatch: true, match: [ 'foo/', 'foo', 'bar' ], output: 'foo/bar' }
   * ```
   * @param {String} `input` String to test.
   * @param {RegExp} `regex`
   * @return {Object} Returns an object with matching info.
   * @api public
   */

  picomatch.test = (input, regex, options, { glob, posix } = {}) => {
    if (typeof input !== 'string') {
      throw new TypeError('Expected input to be a string')
    }
    if (input === '') {
      return {
        isMatch: false,
        output: ''
      }
    }
    const opts = options || {}
    const format = opts.format || (posix ? utils.toPosixSlashes : null)
    let match = input === glob
    let output = match && format ? format(input) : input
    if (match === false) {
      output = format ? format(input) : input
      match = output === glob
    }
    if (match === false || opts.capture === true) {
      if (opts.matchBase === true || opts.basename === true) {
        match = picomatch.matchBase(input, regex, options, posix)
      } else {
        match = regex.exec(output)
      }
    }
    return {
      isMatch: Boolean(match),
      match,
      output
    }
  }

  /**
   * Match the basename of a filepath.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch.matchBase(input, glob[, options]);
   * console.log(picomatch.matchBase('foo/bar.js', '*.js'); // true
   * ```
   * @param {String} `input` String to test.
   * @param {RegExp|String} `glob` Glob pattern or regex created by [.makeRe](#makeRe).
   * @return {Boolean}
   * @api public
   */

  picomatch.matchBase = (
    input,
    glob,
    options,
    posix = utils.isWindows(options)
  ) => {
    const regex =
      glob instanceof RegExp ? glob : picomatch.makeRe(glob, options)
    return regex.test(path.basename(input))
  }

  /**
   * Returns true if **any** of the given glob `patterns` match the specified `string`.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch.isMatch(string, patterns[, options]);
   *
   * console.log(picomatch.isMatch('a.a', ['b.*', '*.a'])); //=> true
   * console.log(picomatch.isMatch('a.a', 'b.*')); //=> false
   * ```
   * @param {String|Array} str The string to test.
   * @param {String|Array} patterns One or more glob patterns to use for matching.
   * @param {Object} [options] See available [options](#options).
   * @return {Boolean} Returns true if any patterns match `str`
   * @api public
   */

  picomatch.isMatch = (str, patterns, options) =>
    picomatch(patterns, options)(str)

  /**
   * Parse a glob pattern to create the source string for a regular
   * expression.
   *
   * ```js
   * const picomatch = require('picomatch');
   * const result = picomatch.parse(pattern[, options]);
   * ```
   * @param {String} `pattern`
   * @param {Object} `options`
   * @return {Object} Returns an object with useful properties and output to be used as a regex source string.
   * @api public
   */

  picomatch.parse = (pattern, options) => {
    if (Array.isArray(pattern)) {
      return pattern.map(p => picomatch.parse(p, options))
    }
    return parse(pattern, {
      ...options,
      fastpaths: false
    })
  }

  /**
   * Scan a glob pattern to separate the pattern into segments.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch.scan(input[, options]);
   *
   * const result = picomatch.scan('!./foo/*.js');
   * console.log(result);
   * { prefix: '!./',
   *   input: '!./foo/*.js',
   *   start: 3,
   *   base: 'foo',
   *   glob: '*.js',
   *   isBrace: false,
   *   isBracket: false,
   *   isGlob: true,
   *   isExtglob: false,
   *   isGlobstar: false,
   *   negated: true }
   * ```
   * @param {String} `input` Glob pattern to scan.
   * @param {Object} `options`
   * @return {Object} Returns an object with
   * @api public
   */

  picomatch.scan = (input, options) => scan(input, options)

  /**
   * Compile a regular expression from the `state` object returned by the
   * [parse()](#parse) method.
   *
   * @param {Object} `state`
   * @param {Object} `options`
   * @param {Boolean} `returnOutput` Intended for implementors, this argument allows you to return the raw output from the parser.
   * @param {Boolean} `returnState` Adds the state to a `state` property on the returned regex. Useful for implementors and debugging.
   * @return {RegExp}
   * @api public
   */

  picomatch.compileRe = (
    state,
    options,
    returnOutput = false,
    returnState = false
  ) => {
    if (returnOutput === true) {
      return state.output
    }
    const opts = options || {}
    const prepend = opts.contains ? '' : '^'
    const append = opts.contains ? '' : '$'
    let source = `${prepend}(?:${state.output})${append}`
    if (state && state.negated === true) {
      source = `^(?!${source}).*$`
    }
    const regex = picomatch.toRegex(source, options)
    if (returnState === true) {
      regex.state = state
    }
    return regex
  }

  /**
   * Create a regular expression from a parsed glob pattern.
   *
   * ```js
   * const picomatch = require('picomatch');
   * const state = picomatch.parse('*.js');
   * // picomatch.compileRe(state[, options]);
   *
   * console.log(picomatch.compileRe(state));
   * //=> /^(?:(?!\.)(?=.)[^/]*?\.js)$/
   * ```
   * @param {String} `state` The object returned from the `.parse` method.
   * @param {Object} `options`
   * @param {Boolean} `returnOutput` Implementors may use this argument to return the compiled output, instead of a regular expression. This is not exposed on the options to prevent end-users from mutating the result.
   * @param {Boolean} `returnState` Implementors may use this argument to return the state from the parsed glob with the returned regular expression.
   * @return {RegExp} Returns a regex created from the given pattern.
   * @api public
   */

  picomatch.makeRe = (
    input,
    options = {},
    returnOutput = false,
    returnState = false
  ) => {
    if (!input || typeof input !== 'string') {
      throw new TypeError('Expected a non-empty string')
    }
    let parsed = {
      negated: false,
      fastpaths: true
    }
    if (options.fastpaths !== false && (input[0] === '.' || input[0] === '*')) {
      parsed.output = parse.fastpaths(input, options)
    }
    if (!parsed.output) {
      parsed = parse(input, options)
    }
    return picomatch.compileRe(parsed, options, returnOutput, returnState)
  }

  /**
   * Create a regular expression from the given regex source string.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch.toRegex(source[, options]);
   *
   * const { output } = picomatch.parse('*.js');
   * console.log(picomatch.toRegex(output));
   * //=> /^(?:(?!\.)(?=.)[^/]*?\.js)$/
   * ```
   * @param {String} `source` Regular expression source string.
   * @param {Object} `options`
   * @return {RegExp}
   * @api public
   */

  picomatch.toRegex = (source, options) => {
    try {
      const opts = options || {}
      return new RegExp(source, opts.flags || (opts.nocase ? 'i' : ''))
    } catch (err) {
      if (options && options.debug === true) {
        throw err
      }
      return /$^/
    }
  }

  /**
   * Picomatch constants.
   * @return {Object}
   */

  picomatch.constants = constants

  /**
   * Expose "picomatch"
   */

  picomatch_1$2 = picomatch
  return picomatch_1$2
}

let picomatch
let hasRequiredPicomatch$2
function requirePicomatch$2() {
  if (hasRequiredPicomatch$2) {
    return picomatch
  }
  hasRequiredPicomatch$2 = 1
  picomatch = requirePicomatch$3()
  return picomatch
}

let micromatch_1
let hasRequiredMicromatch
function requireMicromatch() {
  if (hasRequiredMicromatch) {
    return micromatch_1
  }
  hasRequiredMicromatch = 1
  const util = require$$0$4
  const braces = requireBraces()
  const picomatch = requirePicomatch$2()
  const utils = requireUtils$2()
  const isEmptyString = v => v === '' || v === './'
  const hasBraces = v => {
    const index = v.indexOf('{')
    return index > -1 && v.indexOf('}', index) > -1
  }

  /**
   * Returns an array of strings that match one or more glob patterns.
   *
   * ```js
   * const mm = require('micromatch');
   * // mm(list, patterns[, options]);
   *
   * console.log(mm(['a.js', 'a.txt'], ['*.js']));
   * //=> [ 'a.js' ]
   * ```
   * @param {String|Array<string>} `list` List of strings to match.
   * @param {String|Array<string>} `patterns` One or more glob patterns to use for matching.
   * @param {Object} `options` See available [options](#options)
   * @return {Array} Returns an array of matches
   * @summary false
   * @api public
   */

  const micromatch = (list, patterns, options) => {
    patterns = [].concat(patterns)
    list = [].concat(list)
    let omit = new Set()
    let keep = new Set()
    let items = new Set()
    let negatives = 0
    let onResult = state => {
      items.add(state.output)
      if (options && options.onResult) {
        options.onResult(state)
      }
    }
    for (let i = 0; i < patterns.length; i++) {
      let isMatch = picomatch(
        String(patterns[i]),
        {
          ...options,
          onResult
        },
        true
      )
      let negated = isMatch.state.negated || isMatch.state.negatedExtglob
      if (negated) {
        negatives++
      }
      for (let item of list) {
        let matched = isMatch(item, true)
        let match = negated ? !matched.isMatch : matched.isMatch
        if (!match) {
          continue
        }
        if (negated) {
          omit.add(matched.output)
        } else {
          omit.delete(matched.output)
          keep.add(matched.output)
        }
      }
    }
    let result = negatives === patterns.length ? [...items] : [...keep]
    let matches = result.filter(item => !omit.has(item))
    if (options && matches.length === 0) {
      if (options.failglob === true) {
        throw new Error(`No matches found for "${patterns.join(', ')}"`)
      }
      if (options.nonull === true || options.nullglob === true) {
        return options.unescape
          ? patterns.map(p => p.replace(/\\/g, ''))
          : patterns
      }
    }
    return matches
  }

  /**
   * Backwards compatibility
   */

  micromatch.match = micromatch

  /**
   * Returns a matcher function from the given glob `pattern` and `options`.
   * The returned function takes a string to match as its only argument and returns
   * true if the string is a match.
   *
   * ```js
   * const mm = require('micromatch');
   * // mm.matcher(pattern[, options]);
   *
   * const isMatch = mm.matcher('*.!(*a)');
   * console.log(isMatch('a.a')); //=> false
   * console.log(isMatch('a.b')); //=> true
   * ```
   * @param {String} `pattern` Glob pattern
   * @param {Object} `options`
   * @return {Function} Returns a matcher function.
   * @api public
   */

  micromatch.matcher = (pattern, options) => picomatch(pattern, options)

  /**
   * Returns true if **any** of the given glob `patterns` match the specified `string`.
   *
   * ```js
   * const mm = require('micromatch');
   * // mm.isMatch(string, patterns[, options]);
   *
   * console.log(mm.isMatch('a.a', ['b.*', '*.a'])); //=> true
   * console.log(mm.isMatch('a.a', 'b.*')); //=> false
   * ```
   * @param {String} `str` The string to test.
   * @param {String|Array} `patterns` One or more glob patterns to use for matching.
   * @param {Object} `[options]` See available [options](#options).
   * @return {Boolean} Returns true if any patterns match `str`
   * @api public
   */

  micromatch.isMatch = (str, patterns, options) =>
    picomatch(patterns, options)(str)

  /**
   * Backwards compatibility
   */

  micromatch.any = micromatch.isMatch

  /**
   * Returns a list of strings that _**do not match any**_ of the given `patterns`.
   *
   * ```js
   * const mm = require('micromatch');
   * // mm.not(list, patterns[, options]);
   *
   * console.log(mm.not(['a.a', 'b.b', 'c.c'], '*.a'));
   * //=> ['b.b', 'c.c']
   * ```
   * @param {Array} `list` Array of strings to match.
   * @param {String|Array} `patterns` One or more glob pattern to use for matching.
   * @param {Object} `options` See available [options](#options) for changing how matches are performed
   * @return {Array} Returns an array of strings that **do not match** the given patterns.
   * @api public
   */

  micromatch.not = (list, patterns, options = {}) => {
    patterns = [].concat(patterns).map(String)
    let result = new Set()
    let items = []
    let onResult = state => {
      if (options.onResult) {
        options.onResult(state)
      }
      items.push(state.output)
    }
    let matches = new Set(
      micromatch(list, patterns, {
        ...options,
        onResult
      })
    )
    for (let item of items) {
      if (!matches.has(item)) {
        result.add(item)
      }
    }
    return [...result]
  }

  /**
   * Returns true if the given `string` contains the given pattern. Similar
   * to [.isMatch](#isMatch) but the pattern can match any part of the string.
   *
   * ```js
   * var mm = require('micromatch');
   * // mm.contains(string, pattern[, options]);
   *
   * console.log(mm.contains('aa/bb/cc', '*b'));
   * //=> true
   * console.log(mm.contains('aa/bb/cc', '*d'));
   * //=> false
   * ```
   * @param {String} `str` The string to match.
   * @param {String|Array} `patterns` Glob pattern to use for matching.
   * @param {Object} `options` See available [options](#options) for changing how matches are performed
   * @return {Boolean} Returns true if any of the patterns matches any part of `str`.
   * @api public
   */

  micromatch.contains = (str, pattern, options) => {
    if (typeof str !== 'string') {
      throw new TypeError(`Expected a string: "${util.inspect(str)}"`)
    }
    if (Array.isArray(pattern)) {
      return pattern.some(p => micromatch.contains(str, p, options))
    }
    if (typeof pattern === 'string') {
      if (isEmptyString(str) || isEmptyString(pattern)) {
        return false
      }
      if (
        str.includes(pattern) ||
        (str.startsWith('./') && str.slice(2).includes(pattern))
      ) {
        return true
      }
    }
    return micromatch.isMatch(str, pattern, {
      ...options,
      contains: true
    })
  }

  /**
   * Filter the keys of the given object with the given `glob` pattern
   * and `options`. Does not attempt to match nested keys. If you need this feature,
   * use [glob-object][] instead.
   *
   * ```js
   * const mm = require('micromatch');
   * // mm.matchKeys(object, patterns[, options]);
   *
   * const obj = { aa: 'a', ab: 'b', ac: 'c' };
   * console.log(mm.matchKeys(obj, '*b'));
   * //=> { ab: 'b' }
   * ```
   * @param {Object} `object` The object with keys to filter.
   * @param {String|Array} `patterns` One or more glob patterns to use for matching.
   * @param {Object} `options` See available [options](#options) for changing how matches are performed
   * @return {Object} Returns an object with only keys that match the given patterns.
   * @api public
   */

  micromatch.matchKeys = (obj, patterns, options) => {
    if (!utils.isObject(obj)) {
      throw new TypeError('Expected the first argument to be an object')
    }
    let keys = micromatch(Object.keys(obj), patterns, options)
    let res = {}
    for (let key of keys) {
      res[key] = obj[key]
    }
    return res
  }

  /**
   * Returns true if some of the strings in the given `list` match any of the given glob `patterns`.
   *
   * ```js
   * const mm = require('micromatch');
   * // mm.some(list, patterns[, options]);
   *
   * console.log(mm.some(['foo.js', 'bar.js'], ['*.js', '!foo.js']));
   * // true
   * console.log(mm.some(['foo.js'], ['*.js', '!foo.js']));
   * // false
   * ```
   * @param {String|Array} `list` The string or array of strings to test. Returns as soon as the first match is found.
   * @param {String|Array} `patterns` One or more glob patterns to use for matching.
   * @param {Object} `options` See available [options](#options) for changing how matches are performed
   * @return {Boolean} Returns true if any `patterns` matches any of the strings in `list`
   * @api public
   */

  micromatch.some = (list, patterns, options) => {
    let items = [].concat(list)
    for (let pattern of [].concat(patterns)) {
      let isMatch = picomatch(String(pattern), options)
      if (items.some(item => isMatch(item))) {
        return true
      }
    }
    return false
  }

  /**
   * Returns true if every string in the given `list` matches
   * any of the given glob `patterns`.
   *
   * ```js
   * const mm = require('micromatch');
   * // mm.every(list, patterns[, options]);
   *
   * console.log(mm.every('foo.js', ['foo.js']));
   * // true
   * console.log(mm.every(['foo.js', 'bar.js'], ['*.js']));
   * // true
   * console.log(mm.every(['foo.js', 'bar.js'], ['*.js', '!foo.js']));
   * // false
   * console.log(mm.every(['foo.js'], ['*.js', '!foo.js']));
   * // false
   * ```
   * @param {String|Array} `list` The string or array of strings to test.
   * @param {String|Array} `patterns` One or more glob patterns to use for matching.
   * @param {Object} `options` See available [options](#options) for changing how matches are performed
   * @return {Boolean} Returns true if all `patterns` matches all of the strings in `list`
   * @api public
   */

  micromatch.every = (list, patterns, options) => {
    let items = [].concat(list)
    for (let pattern of [].concat(patterns)) {
      let isMatch = picomatch(String(pattern), options)
      if (!items.every(item => isMatch(item))) {
        return false
      }
    }
    return true
  }

  /**
   * Returns true if **all** of the given `patterns` match
   * the specified string.
   *
   * ```js
   * const mm = require('micromatch');
   * // mm.all(string, patterns[, options]);
   *
   * console.log(mm.all('foo.js', ['foo.js']));
   * // true
   *
   * console.log(mm.all('foo.js', ['*.js', '!foo.js']));
   * // false
   *
   * console.log(mm.all('foo.js', ['*.js', 'foo.js']));
   * // true
   *
   * console.log(mm.all('foo.js', ['*.js', 'f*', '*o*', '*o.js']));
   * // true
   * ```
   * @param {String|Array} `str` The string to test.
   * @param {String|Array} `patterns` One or more glob patterns to use for matching.
   * @param {Object} `options` See available [options](#options) for changing how matches are performed
   * @return {Boolean} Returns true if any patterns match `str`
   * @api public
   */

  micromatch.all = (str, patterns, options) => {
    if (typeof str !== 'string') {
      throw new TypeError(`Expected a string: "${util.inspect(str)}"`)
    }
    return [].concat(patterns).every(p => picomatch(p, options)(str))
  }

  /**
   * Returns an array of matches captured by `pattern` in `string, or `null` if the pattern did not match.
   *
   * ```js
   * const mm = require('micromatch');
   * // mm.capture(pattern, string[, options]);
   *
   * console.log(mm.capture('test/*.js', 'test/foo.js'));
   * //=> ['foo']
   * console.log(mm.capture('test/*.js', 'foo/bar.css'));
   * //=> null
   * ```
   * @param {String} `glob` Glob pattern to use for matching.
   * @param {String} `input` String to match
   * @param {Object} `options` See available [options](#options) for changing how matches are performed
   * @return {Array|null} Returns an array of captures if the input matches the glob pattern, otherwise `null`.
   * @api public
   */

  micromatch.capture = (glob, input, options) => {
    let posix = utils.isWindows(options)
    let regex = picomatch.makeRe(String(glob), {
      ...options,
      capture: true
    })
    let match = regex.exec(posix ? utils.toPosixSlashes(input) : input)
    if (match) {
      return match.slice(1).map(v => (v === void 0 ? '' : v))
    }
  }

  /**
   * Create a regular expression from the given glob `pattern`.
   *
   * ```js
   * const mm = require('micromatch');
   * // mm.makeRe(pattern[, options]);
   *
   * console.log(mm.makeRe('*.js'));
   * //=> /^(?:(\.[\\\/])?(?!\.)(?=.)[^\/]*?\.js)$/
   * ```
   * @param {String} `pattern` A glob pattern to convert to regex.
   * @param {Object} `options`
   * @return {RegExp} Returns a regex created from the given pattern.
   * @api public
   */

  micromatch.makeRe = (...args) => picomatch.makeRe(...args)

  /**
   * Scan a glob pattern to separate the pattern into segments. Used
   * by the [split](#split) method.
   *
   * ```js
   * const mm = require('micromatch');
   * const state = mm.scan(pattern[, options]);
   * ```
   * @param {String} `pattern`
   * @param {Object} `options`
   * @return {Object} Returns an object with
   * @api public
   */

  micromatch.scan = (...args) => picomatch.scan(...args)

  /**
   * Parse a glob pattern to create the source string for a regular
   * expression.
   *
   * ```js
   * const mm = require('micromatch');
   * const state = mm.parse(pattern[, options]);
   * ```
   * @param {String} `glob`
   * @param {Object} `options`
   * @return {Object} Returns an object with useful properties and output to be used as regex source string.
   * @api public
   */

  micromatch.parse = (patterns, options) => {
    let res = []
    for (let pattern of [].concat(patterns || [])) {
      for (let str of braces(String(pattern), options)) {
        res.push(picomatch.parse(str, options))
      }
    }
    return res
  }

  /**
   * Process the given brace `pattern`.
   *
   * ```js
   * const { braces } = require('micromatch');
   * console.log(braces('foo/{a,b,c}/bar'));
   * //=> [ 'foo/(a|b|c)/bar' ]
   *
   * console.log(braces('foo/{a,b,c}/bar', { expand: true }));
   * //=> [ 'foo/a/bar', 'foo/b/bar', 'foo/c/bar' ]
   * ```
   * @param {String} `pattern` String with brace pattern to process.
   * @param {Object} `options` Any [options](#options) to change how expansion is performed. See the [braces][] library for all available options.
   * @return {Array}
   * @api public
   */

  micromatch.braces = (pattern, options) => {
    if (typeof pattern !== 'string') {
      throw new TypeError('Expected a string')
    }
    if ((options && options.nobrace === true) || !hasBraces(pattern)) {
      return [pattern]
    }
    return braces(pattern, options)
  }

  /**
   * Expand braces
   */

  micromatch.braceExpand = (pattern, options) => {
    if (typeof pattern !== 'string') {
      throw new TypeError('Expected a string')
    }
    return micromatch.braces(pattern, {
      ...options,
      expand: true
    })
  }

  /**
   * Expose micromatch
   */

  // exposed for tests
  micromatch.hasBraces = hasBraces
  micromatch_1 = micromatch
  return micromatch_1
}

const micromatchExports = requireMicromatch()

const dist$3 = {}

const builder = {}

const apiBuilder = {}

const async = {}

const walker = {}

const utils$1 = {}

let hasRequiredUtils$1
function requireUtils$1() {
  if (hasRequiredUtils$1) {
    return utils$1
  }
  hasRequiredUtils$1 = 1
  Object.defineProperty(utils$1, '__esModule', {
    value: true
  })
  utils$1.normalizePath =
    utils$1.isRootDirectory =
    utils$1.convertSlashes =
    utils$1.cleanPath =
      void 0
  const path_1 = require$$0$5
  function cleanPath(path) {
    let normalized = (0, path_1.normalize)(path)
    // we have to remove the last path separator
    // to account for / root path
    if (
      normalized.length > 1 &&
      normalized[normalized.length - 1] === path_1.sep
    ) {
      normalized = normalized.substring(0, normalized.length - 1)
    }
    return normalized
  }
  utils$1.cleanPath = cleanPath
  const SLASHES_REGEX = /[\\/]/g
  function convertSlashes(path, separator) {
    return path.replace(SLASHES_REGEX, separator)
  }
  utils$1.convertSlashes = convertSlashes
  function isRootDirectory(path) {
    return path === '/' || /^[a-z]:\\$/i.test(path)
  }
  utils$1.isRootDirectory = isRootDirectory
  function normalizePath(path, options) {
    const { resolvePaths, normalizePath, pathSeparator } = options
    const pathNeedsCleaning =
      (process.platform === 'win32' && path.includes('/')) ||
      path.startsWith('.')
    if (resolvePaths) {
      path = (0, path_1.resolve)(path)
    }
    if (normalizePath || pathNeedsCleaning) {
      path = cleanPath(path)
    }
    if (path === '.') {
      return ''
    }
    const needsSeperator = path[path.length - 1] !== pathSeparator
    return convertSlashes(
      needsSeperator ? path + pathSeparator : path,
      pathSeparator
    )
  }
  utils$1.normalizePath = normalizePath
  return utils$1
}

const joinPath = {}

let hasRequiredJoinPath
function requireJoinPath() {
  if (hasRequiredJoinPath) {
    return joinPath
  }
  hasRequiredJoinPath = 1
  Object.defineProperty(joinPath, '__esModule', {
    value: true
  })
  joinPath.build =
    joinPath.joinDirectoryPath =
    joinPath.joinPathWithBasePath =
      void 0
  const path_1 = require$$0$5
  const utils_1 = requireUtils$1()
  function joinPathWithBasePath(filename, directoryPath) {
    return directoryPath + filename
  }
  joinPath.joinPathWithBasePath = joinPathWithBasePath
  function joinPathWithRelativePath(root, options) {
    return function (filename, directoryPath) {
      const sameRoot = directoryPath.startsWith(root)
      if (sameRoot) {
        return directoryPath.replace(root, '') + filename
      } else {
        return (
          (0, utils_1.convertSlashes)(
            (0, path_1.relative)(root, directoryPath),
            options.pathSeparator
          ) +
          options.pathSeparator +
          filename
        )
      }
    }
  }
  function joinPath$1(filename) {
    return filename
  }
  function joinDirectoryPath(filename, directoryPath, separator) {
    return directoryPath + filename + separator
  }
  joinPath.joinDirectoryPath = joinDirectoryPath
  function build(root, options) {
    const { relativePaths, includeBasePath } = options
    return relativePaths && root
      ? joinPathWithRelativePath(root, options)
      : includeBasePath
        ? joinPathWithBasePath
        : joinPath$1
  }
  joinPath.build = build
  return joinPath
}

const pushDirectory = {}

let hasRequiredPushDirectory
function requirePushDirectory() {
  if (hasRequiredPushDirectory) {
    return pushDirectory
  }
  hasRequiredPushDirectory = 1
  Object.defineProperty(pushDirectory, '__esModule', {
    value: true
  })
  pushDirectory.build = void 0
  function pushDirectoryWithRelativePath(root) {
    return function (directoryPath, paths) {
      paths.push(directoryPath.substring(root.length) || '.')
    }
  }
  function pushDirectoryFilterWithRelativePath(root) {
    return function (directoryPath, paths, filters) {
      const relativePath = directoryPath.substring(root.length) || '.'
      if (filters.every(filter => filter(relativePath, true))) {
        paths.push(relativePath)
      }
    }
  }
  const pushDirectory$1 = (directoryPath, paths) => {
    paths.push(directoryPath || '.')
  }
  const pushDirectoryFilter = (directoryPath, paths, filters) => {
    const path = directoryPath || '.'
    if (filters.every(filter => filter(path, true))) {
      paths.push(path)
    }
  }
  const empty = () => {}
  function build(root, options) {
    const { includeDirs, filters, relativePaths } = options
    if (!includeDirs) {
      return empty
    }
    if (relativePaths) {
      return filters && filters.length
        ? pushDirectoryFilterWithRelativePath(root)
        : pushDirectoryWithRelativePath(root)
    }
    return filters && filters.length ? pushDirectoryFilter : pushDirectory$1
  }
  pushDirectory.build = build
  return pushDirectory
}

const pushFile = {}

let hasRequiredPushFile
function requirePushFile() {
  if (hasRequiredPushFile) {
    return pushFile
  }
  hasRequiredPushFile = 1
  Object.defineProperty(pushFile, '__esModule', {
    value: true
  })
  pushFile.build = void 0
  const pushFileFilterAndCount = (filename, _paths, counts, filters) => {
    if (filters.every(filter => filter(filename, false))) {
      counts.files++
    }
  }
  const pushFileFilter = (filename, paths, _counts, filters) => {
    if (filters.every(filter => filter(filename, false))) {
      paths.push(filename)
    }
  }
  const pushFileCount = (_filename, _paths, counts, _filters) => {
    counts.files++
  }
  const pushFile$1 = (filename, paths) => {
    paths.push(filename)
  }
  const empty = () => {}
  function build(options) {
    const { excludeFiles, filters, onlyCounts } = options
    if (excludeFiles) {
      return empty
    }
    if (filters && filters.length) {
      return onlyCounts ? pushFileFilterAndCount : pushFileFilter
    } else if (onlyCounts) {
      return pushFileCount
    } else {
      return pushFile$1
    }
  }
  pushFile.build = build
  return pushFile
}

const getArray = {}

let hasRequiredGetArray
function requireGetArray() {
  if (hasRequiredGetArray) {
    return getArray
  }
  hasRequiredGetArray = 1
  Object.defineProperty(getArray, '__esModule', {
    value: true
  })
  getArray.build = void 0
  const getArray$1 = paths => {
    return paths
  }
  const getArrayGroup = () => {
    return [''].slice(0, 0)
  }
  function build(options) {
    return options.group ? getArrayGroup : getArray$1
  }
  getArray.build = build
  return getArray
}

const groupFiles = {}

let hasRequiredGroupFiles
function requireGroupFiles() {
  if (hasRequiredGroupFiles) {
    return groupFiles
  }
  hasRequiredGroupFiles = 1
  Object.defineProperty(groupFiles, '__esModule', {
    value: true
  })
  groupFiles.build = void 0
  const groupFiles$1 = (groups, directory, files) => {
    groups.push({
      directory,
      files,
      dir: directory
    })
  }
  const empty = () => {}
  function build(options) {
    return options.group ? groupFiles$1 : empty
  }
  groupFiles.build = build
  return groupFiles
}

const resolveSymlink = {}

let hasRequiredResolveSymlink
function requireResolveSymlink() {
  if (hasRequiredResolveSymlink) {
    return resolveSymlink
  }
  hasRequiredResolveSymlink = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(resolveSymlink, '__esModule', {
    value: true
  })
  resolveSymlink.build = void 0
  const fs_1 = __importDefault(require$$0$6)
  const path_1 = require$$0$5
  const resolveSymlinksAsync = function (path, state, callback) {
    const {
      queue,
      options: { suppressErrors }
    } = state
    queue.enqueue()
    fs_1.default.realpath(path, (error, resolvedPath) => {
      if (error) {
        return queue.dequeue(suppressErrors ? null : error, state)
      }
      fs_1.default.stat(resolvedPath, (error, stat) => {
        if (error) {
          return queue.dequeue(suppressErrors ? null : error, state)
        }
        if (stat.isDirectory() && isRecursive(path, resolvedPath, state)) {
          return queue.dequeue(null, state)
        }
        callback(stat, resolvedPath)
        queue.dequeue(null, state)
      })
    })
  }
  const resolveSymlinks = function (path, state, callback) {
    const {
      queue,
      options: { suppressErrors }
    } = state
    queue.enqueue()
    try {
      const resolvedPath = fs_1.default.realpathSync(path)
      const stat = fs_1.default.statSync(resolvedPath)
      if (stat.isDirectory() && isRecursive(path, resolvedPath, state)) {
        return
      }
      callback(stat, resolvedPath)
    } catch (e) {
      if (!suppressErrors) {
        throw e
      }
    }
  }
  function build(options, isSynchronous) {
    if (!options.resolveSymlinks || options.excludeSymlinks) {
      return null
    }
    return isSynchronous ? resolveSymlinks : resolveSymlinksAsync
  }
  resolveSymlink.build = build
  function isRecursive(path, resolved, state) {
    if (state.options.useRealPaths) {
      return isRecursiveUsingRealPaths(resolved, state)
    }
    let parent = (0, path_1.dirname)(path)
    let depth = 1
    while (parent !== state.root && depth < 2) {
      const resolvedPath = state.symlinks.get(parent)
      const isSameRoot =
        !!resolvedPath &&
        (resolvedPath === resolved ||
          resolvedPath.startsWith(resolved) ||
          resolved.startsWith(resolvedPath))
      if (isSameRoot) {
        depth++
      } else {
        parent = (0, path_1.dirname)(parent)
      }
    }
    state.symlinks.set(path, resolved)
    return depth > 1
  }
  function isRecursiveUsingRealPaths(resolved, state) {
    return state.visited.includes(resolved + state.options.pathSeparator)
  }
  return resolveSymlink
}

const invokeCallback = {}

let hasRequiredInvokeCallback
function requireInvokeCallback() {
  if (hasRequiredInvokeCallback) {
    return invokeCallback
  }
  hasRequiredInvokeCallback = 1
  Object.defineProperty(invokeCallback, '__esModule', {
    value: true
  })
  invokeCallback.build = void 0
  const onlyCountsSync = state => {
    return state.counts
  }
  const groupsSync = state => {
    return state.groups
  }
  const defaultSync = state => {
    return state.paths
  }
  const limitFilesSync = state => {
    return state.paths.slice(0, state.options.maxFiles)
  }
  const onlyCountsAsync = (state, error, callback) => {
    report(error, callback, state.counts, state.options.suppressErrors)
    return null
  }
  const defaultAsync = (state, error, callback) => {
    report(error, callback, state.paths, state.options.suppressErrors)
    return null
  }
  const limitFilesAsync = (state, error, callback) => {
    report(
      error,
      callback,
      state.paths.slice(0, state.options.maxFiles),
      state.options.suppressErrors
    )
    return null
  }
  const groupsAsync = (state, error, callback) => {
    report(error, callback, state.groups, state.options.suppressErrors)
    return null
  }
  function report(error, callback, output, suppressErrors) {
    if (error && !suppressErrors) {
      callback(error, output)
    } else {
      callback(null, output)
    }
  }
  function build(options, isSynchronous) {
    const { onlyCounts, group, maxFiles } = options
    if (onlyCounts) {
      return isSynchronous ? onlyCountsSync : onlyCountsAsync
    } else if (group) {
      return isSynchronous ? groupsSync : groupsAsync
    } else if (maxFiles) {
      return isSynchronous ? limitFilesSync : limitFilesAsync
    } else {
      return isSynchronous ? defaultSync : defaultAsync
    }
  }
  invokeCallback.build = build
  return invokeCallback
}

const walkDirectory = {}

let hasRequiredWalkDirectory
function requireWalkDirectory() {
  if (hasRequiredWalkDirectory) {
    return walkDirectory
  }
  hasRequiredWalkDirectory = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(walkDirectory, '__esModule', {
    value: true
  })
  walkDirectory.build = void 0
  const fs_1 = __importDefault(require$$0$6)
  const readdirOpts = {
    withFileTypes: true
  }
  const walkAsync = (
    state,
    crawlPath,
    directoryPath,
    currentDepth,
    callback
  ) => {
    if (currentDepth < 0) {
      return state.queue.dequeue(null, state)
    }
    state.visited.push(crawlPath)
    state.counts.directories++
    state.queue.enqueue()
    // Perf: Node >= 10 introduced withFileTypes that helps us
    // skip an extra fs.stat call.
    fs_1.default.readdir(
      crawlPath || '.',
      readdirOpts,
      (error, entries = []) => {
        callback(entries, directoryPath, currentDepth)
        state.queue.dequeue(state.options.suppressErrors ? null : error, state)
      }
    )
  }
  const walkSync = (
    state,
    crawlPath,
    directoryPath,
    currentDepth,
    callback
  ) => {
    if (currentDepth < 0) {
      return
    }
    state.visited.push(crawlPath)
    state.counts.directories++
    let entries = []
    try {
      entries = fs_1.default.readdirSync(crawlPath || '.', readdirOpts)
    } catch (e) {
      if (!state.options.suppressErrors) {
        throw e
      }
    }
    callback(entries, directoryPath, currentDepth)
  }
  function build(isSynchronous) {
    return isSynchronous ? walkSync : walkAsync
  }
  walkDirectory.build = build
  return walkDirectory
}

const queue = {}

let hasRequiredQueue
function requireQueue() {
  if (hasRequiredQueue) {
    return queue
  }
  hasRequiredQueue = 1
  Object.defineProperty(queue, '__esModule', {
    value: true
  })
  queue.Queue = void 0
  /**
   * This is a custom stateless queue to track concurrent async fs calls.
   * It increments a counter whenever a call is queued and decrements it
   * as soon as it completes. When the counter hits 0, it calls onQueueEmpty.
   */
  class Queue {
    onQueueEmpty
    count = 0
    constructor(onQueueEmpty) {
      this.onQueueEmpty = onQueueEmpty
    }
    enqueue() {
      this.count++
    }
    dequeue(error, output) {
      if (--this.count <= 0 || error) {
        this.onQueueEmpty(error, output)
      }
    }
  }
  queue.Queue = Queue
  return queue
}

const counter = {}

let hasRequiredCounter
function requireCounter() {
  if (hasRequiredCounter) {
    return counter
  }
  hasRequiredCounter = 1
  Object.defineProperty(counter, '__esModule', {
    value: true
  })
  counter.Counter = void 0
  class Counter {
    _files = 0
    _directories = 0
    set files(num) {
      this._files = num
    }
    get files() {
      return this._files
    }
    set directories(num) {
      this._directories = num
    }
    get directories() {
      return this._directories
    }
    /**
     * @deprecated use `directories` instead
     */
    /* c8 ignore next 3 */
    get dirs() {
      return this._directories
    }
  }
  counter.Counter = Counter
  return counter
}

let hasRequiredWalker
function requireWalker() {
  if (hasRequiredWalker) {
    return walker
  }
  hasRequiredWalker = 1
  const __createBinding =
    (this && this.__createBinding) ||
    (Object.create
      ? function (o, m, k, k2) {
          if (k2 === undefined) {
            k2 = k
          }
          let desc = Object.getOwnPropertyDescriptor(m, k)
          if (
            !desc ||
            ('get' in desc ? !m.__esModule : desc.writable || desc.configurable)
          ) {
            desc = {
              enumerable: true,
              get: function () {
                return m[k]
              }
            }
          }
          Object.defineProperty(o, k2, desc)
        }
      : function (o, m, k, k2) {
          if (k2 === undefined) {
            k2 = k
          }
          o[k2] = m[k]
        })
  const __setModuleDefault =
    (this && this.__setModuleDefault) ||
    (Object.create
      ? function (o, v) {
          Object.defineProperty(o, 'default', {
            enumerable: true,
            value: v
          })
        }
      : function (o, v) {
          o['default'] = v
        })
  const __importStar =
    (this && this.__importStar) ||
    function (mod) {
      if (mod && mod.__esModule) {
        return mod
      }
      const result = {}
      if (mod != null) {
        for (var k in mod)
          if (k !== 'default' && Object.prototype.hasOwnProperty.call(mod, k))
            __createBinding(result, mod, k)
      }
      __setModuleDefault(result, mod)
      return result
    }
  Object.defineProperty(walker, '__esModule', {
    value: true
  })
  walker.Walker = void 0
  const path_1 = require$$0$5
  const utils_1 = requireUtils$1()
  const joinPath = __importStar(requireJoinPath())
  const pushDirectory = __importStar(requirePushDirectory())
  const pushFile = __importStar(requirePushFile())
  const getArray = __importStar(requireGetArray())
  const groupFiles = __importStar(requireGroupFiles())
  const resolveSymlink = __importStar(requireResolveSymlink())
  const invokeCallback = __importStar(requireInvokeCallback())
  const walkDirectory = __importStar(requireWalkDirectory())
  const queue_1 = requireQueue()
  const counter_1 = requireCounter()
  class Walker {
    root
    isSynchronous
    state
    joinPath
    pushDirectory
    pushFile
    getArray
    groupFiles
    resolveSymlink
    walkDirectory
    callbackInvoker
    constructor(root, options, callback) {
      this.isSynchronous = !callback
      this.callbackInvoker = invokeCallback.build(options, this.isSynchronous)
      this.root = (0, utils_1.normalizePath)(root, options)
      this.state = {
        root: (0, utils_1.isRootDirectory)(this.root)
          ? this.root
          : this.root.slice(0, -1),
        // Perf: we explicitly tell the compiler to optimize for String arrays
        paths: [''].slice(0, 0),
        groups: [],
        counts: new counter_1.Counter(),
        options,
        queue: new queue_1.Queue((error, state) =>
          this.callbackInvoker(state, error, callback)
        ),
        symlinks: new Map(),
        visited: [''].slice(0, 0)
      }
      /*
       * Perf: We conditionally change functions according to options. This gives a slight
       * performance boost. Since these functions are so small, they are automatically inlined
       * by the javascript engine so there's no function call overhead (in most cases).
       */
      this.joinPath = joinPath.build(this.root, options)
      this.pushDirectory = pushDirectory.build(this.root, options)
      this.pushFile = pushFile.build(options)
      this.getArray = getArray.build(options)
      this.groupFiles = groupFiles.build(options)
      this.resolveSymlink = resolveSymlink.build(options, this.isSynchronous)
      this.walkDirectory = walkDirectory.build(this.isSynchronous)
    }
    start() {
      this.walkDirectory(
        this.state,
        this.root,
        this.root,
        this.state.options.maxDepth,
        this.walk
      )
      return this.isSynchronous ? this.callbackInvoker(this.state, null) : null
    }
    walk = (entries, directoryPath, depth) => {
      const {
        paths,
        options: {
          filters,
          resolveSymlinks,
          excludeSymlinks,
          exclude,
          maxFiles,
          signal,
          useRealPaths,
          pathSeparator
        }
      } = this.state
      if ((signal && signal.aborted) || (maxFiles && paths.length > maxFiles)) {
        return
      }
      this.pushDirectory(directoryPath, paths, filters)
      const files = this.getArray(this.state.paths)
      for (let i = 0; i < entries.length; ++i) {
        const entry = entries[i]
        if (
          entry.isFile() ||
          (entry.isSymbolicLink() && !resolveSymlinks && !excludeSymlinks)
        ) {
          const filename = this.joinPath(entry.name, directoryPath)
          this.pushFile(filename, files, this.state.counts, filters)
        } else if (entry.isDirectory()) {
          let path = joinPath.joinDirectoryPath(
            entry.name,
            directoryPath,
            this.state.options.pathSeparator
          )
          if (exclude && exclude(entry.name, path)) {
            continue
          }
          this.walkDirectory(this.state, path, path, depth - 1, this.walk)
        } else if (entry.isSymbolicLink() && this.resolveSymlink) {
          let path = joinPath.joinPathWithBasePath(entry.name, directoryPath)
          this.resolveSymlink(path, this.state, (stat, resolvedPath) => {
            if (stat.isDirectory()) {
              resolvedPath = (0, utils_1.normalizePath)(
                resolvedPath,
                this.state.options
              )
              if (
                exclude &&
                exclude(
                  entry.name,
                  useRealPaths ? resolvedPath : path + pathSeparator
                )
              ) {
                return
              }
              this.walkDirectory(
                this.state,
                resolvedPath,
                useRealPaths ? resolvedPath : path + pathSeparator,
                depth - 1,
                this.walk
              )
            } else {
              resolvedPath = useRealPaths ? resolvedPath : path
              const filename = (0, path_1.basename)(resolvedPath)
              const directoryPath = (0, utils_1.normalizePath)(
                (0, path_1.dirname)(resolvedPath),
                this.state.options
              )
              resolvedPath = this.joinPath(filename, directoryPath)
              this.pushFile(resolvedPath, files, this.state.counts, filters)
            }
          })
        }
      }
      this.groupFiles(this.state.groups, directoryPath, files)
    }
  }
  walker.Walker = Walker
  return walker
}

let hasRequiredAsync
function requireAsync() {
  if (hasRequiredAsync) {
    return async
  }
  hasRequiredAsync = 1
  Object.defineProperty(async, '__esModule', {
    value: true
  })
  async.callback = async.promise = void 0
  const walker_1 = requireWalker()
  function promise(root, options) {
    return new Promise((resolve, reject) => {
      callback(root, options, (err, output) => {
        if (err) {
          return reject(err)
        }
        resolve(output)
      })
    })
  }
  async.promise = promise
  function callback(root, options, callback) {
    let walker = new walker_1.Walker(root, options, callback)
    walker.start()
  }
  async.callback = callback
  return async
}

const sync = {}

let hasRequiredSync
function requireSync() {
  if (hasRequiredSync) {
    return sync
  }
  hasRequiredSync = 1
  Object.defineProperty(sync, '__esModule', {
    value: true
  })
  sync.sync = void 0
  const walker_1 = requireWalker()
  function sync$1(root, options) {
    const walker = new walker_1.Walker(root, options)
    return walker.start()
  }
  sync.sync = sync$1
  return sync
}

let hasRequiredApiBuilder
function requireApiBuilder() {
  if (hasRequiredApiBuilder) {
    return apiBuilder
  }
  hasRequiredApiBuilder = 1
  Object.defineProperty(apiBuilder, '__esModule', {
    value: true
  })
  apiBuilder.APIBuilder = void 0
  const async_1 = requireAsync()
  const sync_1 = requireSync()
  class APIBuilder {
    root
    options
    constructor(root, options) {
      this.root = root
      this.options = options
    }
    withPromise() {
      return (0, async_1.promise)(this.root, this.options)
    }
    withCallback(cb) {
      ;(0, async_1.callback)(this.root, this.options, cb)
    }
    sync() {
      return (0, sync_1.sync)(this.root, this.options)
    }
  }
  apiBuilder.APIBuilder = APIBuilder
  return apiBuilder
}

const utils = {}

let constants$3
let hasRequiredConstants$2
function requireConstants$2() {
  if (hasRequiredConstants$2) {
    return constants$3
  }
  hasRequiredConstants$2 = 1
  const WIN_SLASH = '\\\\/'
  const WIN_NO_SLASH = `[^${WIN_SLASH}]`

  /**
   * Posix glob regex
   */

  const DOT_LITERAL = '\\.'
  const PLUS_LITERAL = '\\+'
  const QMARK_LITERAL = '\\?'
  const SLASH_LITERAL = '\\/'
  const ONE_CHAR = '(?=.)'
  const QMARK = '[^/]'
  const END_ANCHOR = `(?:${SLASH_LITERAL}|$)`
  const START_ANCHOR = `(?:^|${SLASH_LITERAL})`
  const DOTS_SLASH = `${DOT_LITERAL}{1,2}${END_ANCHOR}`
  const NO_DOT = `(?!${DOT_LITERAL})`
  const NO_DOTS = `(?!${START_ANCHOR}${DOTS_SLASH})`
  const NO_DOT_SLASH = `(?!${DOT_LITERAL}{0,1}${END_ANCHOR})`
  const NO_DOTS_SLASH = `(?!${DOTS_SLASH})`
  const QMARK_NO_DOT = `[^.${SLASH_LITERAL}]`
  const STAR = `${QMARK}*?`
  const SEP = '/'
  const POSIX_CHARS = {
    DOT_LITERAL,
    PLUS_LITERAL,
    QMARK_LITERAL,
    SLASH_LITERAL,
    ONE_CHAR,
    QMARK,
    END_ANCHOR,
    DOTS_SLASH,
    NO_DOT,
    NO_DOTS,
    NO_DOT_SLASH,
    NO_DOTS_SLASH,
    QMARK_NO_DOT,
    STAR,
    START_ANCHOR,
    SEP
  }

  /**
   * Windows glob regex
   */

  const WINDOWS_CHARS = {
    ...POSIX_CHARS,
    SLASH_LITERAL: `[${WIN_SLASH}]`,
    QMARK: WIN_NO_SLASH,
    STAR: `${WIN_NO_SLASH}*?`,
    DOTS_SLASH: `${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$)`,
    NO_DOT: `(?!${DOT_LITERAL})`,
    NO_DOTS: `(?!(?:^|[${WIN_SLASH}])${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$))`,
    NO_DOT_SLASH: `(?!${DOT_LITERAL}{0,1}(?:[${WIN_SLASH}]|$))`,
    NO_DOTS_SLASH: `(?!${DOT_LITERAL}{1,2}(?:[${WIN_SLASH}]|$))`,
    QMARK_NO_DOT: `[^.${WIN_SLASH}]`,
    START_ANCHOR: `(?:^|[${WIN_SLASH}])`,
    END_ANCHOR: `(?:[${WIN_SLASH}]|$)`,
    SEP: '\\'
  }

  /**
   * POSIX Bracket Regex
   */

  const POSIX_REGEX_SOURCE = {
    alnum: 'a-zA-Z0-9',
    alpha: 'a-zA-Z',
    ascii: '\\x00-\\x7F',
    blank: ' \\t',
    cntrl: '\\x00-\\x1F\\x7F',
    digit: '0-9',
    graph: '\\x21-\\x7E',
    lower: 'a-z',
    print: '\\x20-\\x7E ',
    punct: '\\-!"#$%&\'()\\*+,./:;<=>?@[\\]^_`{|}~',
    space: ' \\t\\r\\n\\v\\f',
    upper: 'A-Z',
    word: 'A-Za-z0-9_',
    xdigit: 'A-Fa-f0-9'
  }
  constants$3 = {
    MAX_LENGTH: 1024 * 64,
    POSIX_REGEX_SOURCE,
    // regular expressions
    REGEX_BACKSLASH: /\\(?![*+?^${}(|)[\]])/g,
    REGEX_NON_SPECIAL_CHARS: /^[^@![\].,$*+?^{}()|\\/]+/,
    REGEX_SPECIAL_CHARS: /[-*+?.^${}(|)[\]]/,
    REGEX_SPECIAL_CHARS_BACKREF: /(\\?)((\W)(\3*))/g,
    REGEX_SPECIAL_CHARS_GLOBAL: /([-*+?.^${}(|)[\]])/g,
    REGEX_REMOVE_BACKSLASH: /(?:\[.*?[^\\]\]|\\(?=.))/g,
    // Replace globs with equivalent patterns to reduce parsing time.
    REPLACEMENTS: {
      '***': '*',
      '**/**': '**',
      '**/**/**': '**'
    },
    // Digits
    CHAR_0: 48,
    /* 0 */
    CHAR_9: 57,
    /* 9 */

    // Alphabet chars.
    CHAR_UPPERCASE_A: 65,
    /* A */
    CHAR_LOWERCASE_A: 97,
    /* a */
    CHAR_UPPERCASE_Z: 90,
    /* Z */
    CHAR_LOWERCASE_Z: 122,
    /* z */

    CHAR_LEFT_PARENTHESES: 40,
    /* ( */
    CHAR_RIGHT_PARENTHESES: 41,
    /* ) */

    CHAR_ASTERISK: 42,
    /* * */

    // Non-alphabetic chars.
    CHAR_AMPERSAND: 38,
    /* & */
    CHAR_AT: 64,
    /* @ */
    CHAR_BACKWARD_SLASH: 92,
    /* \ */
    CHAR_CARRIAGE_RETURN: 13,
    /* \r */
    CHAR_CIRCUMFLEX_ACCENT: 94,
    /* ^ */
    CHAR_COLON: 58,
    /* : */
    CHAR_COMMA: 44,
    /* , */
    CHAR_DOT: 46,
    /* . */
    CHAR_DOUBLE_QUOTE: 34,
    /* " */
    CHAR_EQUAL: 61,
    /* = */
    CHAR_EXCLAMATION_MARK: 33,
    /* ! */
    CHAR_FORM_FEED: 12,
    /* \f */
    CHAR_FORWARD_SLASH: 47,
    /* / */
    CHAR_GRAVE_ACCENT: 96,
    /* ` */
    CHAR_HASH: 35,
    /* # */
    CHAR_HYPHEN_MINUS: 45,
    /* - */
    CHAR_LEFT_ANGLE_BRACKET: 60,
    /* < */
    CHAR_LEFT_CURLY_BRACE: 123,
    /* { */
    CHAR_LEFT_SQUARE_BRACKET: 91,
    /* [ */
    CHAR_LINE_FEED: 10,
    /* \n */
    CHAR_NO_BREAK_SPACE: 160,
    /* \u00A0 */
    CHAR_PERCENT: 37,
    /* % */
    CHAR_PLUS: 43,
    /* + */
    CHAR_QUESTION_MARK: 63,
    /* ? */
    CHAR_RIGHT_ANGLE_BRACKET: 62,
    /* > */
    CHAR_RIGHT_CURLY_BRACE: 125,
    /* } */
    CHAR_RIGHT_SQUARE_BRACKET: 93,
    /* ] */
    CHAR_SEMICOLON: 59,
    /* ; */
    CHAR_SINGLE_QUOTE: 39,
    /* ' */
    CHAR_SPACE: 32,
    /*   */
    CHAR_TAB: 9,
    /* \t */
    CHAR_UNDERSCORE: 95,
    /* _ */
    CHAR_VERTICAL_LINE: 124,
    /* | */
    CHAR_ZERO_WIDTH_NOBREAK_SPACE: 65279,
    /* \uFEFF */

    /**
     * Create EXTGLOB_CHARS
     */

    extglobChars(chars) {
      return {
        '!': {
          type: 'negate',
          open: '(?:(?!(?:',
          close: `))${chars.STAR})`
        },
        '?': {
          type: 'qmark',
          open: '(?:',
          close: ')?'
        },
        '+': {
          type: 'plus',
          open: '(?:',
          close: ')+'
        },
        '*': {
          type: 'star',
          open: '(?:',
          close: ')*'
        },
        '@': {
          type: 'at',
          open: '(?:',
          close: ')'
        }
      }
    },
    /**
     * Create GLOB_CHARS
     */

    globChars(win32) {
      return win32 === true ? WINDOWS_CHARS : POSIX_CHARS
    }
  }
  return constants$3
}

/*global navigator*/
let hasRequiredUtils
function requireUtils() {
  if (hasRequiredUtils) {
    return utils
  }
  hasRequiredUtils = 1
  ;(function (exports) {
    const {
      REGEX_BACKSLASH,
      REGEX_REMOVE_BACKSLASH,
      REGEX_SPECIAL_CHARS,
      REGEX_SPECIAL_CHARS_GLOBAL
    } = /*@__PURE__*/ requireConstants$2()
    exports.isObject = val =>
      val !== null && typeof val === 'object' && !Array.isArray(val)
    exports.hasRegexChars = str => REGEX_SPECIAL_CHARS.test(str)
    exports.isRegexChar = str => str.length === 1 && exports.hasRegexChars(str)
    exports.escapeRegex = str => str.replace(REGEX_SPECIAL_CHARS_GLOBAL, '\\$1')
    exports.toPosixSlashes = str => str.replace(REGEX_BACKSLASH, '/')
    exports.isWindows = () => {
      if (typeof navigator !== 'undefined' && navigator.platform) {
        const platform = navigator.platform.toLowerCase()
        return platform === 'win32' || platform === 'windows'
      }
      if (typeof process !== 'undefined' && process.platform) {
        return process.platform === 'win32'
      }
      return false
    }
    exports.removeBackslashes = str => {
      return str.replace(REGEX_REMOVE_BACKSLASH, match => {
        return match === '\\' ? '' : match
      })
    }
    exports.escapeLast = (input, char, lastIdx) => {
      const idx = input.lastIndexOf(char, lastIdx)
      if (idx === -1) {
        return input
      }
      if (input[idx - 1] === '\\') {
        return exports.escapeLast(input, char, idx - 1)
      }
      return `${input.slice(0, idx)}\\${input.slice(idx)}`
    }
    exports.removePrefix = (input, state = {}) => {
      let output = input
      if (output.startsWith('./')) {
        output = output.slice(2)
        state.prefix = './'
      }
      return output
    }
    exports.wrapOutput = (input, state = {}, options = {}) => {
      const prepend = options.contains ? '' : '^'
      const append = options.contains ? '' : '$'
      let output = `${prepend}(?:${input})${append}`
      if (state.negated === true) {
        output = `(?:^(?!${output}).*$)`
      }
      return output
    }
    exports.basename = (path, { windows } = {}) => {
      const segs = path.split(windows ? /[\\/]/ : '/')
      const last = segs[segs.length - 1]
      if (last === '') {
        return segs[segs.length - 2]
      }
      return last
    }
  })(utils)
  return utils
}

let scan_1
let hasRequiredScan
function requireScan() {
  if (hasRequiredScan) {
    return scan_1
  }
  hasRequiredScan = 1
  const utils = /*@__PURE__*/ requireUtils()
  const {
    CHAR_ASTERISK,
    /* * */
    CHAR_AT,
    /* @ */
    CHAR_BACKWARD_SLASH,
    /* \ */
    CHAR_COMMA,
    /* , */
    CHAR_DOT,
    /* . */
    CHAR_EXCLAMATION_MARK,
    /* ! */
    CHAR_FORWARD_SLASH,
    /* / */
    CHAR_LEFT_CURLY_BRACE,
    /* { */
    CHAR_LEFT_PARENTHESES,
    /* ( */
    CHAR_LEFT_SQUARE_BRACKET,
    /* [ */
    CHAR_PLUS,
    /* + */
    CHAR_QUESTION_MARK,
    /* ? */
    CHAR_RIGHT_CURLY_BRACE,
    /* } */
    CHAR_RIGHT_PARENTHESES,
    /* ) */
    CHAR_RIGHT_SQUARE_BRACKET /* ] */
  } = /*@__PURE__*/ requireConstants$2()
  const isPathSeparator = code => {
    return code === CHAR_FORWARD_SLASH || code === CHAR_BACKWARD_SLASH
  }
  const depth = token => {
    if (token.isPrefix !== true) {
      token.depth = token.isGlobstar ? Infinity : 1
    }
  }

  /**
   * Quickly scans a glob pattern and returns an object with a handful of
   * useful properties, like `isGlob`, `path` (the leading non-glob, if it exists),
   * `glob` (the actual pattern), `negated` (true if the path starts with `!` but not
   * with `!(`) and `negatedExtglob` (true if the path starts with `!(`).
   *
   * ```js
   * const pm = require('picomatch');
   * console.log(pm.scan('foo/bar/*.js'));
   * { isGlob: true, input: 'foo/bar/*.js', base: 'foo/bar', glob: '*.js' }
   * ```
   * @param {String} `str`
   * @param {Object} `options`
   * @return {Object} Returns an object with tokens and regex source string.
   * @api public
   */

  const scan = (input, options) => {
    const opts = options || {}
    const length = input.length - 1
    const scanToEnd = opts.parts === true || opts.scanToEnd === true
    const slashes = []
    const tokens = []
    const parts = []
    let str = input
    let index = -1
    let start = 0
    let lastIndex = 0
    let isBrace = false
    let isBracket = false
    let isGlob = false
    let isExtglob = false
    let isGlobstar = false
    let braceEscaped = false
    let backslashes = false
    let negated = false
    let negatedExtglob = false
    let finished = false
    let braces = 0
    let prev
    let code
    let token = {
      value: '',
      depth: 0,
      isGlob: false
    }
    const eos = () => index >= length
    const peek = () => str.charCodeAt(index + 1)
    const advance = () => {
      prev = code
      return str.charCodeAt(++index)
    }
    while (index < length) {
      code = advance()
      let next
      if (code === CHAR_BACKWARD_SLASH) {
        backslashes = token.backslashes = true
        code = advance()
        if (code === CHAR_LEFT_CURLY_BRACE) {
          braceEscaped = true
        }
        continue
      }
      if (braceEscaped === true || code === CHAR_LEFT_CURLY_BRACE) {
        braces++
        while (eos() !== true && (code = advance())) {
          if (code === CHAR_BACKWARD_SLASH) {
            backslashes = token.backslashes = true
            advance()
            continue
          }
          if (code === CHAR_LEFT_CURLY_BRACE) {
            braces++
            continue
          }
          if (
            braceEscaped !== true &&
            code === CHAR_DOT &&
            (code = advance()) === CHAR_DOT
          ) {
            isBrace = token.isBrace = true
            isGlob = token.isGlob = true
            finished = true
            if (scanToEnd === true) {
              continue
            }
            break
          }
          if (braceEscaped !== true && code === CHAR_COMMA) {
            isBrace = token.isBrace = true
            isGlob = token.isGlob = true
            finished = true
            if (scanToEnd === true) {
              continue
            }
            break
          }
          if (code === CHAR_RIGHT_CURLY_BRACE) {
            braces--
            if (braces === 0) {
              braceEscaped = false
              isBrace = token.isBrace = true
              finished = true
              break
            }
          }
        }
        if (scanToEnd === true) {
          continue
        }
        break
      }
      if (code === CHAR_FORWARD_SLASH) {
        slashes.push(index)
        tokens.push(token)
        token = {
          value: '',
          depth: 0,
          isGlob: false
        }
        if (finished === true) {
          continue
        }
        if (prev === CHAR_DOT && index === start + 1) {
          start += 2
          continue
        }
        lastIndex = index + 1
        continue
      }
      if (opts.noext !== true) {
        const isExtglobChar =
          code === CHAR_PLUS ||
          code === CHAR_AT ||
          code === CHAR_ASTERISK ||
          code === CHAR_QUESTION_MARK ||
          code === CHAR_EXCLAMATION_MARK
        if (isExtglobChar === true && peek() === CHAR_LEFT_PARENTHESES) {
          isGlob = token.isGlob = true
          isExtglob = token.isExtglob = true
          finished = true
          if (code === CHAR_EXCLAMATION_MARK && index === start) {
            negatedExtglob = true
          }
          if (scanToEnd === true) {
            while (eos() !== true && (code = advance())) {
              if (code === CHAR_BACKWARD_SLASH) {
                backslashes = token.backslashes = true
                code = advance()
                continue
              }
              if (code === CHAR_RIGHT_PARENTHESES) {
                isGlob = token.isGlob = true
                finished = true
                break
              }
            }
            continue
          }
          break
        }
      }
      if (code === CHAR_ASTERISK) {
        if (prev === CHAR_ASTERISK) {
          isGlobstar = token.isGlobstar = true
        }
        isGlob = token.isGlob = true
        finished = true
        if (scanToEnd === true) {
          continue
        }
        break
      }
      if (code === CHAR_QUESTION_MARK) {
        isGlob = token.isGlob = true
        finished = true
        if (scanToEnd === true) {
          continue
        }
        break
      }
      if (code === CHAR_LEFT_SQUARE_BRACKET) {
        while (eos() !== true && (next = advance())) {
          if (next === CHAR_BACKWARD_SLASH) {
            backslashes = token.backslashes = true
            advance()
            continue
          }
          if (next === CHAR_RIGHT_SQUARE_BRACKET) {
            isBracket = token.isBracket = true
            isGlob = token.isGlob = true
            finished = true
            break
          }
        }
        if (scanToEnd === true) {
          continue
        }
        break
      }
      if (
        opts.nonegate !== true &&
        code === CHAR_EXCLAMATION_MARK &&
        index === start
      ) {
        negated = token.negated = true
        start++
        continue
      }
      if (opts.noparen !== true && code === CHAR_LEFT_PARENTHESES) {
        isGlob = token.isGlob = true
        if (scanToEnd === true) {
          while (eos() !== true && (code = advance())) {
            if (code === CHAR_LEFT_PARENTHESES) {
              backslashes = token.backslashes = true
              code = advance()
              continue
            }
            if (code === CHAR_RIGHT_PARENTHESES) {
              finished = true
              break
            }
          }
          continue
        }
        break
      }
      if (isGlob === true) {
        finished = true
        if (scanToEnd === true) {
          continue
        }
        break
      }
    }
    if (opts.noext === true) {
      isExtglob = false
      isGlob = false
    }
    let base = str
    let prefix = ''
    let glob = ''
    if (start > 0) {
      prefix = str.slice(0, start)
      str = str.slice(start)
      lastIndex -= start
    }
    if (base && isGlob === true && lastIndex > 0) {
      base = str.slice(0, lastIndex)
      glob = str.slice(lastIndex)
    } else if (isGlob === true) {
      base = ''
      glob = str
    } else {
      base = str
    }
    if (base && base !== '' && base !== '/' && base !== str) {
      if (isPathSeparator(base.charCodeAt(base.length - 1))) {
        base = base.slice(0, -1)
      }
    }
    if (opts.unescape === true) {
      if (glob) {
        glob = utils.removeBackslashes(glob)
      }
      if (base && backslashes === true) {
        base = utils.removeBackslashes(base)
      }
    }
    const state = {
      prefix,
      input,
      start,
      base,
      glob,
      isBrace,
      isBracket,
      isGlob,
      isExtglob,
      isGlobstar,
      negated,
      negatedExtglob
    }
    if (opts.tokens === true) {
      state.maxDepth = 0
      if (!isPathSeparator(code)) {
        tokens.push(token)
      }
      state.tokens = tokens
    }
    if (opts.parts === true || opts.tokens === true) {
      let prevIndex
      for (let idx = 0; idx < slashes.length; idx++) {
        const n = prevIndex ? prevIndex + 1 : start
        const i = slashes[idx]
        const value = input.slice(n, i)
        if (opts.tokens) {
          if (idx === 0 && start !== 0) {
            tokens[idx].isPrefix = true
            tokens[idx].value = prefix
          } else {
            tokens[idx].value = value
          }
          depth(tokens[idx])
          state.maxDepth += tokens[idx].depth
        }
        if (idx !== 0 || value !== '') {
          parts.push(value)
        }
        prevIndex = i
      }
      if (prevIndex && prevIndex + 1 < input.length) {
        const value = input.slice(prevIndex + 1)
        parts.push(value)
        if (opts.tokens) {
          tokens[tokens.length - 1].value = value
          depth(tokens[tokens.length - 1])
          state.maxDepth += tokens[tokens.length - 1].depth
        }
      }
      state.slashes = slashes
      state.parts = parts
    }
    return state
  }
  scan_1 = scan
  return scan_1
}

let parse_1$3
let hasRequiredParse$3
function requireParse$3() {
  if (hasRequiredParse$3) {
    return parse_1$3
  }
  hasRequiredParse$3 = 1
  const constants = /*@__PURE__*/ requireConstants$2()
  const utils = /*@__PURE__*/ requireUtils()

  /**
   * Constants
   */

  const {
    MAX_LENGTH,
    POSIX_REGEX_SOURCE,
    REGEX_NON_SPECIAL_CHARS,
    REGEX_SPECIAL_CHARS_BACKREF,
    REPLACEMENTS
  } = constants

  /**
   * Helpers
   */

  const expandRange = (args, options) => {
    if (typeof options.expandRange === 'function') {
      return options.expandRange(...args, options)
    }
    args.sort()
    const value = `[${args.join('-')}]`
    try {
      /* eslint-disable-next-line no-new */
      new RegExp(value)
    } catch (ex) {
      return args.map(v => utils.escapeRegex(v)).join('..')
    }
    return value
  }

  /**
   * Create the message for a syntax error
   */

  const syntaxError = (type, char) => {
    return `Missing ${type}: "${char}" - use "\\\\${char}" to match literal characters`
  }

  /**
   * Parse the given input string.
   * @param {String} input
   * @param {Object} options
   * @return {Object}
   */

  const parse = (input, options) => {
    if (typeof input !== 'string') {
      throw new TypeError('Expected a string')
    }
    input = REPLACEMENTS[input] || input
    const opts = {
      ...options
    }
    const max =
      typeof opts.maxLength === 'number'
        ? Math.min(MAX_LENGTH, opts.maxLength)
        : MAX_LENGTH
    let len = input.length
    if (len > max) {
      throw new SyntaxError(
        `Input length: ${len}, exceeds maximum allowed length: ${max}`
      )
    }
    const bos = {
      type: 'bos',
      value: '',
      output: opts.prepend || ''
    }
    const tokens = [bos]
    const capture = opts.capture ? '' : '?:'

    // create constants based on platform, for windows or posix
    const PLATFORM_CHARS = constants.globChars(opts.windows)
    const EXTGLOB_CHARS = constants.extglobChars(PLATFORM_CHARS)
    const {
      DOT_LITERAL,
      PLUS_LITERAL,
      SLASH_LITERAL,
      ONE_CHAR,
      DOTS_SLASH,
      NO_DOT,
      NO_DOT_SLASH,
      NO_DOTS_SLASH,
      QMARK,
      QMARK_NO_DOT,
      STAR,
      START_ANCHOR
    } = PLATFORM_CHARS
    const globstar = opts => {
      return `(${capture}(?:(?!${START_ANCHOR}${opts.dot ? DOTS_SLASH : DOT_LITERAL}).)*?)`
    }
    const nodot = opts.dot ? '' : NO_DOT
    const qmarkNoDot = opts.dot ? QMARK : QMARK_NO_DOT
    let star = opts.bash === true ? globstar(opts) : STAR
    if (opts.capture) {
      star = `(${star})`
    }

    // minimatch options support
    if (typeof opts.noext === 'boolean') {
      opts.noextglob = opts.noext
    }
    const state = {
      input,
      index: -1,
      start: 0,
      dot: opts.dot === true,
      consumed: '',
      output: '',
      prefix: '',
      backtrack: false,
      negated: false,
      brackets: 0,
      braces: 0,
      parens: 0,
      quotes: 0,
      globstar: false,
      tokens
    }
    input = utils.removePrefix(input, state)
    len = input.length
    const extglobs = []
    const braces = []
    const stack = []
    let prev = bos
    let value

    /**
     * Tokenizing helpers
     */

    const eos = () => state.index === len - 1
    const peek = (state.peek = (n = 1) => input[state.index + n])
    const advance = (state.advance = () => input[++state.index] || '')
    const remaining = () => input.slice(state.index + 1)
    const consume = (value = '', num = 0) => {
      state.consumed += value
      state.index += num
    }
    const append = token => {
      state.output += token.output != null ? token.output : token.value
      consume(token.value)
    }
    const negate = () => {
      let count = 1
      while (peek() === '!' && (peek(2) !== '(' || peek(3) === '?')) {
        advance()
        state.start++
        count++
      }
      if (count % 2 === 0) {
        return false
      }
      state.negated = true
      state.start++
      return true
    }
    const increment = type => {
      state[type]++
      stack.push(type)
    }
    const decrement = type => {
      state[type]--
      stack.pop()
    }

    /**
     * Push tokens onto the tokens array. This helper speeds up
     * tokenizing by 1) helping us avoid backtracking as much as possible,
     * and 2) helping us avoid creating extra tokens when consecutive
     * characters are plain text. This improves performance and simplifies
     * lookbehinds.
     */

    const push = tok => {
      if (prev.type === 'globstar') {
        const isBrace =
          state.braces > 0 && (tok.type === 'comma' || tok.type === 'brace')
        const isExtglob =
          tok.extglob === true ||
          (extglobs.length && (tok.type === 'pipe' || tok.type === 'paren'))
        if (
          tok.type !== 'slash' &&
          tok.type !== 'paren' &&
          !isBrace &&
          !isExtglob
        ) {
          state.output = state.output.slice(0, -prev.output.length)
          prev.type = 'star'
          prev.value = '*'
          prev.output = star
          state.output += prev.output
        }
      }
      if (extglobs.length && tok.type !== 'paren') {
        extglobs[extglobs.length - 1].inner += tok.value
      }
      if (tok.value || tok.output) {
        append(tok)
      }
      if (prev && prev.type === 'text' && tok.type === 'text') {
        prev.output = (prev.output || prev.value) + tok.value
        prev.value += tok.value
        return
      }
      tok.prev = prev
      tokens.push(tok)
      prev = tok
    }
    const extglobOpen = (type, value) => {
      const token = {
        ...EXTGLOB_CHARS[value],
        conditions: 1,
        inner: ''
      }
      token.prev = prev
      token.parens = state.parens
      token.output = state.output
      const output = (opts.capture ? '(' : '') + token.open
      increment('parens')
      push({
        type,
        value,
        output: state.output ? '' : ONE_CHAR
      })
      push({
        type: 'paren',
        extglob: true,
        value: advance(),
        output
      })
      extglobs.push(token)
    }
    const extglobClose = token => {
      let output = token.close + (opts.capture ? ')' : '')
      let rest
      if (token.type === 'negate') {
        let extglobStar = star
        if (
          token.inner &&
          token.inner.length > 1 &&
          token.inner.includes('/')
        ) {
          extglobStar = globstar(opts)
        }
        if (extglobStar !== star || eos() || /^\)+$/.test(remaining())) {
          output = token.close = `)$))${extglobStar}`
        }
        if (
          token.inner.includes('*') &&
          (rest = remaining()) &&
          /^\.[^\\/.]+$/.test(rest)
        ) {
          // Any non-magical string (`.ts`) or even nested expression (`.{ts,tsx}`) can follow after the closing parenthesis.
          // In this case, we need to parse the string and use it in the output of the original pattern.
          // Suitable patterns: `/!(*.d).ts`, `/!(*.d).{ts,tsx}`, `**/!(*-dbg).@(js)`.
          //
          // Disabling the `fastpaths` option due to a problem with parsing strings as `.ts` in the pattern like `**/!(*.d).ts`.
          const expression = parse(rest, {
            ...options,
            fastpaths: false
          }).output
          output = token.close = `)${expression})${extglobStar})`
        }
        if (token.prev.type === 'bos') {
          state.negatedExtglob = true
        }
      }
      push({
        type: 'paren',
        extglob: true,
        value,
        output
      })
      decrement('parens')
    }

    /**
     * Fast paths
     */

    if (opts.fastpaths !== false && !/(^[*!]|[/()[\]{}"])/.test(input)) {
      let backslashes = false
      let output = input.replace(
        REGEX_SPECIAL_CHARS_BACKREF,
        (m, esc, chars, first, rest, index) => {
          if (first === '\\') {
            backslashes = true
            return m
          }
          if (first === '?') {
            if (esc) {
              return esc + first + (rest ? QMARK.repeat(rest.length) : '')
            }
            if (index === 0) {
              return qmarkNoDot + (rest ? QMARK.repeat(rest.length) : '')
            }
            return QMARK.repeat(chars.length)
          }
          if (first === '.') {
            return DOT_LITERAL.repeat(chars.length)
          }
          if (first === '*') {
            if (esc) {
              return esc + first + (rest ? star : '')
            }
            return star
          }
          return esc ? m : `\\${m}`
        }
      )
      if (backslashes === true) {
        if (opts.unescape === true) {
          output = output.replace(/\\/g, '')
        } else {
          output = output.replace(/\\+/g, m => {
            return m.length % 2 === 0 ? '\\\\' : m ? '\\' : ''
          })
        }
      }
      if (output === input && opts.contains === true) {
        state.output = input
        return state
      }
      state.output = utils.wrapOutput(output, state, options)
      return state
    }

    /**
     * Tokenize input until we reach end-of-string
     */

    while (!eos()) {
      value = advance()
      if (value === '\u0000') {
        continue
      }

      /**
       * Escaped characters
       */

      if (value === '\\') {
        const next = peek()
        if (next === '/' && opts.bash !== true) {
          continue
        }
        if (next === '.' || next === ';') {
          continue
        }
        if (!next) {
          value += '\\'
          push({
            type: 'text',
            value
          })
          continue
        }

        // collapse slashes to reduce potential for exploits
        const match = /^\\+/.exec(remaining())
        let slashes = 0
        if (match && match[0].length > 2) {
          slashes = match[0].length
          state.index += slashes
          if (slashes % 2 !== 0) {
            value += '\\'
          }
        }
        if (opts.unescape === true) {
          value = advance()
        } else {
          value += advance()
        }
        if (state.brackets === 0) {
          push({
            type: 'text',
            value
          })
          continue
        }
      }

      /**
       * If we're inside a regex character class, continue
       * until we reach the closing bracket.
       */

      if (
        state.brackets > 0 &&
        (value !== ']' || prev.value === '[' || prev.value === '[^')
      ) {
        if (opts.posix !== false && value === ':') {
          const inner = new Set(prev.value.slice(1))
          if (inner.has('[')) {
            prev.posix = true
            if (inner.has(':')) {
              const idx = prev.value.lastIndexOf('[')
              const pre = prev.value.slice(0, idx)
              const rest = prev.value.slice(idx + 2)
              const posix = POSIX_REGEX_SOURCE[rest]
              if (posix) {
                prev.value = pre + posix
                state.backtrack = true
                advance()
                if (!bos.output && tokens.indexOf(prev) === 1) {
                  bos.output = ONE_CHAR
                }
                continue
              }
            }
          }
        }
        if (
          (value === '[' && peek() !== ':') ||
          (value === '-' && peek() === ']')
        ) {
          value = `\\${value}`
        }
        if (value === ']' && (prev.value === '[' || prev.value === '[^')) {
          value = `\\${value}`
        }
        if (opts.posix === true && value === '!' && prev.value === '[') {
          value = '^'
        }
        prev.value += value
        append({
          value
        })
        continue
      }

      /**
       * If we're inside a quoted string, continue
       * until we reach the closing double quote.
       */

      if (state.quotes === 1 && value !== '"') {
        value = utils.escapeRegex(value)
        prev.value += value
        append({
          value
        })
        continue
      }

      /**
       * Double quotes
       */

      if (value === '"') {
        state.quotes = state.quotes === 1 ? 0 : 1
        if (opts.keepQuotes === true) {
          push({
            type: 'text',
            value
          })
        }
        continue
      }

      /**
       * Parentheses
       */

      if (value === '(') {
        increment('parens')
        push({
          type: 'paren',
          value
        })
        continue
      }
      if (value === ')') {
        if (state.parens === 0 && opts.strictBrackets === true) {
          throw new SyntaxError(syntaxError('opening', '('))
        }
        const extglob = extglobs[extglobs.length - 1]
        if (extglob && state.parens === extglob.parens + 1) {
          extglobClose(extglobs.pop())
          continue
        }
        push({
          type: 'paren',
          value,
          output: state.parens ? ')' : '\\)'
        })
        decrement('parens')
        continue
      }

      /**
       * Square brackets
       */

      if (value === '[') {
        if (opts.nobracket === true || !remaining().includes(']')) {
          if (opts.nobracket !== true && opts.strictBrackets === true) {
            throw new SyntaxError(syntaxError('closing', ']'))
          }
          value = `\\${value}`
        } else {
          increment('brackets')
        }
        push({
          type: 'bracket',
          value
        })
        continue
      }
      if (value === ']') {
        if (
          opts.nobracket === true ||
          (prev && prev.type === 'bracket' && prev.value.length === 1)
        ) {
          push({
            type: 'text',
            value,
            output: `\\${value}`
          })
          continue
        }
        if (state.brackets === 0) {
          if (opts.strictBrackets === true) {
            throw new SyntaxError(syntaxError('opening', '['))
          }
          push({
            type: 'text',
            value,
            output: `\\${value}`
          })
          continue
        }
        decrement('brackets')
        const prevValue = prev.value.slice(1)
        if (
          prev.posix !== true &&
          prevValue[0] === '^' &&
          !prevValue.includes('/')
        ) {
          value = `/${value}`
        }
        prev.value += value
        append({
          value
        })

        // when literal brackets are explicitly disabled
        // assume we should match with a regex character class
        if (opts.literalBrackets === false || utils.hasRegexChars(prevValue)) {
          continue
        }
        const escaped = utils.escapeRegex(prev.value)
        state.output = state.output.slice(0, -prev.value.length)

        // when literal brackets are explicitly enabled
        // assume we should escape the brackets to match literal characters
        if (opts.literalBrackets === true) {
          state.output += escaped
          prev.value = escaped
          continue
        }

        // when the user specifies nothing, try to match both
        prev.value = `(${capture}${escaped}|${prev.value})`
        state.output += prev.value
        continue
      }

      /**
       * Braces
       */

      if (value === '{' && opts.nobrace !== true) {
        increment('braces')
        const open = {
          type: 'brace',
          value,
          output: '(',
          outputIndex: state.output.length,
          tokensIndex: state.tokens.length
        }
        braces.push(open)
        push(open)
        continue
      }
      if (value === '}') {
        const brace = braces[braces.length - 1]
        if (opts.nobrace === true || !brace) {
          push({
            type: 'text',
            value,
            output: value
          })
          continue
        }
        let output = ')'
        if (brace.dots === true) {
          const arr = tokens.slice()
          const range = []
          for (let i = arr.length - 1; i >= 0; i--) {
            tokens.pop()
            if (arr[i].type === 'brace') {
              break
            }
            if (arr[i].type !== 'dots') {
              range.unshift(arr[i].value)
            }
          }
          output = expandRange(range, opts)
          state.backtrack = true
        }
        if (brace.comma !== true && brace.dots !== true) {
          const out = state.output.slice(0, brace.outputIndex)
          const toks = state.tokens.slice(brace.tokensIndex)
          brace.value = brace.output = '\\{'
          value = output = '\\}'
          state.output = out
          for (const t of toks) {
            state.output += t.output || t.value
          }
        }
        push({
          type: 'brace',
          value,
          output
        })
        decrement('braces')
        braces.pop()
        continue
      }

      /**
       * Pipes
       */

      if (value === '|') {
        if (extglobs.length > 0) {
          extglobs[extglobs.length - 1].conditions++
        }
        push({
          type: 'text',
          value
        })
        continue
      }

      /**
       * Commas
       */

      if (value === ',') {
        let output = value
        const brace = braces[braces.length - 1]
        if (brace && stack[stack.length - 1] === 'braces') {
          brace.comma = true
          output = '|'
        }
        push({
          type: 'comma',
          value,
          output
        })
        continue
      }

      /**
       * Slashes
       */

      if (value === '/') {
        // if the beginning of the glob is "./", advance the start
        // to the current index, and don't add the "./" characters
        // to the state. This greatly simplifies lookbehinds when
        // checking for BOS characters like "!" and "." (not "./")
        if (prev.type === 'dot' && state.index === state.start + 1) {
          state.start = state.index + 1
          state.consumed = ''
          state.output = ''
          tokens.pop()
          prev = bos // reset "prev" to the first token
          continue
        }
        push({
          type: 'slash',
          value,
          output: SLASH_LITERAL
        })
        continue
      }

      /**
       * Dots
       */

      if (value === '.') {
        if (state.braces > 0 && prev.type === 'dot') {
          if (prev.value === '.') {
            prev.output = DOT_LITERAL
          }
          const brace = braces[braces.length - 1]
          prev.type = 'dots'
          prev.output += value
          prev.value += value
          brace.dots = true
          continue
        }
        if (
          state.braces + state.parens === 0 &&
          prev.type !== 'bos' &&
          prev.type !== 'slash'
        ) {
          push({
            type: 'text',
            value,
            output: DOT_LITERAL
          })
          continue
        }
        push({
          type: 'dot',
          value,
          output: DOT_LITERAL
        })
        continue
      }

      /**
       * Question marks
       */

      if (value === '?') {
        const isGroup = prev && prev.value === '('
        if (
          !isGroup &&
          opts.noextglob !== true &&
          peek() === '(' &&
          peek(2) !== '?'
        ) {
          extglobOpen('qmark', value)
          continue
        }
        if (prev && prev.type === 'paren') {
          const next = peek()
          let output = value
          if (
            (prev.value === '(' && !/[!=<:]/.test(next)) ||
            (next === '<' && !/<([!=]|\w+>)/.test(remaining()))
          ) {
            output = `\\${value}`
          }
          push({
            type: 'text',
            value,
            output
          })
          continue
        }
        if (
          opts.dot !== true &&
          (prev.type === 'slash' || prev.type === 'bos')
        ) {
          push({
            type: 'qmark',
            value,
            output: QMARK_NO_DOT
          })
          continue
        }
        push({
          type: 'qmark',
          value,
          output: QMARK
        })
        continue
      }

      /**
       * Exclamation
       */

      if (value === '!') {
        if (opts.noextglob !== true && peek() === '(') {
          if (peek(2) !== '?' || !/[!=<:]/.test(peek(3))) {
            extglobOpen('negate', value)
            continue
          }
        }
        if (opts.nonegate !== true && state.index === 0) {
          negate()
          continue
        }
      }

      /**
       * Plus
       */

      if (value === '+') {
        if (opts.noextglob !== true && peek() === '(' && peek(2) !== '?') {
          extglobOpen('plus', value)
          continue
        }
        if ((prev && prev.value === '(') || opts.regex === false) {
          push({
            type: 'plus',
            value,
            output: PLUS_LITERAL
          })
          continue
        }
        if (
          (prev &&
            (prev.type === 'bracket' ||
              prev.type === 'paren' ||
              prev.type === 'brace')) ||
          state.parens > 0
        ) {
          push({
            type: 'plus',
            value
          })
          continue
        }
        push({
          type: 'plus',
          value: PLUS_LITERAL
        })
        continue
      }

      /**
       * Plain text
       */

      if (value === '@') {
        if (opts.noextglob !== true && peek() === '(' && peek(2) !== '?') {
          push({
            type: 'at',
            extglob: true,
            value,
            output: ''
          })
          continue
        }
        push({
          type: 'text',
          value
        })
        continue
      }

      /**
       * Plain text
       */

      if (value !== '*') {
        if (value === '$' || value === '^') {
          value = `\\${value}`
        }
        const match = REGEX_NON_SPECIAL_CHARS.exec(remaining())
        if (match) {
          value += match[0]
          state.index += match[0].length
        }
        push({
          type: 'text',
          value
        })
        continue
      }

      /**
       * Stars
       */

      if (prev && (prev.type === 'globstar' || prev.star === true)) {
        prev.type = 'star'
        prev.star = true
        prev.value += value
        prev.output = star
        state.backtrack = true
        state.globstar = true
        consume(value)
        continue
      }
      let rest = remaining()
      if (opts.noextglob !== true && /^\([^?]/.test(rest)) {
        extglobOpen('star', value)
        continue
      }
      if (prev.type === 'star') {
        if (opts.noglobstar === true) {
          consume(value)
          continue
        }
        const prior = prev.prev
        const before = prior.prev
        const isStart = prior.type === 'slash' || prior.type === 'bos'
        const afterStar =
          before && (before.type === 'star' || before.type === 'globstar')
        if (opts.bash === true && (!isStart || (rest[0] && rest[0] !== '/'))) {
          push({
            type: 'star',
            value,
            output: ''
          })
          continue
        }
        const isBrace =
          state.braces > 0 && (prior.type === 'comma' || prior.type === 'brace')
        const isExtglob =
          extglobs.length && (prior.type === 'pipe' || prior.type === 'paren')
        if (!isStart && prior.type !== 'paren' && !isBrace && !isExtglob) {
          push({
            type: 'star',
            value,
            output: ''
          })
          continue
        }

        // strip consecutive `/**/`
        while (rest.slice(0, 3) === '/**') {
          const after = input[state.index + 4]
          if (after && after !== '/') {
            break
          }
          rest = rest.slice(3)
          consume('/**', 3)
        }
        if (prior.type === 'bos' && eos()) {
          prev.type = 'globstar'
          prev.value += value
          prev.output = globstar(opts)
          state.output = prev.output
          state.globstar = true
          consume(value)
          continue
        }
        if (
          prior.type === 'slash' &&
          prior.prev.type !== 'bos' &&
          !afterStar &&
          eos()
        ) {
          state.output = state.output.slice(
            0,
            -(prior.output + prev.output).length
          )
          prior.output = `(?:${prior.output}`
          prev.type = 'globstar'
          prev.output = globstar(opts) + (opts.strictSlashes ? ')' : '|$)')
          prev.value += value
          state.globstar = true
          state.output += prior.output + prev.output
          consume(value)
          continue
        }
        if (
          prior.type === 'slash' &&
          prior.prev.type !== 'bos' &&
          rest[0] === '/'
        ) {
          const end = rest[1] !== void 0 ? '|$' : ''
          state.output = state.output.slice(
            0,
            -(prior.output + prev.output).length
          )
          prior.output = `(?:${prior.output}`
          prev.type = 'globstar'
          prev.output = `${globstar(opts)}${SLASH_LITERAL}|${SLASH_LITERAL}${end})`
          prev.value += value
          state.output += prior.output + prev.output
          state.globstar = true
          consume(value + advance())
          push({
            type: 'slash',
            value: '/',
            output: ''
          })
          continue
        }
        if (prior.type === 'bos' && rest[0] === '/') {
          prev.type = 'globstar'
          prev.value += value
          prev.output = `(?:^|${SLASH_LITERAL}|${globstar(opts)}${SLASH_LITERAL})`
          state.output = prev.output
          state.globstar = true
          consume(value + advance())
          push({
            type: 'slash',
            value: '/',
            output: ''
          })
          continue
        }

        // remove single star from output
        state.output = state.output.slice(0, -prev.output.length)

        // reset previous token to globstar
        prev.type = 'globstar'
        prev.output = globstar(opts)
        prev.value += value

        // reset output with globstar
        state.output += prev.output
        state.globstar = true
        consume(value)
        continue
      }
      const token = {
        type: 'star',
        value,
        output: star
      }
      if (opts.bash === true) {
        token.output = '.*?'
        if (prev.type === 'bos' || prev.type === 'slash') {
          token.output = nodot + token.output
        }
        push(token)
        continue
      }
      if (
        prev &&
        (prev.type === 'bracket' || prev.type === 'paren') &&
        opts.regex === true
      ) {
        token.output = value
        push(token)
        continue
      }
      if (
        state.index === state.start ||
        prev.type === 'slash' ||
        prev.type === 'dot'
      ) {
        if (prev.type === 'dot') {
          state.output += NO_DOT_SLASH
          prev.output += NO_DOT_SLASH
        } else if (opts.dot === true) {
          state.output += NO_DOTS_SLASH
          prev.output += NO_DOTS_SLASH
        } else {
          state.output += nodot
          prev.output += nodot
        }
        if (peek() !== '*') {
          state.output += ONE_CHAR
          prev.output += ONE_CHAR
        }
      }
      push(token)
    }
    while (state.brackets > 0) {
      if (opts.strictBrackets === true) {
        throw new SyntaxError(syntaxError('closing', ']'))
      }
      state.output = utils.escapeLast(state.output, '[')
      decrement('brackets')
    }
    while (state.parens > 0) {
      if (opts.strictBrackets === true) {
        throw new SyntaxError(syntaxError('closing', ')'))
      }
      state.output = utils.escapeLast(state.output, '(')
      decrement('parens')
    }
    while (state.braces > 0) {
      if (opts.strictBrackets === true) {
        throw new SyntaxError(syntaxError('closing', '}'))
      }
      state.output = utils.escapeLast(state.output, '{')
      decrement('braces')
    }
    if (
      opts.strictSlashes !== true &&
      (prev.type === 'star' || prev.type === 'bracket')
    ) {
      push({
        type: 'maybe_slash',
        value: '',
        output: `${SLASH_LITERAL}?`
      })
    }

    // rebuild the output if we had to backtrack at any point
    if (state.backtrack === true) {
      state.output = ''
      for (const token of state.tokens) {
        state.output += token.output != null ? token.output : token.value
        if (token.suffix) {
          state.output += token.suffix
        }
      }
    }
    return state
  }

  /**
   * Fast paths for creating regular expressions for common glob patterns.
   * This can significantly speed up processing and has very little downside
   * impact when none of the fast paths match.
   */

  parse.fastpaths = (input, options) => {
    const opts = {
      ...options
    }
    const max =
      typeof opts.maxLength === 'number'
        ? Math.min(MAX_LENGTH, opts.maxLength)
        : MAX_LENGTH
    const len = input.length
    if (len > max) {
      throw new SyntaxError(
        `Input length: ${len}, exceeds maximum allowed length: ${max}`
      )
    }
    input = REPLACEMENTS[input] || input

    // create constants based on platform, for windows or posix
    const {
      DOT_LITERAL,
      SLASH_LITERAL,
      ONE_CHAR,
      DOTS_SLASH,
      NO_DOT,
      NO_DOTS,
      NO_DOTS_SLASH,
      STAR,
      START_ANCHOR
    } = constants.globChars(opts.windows)
    const nodot = opts.dot ? NO_DOTS : NO_DOT
    const slashDot = opts.dot ? NO_DOTS_SLASH : NO_DOT
    const capture = opts.capture ? '' : '?:'
    const state = {
      negated: false,
      prefix: ''
    }
    let star = opts.bash === true ? '.*?' : STAR
    if (opts.capture) {
      star = `(${star})`
    }
    const globstar = opts => {
      if (opts.noglobstar === true) {
        return star
      }
      return `(${capture}(?:(?!${START_ANCHOR}${opts.dot ? DOTS_SLASH : DOT_LITERAL}).)*?)`
    }
    const create = str => {
      switch (str) {
        case '*':
          return `${nodot}${ONE_CHAR}${star}`
        case '.*':
          return `${DOT_LITERAL}${ONE_CHAR}${star}`
        case '*.*':
          return `${nodot}${star}${DOT_LITERAL}${ONE_CHAR}${star}`
        case '*/*':
          return `${nodot}${star}${SLASH_LITERAL}${ONE_CHAR}${slashDot}${star}`
        case '**':
          return nodot + globstar(opts)
        case '**/*':
          return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${slashDot}${ONE_CHAR}${star}`
        case '**/*.*':
          return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${slashDot}${star}${DOT_LITERAL}${ONE_CHAR}${star}`
        case '**/.*':
          return `(?:${nodot}${globstar(opts)}${SLASH_LITERAL})?${DOT_LITERAL}${ONE_CHAR}${star}`
        default: {
          const match = /^(.*?)\.(\w+)$/.exec(str)
          if (!match) {
            return
          }
          const source = create(match[1])
          if (!source) {
            return
          }
          return source + DOT_LITERAL + match[2]
        }
      }
    }
    const output = utils.removePrefix(input, state)
    let source = create(output)
    if (source && opts.strictSlashes !== true) {
      source += `${SLASH_LITERAL}?`
    }
    return source
  }
  parse_1$3 = parse
  return parse_1$3
}

let picomatch_1$1
let hasRequiredPicomatch$1
function requirePicomatch$1() {
  if (hasRequiredPicomatch$1) {
    return picomatch_1$1
  }
  hasRequiredPicomatch$1 = 1
  const scan = /*@__PURE__*/ requireScan()
  const parse = /*@__PURE__*/ requireParse$3()
  const utils = /*@__PURE__*/ requireUtils()
  const constants = /*@__PURE__*/ requireConstants$2()
  const isObject = val => val && typeof val === 'object' && !Array.isArray(val)

  /**
   * Creates a matcher function from one or more glob patterns. The
   * returned function takes a string to match as its first argument,
   * and returns true if the string is a match. The returned matcher
   * function also takes a boolean as the second argument that, when true,
   * returns an object with additional information.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch(glob[, options]);
   *
   * const isMatch = picomatch('*.!(*a)');
   * console.log(isMatch('a.a')); //=> false
   * console.log(isMatch('a.b')); //=> true
   * ```
   * @name picomatch
   * @param {String|Array} `globs` One or more glob patterns.
   * @param {Object=} `options`
   * @return {Function=} Returns a matcher function.
   * @api public
   */

  const picomatch = (glob, options, returnState = false) => {
    if (Array.isArray(glob)) {
      const fns = glob.map(input => picomatch(input, options, returnState))
      const arrayMatcher = str => {
        for (const isMatch of fns) {
          const state = isMatch(str)
          if (state) {
            return state
          }
        }
        return false
      }
      return arrayMatcher
    }
    const isState = isObject(glob) && glob.tokens && glob.input
    if (glob === '' || (typeof glob !== 'string' && !isState)) {
      throw new TypeError('Expected pattern to be a non-empty string')
    }
    const opts = options || {}
    const posix = opts.windows
    const regex = isState
      ? picomatch.compileRe(glob, options)
      : picomatch.makeRe(glob, options, false, true)
    const state = regex.state
    delete regex.state
    let isIgnored = () => false
    if (opts.ignore) {
      const ignoreOpts = {
        ...options,
        ignore: null,
        onMatch: null,
        onResult: null
      }
      isIgnored = picomatch(opts.ignore, ignoreOpts, returnState)
    }
    const matcher = (input, returnObject = false) => {
      const { isMatch, match, output } = picomatch.test(input, regex, options, {
        glob,
        posix
      })
      const result = {
        glob,
        state,
        regex,
        posix,
        input,
        output,
        match,
        isMatch
      }
      if (typeof opts.onResult === 'function') {
        opts.onResult(result)
      }
      if (isMatch === false) {
        result.isMatch = false
        return returnObject ? result : false
      }
      if (isIgnored(input)) {
        if (typeof opts.onIgnore === 'function') {
          opts.onIgnore(result)
        }
        result.isMatch = false
        return returnObject ? result : false
      }
      if (typeof opts.onMatch === 'function') {
        opts.onMatch(result)
      }
      return returnObject ? result : true
    }
    if (returnState) {
      matcher.state = state
    }
    return matcher
  }

  /**
   * Test `input` with the given `regex`. This is used by the main
   * `picomatch()` function to test the input string.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch.test(input, regex[, options]);
   *
   * console.log(picomatch.test('foo/bar', /^(?:([^/]*?)\/([^/]*?))$/));
   * // { isMatch: true, match: [ 'foo/', 'foo', 'bar' ], output: 'foo/bar' }
   * ```
   * @param {String} `input` String to test.
   * @param {RegExp} `regex`
   * @return {Object} Returns an object with matching info.
   * @api public
   */

  picomatch.test = (input, regex, options, { glob, posix } = {}) => {
    if (typeof input !== 'string') {
      throw new TypeError('Expected input to be a string')
    }
    if (input === '') {
      return {
        isMatch: false,
        output: ''
      }
    }
    const opts = options || {}
    const format = opts.format || (posix ? utils.toPosixSlashes : null)
    let match = input === glob
    let output = match && format ? format(input) : input
    if (match === false) {
      output = format ? format(input) : input
      match = output === glob
    }
    if (match === false || opts.capture === true) {
      if (opts.matchBase === true || opts.basename === true) {
        match = picomatch.matchBase(input, regex, options, posix)
      } else {
        match = regex.exec(output)
      }
    }
    return {
      isMatch: Boolean(match),
      match,
      output
    }
  }

  /**
   * Match the basename of a filepath.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch.matchBase(input, glob[, options]);
   * console.log(picomatch.matchBase('foo/bar.js', '*.js'); // true
   * ```
   * @param {String} `input` String to test.
   * @param {RegExp|String} `glob` Glob pattern or regex created by [.makeRe](#makeRe).
   * @return {Boolean}
   * @api public
   */

  picomatch.matchBase = (input, glob, options) => {
    const regex =
      glob instanceof RegExp ? glob : picomatch.makeRe(glob, options)
    return regex.test(utils.basename(input))
  }

  /**
   * Returns true if **any** of the given glob `patterns` match the specified `string`.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch.isMatch(string, patterns[, options]);
   *
   * console.log(picomatch.isMatch('a.a', ['b.*', '*.a'])); //=> true
   * console.log(picomatch.isMatch('a.a', 'b.*')); //=> false
   * ```
   * @param {String|Array} str The string to test.
   * @param {String|Array} patterns One or more glob patterns to use for matching.
   * @param {Object} [options] See available [options](#options).
   * @return {Boolean} Returns true if any patterns match `str`
   * @api public
   */

  picomatch.isMatch = (str, patterns, options) =>
    picomatch(patterns, options)(str)

  /**
   * Parse a glob pattern to create the source string for a regular
   * expression.
   *
   * ```js
   * const picomatch = require('picomatch');
   * const result = picomatch.parse(pattern[, options]);
   * ```
   * @param {String} `pattern`
   * @param {Object} `options`
   * @return {Object} Returns an object with useful properties and output to be used as a regex source string.
   * @api public
   */

  picomatch.parse = (pattern, options) => {
    if (Array.isArray(pattern)) {
      return pattern.map(p => picomatch.parse(p, options))
    }
    return parse(pattern, {
      ...options,
      fastpaths: false
    })
  }

  /**
   * Scan a glob pattern to separate the pattern into segments.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch.scan(input[, options]);
   *
   * const result = picomatch.scan('!./foo/*.js');
   * console.log(result);
   * { prefix: '!./',
   *   input: '!./foo/*.js',
   *   start: 3,
   *   base: 'foo',
   *   glob: '*.js',
   *   isBrace: false,
   *   isBracket: false,
   *   isGlob: true,
   *   isExtglob: false,
   *   isGlobstar: false,
   *   negated: true }
   * ```
   * @param {String} `input` Glob pattern to scan.
   * @param {Object} `options`
   * @return {Object} Returns an object with
   * @api public
   */

  picomatch.scan = (input, options) => scan(input, options)

  /**
   * Compile a regular expression from the `state` object returned by the
   * [parse()](#parse) method.
   *
   * @param {Object} `state`
   * @param {Object} `options`
   * @param {Boolean} `returnOutput` Intended for implementors, this argument allows you to return the raw output from the parser.
   * @param {Boolean} `returnState` Adds the state to a `state` property on the returned regex. Useful for implementors and debugging.
   * @return {RegExp}
   * @api public
   */

  picomatch.compileRe = (
    state,
    options,
    returnOutput = false,
    returnState = false
  ) => {
    if (returnOutput === true) {
      return state.output
    }
    const opts = options || {}
    const prepend = opts.contains ? '' : '^'
    const append = opts.contains ? '' : '$'
    let source = `${prepend}(?:${state.output})${append}`
    if (state && state.negated === true) {
      source = `^(?!${source}).*$`
    }
    const regex = picomatch.toRegex(source, options)
    if (returnState === true) {
      regex.state = state
    }
    return regex
  }

  /**
   * Create a regular expression from a parsed glob pattern.
   *
   * ```js
   * const picomatch = require('picomatch');
   * const state = picomatch.parse('*.js');
   * // picomatch.compileRe(state[, options]);
   *
   * console.log(picomatch.compileRe(state));
   * //=> /^(?:(?!\.)(?=.)[^/]*?\.js)$/
   * ```
   * @param {String} `state` The object returned from the `.parse` method.
   * @param {Object} `options`
   * @param {Boolean} `returnOutput` Implementors may use this argument to return the compiled output, instead of a regular expression. This is not exposed on the options to prevent end-users from mutating the result.
   * @param {Boolean} `returnState` Implementors may use this argument to return the state from the parsed glob with the returned regular expression.
   * @return {RegExp} Returns a regex created from the given pattern.
   * @api public
   */

  picomatch.makeRe = (
    input,
    options = {},
    returnOutput = false,
    returnState = false
  ) => {
    if (!input || typeof input !== 'string') {
      throw new TypeError('Expected a non-empty string')
    }
    let parsed = {
      negated: false,
      fastpaths: true
    }
    if (options.fastpaths !== false && (input[0] === '.' || input[0] === '*')) {
      parsed.output = parse.fastpaths(input, options)
    }
    if (!parsed.output) {
      parsed = parse(input, options)
    }
    return picomatch.compileRe(parsed, options, returnOutput, returnState)
  }

  /**
   * Create a regular expression from the given regex source string.
   *
   * ```js
   * const picomatch = require('picomatch');
   * // picomatch.toRegex(source[, options]);
   *
   * const { output } = picomatch.parse('*.js');
   * console.log(picomatch.toRegex(output));
   * //=> /^(?:(?!\.)(?=.)[^/]*?\.js)$/
   * ```
   * @param {String} `source` Regular expression source string.
   * @param {Object} `options`
   * @return {RegExp}
   * @api public
   */

  picomatch.toRegex = (source, options) => {
    try {
      const opts = options || {}
      return new RegExp(source, opts.flags || (opts.nocase ? 'i' : ''))
    } catch (err) {
      if (options && options.debug === true) {
        throw err
      }
      return /$^/
    }
  }

  /**
   * Picomatch constants.
   * @return {Object}
   */

  picomatch.constants = constants

  /**
   * Expose "picomatch"
   */

  picomatch_1$1 = picomatch
  return picomatch_1$1
}

let picomatch_1
let hasRequiredPicomatch
function requirePicomatch() {
  if (hasRequiredPicomatch) {
    return picomatch_1
  }
  hasRequiredPicomatch = 1
  const pico = /*@__PURE__*/ requirePicomatch$1()
  const utils = /*@__PURE__*/ requireUtils()
  function picomatch(glob, options, returnState = false) {
    // default to os.platform()
    if (
      options &&
      (options.windows === null || options.windows === undefined)
    ) {
      // don't mutate the original options object
      options = {
        ...options,
        windows: utils.isWindows()
      }
    }
    return pico(glob, options, returnState)
  }
  Object.assign(picomatch, pico)
  picomatch_1 = picomatch
  return picomatch_1
}

let hasRequiredBuilder
function requireBuilder() {
  if (hasRequiredBuilder) {
    return builder
  }
  hasRequiredBuilder = 1
  Object.defineProperty(builder, '__esModule', {
    value: true
  })
  builder.Builder = void 0
  const path_1 = require$$0$5
  const api_builder_1 = requireApiBuilder()
  let pm = null
  /* c8 ignore next 6 */
  try {
    require.resolve('picomatch')
    pm = /*@__PURE__*/ requirePicomatch()
  } catch (_e) {
    // do nothing
  }
  class Builder {
    globCache = {}
    options = {
      maxDepth: Infinity,
      suppressErrors: true,
      pathSeparator: path_1.sep,
      filters: []
    }
    globFunction
    constructor(options) {
      this.options = {
        ...this.options,
        ...options
      }
      this.globFunction = this.options.globFunction
    }
    group() {
      this.options.group = true
      return this
    }
    withPathSeparator(separator) {
      this.options.pathSeparator = separator
      return this
    }
    withBasePath() {
      this.options.includeBasePath = true
      return this
    }
    withRelativePaths() {
      this.options.relativePaths = true
      return this
    }
    withDirs() {
      this.options.includeDirs = true
      return this
    }
    withMaxDepth(depth) {
      this.options.maxDepth = depth
      return this
    }
    withMaxFiles(limit) {
      this.options.maxFiles = limit
      return this
    }
    withFullPaths() {
      this.options.resolvePaths = true
      this.options.includeBasePath = true
      return this
    }
    withErrors() {
      this.options.suppressErrors = false
      return this
    }
    withSymlinks({ resolvePaths = true } = {}) {
      this.options.resolveSymlinks = true
      this.options.useRealPaths = resolvePaths
      return this.withFullPaths()
    }
    withAbortSignal(signal) {
      this.options.signal = signal
      return this
    }
    normalize() {
      this.options.normalizePath = true
      return this
    }
    filter(predicate) {
      this.options.filters.push(predicate)
      return this
    }
    onlyDirs() {
      this.options.excludeFiles = true
      this.options.includeDirs = true
      return this
    }
    exclude(predicate) {
      this.options.exclude = predicate
      return this
    }
    onlyCounts() {
      this.options.onlyCounts = true
      return this
    }
    crawl(root) {
      return new api_builder_1.APIBuilder(root || '.', this.options)
    }
    withGlobFunction(fn) {
      // cast this since we don't have the new type params yet
      this.globFunction = fn
      return this
    }
    /**
     * @deprecated Pass options using the constructor instead:
     * ```ts
     * new fdir(options).crawl("/path/to/root");
     * ```
     * This method will be removed in v7.0
     */
    /* c8 ignore next 4 */
    crawlWithOptions(root, options) {
      this.options = {
        ...this.options,
        ...options
      }
      return new api_builder_1.APIBuilder(root || '.', this.options)
    }
    glob(...patterns) {
      if (this.globFunction) {
        return this.globWithOptions(patterns)
      }
      return this.globWithOptions(patterns, {
        dot: true
      })
    }
    globWithOptions(patterns, ...options) {
      const globFn = this.globFunction || pm
      /* c8 ignore next 5 */
      if (!globFn) {
        throw new Error('Please specify a glob function to use glob matching.')
      }
      let isMatch = this.globCache[patterns.join('\0')]
      if (!isMatch) {
        isMatch = globFn(patterns, ...options)
        this.globCache[patterns.join('\0')] = isMatch
      }
      this.options.filters.push(path => isMatch(path))
      return this
    }
  }
  builder.Builder = Builder
  return builder
}

const types = {}

let hasRequiredTypes
function requireTypes() {
  if (hasRequiredTypes) {
    return types
  }
  hasRequiredTypes = 1
  Object.defineProperty(types, '__esModule', {
    value: true
  })
  return types
}

let hasRequiredDist$3
function requireDist$3() {
  if (hasRequiredDist$3) {
    return dist$3
  }
  hasRequiredDist$3 = 1
  ;(function (exports) {
    const __createBinding =
      (this && this.__createBinding) ||
      (Object.create
        ? function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            let desc = Object.getOwnPropertyDescriptor(m, k)
            if (
              !desc ||
              ('get' in desc
                ? !m.__esModule
                : desc.writable || desc.configurable)
            ) {
              desc = {
                enumerable: true,
                get: function () {
                  return m[k]
                }
              }
            }
            Object.defineProperty(o, k2, desc)
          }
        : function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            o[k2] = m[k]
          })
    const __exportStar =
      (this && this.__exportStar) ||
      function (m, exports) {
        for (const p in m) {
          if (
            p !== 'default' &&
            !Object.prototype.hasOwnProperty.call(exports, p)
          )
            __createBinding(exports, m, p)
        }
      }
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.fdir = void 0
    const builder_1 = requireBuilder()
    Object.defineProperty(exports, 'fdir', {
      enumerable: true,
      get: function () {
        return builder_1.Builder
      }
    })
    __exportStar(requireTypes(), exports)
  })(dist$3)
  return dist$3
}

let dist$2
let hasRequiredDist$2
function requireDist$2() {
  if (hasRequiredDist$2) {
    return dist$2
  }
  hasRequiredDist$2 = 1
  const __create = Object.create
  const __defProp = Object.defineProperty
  const __getOwnPropDesc = Object.getOwnPropertyDescriptor
  const __getOwnPropNames = Object.getOwnPropertyNames
  const __getProtoOf = Object.getPrototypeOf
  const __hasOwnProp = Object.prototype.hasOwnProperty
  const __export = (target, all) => {
    for (const name in all) {
      __defProp(target, name, {
        get: all[name],
        enumerable: true
      })
    }
  }
  const __copyProps = (to, from, except, desc) => {
    if ((from && typeof from === 'object') || typeof from === 'function') {
      for (let key of __getOwnPropNames(from)) {
        if (!__hasOwnProp.call(to, key) && key !== except)
          __defProp(to, key, {
            get: () => from[key],
            enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
          })
      }
    }
    return to
  }
  const __toESM = (mod, isNodeMode, target) => (
    (target = mod != null ? __create(__getProtoOf(mod)) : {}),
    __copyProps(
      // If the importer is in node compatibility mode or this is not an ESM
      // file that has been converted to a CommonJS file using a Babel-
      // compatible transform (i.e. "__esModule" has not been set), then set
      // "default" to the CommonJS "module.exports" for node compatibility.
      !mod || !mod.__esModule
        ? __defProp(target, 'default', {
            value: mod,
            enumerable: true
          })
        : target,
      mod
    )
  )
  const __toCommonJS = mod =>
    __copyProps(
      __defProp({}, '__esModule', {
        value: true
      }),
      mod
    )

  // src/index.ts
  const index_exports = {}
  __export(index_exports, {
    convertPathToPattern: () => convertPathToPattern,
    escapePath: () => escapePath,
    glob: () => glob,
    globSync: () => globSync,
    isDynamicPattern: () => isDynamicPattern
  })
  dist$2 = __toCommonJS(index_exports)
  const import_node_path = __toESM(require$$0$5)
  const import_fdir = requireDist$3()
  const import_picomatch2 = __toESM(/*@__PURE__*/ requirePicomatch())

  // src/utils.ts
  const import_picomatch = __toESM(/*@__PURE__*/ requirePicomatch())
  const ONLY_PARENT_DIRECTORIES = /^(\/?\.\.)+$/
  function getPartialMatcher(patterns, options) {
    const patternsCount = patterns.length
    const patternsParts = Array(patternsCount)
    const regexes = Array(patternsCount)
    for (let i = 0; i < patternsCount; i++) {
      const parts = splitPattern(patterns[i])
      patternsParts[i] = parts
      const partsCount = parts.length
      const partRegexes = Array(partsCount)
      for (let j = 0; j < partsCount; j++) {
        partRegexes[j] = import_picomatch.default.makeRe(parts[j], options)
      }
      regexes[i] = partRegexes
    }
    return input => {
      const inputParts = input.split('/')
      if (inputParts[0] === '..' && ONLY_PARENT_DIRECTORIES.test(input)) {
        return true
      }
      for (let i = 0; i < patterns.length; i++) {
        const patternParts = patternsParts[i]
        const regex = regexes[i]
        const inputPatternCount = inputParts.length
        const minParts = Math.min(inputPatternCount, patternParts.length)
        let j = 0
        while (j < minParts) {
          const part = patternParts[j]
          if (part.includes('/')) {
            return true
          }
          const match = regex[j].test(inputParts[j])
          if (!match) {
            break
          }
          if (part === '**') {
            return true
          }
          j++
        }
        if (j === inputPatternCount) {
          return true
        }
      }
      return false
    }
  }
  const splitPatternOptions = {
    parts: true
  }
  function splitPattern(path2) {
    let _a
    const result = import_picomatch.default.scan(path2, splitPatternOptions)
    return ((_a = result.parts) == null ? void 0 : _a.length)
      ? result.parts
      : [path2]
  }
  const isWin = process.platform === 'win32'
  const ESCAPED_WIN32_BACKSLASHES = /\\(?![()[\]{}!+@])/g
  function convertPosixPathToPattern(path2) {
    return escapePosixPath(path2)
  }
  function convertWin32PathToPattern(path2) {
    return escapeWin32Path(path2).replace(ESCAPED_WIN32_BACKSLASHES, '/')
  }
  const convertPathToPattern = isWin
    ? convertWin32PathToPattern
    : convertPosixPathToPattern
  const POSIX_UNESCAPED_GLOB_SYMBOLS =
    /(?<!\\)([()[\]{}*?|]|^!|[!+@](?=\()|\\(?![()[\]{}!*+?@|]))/g
  const WIN32_UNESCAPED_GLOB_SYMBOLS = /(?<!\\)([()[\]{}]|^!|[!+@](?=\())/g
  const escapePosixPath = path2 =>
    path2.replace(POSIX_UNESCAPED_GLOB_SYMBOLS, '\\$&')
  const escapeWin32Path = path2 =>
    path2.replace(WIN32_UNESCAPED_GLOB_SYMBOLS, '\\$&')
  const escapePath = isWin ? escapeWin32Path : escapePosixPath
  function isDynamicPattern(pattern, options) {
    if ((options == null ? void 0 : options.caseSensitiveMatch) === false) {
      return true
    }
    const scan = import_picomatch.default.scan(pattern)
    return scan.isGlob || scan.negated
  }
  function log(...tasks) {
    console.log(
      `[tinyglobby ${(/* @__PURE__ */ new Date()).toLocaleTimeString('es')}]`,
      ...tasks
    )
  }

  // src/index.ts
  const PARENT_DIRECTORY = /^(\/?\.\.)+/
  const ESCAPING_BACKSLASHES = /\\(?=[()[\]{}!*+?@|])/g
  const BACKSLASHES = /\\/g
  function normalizePattern(pattern, expandDirectories, cwd, props, isIgnore) {
    let _a
    let result = pattern
    if (pattern.endsWith('/')) {
      result = pattern.slice(0, -1)
    }
    if (!result.endsWith('*') && expandDirectories) {
      result += '/**'
    }
    if (
      import_node_path.default.isAbsolute(
        result.replace(ESCAPING_BACKSLASHES, '')
      )
    ) {
      result = import_node_path.posix.relative(escapePath(cwd), result)
    } else {
      result = import_node_path.posix.normalize(result)
    }
    const parentDirectoryMatch = PARENT_DIRECTORY.exec(result)
    if (parentDirectoryMatch == null ? void 0 : parentDirectoryMatch[0]) {
      const potentialRoot = import_node_path.posix.join(
        cwd,
        parentDirectoryMatch[0]
      )
      if (props.root.length > potentialRoot.length) {
        props.root = potentialRoot
        props.depthOffset = -(parentDirectoryMatch[0].length + 1) / 3
      }
    } else if (!isIgnore && props.depthOffset >= 0) {
      const parts = splitPattern(result)
      ;(_a = props.commonPath) != null ? _a : (props.commonPath = parts)
      const newCommonPath = []
      const length = Math.min(props.commonPath.length, parts.length)
      for (let i = 0; i < length; i++) {
        const part = parts[i]
        if (part === '**' && !parts[i + 1]) {
          newCommonPath.pop()
          break
        }
        if (
          part !== props.commonPath[i] ||
          isDynamicPattern(part) ||
          i === parts.length - 1
        ) {
          break
        }
        newCommonPath.push(part)
      }
      props.depthOffset = newCommonPath.length
      props.commonPath = newCommonPath
      props.root =
        newCommonPath.length > 0
          ? import_node_path.default.posix.join(cwd, ...newCommonPath)
          : cwd
    }
    return result
  }
  function processPatterns(
    { patterns, ignore = [], expandDirectories = true },
    cwd,
    props
  ) {
    if (typeof patterns === 'string') {
      patterns = [patterns]
    } else if (!patterns) {
      patterns = ['**/*']
    }
    if (typeof ignore === 'string') {
      ignore = [ignore]
    }
    const matchPatterns = []
    const ignorePatterns = []
    for (const pattern of ignore) {
      if (!pattern) {
        continue
      }
      if (pattern[0] !== '!' || pattern[1] === '(') {
        ignorePatterns.push(
          normalizePattern(pattern, expandDirectories, cwd, props, true)
        )
      }
    }
    for (const pattern of patterns) {
      if (!pattern) {
        continue
      }
      if (pattern[0] !== '!' || pattern[1] === '(') {
        matchPatterns.push(
          normalizePattern(pattern, expandDirectories, cwd, props, false)
        )
      } else if (pattern[1] !== '!' || pattern[2] === '(') {
        ignorePatterns.push(
          normalizePattern(
            pattern.slice(1),
            expandDirectories,
            cwd,
            props,
            true
          )
        )
      }
    }
    return {
      match: matchPatterns,
      ignore: ignorePatterns
    }
  }
  function getRelativePath(path2, cwd, root) {
    return import_node_path.posix.relative(cwd, `${root}/${path2}`) || '.'
  }
  function processPath(path2, cwd, root, isDirectory, absolute) {
    const relativePath = absolute
      ? path2.slice(root === '/' ? 1 : root.length + 1) || '.'
      : path2
    if (root === cwd) {
      return isDirectory && relativePath !== '.'
        ? relativePath.slice(0, -1)
        : relativePath
    }
    return getRelativePath(relativePath, cwd, root)
  }
  function formatPaths(paths, cwd, root) {
    for (let i = paths.length - 1; i >= 0; i--) {
      const path2 = paths[i]
      paths[i] =
        getRelativePath(path2, cwd, root) +
        (!path2 || path2.endsWith('/') ? '/' : '')
    }
    return paths
  }
  function crawl(options, cwd, sync) {
    if (process.env.TINYGLOBBY_DEBUG) {
      options.debug = true
    }
    if (options.debug) {
      log('globbing with options:', options, 'cwd:', cwd)
    }
    if (Array.isArray(options.patterns) && options.patterns.length === 0) {
      return sync ? [] : Promise.resolve([])
    }
    const props = {
      root: cwd,
      commonPath: null,
      depthOffset: 0
    }
    const processed = processPatterns(options, cwd, props)
    const nocase = options.caseSensitiveMatch === false
    if (options.debug) {
      log('internal processing patterns:', processed)
    }
    const matcher = (0, import_picomatch2.default)(processed.match, {
      dot: options.dot,
      nocase,
      ignore: processed.ignore
    })
    const ignore = (0, import_picomatch2.default)(processed.ignore, {
      dot: options.dot,
      nocase
    })
    const partialMatcher = getPartialMatcher(processed.match, {
      dot: options.dot,
      nocase
    })
    const fdirOptions = {
      // use relative paths in the matcher
      filters: [
        options.debug
          ? (p, isDirectory) => {
              const path2 = processPath(
                p,
                cwd,
                props.root,
                isDirectory,
                options.absolute
              )
              const matches = matcher(path2)
              if (matches) {
                log(`matched ${path2}`)
              }
              return matches
            }
          : (p, isDirectory) =>
              matcher(
                processPath(p, cwd, props.root, isDirectory, options.absolute)
              )
      ],
      exclude: options.debug
        ? (_, p) => {
            const relativePath = processPath(p, cwd, props.root, true, true)
            const skipped =
              (relativePath !== '.' && !partialMatcher(relativePath)) ||
              ignore(relativePath)
            if (skipped) {
              log(`skipped ${p}`)
            } else {
              log(`crawling ${p}`)
            }
            return skipped
          }
        : (_, p) => {
            const relativePath = processPath(p, cwd, props.root, true, true)
            return (
              (relativePath !== '.' && !partialMatcher(relativePath)) ||
              ignore(relativePath)
            )
          },
      pathSeparator: '/',
      relativePaths: true,
      resolveSymlinks: true
    }
    if (options.deep) {
      fdirOptions.maxDepth = Math.round(options.deep - props.depthOffset)
    }
    if (options.absolute) {
      fdirOptions.relativePaths = false
      fdirOptions.resolvePaths = true
      fdirOptions.includeBasePath = true
    }
    if (options.followSymbolicLinks === false) {
      fdirOptions.resolveSymlinks = false
      fdirOptions.excludeSymlinks = true
    }
    if (options.onlyDirectories) {
      fdirOptions.excludeFiles = true
      fdirOptions.includeDirs = true
    } else if (options.onlyFiles === false) {
      fdirOptions.includeDirs = true
    }
    props.root = props.root.replace(BACKSLASHES, '')
    const root = props.root
    if (options.debug) {
      log('internal properties:', props)
    }
    const api = new import_fdir.fdir(fdirOptions).crawl(root)
    if (cwd === root || options.absolute) {
      return sync ? api.sync() : api.withPromise()
    }
    return sync
      ? formatPaths(api.sync(), cwd, root)
      : api.withPromise().then(paths => formatPaths(paths, cwd, root))
  }
  async function glob(patternsOrOptions, options) {
    if (patternsOrOptions && (options == null ? void 0 : options.patterns)) {
      throw new Error('Cannot pass patterns as both an argument and an option')
    }
    const opts =
      Array.isArray(patternsOrOptions) || typeof patternsOrOptions === 'string'
        ? {
            ...options,
            patterns: patternsOrOptions
          }
        : patternsOrOptions
    const cwd = opts.cwd
      ? import_node_path.default.resolve(opts.cwd).replace(BACKSLASHES, '/')
      : process.cwd().replace(BACKSLASHES, '/')
    return crawl(opts, cwd, false)
  }
  function globSync(patternsOrOptions, options) {
    if (patternsOrOptions && (options == null ? void 0 : options.patterns)) {
      throw new Error('Cannot pass patterns as both an argument and an option')
    }
    const opts =
      Array.isArray(patternsOrOptions) || typeof patternsOrOptions === 'string'
        ? {
            ...options,
            patterns: patternsOrOptions
          }
        : patternsOrOptions
    const cwd = opts.cwd
      ? import_node_path.default.resolve(opts.cwd).replace(BACKSLASHES, '/')
      : process.cwd().replace(BACKSLASHES, '/')
    return crawl(opts, cwd, true)
  }
  return dist$2
}

const distExports$2 = /*@__PURE__*/ requireDist$2()

const distExports$1 = requireDist$4()

let yoctocolorsCjs
let hasRequiredYoctocolorsCjs
function requireYoctocolorsCjs() {
  if (hasRequiredYoctocolorsCjs) {
    return yoctocolorsCjs
  }
  hasRequiredYoctocolorsCjs = 1
  const tty = require$$0$7

  // eslint-disable-next-line no-warning-comments
  // TODO: Use a better method when it's added to Node.js (https://github.com/nodejs/node/pull/40240)
  // Lots of optionals here to support Deno.
  const hasColors = tty?.WriteStream?.prototype?.hasColors?.() ?? false
  const format = (open, close) => {
    if (!hasColors) {
      return input => input
    }
    const openCode = `\u001B[${open}m`
    const closeCode = `\u001B[${close}m`
    return input => {
      const string = input + '' // eslint-disable-line no-implicit-coercion -- This is faster.
      let index = string.indexOf(closeCode)
      if (index === -1) {
        // Note: Intentionally not using string interpolation for performance reasons.
        return openCode + string + closeCode
      }

      // Handle nested colors.

      // We could have done this, but it's too slow (as of Node.js 22).
      // return openCode + string.replaceAll(closeCode, openCode) + closeCode;

      let result = openCode
      let lastIndex = 0
      while (index !== -1) {
        result += string.slice(lastIndex, index) + openCode
        lastIndex = index + closeCode.length
        index = string.indexOf(closeCode, lastIndex)
      }
      result += string.slice(lastIndex) + closeCode
      return result
    }
  }
  const colors = {}
  colors.reset = format(0, 0)
  colors.bold = format(1, 22)
  colors.dim = format(2, 22)
  colors.italic = format(3, 23)
  colors.underline = format(4, 24)
  colors.overline = format(53, 55)
  colors.inverse = format(7, 27)
  colors.hidden = format(8, 28)
  colors.strikethrough = format(9, 29)
  colors.black = format(30, 39)
  colors.red = format(31, 39)
  colors.green = format(32, 39)
  colors.yellow = format(33, 39)
  colors.blue = format(34, 39)
  colors.magenta = format(35, 39)
  colors.cyan = format(36, 39)
  colors.white = format(37, 39)
  colors.gray = format(90, 39)
  colors.bgBlack = format(40, 49)
  colors.bgRed = format(41, 49)
  colors.bgGreen = format(42, 49)
  colors.bgYellow = format(43, 49)
  colors.bgBlue = format(44, 49)
  colors.bgMagenta = format(45, 49)
  colors.bgCyan = format(46, 49)
  colors.bgWhite = format(47, 49)
  colors.bgGray = format(100, 49)
  colors.redBright = format(91, 39)
  colors.greenBright = format(92, 39)
  colors.yellowBright = format(93, 39)
  colors.blueBright = format(94, 39)
  colors.magentaBright = format(95, 39)
  colors.cyanBright = format(96, 39)
  colors.whiteBright = format(97, 39)
  colors.bgRedBright = format(101, 49)
  colors.bgGreenBright = format(102, 49)
  colors.bgYellowBright = format(103, 49)
  colors.bgBlueBright = format(104, 49)
  colors.bgMagentaBright = format(105, 49)
  colors.bgCyanBright = format(106, 49)
  colors.bgWhiteBright = format(107, 49)
  yoctocolorsCjs = colors
  return yoctocolorsCjs
}

const yoctocolorsCjsExports = /*@__PURE__*/ requireYoctocolorsCjs()

let hpagent
let hasRequiredHpagent
function requireHpagent() {
  if (hasRequiredHpagent) {
    return hpagent
  }
  hasRequiredHpagent = 1
  const https = require$$0$8
  const http = require$$1$5
  const { URL } = require$$2$1
  class HttpProxyAgent extends http.Agent {
    constructor(options) {
      const { proxy, proxyRequestOptions, ...opts } = options
      super(opts)
      this.proxy = typeof proxy === 'string' ? new URL(proxy) : proxy
      this.proxyRequestOptions = proxyRequestOptions || {}
    }
    createConnection(options, callback) {
      const requestOptions = {
        ...this.proxyRequestOptions,
        method: 'CONNECT',
        host: this.proxy.hostname,
        port: this.proxy.port,
        path: `${options.host}:${options.port}`,
        setHost: false,
        headers: {
          ...this.proxyRequestOptions.headers,
          connection: this.keepAlive ? 'keep-alive' : 'close',
          host: `${options.host}:${options.port}`
        },
        agent: false,
        timeout: options.timeout || 0
      }
      if (this.proxy.username || this.proxy.password) {
        const base64 = Buffer.from(
          `${decodeURIComponent(this.proxy.username || '')}:${decodeURIComponent(this.proxy.password || '')}`
        ).toString('base64')
        requestOptions.headers['proxy-authorization'] = `Basic ${base64}`
      }
      if (this.proxy.protocol === 'https:') {
        requestOptions.servername = this.proxy.hostname
      }
      const request = (this.proxy.protocol === 'http:' ? http : https).request(
        requestOptions
      )
      request.once('connect', (response, socket, head) => {
        request.removeAllListeners()
        socket.removeAllListeners()
        if (response.statusCode === 200) {
          callback(null, socket)
        } else {
          socket.destroy()
          callback(new Error(`Bad response: ${response.statusCode}`), null)
        }
      })
      request.once('timeout', () => {
        request.destroy(new Error('Proxy timeout'))
      })
      request.once('error', err => {
        request.removeAllListeners()
        callback(err, null)
      })
      request.end()
    }
  }
  class HttpsProxyAgent extends https.Agent {
    constructor(options) {
      const { proxy, proxyRequestOptions, ...opts } = options
      super(opts)
      this.proxy = typeof proxy === 'string' ? new URL(proxy) : proxy
      this.proxyRequestOptions = proxyRequestOptions || {}
    }
    createConnection(options, callback) {
      const requestOptions = {
        ...this.proxyRequestOptions,
        method: 'CONNECT',
        host: this.proxy.hostname,
        port: this.proxy.port,
        path: `${options.host}:${options.port}`,
        setHost: false,
        headers: {
          ...this.proxyRequestOptions.headers,
          connection: this.keepAlive ? 'keep-alive' : 'close',
          host: `${options.host}:${options.port}`
        },
        agent: false,
        timeout: options.timeout || 0
      }
      if (this.proxy.username || this.proxy.password) {
        const base64 = Buffer.from(
          `${decodeURIComponent(this.proxy.username || '')}:${decodeURIComponent(this.proxy.password || '')}`
        ).toString('base64')
        requestOptions.headers['proxy-authorization'] = `Basic ${base64}`
      }

      // Necessary for the TLS check with the proxy to succeed.
      if (this.proxy.protocol === 'https:') {
        requestOptions.servername = this.proxy.hostname
      }
      const request = (this.proxy.protocol === 'http:' ? http : https).request(
        requestOptions
      )
      request.once('connect', (response, socket, head) => {
        request.removeAllListeners()
        socket.removeAllListeners()
        if (response.statusCode === 200) {
          const secureSocket = super.createConnection({
            ...options,
            socket
          })
          callback(null, secureSocket)
        } else {
          socket.destroy()
          callback(new Error(`Bad response: ${response.statusCode}`), null)
        }
      })
      request.once('timeout', () => {
        request.destroy(new Error('Proxy timeout'))
      })
      request.once('error', err => {
        request.removeAllListeners()
        callback(err, null)
      })
      request.end()
    }
  }
  hpagent = {
    HttpProxyAgent,
    HttpsProxyAgent
  }
  return hpagent
}

const hpagentExports = requireHpagent()

hpagentExports.HttpProxyAgent
const HttpsProxyAgent = hpagentExports.HttpsProxyAgent

let isInteractive
let hasRequiredIsInteractive

function requireIsInteractive() {
  if (hasRequiredIsInteractive) {
    return isInteractive
  }
  hasRequiredIsInteractive = 1

  let _process
  function getProcess() {
    if (_process === undefined) {
      // Use non-'node:' prefixed require to avoid Webpack errors.
      // eslint-disable-next-line n/prefer-node-protocol
      _process = require$$0$9
    }
    return _process
  }

  isInteractive = function isInteractive({
    stream = getProcess().stdout
  } = {}) {
    if (!(stream && stream.isTTY)) {
      return false
    }
    const { env } = getProcess()
    return env.TERM !== 'dumb' && !('CI' in env)
  }
  return isInteractive
}

const isInteractiveExports = /*@__PURE__*/ requireIsInteractive()

const dist$1 = {}

const name = '@socketsecurity/sdk'
const version = '1.4.32'
const license = 'MIT'
const description = 'SDK for the Socket API client'
const author = {
  name: 'Socket Inc',
  email: 'eng@socket.dev',
  url: 'https://socket.dev'
}
const homepage = 'https://github.com/SocketDev/socket-sdk-js'
const repository = {
  type: 'git',
  url: 'git://github.com/SocketDev/socket-sdk-js.git'
}
const type$1 = 'module'
const exports$1 = {
  '.': {
    node: {
      'module-sync': {
        types: './dist/index.d.mts',
        default: './dist/index.js'
      },
      default: {
        types: './dist/index.d.cts',
        default: './dist/index.cjs'
      }
    },
    default: {
      types: './dist/index.d.mts',
      default: './dist/index.js'
    }
  },
  './dist/index.cjs': {
    types: './dist/index.d.cts',
    default: './dist/index.cjs'
  },
  './dist/index.d.cts': './dist/index.d.cts',
  './dist/index.d.mts': './dist/index.d.mts',
  './types/api-helpers': './types/api-helpers.d.ts',
  './types/api-helpers.d.ts': './types/api-helpers.d.ts',
  './types/api': './types/api.d.ts',
  './types/api.d.ts': './types/api.d.ts',
  './package.json': './package.json'
}
const scripts = {
  build:
    'npm run clean && run-p -c --aggregate-output build:* && run-p -c --aggregate-output build:clean:*',
  'build:cjs': 'tsc',
  'build:esm': 'tsc -p tsconfig.esm.json',
  'build:clean:cjs': 'node scripts/rename-dist-cjs-files.mjs',
  'build:clean:esm': 'node scripts/rename-dist-esm-files.mjs',
  check: 'run-p -c --aggregate-output check:*',
  'check:lint': 'eslint --report-unused-disable-directives .',
  'check:lint:fix': 'npm run check:lint -- --fix',
  'check:tsc': 'tsc',
  coverage: 'run-s coverage:*',
  'coverage:test': 'run-s test:prepare test:unit:coverage',
  'coverage:type': 'type-coverage --detail',
  clean: 'run-p -c --aggregate-output clean:*',
  'clean:dist': "del-cli 'dist'",
  'clean:declarations': "del-cli '*.d.ts' '!api*.d.ts'",
  fix: 'run-s lint:fix check:lint:fix',
  'generate-sdk': 'run-s generate-sdk:*',
  'generate-sdk:01-prettify': 'node scripts/prettify-base-json.mjs',
  'generate-sdk:02-generate':
    'node scripts/generate-types.mjs > types/api.d.ts',
  'generate-sdk:03-clean-api': 'npm run fix && npm run fix',
  'knip:dependencies': 'knip --dependencies',
  'knip:exports': 'knip --include exports,duplicates',
  lint: 'oxlint -c=./.oxlintrc.json --ignore-path=./.oxlintignore --tsconfig=./tsconfig.json .',
  'lint:fix': 'npm run lint -- --fix && npm run lint:fix:fast',
  'lint:fix:fast': 'biome format --write',
  'lint-staged': 'lint-staged',
  precommit: 'lint-staged',
  prepare: 'husky',
  prepublishOnly: 'run-s build',
  test: 'run-s check test:*',
  'test:prepare': 'cross-env VITEST=1 npm run build',
  'test:unit': 'vitest --run',
  'test:unit:update': 'vitest --run --update',
  'test:unit:coverage': 'vitest run --coverage',
  'test-ci': 'run-s build test:*',
  update: 'run-p --aggregate-output update:**',
  'update:deps': 'npx --yes npm-check-updates'
}
const dependencies = {
  '@socketsecurity/registry': '1.0.160'
}
const devDependencies = {
  '@biomejs/biome': '1.9.4',
  '@eslint/compat': '1.2.9',
  '@eslint/js': '9.26.0',
  '@types/node': '22.15.14',
  '@typescript-eslint/parser': '8.32.0',
  '@vitest/coverage-v8': '3.1.3',
  'cross-env': '7.0.3',
  'del-cli': '6.0.0',
  eslint: '9.26.0',
  'eslint-import-resolver-typescript': '4.3.4',
  'eslint-plugin-import-x': '4.11.0',
  'eslint-plugin-jsdoc': '50.6.11',
  'eslint-plugin-n': '17.17.0',
  'eslint-plugin-sort-destructure-keys': '2.0.0',
  'eslint-plugin-unicorn': '56.0.1',
  globals: '16.0.0',
  husky: '9.1.7',
  knip: '5.54.1',
  'lint-staged': '15.5.2',
  nock: '14.0.4',
  'npm-run-all2': '8.0.1',
  'openapi-typescript': '6.7.6',
  oxlint: '0.16.9',
  'type-coverage': '2.29.7',
  typescript: '~5.8.3',
  'typescript-eslint': '8.32.0',
  vitest: '3.1.3'
}
const overrides = {
  vite: '6.3.5'
}
const engines = {
  node: '18.20.7 || ^20.18.3 || >=22.14.0'
}
const files = ['dist/**', 'types/**']
const require$$7$2 = {
  name: name,
  version: version,
  license: license,
  description: description,
  author: author,
  homepage: homepage,
  repository: repository,
  type: type$1,
  exports: exports$1,
  scripts: scripts,
  dependencies: dependencies,
  devDependencies: devDependencies,
  overrides: overrides,
  engines: engines,
  files: files,
  'lint-staged': {
    '*.{cjs,js,json,md,mjs,mts,ts}': [
      'npm run lint -- --fix',
      'npm run lint:fix:fast -- --no-errors-on-unmatched --files-ignore-unknown=true --colors=off'
    ]
  }
}

let hasRequiredDist$1

function requireDist$1() {
  if (hasRequiredDist$1) {
    return dist$1
  }
  hasRequiredDist$1 = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule ? mod : { default: mod }
    }
  Object.defineProperty(dist$1, '__esModule', { value: true })
  dist$1.SocketSdk = void 0
  dist$1.createUserAgentFromPkgJson = createUserAgentFromPkgJson
  const node_events_1 = __importDefault(require$$0$a)
  const node_fs_1 = fs$1
  const node_http_1 = __importDefault(require$$2$2)
  const node_https_1 = __importDefault(require$$3$2)
  const node_path_1 = __importDefault(path$1)
  const node_readline_1 = __importDefault(require$$5)
  const abort_signal_1 = __importDefault(require$$6$1)
  // @ts-ignore
  const package_json_1 = __importDefault(require$$7$2)
  const DEFAULT_USER_AGENT = createUserAgentFromPkgJson(package_json_1.default)
  class ResponseError extends Error {
    response
    constructor(response, message = '') {
      const statusCode = response.statusCode ?? 'unknown'
      const statusMessage = response.statusMessage ?? 'No status message'
      super(
        `Socket API ${message || 'Request failed'} (${statusCode}): ${statusMessage}`
      )
      this.name = 'ResponseError'
      this.response = response
      Error.captureStackTrace(this, ResponseError)
    }
  }
  async function createDeleteRequest(baseUrl, urlPath, options) {
    const req = getHttpModule(baseUrl)
      .request(`${baseUrl}${urlPath}`, {
        method: 'DELETE',
        ...options
      })
      .end()
    return await getResponse(req)
  }
  async function createGetRequest(baseUrl, urlPath, options) {
    const req = getHttpModule(baseUrl)
      .request(`${baseUrl}${urlPath}`, {
        method: 'GET',
        ...options
      })
      .end()
    return await getResponse(req)
  }
  async function createPostRequest(baseUrl, urlPath, postJson, options) {
    const req = getHttpModule(baseUrl)
      .request(`${baseUrl}${urlPath}`, {
        method: 'POST',
        ...options
      })
      .end(JSON.stringify(postJson))
    return await getResponse(req)
  }
  function createRequestBodyForFilepaths(filepaths, basePath) {
    const requestBody = []
    for (const absPath of filepaths) {
      const relPath = node_path_1.default.relative(basePath, absPath)
      const filename = node_path_1.default.basename(absPath)
      requestBody.push(
        `Content-Disposition: form-data; name="${relPath}"; filename="${filename}"\r\n`,
        `Content-Type: application/octet-stream\r\n\r\n`,
        (0, node_fs_1.createReadStream)(absPath)
      )
    }
    return requestBody
  }
  function createRequestBodyForJson(jsonData, basename = 'data.json') {
    const ext = node_path_1.default.extname(basename)
    const name = node_path_1.default.basename(basename, ext)
    return [
      `Content-Disposition: form-data; name="${name}"; filename="${basename}"\r\n`,
      'Content-Type: application/json\r\n\r\n',
      JSON.stringify(jsonData),
      // New line after file content.
      '\r\n'
    ]
  }
  async function createUploadRequest(
    baseUrl,
    urlPath,
    requestBodyNoBoundaries,
    options
  ) {
    // Generate a unique boundary for multipart encoding.
    const boundary = `NodeMultipartBoundary${Date.now()}`
    const boundarySep = `--${boundary}\r\n`
    const finalBoundary = `--${boundary}--\r\n`
    const requestBody = [
      ...requestBodyNoBoundaries.flatMap(part => [
        boundarySep,
        ...(Array.isArray(part) ? part : [part])
      ]),
      finalBoundary
    ]
    const url = new URL(urlPath, baseUrl)
    const req = getHttpModule(baseUrl).request(url, {
      method: 'POST',
      ...options,
      headers: {
        ...options?.headers,
        'Content-Type': `multipart/form-data; boundary=${boundary}`
      }
    })
    let aborted = false
    req.on('error', _err => {
      aborted = true
    })
    req.on('close', () => {
      aborted = true
    })
    try {
      // Send the request body (headers + files).
      for (const part of requestBody) {
        if (aborted) {
          break
        }
        if (typeof part === 'string') {
          req.write(part)
        } else if (typeof part?.pipe === 'function') {
          part.pipe(req, { end: false })
          // Wait for file streaming to complete.
          // eslint-disable-next-line no-await-in-loop
          await node_events_1.default.once(part, 'end')
          if (!aborted) {
            // Ensure a new line after file content.
            req.write('\r\n')
          }
        } else {
          throw new TypeError(
            'Socket API - Invalid multipart part, expected string or stream'
          )
        }
      }
    } catch (e) {
      req.destroy(e)
      throw e
    } finally {
      if (!aborted) {
        // Close request after writing all data.
        req.end()
      }
    }
    return await getResponse(req)
  }
  async function getErrorResponseBody(response) {
    const chunks = []
    response.on('data', chunk => chunks.push(chunk))
    try {
      await node_events_1.default.once(response, 'end')
      return Buffer.concat(chunks).toString('utf8')
    } catch {
      return '(there was an error reading the body content)'
    }
  }
  function getHttpModule(baseUrl) {
    const { protocol } = new URL(baseUrl)
    return protocol === 'https:' ? node_https_1.default : node_http_1.default
  }
  async function getResponse(req) {
    try {
      const { 0: res } = await node_events_1.default.once(req, 'response', {
        signal: abort_signal_1.default
      })
      if (!isResponseOk(res)) {
        throw new ResponseError(res, `${req.method} request failed`)
      }
      return res
    } catch (e) {
      req.destroy()
      throw e
    }
  }
  async function getResponseJson(response) {
    let data = ''
    for await (const chunk of response) {
      data += chunk
    }
    try {
      return JSON.parse(data)
    } catch (e) {
      throw new SyntaxError(
        `Socket API - Invalid JSON response:\n${data}\n→ ${e?.message || 'Unknown error'}`,
        { cause: e }
      )
    }
  }
  function isResponseOk(response) {
    const { statusCode } = response
    return (
      typeof statusCode === 'number' && statusCode >= 200 && statusCode <= 299
    )
  }
  function resolveAbsPaths(filepaths, pathsRelativeTo) {
    const basePath = resolveBasePath(pathsRelativeTo)
    // Node's path.resolve will process path segments from right to left until
    // it creates a valid absolute path. So if `pathsRelativeTo` is an absolute
    // path, process.cwd() is not used, which is the common expectation. If none
    // of the paths resolve then it defaults to process.cwd().
    return filepaths.map(p => node_path_1.default.resolve(basePath, p))
  }
  function resolveBasePath(pathsRelativeTo = '.') {
    // Node's path.resolve will process path segments from right to left until
    // it creates a valid absolute path. So if `pathsRelativeTo` is an absolute
    // path, process.cwd() is not used, which is the common expectation. If none
    // of the paths resolve then it defaults to process.cwd().
    return node_path_1.default.resolve(process.cwd(), pathsRelativeTo)
  }
  /**
   * Package.json data to base the User-Agent on
   */
  function createUserAgentFromPkgJson(pkgData) {
    const { homepage } = pkgData
    const name = pkgData.name.replace('@', '').replace('/', '-')
    return `${name}/${pkgData.version}${homepage ? ` (${homepage})` : ''}`
  }
  // https://github.com/sindresorhus/got/blob/v14.4.6/documentation/2-options.md#agent
  const agentNames = new Set(['http', 'https', 'http2'])
  class SocketSdk {
    #baseUrl
    #reqOptions
    /**
     * @throws {SocketSdkAuthError}
     */
    constructor(apiToken, options) {
      const {
        agent: agentOrObj,
        baseUrl = 'https://api.socket.dev/v0/',
        userAgent
      } = { __proto__: null, ...options }
      const agentKeys = agentOrObj ? Object.keys(agentOrObj) : []
      const agent =
        agentKeys.length && agentKeys.every(k => agentNames.has(k))
          ? agentOrObj.https
          : agentOrObj
      this.#baseUrl = baseUrl
      this.#reqOptions = {
        ...(agent ? { agent } : {}),
        headers: {
          Authorization: `Basic ${btoa(`${apiToken}:`)}`,
          'User-Agent': userAgent ?? DEFAULT_USER_AGENT
        },
        signal: abort_signal_1.default
      }
    }
    async #createBatchPurlRequest(queryParams, componentsObj) {
      // Adds the first 'abort' listener to abortSignal.
      const req = getHttpModule(this.#baseUrl)
        .request(
          `${this.#baseUrl}purl?${new URLSearchParams(queryParams ?? '')}`,
          {
            method: 'POST',
            ...this.#reqOptions
          }
        )
        .end(JSON.stringify(componentsObj))
      return await getResponse(req)
    }
    async *#createBatchPurlGenerator(queryParams, componentsObj) {
      let res
      try {
        res = await this.#createBatchPurlRequest(queryParams, componentsObj)
      } catch (e) {
        return await this.#handleApiError(e)
      }
      const rli = node_readline_1.default.createInterface({
        input: res,
        crlfDelay: Infinity,
        signal: abort_signal_1.default
      })
      for await (const line of rli) {
        yield this.#handleApiSuccess(JSON.parse(line))
      }
    }
    async #handleApiError(error) {
      if (!(error instanceof ResponseError)) {
        throw new Error('Unexpected Socket API error', {
          cause: error
        })
      }
      const statusCode = error.response.statusCode
      if (statusCode >= 500) {
        throw new Error(`Socket API server error (${statusCode})`, {
          cause: error
        })
      }
      // The error payload may give a meaningful hint as to what went wrong.
      const bodyStr = await getErrorResponseBody(error.response)
      // Try to parse the body as JSON, fallback to treating as plain text.
      let body
      try {
        const parsed = JSON.parse(bodyStr)
        // A 400 should return an actionable message.
        // TODO: Do we care about the body.error.details object?
        if (typeof parsed?.error?.message === 'string') {
          body = parsed.error.message
        }
      } catch {
        body = bodyStr
      }
      return {
        success: false,
        status: statusCode,
        error: error.message ?? '',
        cause: body
      }
    }
    #handleApiSuccess(data) {
      return {
        success: true,
        status: 200,
        data: data
      }
    }
    async batchPackageFetch(queryParams, componentsObj) {
      let res
      try {
        res = await this.#createBatchPurlRequest(queryParams, componentsObj)
      } catch (e) {
        return await this.#handleApiError(e)
      }
      // Parse the newline delimited JSON response.
      const rl = node_readline_1.default.createInterface({
        input: res,
        crlfDelay: Infinity
      })
      const results = []
      for await (const line of rl) {
        if (line.trim()) {
          results.push(JSON.parse(line))
        }
      }
      return this.#handleApiSuccess(results)
    }
    async *batchPackageStream(queryParams, componentsObj, options) {
      const { chunkSize = 5, concurrencyLimit = 10 } = {
        __proto__: null,
        ...options
      }
      // The createBatchPurlGenerator method will add 2 'abort' event listeners to
      // abortSignal so we multiply the concurrencyLimit by 2.
      const neededMaxListeners = concurrencyLimit * 2
      // Increase abortSignal max listeners count to avoid Node's MaxListenersExceededWarning.
      const oldAbortSignalMaxListeners = node_events_1.default.getMaxListeners(
        abort_signal_1.default
      )
      let abortSignalMaxListeners = oldAbortSignalMaxListeners
      if (oldAbortSignalMaxListeners < neededMaxListeners) {
        abortSignalMaxListeners =
          oldAbortSignalMaxListeners + neededMaxListeners
        node_events_1.default.setMaxListeners(
          abortSignalMaxListeners,
          abort_signal_1.default
        )
      }
      const { components } = componentsObj
      const { length: componentsCount } = components
      const running = []
      let index = 0
      const enqueueGen = () => {
        if (index >= componentsCount) {
          // No more work to do.
          return
        }
        const generator = this.#createBatchPurlGenerator(queryParams, {
          // Chunk components.
          components: components.slice(index, index + chunkSize)
        })
        continueGen(generator)
        index += chunkSize
      }
      const continueGen = generator => {
        let resolveFn
        running.push({
          generator,
          promise: new Promise(resolve => (resolveFn = resolve))
        })
        void generator
          .next()
          .then(iteratorResult => resolveFn({ generator, iteratorResult }))
      }
      // Start initial batch of generators.
      while (running.length < concurrencyLimit && index < componentsCount) {
        enqueueGen()
      }
      while (running.length > 0) {
        // eslint-disable-next-line no-await-in-loop
        const { generator, iteratorResult } = await Promise.race(
          running.map(entry => entry.promise)
        )
        // Remove generator.
        running.splice(
          running.findIndex(entry => entry.generator === generator),
          1
        )
        if (iteratorResult.done) {
          // Start a new generator if available.
          enqueueGen()
        } else {
          yield iteratorResult.value
          // Keep fetching values from this generator.
          continueGen(generator)
        }
      }
      // Reset abortSignal max listeners count.
      if (abortSignalMaxListeners > oldAbortSignalMaxListeners) {
        node_events_1.default.setMaxListeners(
          oldAbortSignalMaxListeners,
          abort_signal_1.default
        )
      }
    }
    async createDependenciesSnapshot(params, filepaths, pathsRelativeTo = '.') {
      const basePath = resolveBasePath(pathsRelativeTo)
      const absFilepaths = resolveAbsPaths(filepaths, basePath)
      try {
        const data = await getResponseJson(
          await createUploadRequest(
            this.#baseUrl,
            `dependencies/upload?${new URLSearchParams(params)}`,
            createRequestBodyForFilepaths(absFilepaths, basePath),
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async createOrgFullScan(
      orgSlug,
      queryParams,
      filepaths,
      pathsRelativeTo = '.'
    ) {
      const basePath = resolveBasePath(pathsRelativeTo)
      const absFilepaths = resolveAbsPaths(filepaths, basePath)
      try {
        const data = await getResponseJson(
          await createUploadRequest(
            this.#baseUrl,
            `orgs/${encodeURIComponent(orgSlug)}/full-scans?${new URLSearchParams(queryParams ?? '')}`,
            createRequestBodyForFilepaths(absFilepaths, basePath),
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async createOrgRepo(orgSlug, params) {
      try {
        const data = await getResponseJson(
          await createPostRequest(
            this.#baseUrl,
            `orgs/${encodeURIComponent(orgSlug)}/repos`,
            params,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async createReportFromFilepaths(
      filepaths,
      pathsRelativeTo = '.',
      issueRules
    ) {
      const basePath = resolveBasePath(pathsRelativeTo)
      const absFilepaths = resolveAbsPaths(filepaths, basePath)
      try {
        const data = await createUploadRequest(
          this.#baseUrl,
          'report/upload',
          [
            ...createRequestBodyForFilepaths(absFilepaths, basePath),
            ...(issueRules
              ? createRequestBodyForJson(issueRules, 'issueRules')
              : [])
          ],
          {
            ...this.#reqOptions,
            method: 'PUT'
          }
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    // Alias to preserve backwards compatibility.
    async createReportFromFilePaths(
      filepaths,
      pathsRelativeTo = '.',
      issueRules
    ) {
      return await this.createReportFromFilepaths(
        filepaths,
        pathsRelativeTo,
        issueRules
      )
    }
    async deleteOrgFullScan(orgSlug, fullScanId) {
      try {
        const data = await getResponseJson(
          await createDeleteRequest(
            this.#baseUrl,
            `orgs/${encodeURIComponent(orgSlug)}/full-scans/${encodeURIComponent(fullScanId)}`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async deleteOrgRepo(orgSlug, repoSlug) {
      try {
        const data = await getResponseJson(
          await createDeleteRequest(
            this.#baseUrl,
            `orgs/${encodeURIComponent(orgSlug)}/repos/${encodeURIComponent(repoSlug)}`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getAuditLogEvents(orgSlug, queryParams) {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `orgs/${encodeURIComponent(orgSlug)}/audit-log?${new URLSearchParams(queryParams ?? '')}`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getIssuesByNPMPackage(pkgName, version) {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `npm/${encodeURIComponent(pkgName)}/${encodeURIComponent(version)}/issues`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getOrgAnalytics(time) {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `analytics/org/${encodeURIComponent(time)}`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getOrganizations() {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            'organizations',
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getOrgFullScan(orgSlug, fullScanId, file) {
      try {
        const req = getHttpModule(this.#baseUrl)
          .request(
            `${this.#baseUrl}orgs/${encodeURIComponent(orgSlug)}/full-scans/${encodeURIComponent(fullScanId)}`,
            {
              method: 'GET',
              ...this.#reqOptions
            }
          )
          .end()
        const res = await getResponse(req)
        if (file) {
          res.pipe((0, node_fs_1.createWriteStream)(file))
        } else {
          res.pipe(process.stdout)
        }
        return this.#handleApiSuccess(res)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getOrgFullScanList(orgSlug, queryParams) {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `orgs/${encodeURIComponent(orgSlug)}/full-scans?${new URLSearchParams(queryParams ?? '')}`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getOrgFullScanMetadata(orgSlug, fullScanId) {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `orgs/${encodeURIComponent(orgSlug)}/full-scans/${encodeURIComponent(fullScanId)}/metadata`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getOrgLicensePolicy(orgSlug) {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `orgs/${encodeURIComponent(orgSlug)}/settings/license-policy`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getOrgRepo(orgSlug, repoSlug) {
      const orgSlugParam = encodeURIComponent(orgSlug)
      const repoSlugParam = encodeURIComponent(repoSlug)
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `orgs/${orgSlugParam}/repos/${repoSlugParam}`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getOrgRepoList(orgSlug, queryParams) {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `orgs/${encodeURIComponent(orgSlug)}/repos?${new URLSearchParams(queryParams ?? '')}`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getOrgSecurityPolicy(orgSlug) {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `orgs/${encodeURIComponent(orgSlug)}/settings/security-policy`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getQuota() {
      try {
        const data = await getResponseJson(
          await createGetRequest(this.#baseUrl, 'quota', this.#reqOptions)
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getRepoAnalytics(repo, time) {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `analytics/repo/${encodeURIComponent(repo)}/${encodeURIComponent(time)}`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getReport(id) {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `report/view/${encodeURIComponent(id)}`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getReportList() {
      try {
        const data = await getResponseJson(
          await createGetRequest(this.#baseUrl, 'report/list', this.#reqOptions)
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getReportSupportedFiles() {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            'report/supported',
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async getScoreByNPMPackage(pkgName, version) {
      try {
        const data = await getResponseJson(
          await createGetRequest(
            this.#baseUrl,
            `npm/${encodeURIComponent(pkgName)}/${encodeURIComponent(version)}/score`,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async postSettings(selectors) {
      try {
        const data = await getResponseJson(
          await createPostRequest(
            this.#baseUrl,
            'settings',
            { json: selectors },
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async searchDependencies(params) {
      try {
        const data = await getResponseJson(
          await createPostRequest(
            this.#baseUrl,
            'dependencies/search',
            params,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
    async updateOrgRepo(orgSlug, repoSlug, params) {
      try {
        const data = await getResponseJson(
          await createPostRequest(
            this.#baseUrl,
            `orgs/${encodeURIComponent(orgSlug)}/repos/${encodeURIComponent(repoSlug)}`,
            params,
            this.#reqOptions
          )
        )
        return this.#handleApiSuccess(data)
      } catch (e) {
        return await this.#handleApiError(e)
      }
    }
  }
  dist$1.SocketSdk = SocketSdk

  return dist$1
}

const distExports = requireDist$1()

function camelCase$1(str) {
  const isCamelCase = str !== str.toLowerCase() && str !== str.toUpperCase()
  if (!isCamelCase) {
    str = str.toLowerCase()
  }
  if (str.indexOf('-') === -1 && str.indexOf('_') === -1) {
    return str
  } else {
    let camelcase = ''
    let nextChrUpper = false
    const leadingHyphens = str.match(/^-+/)
    for (
      let i = leadingHyphens ? leadingHyphens[0].length : 0;
      i < str.length;
      i++
    ) {
      let chr = str.charAt(i)
      if (nextChrUpper) {
        nextChrUpper = false
        chr = chr.toUpperCase()
      }
      if (i !== 0 && (chr === '-' || chr === '_')) {
        nextChrUpper = true
      } else if (chr !== '-' && chr !== '_') {
        camelcase += chr
      }
    }
    return camelcase
  }
}
function decamelize$1(str, joinString) {
  const lowercase = str.toLowerCase()
  joinString = joinString || '-'
  let notCamelcase = ''
  for (let i = 0; i < str.length; i++) {
    const chrLower = lowercase.charAt(i)
    const chrString = str.charAt(i)
    if (chrLower !== chrString && i > 0) {
      notCamelcase += `${joinString}${lowercase.charAt(i)}`
    } else {
      notCamelcase += chrString
    }
  }
  return notCamelcase
}
function looksLikeNumber$1(x) {
  if (x === null || x === undefined) {
    return false
  }
  if (typeof x === 'number') {
    return true
  }
  if (/^0x[0-9a-f]+$/i.test(x)) {
    return true
  }
  if (/^0[^.]/.test(x)) {
    return false
  }
  return /^[-]?(?:\d+(?:\.\d*)?|\.\d+)(e[-+]?\d+)?$/.test(x)
}
function tokenizeArgString$1(argString) {
  if (Array.isArray(argString)) {
    return argString.map(e => (typeof e !== 'string' ? e + '' : e))
  }
  argString = argString.trim()
  let i = 0
  let prevC = null
  let c = null
  let opening = null
  const args = []
  for (let ii = 0; ii < argString.length; ii++) {
    prevC = c
    c = argString.charAt(ii)
    if (c === ' ' && !opening) {
      if (!(prevC === ' ')) {
        i++
      }
      continue
    }
    if (c === opening) {
      opening = null
    } else if ((c === "'" || c === '"') && !opening) {
      opening = c
    }
    if (!args[i]) {
      args[i] = ''
    }
    args[i] += c
  }
  return args
}
let DefaultValuesForTypeKey$1
;(function (DefaultValuesForTypeKey) {
  DefaultValuesForTypeKey['BOOLEAN'] = 'boolean'
  DefaultValuesForTypeKey['STRING'] = 'string'
  DefaultValuesForTypeKey['NUMBER'] = 'number'
  DefaultValuesForTypeKey['ARRAY'] = 'array'
})(DefaultValuesForTypeKey$1 || (DefaultValuesForTypeKey$1 = {}))
let mixin$1
let YargsParser$1 = class YargsParser {
  constructor(_mixin) {
    mixin$1 = _mixin
  }
  parse(argsInput, options) {
    const opts = Object.assign(
      {
        alias: undefined,
        array: undefined,
        boolean: undefined,
        config: undefined,
        configObjects: undefined,
        configuration: undefined,
        coerce: undefined,
        count: undefined,
        default: undefined,
        envPrefix: undefined,
        narg: undefined,
        normalize: undefined,
        string: undefined,
        number: undefined,
        __: undefined,
        key: undefined
      },
      options
    )
    const args = tokenizeArgString$1(argsInput)
    const inputIsString = typeof argsInput === 'string'
    const aliases = combineAliases$1(
      Object.assign(Object.create(null), opts.alias)
    )
    const configuration = Object.assign(
      {
        'boolean-negation': true,
        'camel-case-expansion': true,
        'combine-arrays': false,
        'dot-notation': true,
        'duplicate-arguments-array': true,
        'flatten-duplicate-arrays': true,
        'greedy-arrays': true,
        'halt-at-non-option': false,
        'nargs-eats-options': false,
        'negation-prefix': 'no-',
        'parse-numbers': true,
        'parse-positional-numbers': true,
        'populate--': false,
        'set-placeholder-key': false,
        'short-option-groups': true,
        'strip-aliased': false,
        'strip-dashed': false,
        'unknown-options-as-args': false
      },
      opts.configuration
    )
    const defaults = Object.assign(Object.create(null), opts.default)
    const configObjects = opts.configObjects || []
    const envPrefix = opts.envPrefix
    const notFlagsOption = configuration['populate--']
    const notFlagsArgv = notFlagsOption ? '--' : '_'
    const newAliases = Object.create(null)
    const defaulted = Object.create(null)
    const __ = opts.__ || mixin$1.format
    const flags = {
      aliases: Object.create(null),
      arrays: Object.create(null),
      bools: Object.create(null),
      strings: Object.create(null),
      numbers: Object.create(null),
      counts: Object.create(null),
      normalize: Object.create(null),
      configs: Object.create(null),
      nargs: Object.create(null),
      coercions: Object.create(null),
      keys: []
    }
    const negative = /^-([0-9]+(\.[0-9]+)?|\.[0-9]+)$/
    const negatedBoolean = new RegExp(
      '^--' + configuration['negation-prefix'] + '(.+)'
    )
    ;[]
      .concat(opts.array || [])
      .filter(Boolean)
      .forEach(function (opt) {
        const key = typeof opt === 'object' ? opt.key : opt
        const assignment = Object.keys(opt)
          .map(function (key) {
            const arrayFlagKeys = {
              boolean: 'bools',
              string: 'strings',
              number: 'numbers'
            }
            return arrayFlagKeys[key]
          })
          .filter(Boolean)
          .pop()
        if (assignment) {
          flags[assignment][key] = true
        }
        flags.arrays[key] = true
        flags.keys.push(key)
      })
    ;[]
      .concat(opts.boolean || [])
      .filter(Boolean)
      .forEach(function (key) {
        flags.bools[key] = true
        flags.keys.push(key)
      })
    ;[]
      .concat(opts.string || [])
      .filter(Boolean)
      .forEach(function (key) {
        flags.strings[key] = true
        flags.keys.push(key)
      })
    ;[]
      .concat(opts.number || [])
      .filter(Boolean)
      .forEach(function (key) {
        flags.numbers[key] = true
        flags.keys.push(key)
      })
    ;[]
      .concat(opts.count || [])
      .filter(Boolean)
      .forEach(function (key) {
        flags.counts[key] = true
        flags.keys.push(key)
      })
    ;[]
      .concat(opts.normalize || [])
      .filter(Boolean)
      .forEach(function (key) {
        flags.normalize[key] = true
        flags.keys.push(key)
      })
    if (typeof opts.narg === 'object') {
      Object.entries(opts.narg).forEach(([key, value]) => {
        if (typeof value === 'number') {
          flags.nargs[key] = value
          flags.keys.push(key)
        }
      })
    }
    if (typeof opts.coerce === 'object') {
      Object.entries(opts.coerce).forEach(([key, value]) => {
        if (typeof value === 'function') {
          flags.coercions[key] = value
          flags.keys.push(key)
        }
      })
    }
    if (typeof opts.config !== 'undefined') {
      if (Array.isArray(opts.config) || typeof opts.config === 'string') {
        ;[]
          .concat(opts.config)
          .filter(Boolean)
          .forEach(function (key) {
            flags.configs[key] = true
          })
      } else if (typeof opts.config === 'object') {
        Object.entries(opts.config).forEach(([key, value]) => {
          if (typeof value === 'boolean' || typeof value === 'function') {
            flags.configs[key] = value
          }
        })
      }
    }
    extendAliases(opts.key, aliases, opts.default, flags.arrays)
    Object.keys(defaults).forEach(function (key) {
      ;(flags.aliases[key] || []).forEach(function (alias) {
        defaults[alias] = defaults[key]
      })
    })
    let error = null
    checkConfiguration()
    let notFlags = []
    const argv = Object.assign(Object.create(null), {
      _: []
    })
    const argvReturn = {}
    for (let i = 0; i < args.length; i++) {
      const arg = args[i]
      const truncatedArg = arg.replace(/^-{3,}/, '---')
      let broken
      let key
      let letters
      let m
      let next
      let value
      if (arg !== '--' && /^-/.test(arg) && isUnknownOptionAsArg(arg)) {
        pushPositional(arg)
      } else if (truncatedArg.match(/^---+(=|$)/)) {
        pushPositional(arg)
        continue
      } else if (
        arg.match(/^--.+=/) ||
        (!configuration['short-option-groups'] && arg.match(/^-.+=/))
      ) {
        m = arg.match(/^--?([^=]+)=([\s\S]*)$/)
        if (m !== null && Array.isArray(m) && m.length >= 3) {
          if (checkAllAliases(m[1], flags.arrays)) {
            i = eatArray(i, m[1], args, m[2])
          } else if (checkAllAliases(m[1], flags.nargs) !== false) {
            i = eatNargs(i, m[1], args, m[2])
          } else {
            setArg(m[1], m[2], true)
          }
        }
      } else if (
        arg.match(negatedBoolean) &&
        configuration['boolean-negation']
      ) {
        m = arg.match(negatedBoolean)
        if (m !== null && Array.isArray(m) && m.length >= 2) {
          key = m[1]
          setArg(key, checkAllAliases(key, flags.arrays) ? [false] : false)
        }
      } else if (
        arg.match(/^--.+/) ||
        (!configuration['short-option-groups'] && arg.match(/^-[^-]+/))
      ) {
        m = arg.match(/^--?(.+)/)
        if (m !== null && Array.isArray(m) && m.length >= 2) {
          key = m[1]
          if (checkAllAliases(key, flags.arrays)) {
            i = eatArray(i, key, args)
          } else if (checkAllAliases(key, flags.nargs) !== false) {
            i = eatNargs(i, key, args)
          } else {
            next = args[i + 1]
            if (
              next !== undefined &&
              (!next.match(/^-/) || next.match(negative)) &&
              !checkAllAliases(key, flags.bools) &&
              !checkAllAliases(key, flags.counts)
            ) {
              setArg(key, next)
              i++
            } else if (/^(true|false)$/.test(next)) {
              setArg(key, next)
              i++
            } else {
              setArg(key, defaultValue(key))
            }
          }
        }
      } else if (arg.match(/^-.\..+=/)) {
        m = arg.match(/^-([^=]+)=([\s\S]*)$/)
        if (m !== null && Array.isArray(m) && m.length >= 3) {
          setArg(m[1], m[2])
        }
      } else if (arg.match(/^-.\..+/) && !arg.match(negative)) {
        next = args[i + 1]
        m = arg.match(/^-(.\..+)/)
        if (m !== null && Array.isArray(m) && m.length >= 2) {
          key = m[1]
          if (
            next !== undefined &&
            !next.match(/^-/) &&
            !checkAllAliases(key, flags.bools) &&
            !checkAllAliases(key, flags.counts)
          ) {
            setArg(key, next)
            i++
          } else {
            setArg(key, defaultValue(key))
          }
        }
      } else if (arg.match(/^-[^-]+/) && !arg.match(negative)) {
        letters = arg.slice(1, -1).split('')
        broken = false
        for (let j = 0; j < letters.length; j++) {
          next = arg.slice(j + 2)
          if (letters[j + 1] && letters[j + 1] === '=') {
            value = arg.slice(j + 3)
            key = letters[j]
            if (checkAllAliases(key, flags.arrays)) {
              i = eatArray(i, key, args, value)
            } else if (checkAllAliases(key, flags.nargs) !== false) {
              i = eatNargs(i, key, args, value)
            } else {
              setArg(key, value)
            }
            broken = true
            break
          }
          if (next === '-') {
            setArg(letters[j], next)
            continue
          }
          if (
            /[A-Za-z]/.test(letters[j]) &&
            /^-?\d+(\.\d*)?(e-?\d+)?$/.test(next) &&
            checkAllAliases(next, flags.bools) === false
          ) {
            setArg(letters[j], next)
            broken = true
            break
          }
          if (letters[j + 1] && letters[j + 1].match(/\W/)) {
            setArg(letters[j], next)
            broken = true
            break
          } else {
            setArg(letters[j], defaultValue(letters[j]))
          }
        }
        key = arg.slice(-1)[0]
        if (!broken && key !== '-') {
          if (checkAllAliases(key, flags.arrays)) {
            i = eatArray(i, key, args)
          } else if (checkAllAliases(key, flags.nargs) !== false) {
            i = eatNargs(i, key, args)
          } else {
            next = args[i + 1]
            if (
              next !== undefined &&
              (!/^(-|--)[^-]/.test(next) || next.match(negative)) &&
              !checkAllAliases(key, flags.bools) &&
              !checkAllAliases(key, flags.counts)
            ) {
              setArg(key, next)
              i++
            } else if (/^(true|false)$/.test(next)) {
              setArg(key, next)
              i++
            } else {
              setArg(key, defaultValue(key))
            }
          }
        }
      } else if (
        arg.match(/^-[0-9]$/) &&
        arg.match(negative) &&
        checkAllAliases(arg.slice(1), flags.bools)
      ) {
        key = arg.slice(1)
        setArg(key, defaultValue(key))
      } else if (arg === '--') {
        notFlags = args.slice(i + 1)
        break
      } else if (configuration['halt-at-non-option']) {
        notFlags = args.slice(i)
        break
      } else {
        pushPositional(arg)
      }
    }
    applyEnvVars(argv, true)
    applyEnvVars(argv, false)
    setConfig(argv)
    setConfigObjects()
    applyDefaultsAndAliases(argv, flags.aliases, defaults, true)
    applyCoercions(argv)
    if (configuration['set-placeholder-key']) {
      setPlaceholderKeys(argv)
    }
    Object.keys(flags.counts).forEach(function (key) {
      if (!hasKey(argv, key.split('.'))) {
        setArg(key, 0)
      }
    })
    if (notFlagsOption && notFlags.length) {
      argv[notFlagsArgv] = []
    }
    notFlags.forEach(function (key) {
      argv[notFlagsArgv].push(key)
    })
    if (
      configuration['camel-case-expansion'] &&
      configuration['strip-dashed']
    ) {
      Object.keys(argv)
        .filter(key => key !== '--' && key.includes('-'))
        .forEach(key => {
          delete argv[key]
        })
    }
    if (configuration['strip-aliased']) {
      ;[]
        .concat(...Object.keys(aliases).map(k => aliases[k]))
        .forEach(alias => {
          if (configuration['camel-case-expansion'] && alias.includes('-')) {
            delete argv[
              alias
                .split('.')
                .map(prop => camelCase$1(prop))
                .join('.')
            ]
          }
          delete argv[alias]
        })
    }
    function pushPositional(arg) {
      const maybeCoercedNumber = maybeCoerceNumber('_', arg)
      if (
        typeof maybeCoercedNumber === 'string' ||
        typeof maybeCoercedNumber === 'number'
      ) {
        argv._.push(maybeCoercedNumber)
      }
    }
    function eatNargs(i, key, args, argAfterEqualSign) {
      let ii
      let toEat = checkAllAliases(key, flags.nargs)
      toEat = typeof toEat !== 'number' || isNaN(toEat) ? 1 : toEat
      if (toEat === 0) {
        if (!isUndefined(argAfterEqualSign)) {
          error = Error(__('Argument unexpected for: %s', key))
        }
        setArg(key, defaultValue(key))
        return i
      }
      let available = isUndefined(argAfterEqualSign) ? 0 : 1
      if (configuration['nargs-eats-options']) {
        if (args.length - (i + 1) + available < toEat) {
          error = Error(__('Not enough arguments following: %s', key))
        }
        available = toEat
      } else {
        for (ii = i + 1; ii < args.length; ii++) {
          if (
            !args[ii].match(/^-[^0-9]/) ||
            args[ii].match(negative) ||
            isUnknownOptionAsArg(args[ii])
          ) {
            available++
          } else {
            break
          }
        }
        if (available < toEat) {
          error = Error(__('Not enough arguments following: %s', key))
        }
      }
      let consumed = Math.min(available, toEat)
      if (!isUndefined(argAfterEqualSign) && consumed > 0) {
        setArg(key, argAfterEqualSign)
        consumed--
      }
      for (ii = i + 1; ii < consumed + i + 1; ii++) {
        setArg(key, args[ii])
      }
      return i + consumed
    }
    function eatArray(i, key, args, argAfterEqualSign) {
      let argsToSet = []
      let next = argAfterEqualSign || args[i + 1]
      const nargsCount = checkAllAliases(key, flags.nargs)
      if (checkAllAliases(key, flags.bools) && !/^(true|false)$/.test(next)) {
        argsToSet.push(true)
      } else if (
        isUndefined(next) ||
        (isUndefined(argAfterEqualSign) &&
          /^-/.test(next) &&
          !negative.test(next) &&
          !isUnknownOptionAsArg(next))
      ) {
        if (defaults[key] !== undefined) {
          const defVal = defaults[key]
          argsToSet = Array.isArray(defVal) ? defVal : [defVal]
        }
      } else {
        if (!isUndefined(argAfterEqualSign)) {
          argsToSet.push(processValue(key, argAfterEqualSign, true))
        }
        for (let ii = i + 1; ii < args.length; ii++) {
          if (
            (!configuration['greedy-arrays'] && argsToSet.length > 0) ||
            (nargsCount &&
              typeof nargsCount === 'number' &&
              argsToSet.length >= nargsCount)
          ) {
            break
          }
          next = args[ii]
          if (
            /^-/.test(next) &&
            !negative.test(next) &&
            !isUnknownOptionAsArg(next)
          ) {
            break
          }
          i = ii
          argsToSet.push(processValue(key, next, inputIsString))
        }
      }
      if (
        typeof nargsCount === 'number' &&
        ((nargsCount && argsToSet.length < nargsCount) ||
          (isNaN(nargsCount) && argsToSet.length === 0))
      ) {
        error = Error(__('Not enough arguments following: %s', key))
      }
      setArg(key, argsToSet)
      return i
    }
    function setArg(key, val, shouldStripQuotes = inputIsString) {
      if (/-/.test(key) && configuration['camel-case-expansion']) {
        const alias = key
          .split('.')
          .map(function (prop) {
            return camelCase$1(prop)
          })
          .join('.')
        addNewAlias(key, alias)
      }
      const value = processValue(key, val, shouldStripQuotes)
      const splitKey = key.split('.')
      setKey(argv, splitKey, value)
      if (flags.aliases[key]) {
        flags.aliases[key].forEach(function (x) {
          const keyProperties = x.split('.')
          setKey(argv, keyProperties, value)
        })
      }
      if (splitKey.length > 1 && configuration['dot-notation']) {
        ;(flags.aliases[splitKey[0]] || []).forEach(function (x) {
          let keyProperties = x.split('.')
          const a = [].concat(splitKey)
          a.shift()
          keyProperties = keyProperties.concat(a)
          if (!(flags.aliases[key] || []).includes(keyProperties.join('.'))) {
            setKey(argv, keyProperties, value)
          }
        })
      }
      if (
        checkAllAliases(key, flags.normalize) &&
        !checkAllAliases(key, flags.arrays)
      ) {
        const keys = [key].concat(flags.aliases[key] || [])
        keys.forEach(function (key) {
          Object.defineProperty(argvReturn, key, {
            enumerable: true,
            get() {
              return val
            },
            set(value) {
              val = typeof value === 'string' ? mixin$1.normalize(value) : value
            }
          })
        })
      }
    }
    function addNewAlias(key, alias) {
      if (!(flags.aliases[key] && flags.aliases[key].length)) {
        flags.aliases[key] = [alias]
        newAliases[alias] = true
      }
      if (!(flags.aliases[alias] && flags.aliases[alias].length)) {
        addNewAlias(alias, key)
      }
    }
    function processValue(key, val, shouldStripQuotes) {
      if (shouldStripQuotes) {
        val = stripQuotes$1(val)
      }
      if (
        checkAllAliases(key, flags.bools) ||
        checkAllAliases(key, flags.counts)
      ) {
        if (typeof val === 'string') {
          val = val === 'true'
        }
      }
      let value = Array.isArray(val)
        ? val.map(function (v) {
            return maybeCoerceNumber(key, v)
          })
        : maybeCoerceNumber(key, val)
      if (
        checkAllAliases(key, flags.counts) &&
        (isUndefined(value) || typeof value === 'boolean')
      ) {
        value = increment$1()
      }
      if (
        checkAllAliases(key, flags.normalize) &&
        checkAllAliases(key, flags.arrays)
      ) {
        if (Array.isArray(val)) {
          value = val.map(val => {
            return mixin$1.normalize(val)
          })
        } else {
          value = mixin$1.normalize(val)
        }
      }
      return value
    }
    function maybeCoerceNumber(key, value) {
      if (!configuration['parse-positional-numbers'] && key === '_') {
        return value
      }
      if (
        !checkAllAliases(key, flags.strings) &&
        !checkAllAliases(key, flags.bools) &&
        !Array.isArray(value)
      ) {
        const shouldCoerceNumber =
          looksLikeNumber$1(value) &&
          configuration['parse-numbers'] &&
          Number.isSafeInteger(Math.floor(parseFloat(`${value}`)))
        if (
          shouldCoerceNumber ||
          (!isUndefined(value) && checkAllAliases(key, flags.numbers))
        ) {
          value = Number(value)
        }
      }
      return value
    }
    function setConfig(argv) {
      const configLookup = Object.create(null)
      applyDefaultsAndAliases(configLookup, flags.aliases, defaults)
      Object.keys(flags.configs).forEach(function (configKey) {
        const configPath = argv[configKey] || configLookup[configKey]
        if (configPath) {
          try {
            let config = null
            const resolvedConfigPath = mixin$1.resolve(
              mixin$1.cwd(),
              configPath
            )
            const resolveConfig = flags.configs[configKey]
            if (typeof resolveConfig === 'function') {
              try {
                config = resolveConfig(resolvedConfigPath)
              } catch (e) {
                config = e
              }
              if (config instanceof Error) {
                error = config
                return
              }
            } else {
              config = mixin$1.require(resolvedConfigPath)
            }
            setConfigObject(config)
          } catch (ex) {
            if (ex.name === 'PermissionDenied') {
              error = ex
            } else if (argv[configKey]) {
              error = Error(__('Invalid JSON config file: %s', configPath))
            }
          }
        }
      })
    }
    function setConfigObject(config, prev) {
      Object.keys(config).forEach(function (key) {
        const value = config[key]
        const fullKey = prev ? prev + '.' + key : key
        if (
          typeof value === 'object' &&
          value !== null &&
          !Array.isArray(value) &&
          configuration['dot-notation']
        ) {
          setConfigObject(value, fullKey)
        } else {
          if (
            !hasKey(argv, fullKey.split('.')) ||
            (checkAllAliases(fullKey, flags.arrays) &&
              configuration['combine-arrays'])
          ) {
            setArg(fullKey, value)
          }
        }
      })
    }
    function setConfigObjects() {
      if (typeof configObjects !== 'undefined') {
        configObjects.forEach(function (configObject) {
          setConfigObject(configObject)
        })
      }
    }
    function applyEnvVars(argv, configOnly) {
      if (typeof envPrefix === 'undefined') {
        return
      }
      const prefix = typeof envPrefix === 'string' ? envPrefix : ''
      const env = mixin$1.env()
      Object.keys(env).forEach(function (envVar) {
        if (prefix === '' || envVar.lastIndexOf(prefix, 0) === 0) {
          const keys = envVar.split('__').map(function (key, i) {
            if (i === 0) {
              key = key.substring(prefix.length)
            }
            return camelCase$1(key)
          })
          if (
            ((configOnly && flags.configs[keys.join('.')]) || !configOnly) &&
            !hasKey(argv, keys)
          ) {
            setArg(keys.join('.'), env[envVar])
          }
        }
      })
    }
    function applyCoercions(argv) {
      let coerce
      const applied = new Set()
      Object.keys(argv).forEach(function (key) {
        if (!applied.has(key)) {
          coerce = checkAllAliases(key, flags.coercions)
          if (typeof coerce === 'function') {
            try {
              const value = maybeCoerceNumber(key, coerce(argv[key]))
              ;[].concat(flags.aliases[key] || [], key).forEach(ali => {
                applied.add(ali)
                argv[ali] = value
              })
            } catch (err) {
              error = err
            }
          }
        }
      })
    }
    function setPlaceholderKeys(argv) {
      flags.keys.forEach(key => {
        if (~key.indexOf('.')) {
          return
        }
        if (typeof argv[key] === 'undefined') {
          argv[key] = undefined
        }
      })
      return argv
    }
    function applyDefaultsAndAliases(obj, aliases, defaults, canLog = false) {
      Object.keys(defaults).forEach(function (key) {
        if (!hasKey(obj, key.split('.'))) {
          setKey(obj, key.split('.'), defaults[key])
          if (canLog) {
            defaulted[key] = true
          }
          ;(aliases[key] || []).forEach(function (x) {
            if (hasKey(obj, x.split('.'))) {
              return
            }
            setKey(obj, x.split('.'), defaults[key])
          })
        }
      })
    }
    function hasKey(obj, keys) {
      let o = obj
      if (!configuration['dot-notation']) {
        keys = [keys.join('.')]
      }
      keys.slice(0, -1).forEach(function (key) {
        o = o[key] || {}
      })
      const key = keys[keys.length - 1]
      if (typeof o !== 'object') {
        return false
      } else {
        return key in o
      }
    }
    function setKey(obj, keys, value) {
      let o = obj
      if (!configuration['dot-notation']) {
        keys = [keys.join('.')]
      }
      keys.slice(0, -1).forEach(function (key) {
        key = sanitizeKey$1(key)
        if (typeof o === 'object' && o[key] === undefined) {
          o[key] = {}
        }
        if (typeof o[key] !== 'object' || Array.isArray(o[key])) {
          if (Array.isArray(o[key])) {
            o[key].push({})
          } else {
            o[key] = [o[key], {}]
          }
          o = o[key][o[key].length - 1]
        } else {
          o = o[key]
        }
      })
      const key = sanitizeKey$1(keys[keys.length - 1])
      const isTypeArray = checkAllAliases(keys.join('.'), flags.arrays)
      const isValueArray = Array.isArray(value)
      let duplicate = configuration['duplicate-arguments-array']
      if (!duplicate && checkAllAliases(key, flags.nargs)) {
        duplicate = true
        if (
          (!isUndefined(o[key]) && flags.nargs[key] === 1) ||
          (Array.isArray(o[key]) && o[key].length === flags.nargs[key])
        ) {
          o[key] = undefined
        }
      }
      if (value === increment$1()) {
        o[key] = increment$1(o[key])
      } else if (Array.isArray(o[key])) {
        if (duplicate && isTypeArray && isValueArray) {
          o[key] = configuration['flatten-duplicate-arrays']
            ? o[key].concat(value)
            : (Array.isArray(o[key][0]) ? o[key] : [o[key]]).concat([value])
        } else if (
          !duplicate &&
          Boolean(isTypeArray) === Boolean(isValueArray)
        ) {
          o[key] = value
        } else {
          o[key] = o[key].concat([value])
        }
      } else if (o[key] === undefined && isTypeArray) {
        o[key] = isValueArray ? value : [value]
      } else if (
        duplicate &&
        !(
          o[key] === undefined ||
          checkAllAliases(key, flags.counts) ||
          checkAllAliases(key, flags.bools)
        )
      ) {
        o[key] = [o[key], value]
      } else {
        o[key] = value
      }
    }
    function extendAliases(...args) {
      args.forEach(function (obj) {
        Object.keys(obj || {}).forEach(function (key) {
          if (flags.aliases[key]) {
            return
          }
          flags.aliases[key] = [].concat(aliases[key] || [])
          flags.aliases[key].concat(key).forEach(function (x) {
            if (/-/.test(x) && configuration['camel-case-expansion']) {
              const c = camelCase$1(x)
              if (c !== key && flags.aliases[key].indexOf(c) === -1) {
                flags.aliases[key].push(c)
                newAliases[c] = true
              }
            }
          })
          flags.aliases[key].concat(key).forEach(function (x) {
            if (
              x.length > 1 &&
              /[A-Z]/.test(x) &&
              configuration['camel-case-expansion']
            ) {
              const c = decamelize$1(x, '-')
              if (c !== key && flags.aliases[key].indexOf(c) === -1) {
                flags.aliases[key].push(c)
                newAliases[c] = true
              }
            }
          })
          flags.aliases[key].forEach(function (x) {
            flags.aliases[x] = [key].concat(
              flags.aliases[key].filter(function (y) {
                return x !== y
              })
            )
          })
        })
      })
    }
    function checkAllAliases(key, flag) {
      const toCheck = [].concat(flags.aliases[key] || [], key)
      const keys = Object.keys(flag)
      const setAlias = toCheck.find(key => keys.includes(key))
      return setAlias ? flag[setAlias] : false
    }
    function hasAnyFlag(key) {
      const flagsKeys = Object.keys(flags)
      const toCheck = [].concat(flagsKeys.map(k => flags[k]))
      return toCheck.some(function (flag) {
        return Array.isArray(flag) ? flag.includes(key) : flag[key]
      })
    }
    function hasFlagsMatching(arg, ...patterns) {
      const toCheck = [].concat(...patterns)
      return toCheck.some(function (pattern) {
        const match = arg.match(pattern)
        return match && hasAnyFlag(match[1])
      })
    }
    function hasAllShortFlags(arg) {
      if (arg.match(negative) || !arg.match(/^-[^-]+/)) {
        return false
      }
      let hasAllFlags = true
      let next
      const letters = arg.slice(1).split('')
      for (let j = 0; j < letters.length; j++) {
        next = arg.slice(j + 2)
        if (!hasAnyFlag(letters[j])) {
          hasAllFlags = false
          break
        }
        if (
          (letters[j + 1] && letters[j + 1] === '=') ||
          next === '-' ||
          (/[A-Za-z]/.test(letters[j]) &&
            /^-?\d+(\.\d*)?(e-?\d+)?$/.test(next)) ||
          (letters[j + 1] && letters[j + 1].match(/\W/))
        ) {
          break
        }
      }
      return hasAllFlags
    }
    function isUnknownOptionAsArg(arg) {
      return configuration['unknown-options-as-args'] && isUnknownOption(arg)
    }
    function isUnknownOption(arg) {
      arg = arg.replace(/^-{3,}/, '--')
      if (arg.match(negative)) {
        return false
      }
      if (hasAllShortFlags(arg)) {
        return false
      }
      const flagWithEquals = /^-+([^=]+?)=[\s\S]*$/
      const normalFlag = /^-+([^=]+?)$/
      const flagEndingInHyphen = /^-+([^=]+?)-$/
      const flagEndingInDigits = /^-+([^=]+?\d+)$/
      const flagEndingInNonWordCharacters = /^-+([^=]+?)\W+.*$/
      return !hasFlagsMatching(
        arg,
        flagWithEquals,
        negatedBoolean,
        normalFlag,
        flagEndingInHyphen,
        flagEndingInDigits,
        flagEndingInNonWordCharacters
      )
    }
    function defaultValue(key) {
      if (
        !checkAllAliases(key, flags.bools) &&
        !checkAllAliases(key, flags.counts) &&
        `${key}` in defaults
      ) {
        return defaults[key]
      } else {
        return defaultForType(guessType(key))
      }
    }
    function defaultForType(type) {
      const def = {
        [DefaultValuesForTypeKey$1.BOOLEAN]: true,
        [DefaultValuesForTypeKey$1.STRING]: '',
        [DefaultValuesForTypeKey$1.NUMBER]: undefined,
        [DefaultValuesForTypeKey$1.ARRAY]: []
      }
      return def[type]
    }
    function guessType(key) {
      let type = DefaultValuesForTypeKey$1.BOOLEAN
      if (checkAllAliases(key, flags.strings)) {
        type = DefaultValuesForTypeKey$1.STRING
      } else if (checkAllAliases(key, flags.numbers)) {
        type = DefaultValuesForTypeKey$1.NUMBER
      } else if (checkAllAliases(key, flags.bools)) {
        type = DefaultValuesForTypeKey$1.BOOLEAN
      } else if (checkAllAliases(key, flags.arrays)) {
        type = DefaultValuesForTypeKey$1.ARRAY
      }
      return type
    }
    function isUndefined(num) {
      return num === undefined
    }
    function checkConfiguration() {
      Object.keys(flags.counts).find(key => {
        if (checkAllAliases(key, flags.arrays)) {
          error = Error(
            __(
              'Invalid configuration: %s, opts.count excludes opts.array.',
              key
            )
          )
          return true
        } else if (checkAllAliases(key, flags.nargs)) {
          error = Error(
            __('Invalid configuration: %s, opts.count excludes opts.narg.', key)
          )
          return true
        }
        return false
      })
    }
    return {
      aliases: Object.assign({}, flags.aliases),
      argv: Object.assign(argvReturn, argv),
      configuration: configuration,
      defaulted: Object.assign({}, defaulted),
      error: error,
      newAliases: Object.assign({}, newAliases)
    }
  }
}
function combineAliases$1(aliases) {
  const aliasArrays = []
  const combined = Object.create(null)
  let change = true
  Object.keys(aliases).forEach(function (key) {
    aliasArrays.push([].concat(aliases[key], key))
  })
  while (change) {
    change = false
    for (let i = 0; i < aliasArrays.length; i++) {
      for (let ii = i + 1; ii < aliasArrays.length; ii++) {
        const intersect = aliasArrays[i].filter(function (v) {
          return aliasArrays[ii].indexOf(v) !== -1
        })
        if (intersect.length) {
          aliasArrays[i] = aliasArrays[i].concat(aliasArrays[ii])
          aliasArrays.splice(ii, 1)
          change = true
          break
        }
      }
    }
  }
  aliasArrays.forEach(function (aliasArray) {
    aliasArray = aliasArray.filter(function (v, i, self) {
      return self.indexOf(v) === i
    })
    const lastAlias = aliasArray.pop()
    if (lastAlias !== undefined && typeof lastAlias === 'string') {
      combined[lastAlias] = aliasArray
    }
  })
  return combined
}
function increment$1(orig) {
  return orig !== undefined ? orig + 1 : 1
}
function sanitizeKey$1(key) {
  if (key === '__proto__') {
    return '___proto___'
  }
  return key
}
function stripQuotes$1(val) {
  return typeof val === 'string' &&
    (val[0] === "'" || val[0] === '"') &&
    val[val.length - 1] === val[0]
    ? val.substring(1, val.length - 1)
    : val
}
let _a$1, _b$1, _c$1
const minNodeVersion$1 =
  process && process.env && process.env.YARGS_MIN_NODE_VERSION
    ? Number(process.env.YARGS_MIN_NODE_VERSION)
    : 12
const nodeVersion$1 =
  (_b$1 =
    (_a$1 =
      process === null || process === void 0 ? void 0 : process.versions) ===
      null || _a$1 === void 0
      ? void 0
      : _a$1.node) !== null && _b$1 !== void 0
    ? _b$1
    : (_c$1 =
          process === null || process === void 0 ? void 0 : process.version) ===
          null || _c$1 === void 0
      ? void 0
      : _c$1.slice(1)
if (nodeVersion$1) {
  const major = Number(nodeVersion$1.match(/^([^.]+)/)[1])
  if (major < minNodeVersion$1) {
    throw Error(
      `yargs parser supports a minimum Node.js version of ${minNodeVersion$1}. Read our version support policy: https://github.com/yargs/yargs-parser#supported-nodejs-versions`
    )
  }
}
const env$2 = process ? process.env : {}
const parser$1 = new YargsParser$1({
  cwd: process.cwd,
  env: () => {
    return env$2
  },
  format: util$3.format,
  normalize: path$1.normalize,
  resolve: path$1.resolve,
  require: path => {
    if (typeof require !== 'undefined') {
      return require(path)
    } else if (path.match(/\.json$/)) {
      return JSON.parse(fs$1.readFileSync(path, 'utf8'))
    } else {
      throw Error('only .json config files are supported in ESM')
    }
  }
})
const yargsParser$1 = function Parser(args, opts) {
  const result = parser$1.parse(args.slice(), opts)
  return result.argv
}
yargsParser$1.detailed = function (args, opts) {
  return parser$1.parse(args.slice(), opts)
}
yargsParser$1.camelCase = camelCase$1
yargsParser$1.decamelize = decamelize$1
yargsParser$1.looksLikeNumber = looksLikeNumber$1
const isObject$3 = value => typeof value === 'object' && value !== null
const isObjectCustom$1 = value =>
  isObject$3(value) &&
  !(value instanceof RegExp) &&
  !(value instanceof Error) &&
  !(value instanceof Date)
const mapObjectSkip$1 = Symbol('mapObjectSkip')
const _mapObject = (object, mapper, options, isSeen = new WeakMap()) => {
  options = {
    deep: false,
    target: {},
    ...options
  }
  if (isSeen.has(object)) {
    return isSeen.get(object)
  }
  isSeen.set(object, options.target)
  const { target } = options
  delete options.target
  const mapArray = array =>
    array.map(element =>
      isObjectCustom$1(element)
        ? _mapObject(element, mapper, options, isSeen)
        : element
    )
  if (Array.isArray(object)) {
    return mapArray(object)
  }
  for (const [key, value] of Object.entries(object)) {
    const mapResult = mapper(key, value, object)
    if (mapResult === mapObjectSkip$1) {
      continue
    }
    let [newKey, newValue, { shouldRecurse = true } = {}] = mapResult
    if (newKey === '__proto__') {
      continue
    }
    if (options.deep && shouldRecurse && isObjectCustom$1(newValue)) {
      newValue = Array.isArray(newValue)
        ? mapArray(newValue)
        : _mapObject(newValue, mapper, options, isSeen)
    }
    target[newKey] = newValue
  }
  return target
}
function mapObject$2(object, mapper, options) {
  if (!isObject$3(object)) {
    throw new TypeError(
      `Expected an object, got \`${object}\` (${typeof object})`
    )
  }
  return _mapObject(object, mapper, options)
}
const UPPERCASE = /[\p{Lu}]/u
const LOWERCASE = /[\p{Ll}]/u
const LEADING_CAPITAL = /^[\p{Lu}](?![\p{Lu}])/gu
const IDENTIFIER$1 = /([\p{Alpha}\p{N}_]|$)/u
const SEPARATORS = /[_.\- ]+/
const LEADING_SEPARATORS = new RegExp('^' + SEPARATORS.source)
const SEPARATORS_AND_IDENTIFIER = new RegExp(
  SEPARATORS.source + IDENTIFIER$1.source,
  'gu'
)
const NUMBERS_AND_IDENTIFIER = new RegExp('\\d+' + IDENTIFIER$1.source, 'gu')
const preserveCamelCase = (
  string,
  toLowerCase,
  toUpperCase,
  preserveConsecutiveUppercase
) => {
  let isLastCharLower = false
  let isLastCharUpper = false
  let isLastLastCharUpper = false
  let isLastLastCharPreserved = false
  for (let index = 0; index < string.length; index++) {
    const character = string[index]
    isLastLastCharPreserved = index > 2 ? string[index - 3] === '-' : true
    if (isLastCharLower && UPPERCASE.test(character)) {
      string = string.slice(0, index) + '-' + string.slice(index)
      isLastCharLower = false
      isLastLastCharUpper = isLastCharUpper
      isLastCharUpper = true
      index++
    } else if (
      isLastCharUpper &&
      isLastLastCharUpper &&
      LOWERCASE.test(character) &&
      (!isLastLastCharPreserved || preserveConsecutiveUppercase)
    ) {
      string = string.slice(0, index - 1) + '-' + string.slice(index - 1)
      isLastLastCharUpper = isLastCharUpper
      isLastCharUpper = false
      isLastCharLower = true
    } else {
      isLastCharLower =
        toLowerCase(character) === character &&
        toUpperCase(character) !== character
      isLastLastCharUpper = isLastCharUpper
      isLastCharUpper =
        toUpperCase(character) === character &&
        toLowerCase(character) !== character
    }
  }
  return string
}
const preserveConsecutiveUppercase = (input, toLowerCase) => {
  LEADING_CAPITAL.lastIndex = 0
  return input.replaceAll(LEADING_CAPITAL, match => toLowerCase(match))
}
const postProcess = (input, toUpperCase) => {
  SEPARATORS_AND_IDENTIFIER.lastIndex = 0
  NUMBERS_AND_IDENTIFIER.lastIndex = 0
  return input
    .replaceAll(NUMBERS_AND_IDENTIFIER, (match, pattern, offset) =>
      ['_', '-'].includes(input.charAt(offset + match.length))
        ? match
        : toUpperCase(match)
    )
    .replaceAll(SEPARATORS_AND_IDENTIFIER, (_, identifier) =>
      toUpperCase(identifier)
    )
}
function camelCase$2(input, options) {
  if (!(typeof input === 'string' || Array.isArray(input))) {
    throw new TypeError('Expected the input to be `string | string[]`')
  }
  options = {
    pascalCase: false,
    preserveConsecutiveUppercase: false,
    ...options
  }
  if (Array.isArray(input)) {
    input = input
      .map(x => x.trim())
      .filter(x => x.length)
      .join('-')
  } else {
    input = input.trim()
  }
  if (input.length === 0) {
    return ''
  }
  const toLowerCase =
    options.locale === false
      ? string => string.toLowerCase()
      : string => string.toLocaleLowerCase(options.locale)
  const toUpperCase =
    options.locale === false
      ? string => string.toUpperCase()
      : string => string.toLocaleUpperCase(options.locale)
  if (input.length === 1) {
    if (SEPARATORS.test(input)) {
      return ''
    }
    return options.pascalCase ? toUpperCase(input) : toLowerCase(input)
  }
  const hasUpperCase = input !== toLowerCase(input)
  if (hasUpperCase) {
    input = preserveCamelCase(
      input,
      toLowerCase,
      toUpperCase,
      options.preserveConsecutiveUppercase
    )
  }
  input = input.replace(LEADING_SEPARATORS, '')
  input = options.preserveConsecutiveUppercase
    ? preserveConsecutiveUppercase(input, toLowerCase)
    : toLowerCase(input)
  if (options.pascalCase) {
    input = toUpperCase(input.charAt(0)) + input.slice(1)
  }
  return postProcess(input, toUpperCase)
}
class QuickLRU extends Map {
  constructor(options = {}) {
    super()
    if (!(options.maxSize && options.maxSize > 0)) {
      throw new TypeError('`maxSize` must be a number greater than 0')
    }
    if (typeof options.maxAge === 'number' && options.maxAge === 0) {
      throw new TypeError('`maxAge` must be a number greater than 0')
    }
    this.maxSize = options.maxSize
    this.maxAge = options.maxAge || Number.POSITIVE_INFINITY
    this.onEviction = options.onEviction
    this.cache = new Map()
    this.oldCache = new Map()
    this._size = 0
  }
  _emitEvictions(cache) {
    if (typeof this.onEviction !== 'function') {
      return
    }
    for (const [key, item] of cache) {
      this.onEviction(key, item.value)
    }
  }
  _deleteIfExpired(key, item) {
    if (typeof item.expiry === 'number' && item.expiry <= Date.now()) {
      if (typeof this.onEviction === 'function') {
        this.onEviction(key, item.value)
      }
      return this.delete(key)
    }
    return false
  }
  _getOrDeleteIfExpired(key, item) {
    const deleted = this._deleteIfExpired(key, item)
    if (deleted === false) {
      return item.value
    }
  }
  _getItemValue(key, item) {
    return item.expiry ? this._getOrDeleteIfExpired(key, item) : item.value
  }
  _peek(key, cache) {
    const item = cache.get(key)
    return this._getItemValue(key, item)
  }
  _set(key, value) {
    this.cache.set(key, value)
    this._size++
    if (this._size >= this.maxSize) {
      this._size = 0
      this._emitEvictions(this.oldCache)
      this.oldCache = this.cache
      this.cache = new Map()
    }
  }
  _moveToRecent(key, item) {
    this.oldCache.delete(key)
    this._set(key, item)
  }
  *_entriesAscending() {
    for (const item of this.oldCache) {
      const [key, value] = item
      if (!this.cache.has(key)) {
        const deleted = this._deleteIfExpired(key, value)
        if (deleted === false) {
          yield item
        }
      }
    }
    for (const item of this.cache) {
      const [key, value] = item
      const deleted = this._deleteIfExpired(key, value)
      if (deleted === false) {
        yield item
      }
    }
  }
  get(key) {
    if (this.cache.has(key)) {
      const item = this.cache.get(key)
      return this._getItemValue(key, item)
    }
    if (this.oldCache.has(key)) {
      const item = this.oldCache.get(key)
      if (this._deleteIfExpired(key, item) === false) {
        this._moveToRecent(key, item)
        return item.value
      }
    }
  }
  set(key, value, { maxAge = this.maxAge } = {}) {
    const expiry =
      typeof maxAge === 'number' && maxAge !== Number.POSITIVE_INFINITY
        ? Date.now() + maxAge
        : undefined
    if (this.cache.has(key)) {
      this.cache.set(key, {
        value,
        expiry
      })
    } else {
      this._set(key, {
        value,
        expiry
      })
    }
    return this
  }
  has(key) {
    if (this.cache.has(key)) {
      return !this._deleteIfExpired(key, this.cache.get(key))
    }
    if (this.oldCache.has(key)) {
      return !this._deleteIfExpired(key, this.oldCache.get(key))
    }
    return false
  }
  peek(key) {
    if (this.cache.has(key)) {
      return this._peek(key, this.cache)
    }
    if (this.oldCache.has(key)) {
      return this._peek(key, this.oldCache)
    }
  }
  delete(key) {
    const deleted = this.cache.delete(key)
    if (deleted) {
      this._size--
    }
    return this.oldCache.delete(key) || deleted
  }
  clear() {
    this.cache.clear()
    this.oldCache.clear()
    this._size = 0
  }
  resize(newSize) {
    if (!(newSize && newSize > 0)) {
      throw new TypeError('`maxSize` must be a number greater than 0')
    }
    const items = [...this._entriesAscending()]
    const removeCount = items.length - newSize
    if (removeCount < 0) {
      this.cache = new Map(items)
      this.oldCache = new Map()
      this._size = items.length
    } else {
      if (removeCount > 0) {
        this._emitEvictions(items.slice(0, removeCount))
      }
      this.oldCache = new Map(items.slice(removeCount))
      this.cache = new Map()
      this._size = 0
    }
    this.maxSize = newSize
  }
  *keys() {
    for (const [key] of this) {
      yield key
    }
  }
  *values() {
    for (const [, value] of this) {
      yield value
    }
  }
  *[Symbol.iterator]() {
    for (const item of this.cache) {
      const [key, value] = item
      const deleted = this._deleteIfExpired(key, value)
      if (deleted === false) {
        yield [key, value.value]
      }
    }
    for (const item of this.oldCache) {
      const [key, value] = item
      if (!this.cache.has(key)) {
        const deleted = this._deleteIfExpired(key, value)
        if (deleted === false) {
          yield [key, value.value]
        }
      }
    }
  }
  *entriesDescending() {
    let items = [...this.cache]
    for (let i = items.length - 1; i >= 0; --i) {
      const item = items[i]
      const [key, value] = item
      const deleted = this._deleteIfExpired(key, value)
      if (deleted === false) {
        yield [key, value.value]
      }
    }
    items = [...this.oldCache]
    for (let i = items.length - 1; i >= 0; --i) {
      const item = items[i]
      const [key, value] = item
      if (!this.cache.has(key)) {
        const deleted = this._deleteIfExpired(key, value)
        if (deleted === false) {
          yield [key, value.value]
        }
      }
    }
  }
  *entriesAscending() {
    for (const [key, value] of this._entriesAscending()) {
      yield [key, value.value]
    }
  }
  get size() {
    if (!this._size) {
      return this.oldCache.size
    }
    let oldCacheSize = 0
    for (const key of this.oldCache.keys()) {
      if (!this.cache.has(key)) {
        oldCacheSize++
      }
    }
    return Math.min(this._size + oldCacheSize, this.maxSize)
  }
  entries() {
    return this.entriesAscending()
  }
  forEach(callbackFunction, thisArgument = this) {
    for (const [key, value] of this.entriesAscending()) {
      callbackFunction.call(thisArgument, value, key, this)
    }
  }
  get [Symbol.toStringTag]() {
    return JSON.stringify([...this.entriesAscending()])
  }
}
const has$1 = (array, key) =>
  array.some(element => {
    if (typeof element === 'string') {
      return element === key
    }
    element.lastIndex = 0
    return element.test(key)
  })
const cache$2 = new QuickLRU({
  maxSize: 100_000
})
const isObject$2 = value =>
  typeof value === 'object' &&
  value !== null &&
  !(value instanceof RegExp) &&
  !(value instanceof Error) &&
  !(value instanceof Date)
const transform$1 = (input, options = {}) => {
  if (!isObject$2(input)) {
    return input
  }
  const {
    exclude,
    pascalCase = false,
    stopPaths,
    deep = false,
    preserveConsecutiveUppercase = false
  } = options
  const stopPathsSet = new Set(stopPaths)
  const makeMapper = parentPath => (key, value) => {
    if (deep && isObject$2(value)) {
      const path = parentPath === undefined ? key : `${parentPath}.${key}`
      if (!stopPathsSet.has(path)) {
        value = mapObject$2(value, makeMapper(path))
      }
    }
    if (!(exclude && has$1(exclude, key))) {
      const cacheKey = pascalCase ? `${key}_` : key
      if (cache$2.has(cacheKey)) {
        key = cache$2.get(cacheKey)
      } else {
        const returnValue = camelCase$2(key, {
          pascalCase,
          locale: false,
          preserveConsecutiveUppercase
        })
        if (key.length < 100) {
          cache$2.set(cacheKey, returnValue)
        }
        key = returnValue
      }
    }
    return [key, value]
  }
  return mapObject$2(input, makeMapper(undefined))
}
function camelcaseKeys(input, options) {
  if (Array.isArray(input)) {
    return Object.keys(input).map(key => transform$1(input[key], options))
  }
  return transform$1(input, options)
}
function trimNewlines(string) {
  let start = 0
  let end = string.length
  while (start < end && (string[start] === '\r' || string[start] === '\n')) {
    start++
  }
  while (
    end > start &&
    (string[end - 1] === '\r' || string[end - 1] === '\n')
  ) {
    end--
  }
  return start > 0 || end < string.length ? string.slice(start, end) : string
}
function getDefaultExportFromCjs(x) {
  return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default')
    ? x['default']
    : x
}
const minIndent = string => {
  const match = string.match(/^[ \t]*(?=\S)/gm)
  if (!match) {
    return 0
  }
  return match.reduce((r, a) => Math.min(r, a.length), Infinity)
}
const minIndent$1 = getDefaultExportFromCjs(minIndent)
function stripIndent(string) {
  const indent = minIndent$1(string)
  if (indent === 0) {
    return string
  }
  const regex = new RegExp(`^[ \\t]{${indent}}`, 'gm')
  return string.replace(regex, '')
}
function indentString$1(string, count = 1, options = {}) {
  const { indent = ' ', includeEmptyLines = false } = options
  if (typeof string !== 'string') {
    throw new TypeError(
      `Expected \`input\` to be a \`string\`, got \`${typeof string}\``
    )
  }
  if (typeof count !== 'number') {
    throw new TypeError(
      `Expected \`count\` to be a \`number\`, got \`${typeof count}\``
    )
  }
  if (count < 0) {
    throw new RangeError(
      `Expected \`count\` to be at least 0, got \`${count}\``
    )
  }
  if (typeof indent !== 'string') {
    throw new TypeError(
      `Expected \`options.indent\` to be a \`string\`, got \`${typeof indent}\``
    )
  }
  if (count === 0) {
    return string
  }
  const regex = includeEmptyLines ? /^/gm : /^(?!\s*$)/gm
  return string.replace(regex, indent.repeat(count))
}
function redent(string, count = 0, options = {}) {
  return indentString$1(stripIndent(string), count, options)
}
const debug$1 =
  typeof process === 'object' &&
  process.env &&
  process.env.NODE_DEBUG &&
  /\bsemver\b/i.test(process.env.NODE_DEBUG)
    ? (...args) => console.error('SEMVER', ...args)
    : () => {}
const debug_1$1 = debug$1
const MAX_LENGTH$1 = 256
const MAX_SAFE_INTEGER$1 = Number.MAX_SAFE_INTEGER || 9007199254740991
const MAX_SAFE_COMPONENT_LENGTH = 16
const MAX_SAFE_BUILD_LENGTH = MAX_LENGTH$1 - 6
const constants$1$1 = {
  MAX_LENGTH: MAX_LENGTH$1,
  MAX_SAFE_COMPONENT_LENGTH,
  MAX_SAFE_BUILD_LENGTH,
  MAX_SAFE_INTEGER: MAX_SAFE_INTEGER$1
}
const re$1 = {
  exports: {}
}
;(function (module, exports) {
  const { MAX_SAFE_COMPONENT_LENGTH, MAX_SAFE_BUILD_LENGTH, MAX_LENGTH } =
    constants$1$1
  const debug = debug_1$1
  exports = module.exports = {}
  const re = (exports.re = [])
  const safeRe = (exports.safeRe = [])
  const src = (exports.src = [])
  const t = (exports.t = {})
  let R = 0
  const LETTERDASHNUMBER = '[a-zA-Z0-9-]'
  const safeRegexReplacements = [
    ['\\s', 1],
    ['\\d', MAX_LENGTH],
    [LETTERDASHNUMBER, MAX_SAFE_BUILD_LENGTH]
  ]
  const makeSafeRegex = value => {
    for (const [token, max] of safeRegexReplacements) {
      value = value
        .split(`${token}*`)
        .join(`${token}{0,${max}}`)
        .split(`${token}+`)
        .join(`${token}{1,${max}}`)
    }
    return value
  }
  const createToken = (name, value, isGlobal) => {
    const safe = makeSafeRegex(value)
    const index = R++
    debug(name, index, value)
    t[name] = index
    src[index] = value
    re[index] = new RegExp(value, isGlobal ? 'g' : undefined)
    safeRe[index] = new RegExp(safe, isGlobal ? 'g' : undefined)
  }
  createToken('NUMERICIDENTIFIER', '0|[1-9]\\d*')
  createToken('NUMERICIDENTIFIERLOOSE', '\\d+')
  createToken('NONNUMERICIDENTIFIER', `\\d*[a-zA-Z-]${LETTERDASHNUMBER}*`)
  createToken(
    'MAINVERSION',
    `(${src[t.NUMERICIDENTIFIER]})\\.` +
      `(${src[t.NUMERICIDENTIFIER]})\\.` +
      `(${src[t.NUMERICIDENTIFIER]})`
  )
  createToken(
    'MAINVERSIONLOOSE',
    `(${src[t.NUMERICIDENTIFIERLOOSE]})\\.` +
      `(${src[t.NUMERICIDENTIFIERLOOSE]})\\.` +
      `(${src[t.NUMERICIDENTIFIERLOOSE]})`
  )
  createToken(
    'PRERELEASEIDENTIFIER',
    `(?:${src[t.NUMERICIDENTIFIER]}|${src[t.NONNUMERICIDENTIFIER]})`
  )
  createToken(
    'PRERELEASEIDENTIFIERLOOSE',
    `(?:${src[t.NUMERICIDENTIFIERLOOSE]}|${src[t.NONNUMERICIDENTIFIER]})`
  )
  createToken(
    'PRERELEASE',
    `(?:-(${src[t.PRERELEASEIDENTIFIER]}(?:\\.${src[t.PRERELEASEIDENTIFIER]})*))`
  )
  createToken(
    'PRERELEASELOOSE',
    `(?:-?(${src[t.PRERELEASEIDENTIFIERLOOSE]}(?:\\.${src[t.PRERELEASEIDENTIFIERLOOSE]})*))`
  )
  createToken('BUILDIDENTIFIER', `${LETTERDASHNUMBER}+`)
  createToken(
    'BUILD',
    `(?:\\+(${src[t.BUILDIDENTIFIER]}(?:\\.${src[t.BUILDIDENTIFIER]})*))`
  )
  createToken(
    'FULLPLAIN',
    `v?${src[t.MAINVERSION]}${src[t.PRERELEASE]}?${src[t.BUILD]}?`
  )
  createToken('FULL', `^${src[t.FULLPLAIN]}$`)
  createToken(
    'LOOSEPLAIN',
    `[v=\\s]*${src[t.MAINVERSIONLOOSE]}${src[t.PRERELEASELOOSE]}?${src[t.BUILD]}?`
  )
  createToken('LOOSE', `^${src[t.LOOSEPLAIN]}$`)
  createToken('GTLT', '((?:<|>)?=?)')
  createToken(
    'XRANGEIDENTIFIERLOOSE',
    `${src[t.NUMERICIDENTIFIERLOOSE]}|x|X|\\*`
  )
  createToken('XRANGEIDENTIFIER', `${src[t.NUMERICIDENTIFIER]}|x|X|\\*`)
  createToken(
    'XRANGEPLAIN',
    `[v=\\s]*(${src[t.XRANGEIDENTIFIER]})` +
      `(?:\\.(${src[t.XRANGEIDENTIFIER]})` +
      `(?:\\.(${src[t.XRANGEIDENTIFIER]})` +
      `(?:${src[t.PRERELEASE]})?${src[t.BUILD]}?` +
      `)?)?`
  )
  createToken(
    'XRANGEPLAINLOOSE',
    `[v=\\s]*(${src[t.XRANGEIDENTIFIERLOOSE]})` +
      `(?:\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +
      `(?:\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +
      `(?:${src[t.PRERELEASELOOSE]})?${src[t.BUILD]}?` +
      `)?)?`
  )
  createToken('XRANGE', `^${src[t.GTLT]}\\s*${src[t.XRANGEPLAIN]}$`)
  createToken('XRANGELOOSE', `^${src[t.GTLT]}\\s*${src[t.XRANGEPLAINLOOSE]}$`)
  createToken(
    'COERCEPLAIN',
    `${'(^|[^\\d])' + '(\\d{1,'}${MAX_SAFE_COMPONENT_LENGTH}})` +
      `(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?` +
      `(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?`
  )
  createToken('COERCE', `${src[t.COERCEPLAIN]}(?:$|[^\\d])`)
  createToken(
    'COERCEFULL',
    src[t.COERCEPLAIN] +
      `(?:${src[t.PRERELEASE]})?` +
      `(?:${src[t.BUILD]})?` +
      `(?:$|[^\\d])`
  )
  createToken('COERCERTL', src[t.COERCE], true)
  createToken('COERCERTLFULL', src[t.COERCEFULL], true)
  createToken('LONETILDE', '(?:~>?)')
  createToken('TILDETRIM', `(\\s*)${src[t.LONETILDE]}\\s+`, true)
  exports.tildeTrimReplace = '$1~'
  createToken('TILDE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAIN]}$`)
  createToken('TILDELOOSE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAINLOOSE]}$`)
  createToken('LONECARET', '(?:\\^)')
  createToken('CARETTRIM', `(\\s*)${src[t.LONECARET]}\\s+`, true)
  exports.caretTrimReplace = '$1^'
  createToken('CARET', `^${src[t.LONECARET]}${src[t.XRANGEPLAIN]}$`)
  createToken('CARETLOOSE', `^${src[t.LONECARET]}${src[t.XRANGEPLAINLOOSE]}$`)
  createToken(
    'COMPARATORLOOSE',
    `^${src[t.GTLT]}\\s*(${src[t.LOOSEPLAIN]})$|^$`
  )
  createToken('COMPARATOR', `^${src[t.GTLT]}\\s*(${src[t.FULLPLAIN]})$|^$`)
  createToken(
    'COMPARATORTRIM',
    `(\\s*)${src[t.GTLT]}\\s*(${src[t.LOOSEPLAIN]}|${src[t.XRANGEPLAIN]})`,
    true
  )
  exports.comparatorTrimReplace = '$1$2$3'
  createToken(
    'HYPHENRANGE',
    `^\\s*(${src[t.XRANGEPLAIN]})` +
      `\\s+-\\s+` +
      `(${src[t.XRANGEPLAIN]})` +
      `\\s*$`
  )
  createToken(
    'HYPHENRANGELOOSE',
    `^\\s*(${src[t.XRANGEPLAINLOOSE]})` +
      `\\s+-\\s+` +
      `(${src[t.XRANGEPLAINLOOSE]})` +
      `\\s*$`
  )
  createToken('STAR', '(<|>)?=?\\s*\\*')
  createToken('GTE0', '^\\s*>=\\s*0\\.0\\.0\\s*$')
  createToken('GTE0PRE', '^\\s*>=\\s*0\\.0\\.0-0\\s*$')
})(re$1, re$1.exports)
const reExports = re$1.exports
const looseOption = Object.freeze({
  loose: true
})
const emptyOpts = Object.freeze({})
const parseOptions$1 = options => {
  if (!options) {
    return emptyOpts
  }
  if (typeof options !== 'object') {
    return looseOption
  }
  return options
}
const parseOptions_1$1 = parseOptions$1
const numeric = /^[0-9]+$/
const compareIdentifiers$1 = (a, b) => {
  const anum = numeric.test(a)
  const bnum = numeric.test(b)
  if (anum && bnum) {
    a = +a
    b = +b
  }
  return a === b ? 0 : anum && !bnum ? -1 : bnum && !anum ? 1 : a < b ? -1 : 1
}
const identifiers$1 = {
  compareIdentifiers: compareIdentifiers$1
}
const debug = debug_1$1
const { MAX_LENGTH, MAX_SAFE_INTEGER } = constants$1$1
const { safeRe: re$2, t } = reExports
const parseOptions = parseOptions_1$1
const { compareIdentifiers } = identifiers$1
let SemVer$1 = class SemVer {
  constructor(version, options) {
    options = parseOptions(options)
    if (version instanceof SemVer) {
      if (
        version.loose === !!options.loose &&
        version.includePrerelease === !!options.includePrerelease
      ) {
        return version
      } else {
        version = version.version
      }
    } else if (typeof version !== 'string') {
      throw new TypeError(
        `Invalid version. Must be a string. Got type "${typeof version}".`
      )
    }
    if (version.length > MAX_LENGTH) {
      throw new TypeError(`version is longer than ${MAX_LENGTH} characters`)
    }
    debug('SemVer', version, options)
    this.options = options
    this.loose = !!options.loose
    this.includePrerelease = !!options.includePrerelease
    const m = version.trim().match(options.loose ? re$2[t.LOOSE] : re$2[t.FULL])
    if (!m) {
      throw new TypeError(`Invalid Version: ${version}`)
    }
    this.raw = version
    this.major = +m[1]
    this.minor = +m[2]
    this.patch = +m[3]
    if (this.major > MAX_SAFE_INTEGER || this.major < 0) {
      throw new TypeError('Invalid major version')
    }
    if (this.minor > MAX_SAFE_INTEGER || this.minor < 0) {
      throw new TypeError('Invalid minor version')
    }
    if (this.patch > MAX_SAFE_INTEGER || this.patch < 0) {
      throw new TypeError('Invalid patch version')
    }
    if (!m[4]) {
      this.prerelease = []
    } else {
      this.prerelease = m[4].split('.').map(id => {
        if (/^[0-9]+$/.test(id)) {
          const num = +id
          if (num >= 0 && num < MAX_SAFE_INTEGER) {
            return num
          }
        }
        return id
      })
    }
    this.build = m[5] ? m[5].split('.') : []
    this.format()
  }
  format() {
    this.version = `${this.major}.${this.minor}.${this.patch}`
    if (this.prerelease.length) {
      this.version += `-${this.prerelease.join('.')}`
    }
    return this.version
  }
  toString() {
    return this.version
  }
  compare(other) {
    debug('SemVer.compare', this.version, this.options, other)
    if (!(other instanceof SemVer)) {
      if (typeof other === 'string' && other === this.version) {
        return 0
      }
      other = new SemVer(other, this.options)
    }
    if (other.version === this.version) {
      return 0
    }
    return this.compareMain(other) || this.comparePre(other)
  }
  compareMain(other) {
    if (!(other instanceof SemVer)) {
      other = new SemVer(other, this.options)
    }
    return (
      compareIdentifiers(this.major, other.major) ||
      compareIdentifiers(this.minor, other.minor) ||
      compareIdentifiers(this.patch, other.patch)
    )
  }
  comparePre(other) {
    if (!(other instanceof SemVer)) {
      other = new SemVer(other, this.options)
    }
    if (this.prerelease.length && !other.prerelease.length) {
      return -1
    } else if (!this.prerelease.length && other.prerelease.length) {
      return 1
    } else if (!this.prerelease.length && !other.prerelease.length) {
      return 0
    }
    let i = 0
    do {
      const a = this.prerelease[i]
      const b = other.prerelease[i]
      debug('prerelease compare', i, a, b)
      if (a === undefined && b === undefined) {
        return 0
      } else if (b === undefined) {
        return 1
      } else if (a === undefined) {
        return -1
      } else if (a === b) {
        continue
      } else {
        return compareIdentifiers(a, b)
      }
    } while (++i)
  }
  compareBuild(other) {
    if (!(other instanceof SemVer)) {
      other = new SemVer(other, this.options)
    }
    let i = 0
    do {
      const a = this.build[i]
      const b = other.build[i]
      debug('prerelease compare', i, a, b)
      if (a === undefined && b === undefined) {
        return 0
      } else if (b === undefined) {
        return 1
      } else if (a === undefined) {
        return -1
      } else if (a === b) {
        continue
      } else {
        return compareIdentifiers(a, b)
      }
    } while (++i)
  }
  inc(release, identifier, identifierBase) {
    switch (release) {
      case 'premajor':
        this.prerelease.length = 0
        this.patch = 0
        this.minor = 0
        this.major++
        this.inc('pre', identifier, identifierBase)
        break
      case 'preminor':
        this.prerelease.length = 0
        this.patch = 0
        this.minor++
        this.inc('pre', identifier, identifierBase)
        break
      case 'prepatch':
        this.prerelease.length = 0
        this.inc('patch', identifier, identifierBase)
        this.inc('pre', identifier, identifierBase)
        break
      case 'prerelease':
        if (this.prerelease.length === 0) {
          this.inc('patch', identifier, identifierBase)
        }
        this.inc('pre', identifier, identifierBase)
        break
      case 'major':
        if (
          this.minor !== 0 ||
          this.patch !== 0 ||
          this.prerelease.length === 0
        ) {
          this.major++
        }
        this.minor = 0
        this.patch = 0
        this.prerelease = []
        break
      case 'minor':
        if (this.patch !== 0 || this.prerelease.length === 0) {
          this.minor++
        }
        this.patch = 0
        this.prerelease = []
        break
      case 'patch':
        if (this.prerelease.length === 0) {
          this.patch++
        }
        this.prerelease = []
        break
      case 'pre': {
        const base = Number(identifierBase) ? 1 : 0
        if (!identifier && identifierBase === false) {
          throw new Error('invalid increment argument: identifier is empty')
        }
        if (this.prerelease.length === 0) {
          this.prerelease = [base]
        } else {
          let i = this.prerelease.length
          while (--i >= 0) {
            if (typeof this.prerelease[i] === 'number') {
              this.prerelease[i]++
              i = -2
            }
          }
          if (i === -1) {
            if (
              identifier === this.prerelease.join('.') &&
              identifierBase === false
            ) {
              throw new Error(
                'invalid increment argument: identifier already exists'
              )
            }
            this.prerelease.push(base)
          }
        }
        if (identifier) {
          let prerelease = [identifier, base]
          if (identifierBase === false) {
            prerelease = [identifier]
          }
          if (compareIdentifiers(this.prerelease[0], identifier) === 0) {
            if (isNaN(this.prerelease[1])) {
              this.prerelease = prerelease
            }
          } else {
            this.prerelease = prerelease
          }
        }
        break
      }
      default:
        throw new Error(`invalid increment argument: ${release}`)
    }
    this.raw = this.format()
    if (this.build.length) {
      this.raw += `+${this.build.join('.')}`
    }
    return this
  }
}
const semver$2 = SemVer$1
const SemVer = semver$2
const parse$6 = (version, options, throwErrors = false) => {
  if (version instanceof SemVer) {
    return version
  }
  try {
    return new SemVer(version, options)
  } catch (er) {
    if (!throwErrors) {
      return null
    }
    throw er
  }
}
const parse_1$2 = parse$6
const parse$5 = parse_1$2
const valid$1 = (version, options) => {
  const v = parse$5(version, options)
  return v ? v.version : null
}
const valid_1$1 = valid$1
const parse$4 = parse_1$2
const clean = (version, options) => {
  const s = parse$4(version.trim().replace(/^[=v]+/, ''), options)
  return s ? s.version : null
}
const clean_1$1 = clean
const require$$1$3 = [
  '0BSD',
  'AAL',
  'ADSL',
  'AFL-1.1',
  'AFL-1.2',
  'AFL-2.0',
  'AFL-2.1',
  'AFL-3.0',
  'AGPL-1.0-only',
  'AGPL-1.0-or-later',
  'AGPL-3.0-only',
  'AGPL-3.0-or-later',
  'AMDPLPA',
  'AML',
  'AMPAS',
  'ANTLR-PD',
  'ANTLR-PD-fallback',
  'APAFML',
  'APL-1.0',
  'APSL-1.0',
  'APSL-1.1',
  'APSL-1.2',
  'APSL-2.0',
  'ASWF-Digital-Assets-1.0',
  'ASWF-Digital-Assets-1.1',
  'Abstyles',
  'AdaCore-doc',
  'Adobe-2006',
  'Adobe-Glyph',
  'Adobe-Utopia',
  'Afmparse',
  'Aladdin',
  'Apache-1.0',
  'Apache-1.1',
  'Apache-2.0',
  'App-s2p',
  'Arphic-1999',
  'Artistic-1.0',
  'Artistic-1.0-Perl',
  'Artistic-1.0-cl8',
  'Artistic-2.0',
  'BSD-1-Clause',
  'BSD-2-Clause',
  'BSD-2-Clause-Patent',
  'BSD-2-Clause-Views',
  'BSD-3-Clause',
  'BSD-3-Clause-Attribution',
  'BSD-3-Clause-Clear',
  'BSD-3-Clause-HP',
  'BSD-3-Clause-LBNL',
  'BSD-3-Clause-Modification',
  'BSD-3-Clause-No-Military-License',
  'BSD-3-Clause-No-Nuclear-License',
  'BSD-3-Clause-No-Nuclear-License-2014',
  'BSD-3-Clause-No-Nuclear-Warranty',
  'BSD-3-Clause-Open-MPI',
  'BSD-3-Clause-Sun',
  'BSD-3-Clause-flex',
  'BSD-4-Clause',
  'BSD-4-Clause-Shortened',
  'BSD-4-Clause-UC',
  'BSD-4.3RENO',
  'BSD-4.3TAHOE',
  'BSD-Advertising-Acknowledgement',
  'BSD-Attribution-HPND-disclaimer',
  'BSD-Inferno-Nettverk',
  'BSD-Protection',
  'BSD-Source-Code',
  'BSD-Systemics',
  'BSL-1.0',
  'BUSL-1.1',
  'Baekmuk',
  'Bahyph',
  'Barr',
  'Beerware',
  'BitTorrent-1.0',
  'BitTorrent-1.1',
  'Bitstream-Charter',
  'Bitstream-Vera',
  'BlueOak-1.0.0',
  'Boehm-GC',
  'Borceux',
  'Brian-Gladman-3-Clause',
  'C-UDA-1.0',
  'CAL-1.0',
  'CAL-1.0-Combined-Work-Exception',
  'CATOSL-1.1',
  'CC-BY-1.0',
  'CC-BY-2.0',
  'CC-BY-2.5',
  'CC-BY-2.5-AU',
  'CC-BY-3.0',
  'CC-BY-3.0-AT',
  'CC-BY-3.0-DE',
  'CC-BY-3.0-IGO',
  'CC-BY-3.0-NL',
  'CC-BY-3.0-US',
  'CC-BY-4.0',
  'CC-BY-NC-1.0',
  'CC-BY-NC-2.0',
  'CC-BY-NC-2.5',
  'CC-BY-NC-3.0',
  'CC-BY-NC-3.0-DE',
  'CC-BY-NC-4.0',
  'CC-BY-NC-ND-1.0',
  'CC-BY-NC-ND-2.0',
  'CC-BY-NC-ND-2.5',
  'CC-BY-NC-ND-3.0',
  'CC-BY-NC-ND-3.0-DE',
  'CC-BY-NC-ND-3.0-IGO',
  'CC-BY-NC-ND-4.0',
  'CC-BY-NC-SA-1.0',
  'CC-BY-NC-SA-2.0',
  'CC-BY-NC-SA-2.0-DE',
  'CC-BY-NC-SA-2.0-FR',
  'CC-BY-NC-SA-2.0-UK',
  'CC-BY-NC-SA-2.5',
  'CC-BY-NC-SA-3.0',
  'CC-BY-NC-SA-3.0-DE',
  'CC-BY-NC-SA-3.0-IGO',
  'CC-BY-NC-SA-4.0',
  'CC-BY-ND-1.0',
  'CC-BY-ND-2.0',
  'CC-BY-ND-2.5',
  'CC-BY-ND-3.0',
  'CC-BY-ND-3.0-DE',
  'CC-BY-ND-4.0',
  'CC-BY-SA-1.0',
  'CC-BY-SA-2.0',
  'CC-BY-SA-2.0-UK',
  'CC-BY-SA-2.1-JP',
  'CC-BY-SA-2.5',
  'CC-BY-SA-3.0',
  'CC-BY-SA-3.0-AT',
  'CC-BY-SA-3.0-DE',
  'CC-BY-SA-3.0-IGO',
  'CC-BY-SA-4.0',
  'CC-PDDC',
  'CC0-1.0',
  'CDDL-1.0',
  'CDDL-1.1',
  'CDL-1.0',
  'CDLA-Permissive-1.0',
  'CDLA-Permissive-2.0',
  'CDLA-Sharing-1.0',
  'CECILL-1.0',
  'CECILL-1.1',
  'CECILL-2.0',
  'CECILL-2.1',
  'CECILL-B',
  'CECILL-C',
  'CERN-OHL-1.1',
  'CERN-OHL-1.2',
  'CERN-OHL-P-2.0',
  'CERN-OHL-S-2.0',
  'CERN-OHL-W-2.0',
  'CFITSIO',
  'CMU-Mach',
  'CNRI-Jython',
  'CNRI-Python',
  'CNRI-Python-GPL-Compatible',
  'COIL-1.0',
  'CPAL-1.0',
  'CPL-1.0',
  'CPOL-1.02',
  'CUA-OPL-1.0',
  'Caldera',
  'ClArtistic',
  'Clips',
  'Community-Spec-1.0',
  'Condor-1.1',
  'Cornell-Lossless-JPEG',
  'Cronyx',
  'Crossword',
  'CrystalStacker',
  'Cube',
  'D-FSL-1.0',
  'DL-DE-BY-2.0',
  'DL-DE-ZERO-2.0',
  'DOC',
  'DRL-1.0',
  'DSDP',
  'Dotseqn',
  'ECL-1.0',
  'ECL-2.0',
  'EFL-1.0',
  'EFL-2.0',
  'EPICS',
  'EPL-1.0',
  'EPL-2.0',
  'EUDatagrid',
  'EUPL-1.0',
  'EUPL-1.1',
  'EUPL-1.2',
  'Elastic-2.0',
  'Entessa',
  'ErlPL-1.1',
  'Eurosym',
  'FBM',
  'FDK-AAC',
  'FSFAP',
  'FSFUL',
  'FSFULLR',
  'FSFULLRWD',
  'FTL',
  'Fair',
  'Ferguson-Twofish',
  'Frameworx-1.0',
  'FreeBSD-DOC',
  'FreeImage',
  'Furuseth',
  'GD',
  'GFDL-1.1-invariants-only',
  'GFDL-1.1-invariants-or-later',
  'GFDL-1.1-no-invariants-only',
  'GFDL-1.1-no-invariants-or-later',
  'GFDL-1.1-only',
  'GFDL-1.1-or-later',
  'GFDL-1.2-invariants-only',
  'GFDL-1.2-invariants-or-later',
  'GFDL-1.2-no-invariants-only',
  'GFDL-1.2-no-invariants-or-later',
  'GFDL-1.2-only',
  'GFDL-1.2-or-later',
  'GFDL-1.3-invariants-only',
  'GFDL-1.3-invariants-or-later',
  'GFDL-1.3-no-invariants-only',
  'GFDL-1.3-no-invariants-or-later',
  'GFDL-1.3-only',
  'GFDL-1.3-or-later',
  'GL2PS',
  'GLWTPL',
  'GPL-1.0-only',
  'GPL-1.0-or-later',
  'GPL-2.0-only',
  'GPL-2.0-or-later',
  'GPL-3.0-only',
  'GPL-3.0-or-later',
  'Giftware',
  'Glide',
  'Glulxe',
  'Graphics-Gems',
  'HP-1986',
  'HP-1989',
  'HPND',
  'HPND-DEC',
  'HPND-Markus-Kuhn',
  'HPND-Pbmplus',
  'HPND-UC',
  'HPND-doc',
  'HPND-doc-sell',
  'HPND-export-US',
  'HPND-export-US-modify',
  'HPND-sell-regexpr',
  'HPND-sell-variant',
  'HPND-sell-variant-MIT-disclaimer',
  'HTMLTIDY',
  'HaskellReport',
  'Hippocratic-2.1',
  'IBM-pibs',
  'ICU',
  'IEC-Code-Components-EULA',
  'IJG',
  'IJG-short',
  'IPA',
  'IPL-1.0',
  'ISC',
  'ImageMagick',
  'Imlib2',
  'Info-ZIP',
  'Inner-Net-2.0',
  'Intel',
  'Intel-ACPI',
  'Interbase-1.0',
  'JPL-image',
  'JPNIC',
  'JSON',
  'Jam',
  'JasPer-2.0',
  'Kastrup',
  'Kazlib',
  'Knuth-CTAN',
  'LAL-1.2',
  'LAL-1.3',
  'LGPL-2.0-only',
  'LGPL-2.0-or-later',
  'LGPL-2.1-only',
  'LGPL-2.1-or-later',
  'LGPL-3.0-only',
  'LGPL-3.0-or-later',
  'LGPLLR',
  'LOOP',
  'LPL-1.0',
  'LPL-1.02',
  'LPPL-1.0',
  'LPPL-1.1',
  'LPPL-1.2',
  'LPPL-1.3a',
  'LPPL-1.3c',
  'LZMA-SDK-9.11-to-9.20',
  'LZMA-SDK-9.22',
  'Latex2e',
  'Latex2e-translated-notice',
  'Leptonica',
  'LiLiQ-P-1.1',
  'LiLiQ-R-1.1',
  'LiLiQ-Rplus-1.1',
  'Libpng',
  'Linux-OpenIB',
  'Linux-man-pages-1-para',
  'Linux-man-pages-copyleft',
  'Linux-man-pages-copyleft-2-para',
  'Linux-man-pages-copyleft-var',
  'Lucida-Bitmap-Fonts',
  'MIT',
  'MIT-0',
  'MIT-CMU',
  'MIT-Festival',
  'MIT-Modern-Variant',
  'MIT-Wu',
  'MIT-advertising',
  'MIT-enna',
  'MIT-feh',
  'MIT-open-group',
  'MIT-testregex',
  'MITNFA',
  'MMIXware',
  'MPEG-SSG',
  'MPL-1.0',
  'MPL-1.1',
  'MPL-2.0',
  'MPL-2.0-no-copyleft-exception',
  'MS-LPL',
  'MS-PL',
  'MS-RL',
  'MTLL',
  'MakeIndex',
  'Martin-Birgmeier',
  'McPhee-slideshow',
  'Minpack',
  'MirOS',
  'Motosoto',
  'MulanPSL-1.0',
  'MulanPSL-2.0',
  'Multics',
  'Mup',
  'NAIST-2003',
  'NASA-1.3',
  'NBPL-1.0',
  'NCGL-UK-2.0',
  'NCSA',
  'NGPL',
  'NICTA-1.0',
  'NIST-PD',
  'NIST-PD-fallback',
  'NIST-Software',
  'NLOD-1.0',
  'NLOD-2.0',
  'NLPL',
  'NOSL',
  'NPL-1.0',
  'NPL-1.1',
  'NPOSL-3.0',
  'NRL',
  'NTP',
  'NTP-0',
  'Naumen',
  'Net-SNMP',
  'NetCDF',
  'Newsletr',
  'Nokia',
  'Noweb',
  'O-UDA-1.0',
  'OCCT-PL',
  'OCLC-2.0',
  'ODC-By-1.0',
  'ODbL-1.0',
  'OFFIS',
  'OFL-1.0',
  'OFL-1.0-RFN',
  'OFL-1.0-no-RFN',
  'OFL-1.1',
  'OFL-1.1-RFN',
  'OFL-1.1-no-RFN',
  'OGC-1.0',
  'OGDL-Taiwan-1.0',
  'OGL-Canada-2.0',
  'OGL-UK-1.0',
  'OGL-UK-2.0',
  'OGL-UK-3.0',
  'OGTSL',
  'OLDAP-1.1',
  'OLDAP-1.2',
  'OLDAP-1.3',
  'OLDAP-1.4',
  'OLDAP-2.0',
  'OLDAP-2.0.1',
  'OLDAP-2.1',
  'OLDAP-2.2',
  'OLDAP-2.2.1',
  'OLDAP-2.2.2',
  'OLDAP-2.3',
  'OLDAP-2.4',
  'OLDAP-2.5',
  'OLDAP-2.6',
  'OLDAP-2.7',
  'OLDAP-2.8',
  'OLFL-1.3',
  'OML',
  'OPL-1.0',
  'OPL-UK-3.0',
  'OPUBL-1.0',
  'OSET-PL-2.1',
  'OSL-1.0',
  'OSL-1.1',
  'OSL-2.0',
  'OSL-2.1',
  'OSL-3.0',
  'OpenPBS-2.3',
  'OpenSSL',
  'PADL',
  'PDDL-1.0',
  'PHP-3.0',
  'PHP-3.01',
  'PSF-2.0',
  'Parity-6.0.0',
  'Parity-7.0.0',
  'Plexus',
  'PolyForm-Noncommercial-1.0.0',
  'PolyForm-Small-Business-1.0.0',
  'PostgreSQL',
  'Python-2.0',
  'Python-2.0.1',
  'QPL-1.0',
  'QPL-1.0-INRIA-2004',
  'Qhull',
  'RHeCos-1.1',
  'RPL-1.1',
  'RPL-1.5',
  'RPSL-1.0',
  'RSA-MD',
  'RSCPL',
  'Rdisc',
  'Ruby',
  'SAX-PD',
  'SCEA',
  'SGI-B-1.0',
  'SGI-B-1.1',
  'SGI-B-2.0',
  'SGI-OpenGL',
  'SGP4',
  'SHL-0.5',
  'SHL-0.51',
  'SISSL',
  'SISSL-1.2',
  'SL',
  'SMLNJ',
  'SMPPL',
  'SNIA',
  'SPL-1.0',
  'SSH-OpenSSH',
  'SSH-short',
  'SSPL-1.0',
  'SWL',
  'Saxpath',
  'SchemeReport',
  'Sendmail',
  'Sendmail-8.23',
  'SimPL-2.0',
  'Sleepycat',
  'Soundex',
  'Spencer-86',
  'Spencer-94',
  'Spencer-99',
  'SugarCRM-1.1.3',
  'SunPro',
  'Symlinks',
  'TAPR-OHL-1.0',
  'TCL',
  'TCP-wrappers',
  'TMate',
  'TORQUE-1.1',
  'TOSL',
  'TPDL',
  'TPL-1.0',
  'TTWL',
  'TTYP0',
  'TU-Berlin-1.0',
  'TU-Berlin-2.0',
  'TermReadKey',
  'UCAR',
  'UCL-1.0',
  'UPL-1.0',
  'URT-RLE',
  'Unicode-DFS-2015',
  'Unicode-DFS-2016',
  'Unicode-TOU',
  'UnixCrypt',
  'Unlicense',
  'VOSTROM',
  'VSL-1.0',
  'Vim',
  'W3C',
  'W3C-19980720',
  'W3C-20150513',
  'WTFPL',
  'Watcom-1.0',
  'Widget-Workshop',
  'Wsuipa',
  'X11',
  'X11-distribute-modifications-variant',
  'XFree86-1.1',
  'XSkat',
  'Xdebug-1.03',
  'Xerox',
  'Xfig',
  'Xnet',
  'YPL-1.0',
  'YPL-1.1',
  'ZPL-1.1',
  'ZPL-2.0',
  'ZPL-2.1',
  'Zed',
  'Zeeff',
  'Zend-2.0',
  'Zimbra-1.3',
  'Zimbra-1.4',
  'Zlib',
  'blessing',
  'bzip2-1.0.6',
  'check-cvs',
  'checkmk',
  'copyleft-next-0.3.0',
  'copyleft-next-0.3.1',
  'curl',
  'diffmark',
  'dtoa',
  'dvipdfm',
  'eGenix',
  'etalab-2.0',
  'fwlw',
  'gSOAP-1.3b',
  'gnuplot',
  'iMatix',
  'libpng-2.0',
  'libselinux-1.0',
  'libtiff',
  'libutil-David-Nugent',
  'lsof',
  'magaz',
  'metamail',
  'mpi-permissive',
  'mpich2',
  'mplus',
  'pnmstitch',
  'psfrag',
  'psutils',
  'python-ldap',
  'snprintf',
  'ssh-keyscan',
  'swrule',
  'ulem',
  'w3m',
  'xinetd',
  'xlock',
  'xpp',
  'zlib-acknowledgement'
]
const require$$1$2 = [
  'AGPL-1.0',
  'AGPL-3.0',
  'BSD-2-Clause-FreeBSD',
  'BSD-2-Clause-NetBSD',
  'GFDL-1.1',
  'GFDL-1.2',
  'GFDL-1.3',
  'GPL-1.0',
  'GPL-1.0+',
  'GPL-2.0',
  'GPL-2.0+',
  'GPL-2.0-with-GCC-exception',
  'GPL-2.0-with-autoconf-exception',
  'GPL-2.0-with-bison-exception',
  'GPL-2.0-with-classpath-exception',
  'GPL-2.0-with-font-exception',
  'GPL-3.0',
  'GPL-3.0+',
  'GPL-3.0-with-GCC-exception',
  'GPL-3.0-with-autoconf-exception',
  'LGPL-2.0',
  'LGPL-2.0+',
  'LGPL-2.1',
  'LGPL-2.1+',
  'LGPL-3.0',
  'LGPL-3.0+',
  'Nunit',
  'StandardML-NJ',
  'bzip2-1.0.5',
  'eCos-2.0',
  'wxWindows'
]
const require$$2 = [
  '389-exception',
  'Asterisk-exception',
  'Autoconf-exception-2.0',
  'Autoconf-exception-3.0',
  'Autoconf-exception-generic',
  'Autoconf-exception-generic-3.0',
  'Autoconf-exception-macro',
  'Bison-exception-2.2',
  'Bootloader-exception',
  'Classpath-exception-2.0',
  'CLISP-exception-2.0',
  'cryptsetup-OpenSSL-exception',
  'DigiRule-FOSS-exception',
  'eCos-exception-2.0',
  'Fawkes-Runtime-exception',
  'FLTK-exception',
  'Font-exception-2.0',
  'freertos-exception-2.0',
  'GCC-exception-2.0',
  'GCC-exception-2.0-note',
  'GCC-exception-3.1',
  'GNAT-exception',
  'GNU-compiler-exception',
  'gnu-javamail-exception',
  'GPL-3.0-interface-exception',
  'GPL-3.0-linking-exception',
  'GPL-3.0-linking-source-exception',
  'GPL-CC-1.0',
  'GStreamer-exception-2005',
  'GStreamer-exception-2008',
  'i2p-gpl-java-exception',
  'KiCad-libraries-exception',
  'LGPL-3.0-linking-exception',
  'libpri-OpenH323-exception',
  'Libtool-exception',
  'Linux-syscall-note',
  'LLGPL',
  'LLVM-exception',
  'LZMA-exception',
  'mif-exception',
  'OCaml-LGPL-linking-exception',
  'OCCT-exception-1.0',
  'OpenJDK-assembly-exception-1.0',
  'openvpn-openssl-exception',
  'PS-or-PDF-font-exception-20170817',
  'QPL-1.0-INRIA-2004-exception',
  'Qt-GPL-exception-1.0',
  'Qt-LGPL-exception-1.1',
  'Qwt-exception-1.0',
  'SANE-exception',
  'SHL-2.0',
  'SHL-2.1',
  'stunnel-exception',
  'SWI-exception',
  'Swift-exception',
  'Texinfo-exception',
  'u-boot-exception-2.0',
  'UBDL-exception',
  'Universal-FOSS-exception-1.0',
  'vsftpd-openssl-exception',
  'WxWindows-exception-3.1',
  'x11vnc-openssl-exception'
]
const licenses = [].concat(require$$1$3).concat(require$$1$2)
const exceptions = require$$2
const scan$1 = function (source) {
  let index = 0
  function hasMore() {
    return index < source.length
  }
  function read(value) {
    if (value instanceof RegExp) {
      const chars = source.slice(index)
      const match = chars.match(value)
      if (match) {
        index += match[0].length
        return match[0]
      }
    } else {
      if (source.indexOf(value, index) === index) {
        index += value.length
        return value
      }
    }
  }
  function skipWhitespace() {
    read(/[ ]*/)
  }
  function operator() {
    let string
    const possibilities = ['WITH', 'AND', 'OR', '(', ')', ':', '+']
    for (let i = 0; i < possibilities.length; i++) {
      string = read(possibilities[i])
      if (string) {
        break
      }
    }
    if (string === '+' && index > 1 && source[index - 2] === ' ') {
      throw new Error('Space before `+`')
    }
    return (
      string && {
        type: 'OPERATOR',
        string: string
      }
    )
  }
  function idstring() {
    return read(/[A-Za-z0-9-.]+/)
  }
  function expectIdstring() {
    const string = idstring()
    if (!string) {
      throw new Error('Expected idstring at offset ' + index)
    }
    return string
  }
  function documentRef() {
    if (read('DocumentRef-')) {
      const string = expectIdstring()
      return {
        type: 'DOCUMENTREF',
        string: string
      }
    }
  }
  function licenseRef() {
    if (read('LicenseRef-')) {
      const string = expectIdstring()
      return {
        type: 'LICENSEREF',
        string: string
      }
    }
  }
  function identifier() {
    const begin = index
    const string = idstring()
    if (licenses.indexOf(string) !== -1) {
      return {
        type: 'LICENSE',
        string: string
      }
    } else if (exceptions.indexOf(string) !== -1) {
      return {
        type: 'EXCEPTION',
        string: string
      }
    }
    index = begin
  }
  function parseToken() {
    return operator() || documentRef() || licenseRef() || identifier()
  }
  const tokens = []
  while (hasMore()) {
    skipWhitespace()
    if (!hasMore()) {
      break
    }
    const token = parseToken()
    if (!token) {
      throw new Error('Unexpected `' + source[index] + '` at offset ' + index)
    }
    tokens.push(token)
  }
  return tokens
}
const parse$3 = function (tokens) {
  let index = 0
  function hasMore() {
    return index < tokens.length
  }
  function token() {
    return hasMore() ? tokens[index] : null
  }
  function next() {
    if (!hasMore()) {
      throw new Error()
    }
    index++
  }
  function parseOperator(operator) {
    const t = token()
    if (t && t.type === 'OPERATOR' && operator === t.string) {
      next()
      return t.string
    }
  }
  function parseWith() {
    if (parseOperator('WITH')) {
      const t = token()
      if (t && t.type === 'EXCEPTION') {
        next()
        return t.string
      }
      throw new Error('Expected exception after `WITH`')
    }
  }
  function parseLicenseRef() {
    const begin = index
    let string = ''
    let t = token()
    if (t.type === 'DOCUMENTREF') {
      next()
      string += 'DocumentRef-' + t.string + ':'
      if (!parseOperator(':')) {
        throw new Error('Expected `:` after `DocumentRef-...`')
      }
    }
    t = token()
    if (t.type === 'LICENSEREF') {
      next()
      string += 'LicenseRef-' + t.string
      return {
        license: string
      }
    }
    index = begin
  }
  function parseLicense() {
    const t = token()
    if (t && t.type === 'LICENSE') {
      next()
      const node = {
        license: t.string
      }
      if (parseOperator('+')) {
        node.plus = true
      }
      const exception = parseWith()
      if (exception) {
        node.exception = exception
      }
      return node
    }
  }
  function parseParenthesizedExpression() {
    const left = parseOperator('(')
    if (!left) {
      return
    }
    const expr = parseExpression()
    if (!parseOperator(')')) {
      throw new Error('Expected `)`')
    }
    return expr
  }
  function parseAtom() {
    return parseParenthesizedExpression() || parseLicenseRef() || parseLicense()
  }
  function makeBinaryOpParser(operator, nextParser) {
    return function parseBinaryOp() {
      const left = nextParser()
      if (!left) {
        return
      }
      if (!parseOperator(operator)) {
        return left
      }
      const right = parseBinaryOp()
      if (!right) {
        throw new Error('Expected expression')
      }
      return {
        left: left,
        conjunction: operator.toLowerCase(),
        right: right
      }
    }
  }
  const parseAnd = makeBinaryOpParser('AND', parseAtom)
  const parseExpression = makeBinaryOpParser('OR', parseAnd)
  const node = parseExpression()
  if (!node || hasMore()) {
    throw new Error('Syntax error')
  }
  return node
}
const scan = scan$1
const parse$2 = parse$3
const spdxExpressionParse = function (source) {
  return parse$2(scan(source))
}
const parse$1$1 = spdxExpressionParse
const spdxLicenseIds = require$$1$3
function valid$2(string) {
  try {
    parse$1$1(string)
    return true
  } catch (error) {
    return false
  }
}
function sortTranspositions(a, b) {
  const length = b[0].length - a[0].length
  if (length !== 0) {
    return length
  }
  return a[0].toUpperCase().localeCompare(b[0].toUpperCase())
}
const transpositions = [
  ['APGL', 'AGPL'],
  ['Gpl', 'GPL'],
  ['GLP', 'GPL'],
  ['APL', 'Apache'],
  ['ISD', 'ISC'],
  ['GLP', 'GPL'],
  ['IST', 'ISC'],
  ['Claude', 'Clause'],
  [' or later', '+'],
  [' International', ''],
  ['GNU', 'GPL'],
  ['GUN', 'GPL'],
  ['+', ''],
  ['GNU GPL', 'GPL'],
  ['GNU LGPL', 'LGPL'],
  ['GNU/GPL', 'GPL'],
  ['GNU GLP', 'GPL'],
  ['GNU LESSER GENERAL PUBLIC LICENSE', 'LGPL'],
  ['GNU Lesser General Public License', 'LGPL'],
  ['GNU LESSER GENERAL PUBLIC LICENSE', 'LGPL-2.1'],
  ['GNU Lesser General Public License', 'LGPL-2.1'],
  ['LESSER GENERAL PUBLIC LICENSE', 'LGPL'],
  ['Lesser General Public License', 'LGPL'],
  ['LESSER GENERAL PUBLIC LICENSE', 'LGPL-2.1'],
  ['Lesser General Public License', 'LGPL-2.1'],
  ['GNU General Public License', 'GPL'],
  ['Gnu public license', 'GPL'],
  ['GNU Public License', 'GPL'],
  ['GNU GENERAL PUBLIC LICENSE', 'GPL'],
  ['MTI', 'MIT'],
  ['Mozilla Public License', 'MPL'],
  ['Universal Permissive License', 'UPL'],
  ['WTH', 'WTF'],
  ['WTFGPL', 'WTFPL'],
  ['-License', '']
].sort(sortTranspositions)
const TRANSPOSED = 0
const CORRECT = 1
const transforms = [
  function (argument) {
    return argument.toUpperCase()
  },
  function (argument) {
    return argument.trim()
  },
  function (argument) {
    return argument.replace(/\./g, '')
  },
  function (argument) {
    return argument.replace(/\s+/g, '')
  },
  function (argument) {
    return argument.replace(/\s+/g, '-')
  },
  function (argument) {
    return argument.replace('v', '-')
  },
  function (argument) {
    return argument.replace(/,?\s*(\d)/, '-$1')
  },
  function (argument) {
    return argument.replace(/,?\s*(\d)/, '-$1.0')
  },
  function (argument) {
    return argument.replace(/,?\s*(V\.|v\.|V|v|Version|version)\s*(\d)/, '-$2')
  },
  function (argument) {
    return argument.replace(
      /,?\s*(V\.|v\.|V|v|Version|version)\s*(\d)/,
      '-$2.0'
    )
  },
  function (argument) {
    return argument[0].toUpperCase() + argument.slice(1)
  },
  function (argument) {
    return argument.replace('/', '-')
  },
  function (argument) {
    return argument.replace(/\s*V\s*(\d)/, '-$1').replace(/(\d)$/, '$1.0')
  },
  function (argument) {
    if (argument.indexOf('3.0') !== -1) {
      return argument + '-or-later'
    } else {
      return argument + '-only'
    }
  },
  function (argument) {
    return argument + 'only'
  },
  function (argument) {
    return argument.replace(/(\d)$/, '-$1.0')
  },
  function (argument) {
    return argument.replace(/(-| )?(\d)$/, '-$2-Clause')
  },
  function (argument) {
    return argument.replace(/(-| )clause(-| )(\d)/, '-$3-Clause')
  },
  function (argument) {
    return argument.replace(
      /\b(Modified|New|Revised)(-| )?BSD((-| )License)?/i,
      'BSD-3-Clause'
    )
  },
  function (argument) {
    return argument.replace(
      /\bSimplified(-| )?BSD((-| )License)?/i,
      'BSD-2-Clause'
    )
  },
  function (argument) {
    return argument.replace(
      /\b(Free|Net)(-| )?BSD((-| )License)?/i,
      'BSD-2-Clause-$1BSD'
    )
  },
  function (argument) {
    return argument.replace(
      /\bClear(-| )?BSD((-| )License)?/i,
      'BSD-3-Clause-Clear'
    )
  },
  function (argument) {
    return argument.replace(
      /\b(Old|Original)(-| )?BSD((-| )License)?/i,
      'BSD-4-Clause'
    )
  },
  function (argument) {
    return 'CC-' + argument
  },
  function (argument) {
    return 'CC-' + argument + '-4.0'
  },
  function (argument) {
    return argument
      .replace('Attribution', 'BY')
      .replace('NonCommercial', 'NC')
      .replace('NoDerivatives', 'ND')
      .replace(/ (\d)/, '-$1')
      .replace(/ ?International/, '')
  },
  function (argument) {
    return (
      'CC-' +
      argument
        .replace('Attribution', 'BY')
        .replace('NonCommercial', 'NC')
        .replace('NoDerivatives', 'ND')
        .replace(/ (\d)/, '-$1')
        .replace(/ ?International/, '') +
      '-4.0'
    )
  }
]
let licensesWithVersions = spdxLicenseIds
  .map(function (id) {
    const match = /^(.*)-\d+\.\d+$/.exec(id)
    return match ? [match[0], match[1]] : [id, null]
  })
  .reduce(function (objectMap, item) {
    const key = item[1]
    objectMap[key] = objectMap[key] || []
    objectMap[key].push(item[0])
    return objectMap
  }, {})
const licensesWithOneVersion = Object.keys(licensesWithVersions)
  .map(function makeEntries(key) {
    return [key, licensesWithVersions[key]]
  })
  .filter(function identifySoleVersions(item) {
    return item[1].length === 1 && item[0] !== null && item[0] !== 'APL'
  })
  .map(function createLastResorts(item) {
    return [item[0], item[1][0]]
  })
licensesWithVersions = undefined
const lastResorts = [
  ['UNLI', 'Unlicense'],
  ['WTF', 'WTFPL'],
  ['2 CLAUSE', 'BSD-2-Clause'],
  ['2-CLAUSE', 'BSD-2-Clause'],
  ['3 CLAUSE', 'BSD-3-Clause'],
  ['3-CLAUSE', 'BSD-3-Clause'],
  ['AFFERO', 'AGPL-3.0-or-later'],
  ['AGPL', 'AGPL-3.0-or-later'],
  ['APACHE', 'Apache-2.0'],
  ['ARTISTIC', 'Artistic-2.0'],
  ['Affero', 'AGPL-3.0-or-later'],
  ['BEER', 'Beerware'],
  ['BOOST', 'BSL-1.0'],
  ['BSD', 'BSD-2-Clause'],
  ['CDDL', 'CDDL-1.1'],
  ['ECLIPSE', 'EPL-1.0'],
  ['FUCK', 'WTFPL'],
  ['GNU', 'GPL-3.0-or-later'],
  ['LGPL', 'LGPL-3.0-or-later'],
  ['GPLV1', 'GPL-1.0-only'],
  ['GPL-1', 'GPL-1.0-only'],
  ['GPLV2', 'GPL-2.0-only'],
  ['GPL-2', 'GPL-2.0-only'],
  ['GPL', 'GPL-3.0-or-later'],
  ['MIT +NO-FALSE-ATTRIBS', 'MITNFA'],
  ['MIT', 'MIT'],
  ['MPL', 'MPL-2.0'],
  ['X11', 'X11'],
  ['ZLIB', 'Zlib']
]
  .concat(licensesWithOneVersion)
  .sort(sortTranspositions)
const SUBSTRING = 0
const IDENTIFIER = 1
const validTransformation = function (identifier) {
  for (let i = 0; i < transforms.length; i++) {
    const transformed = transforms[i](identifier).trim()
    if (transformed !== identifier && valid$2(transformed)) {
      return transformed
    }
  }
  return null
}
const validLastResort = function (identifier) {
  const upperCased = identifier.toUpperCase()
  for (let i = 0; i < lastResorts.length; i++) {
    const lastResort = lastResorts[i]
    if (upperCased.indexOf(lastResort[SUBSTRING]) > -1) {
      return lastResort[IDENTIFIER]
    }
  }
  return null
}
const anyCorrection = function (identifier, check) {
  for (let i = 0; i < transpositions.length; i++) {
    const transposition = transpositions[i]
    const transposed = transposition[TRANSPOSED]
    if (identifier.indexOf(transposed) > -1) {
      const corrected = identifier.replace(transposed, transposition[CORRECT])
      const checked = check(corrected)
      if (checked !== null) {
        return checked
      }
    }
  }
  return null
}
const spdxCorrect = function (identifier, options) {
  options = options || {}
  const upgrade = options.upgrade === undefined ? true : !!options.upgrade
  function postprocess(value) {
    return upgrade ? upgradeGPLs(value) : value
  }
  const validArugment =
    typeof identifier === 'string' && identifier.trim().length !== 0
  if (!validArugment) {
    throw Error('Invalid argument. Expected non-empty string.')
  }
  identifier = identifier.trim()
  if (valid$2(identifier)) {
    return postprocess(identifier)
  }
  const noPlus = identifier.replace(/\+$/, '').trim()
  if (valid$2(noPlus)) {
    return postprocess(noPlus)
  }
  let transformed = validTransformation(identifier)
  if (transformed !== null) {
    return postprocess(transformed)
  }
  transformed = anyCorrection(identifier, function (argument) {
    if (valid$2(argument)) {
      return argument
    }
    return validTransformation(argument)
  })
  if (transformed !== null) {
    return postprocess(transformed)
  }
  transformed = validLastResort(identifier)
  if (transformed !== null) {
    return postprocess(transformed)
  }
  transformed = anyCorrection(identifier, validLastResort)
  if (transformed !== null) {
    return postprocess(transformed)
  }
  return null
}
function upgradeGPLs(value) {
  if (
    [
      'GPL-1.0',
      'LGPL-1.0',
      'AGPL-1.0',
      'GPL-2.0',
      'LGPL-2.0',
      'AGPL-2.0',
      'LGPL-2.1'
    ].indexOf(value) !== -1
  ) {
    return value + '-only'
  } else if (
    [
      'GPL-1.0+',
      'GPL-2.0+',
      'GPL-3.0+',
      'LGPL-2.0+',
      'LGPL-2.1+',
      'LGPL-3.0+',
      'AGPL-1.0+',
      'AGPL-3.0+'
    ].indexOf(value) !== -1
  ) {
    return value.replace(/\+$/, '-or-later')
  } else if (['GPL-3.0', 'LGPL-3.0', 'AGPL-3.0'].indexOf(value) !== -1) {
    return value + '-or-later'
  } else {
    return value
  }
}
const parse$7 = spdxExpressionParse
const correct = spdxCorrect
const genericWarning =
  'license should be ' +
  'a valid SPDX license expression (without "LicenseRef"), ' +
  '"UNLICENSED", or ' +
  '"SEE LICENSE IN <filename>"'
const fileReferenceRE = /^SEE LICEN[CS]E IN (.+)$/
function startsWith(prefix, string) {
  return string.slice(0, prefix.length) === prefix
}
function usesLicenseRef(ast) {
  if (ast.hasOwnProperty('license')) {
    const license = ast.license
    return (
      startsWith('LicenseRef', license) || startsWith('DocumentRef', license)
    )
  } else {
    return usesLicenseRef(ast.left) || usesLicenseRef(ast.right)
  }
}
const validateNpmPackageLicense = function (argument) {
  let ast
  try {
    ast = parse$7(argument)
  } catch (e) {
    let match
    if (argument === 'UNLICENSED' || argument === 'UNLICENCED') {
      return {
        validForOldPackages: true,
        validForNewPackages: true,
        unlicensed: true
      }
    } else if ((match = fileReferenceRE.exec(argument))) {
      return {
        validForOldPackages: true,
        validForNewPackages: true,
        inFile: match[1]
      }
    } else {
      const result = {
        validForOldPackages: false,
        validForNewPackages: false,
        warnings: [genericWarning]
      }
      if (argument.trim().length !== 0) {
        const corrected = correct(argument)
        if (corrected) {
          result.warnings.push(
            'license is similar to the valid expression "' + corrected + '"'
          )
        }
      }
      return result
    }
  }
  if (usesLicenseRef(ast)) {
    return {
      validForNewPackages: false,
      validForOldPackages: false,
      spdx: true,
      warnings: [genericWarning]
    }
  } else {
    return {
      validForNewPackages: true,
      validForOldPackages: true,
      spdx: true
    }
  }
}
const commonjs$2 = {}
Object.defineProperty(commonjs$2, '__esModule', {
  value: true
})
commonjs$2.LRUCache = void 0
const perf =
  typeof performance === 'object' &&
  performance &&
  typeof performance.now === 'function'
    ? performance
    : Date
const warned = new Set()
const PROCESS = typeof process === 'object' && !!process ? process : {}
const emitWarning = (msg, type, code, fn) => {
  typeof PROCESS.emitWarning === 'function'
    ? PROCESS.emitWarning(msg, type, code, fn)
    : console.error(`[${code}] ${type}: ${msg}`)
}
let AC = globalThis.AbortController
let AS = globalThis.AbortSignal
if (typeof AC === 'undefined') {
  AS = class AbortSignal {
    onabort
    _onabort = []
    reason
    aborted = false
    addEventListener(_, fn) {
      this._onabort.push(fn)
    }
  }
  AC = class AbortController {
    constructor() {
      warnACPolyfill()
    }
    signal = new AS()
    abort(reason) {
      if (this.signal.aborted) {
        return
      }
      this.signal.reason = reason
      this.signal.aborted = true
      for (const fn of this.signal._onabort) {
        fn(reason)
      }
      this.signal.onabort?.(reason)
    }
  }
  let printACPolyfillWarning = PROCESS.env?.LRU_CACHE_IGNORE_AC_WARNING !== '1'
  const warnACPolyfill = () => {
    if (!printACPolyfillWarning) {
      return
    }
    printACPolyfillWarning = false
    emitWarning(
      'AbortController is not defined. If using lru-cache in ' +
        'node 14, load an AbortController polyfill from the ' +
        '`node-abort-controller` package. A minimal polyfill is ' +
        'provided for use by LRUCache.fetch(), but it should not be ' +
        'relied upon in other contexts (eg, passing it to other APIs that ' +
        'use AbortController/AbortSignal might have undesirable effects). ' +
        'You may disable this with LRU_CACHE_IGNORE_AC_WARNING=1 in the env.',
      'NO_ABORT_CONTROLLER',
      'ENOTSUP',
      warnACPolyfill
    )
  }
}
const shouldWarn = code => !warned.has(code)
const isPosInt = n => n && n === Math.floor(n) && n > 0 && isFinite(n)
const getUintArray = max =>
  !isPosInt(max)
    ? null
    : max <= Math.pow(2, 8)
      ? Uint8Array
      : max <= Math.pow(2, 16)
        ? Uint16Array
        : max <= Math.pow(2, 32)
          ? Uint32Array
          : max <= Number.MAX_SAFE_INTEGER
            ? ZeroArray
            : null
class ZeroArray extends Array {
  constructor(size) {
    super(size)
    this.fill(0)
  }
}
class Stack {
  heap
  length
  static #constructing = false
  static create(max) {
    const HeapCls = getUintArray(max)
    if (!HeapCls) {
      return []
    }
    Stack.#constructing = true
    const s = new Stack(max, HeapCls)
    Stack.#constructing = false
    return s
  }
  constructor(max, HeapCls) {
    if (!Stack.#constructing) {
      throw new TypeError('instantiate Stack using Stack.create(n)')
    }
    this.heap = new HeapCls(max)
    this.length = 0
  }
  push(n) {
    this.heap[this.length++] = n
  }
  pop() {
    return this.heap[--this.length]
  }
}
let LRUCache$1 = class LRUCache {
  #max
  #maxSize
  #dispose
  #disposeAfter
  #fetchMethod
  ttl
  ttlResolution
  ttlAutopurge
  updateAgeOnGet
  updateAgeOnHas
  allowStale
  noDisposeOnSet
  noUpdateTTL
  maxEntrySize
  sizeCalculation
  noDeleteOnFetchRejection
  noDeleteOnStaleGet
  allowStaleOnFetchAbort
  allowStaleOnFetchRejection
  ignoreFetchAbort
  #size
  #calculatedSize
  #keyMap
  #keyList
  #valList
  #next
  #prev
  #head
  #tail
  #free
  #disposed
  #sizes
  #starts
  #ttls
  #hasDispose
  #hasFetchMethod
  #hasDisposeAfter
  static unsafeExposeInternals(c) {
    return {
      starts: c.#starts,
      ttls: c.#ttls,
      sizes: c.#sizes,
      keyMap: c.#keyMap,
      keyList: c.#keyList,
      valList: c.#valList,
      next: c.#next,
      prev: c.#prev,
      get head() {
        return c.#head
      },
      get tail() {
        return c.#tail
      },
      free: c.#free,
      isBackgroundFetch: p => c.#isBackgroundFetch(p),
      backgroundFetch: (k, index, options, context) =>
        c.#backgroundFetch(k, index, options, context),
      moveToTail: index => c.#moveToTail(index),
      indexes: options => c.#indexes(options),
      rindexes: options => c.#rindexes(options),
      isStale: index => c.#isStale(index)
    }
  }
  get max() {
    return this.#max
  }
  get maxSize() {
    return this.#maxSize
  }
  get calculatedSize() {
    return this.#calculatedSize
  }
  get size() {
    return this.#size
  }
  get fetchMethod() {
    return this.#fetchMethod
  }
  get dispose() {
    return this.#dispose
  }
  get disposeAfter() {
    return this.#disposeAfter
  }
  constructor(options) {
    const {
      max = 0,
      ttl,
      ttlResolution = 1,
      ttlAutopurge,
      updateAgeOnGet,
      updateAgeOnHas,
      allowStale,
      dispose,
      disposeAfter,
      noDisposeOnSet,
      noUpdateTTL,
      maxSize = 0,
      maxEntrySize = 0,
      sizeCalculation,
      fetchMethod,
      noDeleteOnFetchRejection,
      noDeleteOnStaleGet,
      allowStaleOnFetchRejection,
      allowStaleOnFetchAbort,
      ignoreFetchAbort
    } = options
    if (max !== 0 && !isPosInt(max)) {
      throw new TypeError('max option must be a nonnegative integer')
    }
    const UintArray = max ? getUintArray(max) : Array
    if (!UintArray) {
      throw new Error('invalid max value: ' + max)
    }
    this.#max = max
    this.#maxSize = maxSize
    this.maxEntrySize = maxEntrySize || this.#maxSize
    this.sizeCalculation = sizeCalculation
    if (this.sizeCalculation) {
      if (!this.#maxSize && !this.maxEntrySize) {
        throw new TypeError(
          'cannot set sizeCalculation without setting maxSize or maxEntrySize'
        )
      }
      if (typeof this.sizeCalculation !== 'function') {
        throw new TypeError('sizeCalculation set to non-function')
      }
    }
    if (fetchMethod !== undefined && typeof fetchMethod !== 'function') {
      throw new TypeError('fetchMethod must be a function if specified')
    }
    this.#fetchMethod = fetchMethod
    this.#hasFetchMethod = !!fetchMethod
    this.#keyMap = new Map()
    this.#keyList = new Array(max).fill(undefined)
    this.#valList = new Array(max).fill(undefined)
    this.#next = new UintArray(max)
    this.#prev = new UintArray(max)
    this.#head = 0
    this.#tail = 0
    this.#free = Stack.create(max)
    this.#size = 0
    this.#calculatedSize = 0
    if (typeof dispose === 'function') {
      this.#dispose = dispose
    }
    if (typeof disposeAfter === 'function') {
      this.#disposeAfter = disposeAfter
      this.#disposed = []
    } else {
      this.#disposeAfter = undefined
      this.#disposed = undefined
    }
    this.#hasDispose = !!this.#dispose
    this.#hasDisposeAfter = !!this.#disposeAfter
    this.noDisposeOnSet = !!noDisposeOnSet
    this.noUpdateTTL = !!noUpdateTTL
    this.noDeleteOnFetchRejection = !!noDeleteOnFetchRejection
    this.allowStaleOnFetchRejection = !!allowStaleOnFetchRejection
    this.allowStaleOnFetchAbort = !!allowStaleOnFetchAbort
    this.ignoreFetchAbort = !!ignoreFetchAbort
    if (this.maxEntrySize !== 0) {
      if (this.#maxSize !== 0) {
        if (!isPosInt(this.#maxSize)) {
          throw new TypeError('maxSize must be a positive integer if specified')
        }
      }
      if (!isPosInt(this.maxEntrySize)) {
        throw new TypeError(
          'maxEntrySize must be a positive integer if specified'
        )
      }
      this.#initializeSizeTracking()
    }
    this.allowStale = !!allowStale
    this.noDeleteOnStaleGet = !!noDeleteOnStaleGet
    this.updateAgeOnGet = !!updateAgeOnGet
    this.updateAgeOnHas = !!updateAgeOnHas
    this.ttlResolution =
      isPosInt(ttlResolution) || ttlResolution === 0 ? ttlResolution : 1
    this.ttlAutopurge = !!ttlAutopurge
    this.ttl = ttl || 0
    if (this.ttl) {
      if (!isPosInt(this.ttl)) {
        throw new TypeError('ttl must be a positive integer if specified')
      }
      this.#initializeTTLTracking()
    }
    if (this.#max === 0 && this.ttl === 0 && this.#maxSize === 0) {
      throw new TypeError('At least one of max, maxSize, or ttl is required')
    }
    if (!this.ttlAutopurge && !this.#max && !this.#maxSize) {
      const code = 'LRU_CACHE_UNBOUNDED'
      if (shouldWarn(code)) {
        warned.add(code)
        const msg =
          'TTL caching without ttlAutopurge, max, or maxSize can ' +
          'result in unbounded memory consumption.'
        emitWarning(msg, 'UnboundedCacheWarning', code, LRUCache)
      }
    }
  }
  getRemainingTTL(key) {
    return this.#keyMap.has(key) ? Infinity : 0
  }
  #initializeTTLTracking() {
    const ttls = new ZeroArray(this.#max)
    const starts = new ZeroArray(this.#max)
    this.#ttls = ttls
    this.#starts = starts
    this.#setItemTTL = (index, ttl, start = perf.now()) => {
      starts[index] = ttl !== 0 ? start : 0
      ttls[index] = ttl
      if (ttl !== 0 && this.ttlAutopurge) {
        const t = setTimeout(() => {
          if (this.#isStale(index)) {
            this.delete(this.#keyList[index])
          }
        }, ttl + 1)
        if (t.unref) {
          t.unref()
        }
      }
    }
    this.#updateItemAge = index => {
      starts[index] = ttls[index] !== 0 ? perf.now() : 0
    }
    this.#statusTTL = (status, index) => {
      if (ttls[index]) {
        const ttl = ttls[index]
        const start = starts[index]
        if (!ttl || !start) {
          return
        }
        status.ttl = ttl
        status.start = start
        status.now = cachedNow || getNow()
        const age = status.now - start
        status.remainingTTL = ttl - age
      }
    }
    let cachedNow = 0
    const getNow = () => {
      const n = perf.now()
      if (this.ttlResolution > 0) {
        cachedNow = n
        const t = setTimeout(() => (cachedNow = 0), this.ttlResolution)
        if (t.unref) {
          t.unref()
        }
      }
      return n
    }
    this.getRemainingTTL = key => {
      const index = this.#keyMap.get(key)
      if (index === undefined) {
        return 0
      }
      const ttl = ttls[index]
      const start = starts[index]
      if (!ttl || !start) {
        return Infinity
      }
      const age = (cachedNow || getNow()) - start
      return ttl - age
    }
    this.#isStale = index => {
      const s = starts[index]
      const t = ttls[index]
      return !!t && !!s && (cachedNow || getNow()) - s > t
    }
  }
  #updateItemAge = () => {}
  #statusTTL = () => {}
  #setItemTTL = () => {}
  #isStale = () => false
  #initializeSizeTracking() {
    const sizes = new ZeroArray(this.#max)
    this.#calculatedSize = 0
    this.#sizes = sizes
    this.#removeItemSize = index => {
      this.#calculatedSize -= sizes[index]
      sizes[index] = 0
    }
    this.#requireSize = (k, v, size, sizeCalculation) => {
      if (this.#isBackgroundFetch(v)) {
        return 0
      }
      if (!isPosInt(size)) {
        if (sizeCalculation) {
          if (typeof sizeCalculation !== 'function') {
            throw new TypeError('sizeCalculation must be a function')
          }
          size = sizeCalculation(v, k)
          if (!isPosInt(size)) {
            throw new TypeError(
              'sizeCalculation return invalid (expect positive integer)'
            )
          }
        } else {
          throw new TypeError(
            'invalid size value (must be positive integer). ' +
              'When maxSize or maxEntrySize is used, sizeCalculation ' +
              'or size must be set.'
          )
        }
      }
      return size
    }
    this.#addItemSize = (index, size, status) => {
      sizes[index] = size
      if (this.#maxSize) {
        const maxSize = this.#maxSize - sizes[index]
        while (this.#calculatedSize > maxSize) {
          this.#evict(true)
        }
      }
      this.#calculatedSize += sizes[index]
      if (status) {
        status.entrySize = size
        status.totalCalculatedSize = this.#calculatedSize
      }
    }
  }
  #removeItemSize = _i => {}
  #addItemSize = (_i, _s, _st) => {}
  #requireSize = (_k, _v, size, sizeCalculation) => {
    if (size || sizeCalculation) {
      throw new TypeError(
        'cannot set size without setting maxSize or maxEntrySize on cache'
      )
    }
    return 0
  };
  *#indexes({ allowStale = this.allowStale } = {}) {
    if (this.#size) {
      for (let i = this.#tail; true; ) {
        if (!this.#isValidIndex(i)) {
          break
        }
        if (allowStale || !this.#isStale(i)) {
          yield i
        }
        if (i === this.#head) {
          break
        } else {
          i = this.#prev[i]
        }
      }
    }
  }
  *#rindexes({ allowStale = this.allowStale } = {}) {
    if (this.#size) {
      for (let i = this.#head; true; ) {
        if (!this.#isValidIndex(i)) {
          break
        }
        if (allowStale || !this.#isStale(i)) {
          yield i
        }
        if (i === this.#tail) {
          break
        } else {
          i = this.#next[i]
        }
      }
    }
  }
  #isValidIndex(index) {
    return (
      index !== undefined && this.#keyMap.get(this.#keyList[index]) === index
    )
  }
  *entries() {
    for (const i of this.#indexes()) {
      if (
        this.#valList[i] !== undefined &&
        this.#keyList[i] !== undefined &&
        !this.#isBackgroundFetch(this.#valList[i])
      ) {
        yield [this.#keyList[i], this.#valList[i]]
      }
    }
  }
  *rentries() {
    for (const i of this.#rindexes()) {
      if (
        this.#valList[i] !== undefined &&
        this.#keyList[i] !== undefined &&
        !this.#isBackgroundFetch(this.#valList[i])
      ) {
        yield [this.#keyList[i], this.#valList[i]]
      }
    }
  }
  *keys() {
    for (const i of this.#indexes()) {
      const k = this.#keyList[i]
      if (k !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
        yield k
      }
    }
  }
  *rkeys() {
    for (const i of this.#rindexes()) {
      const k = this.#keyList[i]
      if (k !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
        yield k
      }
    }
  }
  *values() {
    for (const i of this.#indexes()) {
      const v = this.#valList[i]
      if (v !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
        yield this.#valList[i]
      }
    }
  }
  *rvalues() {
    for (const i of this.#rindexes()) {
      const v = this.#valList[i]
      if (v !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
        yield this.#valList[i]
      }
    }
  }
  [Symbol.iterator]() {
    return this.entries()
  }
  [Symbol.toStringTag] = 'LRUCache'
  find(fn, getOptions = {}) {
    for (const i of this.#indexes()) {
      const v = this.#valList[i]
      const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
      if (value === undefined) {
        continue
      }
      if (fn(value, this.#keyList[i], this)) {
        return this.get(this.#keyList[i], getOptions)
      }
    }
  }
  forEach(fn, thisp = this) {
    for (const i of this.#indexes()) {
      const v = this.#valList[i]
      const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
      if (value === undefined) {
        continue
      }
      fn.call(thisp, value, this.#keyList[i], this)
    }
  }
  rforEach(fn, thisp = this) {
    for (const i of this.#rindexes()) {
      const v = this.#valList[i]
      const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
      if (value === undefined) {
        continue
      }
      fn.call(thisp, value, this.#keyList[i], this)
    }
  }
  purgeStale() {
    let deleted = false
    for (const i of this.#rindexes({
      allowStale: true
    })) {
      if (this.#isStale(i)) {
        this.delete(this.#keyList[i])
        deleted = true
      }
    }
    return deleted
  }
  info(key) {
    const i = this.#keyMap.get(key)
    if (i === undefined) {
      return undefined
    }
    const v = this.#valList[i]
    const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
    if (value === undefined) {
      return undefined
    }
    const entry = {
      value
    }
    if (this.#ttls && this.#starts) {
      const ttl = this.#ttls[i]
      const start = this.#starts[i]
      if (ttl && start) {
        const remain = ttl - (perf.now() - start)
        entry.ttl = remain
        entry.start = Date.now()
      }
    }
    if (this.#sizes) {
      entry.size = this.#sizes[i]
    }
    return entry
  }
  dump() {
    const arr = []
    for (const i of this.#indexes({
      allowStale: true
    })) {
      const key = this.#keyList[i]
      const v = this.#valList[i]
      const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
      if (value === undefined || key === undefined) {
        continue
      }
      const entry = {
        value
      }
      if (this.#ttls && this.#starts) {
        entry.ttl = this.#ttls[i]
        const age = perf.now() - this.#starts[i]
        entry.start = Math.floor(Date.now() - age)
      }
      if (this.#sizes) {
        entry.size = this.#sizes[i]
      }
      arr.unshift([key, entry])
    }
    return arr
  }
  load(arr) {
    this.clear()
    for (const [key, entry] of arr) {
      if (entry.start) {
        const age = Date.now() - entry.start
        entry.start = perf.now() - age
      }
      this.set(key, entry.value, entry)
    }
  }
  set(k, v, setOptions = {}) {
    if (v === undefined) {
      this.delete(k)
      return this
    }
    const {
      ttl = this.ttl,
      start,
      noDisposeOnSet = this.noDisposeOnSet,
      sizeCalculation = this.sizeCalculation,
      status
    } = setOptions
    let { noUpdateTTL = this.noUpdateTTL } = setOptions
    const size = this.#requireSize(k, v, setOptions.size || 0, sizeCalculation)
    if (this.maxEntrySize && size > this.maxEntrySize) {
      if (status) {
        status.set = 'miss'
        status.maxEntrySizeExceeded = true
      }
      this.delete(k)
      return this
    }
    let index = this.#size === 0 ? undefined : this.#keyMap.get(k)
    if (index === undefined) {
      index =
        this.#size === 0
          ? this.#tail
          : this.#free.length !== 0
            ? this.#free.pop()
            : this.#size === this.#max
              ? this.#evict(false)
              : this.#size
      this.#keyList[index] = k
      this.#valList[index] = v
      this.#keyMap.set(k, index)
      this.#next[this.#tail] = index
      this.#prev[index] = this.#tail
      this.#tail = index
      this.#size++
      this.#addItemSize(index, size, status)
      if (status) {
        status.set = 'add'
      }
      noUpdateTTL = false
    } else {
      this.#moveToTail(index)
      const oldVal = this.#valList[index]
      if (v !== oldVal) {
        if (this.#hasFetchMethod && this.#isBackgroundFetch(oldVal)) {
          oldVal.__abortController.abort(new Error('replaced'))
          const { __staleWhileFetching: s } = oldVal
          if (s !== undefined && !noDisposeOnSet) {
            if (this.#hasDispose) {
              this.#dispose?.(s, k, 'set')
            }
            if (this.#hasDisposeAfter) {
              this.#disposed?.push([s, k, 'set'])
            }
          }
        } else if (!noDisposeOnSet) {
          if (this.#hasDispose) {
            this.#dispose?.(oldVal, k, 'set')
          }
          if (this.#hasDisposeAfter) {
            this.#disposed?.push([oldVal, k, 'set'])
          }
        }
        this.#removeItemSize(index)
        this.#addItemSize(index, size, status)
        this.#valList[index] = v
        if (status) {
          status.set = 'replace'
          const oldValue =
            oldVal && this.#isBackgroundFetch(oldVal)
              ? oldVal.__staleWhileFetching
              : oldVal
          if (oldValue !== undefined) {
            status.oldValue = oldValue
          }
        }
      } else if (status) {
        status.set = 'update'
      }
    }
    if (ttl !== 0 && !this.#ttls) {
      this.#initializeTTLTracking()
    }
    if (this.#ttls) {
      if (!noUpdateTTL) {
        this.#setItemTTL(index, ttl, start)
      }
      if (status) {
        this.#statusTTL(status, index)
      }
    }
    if (!noDisposeOnSet && this.#hasDisposeAfter && this.#disposed) {
      const dt = this.#disposed
      let task
      while ((task = dt?.shift())) {
        this.#disposeAfter?.(...task)
      }
    }
    return this
  }
  pop() {
    try {
      while (this.#size) {
        const val = this.#valList[this.#head]
        this.#evict(true)
        if (this.#isBackgroundFetch(val)) {
          if (val.__staleWhileFetching) {
            return val.__staleWhileFetching
          }
        } else if (val !== undefined) {
          return val
        }
      }
    } finally {
      if (this.#hasDisposeAfter && this.#disposed) {
        const dt = this.#disposed
        let task
        while ((task = dt?.shift())) {
          this.#disposeAfter?.(...task)
        }
      }
    }
  }
  #evict(free) {
    const head = this.#head
    const k = this.#keyList[head]
    const v = this.#valList[head]
    if (this.#hasFetchMethod && this.#isBackgroundFetch(v)) {
      v.__abortController.abort(new Error('evicted'))
    } else if (this.#hasDispose || this.#hasDisposeAfter) {
      if (this.#hasDispose) {
        this.#dispose?.(v, k, 'evict')
      }
      if (this.#hasDisposeAfter) {
        this.#disposed?.push([v, k, 'evict'])
      }
    }
    this.#removeItemSize(head)
    if (free) {
      this.#keyList[head] = undefined
      this.#valList[head] = undefined
      this.#free.push(head)
    }
    if (this.#size === 1) {
      this.#head = this.#tail = 0
      this.#free.length = 0
    } else {
      this.#head = this.#next[head]
    }
    this.#keyMap.delete(k)
    this.#size--
    return head
  }
  has(k, hasOptions = {}) {
    const { updateAgeOnHas = this.updateAgeOnHas, status } = hasOptions
    const index = this.#keyMap.get(k)
    if (index !== undefined) {
      const v = this.#valList[index]
      if (this.#isBackgroundFetch(v) && v.__staleWhileFetching === undefined) {
        return false
      }
      if (!this.#isStale(index)) {
        if (updateAgeOnHas) {
          this.#updateItemAge(index)
        }
        if (status) {
          status.has = 'hit'
          this.#statusTTL(status, index)
        }
        return true
      } else if (status) {
        status.has = 'stale'
        this.#statusTTL(status, index)
      }
    } else if (status) {
      status.has = 'miss'
    }
    return false
  }
  peek(k, peekOptions = {}) {
    const { allowStale = this.allowStale } = peekOptions
    const index = this.#keyMap.get(k)
    if (index === undefined || (!allowStale && this.#isStale(index))) {
      return
    }
    const v = this.#valList[index]
    return this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
  }
  #backgroundFetch(k, index, options, context) {
    const v = index === undefined ? undefined : this.#valList[index]
    if (this.#isBackgroundFetch(v)) {
      return v
    }
    const ac = new AC()
    const { signal } = options
    signal?.addEventListener('abort', () => ac.abort(signal.reason), {
      signal: ac.signal
    })
    const fetchOpts = {
      signal: ac.signal,
      options,
      context
    }
    const cb = (v, updateCache = false) => {
      const { aborted } = ac.signal
      const ignoreAbort = options.ignoreFetchAbort && v !== undefined
      if (options.status) {
        if (aborted && !updateCache) {
          options.status.fetchAborted = true
          options.status.fetchError = ac.signal.reason
          if (ignoreAbort) {
            options.status.fetchAbortIgnored = true
          }
        } else {
          options.status.fetchResolved = true
        }
      }
      if (aborted && !ignoreAbort && !updateCache) {
        return fetchFail(ac.signal.reason)
      }
      const bf = p
      if (this.#valList[index] === p) {
        if (v === undefined) {
          if (bf.__staleWhileFetching) {
            this.#valList[index] = bf.__staleWhileFetching
          } else {
            this.delete(k)
          }
        } else {
          if (options.status) {
            options.status.fetchUpdated = true
          }
          this.set(k, v, fetchOpts.options)
        }
      }
      return v
    }
    const eb = er => {
      if (options.status) {
        options.status.fetchRejected = true
        options.status.fetchError = er
      }
      return fetchFail(er)
    }
    const fetchFail = er => {
      const { aborted } = ac.signal
      const allowStaleAborted = aborted && options.allowStaleOnFetchAbort
      const allowStale = allowStaleAborted || options.allowStaleOnFetchRejection
      const noDelete = allowStale || options.noDeleteOnFetchRejection
      const bf = p
      if (this.#valList[index] === p) {
        const del = !noDelete || bf.__staleWhileFetching === undefined
        if (del) {
          this.delete(k)
        } else if (!allowStaleAborted) {
          this.#valList[index] = bf.__staleWhileFetching
        }
      }
      if (allowStale) {
        if (options.status && bf.__staleWhileFetching !== undefined) {
          options.status.returnedStale = true
        }
        return bf.__staleWhileFetching
      } else if (bf.__returned === bf) {
        throw er
      }
    }
    const pcall = (res, rej) => {
      const fmp = this.#fetchMethod?.(k, v, fetchOpts)
      if (fmp && fmp instanceof Promise) {
        fmp.then(v => res(v === undefined ? undefined : v), rej)
      }
      ac.signal.addEventListener('abort', () => {
        if (!options.ignoreFetchAbort || options.allowStaleOnFetchAbort) {
          res(undefined)
          if (options.allowStaleOnFetchAbort) {
            res = v => cb(v, true)
          }
        }
      })
    }
    if (options.status) {
      options.status.fetchDispatched = true
    }
    const p = new Promise(pcall).then(cb, eb)
    const bf = Object.assign(p, {
      __abortController: ac,
      __staleWhileFetching: v,
      __returned: undefined
    })
    if (index === undefined) {
      this.set(k, bf, {
        ...fetchOpts.options,
        status: undefined
      })
      index = this.#keyMap.get(k)
    } else {
      this.#valList[index] = bf
    }
    return bf
  }
  #isBackgroundFetch(p) {
    if (!this.#hasFetchMethod) {
      return false
    }
    const b = p
    return (
      !!b &&
      b instanceof Promise &&
      b.hasOwnProperty('__staleWhileFetching') &&
      b.__abortController instanceof AC
    )
  }
  async fetch(k, fetchOptions = {}) {
    const {
      allowStale = this.allowStale,
      updateAgeOnGet = this.updateAgeOnGet,
      noDeleteOnStaleGet = this.noDeleteOnStaleGet,
      ttl = this.ttl,
      noDisposeOnSet = this.noDisposeOnSet,
      size = 0,
      sizeCalculation = this.sizeCalculation,
      noUpdateTTL = this.noUpdateTTL,
      noDeleteOnFetchRejection = this.noDeleteOnFetchRejection,
      allowStaleOnFetchRejection = this.allowStaleOnFetchRejection,
      ignoreFetchAbort = this.ignoreFetchAbort,
      allowStaleOnFetchAbort = this.allowStaleOnFetchAbort,
      context,
      forceRefresh = false,
      status,
      signal
    } = fetchOptions
    if (!this.#hasFetchMethod) {
      if (status) {
        status.fetch = 'get'
      }
      return this.get(k, {
        allowStale,
        updateAgeOnGet,
        noDeleteOnStaleGet,
        status
      })
    }
    const options = {
      allowStale,
      updateAgeOnGet,
      noDeleteOnStaleGet,
      ttl,
      noDisposeOnSet,
      size,
      sizeCalculation,
      noUpdateTTL,
      noDeleteOnFetchRejection,
      allowStaleOnFetchRejection,
      allowStaleOnFetchAbort,
      ignoreFetchAbort,
      status,
      signal
    }
    let index = this.#keyMap.get(k)
    if (index === undefined) {
      if (status) {
        status.fetch = 'miss'
      }
      const p = this.#backgroundFetch(k, index, options, context)
      return (p.__returned = p)
    } else {
      const v = this.#valList[index]
      if (this.#isBackgroundFetch(v)) {
        const stale = allowStale && v.__staleWhileFetching !== undefined
        if (status) {
          status.fetch = 'inflight'
          if (stale) {
            status.returnedStale = true
          }
        }
        return stale ? v.__staleWhileFetching : (v.__returned = v)
      }
      const isStale = this.#isStale(index)
      if (!forceRefresh && !isStale) {
        if (status) {
          status.fetch = 'hit'
        }
        this.#moveToTail(index)
        if (updateAgeOnGet) {
          this.#updateItemAge(index)
        }
        if (status) {
          this.#statusTTL(status, index)
        }
        return v
      }
      const p = this.#backgroundFetch(k, index, options, context)
      const hasStale = p.__staleWhileFetching !== undefined
      const staleVal = hasStale && allowStale
      if (status) {
        status.fetch = isStale ? 'stale' : 'refresh'
        if (staleVal && isStale) {
          status.returnedStale = true
        }
      }
      return staleVal ? p.__staleWhileFetching : (p.__returned = p)
    }
  }
  get(k, getOptions = {}) {
    const {
      allowStale = this.allowStale,
      updateAgeOnGet = this.updateAgeOnGet,
      noDeleteOnStaleGet = this.noDeleteOnStaleGet,
      status
    } = getOptions
    const index = this.#keyMap.get(k)
    if (index !== undefined) {
      const value = this.#valList[index]
      const fetching = this.#isBackgroundFetch(value)
      if (status) {
        this.#statusTTL(status, index)
      }
      if (this.#isStale(index)) {
        if (status) {
          status.get = 'stale'
        }
        if (!fetching) {
          if (!noDeleteOnStaleGet) {
            this.delete(k)
          }
          if (status && allowStale) {
            status.returnedStale = true
          }
          return allowStale ? value : undefined
        } else {
          if (
            status &&
            allowStale &&
            value.__staleWhileFetching !== undefined
          ) {
            status.returnedStale = true
          }
          return allowStale ? value.__staleWhileFetching : undefined
        }
      } else {
        if (status) {
          status.get = 'hit'
        }
        if (fetching) {
          return value.__staleWhileFetching
        }
        this.#moveToTail(index)
        if (updateAgeOnGet) {
          this.#updateItemAge(index)
        }
        return value
      }
    } else if (status) {
      status.get = 'miss'
    }
  }
  #connect(p, n) {
    this.#prev[n] = p
    this.#next[p] = n
  }
  #moveToTail(index) {
    if (index !== this.#tail) {
      if (index === this.#head) {
        this.#head = this.#next[index]
      } else {
        this.#connect(this.#prev[index], this.#next[index])
      }
      this.#connect(this.#tail, index)
      this.#tail = index
    }
  }
  delete(k) {
    let deleted = false
    if (this.#size !== 0) {
      const index = this.#keyMap.get(k)
      if (index !== undefined) {
        deleted = true
        if (this.#size === 1) {
          this.clear()
        } else {
          this.#removeItemSize(index)
          const v = this.#valList[index]
          if (this.#isBackgroundFetch(v)) {
            v.__abortController.abort(new Error('deleted'))
          } else if (this.#hasDispose || this.#hasDisposeAfter) {
            if (this.#hasDispose) {
              this.#dispose?.(v, k, 'delete')
            }
            if (this.#hasDisposeAfter) {
              this.#disposed?.push([v, k, 'delete'])
            }
          }
          this.#keyMap.delete(k)
          this.#keyList[index] = undefined
          this.#valList[index] = undefined
          if (index === this.#tail) {
            this.#tail = this.#prev[index]
          } else if (index === this.#head) {
            this.#head = this.#next[index]
          } else {
            const pi = this.#prev[index]
            this.#next[pi] = this.#next[index]
            const ni = this.#next[index]
            this.#prev[ni] = this.#prev[index]
          }
          this.#size--
          this.#free.push(index)
        }
      }
    }
    if (this.#hasDisposeAfter && this.#disposed?.length) {
      const dt = this.#disposed
      let task
      while ((task = dt?.shift())) {
        this.#disposeAfter?.(...task)
      }
    }
    return deleted
  }
  clear() {
    for (const index of this.#rindexes({
      allowStale: true
    })) {
      const v = this.#valList[index]
      if (this.#isBackgroundFetch(v)) {
        v.__abortController.abort(new Error('deleted'))
      } else {
        const k = this.#keyList[index]
        if (this.#hasDispose) {
          this.#dispose?.(v, k, 'delete')
        }
        if (this.#hasDisposeAfter) {
          this.#disposed?.push([v, k, 'delete'])
        }
      }
    }
    this.#keyMap.clear()
    this.#valList.fill(undefined)
    this.#keyList.fill(undefined)
    if (this.#ttls && this.#starts) {
      this.#ttls.fill(0)
      this.#starts.fill(0)
    }
    if (this.#sizes) {
      this.#sizes.fill(0)
    }
    this.#head = 0
    this.#tail = 0
    this.#free.length = 0
    this.#calculatedSize = 0
    this.#size = 0
    if (this.#hasDisposeAfter && this.#disposed) {
      const dt = this.#disposed
      let task
      while ((task = dt?.shift())) {
        this.#disposeAfter?.(...task)
      }
    }
  }
}
commonjs$2.LRUCache = LRUCache$1
const maybeJoin = (...args) => (args.every(arg => arg) ? args.join('') : '')
const maybeEncode = arg => (arg ? encodeURIComponent(arg) : '')
const formatHashFragment = f =>
  f
    .toLowerCase()
    .replace(/^\W+|\/|\W+$/g, '')
    .replace(/\W+/g, '-')
const defaults = {
  sshtemplate: ({ domain, user, project, committish }) =>
    `git@${domain}:${user}/${project}.git${maybeJoin('#', committish)}`,
  sshurltemplate: ({ domain, user, project, committish }) =>
    `git+ssh://git@${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
  edittemplate: ({ domain, user, project, committish, editpath, path }) =>
    `https://${domain}/${user}/${project}${maybeJoin('/', editpath, '/', maybeEncode(committish || 'HEAD'), '/', path)}`,
  browsetemplate: ({ domain, user, project, committish, treepath }) =>
    `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish))}`,
  browsetreetemplate: ({
    domain,
    user,
    project,
    committish,
    treepath,
    path,
    fragment,
    hashformat
  }) =>
    `https://${domain}/${user}/${project}/${treepath}/${maybeEncode(committish || 'HEAD')}/${path}${maybeJoin('#', hashformat(fragment || ''))}`,
  browseblobtemplate: ({
    domain,
    user,
    project,
    committish,
    blobpath,
    path,
    fragment,
    hashformat
  }) =>
    `https://${domain}/${user}/${project}/${blobpath}/${maybeEncode(committish || 'HEAD')}/${path}${maybeJoin('#', hashformat(fragment || ''))}`,
  docstemplate: ({ domain, user, project, treepath, committish }) =>
    `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish))}#readme`,
  httpstemplate: ({ auth, domain, user, project, committish }) =>
    `git+https://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
  filetemplate: ({ domain, user, project, committish, path }) =>
    `https://${domain}/${user}/${project}/raw/${maybeEncode(committish || 'HEAD')}/${path}`,
  shortcuttemplate: ({ type, user, project, committish }) =>
    `${type}:${user}/${project}${maybeJoin('#', committish)}`,
  pathtemplate: ({ user, project, committish }) =>
    `${user}/${project}${maybeJoin('#', committish)}`,
  bugstemplate: ({ domain, user, project }) =>
    `https://${domain}/${user}/${project}/issues`,
  hashformat: formatHashFragment
}
const hosts$1 = {}
hosts$1.github = {
  protocols: ['git:', 'http:', 'git+ssh:', 'git+https:', 'ssh:', 'https:'],
  domain: 'github.com',
  treepath: 'tree',
  blobpath: 'blob',
  editpath: 'edit',
  filetemplate: ({ auth, user, project, committish, path }) =>
    `https://${maybeJoin(auth, '@')}raw.githubusercontent.com/${user}/${project}/${maybeEncode(committish || 'HEAD')}/${path}`,
  gittemplate: ({ auth, domain, user, project, committish }) =>
    `git://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
  tarballtemplate: ({ domain, user, project, committish }) =>
    `https://codeload.${domain}/${user}/${project}/tar.gz/${maybeEncode(committish || 'HEAD')}`,
  extract: url => {
    let [, user, project, type, committish] = url.pathname.split('/', 5)
    if (type && type !== 'tree') {
      return
    }
    if (!type) {
      committish = url.hash.slice(1)
    }
    if (project && project.endsWith('.git')) {
      project = project.slice(0, -4)
    }
    if (!user || !project) {
      return
    }
    return {
      user,
      project,
      committish
    }
  }
}
hosts$1.bitbucket = {
  protocols: ['git+ssh:', 'git+https:', 'ssh:', 'https:'],
  domain: 'bitbucket.org',
  treepath: 'src',
  blobpath: 'src',
  editpath: '?mode=edit',
  edittemplate: ({
    domain,
    user,
    project,
    committish,
    treepath,
    path,
    editpath
  }) =>
    `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish || 'HEAD'), '/', path, editpath)}`,
  tarballtemplate: ({ domain, user, project, committish }) =>
    `https://${domain}/${user}/${project}/get/${maybeEncode(committish || 'HEAD')}.tar.gz`,
  extract: url => {
    let [, user, project, aux] = url.pathname.split('/', 4)
    if (['get'].includes(aux)) {
      return
    }
    if (project && project.endsWith('.git')) {
      project = project.slice(0, -4)
    }
    if (!user || !project) {
      return
    }
    return {
      user,
      project,
      committish: url.hash.slice(1)
    }
  }
}
hosts$1.gitlab = {
  protocols: ['git+ssh:', 'git+https:', 'ssh:', 'https:'],
  domain: 'gitlab.com',
  treepath: 'tree',
  blobpath: 'tree',
  editpath: '-/edit',
  httpstemplate: ({ auth, domain, user, project, committish }) =>
    `git+https://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
  tarballtemplate: ({ domain, user, project, committish }) =>
    `https://${domain}/${user}/${project}/repository/archive.tar.gz?ref=${maybeEncode(committish || 'HEAD')}`,
  extract: url => {
    const path = url.pathname.slice(1)
    if (path.includes('/-/') || path.includes('/archive.tar.gz')) {
      return
    }
    const segments = path.split('/')
    let project = segments.pop()
    if (project.endsWith('.git')) {
      project = project.slice(0, -4)
    }
    const user = segments.join('/')
    if (!user || !project) {
      return
    }
    return {
      user,
      project,
      committish: url.hash.slice(1)
    }
  }
}
hosts$1.gist = {
  protocols: ['git:', 'git+ssh:', 'git+https:', 'ssh:', 'https:'],
  domain: 'gist.github.com',
  editpath: 'edit',
  sshtemplate: ({ domain, project, committish }) =>
    `git@${domain}:${project}.git${maybeJoin('#', committish)}`,
  sshurltemplate: ({ domain, project, committish }) =>
    `git+ssh://git@${domain}/${project}.git${maybeJoin('#', committish)}`,
  edittemplate: ({ domain, user, project, committish, editpath }) =>
    `https://${domain}/${user}/${project}${maybeJoin('/', maybeEncode(committish))}/${editpath}`,
  browsetemplate: ({ domain, project, committish }) =>
    `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}`,
  browsetreetemplate: ({ domain, project, committish, path, hashformat }) =>
    `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}${maybeJoin('#', hashformat(path))}`,
  browseblobtemplate: ({ domain, project, committish, path, hashformat }) =>
    `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}${maybeJoin('#', hashformat(path))}`,
  docstemplate: ({ domain, project, committish }) =>
    `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}`,
  httpstemplate: ({ domain, project, committish }) =>
    `git+https://${domain}/${project}.git${maybeJoin('#', committish)}`,
  filetemplate: ({ user, project, committish, path }) =>
    `https://gist.githubusercontent.com/${user}/${project}/raw${maybeJoin('/', maybeEncode(committish))}/${path}`,
  shortcuttemplate: ({ type, project, committish }) =>
    `${type}:${project}${maybeJoin('#', committish)}`,
  pathtemplate: ({ project, committish }) =>
    `${project}${maybeJoin('#', committish)}`,
  bugstemplate: ({ domain, project }) => `https://${domain}/${project}`,
  gittemplate: ({ domain, project, committish }) =>
    `git://${domain}/${project}.git${maybeJoin('#', committish)}`,
  tarballtemplate: ({ project, committish }) =>
    `https://codeload.github.com/gist/${project}/tar.gz/${maybeEncode(committish || 'HEAD')}`,
  extract: url => {
    let [, user, project, aux] = url.pathname.split('/', 4)
    if (aux === 'raw') {
      return
    }
    if (!project) {
      if (!user) {
        return
      }
      project = user
      user = null
    }
    if (project.endsWith('.git')) {
      project = project.slice(0, -4)
    }
    return {
      user,
      project,
      committish: url.hash.slice(1)
    }
  },
  hashformat: function (fragment) {
    return fragment && 'file-' + formatHashFragment(fragment)
  }
}
hosts$1.sourcehut = {
  protocols: ['git+ssh:', 'https:'],
  domain: 'git.sr.ht',
  treepath: 'tree',
  blobpath: 'tree',
  filetemplate: ({ domain, user, project, committish, path }) =>
    `https://${domain}/${user}/${project}/blob/${maybeEncode(committish) || 'HEAD'}/${path}`,
  httpstemplate: ({ domain, user, project, committish }) =>
    `https://${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
  tarballtemplate: ({ domain, user, project, committish }) =>
    `https://${domain}/${user}/${project}/archive/${maybeEncode(committish) || 'HEAD'}.tar.gz`,
  bugstemplate: ({ user, project }) => null,
  extract: url => {
    let [, user, project, aux] = url.pathname.split('/', 4)
    if (['archive'].includes(aux)) {
      return
    }
    if (project && project.endsWith('.git')) {
      project = project.slice(0, -4)
    }
    if (!user || !project) {
      return
    }
    return {
      user,
      project,
      committish: url.hash.slice(1)
    }
  }
}
for (const [name, host] of Object.entries(hosts$1)) {
  hosts$1[name] = Object.assign({}, defaults, host)
}
const hosts_1$1 = hosts$1
const url$2 = require$$0$b
const lastIndexOfBefore = (str, char, beforeChar) => {
  const startPosition = str.indexOf(beforeChar)
  return str.lastIndexOf(char, startPosition > -1 ? startPosition : Infinity)
}
const safeUrl = u => {
  try {
    return new url$2.URL(u)
  } catch {}
}
const correctProtocol = (arg, protocols) => {
  const firstColon = arg.indexOf(':')
  const proto = arg.slice(0, firstColon + 1)
  if (Object.prototype.hasOwnProperty.call(protocols, proto)) {
    return arg
  }
  const firstAt = arg.indexOf('@')
  if (firstAt > -1) {
    if (firstAt > firstColon) {
      return `git+ssh://${arg}`
    } else {
      return arg
    }
  }
  const doubleSlash = arg.indexOf('//')
  if (doubleSlash === firstColon + 1) {
    return arg
  }
  return `${arg.slice(0, firstColon + 1)}//${arg.slice(firstColon + 1)}`
}
const correctUrl = giturl => {
  const firstAt = lastIndexOfBefore(giturl, '@', '#')
  const lastColonBeforeHash = lastIndexOfBefore(giturl, ':', '#')
  if (lastColonBeforeHash > firstAt) {
    giturl =
      giturl.slice(0, lastColonBeforeHash) +
      '/' +
      giturl.slice(lastColonBeforeHash + 1)
  }
  if (
    lastIndexOfBefore(giturl, ':', '#') === -1 &&
    giturl.indexOf('//') === -1
  ) {
    giturl = `git+ssh://${giturl}`
  }
  return giturl
}
const parseUrl$2 = (giturl, protocols) => {
  const withProtocol = protocols ? correctProtocol(giturl, protocols) : giturl
  return safeUrl(withProtocol) || safeUrl(correctUrl(withProtocol))
}
const parseUrl$1$1 = parseUrl$2
const isGitHubShorthand = arg => {
  const firstHash = arg.indexOf('#')
  const firstSlash = arg.indexOf('/')
  const secondSlash = arg.indexOf('/', firstSlash + 1)
  const firstColon = arg.indexOf(':')
  const firstSpace = /\s/.exec(arg)
  const firstAt = arg.indexOf('@')
  const spaceOnlyAfterHash =
    !firstSpace || (firstHash > -1 && firstSpace.index > firstHash)
  const atOnlyAfterHash =
    firstAt === -1 || (firstHash > -1 && firstAt > firstHash)
  const colonOnlyAfterHash =
    firstColon === -1 || (firstHash > -1 && firstColon > firstHash)
  const secondSlashOnlyAfterHash =
    secondSlash === -1 || (firstHash > -1 && secondSlash > firstHash)
  const hasSlash = firstSlash > 0
  const doesNotEndWithSlash =
    firstHash > -1 ? arg[firstHash - 1] !== '/' : !arg.endsWith('/')
  const doesNotStartWithDot = !arg.startsWith('.')
  return (
    spaceOnlyAfterHash &&
    hasSlash &&
    doesNotEndWithSlash &&
    doesNotStartWithDot &&
    atOnlyAfterHash &&
    colonOnlyAfterHash &&
    secondSlashOnlyAfterHash
  )
}
const fromUrl$1 = (giturl, opts, { gitHosts, protocols }) => {
  if (!giturl) {
    return
  }
  const correctedUrl = isGitHubShorthand(giturl) ? `github:${giturl}` : giturl
  const parsed = parseUrl$1$1(correctedUrl, protocols)
  if (!parsed) {
    return
  }
  const gitHostShortcut = gitHosts.byShortcut[parsed.protocol]
  const gitHostDomain =
    gitHosts.byDomain[
      parsed.hostname.startsWith('www.')
        ? parsed.hostname.slice(4)
        : parsed.hostname
    ]
  const gitHostName = gitHostShortcut || gitHostDomain
  if (!gitHostName) {
    return
  }
  const gitHostInfo = gitHosts[gitHostShortcut || gitHostDomain]
  let auth = null
  if (
    protocols[parsed.protocol]?.auth &&
    (parsed.username || parsed.password)
  ) {
    auth = `${parsed.username}${parsed.password ? ':' + parsed.password : ''}`
  }
  let committish = null
  let user = null
  let project = null
  let defaultRepresentation = null
  try {
    if (gitHostShortcut) {
      let pathname = parsed.pathname.startsWith('/')
        ? parsed.pathname.slice(1)
        : parsed.pathname
      const firstAt = pathname.indexOf('@')
      if (firstAt > -1) {
        pathname = pathname.slice(firstAt + 1)
      }
      const lastSlash = pathname.lastIndexOf('/')
      if (lastSlash > -1) {
        user = decodeURIComponent(pathname.slice(0, lastSlash))
        if (!user) {
          user = null
        }
        project = decodeURIComponent(pathname.slice(lastSlash + 1))
      } else {
        project = decodeURIComponent(pathname)
      }
      if (project.endsWith('.git')) {
        project = project.slice(0, -4)
      }
      if (parsed.hash) {
        committish = decodeURIComponent(parsed.hash.slice(1))
      }
      defaultRepresentation = 'shortcut'
    } else {
      if (!gitHostInfo.protocols.includes(parsed.protocol)) {
        return
      }
      const segments = gitHostInfo.extract(parsed)
      if (!segments) {
        return
      }
      user = segments.user && decodeURIComponent(segments.user)
      project = decodeURIComponent(segments.project)
      committish = decodeURIComponent(segments.committish)
      defaultRepresentation =
        protocols[parsed.protocol]?.name || parsed.protocol.slice(0, -1)
    }
  } catch (err) {
    if (err instanceof URIError) {
      return
    } else {
      throw err
    }
  }
  return [
    gitHostName,
    user,
    auth,
    project,
    committish,
    defaultRepresentation,
    opts
  ]
}
const { LRUCache } = commonjs$2
const hosts = hosts_1$1
const fromUrl$2 = fromUrl$1
const parseUrl$3 = parseUrl$2
const cache$1 = new LRUCache({
  max: 1000
})
class GitHost {
  constructor(
    type,
    user,
    auth,
    project,
    committish,
    defaultRepresentation,
    opts = {}
  ) {
    Object.assign(this, GitHost.#gitHosts[type], {
      type,
      user,
      auth,
      project,
      committish,
      default: defaultRepresentation,
      opts
    })
  }
  static #gitHosts = {
    byShortcut: {},
    byDomain: {}
  }
  static #protocols = {
    'git+ssh:': {
      name: 'sshurl'
    },
    'ssh:': {
      name: 'sshurl'
    },
    'git+https:': {
      name: 'https',
      auth: true
    },
    'git:': {
      auth: true
    },
    'http:': {
      auth: true
    },
    'https:': {
      auth: true
    },
    'git+http:': {
      auth: true
    }
  }
  static addHost(name, host) {
    GitHost.#gitHosts[name] = host
    GitHost.#gitHosts.byDomain[host.domain] = name
    GitHost.#gitHosts.byShortcut[`${name}:`] = name
    GitHost.#protocols[`${name}:`] = {
      name
    }
  }
  static fromUrl(giturl, opts) {
    if (typeof giturl !== 'string') {
      return
    }
    const key = giturl + JSON.stringify(opts || {})
    if (!cache$1.has(key)) {
      const hostArgs = fromUrl$2(giturl, opts, {
        gitHosts: GitHost.#gitHosts,
        protocols: GitHost.#protocols
      })
      cache$1.set(key, hostArgs ? new GitHost(...hostArgs) : undefined)
    }
    return cache$1.get(key)
  }
  static parseUrl(url) {
    return parseUrl$3(url)
  }
  #fill(template, opts) {
    if (typeof template !== 'function') {
      return null
    }
    const options = {
      ...this,
      ...this.opts,
      ...opts
    }
    if (!options.path) {
      options.path = ''
    }
    if (options.path.startsWith('/')) {
      options.path = options.path.slice(1)
    }
    if (options.noCommittish) {
      options.committish = null
    }
    const result = template(options)
    return options.noGitPlus && result.startsWith('git+')
      ? result.slice(4)
      : result
  }
  hash() {
    return this.committish ? `#${this.committish}` : ''
  }
  ssh(opts) {
    return this.#fill(this.sshtemplate, opts)
  }
  sshurl(opts) {
    return this.#fill(this.sshurltemplate, opts)
  }
  browse(path, ...args) {
    if (typeof path !== 'string') {
      return this.#fill(this.browsetemplate, path)
    }
    if (typeof args[0] !== 'string') {
      return this.#fill(this.browsetreetemplate, {
        ...args[0],
        path
      })
    }
    return this.#fill(this.browsetreetemplate, {
      ...args[1],
      fragment: args[0],
      path
    })
  }
  browseFile(path, ...args) {
    if (typeof args[0] !== 'string') {
      return this.#fill(this.browseblobtemplate, {
        ...args[0],
        path
      })
    }
    return this.#fill(this.browseblobtemplate, {
      ...args[1],
      fragment: args[0],
      path
    })
  }
  docs(opts) {
    return this.#fill(this.docstemplate, opts)
  }
  bugs(opts) {
    return this.#fill(this.bugstemplate, opts)
  }
  https(opts) {
    return this.#fill(this.httpstemplate, opts)
  }
  git(opts) {
    return this.#fill(this.gittemplate, opts)
  }
  shortcut(opts) {
    return this.#fill(this.shortcuttemplate, opts)
  }
  path(opts) {
    return this.#fill(this.pathtemplate, opts)
  }
  tarball(opts) {
    return this.#fill(this.tarballtemplate, {
      ...opts,
      noCommittish: false
    })
  }
  file(path, opts) {
    return this.#fill(this.filetemplate, {
      ...opts,
      path
    })
  }
  edit(path, opts) {
    return this.#fill(this.edittemplate, {
      ...opts,
      path
    })
  }
  getDefaultRepresentation() {
    return this.default
  }
  toString(opts) {
    if (this.default && typeof this[this.default] === 'function') {
      return this[this.default](opts)
    }
    return this.sshurl(opts)
  }
}
for (const [name, host] of Object.entries(hosts)) {
  GitHost.addHost(name, host)
}
const lib$3$1 = GitHost
const ERROR_MESSAGE = 'Function.prototype.bind called on incompatible '
const toStr = Object.prototype.toString
const max = Math.max
const funcType = '[object Function]'
const concatty = function concatty(a, b) {
  const arr = []
  for (let i = 0; i < a.length; i += 1) {
    arr[i] = a[i]
  }
  for (let j = 0; j < b.length; j += 1) {
    arr[j + a.length] = b[j]
  }
  return arr
}
const slicy = function slicy(arrLike, offset) {
  const arr = []
  for (let i = offset, j = 0; i < arrLike.length; i += 1, j += 1) {
    arr[j] = arrLike[i]
  }
  return arr
}
const joiny = function (arr, joiner) {
  let str = ''
  for (let i = 0; i < arr.length; i += 1) {
    str += arr[i]
    if (i + 1 < arr.length) {
      str += joiner
    }
  }
  return str
}
const implementation$1 = function bind(that) {
  const target = this
  if (typeof target !== 'function' || toStr.apply(target) !== funcType) {
    throw new TypeError(ERROR_MESSAGE + target)
  }
  const args = slicy(arguments, 1)
  let bound
  const binder = function () {
    if (this instanceof bound) {
      const result = target.apply(this, concatty(args, arguments))
      if (Object(result) === result) {
        return result
      }
      return this
    }
    return target.apply(that, concatty(args, arguments))
  }
  const boundLength = max(0, target.length - args.length)
  const boundArgs = []
  for (let i = 0; i < boundLength; i++) {
    boundArgs[i] = '$' + i
  }
  bound = Function(
    'binder',
    'return function (' +
      joiny(boundArgs, ',') +
      '){ return binder.apply(this,arguments); }'
  )(binder)
  if (target.prototype) {
    const Empty = function Empty() {}
    Empty.prototype = target.prototype
    bound.prototype = new Empty()
    Empty.prototype = null
  }
  return bound
}
const implementation = implementation$1
const functionBind = Function.prototype.bind || implementation
const call = Function.prototype.call
const $hasOwn = Object.prototype.hasOwnProperty
const bind$1 = functionBind
const hasown = bind$1.call(call, $hasOwn)
const assert = true
const async_hooks = '>= 8'
const buffer_ieee754 = '>= 0.5 && < 0.9.7'
const buffer = true
const child_process = true
const cluster = '>= 0.5'
const console$1 = true
const constants$2 = true
const crypto = true
const _debug_agent = '>= 1 && < 8'
const _debugger = '< 8'
const dgram = true
const diagnostics_channel = ['>= 14.17 && < 15', '>= 15.1']
const dns = true
const domain = '>= 0.7.12'
const events = true
const freelist = '< 6'
const fs = true
const _http_agent = '>= 0.11.1'
const _http_client = '>= 0.11.1'
const _http_common = '>= 0.11.1'
const _http_incoming = '>= 0.11.1'
const _http_outgoing = '>= 0.11.1'
const _http_server = '>= 0.11.1'
const http = true
const http2 = '>= 8.8'
const https = true
const inspector = '>= 8'
const _linklist = '< 8'
const module$1 = true
const net = true
const os$2 = true
const path = true
const perf_hooks = '>= 8.5'
const process$1 = '>= 1'
const punycode = '>= 0.5'
const querystring = true
const readline = true
const repl = true
const smalloc = '>= 0.11.5 && < 3'
const _stream_duplex$2 = '>= 0.9.4'
const _stream_transform$2 = '>= 0.9.4'
const _stream_wrap = '>= 1.4.1'
const _stream_passthrough$2 = '>= 0.9.4'
const _stream_readable$2 = '>= 0.9.4'
const _stream_writable$2 = '>= 0.9.4'
const stream$3 = true
const string_decoder$2 = true
const sys = ['>= 0.4 && < 0.7', '>= 0.8']
const timers = true
const _tls_common = '>= 0.11.13'
const _tls_legacy = '>= 0.11.3 && < 10'
const _tls_wrap = '>= 0.11.3'
const tls = true
const trace_events = '>= 10'
const tty = true
const url$1 = true
const util$1 = true
const v8$1 = '>= 1'
const vm = true
const wasi = ['>= 13.4 && < 13.5', '>= 18.17 && < 19', '>= 20']
const worker_threads = '>= 11.7'
const zlib = '>= 0.5'
const require$$1$1 = {
  assert: assert,
  'node:assert': ['>= 14.18 && < 15', '>= 16'],
  'assert/strict': '>= 15',
  'node:assert/strict': '>= 16',
  async_hooks: async_hooks,
  'node:async_hooks': ['>= 14.18 && < 15', '>= 16'],
  buffer_ieee754: buffer_ieee754,
  buffer: buffer,
  'node:buffer': ['>= 14.18 && < 15', '>= 16'],
  child_process: child_process,
  'node:child_process': ['>= 14.18 && < 15', '>= 16'],
  cluster: cluster,
  'node:cluster': ['>= 14.18 && < 15', '>= 16'],
  console: console$1,
  'node:console': ['>= 14.18 && < 15', '>= 16'],
  constants: constants$2,
  'node:constants': ['>= 14.18 && < 15', '>= 16'],
  crypto: crypto,
  'node:crypto': ['>= 14.18 && < 15', '>= 16'],
  _debug_agent: _debug_agent,
  _debugger: _debugger,
  dgram: dgram,
  'node:dgram': ['>= 14.18 && < 15', '>= 16'],
  diagnostics_channel: diagnostics_channel,
  'node:diagnostics_channel': ['>= 14.18 && < 15', '>= 16'],
  dns: dns,
  'node:dns': ['>= 14.18 && < 15', '>= 16'],
  'dns/promises': '>= 15',
  'node:dns/promises': '>= 16',
  domain: domain,
  'node:domain': ['>= 14.18 && < 15', '>= 16'],
  events: events,
  'node:events': ['>= 14.18 && < 15', '>= 16'],
  freelist: freelist,
  fs: fs,
  'node:fs': ['>= 14.18 && < 15', '>= 16'],
  'fs/promises': ['>= 10 && < 10.1', '>= 14'],
  'node:fs/promises': ['>= 14.18 && < 15', '>= 16'],
  _http_agent: _http_agent,
  'node:_http_agent': ['>= 14.18 && < 15', '>= 16'],
  _http_client: _http_client,
  'node:_http_client': ['>= 14.18 && < 15', '>= 16'],
  _http_common: _http_common,
  'node:_http_common': ['>= 14.18 && < 15', '>= 16'],
  _http_incoming: _http_incoming,
  'node:_http_incoming': ['>= 14.18 && < 15', '>= 16'],
  _http_outgoing: _http_outgoing,
  'node:_http_outgoing': ['>= 14.18 && < 15', '>= 16'],
  _http_server: _http_server,
  'node:_http_server': ['>= 14.18 && < 15', '>= 16'],
  http: http,
  'node:http': ['>= 14.18 && < 15', '>= 16'],
  http2: http2,
  'node:http2': ['>= 14.18 && < 15', '>= 16'],
  https: https,
  'node:https': ['>= 14.18 && < 15', '>= 16'],
  inspector: inspector,
  'node:inspector': ['>= 14.18 && < 15', '>= 16'],
  'inspector/promises': ['>= 19'],
  'node:inspector/promises': ['>= 19'],
  _linklist: _linklist,
  module: module$1,
  'node:module': ['>= 14.18 && < 15', '>= 16'],
  net: net,
  'node:net': ['>= 14.18 && < 15', '>= 16'],
  'node-inspect/lib/_inspect': '>= 7.6 && < 12',
  'node-inspect/lib/internal/inspect_client': '>= 7.6 && < 12',
  'node-inspect/lib/internal/inspect_repl': '>= 7.6 && < 12',
  os: os$2,
  'node:os': ['>= 14.18 && < 15', '>= 16'],
  path: path,
  'node:path': ['>= 14.18 && < 15', '>= 16'],
  'path/posix': '>= 15.3',
  'node:path/posix': '>= 16',
  'path/win32': '>= 15.3',
  'node:path/win32': '>= 16',
  perf_hooks: perf_hooks,
  'node:perf_hooks': ['>= 14.18 && < 15', '>= 16'],
  process: process$1,
  'node:process': ['>= 14.18 && < 15', '>= 16'],
  punycode: punycode,
  'node:punycode': ['>= 14.18 && < 15', '>= 16'],
  querystring: querystring,
  'node:querystring': ['>= 14.18 && < 15', '>= 16'],
  readline: readline,
  'node:readline': ['>= 14.18 && < 15', '>= 16'],
  'readline/promises': '>= 17',
  'node:readline/promises': '>= 17',
  repl: repl,
  'node:repl': ['>= 14.18 && < 15', '>= 16'],
  smalloc: smalloc,
  _stream_duplex: _stream_duplex$2,
  'node:_stream_duplex': ['>= 14.18 && < 15', '>= 16'],
  _stream_transform: _stream_transform$2,
  'node:_stream_transform': ['>= 14.18 && < 15', '>= 16'],
  _stream_wrap: _stream_wrap,
  'node:_stream_wrap': ['>= 14.18 && < 15', '>= 16'],
  _stream_passthrough: _stream_passthrough$2,
  'node:_stream_passthrough': ['>= 14.18 && < 15', '>= 16'],
  _stream_readable: _stream_readable$2,
  'node:_stream_readable': ['>= 14.18 && < 15', '>= 16'],
  _stream_writable: _stream_writable$2,
  'node:_stream_writable': ['>= 14.18 && < 15', '>= 16'],
  stream: stream$3,
  'node:stream': ['>= 14.18 && < 15', '>= 16'],
  'stream/consumers': '>= 16.7',
  'node:stream/consumers': '>= 16.7',
  'stream/promises': '>= 15',
  'node:stream/promises': '>= 16',
  'stream/web': '>= 16.5',
  'node:stream/web': '>= 16.5',
  string_decoder: string_decoder$2,
  'node:string_decoder': ['>= 14.18 && < 15', '>= 16'],
  sys: sys,
  'node:sys': ['>= 14.18 && < 15', '>= 16'],
  'test/reporters': '>= 19.9 && < 20.2',
  'node:test/reporters': ['>= 18.17 && < 19', '>= 19.9', '>= 20'],
  'node:test': ['>= 16.17 && < 17', '>= 18'],
  timers: timers,
  'node:timers': ['>= 14.18 && < 15', '>= 16'],
  'timers/promises': '>= 15',
  'node:timers/promises': '>= 16',
  _tls_common: _tls_common,
  'node:_tls_common': ['>= 14.18 && < 15', '>= 16'],
  _tls_legacy: _tls_legacy,
  _tls_wrap: _tls_wrap,
  'node:_tls_wrap': ['>= 14.18 && < 15', '>= 16'],
  tls: tls,
  'node:tls': ['>= 14.18 && < 15', '>= 16'],
  trace_events: trace_events,
  'node:trace_events': ['>= 14.18 && < 15', '>= 16'],
  tty: tty,
  'node:tty': ['>= 14.18 && < 15', '>= 16'],
  url: url$1,
  'node:url': ['>= 14.18 && < 15', '>= 16'],
  util: util$1,
  'node:util': ['>= 14.18 && < 15', '>= 16'],
  'util/types': '>= 15.3',
  'node:util/types': '>= 16',
  'v8/tools/arguments': '>= 10 && < 12',
  'v8/tools/codemap': ['>= 4.4 && < 5', '>= 5.2 && < 12'],
  'v8/tools/consarray': ['>= 4.4 && < 5', '>= 5.2 && < 12'],
  'v8/tools/csvparser': ['>= 4.4 && < 5', '>= 5.2 && < 12'],
  'v8/tools/logreader': ['>= 4.4 && < 5', '>= 5.2 && < 12'],
  'v8/tools/profile_view': ['>= 4.4 && < 5', '>= 5.2 && < 12'],
  'v8/tools/splaytree': ['>= 4.4 && < 5', '>= 5.2 && < 12'],
  v8: v8$1,
  'node:v8': ['>= 14.18 && < 15', '>= 16'],
  vm: vm,
  'node:vm': ['>= 14.18 && < 15', '>= 16'],
  wasi: wasi,
  'node:wasi': ['>= 18.17 && < 19', '>= 20'],
  worker_threads: worker_threads,
  'node:worker_threads': ['>= 14.18 && < 15', '>= 16'],
  zlib: zlib,
  'node:zlib': ['>= 14.18 && < 15', '>= 16']
}
const hasOwn = hasown
function specifierIncluded(current, specifier) {
  const nodeParts = current.split('.')
  const parts = specifier.split(' ')
  const op = parts.length > 1 ? parts[0] : '='
  const versionParts = (parts.length > 1 ? parts[1] : parts[0]).split('.')
  for (let i = 0; i < 3; ++i) {
    const cur = parseInt(nodeParts[i] || 0, 10)
    const ver = parseInt(versionParts[i] || 0, 10)
    if (cur === ver) {
      continue
    }
    if (op === '<') {
      return cur < ver
    }
    if (op === '>=') {
      return cur >= ver
    }
    return false
  }
  return op === '>='
}
function matchesRange(current, range) {
  const specifiers = range.split(/ ?&& ?/)
  if (specifiers.length === 0) {
    return false
  }
  for (let i = 0; i < specifiers.length; ++i) {
    if (!specifierIncluded(current, specifiers[i])) {
      return false
    }
  }
  return true
}
function versionIncluded(nodeVersion, specifierValue) {
  if (typeof specifierValue === 'boolean') {
    return specifierValue
  }
  const current =
    typeof nodeVersion === 'undefined'
      ? process.versions && process.versions.node
      : nodeVersion
  if (typeof current !== 'string') {
    throw new TypeError(
      typeof nodeVersion === 'undefined'
        ? 'Unable to determine current node version'
        : 'If provided, a valid node version is required'
    )
  }
  if (specifierValue && typeof specifierValue === 'object') {
    for (let i = 0; i < specifierValue.length; ++i) {
      if (matchesRange(current, specifierValue[i])) {
        return true
      }
    }
    return false
  }
  return matchesRange(current, specifierValue)
}
const data = require$$1$1
const isCoreModule = function isCore(x, nodeVersion) {
  return hasOwn(data, x) && versionIncluded(nodeVersion, data[x])
}
const extract_description = extractDescription$1
function extractDescription$1(d) {
  if (!d) {
    return
  }
  if (d === 'ERROR: No README data found!') {
    return
  }
  d = d.trim().split('\n')
  let s = 0
  while (d[s] && d[s].trim().match(/^(#|$)/)) {
    s++
  }
  const l = d.length
  let e = s + 1
  while (e < l && d[e].trim()) {
    e++
  }
  return d.slice(s, e).join(' ').trim()
}
const topLevel = {
  dependancies: 'dependencies',
  dependecies: 'dependencies',
  depdenencies: 'dependencies',
  devEependencies: 'devDependencies',
  depends: 'dependencies',
  'dev-dependencies': 'devDependencies',
  devDependences: 'devDependencies',
  devDepenencies: 'devDependencies',
  devdependencies: 'devDependencies',
  repostitory: 'repository',
  repo: 'repository',
  prefereGlobal: 'preferGlobal',
  hompage: 'homepage',
  hampage: 'homepage',
  autohr: 'author',
  autor: 'author',
  contributers: 'contributors',
  publicationConfig: 'publishConfig',
  script: 'scripts'
}
const bugs = {
  web: 'url',
  name: 'url'
}
const script = {
  server: 'start',
  tests: 'test'
}
const require$$7$1 = {
  topLevel: topLevel,
  bugs: bugs,
  script: script
}
const isValidSemver = valid_1$1
const cleanSemver = clean_1$1
const validateLicense = validateNpmPackageLicense
const hostedGitInfo = lib$3$1
const isBuiltinModule = isCoreModule
const depTypes = ['dependencies', 'devDependencies', 'optionalDependencies']
const extractDescription = extract_description
const url = require$$0$b
const typos = require$$7$1
const isEmail = str =>
  str.includes('@') && str.indexOf('@') < str.lastIndexOf('.')
const fixer$1 = {
  warn: function () {},
  fixRepositoryField: function (data) {
    if (data.repositories) {
      this.warn('repositories')
      data.repository = data.repositories[0]
    }
    if (!data.repository) {
      return this.warn('missingRepository')
    }
    if (typeof data.repository === 'string') {
      data.repository = {
        type: 'git',
        url: data.repository
      }
    }
    let r = data.repository.url || ''
    if (r) {
      const hosted = hostedGitInfo.fromUrl(r)
      if (hosted) {
        r = data.repository.url =
          hosted.getDefaultRepresentation() === 'shortcut'
            ? hosted.https()
            : hosted.toString()
      }
    }
    if (r.match(/github.com\/[^/]+\/[^/]+\.git\.git$/)) {
      this.warn('brokenGitUrl', r)
    }
  },
  fixTypos: function (data) {
    Object.keys(typos.topLevel).forEach(function (d) {
      if (Object.prototype.hasOwnProperty.call(data, d)) {
        this.warn('typo', d, typos.topLevel[d])
      }
    }, this)
  },
  fixScriptsField: function (data) {
    if (!data.scripts) {
      return
    }
    if (typeof data.scripts !== 'object') {
      this.warn('nonObjectScripts')
      delete data.scripts
      return
    }
    Object.keys(data.scripts).forEach(function (k) {
      if (typeof data.scripts[k] !== 'string') {
        this.warn('nonStringScript')
        delete data.scripts[k]
      } else if (typos.script[k] && !data.scripts[typos.script[k]]) {
        this.warn('typo', k, typos.script[k], 'scripts')
      }
    }, this)
  },
  fixFilesField: function (data) {
    const files = data.files
    if (files && !Array.isArray(files)) {
      this.warn('nonArrayFiles')
      delete data.files
    } else if (data.files) {
      data.files = data.files.filter(function (file) {
        if (!file || typeof file !== 'string') {
          this.warn('invalidFilename', file)
          return false
        } else {
          return true
        }
      }, this)
    }
  },
  fixBinField: function (data) {
    if (!data.bin) {
      return
    }
    if (typeof data.bin === 'string') {
      const b = {}
      let match
      if ((match = data.name.match(/^@[^/]+[/](.*)$/))) {
        b[match[1]] = data.bin
      } else {
        b[data.name] = data.bin
      }
      data.bin = b
    }
  },
  fixManField: function (data) {
    if (!data.man) {
      return
    }
    if (typeof data.man === 'string') {
      data.man = [data.man]
    }
  },
  fixBundleDependenciesField: function (data) {
    const bdd = 'bundledDependencies'
    const bd = 'bundleDependencies'
    if (data[bdd] && !data[bd]) {
      data[bd] = data[bdd]
      delete data[bdd]
    }
    if (data[bd] && !Array.isArray(data[bd])) {
      this.warn('nonArrayBundleDependencies')
      delete data[bd]
    } else if (data[bd]) {
      data[bd] = data[bd].filter(function (filtered) {
        if (!filtered || typeof filtered !== 'string') {
          this.warn('nonStringBundleDependency', filtered)
          return false
        } else {
          if (!data.dependencies) {
            data.dependencies = {}
          }
          if (
            !Object.prototype.hasOwnProperty.call(data.dependencies, filtered)
          ) {
            this.warn('nonDependencyBundleDependency', filtered)
            data.dependencies[filtered] = '*'
          }
          return true
        }
      }, this)
    }
  },
  fixDependencies: function (data, strict) {
    objectifyDeps(data, this.warn)
    addOptionalDepsToDeps(data, this.warn)
    this.fixBundleDependenciesField(data)
    ;['dependencies', 'devDependencies'].forEach(function (deps) {
      if (!(deps in data)) {
        return
      }
      if (!data[deps] || typeof data[deps] !== 'object') {
        this.warn('nonObjectDependencies', deps)
        delete data[deps]
        return
      }
      Object.keys(data[deps]).forEach(function (d) {
        const r = data[deps][d]
        if (typeof r !== 'string') {
          this.warn('nonStringDependency', d, JSON.stringify(r))
          delete data[deps][d]
        }
        const hosted = hostedGitInfo.fromUrl(data[deps][d])
        if (hosted) {
          data[deps][d] = hosted.toString()
        }
      }, this)
    }, this)
  },
  fixModulesField: function (data) {
    if (data.modules) {
      this.warn('deprecatedModules')
      delete data.modules
    }
  },
  fixKeywordsField: function (data) {
    if (typeof data.keywords === 'string') {
      data.keywords = data.keywords.split(/,\s+/)
    }
    if (data.keywords && !Array.isArray(data.keywords)) {
      delete data.keywords
      this.warn('nonArrayKeywords')
    } else if (data.keywords) {
      data.keywords = data.keywords.filter(function (kw) {
        if (typeof kw !== 'string' || !kw) {
          this.warn('nonStringKeyword')
          return false
        } else {
          return true
        }
      }, this)
    }
  },
  fixVersionField: function (data, strict) {
    const loose = !strict
    if (!data.version) {
      data.version = ''
      return true
    }
    if (!isValidSemver(data.version, loose)) {
      throw new Error('Invalid version: "' + data.version + '"')
    }
    data.version = cleanSemver(data.version, loose)
    return true
  },
  fixPeople: function (data) {
    modifyPeople(data, unParsePerson)
    modifyPeople(data, parsePerson)
  },
  fixNameField: function (data, options) {
    if (typeof options === 'boolean') {
      options = {
        strict: options
      }
    } else if (typeof options === 'undefined') {
      options = {}
    }
    const strict = options.strict
    if (!data.name && !strict) {
      data.name = ''
      return
    }
    if (typeof data.name !== 'string') {
      throw new Error('name field must be a string.')
    }
    if (!strict) {
      data.name = data.name.trim()
    }
    ensureValidName(data.name, strict, options.allowLegacyCase)
    if (isBuiltinModule(data.name)) {
      this.warn('conflictingName', data.name)
    }
  },
  fixDescriptionField: function (data) {
    if (data.description && typeof data.description !== 'string') {
      this.warn('nonStringDescription')
      delete data.description
    }
    if (data.readme && !data.description) {
      data.description = extractDescription(data.readme)
    }
    if (data.description === undefined) {
      delete data.description
    }
    if (!data.description) {
      this.warn('missingDescription')
    }
  },
  fixReadmeField: function (data) {
    if (!data.readme) {
      this.warn('missingReadme')
      data.readme = 'ERROR: No README data found!'
    }
  },
  fixBugsField: function (data) {
    if (!data.bugs && data.repository && data.repository.url) {
      const hosted = hostedGitInfo.fromUrl(data.repository.url)
      if (hosted && hosted.bugs()) {
        data.bugs = {
          url: hosted.bugs()
        }
      }
    } else if (data.bugs) {
      if (typeof data.bugs === 'string') {
        if (isEmail(data.bugs)) {
          data.bugs = {
            email: data.bugs
          }
        } else if (url.parse(data.bugs).protocol) {
          data.bugs = {
            url: data.bugs
          }
        } else {
          this.warn('nonEmailUrlBugsString')
        }
      } else {
        bugsTypos(data.bugs, this.warn)
        const oldBugs = data.bugs
        data.bugs = {}
        if (oldBugs.url) {
          if (
            typeof oldBugs.url === 'string' &&
            url.parse(oldBugs.url).protocol
          ) {
            data.bugs.url = oldBugs.url
          } else {
            this.warn('nonUrlBugsUrlField')
          }
        }
        if (oldBugs.email) {
          if (typeof oldBugs.email === 'string' && isEmail(oldBugs.email)) {
            data.bugs.email = oldBugs.email
          } else {
            this.warn('nonEmailBugsEmailField')
          }
        }
      }
      if (!data.bugs.email && !data.bugs.url) {
        delete data.bugs
        this.warn('emptyNormalizedBugs')
      }
    }
  },
  fixHomepageField: function (data) {
    if (!data.homepage && data.repository && data.repository.url) {
      const hosted = hostedGitInfo.fromUrl(data.repository.url)
      if (hosted && hosted.docs()) {
        data.homepage = hosted.docs()
      }
    }
    if (!data.homepage) {
      return
    }
    if (typeof data.homepage !== 'string') {
      this.warn('nonUrlHomepage')
      return delete data.homepage
    }
    if (!url.parse(data.homepage).protocol) {
      data.homepage = 'http://' + data.homepage
    }
  },
  fixLicenseField: function (data) {
    const license = data.license || data.licence
    if (!license) {
      return this.warn('missingLicense')
    }
    if (
      typeof license !== 'string' ||
      license.length < 1 ||
      license.trim() === ''
    ) {
      return this.warn('invalidLicense')
    }
    if (!validateLicense(license).validForNewPackages) {
      return this.warn('invalidLicense')
    }
  }
}
function isValidScopedPackageName(spec) {
  if (spec.charAt(0) !== '@') {
    return false
  }
  const rest = spec.slice(1).split('/')
  if (rest.length !== 2) {
    return false
  }
  return (
    rest[0] &&
    rest[1] &&
    rest[0] === encodeURIComponent(rest[0]) &&
    rest[1] === encodeURIComponent(rest[1])
  )
}
function isCorrectlyEncodedName(spec) {
  return !spec.match(/[/@\s+%:]/) && spec === encodeURIComponent(spec)
}
function ensureValidName(name, strict, allowLegacyCase) {
  if (
    name.charAt(0) === '.' ||
    !(isValidScopedPackageName(name) || isCorrectlyEncodedName(name)) ||
    (strict && !allowLegacyCase && name !== name.toLowerCase()) ||
    name.toLowerCase() === 'node_modules' ||
    name.toLowerCase() === 'favicon.ico'
  ) {
    throw new Error('Invalid name: ' + JSON.stringify(name))
  }
}
function modifyPeople(data, fn) {
  if (data.author) {
    data.author = fn(data.author)
  }
  ;['maintainers', 'contributors'].forEach(function (set) {
    if (!Array.isArray(data[set])) {
      return
    }
    data[set] = data[set].map(fn)
  })
  return data
}
function unParsePerson(person) {
  if (typeof person === 'string') {
    return person
  }
  const name = person.name || ''
  const u = person.url || person.web
  const wrappedUrl = u ? ' (' + u + ')' : ''
  const e = person.email || person.mail
  const wrappedEmail = e ? ' <' + e + '>' : ''
  return name + wrappedEmail + wrappedUrl
}
function parsePerson(person) {
  if (typeof person !== 'string') {
    return person
  }
  const matchedName = person.match(/^([^(<]+)/)
  const matchedUrl = person.match(/\(([^()]+)\)/)
  const matchedEmail = person.match(/<([^<>]+)>/)
  const obj = {}
  if (matchedName && matchedName[0].trim()) {
    obj.name = matchedName[0].trim()
  }
  if (matchedEmail) {
    obj.email = matchedEmail[1]
  }
  if (matchedUrl) {
    obj.url = matchedUrl[1]
  }
  return obj
}
function addOptionalDepsToDeps(data, warn) {
  const o = data.optionalDependencies
  if (!o) {
    return
  }
  const d = data.dependencies || {}
  Object.keys(o).forEach(function (k) {
    d[k] = o[k]
  })
  data.dependencies = d
}
function depObjectify(deps, type, warn) {
  if (!deps) {
    return {}
  }
  if (typeof deps === 'string') {
    deps = deps.trim().split(/[\n\r\s\t ,]+/)
  }
  if (!Array.isArray(deps)) {
    return deps
  }
  warn('deprecatedArrayDependencies', type)
  const o = {}
  deps
    .filter(function (d) {
      return typeof d === 'string'
    })
    .forEach(function (d) {
      d = d.trim().split(/(:?[@\s><=])/)
      const dn = d.shift()
      let dv = d.join('')
      dv = dv.trim()
      dv = dv.replace(/^@/, '')
      o[dn] = dv
    })
  return o
}
function objectifyDeps(data, warn) {
  depTypes.forEach(function (type) {
    if (!data[type]) {
      return
    }
    data[type] = depObjectify(data[type], type, warn)
  })
}
function bugsTypos(bugs, warn) {
  if (!bugs) {
    return
  }
  Object.keys(bugs).forEach(function (k) {
    if (typos.bugs[k]) {
      warn('typo', k, typos.bugs[k], 'bugs')
      bugs[typos.bugs[k]] = bugs[k]
      delete bugs[k]
    }
  })
}
const repositories =
  "'repositories' (plural) Not supported. Please pick one as the 'repository' field"
const missingRepository = 'No repository field.'
const brokenGitUrl = 'Probably broken git url: %s'
const nonObjectScripts = 'scripts must be an object'
const nonStringScript = 'script values must be string commands'
const nonArrayFiles = "Invalid 'files' member"
const invalidFilename = "Invalid filename in 'files' list: %s"
const nonArrayBundleDependencies =
  "Invalid 'bundleDependencies' list. Must be array of package names"
const nonStringBundleDependency = 'Invalid bundleDependencies member: %s'
const nonDependencyBundleDependency = 'Non-dependency in bundleDependencies: %s'
const nonObjectDependencies = '%s field must be an object'
const nonStringDependency = 'Invalid dependency: %s %s'
const deprecatedArrayDependencies = 'specifying %s as array is deprecated'
const deprecatedModules = 'modules field is deprecated'
const nonArrayKeywords = 'keywords should be an array of strings'
const nonStringKeyword = 'keywords should be an array of strings'
const conflictingName = '%s is also the name of a node core module.'
const nonStringDescription = "'description' field should be a string"
const missingDescription = 'No description'
const missingReadme = 'No README data'
const missingLicense = 'No license field.'
const nonEmailUrlBugsString =
  'Bug string field must be url, email, or {email,url}'
const nonUrlBugsUrlField = 'bugs.url field must be a string url. Deleted.'
const nonEmailBugsEmailField =
  'bugs.email field must be a string email. Deleted.'
const emptyNormalizedBugs =
  'Normalized value of bugs field is an empty object. Deleted.'
const nonUrlHomepage = 'homepage field must be a string url. Deleted.'
const invalidLicense = 'license should be a valid SPDX license expression'
const typo = '%s should probably be %s.'
const require$$1 = {
  repositories: repositories,
  missingRepository: missingRepository,
  brokenGitUrl: brokenGitUrl,
  nonObjectScripts: nonObjectScripts,
  nonStringScript: nonStringScript,
  nonArrayFiles: nonArrayFiles,
  invalidFilename: invalidFilename,
  nonArrayBundleDependencies: nonArrayBundleDependencies,
  nonStringBundleDependency: nonStringBundleDependency,
  nonDependencyBundleDependency: nonDependencyBundleDependency,
  nonObjectDependencies: nonObjectDependencies,
  nonStringDependency: nonStringDependency,
  deprecatedArrayDependencies: deprecatedArrayDependencies,
  deprecatedModules: deprecatedModules,
  nonArrayKeywords: nonArrayKeywords,
  nonStringKeyword: nonStringKeyword,
  conflictingName: conflictingName,
  nonStringDescription: nonStringDescription,
  missingDescription: missingDescription,
  missingReadme: missingReadme,
  missingLicense: missingLicense,
  nonEmailUrlBugsString: nonEmailUrlBugsString,
  nonUrlBugsUrlField: nonUrlBugsUrlField,
  nonEmailBugsEmailField: nonEmailBugsEmailField,
  emptyNormalizedBugs: emptyNormalizedBugs,
  nonUrlHomepage: nonUrlHomepage,
  invalidLicense: invalidLicense,
  typo: typo
}
const util = util$3
const messages = require$$1
const make_warning = function () {
  const args = Array.prototype.slice.call(arguments, 0)
  const warningName = args.shift()
  if (warningName === 'typo') {
    return makeTypoWarning.apply(null, args)
  } else {
    const msgTemplate = messages[warningName]
      ? messages[warningName]
      : warningName + ": '%s'"
    args.unshift(msgTemplate)
    return util.format.apply(null, args)
  }
}
function makeTypoWarning(providedName, probableName, field) {
  if (field) {
    providedName = field + "['" + providedName + "']"
    probableName = field + "['" + probableName + "']"
  }
  return util.format(messages.typo, providedName, probableName)
}
const normalize_1 = normalize$1
const fixer = fixer$1
normalize$1.fixer = fixer
const makeWarning = make_warning
const fieldsToFix = [
  'name',
  'version',
  'description',
  'repository',
  'modules',
  'scripts',
  'files',
  'bin',
  'man',
  'bugs',
  'keywords',
  'readme',
  'homepage',
  'license'
]
const otherThingsToFix = ['dependencies', 'people', 'typos']
let thingsToFix = fieldsToFix.map(function (fieldName) {
  return ucFirst(fieldName) + 'Field'
})
thingsToFix = thingsToFix.concat(otherThingsToFix)
function normalize$1(data, warn, strict) {
  if (warn === true) {
    warn = null
    strict = true
  }
  if (!strict) {
    strict = false
  }
  if (!warn || data.private) {
    warn = function (msg) {}
  }
  if (
    data.scripts &&
    data.scripts.install === 'node-gyp rebuild' &&
    !data.scripts.preinstall
  ) {
    data.gypfile = true
  }
  fixer.warn = function () {
    warn(makeWarning.apply(null, arguments))
  }
  thingsToFix.forEach(function (thingName) {
    fixer['fix' + ucFirst(thingName)](data, strict)
  })
  data._id = data.name + '@' + data.version
}
function ucFirst(string) {
  return string.charAt(0).toUpperCase() + string.slice(1)
}
const normalizePackageData = getDefaultExportFromCjs(normalize_1)
const toPath$1 = urlOrPath =>
  urlOrPath instanceof URL ? require$$0$b.fileURLToPath(urlOrPath) : urlOrPath
function findUpSync(
  name,
  { cwd = process$2.cwd(), type = 'file', stopAt } = {}
) {
  let directory = path$1.resolve(toPath$1(cwd) ?? '')
  const { root } = path$1.parse(directory)
  stopAt = path$1.resolve(directory, toPath$1(stopAt) ?? root)
  while (directory && directory !== stopAt && directory !== root) {
    const filePath = path$1.isAbsolute(name)
      ? name
      : path$1.join(directory, name)
    try {
      const stats = fs$1.statSync(filePath, {
        throwIfNoEntry: false
      })
      if (
        (type === 'file' && stats?.isFile()) ||
        (type === 'directory' && stats?.isDirectory())
      ) {
        return filePath
      }
    } catch {}
    directory = path$1.dirname(directory)
  }
}
const lib$2$1 = {}
const lib$1$1 = {}
const jsTokens = {}
Object.defineProperty(jsTokens, '__esModule', {
  value: true
})
jsTokens.default =
  /((['"])(?:(?!\2|\\).|\\(?:\r\n|[\s\S]))*(\2)?|`(?:[^`\\$]|\\[\s\S]|\$(?!\{)|\$\{(?:[^{}]|\{[^}]*\}?)*\}?)*(`)?)|(\/\/.*)|(\/\*(?:[^*]|\*(?!\/))*(\*\/)?)|(\/(?!\*)(?:\[(?:(?![\]\\]).|\\.)*\]|(?![/\]\\]).|\\.)+\/(?:(?!\s*(?:\b|[\u0080-\uFFFF$\\'"~({]|[+\-!](?!=)|\.?\d))|[gmiyus]{1,6}\b(?![\u0080-\uFFFF$\\]|\s*(?:[+\-*%&|^<>!=?({]|\/(?![/*])))))|(0[xX][\da-fA-F]+|0[oO][0-7]+|0[bB][01]+|(?:\d*\.\d+|\d+\.?)(?:[eE][+-]?\d+)?)|((?!\d)(?:(?!\s)[$\w\u0080-\uFFFF]|\\u[\da-fA-F]{4}|\\u\{[\da-fA-F]+\})+)|(--|\+\+|&&|\|\||=>|\.{3}|(?:[+\-/%&|^]|\*{1,2}|<{1,2}|>{1,3}|!=?|={1,2})=?|[?~.,:;[\](){}])|(\s+)|(^$|[\s\S])/g
jsTokens.matchToToken = function (match) {
  const token = {
    type: 'invalid',
    value: match[0],
    closed: undefined
  }
  if (match[1]) {
    ;(token.type = 'string'), (token.closed = !!(match[3] || match[4]))
  } else if (match[5]) {
    token.type = 'comment'
  } else if (match[6]) {
    ;(token.type = 'comment'), (token.closed = !!match[7])
  } else if (match[8]) {
    token.type = 'regex'
  } else if (match[9]) {
    token.type = 'number'
  } else if (match[10]) {
    token.type = 'name'
  } else if (match[11]) {
    token.type = 'punctuator'
  } else if (match[12]) {
    token.type = 'whitespace'
  }
  return token
}
const lib$m = {}
const identifier = {}
Object.defineProperty(identifier, '__esModule', {
  value: true
})
identifier.isIdentifierChar = isIdentifierChar
identifier.isIdentifierName = isIdentifierName
identifier.isIdentifierStart = isIdentifierStart
let nonASCIIidentifierStartChars =
  '\xaa\xb5\xba\xc0-\xd6\xd8-\xf6\xf8-\u02c1\u02c6-\u02d1\u02e0-\u02e4\u02ec\u02ee\u0370-\u0374\u0376\u0377\u037a-\u037d\u037f\u0386\u0388-\u038a\u038c\u038e-\u03a1\u03a3-\u03f5\u03f7-\u0481\u048a-\u052f\u0531-\u0556\u0559\u0560-\u0588\u05d0-\u05ea\u05ef-\u05f2\u0620-\u064a\u066e\u066f\u0671-\u06d3\u06d5\u06e5\u06e6\u06ee\u06ef\u06fa-\u06fc\u06ff\u0710\u0712-\u072f\u074d-\u07a5\u07b1\u07ca-\u07ea\u07f4\u07f5\u07fa\u0800-\u0815\u081a\u0824\u0828\u0840-\u0858\u0860-\u086a\u0870-\u0887\u0889-\u088e\u08a0-\u08c9\u0904-\u0939\u093d\u0950\u0958-\u0961\u0971-\u0980\u0985-\u098c\u098f\u0990\u0993-\u09a8\u09aa-\u09b0\u09b2\u09b6-\u09b9\u09bd\u09ce\u09dc\u09dd\u09df-\u09e1\u09f0\u09f1\u09fc\u0a05-\u0a0a\u0a0f\u0a10\u0a13-\u0a28\u0a2a-\u0a30\u0a32\u0a33\u0a35\u0a36\u0a38\u0a39\u0a59-\u0a5c\u0a5e\u0a72-\u0a74\u0a85-\u0a8d\u0a8f-\u0a91\u0a93-\u0aa8\u0aaa-\u0ab0\u0ab2\u0ab3\u0ab5-\u0ab9\u0abd\u0ad0\u0ae0\u0ae1\u0af9\u0b05-\u0b0c\u0b0f\u0b10\u0b13-\u0b28\u0b2a-\u0b30\u0b32\u0b33\u0b35-\u0b39\u0b3d\u0b5c\u0b5d\u0b5f-\u0b61\u0b71\u0b83\u0b85-\u0b8a\u0b8e-\u0b90\u0b92-\u0b95\u0b99\u0b9a\u0b9c\u0b9e\u0b9f\u0ba3\u0ba4\u0ba8-\u0baa\u0bae-\u0bb9\u0bd0\u0c05-\u0c0c\u0c0e-\u0c10\u0c12-\u0c28\u0c2a-\u0c39\u0c3d\u0c58-\u0c5a\u0c5d\u0c60\u0c61\u0c80\u0c85-\u0c8c\u0c8e-\u0c90\u0c92-\u0ca8\u0caa-\u0cb3\u0cb5-\u0cb9\u0cbd\u0cdd\u0cde\u0ce0\u0ce1\u0cf1\u0cf2\u0d04-\u0d0c\u0d0e-\u0d10\u0d12-\u0d3a\u0d3d\u0d4e\u0d54-\u0d56\u0d5f-\u0d61\u0d7a-\u0d7f\u0d85-\u0d96\u0d9a-\u0db1\u0db3-\u0dbb\u0dbd\u0dc0-\u0dc6\u0e01-\u0e30\u0e32\u0e33\u0e40-\u0e46\u0e81\u0e82\u0e84\u0e86-\u0e8a\u0e8c-\u0ea3\u0ea5\u0ea7-\u0eb0\u0eb2\u0eb3\u0ebd\u0ec0-\u0ec4\u0ec6\u0edc-\u0edf\u0f00\u0f40-\u0f47\u0f49-\u0f6c\u0f88-\u0f8c\u1000-\u102a\u103f\u1050-\u1055\u105a-\u105d\u1061\u1065\u1066\u106e-\u1070\u1075-\u1081\u108e\u10a0-\u10c5\u10c7\u10cd\u10d0-\u10fa\u10fc-\u1248\u124a-\u124d\u1250-\u1256\u1258\u125a-\u125d\u1260-\u1288\u128a-\u128d\u1290-\u12b0\u12b2-\u12b5\u12b8-\u12be\u12c0\u12c2-\u12c5\u12c8-\u12d6\u12d8-\u1310\u1312-\u1315\u1318-\u135a\u1380-\u138f\u13a0-\u13f5\u13f8-\u13fd\u1401-\u166c\u166f-\u167f\u1681-\u169a\u16a0-\u16ea\u16ee-\u16f8\u1700-\u1711\u171f-\u1731\u1740-\u1751\u1760-\u176c\u176e-\u1770\u1780-\u17b3\u17d7\u17dc\u1820-\u1878\u1880-\u18a8\u18aa\u18b0-\u18f5\u1900-\u191e\u1950-\u196d\u1970-\u1974\u1980-\u19ab\u19b0-\u19c9\u1a00-\u1a16\u1a20-\u1a54\u1aa7\u1b05-\u1b33\u1b45-\u1b4c\u1b83-\u1ba0\u1bae\u1baf\u1bba-\u1be5\u1c00-\u1c23\u1c4d-\u1c4f\u1c5a-\u1c7d\u1c80-\u1c88\u1c90-\u1cba\u1cbd-\u1cbf\u1ce9-\u1cec\u1cee-\u1cf3\u1cf5\u1cf6\u1cfa\u1d00-\u1dbf\u1e00-\u1f15\u1f18-\u1f1d\u1f20-\u1f45\u1f48-\u1f4d\u1f50-\u1f57\u1f59\u1f5b\u1f5d\u1f5f-\u1f7d\u1f80-\u1fb4\u1fb6-\u1fbc\u1fbe\u1fc2-\u1fc4\u1fc6-\u1fcc\u1fd0-\u1fd3\u1fd6-\u1fdb\u1fe0-\u1fec\u1ff2-\u1ff4\u1ff6-\u1ffc\u2071\u207f\u2090-\u209c\u2102\u2107\u210a-\u2113\u2115\u2118-\u211d\u2124\u2126\u2128\u212a-\u2139\u213c-\u213f\u2145-\u2149\u214e\u2160-\u2188\u2c00-\u2ce4\u2ceb-\u2cee\u2cf2\u2cf3\u2d00-\u2d25\u2d27\u2d2d\u2d30-\u2d67\u2d6f\u2d80-\u2d96\u2da0-\u2da6\u2da8-\u2dae\u2db0-\u2db6\u2db8-\u2dbe\u2dc0-\u2dc6\u2dc8-\u2dce\u2dd0-\u2dd6\u2dd8-\u2dde\u3005-\u3007\u3021-\u3029\u3031-\u3035\u3038-\u303c\u3041-\u3096\u309b-\u309f\u30a1-\u30fa\u30fc-\u30ff\u3105-\u312f\u3131-\u318e\u31a0-\u31bf\u31f0-\u31ff\u3400-\u4dbf\u4e00-\ua48c\ua4d0-\ua4fd\ua500-\ua60c\ua610-\ua61f\ua62a\ua62b\ua640-\ua66e\ua67f-\ua69d\ua6a0-\ua6ef\ua717-\ua71f\ua722-\ua788\ua78b-\ua7ca\ua7d0\ua7d1\ua7d3\ua7d5-\ua7d9\ua7f2-\ua801\ua803-\ua805\ua807-\ua80a\ua80c-\ua822\ua840-\ua873\ua882-\ua8b3\ua8f2-\ua8f7\ua8fb\ua8fd\ua8fe\ua90a-\ua925\ua930-\ua946\ua960-\ua97c\ua984-\ua9b2\ua9cf\ua9e0-\ua9e4\ua9e6-\ua9ef\ua9fa-\ua9fe\uaa00-\uaa28\uaa40-\uaa42\uaa44-\uaa4b\uaa60-\uaa76\uaa7a\uaa7e-\uaaaf\uaab1\uaab5\uaab6\uaab9-\uaabd\uaac0\uaac2\uaadb-\uaadd\uaae0-\uaaea\uaaf2-\uaaf4\uab01-\uab06\uab09-\uab0e\uab11-\uab16\uab20-\uab26\uab28-\uab2e\uab30-\uab5a\uab5c-\uab69\uab70-\uabe2\uac00-\ud7a3\ud7b0-\ud7c6\ud7cb-\ud7fb\uf900-\ufa6d\ufa70-\ufad9\ufb00-\ufb06\ufb13-\ufb17\ufb1d\ufb1f-\ufb28\ufb2a-\ufb36\ufb38-\ufb3c\ufb3e\ufb40\ufb41\ufb43\ufb44\ufb46-\ufbb1\ufbd3-\ufd3d\ufd50-\ufd8f\ufd92-\ufdc7\ufdf0-\ufdfb\ufe70-\ufe74\ufe76-\ufefc\uff21-\uff3a\uff41-\uff5a\uff66-\uffbe\uffc2-\uffc7\uffca-\uffcf\uffd2-\uffd7\uffda-\uffdc'
let nonASCIIidentifierChars =
  '\u200c\u200d\xb7\u0300-\u036f\u0387\u0483-\u0487\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u0669\u0670\u06d6-\u06dc\u06df-\u06e4\u06e7\u06e8\u06ea-\u06ed\u06f0-\u06f9\u0711\u0730-\u074a\u07a6-\u07b0\u07c0-\u07c9\u07eb-\u07f3\u07fd\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0859-\u085b\u0898-\u089f\u08ca-\u08e1\u08e3-\u0903\u093a-\u093c\u093e-\u094f\u0951-\u0957\u0962\u0963\u0966-\u096f\u0981-\u0983\u09bc\u09be-\u09c4\u09c7\u09c8\u09cb-\u09cd\u09d7\u09e2\u09e3\u09e6-\u09ef\u09fe\u0a01-\u0a03\u0a3c\u0a3e-\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a66-\u0a71\u0a75\u0a81-\u0a83\u0abc\u0abe-\u0ac5\u0ac7-\u0ac9\u0acb-\u0acd\u0ae2\u0ae3\u0ae6-\u0aef\u0afa-\u0aff\u0b01-\u0b03\u0b3c\u0b3e-\u0b44\u0b47\u0b48\u0b4b-\u0b4d\u0b55-\u0b57\u0b62\u0b63\u0b66-\u0b6f\u0b82\u0bbe-\u0bc2\u0bc6-\u0bc8\u0bca-\u0bcd\u0bd7\u0be6-\u0bef\u0c00-\u0c04\u0c3c\u0c3e-\u0c44\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0c66-\u0c6f\u0c81-\u0c83\u0cbc\u0cbe-\u0cc4\u0cc6-\u0cc8\u0cca-\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0ce6-\u0cef\u0cf3\u0d00-\u0d03\u0d3b\u0d3c\u0d3e-\u0d44\u0d46-\u0d48\u0d4a-\u0d4d\u0d57\u0d62\u0d63\u0d66-\u0d6f\u0d81-\u0d83\u0dca\u0dcf-\u0dd4\u0dd6\u0dd8-\u0ddf\u0de6-\u0def\u0df2\u0df3\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0e50-\u0e59\u0eb1\u0eb4-\u0ebc\u0ec8-\u0ece\u0ed0-\u0ed9\u0f18\u0f19\u0f20-\u0f29\u0f35\u0f37\u0f39\u0f3e\u0f3f\u0f71-\u0f84\u0f86\u0f87\u0f8d-\u0f97\u0f99-\u0fbc\u0fc6\u102b-\u103e\u1040-\u1049\u1056-\u1059\u105e-\u1060\u1062-\u1064\u1067-\u106d\u1071-\u1074\u1082-\u108d\u108f-\u109d\u135d-\u135f\u1369-\u1371\u1712-\u1715\u1732-\u1734\u1752\u1753\u1772\u1773\u17b4-\u17d3\u17dd\u17e0-\u17e9\u180b-\u180d\u180f-\u1819\u18a9\u1920-\u192b\u1930-\u193b\u1946-\u194f\u19d0-\u19da\u1a17-\u1a1b\u1a55-\u1a5e\u1a60-\u1a7c\u1a7f-\u1a89\u1a90-\u1a99\u1ab0-\u1abd\u1abf-\u1ace\u1b00-\u1b04\u1b34-\u1b44\u1b50-\u1b59\u1b6b-\u1b73\u1b80-\u1b82\u1ba1-\u1bad\u1bb0-\u1bb9\u1be6-\u1bf3\u1c24-\u1c37\u1c40-\u1c49\u1c50-\u1c59\u1cd0-\u1cd2\u1cd4-\u1ce8\u1ced\u1cf4\u1cf7-\u1cf9\u1dc0-\u1dff\u200c\u200d\u203f\u2040\u2054\u20d0-\u20dc\u20e1\u20e5-\u20f0\u2cef-\u2cf1\u2d7f\u2de0-\u2dff\u302a-\u302f\u3099\u309a\u30fb\ua620-\ua629\ua66f\ua674-\ua67d\ua69e\ua69f\ua6f0\ua6f1\ua802\ua806\ua80b\ua823-\ua827\ua82c\ua880\ua881\ua8b4-\ua8c5\ua8d0-\ua8d9\ua8e0-\ua8f1\ua8ff-\ua909\ua926-\ua92d\ua947-\ua953\ua980-\ua983\ua9b3-\ua9c0\ua9d0-\ua9d9\ua9e5\ua9f0-\ua9f9\uaa29-\uaa36\uaa43\uaa4c\uaa4d\uaa50-\uaa59\uaa7b-\uaa7d\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uaaeb-\uaaef\uaaf5\uaaf6\uabe3-\uabea\uabec\uabed\uabf0-\uabf9\ufb1e\ufe00-\ufe0f\ufe20-\ufe2f\ufe33\ufe34\ufe4d-\ufe4f\uff10-\uff19\uff3f\uff65'
const nonASCIIidentifierStart = new RegExp(
  '[' + nonASCIIidentifierStartChars + ']'
)
const nonASCIIidentifier = new RegExp(
  '[' + nonASCIIidentifierStartChars + nonASCIIidentifierChars + ']'
)
nonASCIIidentifierStartChars = nonASCIIidentifierChars = null
const astralIdentifierStartCodes = [
  0, 11, 2, 25, 2, 18, 2, 1, 2, 14, 3, 13, 35, 122, 70, 52, 268, 28, 4, 48, 48,
  31, 14, 29, 6, 37, 11, 29, 3, 35, 5, 7, 2, 4, 43, 157, 19, 35, 5, 35, 5, 39,
  9, 51, 13, 10, 2, 14, 2, 6, 2, 1, 2, 10, 2, 14, 2, 6, 2, 1, 68, 310, 10, 21,
  11, 7, 25, 5, 2, 41, 2, 8, 70, 5, 3, 0, 2, 43, 2, 1, 4, 0, 3, 22, 11, 22, 10,
  30, 66, 18, 2, 1, 11, 21, 11, 25, 71, 55, 7, 1, 65, 0, 16, 3, 2, 2, 2, 28, 43,
  28, 4, 28, 36, 7, 2, 27, 28, 53, 11, 21, 11, 18, 14, 17, 111, 72, 56, 50, 14,
  50, 14, 35, 349, 41, 7, 1, 79, 28, 11, 0, 9, 21, 43, 17, 47, 20, 28, 22, 13,
  52, 58, 1, 3, 0, 14, 44, 33, 24, 27, 35, 30, 0, 3, 0, 9, 34, 4, 0, 13, 47, 15,
  3, 22, 0, 2, 0, 36, 17, 2, 24, 20, 1, 64, 6, 2, 0, 2, 3, 2, 14, 2, 9, 8, 46,
  39, 7, 3, 1, 3, 21, 2, 6, 2, 1, 2, 4, 4, 0, 19, 0, 13, 4, 159, 52, 19, 3, 21,
  2, 31, 47, 21, 1, 2, 0, 185, 46, 42, 3, 37, 47, 21, 0, 60, 42, 14, 0, 72, 26,
  38, 6, 186, 43, 117, 63, 32, 7, 3, 0, 3, 7, 2, 1, 2, 23, 16, 0, 2, 0, 95, 7,
  3, 38, 17, 0, 2, 0, 29, 0, 11, 39, 8, 0, 22, 0, 12, 45, 20, 0, 19, 72, 264, 8,
  2, 36, 18, 0, 50, 29, 113, 6, 2, 1, 2, 37, 22, 0, 26, 5, 2, 1, 2, 31, 15, 0,
  328, 18, 16, 0, 2, 12, 2, 33, 125, 0, 80, 921, 103, 110, 18, 195, 2637, 96,
  16, 1071, 18, 5, 4026, 582, 8634, 568, 8, 30, 18, 78, 18, 29, 19, 47, 17, 3,
  32, 20, 6, 18, 689, 63, 129, 74, 6, 0, 67, 12, 65, 1, 2, 0, 29, 6135, 9, 1237,
  43, 8, 8936, 3, 2, 6, 2, 1, 2, 290, 16, 0, 30, 2, 3, 0, 15, 3, 9, 395, 2309,
  106, 6, 12, 4, 8, 8, 9, 5991, 84, 2, 70, 2, 1, 3, 0, 3, 1, 3, 3, 2, 11, 2, 0,
  2, 6, 2, 64, 2, 3, 3, 7, 2, 6, 2, 27, 2, 3, 2, 4, 2, 0, 4, 6, 2, 339, 3, 24,
  2, 24, 2, 30, 2, 24, 2, 30, 2, 24, 2, 30, 2, 24, 2, 30, 2, 24, 2, 7, 1845, 30,
  7, 5, 262, 61, 147, 44, 11, 6, 17, 0, 322, 29, 19, 43, 485, 27, 757, 6, 2, 3,
  2, 1, 2, 14, 2, 196, 60, 67, 8, 0, 1205, 3, 2, 26, 2, 1, 2, 0, 3, 0, 2, 9, 2,
  3, 2, 0, 2, 0, 7, 0, 5, 0, 2, 0, 2, 0, 2, 2, 2, 1, 2, 0, 3, 0, 2, 0, 2, 0, 2,
  0, 2, 0, 2, 1, 2, 0, 3, 3, 2, 6, 2, 3, 2, 3, 2, 0, 2, 9, 2, 16, 6, 2, 2, 4, 2,
  16, 4421, 42719, 33, 4153, 7, 221, 3, 5761, 15, 7472, 16, 621, 2467, 541,
  1507, 4938, 6, 4191
]
const astralIdentifierCodes = [
  509, 0, 227, 0, 150, 4, 294, 9, 1368, 2, 2, 1, 6, 3, 41, 2, 5, 0, 166, 1, 574,
  3, 9, 9, 370, 1, 81, 2, 71, 10, 50, 3, 123, 2, 54, 14, 32, 10, 3, 1, 11, 3,
  46, 10, 8, 0, 46, 9, 7, 2, 37, 13, 2, 9, 6, 1, 45, 0, 13, 2, 49, 13, 9, 3, 2,
  11, 83, 11, 7, 0, 3, 0, 158, 11, 6, 9, 7, 3, 56, 1, 2, 6, 3, 1, 3, 2, 10, 0,
  11, 1, 3, 6, 4, 4, 193, 17, 10, 9, 5, 0, 82, 19, 13, 9, 214, 6, 3, 8, 28, 1,
  83, 16, 16, 9, 82, 12, 9, 9, 84, 14, 5, 9, 243, 14, 166, 9, 71, 5, 2, 1, 3, 3,
  2, 0, 2, 1, 13, 9, 120, 6, 3, 6, 4, 0, 29, 9, 41, 6, 2, 3, 9, 0, 10, 10, 47,
  15, 406, 7, 2, 7, 17, 9, 57, 21, 2, 13, 123, 5, 4, 0, 2, 1, 2, 6, 2, 0, 9, 9,
  49, 4, 2, 1, 2, 4, 9, 9, 330, 3, 10, 1, 2, 0, 49, 6, 4, 4, 14, 9, 5351, 0, 7,
  14, 13835, 9, 87, 9, 39, 4, 60, 6, 26, 9, 1014, 0, 2, 54, 8, 3, 82, 0, 12, 1,
  19628, 1, 4706, 45, 3, 22, 543, 4, 4, 5, 9, 7, 3, 6, 31, 3, 149, 2, 1418, 49,
  513, 54, 5, 49, 9, 0, 15, 0, 23, 4, 2, 14, 1361, 6, 2, 16, 3, 6, 2, 1, 2, 4,
  101, 0, 161, 6, 10, 9, 357, 0, 62, 13, 499, 13, 983, 6, 110, 6, 6, 9, 4759, 9,
  787719, 239
]
function isInAstralSet(code, set) {
  let pos = 0x10000
  for (let i = 0, length = set.length; i < length; i += 2) {
    pos += set[i]
    if (pos > code) {
      return false
    }
    pos += set[i + 1]
    if (pos >= code) {
      return true
    }
  }
  return false
}
function isIdentifierStart(code) {
  if (code < 65) {
    return code === 36
  }
  if (code <= 90) {
    return true
  }
  if (code < 97) {
    return code === 95
  }
  if (code <= 122) {
    return true
  }
  if (code <= 0xffff) {
    return (
      code >= 0xaa && nonASCIIidentifierStart.test(String.fromCharCode(code))
    )
  }
  return isInAstralSet(code, astralIdentifierStartCodes)
}
function isIdentifierChar(code) {
  if (code < 48) {
    return code === 36
  }
  if (code < 58) {
    return true
  }
  if (code < 65) {
    return false
  }
  if (code <= 90) {
    return true
  }
  if (code < 97) {
    return code === 95
  }
  if (code <= 122) {
    return true
  }
  if (code <= 0xffff) {
    return code >= 0xaa && nonASCIIidentifier.test(String.fromCharCode(code))
  }
  return (
    isInAstralSet(code, astralIdentifierStartCodes) ||
    isInAstralSet(code, astralIdentifierCodes)
  )
}
function isIdentifierName(name) {
  let isFirst = true
  for (let i = 0; i < name.length; i++) {
    let cp = name.charCodeAt(i)
    if ((cp & 0xfc00) === 0xd800 && i + 1 < name.length) {
      const trail = name.charCodeAt(++i)
      if ((trail & 0xfc00) === 0xdc00) {
        cp = 0x10000 + ((cp & 0x3ff) << 10) + (trail & 0x3ff)
      }
    }
    if (isFirst) {
      isFirst = false
      if (!isIdentifierStart(cp)) {
        return false
      }
    } else if (!isIdentifierChar(cp)) {
      return false
    }
  }
  return !isFirst
}
const keyword = {}
Object.defineProperty(keyword, '__esModule', {
  value: true
})
keyword.isKeyword = isKeyword
keyword.isReservedWord = isReservedWord
keyword.isStrictBindOnlyReservedWord = isStrictBindOnlyReservedWord
keyword.isStrictBindReservedWord = isStrictBindReservedWord
keyword.isStrictReservedWord = isStrictReservedWord
const reservedWords = {
  keyword: [
    'break',
    'case',
    'catch',
    'continue',
    'debugger',
    'default',
    'do',
    'else',
    'finally',
    'for',
    'function',
    'if',
    'return',
    'switch',
    'throw',
    'try',
    'var',
    'const',
    'while',
    'with',
    'new',
    'this',
    'super',
    'class',
    'extends',
    'export',
    'import',
    'null',
    'true',
    'false',
    'in',
    'instanceof',
    'typeof',
    'void',
    'delete'
  ],
  strict: [
    'implements',
    'interface',
    'let',
    'package',
    'private',
    'protected',
    'public',
    'static',
    'yield'
  ],
  strictBind: ['eval', 'arguments']
}
const keywords = new Set(reservedWords.keyword)
const reservedWordsStrictSet = new Set(reservedWords.strict)
const reservedWordsStrictBindSet = new Set(reservedWords.strictBind)
function isReservedWord(word, inModule) {
  return (inModule && word === 'await') || word === 'enum'
}
function isStrictReservedWord(word, inModule) {
  return isReservedWord(word, inModule) || reservedWordsStrictSet.has(word)
}
function isStrictBindOnlyReservedWord(word) {
  return reservedWordsStrictBindSet.has(word)
}
function isStrictBindReservedWord(word, inModule) {
  return (
    isStrictReservedWord(word, inModule) || isStrictBindOnlyReservedWord(word)
  )
}
function isKeyword(word) {
  return keywords.has(word)
}
;(function (exports) {
  Object.defineProperty(exports, '__esModule', {
    value: true
  })
  Object.defineProperty(exports, 'isIdentifierChar', {
    enumerable: true,
    get: function () {
      return _identifier.isIdentifierChar
    }
  })
  Object.defineProperty(exports, 'isIdentifierName', {
    enumerable: true,
    get: function () {
      return _identifier.isIdentifierName
    }
  })
  Object.defineProperty(exports, 'isIdentifierStart', {
    enumerable: true,
    get: function () {
      return _identifier.isIdentifierStart
    }
  })
  Object.defineProperty(exports, 'isKeyword', {
    enumerable: true,
    get: function () {
      return _keyword.isKeyword
    }
  })
  Object.defineProperty(exports, 'isReservedWord', {
    enumerable: true,
    get: function () {
      return _keyword.isReservedWord
    }
  })
  Object.defineProperty(exports, 'isStrictBindOnlyReservedWord', {
    enumerable: true,
    get: function () {
      return _keyword.isStrictBindOnlyReservedWord
    }
  })
  Object.defineProperty(exports, 'isStrictBindReservedWord', {
    enumerable: true,
    get: function () {
      return _keyword.isStrictBindReservedWord
    }
  })
  Object.defineProperty(exports, 'isStrictReservedWord', {
    enumerable: true,
    get: function () {
      return _keyword.isStrictReservedWord
    }
  })
  const _identifier = identifier
  const _keyword = keyword
})(lib$m)
const chalk$1 = {
  exports: {}
}
const matchOperatorsRe$1 = /[|\\{}()[\]^$+*?.]/g
const escapeStringRegexp$1 = function (str) {
  if (typeof str !== 'string') {
    throw new TypeError('Expected a string')
  }
  return str.replace(matchOperatorsRe$1, '\\$&')
}
const ansiStyles$1 = {
  exports: {}
}
const conversions$2 = {
  exports: {}
}
const colorName$1 = {
  aliceblue: [240, 248, 255],
  antiquewhite: [250, 235, 215],
  aqua: [0, 255, 255],
  aquamarine: [127, 255, 212],
  azure: [240, 255, 255],
  beige: [245, 245, 220],
  bisque: [255, 228, 196],
  black: [0, 0, 0],
  blanchedalmond: [255, 235, 205],
  blue: [0, 0, 255],
  blueviolet: [138, 43, 226],
  brown: [165, 42, 42],
  burlywood: [222, 184, 135],
  cadetblue: [95, 158, 160],
  chartreuse: [127, 255, 0],
  chocolate: [210, 105, 30],
  coral: [255, 127, 80],
  cornflowerblue: [100, 149, 237],
  cornsilk: [255, 248, 220],
  crimson: [220, 20, 60],
  cyan: [0, 255, 255],
  darkblue: [0, 0, 139],
  darkcyan: [0, 139, 139],
  darkgoldenrod: [184, 134, 11],
  darkgray: [169, 169, 169],
  darkgreen: [0, 100, 0],
  darkgrey: [169, 169, 169],
  darkkhaki: [189, 183, 107],
  darkmagenta: [139, 0, 139],
  darkolivegreen: [85, 107, 47],
  darkorange: [255, 140, 0],
  darkorchid: [153, 50, 204],
  darkred: [139, 0, 0],
  darksalmon: [233, 150, 122],
  darkseagreen: [143, 188, 143],
  darkslateblue: [72, 61, 139],
  darkslategray: [47, 79, 79],
  darkslategrey: [47, 79, 79],
  darkturquoise: [0, 206, 209],
  darkviolet: [148, 0, 211],
  deeppink: [255, 20, 147],
  deepskyblue: [0, 191, 255],
  dimgray: [105, 105, 105],
  dimgrey: [105, 105, 105],
  dodgerblue: [30, 144, 255],
  firebrick: [178, 34, 34],
  floralwhite: [255, 250, 240],
  forestgreen: [34, 139, 34],
  fuchsia: [255, 0, 255],
  gainsboro: [220, 220, 220],
  ghostwhite: [248, 248, 255],
  gold: [255, 215, 0],
  goldenrod: [218, 165, 32],
  gray: [128, 128, 128],
  green: [0, 128, 0],
  greenyellow: [173, 255, 47],
  grey: [128, 128, 128],
  honeydew: [240, 255, 240],
  hotpink: [255, 105, 180],
  indianred: [205, 92, 92],
  indigo: [75, 0, 130],
  ivory: [255, 255, 240],
  khaki: [240, 230, 140],
  lavender: [230, 230, 250],
  lavenderblush: [255, 240, 245],
  lawngreen: [124, 252, 0],
  lemonchiffon: [255, 250, 205],
  lightblue: [173, 216, 230],
  lightcoral: [240, 128, 128],
  lightcyan: [224, 255, 255],
  lightgoldenrodyellow: [250, 250, 210],
  lightgray: [211, 211, 211],
  lightgreen: [144, 238, 144],
  lightgrey: [211, 211, 211],
  lightpink: [255, 182, 193],
  lightsalmon: [255, 160, 122],
  lightseagreen: [32, 178, 170],
  lightskyblue: [135, 206, 250],
  lightslategray: [119, 136, 153],
  lightslategrey: [119, 136, 153],
  lightsteelblue: [176, 196, 222],
  lightyellow: [255, 255, 224],
  lime: [0, 255, 0],
  limegreen: [50, 205, 50],
  linen: [250, 240, 230],
  magenta: [255, 0, 255],
  maroon: [128, 0, 0],
  mediumaquamarine: [102, 205, 170],
  mediumblue: [0, 0, 205],
  mediumorchid: [186, 85, 211],
  mediumpurple: [147, 112, 219],
  mediumseagreen: [60, 179, 113],
  mediumslateblue: [123, 104, 238],
  mediumspringgreen: [0, 250, 154],
  mediumturquoise: [72, 209, 204],
  mediumvioletred: [199, 21, 133],
  midnightblue: [25, 25, 112],
  mintcream: [245, 255, 250],
  mistyrose: [255, 228, 225],
  moccasin: [255, 228, 181],
  navajowhite: [255, 222, 173],
  navy: [0, 0, 128],
  oldlace: [253, 245, 230],
  olive: [128, 128, 0],
  olivedrab: [107, 142, 35],
  orange: [255, 165, 0],
  orangered: [255, 69, 0],
  orchid: [218, 112, 214],
  palegoldenrod: [238, 232, 170],
  palegreen: [152, 251, 152],
  paleturquoise: [175, 238, 238],
  palevioletred: [219, 112, 147],
  papayawhip: [255, 239, 213],
  peachpuff: [255, 218, 185],
  peru: [205, 133, 63],
  pink: [255, 192, 203],
  plum: [221, 160, 221],
  powderblue: [176, 224, 230],
  purple: [128, 0, 128],
  rebeccapurple: [102, 51, 153],
  red: [255, 0, 0],
  rosybrown: [188, 143, 143],
  royalblue: [65, 105, 225],
  saddlebrown: [139, 69, 19],
  salmon: [250, 128, 114],
  sandybrown: [244, 164, 96],
  seagreen: [46, 139, 87],
  seashell: [255, 245, 238],
  sienna: [160, 82, 45],
  silver: [192, 192, 192],
  skyblue: [135, 206, 235],
  slateblue: [106, 90, 205],
  slategray: [112, 128, 144],
  slategrey: [112, 128, 144],
  snow: [255, 250, 250],
  springgreen: [0, 255, 127],
  steelblue: [70, 130, 180],
  tan: [210, 180, 140],
  teal: [0, 128, 128],
  thistle: [216, 191, 216],
  tomato: [255, 99, 71],
  turquoise: [64, 224, 208],
  violet: [238, 130, 238],
  wheat: [245, 222, 179],
  white: [255, 255, 255],
  whitesmoke: [245, 245, 245],
  yellow: [255, 255, 0],
  yellowgreen: [154, 205, 50]
}
const cssKeywords = colorName$1
const reverseKeywords = {}
for (const key in cssKeywords) {
  if (cssKeywords.hasOwnProperty(key)) {
    reverseKeywords[cssKeywords[key]] = key
  }
}
const convert$1 = (conversions$2.exports = {
  rgb: {
    channels: 3,
    labels: 'rgb'
  },
  hsl: {
    channels: 3,
    labels: 'hsl'
  },
  hsv: {
    channels: 3,
    labels: 'hsv'
  },
  hwb: {
    channels: 3,
    labels: 'hwb'
  },
  cmyk: {
    channels: 4,
    labels: 'cmyk'
  },
  xyz: {
    channels: 3,
    labels: 'xyz'
  },
  lab: {
    channels: 3,
    labels: 'lab'
  },
  lch: {
    channels: 3,
    labels: 'lch'
  },
  hex: {
    channels: 1,
    labels: ['hex']
  },
  keyword: {
    channels: 1,
    labels: ['keyword']
  },
  ansi16: {
    channels: 1,
    labels: ['ansi16']
  },
  ansi256: {
    channels: 1,
    labels: ['ansi256']
  },
  hcg: {
    channels: 3,
    labels: ['h', 'c', 'g']
  },
  apple: {
    channels: 3,
    labels: ['r16', 'g16', 'b16']
  },
  gray: {
    channels: 1,
    labels: ['gray']
  }
})
for (const model in convert$1) {
  if (convert$1.hasOwnProperty(model)) {
    if (!('channels' in convert$1[model])) {
      throw new Error('missing channels property: ' + model)
    }
    if (!('labels' in convert$1[model])) {
      throw new Error('missing channel labels property: ' + model)
    }
    if (convert$1[model].labels.length !== convert$1[model].channels) {
      throw new Error('channel and label counts mismatch: ' + model)
    }
    const channels = convert$1[model].channels
    const labels = convert$1[model].labels
    delete convert$1[model].channels
    delete convert$1[model].labels
    Object.defineProperty(convert$1[model], 'channels', {
      value: channels
    })
    Object.defineProperty(convert$1[model], 'labels', {
      value: labels
    })
  }
}
convert$1.rgb.hsl = function (rgb) {
  const r = rgb[0] / 255
  const g = rgb[1] / 255
  const b = rgb[2] / 255
  const min = Math.min(r, g, b)
  const max = Math.max(r, g, b)
  const delta = max - min
  let h
  let s
  let l
  if (max === min) {
    h = 0
  } else if (r === max) {
    h = (g - b) / delta
  } else if (g === max) {
    h = 2 + (b - r) / delta
  } else if (b === max) {
    h = 4 + (r - g) / delta
  }
  h = Math.min(h * 60, 360)
  if (h < 0) {
    h += 360
  }
  l = (min + max) / 2
  if (max === min) {
    s = 0
  } else if (l <= 0.5) {
    s = delta / (max + min)
  } else {
    s = delta / (2 - max - min)
  }
  return [h, s * 100, l * 100]
}
convert$1.rgb.hsv = function (rgb) {
  let rdif
  let gdif
  let bdif
  let h
  let s
  const r = rgb[0] / 255
  const g = rgb[1] / 255
  const b = rgb[2] / 255
  const v = Math.max(r, g, b)
  const diff = v - Math.min(r, g, b)
  const diffc = function (c) {
    return (v - c) / 6 / diff + 1 / 2
  }
  if (diff === 0) {
    h = s = 0
  } else {
    s = diff / v
    rdif = diffc(r)
    gdif = diffc(g)
    bdif = diffc(b)
    if (r === v) {
      h = bdif - gdif
    } else if (g === v) {
      h = 1 / 3 + rdif - bdif
    } else if (b === v) {
      h = 2 / 3 + gdif - rdif
    }
    if (h < 0) {
      h += 1
    } else if (h > 1) {
      h -= 1
    }
  }
  return [h * 360, s * 100, v * 100]
}
convert$1.rgb.hwb = function (rgb) {
  const r = rgb[0]
  const g = rgb[1]
  let b = rgb[2]
  const h = convert$1.rgb.hsl(rgb)[0]
  const w = (1 / 255) * Math.min(r, Math.min(g, b))
  b = 1 - (1 / 255) * Math.max(r, Math.max(g, b))
  return [h, w * 100, b * 100]
}
convert$1.rgb.cmyk = function (rgb) {
  const r = rgb[0] / 255
  const g = rgb[1] / 255
  const b = rgb[2] / 255
  let c
  let m
  let y
  let k
  k = Math.min(1 - r, 1 - g, 1 - b)
  c = (1 - r - k) / (1 - k) || 0
  m = (1 - g - k) / (1 - k) || 0
  y = (1 - b - k) / (1 - k) || 0
  return [c * 100, m * 100, y * 100, k * 100]
}
function comparativeDistance(x, y) {
  return (
    Math.pow(x[0] - y[0], 2) +
    Math.pow(x[1] - y[1], 2) +
    Math.pow(x[2] - y[2], 2)
  )
}
convert$1.rgb.keyword = function (rgb) {
  const reversed = reverseKeywords[rgb]
  if (reversed) {
    return reversed
  }
  let currentClosestDistance = Infinity
  let currentClosestKeyword
  for (const keyword in cssKeywords) {
    if (cssKeywords.hasOwnProperty(keyword)) {
      const value = cssKeywords[keyword]
      const distance = comparativeDistance(rgb, value)
      if (distance < currentClosestDistance) {
        currentClosestDistance = distance
        currentClosestKeyword = keyword
      }
    }
  }
  return currentClosestKeyword
}
convert$1.keyword.rgb = function (keyword) {
  return cssKeywords[keyword]
}
convert$1.rgb.xyz = function (rgb) {
  let r = rgb[0] / 255
  let g = rgb[1] / 255
  let b = rgb[2] / 255
  r = r > 0.04045 ? Math.pow((r + 0.055) / 1.055, 2.4) : r / 12.92
  g = g > 0.04045 ? Math.pow((g + 0.055) / 1.055, 2.4) : g / 12.92
  b = b > 0.04045 ? Math.pow((b + 0.055) / 1.055, 2.4) : b / 12.92
  const x = r * 0.4124 + g * 0.3576 + b * 0.1805
  const y = r * 0.2126 + g * 0.7152 + b * 0.0722
  const z = r * 0.0193 + g * 0.1192 + b * 0.9505
  return [x * 100, y * 100, z * 100]
}
convert$1.rgb.lab = function (rgb) {
  const xyz = convert$1.rgb.xyz(rgb)
  let x = xyz[0]
  let y = xyz[1]
  let z = xyz[2]
  let l
  let a
  let b
  x /= 95.047
  y /= 100
  z /= 108.883
  x = x > 0.008856 ? Math.pow(x, 1 / 3) : 7.787 * x + 16 / 116
  y = y > 0.008856 ? Math.pow(y, 1 / 3) : 7.787 * y + 16 / 116
  z = z > 0.008856 ? Math.pow(z, 1 / 3) : 7.787 * z + 16 / 116
  l = 116 * y - 16
  a = 500 * (x - y)
  b = 200 * (y - z)
  return [l, a, b]
}
convert$1.hsl.rgb = function (hsl) {
  const h = hsl[0] / 360
  const s = hsl[1] / 100
  const l = hsl[2] / 100
  let t1
  let t2
  let t3
  let rgb
  let val
  if (s === 0) {
    val = l * 255
    return [val, val, val]
  }
  if (l < 0.5) {
    t2 = l * (1 + s)
  } else {
    t2 = l + s - l * s
  }
  t1 = 2 * l - t2
  rgb = [0, 0, 0]
  for (let i = 0; i < 3; i++) {
    t3 = h + (1 / 3) * -(i - 1)
    if (t3 < 0) {
      t3++
    }
    if (t3 > 1) {
      t3--
    }
    if (6 * t3 < 1) {
      val = t1 + (t2 - t1) * 6 * t3
    } else if (2 * t3 < 1) {
      val = t2
    } else if (3 * t3 < 2) {
      val = t1 + (t2 - t1) * (2 / 3 - t3) * 6
    } else {
      val = t1
    }
    rgb[i] = val * 255
  }
  return rgb
}
convert$1.hsl.hsv = function (hsl) {
  const h = hsl[0]
  let s = hsl[1] / 100
  let l = hsl[2] / 100
  let smin = s
  const lmin = Math.max(l, 0.01)
  let sv
  let v
  l *= 2
  s *= l <= 1 ? l : 2 - l
  smin *= lmin <= 1 ? lmin : 2 - lmin
  v = (l + s) / 2
  sv = l === 0 ? (2 * smin) / (lmin + smin) : (2 * s) / (l + s)
  return [h, sv * 100, v * 100]
}
convert$1.hsv.rgb = function (hsv) {
  const h = hsv[0] / 60
  const s = hsv[1] / 100
  let v = hsv[2] / 100
  const hi = Math.floor(h) % 6
  const f = h - Math.floor(h)
  const p = 255 * v * (1 - s)
  const q = 255 * v * (1 - s * f)
  const t = 255 * v * (1 - s * (1 - f))
  v *= 255
  switch (hi) {
    case 0:
      return [v, t, p]
    case 1:
      return [q, v, p]
    case 2:
      return [p, v, t]
    case 3:
      return [p, q, v]
    case 4:
      return [t, p, v]
    case 5:
      return [v, p, q]
  }
}
convert$1.hsv.hsl = function (hsv) {
  const h = hsv[0]
  const s = hsv[1] / 100
  const v = hsv[2] / 100
  const vmin = Math.max(v, 0.01)
  let lmin
  let sl
  let l
  l = (2 - s) * v
  lmin = (2 - s) * vmin
  sl = s * vmin
  sl /= lmin <= 1 ? lmin : 2 - lmin
  sl = sl || 0
  l /= 2
  return [h, sl * 100, l * 100]
}
convert$1.hwb.rgb = function (hwb) {
  const h = hwb[0] / 360
  let wh = hwb[1] / 100
  let bl = hwb[2] / 100
  const ratio = wh + bl
  let i
  let v
  let f
  let n
  if (ratio > 1) {
    wh /= ratio
    bl /= ratio
  }
  i = Math.floor(6 * h)
  v = 1 - bl
  f = 6 * h - i
  if ((i & 0x01) !== 0) {
    f = 1 - f
  }
  n = wh + f * (v - wh)
  let r
  let g
  let b
  switch (i) {
    default:
    case 6:
    case 0:
      r = v
      g = n
      b = wh
      break
    case 1:
      r = n
      g = v
      b = wh
      break
    case 2:
      r = wh
      g = v
      b = n
      break
    case 3:
      r = wh
      g = n
      b = v
      break
    case 4:
      r = n
      g = wh
      b = v
      break
    case 5:
      r = v
      g = wh
      b = n
      break
  }
  return [r * 255, g * 255, b * 255]
}
convert$1.cmyk.rgb = function (cmyk) {
  const c = cmyk[0] / 100
  const m = cmyk[1] / 100
  const y = cmyk[2] / 100
  const k = cmyk[3] / 100
  let r
  let g
  let b
  r = 1 - Math.min(1, c * (1 - k) + k)
  g = 1 - Math.min(1, m * (1 - k) + k)
  b = 1 - Math.min(1, y * (1 - k) + k)
  return [r * 255, g * 255, b * 255]
}
convert$1.xyz.rgb = function (xyz) {
  const x = xyz[0] / 100
  const y = xyz[1] / 100
  const z = xyz[2] / 100
  let r
  let g
  let b
  r = x * 3.2406 + y * -1.5372 + z * -0.4986
  g = x * -0.9689 + y * 1.8758 + z * 0.0415
  b = x * 0.0557 + y * -0.204 + z * 1.057
  r = r > 0.0031308 ? 1.055 * Math.pow(r, 1.0 / 2.4) - 0.055 : r * 12.92
  g = g > 0.0031308 ? 1.055 * Math.pow(g, 1.0 / 2.4) - 0.055 : g * 12.92
  b = b > 0.0031308 ? 1.055 * Math.pow(b, 1.0 / 2.4) - 0.055 : b * 12.92
  r = Math.min(Math.max(0, r), 1)
  g = Math.min(Math.max(0, g), 1)
  b = Math.min(Math.max(0, b), 1)
  return [r * 255, g * 255, b * 255]
}
convert$1.xyz.lab = function (xyz) {
  let x = xyz[0]
  let y = xyz[1]
  let z = xyz[2]
  let l
  let a
  let b
  x /= 95.047
  y /= 100
  z /= 108.883
  x = x > 0.008856 ? Math.pow(x, 1 / 3) : 7.787 * x + 16 / 116
  y = y > 0.008856 ? Math.pow(y, 1 / 3) : 7.787 * y + 16 / 116
  z = z > 0.008856 ? Math.pow(z, 1 / 3) : 7.787 * z + 16 / 116
  l = 116 * y - 16
  a = 500 * (x - y)
  b = 200 * (y - z)
  return [l, a, b]
}
convert$1.lab.xyz = function (lab) {
  const l = lab[0]
  const a = lab[1]
  const b = lab[2]
  let x
  let y
  let z
  y = (l + 16) / 116
  x = a / 500 + y
  z = y - b / 200
  const y2 = Math.pow(y, 3)
  const x2 = Math.pow(x, 3)
  const z2 = Math.pow(z, 3)
  y = y2 > 0.008856 ? y2 : (y - 16 / 116) / 7.787
  x = x2 > 0.008856 ? x2 : (x - 16 / 116) / 7.787
  z = z2 > 0.008856 ? z2 : (z - 16 / 116) / 7.787
  x *= 95.047
  y *= 100
  z *= 108.883
  return [x, y, z]
}
convert$1.lab.lch = function (lab) {
  const l = lab[0]
  const a = lab[1]
  const b = lab[2]
  let hr
  let h
  let c
  hr = Math.atan2(b, a)
  h = (hr * 360) / 2 / Math.PI
  if (h < 0) {
    h += 360
  }
  c = Math.sqrt(a * a + b * b)
  return [l, c, h]
}
convert$1.lch.lab = function (lch) {
  const l = lch[0]
  const c = lch[1]
  const h = lch[2]
  let a
  let b
  let hr
  hr = (h / 360) * 2 * Math.PI
  a = c * Math.cos(hr)
  b = c * Math.sin(hr)
  return [l, a, b]
}
convert$1.rgb.ansi16 = function (args) {
  const r = args[0]
  const g = args[1]
  const b = args[2]
  let value = 1 in arguments ? arguments[1] : convert$1.rgb.hsv(args)[2]
  value = Math.round(value / 50)
  if (value === 0) {
    return 30
  }
  let ansi =
    30 +
    ((Math.round(b / 255) << 2) |
      (Math.round(g / 255) << 1) |
      Math.round(r / 255))
  if (value === 2) {
    ansi += 60
  }
  return ansi
}
convert$1.hsv.ansi16 = function (args) {
  return convert$1.rgb.ansi16(convert$1.hsv.rgb(args), args[2])
}
convert$1.rgb.ansi256 = function (args) {
  const r = args[0]
  const g = args[1]
  const b = args[2]
  if (r === g && g === b) {
    if (r < 8) {
      return 16
    }
    if (r > 248) {
      return 231
    }
    return Math.round(((r - 8) / 247) * 24) + 232
  }
  const ansi =
    16 +
    36 * Math.round((r / 255) * 5) +
    6 * Math.round((g / 255) * 5) +
    Math.round((b / 255) * 5)
  return ansi
}
convert$1.ansi16.rgb = function (args) {
  let color = args % 10
  if (color === 0 || color === 7) {
    if (args > 50) {
      color += 3.5
    }
    color = (color / 10.5) * 255
    return [color, color, color]
  }
  const mult = (~~(args > 50) + 1) * 0.5
  const r = (color & 1) * mult * 255
  const g = ((color >> 1) & 1) * mult * 255
  const b = ((color >> 2) & 1) * mult * 255
  return [r, g, b]
}
convert$1.ansi256.rgb = function (args) {
  if (args >= 232) {
    const c = (args - 232) * 10 + 8
    return [c, c, c]
  }
  args -= 16
  let rem
  const r = (Math.floor(args / 36) / 5) * 255
  const g = (Math.floor((rem = args % 36) / 6) / 5) * 255
  const b = ((rem % 6) / 5) * 255
  return [r, g, b]
}
convert$1.rgb.hex = function (args) {
  const integer =
    ((Math.round(args[0]) & 0xff) << 16) +
    ((Math.round(args[1]) & 0xff) << 8) +
    (Math.round(args[2]) & 0xff)
  const string = integer.toString(16).toUpperCase()
  return '000000'.substring(string.length) + string
}
convert$1.hex.rgb = function (args) {
  const match = args.toString(16).match(/[a-f0-9]{6}|[a-f0-9]{3}/i)
  if (!match) {
    return [0, 0, 0]
  }
  let colorString = match[0]
  if (match[0].length === 3) {
    colorString = colorString
      .split('')
      .map(function (char) {
        return char + char
      })
      .join('')
  }
  const integer = parseInt(colorString, 16)
  const r = (integer >> 16) & 0xff
  const g = (integer >> 8) & 0xff
  const b = integer & 0xff
  return [r, g, b]
}
convert$1.rgb.hcg = function (rgb) {
  const r = rgb[0] / 255
  const g = rgb[1] / 255
  const b = rgb[2] / 255
  const max = Math.max(Math.max(r, g), b)
  const min = Math.min(Math.min(r, g), b)
  const chroma = max - min
  let grayscale
  let hue
  if (chroma < 1) {
    grayscale = min / (1 - chroma)
  } else {
    grayscale = 0
  }
  if (chroma <= 0) {
    hue = 0
  } else if (max === r) {
    hue = ((g - b) / chroma) % 6
  } else if (max === g) {
    hue = 2 + (b - r) / chroma
  } else {
    hue = 4 + (r - g) / chroma + 4
  }
  hue /= 6
  hue %= 1
  return [hue * 360, chroma * 100, grayscale * 100]
}
convert$1.hsl.hcg = function (hsl) {
  const s = hsl[1] / 100
  const l = hsl[2] / 100
  let c = 1
  let f = 0
  if (l < 0.5) {
    c = 2.0 * s * l
  } else {
    c = 2.0 * s * (1.0 - l)
  }
  if (c < 1.0) {
    f = (l - 0.5 * c) / (1.0 - c)
  }
  return [hsl[0], c * 100, f * 100]
}
convert$1.hsv.hcg = function (hsv) {
  const s = hsv[1] / 100
  const v = hsv[2] / 100
  const c = s * v
  let f = 0
  if (c < 1.0) {
    f = (v - c) / (1 - c)
  }
  return [hsv[0], c * 100, f * 100]
}
convert$1.hcg.rgb = function (hcg) {
  const h = hcg[0] / 360
  const c = hcg[1] / 100
  const g = hcg[2] / 100
  if (c === 0.0) {
    return [g * 255, g * 255, g * 255]
  }
  const pure = [0, 0, 0]
  const hi = (h % 1) * 6
  const v = hi % 1
  const w = 1 - v
  let mg = 0
  switch (Math.floor(hi)) {
    case 0:
      pure[0] = 1
      pure[1] = v
      pure[2] = 0
      break
    case 1:
      pure[0] = w
      pure[1] = 1
      pure[2] = 0
      break
    case 2:
      pure[0] = 0
      pure[1] = 1
      pure[2] = v
      break
    case 3:
      pure[0] = 0
      pure[1] = w
      pure[2] = 1
      break
    case 4:
      pure[0] = v
      pure[1] = 0
      pure[2] = 1
      break
    default:
      pure[0] = 1
      pure[1] = 0
      pure[2] = w
  }
  mg = (1.0 - c) * g
  return [
    (c * pure[0] + mg) * 255,
    (c * pure[1] + mg) * 255,
    (c * pure[2] + mg) * 255
  ]
}
convert$1.hcg.hsv = function (hcg) {
  const c = hcg[1] / 100
  const g = hcg[2] / 100
  const v = c + g * (1.0 - c)
  let f = 0
  if (v > 0.0) {
    f = c / v
  }
  return [hcg[0], f * 100, v * 100]
}
convert$1.hcg.hsl = function (hcg) {
  const c = hcg[1] / 100
  const g = hcg[2] / 100
  const l = g * (1.0 - c) + 0.5 * c
  let s = 0
  if (l > 0.0 && l < 0.5) {
    s = c / (2 * l)
  } else if (l >= 0.5 && l < 1.0) {
    s = c / (2 * (1 - l))
  }
  return [hcg[0], s * 100, l * 100]
}
convert$1.hcg.hwb = function (hcg) {
  const c = hcg[1] / 100
  const g = hcg[2] / 100
  const v = c + g * (1.0 - c)
  return [hcg[0], (v - c) * 100, (1 - v) * 100]
}
convert$1.hwb.hcg = function (hwb) {
  const w = hwb[1] / 100
  const b = hwb[2] / 100
  const v = 1 - b
  const c = v - w
  let g = 0
  if (c < 1) {
    g = (v - c) / (1 - c)
  }
  return [hwb[0], c * 100, g * 100]
}
convert$1.apple.rgb = function (apple) {
  return [
    (apple[0] / 65535) * 255,
    (apple[1] / 65535) * 255,
    (apple[2] / 65535) * 255
  ]
}
convert$1.rgb.apple = function (rgb) {
  return [
    (rgb[0] / 255) * 65535,
    (rgb[1] / 255) * 65535,
    (rgb[2] / 255) * 65535
  ]
}
convert$1.gray.rgb = function (args) {
  return [(args[0] / 100) * 255, (args[0] / 100) * 255, (args[0] / 100) * 255]
}
convert$1.gray.hsl = convert$1.gray.hsv = function (args) {
  return [0, 0, args[0]]
}
convert$1.gray.hwb = function (gray) {
  return [0, 100, gray[0]]
}
convert$1.gray.cmyk = function (gray) {
  return [0, 0, 0, gray[0]]
}
convert$1.gray.lab = function (gray) {
  return [gray[0], 0, 0]
}
convert$1.gray.hex = function (gray) {
  const val = Math.round((gray[0] / 100) * 255) & 0xff
  const integer = (val << 16) + (val << 8) + val
  const string = integer.toString(16).toUpperCase()
  return '000000'.substring(string.length) + string
}
convert$1.rgb.gray = function (rgb) {
  const val = (rgb[0] + rgb[1] + rgb[2]) / 3
  return [(val / 255) * 100]
}
const conversionsExports = conversions$2.exports
const conversions$1 = conversionsExports
function buildGraph() {
  const graph = {}
  const models = Object.keys(conversions$1)
  for (let len = models.length, i = 0; i < len; i++) {
    graph[models[i]] = {
      distance: -1,
      parent: null
    }
  }
  return graph
}
function deriveBFS(fromModel) {
  const graph = buildGraph()
  const queue = [fromModel]
  graph[fromModel].distance = 0
  while (queue.length) {
    const current = queue.pop()
    const adjacents = Object.keys(conversions$1[current])
    for (let len = adjacents.length, i = 0; i < len; i++) {
      const adjacent = adjacents[i]
      const node = graph[adjacent]
      if (node.distance === -1) {
        node.distance = graph[current].distance + 1
        node.parent = current
        queue.unshift(adjacent)
      }
    }
  }
  return graph
}
function link(from, to) {
  return function (args) {
    return to(from(args))
  }
}
function wrapConversion(toModel, graph) {
  const path = [graph[toModel].parent, toModel]
  let fn = conversions$1[graph[toModel].parent][toModel]
  let cur = graph[toModel].parent
  while (graph[cur].parent) {
    path.unshift(graph[cur].parent)
    fn = link(conversions$1[graph[cur].parent][cur], fn)
    cur = graph[cur].parent
  }
  fn.conversion = path
  return fn
}
const route$1 = function (fromModel) {
  const graph = deriveBFS(fromModel)
  const conversion = {}
  const models = Object.keys(graph)
  for (let len = models.length, i = 0; i < len; i++) {
    const toModel = models[i]
    const node = graph[toModel]
    if (node.parent === null) {
      continue
    }
    conversion[toModel] = wrapConversion(toModel, graph)
  }
  return conversion
}
const conversions$3 = conversionsExports
const route$2 = route$1
const convert = {}
const models = Object.keys(conversions$3)
function wrapRaw(fn) {
  const wrappedFn = function (args) {
    if (args === undefined || args === null) {
      return args
    }
    if (arguments.length > 1) {
      args = Array.prototype.slice.call(arguments)
    }
    return fn(args)
  }
  if ('conversion' in fn) {
    wrappedFn.conversion = fn.conversion
  }
  return wrappedFn
}
function wrapRounded(fn) {
  const wrappedFn = function (args) {
    if (args === undefined || args === null) {
      return args
    }
    if (arguments.length > 1) {
      args = Array.prototype.slice.call(arguments)
    }
    const result = fn(args)
    if (typeof result === 'object') {
      for (let len = result.length, i = 0; i < len; i++) {
        result[i] = Math.round(result[i])
      }
    }
    return result
  }
  if ('conversion' in fn) {
    wrappedFn.conversion = fn.conversion
  }
  return wrappedFn
}
models.forEach(function (fromModel) {
  convert[fromModel] = {}
  Object.defineProperty(convert[fromModel], 'channels', {
    value: conversions$3[fromModel].channels
  })
  Object.defineProperty(convert[fromModel], 'labels', {
    value: conversions$3[fromModel].labels
  })
  const routes = route$2(fromModel)
  const routeModels = Object.keys(routes)
  routeModels.forEach(function (toModel) {
    const fn = routes[toModel]
    convert[fromModel][toModel] = wrapRounded(fn)
    convert[fromModel][toModel].raw = wrapRaw(fn)
  })
})
const colorConvert$1 = convert
ansiStyles$1.exports
;(function (module) {
  const colorConvert$1$1 = colorConvert$1
  const wrapAnsi16 = (fn, offset) =>
    function () {
      const code = fn.apply(colorConvert$1$1, arguments)
      return `\u001B[${code + offset}m`
    }
  const wrapAnsi256 = (fn, offset) =>
    function () {
      const code = fn.apply(colorConvert$1$1, arguments)
      return `\u001B[${38 + offset};5;${code}m`
    }
  const wrapAnsi16m = (fn, offset) =>
    function () {
      const rgb = fn.apply(colorConvert$1$1, arguments)
      return `\u001B[${38 + offset};2;${rgb[0]};${rgb[1]};${rgb[2]}m`
    }
  function assembleStyles() {
    const codes = new Map()
    const styles = {
      modifier: {
        reset: [0, 0],
        bold: [1, 22],
        dim: [2, 22],
        italic: [3, 23],
        underline: [4, 24],
        inverse: [7, 27],
        hidden: [8, 28],
        strikethrough: [9, 29]
      },
      color: {
        black: [30, 39],
        red: [31, 39],
        green: [32, 39],
        yellow: [33, 39],
        blue: [34, 39],
        magenta: [35, 39],
        cyan: [36, 39],
        white: [37, 39],
        gray: [90, 39],
        redBright: [91, 39],
        greenBright: [92, 39],
        yellowBright: [93, 39],
        blueBright: [94, 39],
        magentaBright: [95, 39],
        cyanBright: [96, 39],
        whiteBright: [97, 39]
      },
      bgColor: {
        bgBlack: [40, 49],
        bgRed: [41, 49],
        bgGreen: [42, 49],
        bgYellow: [43, 49],
        bgBlue: [44, 49],
        bgMagenta: [45, 49],
        bgCyan: [46, 49],
        bgWhite: [47, 49],
        bgBlackBright: [100, 49],
        bgRedBright: [101, 49],
        bgGreenBright: [102, 49],
        bgYellowBright: [103, 49],
        bgBlueBright: [104, 49],
        bgMagentaBright: [105, 49],
        bgCyanBright: [106, 49],
        bgWhiteBright: [107, 49]
      }
    }
    styles.color.grey = styles.color.gray
    for (const groupName of Object.keys(styles)) {
      const group = styles[groupName]
      for (const styleName of Object.keys(group)) {
        const style = group[styleName]
        styles[styleName] = {
          open: `\u001B[${style[0]}m`,
          close: `\u001B[${style[1]}m`
        }
        group[styleName] = styles[styleName]
        codes.set(style[0], style[1])
      }
      Object.defineProperty(styles, groupName, {
        value: group,
        enumerable: false
      })
      Object.defineProperty(styles, 'codes', {
        value: codes,
        enumerable: false
      })
    }
    const ansi2ansi = n => n
    const rgb2rgb = (r, g, b) => [r, g, b]
    styles.color.close = '\u001B[39m'
    styles.bgColor.close = '\u001B[49m'
    styles.color.ansi = {
      ansi: wrapAnsi16(ansi2ansi, 0)
    }
    styles.color.ansi256 = {
      ansi256: wrapAnsi256(ansi2ansi, 0)
    }
    styles.color.ansi16m = {
      rgb: wrapAnsi16m(rgb2rgb, 0)
    }
    styles.bgColor.ansi = {
      ansi: wrapAnsi16(ansi2ansi, 10)
    }
    styles.bgColor.ansi256 = {
      ansi256: wrapAnsi256(ansi2ansi, 10)
    }
    styles.bgColor.ansi16m = {
      rgb: wrapAnsi16m(rgb2rgb, 10)
    }
    for (let key of Object.keys(colorConvert$1$1)) {
      if (typeof colorConvert$1$1[key] !== 'object') {
        continue
      }
      const suite = colorConvert$1$1[key]
      if (key === 'ansi16') {
        key = 'ansi'
      }
      if ('ansi16' in suite) {
        styles.color.ansi[key] = wrapAnsi16(suite.ansi16, 0)
        styles.bgColor.ansi[key] = wrapAnsi16(suite.ansi16, 10)
      }
      if ('ansi256' in suite) {
        styles.color.ansi256[key] = wrapAnsi256(suite.ansi256, 0)
        styles.bgColor.ansi256[key] = wrapAnsi256(suite.ansi256, 10)
      }
      if ('rgb' in suite) {
        styles.color.ansi16m[key] = wrapAnsi16m(suite.rgb, 0)
        styles.bgColor.ansi16m[key] = wrapAnsi16m(suite.rgb, 10)
      }
    }
    return styles
  }
  Object.defineProperty(module, 'exports', {
    enumerable: true,
    get: assembleStyles
  })
})(ansiStyles$1)
const ansiStylesExports$1 = ansiStyles$1.exports
const hasFlag$3 = (flag, argv) => {
  argv = argv || process.argv
  const prefix = flag.startsWith('-') ? '' : flag.length === 1 ? '-' : '--'
  const pos = argv.indexOf(prefix + flag)
  const terminatorPos = argv.indexOf('--')
  return pos !== -1 && (terminatorPos === -1 ? true : pos < terminatorPos)
}
const os$1 = os$3
const hasFlag$2 = hasFlag$3
const env$1$1 = process.env
let forceColor$1
if (
  hasFlag$2('no-color') ||
  hasFlag$2('no-colors') ||
  hasFlag$2('color=false')
) {
  forceColor$1 = false
} else if (
  hasFlag$2('color') ||
  hasFlag$2('colors') ||
  hasFlag$2('color=true') ||
  hasFlag$2('color=always')
) {
  forceColor$1 = true
}
if ('FORCE_COLOR' in env$1$1) {
  forceColor$1 =
    env$1$1.FORCE_COLOR.length === 0 || parseInt(env$1$1.FORCE_COLOR, 10) !== 0
}
function translateLevel$1(level) {
  if (level === 0) {
    return false
  }
  return {
    level,
    hasBasic: true,
    has256: level >= 2,
    has16m: level >= 3
  }
}
function supportsColor$1(stream) {
  if (forceColor$1 === false) {
    return 0
  }
  if (
    hasFlag$2('color=16m') ||
    hasFlag$2('color=full') ||
    hasFlag$2('color=truecolor')
  ) {
    return 3
  }
  if (hasFlag$2('color=256')) {
    return 2
  }
  if (stream && !stream.isTTY && forceColor$1 !== true) {
    return 0
  }
  const min = forceColor$1 ? 1 : 0
  if (process.platform === 'win32') {
    const osRelease = os$1.release().split('.')
    if (
      Number(process.versions.node.split('.')[0]) >= 8 &&
      Number(osRelease[0]) >= 10 &&
      Number(osRelease[2]) >= 10586
    ) {
      return Number(osRelease[2]) >= 14931 ? 3 : 2
    }
    return 1
  }
  if ('CI' in env$1$1) {
    if (
      ['TRAVIS', 'CIRCLECI', 'APPVEYOR', 'GITLAB_CI'].some(
        sign => sign in env$1$1
      ) ||
      env$1$1.CI_NAME === 'codeship'
    ) {
      return 1
    }
    return min
  }
  if ('TEAMCITY_VERSION' in env$1$1) {
    return /^(9\.(0*[1-9]\d*)\.|\d{2,}\.)/.test(env$1$1.TEAMCITY_VERSION)
      ? 1
      : 0
  }
  if (env$1$1.COLORTERM === 'truecolor') {
    return 3
  }
  if ('TERM_PROGRAM' in env$1$1) {
    const version = parseInt(
      (env$1$1.TERM_PROGRAM_VERSION || '').split('.')[0],
      10
    )
    switch (env$1$1.TERM_PROGRAM) {
      case 'iTerm.app':
        return version >= 3 ? 3 : 2
      case 'Apple_Terminal':
        return 2
    }
  }
  if (/-256(color)?$/i.test(env$1$1.TERM)) {
    return 2
  }
  if (
    /^screen|^xterm|^vt100|^vt220|^rxvt|color|ansi|cygwin|linux/i.test(
      env$1$1.TERM
    )
  ) {
    return 1
  }
  if ('COLORTERM' in env$1$1) {
    return 1
  }
  if (env$1$1.TERM === 'dumb') {
    return min
  }
  return min
}
function getSupportLevel$1(stream) {
  const level = supportsColor$1(stream)
  return translateLevel$1(level)
}
const supportsColor_1$1$1 = {
  stdout: getSupportLevel$1(process.stdout),
  stderr: getSupportLevel$1(process.stderr)
}
const TEMPLATE_REGEX$1 =
  /(?:\\(u[a-f\d]{4}|x[a-f\d]{2}|.))|(?:\{(~)?(\w+(?:\([^)]*\))?(?:\.\w+(?:\([^)]*\))?)*)(?:[ \t]|(?=\r?\n)))|(\})|((?:.|[\r\n\f])+?)/gi
const STYLE_REGEX$1 = /(?:^|\.)(\w+)(?:\(([^)]*)\))?/g
const STRING_REGEX$1 = /^(['"])((?:\\.|(?!\1)[^\\])*)\1$/
const ESCAPE_REGEX$1 = /\\(u[a-f\d]{4}|x[a-f\d]{2}|.)|([^\\])/gi
const ESCAPES$1 = new Map([
  ['n', '\n'],
  ['r', '\r'],
  ['t', '\t'],
  ['b', '\b'],
  ['f', '\f'],
  ['v', '\v'],
  ['0', '\0'],
  ['\\', '\\'],
  ['e', '\u001B'],
  ['a', '\u0007']
])
function unescape$1(c) {
  if ((c[0] === 'u' && c.length === 5) || (c[0] === 'x' && c.length === 3)) {
    return String.fromCharCode(parseInt(c.slice(1), 16))
  }
  return ESCAPES$1.get(c) || c
}
function parseArguments$1(name, args) {
  const results = []
  const chunks = args.trim().split(/\s*,\s*/g)
  let matches
  for (const chunk of chunks) {
    if (!isNaN(chunk)) {
      results.push(Number(chunk))
    } else if ((matches = chunk.match(STRING_REGEX$1))) {
      results.push(
        matches[2].replace(ESCAPE_REGEX$1, (m, escape, chr) =>
          escape ? unescape$1(escape) : chr
        )
      )
    } else {
      throw new Error(
        `Invalid Chalk template style argument: ${chunk} (in style '${name}')`
      )
    }
  }
  return results
}
function parseStyle$1(style) {
  STYLE_REGEX$1.lastIndex = 0
  const results = []
  let matches
  while ((matches = STYLE_REGEX$1.exec(style)) !== null) {
    const name = matches[1]
    if (matches[2]) {
      const args = parseArguments$1(name, matches[2])
      results.push([name].concat(args))
    } else {
      results.push([name])
    }
  }
  return results
}
function buildStyle$1(chalk, styles) {
  const enabled = {}
  for (const layer of styles) {
    for (const style of layer.styles) {
      enabled[style[0]] = layer.inverse ? null : style.slice(1)
    }
  }
  let current = chalk
  for (const styleName of Object.keys(enabled)) {
    if (Array.isArray(enabled[styleName])) {
      if (!(styleName in current)) {
        throw new Error(`Unknown Chalk style: ${styleName}`)
      }
      if (enabled[styleName].length > 0) {
        current = current[styleName].apply(current, enabled[styleName])
      } else {
        current = current[styleName]
      }
    }
  }
  return current
}
const templates$1 = (chalk, tmp) => {
  const styles = []
  const chunks = []
  let chunk = []
  tmp.replace(TEMPLATE_REGEX$1, (m, escapeChar, inverse, style, close, chr) => {
    if (escapeChar) {
      chunk.push(unescape$1(escapeChar))
    } else if (style) {
      const str = chunk.join('')
      chunk = []
      chunks.push(styles.length === 0 ? str : buildStyle$1(chalk, styles)(str))
      styles.push({
        inverse,
        styles: parseStyle$1(style)
      })
    } else if (close) {
      if (styles.length === 0) {
        throw new Error('Found extraneous } in Chalk template literal')
      }
      chunks.push(buildStyle$1(chalk, styles)(chunk.join('')))
      chunk = []
      styles.pop()
    } else {
      chunk.push(chr)
    }
  })
  chunks.push(chunk.join(''))
  if (styles.length > 0) {
    const errMsg = `Chalk template literal is missing ${styles.length} closing bracket${styles.length === 1 ? '' : 's'} (\`}\`)`
    throw new Error(errMsg)
  }
  return chunks.join('')
}
;(function (module) {
  const escapeStringRegexp = escapeStringRegexp$1
  const ansiStyles = ansiStylesExports$1
  const stdoutColor = supportsColor_1$1$1.stdout
  const template = templates$1
  const isSimpleWindowsTerm =
    process.platform === 'win32' &&
    !(process.env.TERM || '').toLowerCase().startsWith('xterm')
  const levelMapping = ['ansi', 'ansi', 'ansi256', 'ansi16m']
  const skipModels = new Set(['gray'])
  const styles = Object.create(null)
  function applyOptions(obj, options) {
    options = options || {}
    const scLevel = stdoutColor ? stdoutColor.level : 0
    obj.level = options.level === undefined ? scLevel : options.level
    obj.enabled = 'enabled' in options ? options.enabled : obj.level > 0
  }
  function Chalk(options) {
    if (!this || !(this instanceof Chalk) || this.template) {
      const chalk = {}
      applyOptions(chalk, options)
      chalk.template = function () {
        const args = [].slice.call(arguments)
        return chalkTag.apply(null, [chalk.template].concat(args))
      }
      Object.setPrototypeOf(chalk, Chalk.prototype)
      Object.setPrototypeOf(chalk.template, chalk)
      chalk.template.constructor = Chalk
      return chalk.template
    }
    applyOptions(this, options)
  }
  if (isSimpleWindowsTerm) {
    ansiStyles.blue.open = '\u001B[94m'
  }
  for (const key of Object.keys(ansiStyles)) {
    ansiStyles[key].closeRe = new RegExp(
      escapeStringRegexp(ansiStyles[key].close),
      'g'
    )
    styles[key] = {
      get() {
        const codes = ansiStyles[key]
        return build.call(
          this,
          this._styles ? this._styles.concat(codes) : [codes],
          this._empty,
          key
        )
      }
    }
  }
  styles.visible = {
    get() {
      return build.call(this, this._styles || [], true, 'visible')
    }
  }
  ansiStyles.color.closeRe = new RegExp(
    escapeStringRegexp(ansiStyles.color.close),
    'g'
  )
  for (const model of Object.keys(ansiStyles.color.ansi)) {
    if (skipModels.has(model)) {
      continue
    }
    styles[model] = {
      get() {
        const level = this.level
        return function () {
          const open = ansiStyles.color[levelMapping[level]][model].apply(
            null,
            arguments
          )
          const codes = {
            open,
            close: ansiStyles.color.close,
            closeRe: ansiStyles.color.closeRe
          }
          return build.call(
            this,
            this._styles ? this._styles.concat(codes) : [codes],
            this._empty,
            model
          )
        }
      }
    }
  }
  ansiStyles.bgColor.closeRe = new RegExp(
    escapeStringRegexp(ansiStyles.bgColor.close),
    'g'
  )
  for (const model of Object.keys(ansiStyles.bgColor.ansi)) {
    if (skipModels.has(model)) {
      continue
    }
    const bgModel = 'bg' + model[0].toUpperCase() + model.slice(1)
    styles[bgModel] = {
      get() {
        const level = this.level
        return function () {
          const open = ansiStyles.bgColor[levelMapping[level]][model].apply(
            null,
            arguments
          )
          const codes = {
            open,
            close: ansiStyles.bgColor.close,
            closeRe: ansiStyles.bgColor.closeRe
          }
          return build.call(
            this,
            this._styles ? this._styles.concat(codes) : [codes],
            this._empty,
            model
          )
        }
      }
    }
  }
  const proto = Object.defineProperties(() => {}, styles)
  function build(_styles, _empty, key) {
    const builder = function () {
      return applyStyle.apply(builder, arguments)
    }
    builder._styles = _styles
    builder._empty = _empty
    const self = this
    Object.defineProperty(builder, 'level', {
      enumerable: true,
      get() {
        return self.level
      },
      set(level) {
        self.level = level
      }
    })
    Object.defineProperty(builder, 'enabled', {
      enumerable: true,
      get() {
        return self.enabled
      },
      set(enabled) {
        self.enabled = enabled
      }
    })
    builder.hasGrey = this.hasGrey || key === 'gray' || key === 'grey'
    Object.setPrototypeOf(builder, proto)
    return builder
  }
  function applyStyle() {
    const args = arguments
    const argsLen = args.length
    let str = String(arguments[0])
    if (argsLen === 0) {
      return ''
    }
    if (argsLen > 1) {
      for (let a = 1; a < argsLen; a++) {
        str += ' ' + args[a]
      }
    }
    if (!this.enabled || this.level <= 0 || !str) {
      return this._empty ? '' : str
    }
    const originalDim = ansiStyles.dim.open
    if (isSimpleWindowsTerm && this.hasGrey) {
      ansiStyles.dim.open = ''
    }
    for (const code of this._styles.slice().reverse()) {
      str = code.open + str.replace(code.closeRe, code.open) + code.close
      str = str.replace(/\r?\n/g, `${code.close}$&${code.open}`)
    }
    ansiStyles.dim.open = originalDim
    return str
  }
  function chalkTag(chalk, strings) {
    if (!Array.isArray(strings)) {
      return [].slice.call(arguments, 1).join(' ')
    }
    const args = [].slice.call(arguments, 2)
    const parts = [strings.raw[0]]
    for (let i = 1; i < strings.length; i++) {
      parts.push(String(args[i - 1]).replace(/[{}\\]/g, '\\$&'))
      parts.push(String(strings.raw[i]))
    }
    return template(chalk, parts.join(''))
  }
  Object.defineProperties(Chalk.prototype, styles)
  module.exports = Chalk()
  module.exports.supportsColor = stdoutColor
  module.exports.default = module.exports
})(chalk$1)
const chalkExports$1 = chalk$1.exports
Object.defineProperty(lib$1$1, '__esModule', {
  value: true
})
lib$1$1.default = highlight
lib$1$1.shouldHighlight = shouldHighlight
const _jsTokens = jsTokens
const _helperValidatorIdentifier = lib$m
const _chalk$1 = _interopRequireWildcard$1(chalkExports$1, true)
function _getRequireWildcardCache$1(e) {
  if ('function' != typeof WeakMap) {
    return null
  }
  const r = new WeakMap(),
    t = new WeakMap()
  return (_getRequireWildcardCache$1 = function (e) {
    return e ? t : r
  })(e)
}
function _interopRequireWildcard$1(e, r) {
  if (null === e || ('object' != typeof e && 'function' != typeof e)) {
    return {
      default: e
    }
  }
  const t = _getRequireWildcardCache$1(r)
  if (t && t.has(e)) {
    return t.get(e)
  }
  const n = {
      __proto__: null
    },
    a = Object.defineProperty && Object.getOwnPropertyDescriptor
  for (const u in e) {
    if ('default' !== u && Object.prototype.hasOwnProperty.call(e, u)) {
      var i = a ? Object.getOwnPropertyDescriptor(e, u) : null
      i && (i.get || i.set) ? Object.defineProperty(n, u, i) : (n[u] = e[u])
    }
  }
  return (n.default = e), t && t.set(e, n), n
}
const sometimesKeywords = new Set(['as', 'async', 'from', 'get', 'of', 'set'])
function getDefs$1(chalk) {
  return {
    keyword: chalk.cyan,
    capitalized: chalk.yellow,
    jsxIdentifier: chalk.yellow,
    punctuator: chalk.yellow,
    number: chalk.magenta,
    string: chalk.green,
    regex: chalk.magenta,
    comment: chalk.grey,
    invalid: chalk.white.bgRed.bold
  }
}
const NEWLINE$1 = /\r\n|[\n\r\u2028\u2029]/
const BRACKET = /^[()[\]{}]$/
let tokenize
{
  const JSX_TAG = /^[a-z][\w-]*$/i
  const getTokenType = function (token, offset, text) {
    if (token.type === 'name') {
      if (
        (0, _helperValidatorIdentifier.isKeyword)(token.value) ||
        (0, _helperValidatorIdentifier.isStrictReservedWord)(
          token.value,
          true
        ) ||
        sometimesKeywords.has(token.value)
      ) {
        return 'keyword'
      }
      if (
        JSX_TAG.test(token.value) &&
        (text[offset - 1] === '<' || text.slice(offset - 2, offset) == '</')
      ) {
        return 'jsxIdentifier'
      }
      if (token.value[0] !== token.value[0].toLowerCase()) {
        return 'capitalized'
      }
    }
    if (token.type === 'punctuator' && BRACKET.test(token.value)) {
      return 'bracket'
    }
    if (
      token.type === 'invalid' &&
      (token.value === '@' || token.value === '#')
    ) {
      return 'punctuator'
    }
    return token.type
  }
  tokenize = function* (text) {
    let match
    while ((match = _jsTokens.default.exec(text))) {
      const token = _jsTokens.matchToToken(match)
      yield {
        type: getTokenType(token, match.index, text),
        value: token.value
      }
    }
  }
}
function highlightTokens(defs, text) {
  let highlighted = ''
  for (const { type, value } of tokenize(text)) {
    const colorize = defs[type]
    if (colorize) {
      highlighted += value
        .split(NEWLINE$1)
        .map(str => colorize(str))
        .join('\n')
    } else {
      highlighted += value
    }
  }
  return highlighted
}
function shouldHighlight(options) {
  return _chalk$1.default.level > 0 || options.forceColor
}
let chalkWithForcedColor$1 = undefined
function getChalk$1(forceColor) {
  if (forceColor) {
    let _chalkWithForcedColor
    ;(_chalkWithForcedColor = chalkWithForcedColor$1) != null
      ? _chalkWithForcedColor
      : (chalkWithForcedColor$1 = new _chalk$1.default.constructor({
          enabled: true,
          level: 1
        }))
    return chalkWithForcedColor$1
  }
  return _chalk$1.default
}
{
  lib$1$1.getChalk = options => getChalk$1(options.forceColor)
}
function highlight(code, options = {}) {
  if (code !== '' && shouldHighlight(options)) {
    const defs = getDefs$1(getChalk$1(options.forceColor))
    return highlightTokens(defs, code)
  } else {
    return code
  }
}
const chalk$2 = {
  exports: {}
}
const matchOperatorsRe = /[|\\{}()[\]^$+*?.]/g
const escapeStringRegexp$2 = function (str) {
  if (typeof str !== 'string') {
    throw new TypeError('Expected a string')
  }
  return str.replace(matchOperatorsRe, '\\$&')
}
const ansiStyles$2 = {
  exports: {}
}
ansiStyles$2.exports
;(function (module) {
  const colorConvert$1$1 = colorConvert$1
  const wrapAnsi16 = (fn, offset) =>
    function () {
      const code = fn.apply(colorConvert$1$1, arguments)
      return `\u001B[${code + offset}m`
    }
  const wrapAnsi256 = (fn, offset) =>
    function () {
      const code = fn.apply(colorConvert$1$1, arguments)
      return `\u001B[${38 + offset};5;${code}m`
    }
  const wrapAnsi16m = (fn, offset) =>
    function () {
      const rgb = fn.apply(colorConvert$1$1, arguments)
      return `\u001B[${38 + offset};2;${rgb[0]};${rgb[1]};${rgb[2]}m`
    }
  function assembleStyles() {
    const codes = new Map()
    const styles = {
      modifier: {
        reset: [0, 0],
        bold: [1, 22],
        dim: [2, 22],
        italic: [3, 23],
        underline: [4, 24],
        inverse: [7, 27],
        hidden: [8, 28],
        strikethrough: [9, 29]
      },
      color: {
        black: [30, 39],
        red: [31, 39],
        green: [32, 39],
        yellow: [33, 39],
        blue: [34, 39],
        magenta: [35, 39],
        cyan: [36, 39],
        white: [37, 39],
        gray: [90, 39],
        redBright: [91, 39],
        greenBright: [92, 39],
        yellowBright: [93, 39],
        blueBright: [94, 39],
        magentaBright: [95, 39],
        cyanBright: [96, 39],
        whiteBright: [97, 39]
      },
      bgColor: {
        bgBlack: [40, 49],
        bgRed: [41, 49],
        bgGreen: [42, 49],
        bgYellow: [43, 49],
        bgBlue: [44, 49],
        bgMagenta: [45, 49],
        bgCyan: [46, 49],
        bgWhite: [47, 49],
        bgBlackBright: [100, 49],
        bgRedBright: [101, 49],
        bgGreenBright: [102, 49],
        bgYellowBright: [103, 49],
        bgBlueBright: [104, 49],
        bgMagentaBright: [105, 49],
        bgCyanBright: [106, 49],
        bgWhiteBright: [107, 49]
      }
    }
    styles.color.grey = styles.color.gray
    for (const groupName of Object.keys(styles)) {
      const group = styles[groupName]
      for (const styleName of Object.keys(group)) {
        const style = group[styleName]
        styles[styleName] = {
          open: `\u001B[${style[0]}m`,
          close: `\u001B[${style[1]}m`
        }
        group[styleName] = styles[styleName]
        codes.set(style[0], style[1])
      }
      Object.defineProperty(styles, groupName, {
        value: group,
        enumerable: false
      })
      Object.defineProperty(styles, 'codes', {
        value: codes,
        enumerable: false
      })
    }
    const ansi2ansi = n => n
    const rgb2rgb = (r, g, b) => [r, g, b]
    styles.color.close = '\u001B[39m'
    styles.bgColor.close = '\u001B[49m'
    styles.color.ansi = {
      ansi: wrapAnsi16(ansi2ansi, 0)
    }
    styles.color.ansi256 = {
      ansi256: wrapAnsi256(ansi2ansi, 0)
    }
    styles.color.ansi16m = {
      rgb: wrapAnsi16m(rgb2rgb, 0)
    }
    styles.bgColor.ansi = {
      ansi: wrapAnsi16(ansi2ansi, 10)
    }
    styles.bgColor.ansi256 = {
      ansi256: wrapAnsi256(ansi2ansi, 10)
    }
    styles.bgColor.ansi16m = {
      rgb: wrapAnsi16m(rgb2rgb, 10)
    }
    for (let key of Object.keys(colorConvert$1$1)) {
      if (typeof colorConvert$1$1[key] !== 'object') {
        continue
      }
      const suite = colorConvert$1$1[key]
      if (key === 'ansi16') {
        key = 'ansi'
      }
      if ('ansi16' in suite) {
        styles.color.ansi[key] = wrapAnsi16(suite.ansi16, 0)
        styles.bgColor.ansi[key] = wrapAnsi16(suite.ansi16, 10)
      }
      if ('ansi256' in suite) {
        styles.color.ansi256[key] = wrapAnsi256(suite.ansi256, 0)
        styles.bgColor.ansi256[key] = wrapAnsi256(suite.ansi256, 10)
      }
      if ('rgb' in suite) {
        styles.color.ansi16m[key] = wrapAnsi16m(suite.rgb, 0)
        styles.bgColor.ansi16m[key] = wrapAnsi16m(suite.rgb, 10)
      }
    }
    return styles
  }
  Object.defineProperty(module, 'exports', {
    enumerable: true,
    get: assembleStyles
  })
})(ansiStyles$2)
const ansiStylesExports = ansiStyles$2.exports
const hasFlag$1$1 = (flag, argv) => {
  argv = argv || process.argv
  const prefix = flag.startsWith('-') ? '' : flag.length === 1 ? '-' : '--'
  const pos = argv.indexOf(prefix + flag)
  const terminatorPos = argv.indexOf('--')
  return pos !== -1 && (terminatorPos === -1 ? true : pos < terminatorPos)
}
const os = os$3
const hasFlag$4 = hasFlag$1$1
const env$3 = process.env
let forceColor
if (
  hasFlag$4('no-color') ||
  hasFlag$4('no-colors') ||
  hasFlag$4('color=false')
) {
  forceColor = false
} else if (
  hasFlag$4('color') ||
  hasFlag$4('colors') ||
  hasFlag$4('color=true') ||
  hasFlag$4('color=always')
) {
  forceColor = true
}
if ('FORCE_COLOR' in env$3) {
  forceColor =
    env$3.FORCE_COLOR.length === 0 || parseInt(env$3.FORCE_COLOR, 10) !== 0
}
function translateLevel(level) {
  if (level === 0) {
    return false
  }
  return {
    level,
    hasBasic: true,
    has256: level >= 2,
    has16m: level >= 3
  }
}
function supportsColor(stream) {
  if (forceColor === false) {
    return 0
  }
  if (
    hasFlag$4('color=16m') ||
    hasFlag$4('color=full') ||
    hasFlag$4('color=truecolor')
  ) {
    return 3
  }
  if (hasFlag$4('color=256')) {
    return 2
  }
  if (stream && !stream.isTTY && forceColor !== true) {
    return 0
  }
  const min = forceColor ? 1 : 0
  if (process.platform === 'win32') {
    const osRelease = os.release().split('.')
    if (
      Number(process.versions.node.split('.')[0]) >= 8 &&
      Number(osRelease[0]) >= 10 &&
      Number(osRelease[2]) >= 10586
    ) {
      return Number(osRelease[2]) >= 14931 ? 3 : 2
    }
    return 1
  }
  if ('CI' in env$3) {
    if (
      ['TRAVIS', 'CIRCLECI', 'APPVEYOR', 'GITLAB_CI'].some(
        sign => sign in env$3
      ) ||
      env$3.CI_NAME === 'codeship'
    ) {
      return 1
    }
    return min
  }
  if ('TEAMCITY_VERSION' in env$3) {
    return /^(9\.(0*[1-9]\d*)\.|\d{2,}\.)/.test(env$3.TEAMCITY_VERSION) ? 1 : 0
  }
  if (env$3.COLORTERM === 'truecolor') {
    return 3
  }
  if ('TERM_PROGRAM' in env$3) {
    const version = parseInt(
      (env$3.TERM_PROGRAM_VERSION || '').split('.')[0],
      10
    )
    switch (env$3.TERM_PROGRAM) {
      case 'iTerm.app':
        return version >= 3 ? 3 : 2
      case 'Apple_Terminal':
        return 2
    }
  }
  if (/-256(color)?$/i.test(env$3.TERM)) {
    return 2
  }
  if (
    /^screen|^xterm|^vt100|^vt220|^rxvt|color|ansi|cygwin|linux/i.test(
      env$3.TERM
    )
  ) {
    return 1
  }
  if ('COLORTERM' in env$3) {
    return 1
  }
  if (env$3.TERM === 'dumb') {
    return min
  }
  return min
}
function getSupportLevel(stream) {
  const level = supportsColor(stream)
  return translateLevel(level)
}
const supportsColor_1$2 = {
  stdout: getSupportLevel(process.stdout),
  stderr: getSupportLevel(process.stderr)
}
const TEMPLATE_REGEX =
  /(?:\\(u[a-f\d]{4}|x[a-f\d]{2}|.))|(?:\{(~)?(\w+(?:\([^)]*\))?(?:\.\w+(?:\([^)]*\))?)*)(?:[ \t]|(?=\r?\n)))|(\})|((?:.|[\r\n\f])+?)/gi
const STYLE_REGEX = /(?:^|\.)(\w+)(?:\(([^)]*)\))?/g
const STRING_REGEX = /^(['"])((?:\\.|(?!\1)[^\\])*)\1$/
const ESCAPE_REGEX = /\\(u[a-f\d]{4}|x[a-f\d]{2}|.)|([^\\])/gi
const ESCAPES = new Map([
  ['n', '\n'],
  ['r', '\r'],
  ['t', '\t'],
  ['b', '\b'],
  ['f', '\f'],
  ['v', '\v'],
  ['0', '\0'],
  ['\\', '\\'],
  ['e', '\u001B'],
  ['a', '\u0007']
])
function unescape$2(c) {
  if ((c[0] === 'u' && c.length === 5) || (c[0] === 'x' && c.length === 3)) {
    return String.fromCharCode(parseInt(c.slice(1), 16))
  }
  return ESCAPES.get(c) || c
}
function parseArguments(name, args) {
  const results = []
  const chunks = args.trim().split(/\s*,\s*/g)
  let matches
  for (const chunk of chunks) {
    if (!isNaN(chunk)) {
      results.push(Number(chunk))
    } else if ((matches = chunk.match(STRING_REGEX))) {
      results.push(
        matches[2].replace(ESCAPE_REGEX, (m, escape, chr) =>
          escape ? unescape$2(escape) : chr
        )
      )
    } else {
      throw new Error(
        `Invalid Chalk template style argument: ${chunk} (in style '${name}')`
      )
    }
  }
  return results
}
function parseStyle(style) {
  STYLE_REGEX.lastIndex = 0
  const results = []
  let matches
  while ((matches = STYLE_REGEX.exec(style)) !== null) {
    const name = matches[1]
    if (matches[2]) {
      const args = parseArguments(name, matches[2])
      results.push([name].concat(args))
    } else {
      results.push([name])
    }
  }
  return results
}
function buildStyle(chalk, styles) {
  const enabled = {}
  for (const layer of styles) {
    for (const style of layer.styles) {
      enabled[style[0]] = layer.inverse ? null : style.slice(1)
    }
  }
  let current = chalk
  for (const styleName of Object.keys(enabled)) {
    if (Array.isArray(enabled[styleName])) {
      if (!(styleName in current)) {
        throw new Error(`Unknown Chalk style: ${styleName}`)
      }
      if (enabled[styleName].length > 0) {
        current = current[styleName].apply(current, enabled[styleName])
      } else {
        current = current[styleName]
      }
    }
  }
  return current
}
const templates$2 = (chalk, tmp) => {
  const styles = []
  const chunks = []
  let chunk = []
  tmp.replace(TEMPLATE_REGEX, (m, escapeChar, inverse, style, close, chr) => {
    if (escapeChar) {
      chunk.push(unescape$2(escapeChar))
    } else if (style) {
      const str = chunk.join('')
      chunk = []
      chunks.push(styles.length === 0 ? str : buildStyle(chalk, styles)(str))
      styles.push({
        inverse,
        styles: parseStyle(style)
      })
    } else if (close) {
      if (styles.length === 0) {
        throw new Error('Found extraneous } in Chalk template literal')
      }
      chunks.push(buildStyle(chalk, styles)(chunk.join('')))
      chunk = []
      styles.pop()
    } else {
      chunk.push(chr)
    }
  })
  chunks.push(chunk.join(''))
  if (styles.length > 0) {
    const errMsg = `Chalk template literal is missing ${styles.length} closing bracket${styles.length === 1 ? '' : 's'} (\`}\`)`
    throw new Error(errMsg)
  }
  return chunks.join('')
}
;(function (module) {
  const escapeStringRegexp$1 = escapeStringRegexp$2
  const ansiStyles = ansiStylesExports
  const stdoutColor = supportsColor_1$2.stdout
  const template = templates$2
  const isSimpleWindowsTerm =
    process.platform === 'win32' &&
    !(process.env.TERM || '').toLowerCase().startsWith('xterm')
  const levelMapping = ['ansi', 'ansi', 'ansi256', 'ansi16m']
  const skipModels = new Set(['gray'])
  const styles = Object.create(null)
  function applyOptions(obj, options) {
    options = options || {}
    const scLevel = stdoutColor ? stdoutColor.level : 0
    obj.level = options.level === undefined ? scLevel : options.level
    obj.enabled = 'enabled' in options ? options.enabled : obj.level > 0
  }
  function Chalk(options) {
    if (!this || !(this instanceof Chalk) || this.template) {
      const chalk = {}
      applyOptions(chalk, options)
      chalk.template = function () {
        const args = [].slice.call(arguments)
        return chalkTag.apply(null, [chalk.template].concat(args))
      }
      Object.setPrototypeOf(chalk, Chalk.prototype)
      Object.setPrototypeOf(chalk.template, chalk)
      chalk.template.constructor = Chalk
      return chalk.template
    }
    applyOptions(this, options)
  }
  if (isSimpleWindowsTerm) {
    ansiStyles.blue.open = '\u001B[94m'
  }
  for (const key of Object.keys(ansiStyles)) {
    ansiStyles[key].closeRe = new RegExp(
      escapeStringRegexp$1(ansiStyles[key].close),
      'g'
    )
    styles[key] = {
      get() {
        const codes = ansiStyles[key]
        return build.call(
          this,
          this._styles ? this._styles.concat(codes) : [codes],
          this._empty,
          key
        )
      }
    }
  }
  styles.visible = {
    get() {
      return build.call(this, this._styles || [], true, 'visible')
    }
  }
  ansiStyles.color.closeRe = new RegExp(
    escapeStringRegexp$1(ansiStyles.color.close),
    'g'
  )
  for (const model of Object.keys(ansiStyles.color.ansi)) {
    if (skipModels.has(model)) {
      continue
    }
    styles[model] = {
      get() {
        const level = this.level
        return function () {
          const open = ansiStyles.color[levelMapping[level]][model].apply(
            null,
            arguments
          )
          const codes = {
            open,
            close: ansiStyles.color.close,
            closeRe: ansiStyles.color.closeRe
          }
          return build.call(
            this,
            this._styles ? this._styles.concat(codes) : [codes],
            this._empty,
            model
          )
        }
      }
    }
  }
  ansiStyles.bgColor.closeRe = new RegExp(
    escapeStringRegexp$1(ansiStyles.bgColor.close),
    'g'
  )
  for (const model of Object.keys(ansiStyles.bgColor.ansi)) {
    if (skipModels.has(model)) {
      continue
    }
    const bgModel = 'bg' + model[0].toUpperCase() + model.slice(1)
    styles[bgModel] = {
      get() {
        const level = this.level
        return function () {
          const open = ansiStyles.bgColor[levelMapping[level]][model].apply(
            null,
            arguments
          )
          const codes = {
            open,
            close: ansiStyles.bgColor.close,
            closeRe: ansiStyles.bgColor.closeRe
          }
          return build.call(
            this,
            this._styles ? this._styles.concat(codes) : [codes],
            this._empty,
            model
          )
        }
      }
    }
  }
  const proto = Object.defineProperties(() => {}, styles)
  function build(_styles, _empty, key) {
    const builder = function () {
      return applyStyle.apply(builder, arguments)
    }
    builder._styles = _styles
    builder._empty = _empty
    const self = this
    Object.defineProperty(builder, 'level', {
      enumerable: true,
      get() {
        return self.level
      },
      set(level) {
        self.level = level
      }
    })
    Object.defineProperty(builder, 'enabled', {
      enumerable: true,
      get() {
        return self.enabled
      },
      set(enabled) {
        self.enabled = enabled
      }
    })
    builder.hasGrey = this.hasGrey || key === 'gray' || key === 'grey'
    Object.setPrototypeOf(builder, proto)
    return builder
  }
  function applyStyle() {
    const args = arguments
    const argsLen = args.length
    let str = String(arguments[0])
    if (argsLen === 0) {
      return ''
    }
    if (argsLen > 1) {
      for (let a = 1; a < argsLen; a++) {
        str += ' ' + args[a]
      }
    }
    if (!this.enabled || this.level <= 0 || !str) {
      return this._empty ? '' : str
    }
    const originalDim = ansiStyles.dim.open
    if (isSimpleWindowsTerm && this.hasGrey) {
      ansiStyles.dim.open = ''
    }
    for (const code of this._styles.slice().reverse()) {
      str = code.open + str.replace(code.closeRe, code.open) + code.close
      str = str.replace(/\r?\n/g, `${code.close}$&${code.open}`)
    }
    ansiStyles.dim.open = originalDim
    return str
  }
  function chalkTag(chalk, strings) {
    if (!Array.isArray(strings)) {
      return [].slice.call(arguments, 1).join(' ')
    }
    const args = [].slice.call(arguments, 2)
    const parts = [strings.raw[0]]
    for (let i = 1; i < strings.length; i++) {
      parts.push(String(args[i - 1]).replace(/[{}\\]/g, '\\$&'))
      parts.push(String(strings.raw[i]))
    }
    return template(chalk, parts.join(''))
  }
  Object.defineProperties(Chalk.prototype, styles)
  module.exports = Chalk()
  module.exports.supportsColor = stdoutColor
  module.exports.default = module.exports
})(chalk$2)
const chalkExports = chalk$2.exports
Object.defineProperty(lib$2$1, '__esModule', {
  value: true
})
const codeFrameColumns_1 = (lib$2$1.codeFrameColumns = codeFrameColumns)
lib$2$1.default = _default$1
const _highlight = lib$1$1
const _chalk = _interopRequireWildcard(chalkExports, true)
function _getRequireWildcardCache(e) {
  if ('function' != typeof WeakMap) {
    return null
  }
  const r = new WeakMap(),
    t = new WeakMap()
  return (_getRequireWildcardCache = function (e) {
    return e ? t : r
  })(e)
}
function _interopRequireWildcard(e, r) {
  if (null === e || ('object' != typeof e && 'function' != typeof e)) {
    return {
      default: e
    }
  }
  const t = _getRequireWildcardCache(r)
  if (t && t.has(e)) {
    return t.get(e)
  }
  const n = {
      __proto__: null
    },
    a = Object.defineProperty && Object.getOwnPropertyDescriptor
  for (const u in e) {
    if ('default' !== u && Object.prototype.hasOwnProperty.call(e, u)) {
      var i = a ? Object.getOwnPropertyDescriptor(e, u) : null
      i && (i.get || i.set) ? Object.defineProperty(n, u, i) : (n[u] = e[u])
    }
  }
  return (n.default = e), t && t.set(e, n), n
}
let chalkWithForcedColor = undefined
function getChalk(forceColor) {
  if (forceColor) {
    let _chalkWithForcedColor
    ;(_chalkWithForcedColor = chalkWithForcedColor) != null
      ? _chalkWithForcedColor
      : (chalkWithForcedColor = new _chalk.default.constructor({
          enabled: true,
          level: 1
        }))
    return chalkWithForcedColor
  }
  return _chalk.default
}
let deprecationWarningShown = false
function getDefs(chalk) {
  return {
    gutter: chalk.grey,
    marker: chalk.red.bold,
    message: chalk.red.bold
  }
}
const NEWLINE = /\r\n|[\n\r\u2028\u2029]/
function getMarkerLines(loc, source, opts) {
  const startLoc = Object.assign(
    {
      column: 0,
      line: -1
    },
    loc.start
  )
  const endLoc = Object.assign({}, startLoc, loc.end)
  const { linesAbove = 2, linesBelow = 3 } = opts || {}
  const startLine = startLoc.line
  const startColumn = startLoc.column
  const endLine = endLoc.line
  const endColumn = endLoc.column
  let start = Math.max(startLine - (linesAbove + 1), 0)
  let end = Math.min(source.length, endLine + linesBelow)
  if (startLine === -1) {
    start = 0
  }
  if (endLine === -1) {
    end = source.length
  }
  const lineDiff = endLine - startLine
  const markerLines = {}
  if (lineDiff) {
    for (let i = 0; i <= lineDiff; i++) {
      const lineNumber = i + startLine
      if (!startColumn) {
        markerLines[lineNumber] = true
      } else if (i === 0) {
        const sourceLength = source[lineNumber - 1].length
        markerLines[lineNumber] = [startColumn, sourceLength - startColumn + 1]
      } else if (i === lineDiff) {
        markerLines[lineNumber] = [0, endColumn]
      } else {
        const sourceLength = source[lineNumber - i].length
        markerLines[lineNumber] = [0, sourceLength]
      }
    }
  } else {
    if (startColumn === endColumn) {
      if (startColumn) {
        markerLines[startLine] = [startColumn, 0]
      } else {
        markerLines[startLine] = true
      }
    } else {
      markerLines[startLine] = [startColumn, endColumn - startColumn]
    }
  }
  return {
    start,
    end,
    markerLines
  }
}
function codeFrameColumns(rawLines, loc, opts = {}) {
  const highlighted =
    (opts.highlightCode || opts.forceColor) &&
    (0, _highlight.shouldHighlight)(opts)
  const chalk = getChalk(opts.forceColor)
  const defs = getDefs(chalk)
  const maybeHighlight = (chalkFn, string) => {
    return highlighted ? chalkFn(string) : string
  }
  const lines = rawLines.split(NEWLINE)
  const { start, end, markerLines } = getMarkerLines(loc, lines, opts)
  const hasColumns = loc.start && typeof loc.start.column === 'number'
  const numberMaxWidth = String(end).length
  const highlightedLines = highlighted
    ? (0, _highlight.default)(rawLines, opts)
    : rawLines
  let frame = highlightedLines
    .split(NEWLINE, end)
    .slice(start, end)
    .map((line, index) => {
      const number = start + 1 + index
      const paddedNumber = ` ${number}`.slice(-numberMaxWidth)
      const gutter = ` ${paddedNumber} |`
      const hasMarker = markerLines[number]
      const lastMarkerLine = !markerLines[number + 1]
      if (hasMarker) {
        let markerLine = ''
        if (Array.isArray(hasMarker)) {
          const markerSpacing = line
            .slice(0, Math.max(hasMarker[0] - 1, 0))
            .replace(/[^\t]/g, ' ')
          const numberOfMarkers = hasMarker[1] || 1
          markerLine = [
            '\n ',
            maybeHighlight(defs.gutter, gutter.replace(/\d/g, ' ')),
            ' ',
            markerSpacing,
            maybeHighlight(defs.marker, '^').repeat(numberOfMarkers)
          ].join('')
          if (lastMarkerLine && opts.message) {
            markerLine += ' ' + maybeHighlight(defs.message, opts.message)
          }
        }
        return [
          maybeHighlight(defs.marker, '>'),
          maybeHighlight(defs.gutter, gutter),
          line.length > 0 ? ` ${line}` : '',
          markerLine
        ].join('')
      } else {
        return ` ${maybeHighlight(defs.gutter, gutter)}${line.length > 0 ? ` ${line}` : ''}`
      }
    })
    .join('\n')
  if (opts.message && !hasColumns) {
    frame = `${' '.repeat(numberMaxWidth + 1)}${opts.message}\n${frame}`
  }
  if (highlighted) {
    return chalk.reset(frame)
  } else {
    return frame
  }
}
function _default$1(rawLines, lineNumber, colNumber, opts = {}) {
  if (!deprecationWarningShown) {
    deprecationWarningShown = true
    const message =
      'Passing lineNumber and colNumber is deprecated to @babel/code-frame. Please use `codeFrameColumns`.'
    if (process.emitWarning) {
      process.emitWarning(message, 'DeprecationWarning')
    } else {
      const deprecationError = new Error(message)
      deprecationError.name = 'DeprecationWarning'
      console.warn(new Error(message))
    }
  }
  colNumber = Math.max(colNumber, 0)
  const location = {
    start: {
      column: colNumber,
      line: lineNumber
    }
  }
  return codeFrameColumns(rawLines, location, opts)
}
const safeLastIndexOf = (string, searchString, index) =>
  index < 0 ? -1 : string.lastIndexOf(searchString, index)
function getPosition(text, textIndex) {
  const lineBreakBefore = safeLastIndexOf(text, '\n', textIndex - 1)
  const column = textIndex - lineBreakBefore - 1
  let line = 0
  for (
    let index = lineBreakBefore;
    index >= 0;
    index = safeLastIndexOf(text, '\n', index - 1)
  ) {
    line++
  }
  return {
    line,
    column
  }
}
function indexToLineColumn(text, textIndex, { oneBased = false } = {}) {
  if (textIndex < 0 || (textIndex >= text.length && text.length > 0)) {
    throw new RangeError('Index out of bounds')
  }
  const position = getPosition(text, textIndex)
  return oneBased
    ? {
        line: position.line + 1,
        column: position.column + 1
      }
    : position
}
const getCodePoint = character =>
  `\\u{${character.codePointAt(0).toString(16)}}`
class JSONError extends Error {
  name = 'JSONError'
  fileName
  codeFrame
  rawCodeFrame
  #message
  constructor(message) {
    super()
    this.#message = message
    Error.captureStackTrace?.(this, JSONError)
  }
  get message() {
    const { fileName, codeFrame } = this
    return `${this.#message}${fileName ? ` in ${fileName}` : ''}${codeFrame ? `\n\n${codeFrame}\n` : ''}`
  }
  set message(message) {
    this.#message = message
  }
}
const generateCodeFrame = (string, location, highlightCode = true) =>
  codeFrameColumns_1(
    string,
    {
      start: location
    },
    {
      highlightCode
    }
  )
const getErrorLocation = (string, message) => {
  const match = message.match(
    /in JSON at position (?<index>\d+)(?: \(line (?<line>\d+) column (?<column>\d+)\))?$/
  )
  if (!match) {
    return
  }
  let { index, line, column } = match.groups
  if (line && column) {
    return {
      line: Number(line),
      column: Number(column)
    }
  }
  index = Number(index)
  if (index === string.length) {
    const { line, column } = indexToLineColumn(string, string.length - 1, {
      oneBased: true
    })
    return {
      line,
      column: column + 1
    }
  }
  return indexToLineColumn(string, index, {
    oneBased: true
  })
}
const addCodePointToUnexpectedToken = message =>
  message.replace(
    /(?<=^Unexpected token )(?<quote>')?(.)\k<quote>/,
    (_, _quote, token) => `"${token}"(${getCodePoint(token)})`
  )
function parseJson(string, reviver, fileName) {
  let message
  try {
    return JSON.parse(string, reviver)
  } catch (error) {
    message = error.message
  }
  let location
  if (string) {
    location = getErrorLocation(string, message)
    message = addCodePointToUnexpectedToken(message)
  } else {
    message += ' while parsing empty string'
  }
  const jsonError = new JSONError(message)
  jsonError.fileName = fileName
  if (location) {
    jsonError.codeFrame = generateCodeFrame(string, location)
    jsonError.rawCodeFrame = generateCodeFrame(
      string,
      location,
      /* highlightCode */ false
    )
  }
  throw jsonError
}
function toPath(urlOrPath) {
  return urlOrPath instanceof URL
    ? require$$0$b.fileURLToPath(urlOrPath)
    : urlOrPath
}
const getPackagePath = cwd => path$1.resolve(toPath(cwd) ?? '.', 'package.json')
const _readPackage = (file, normalize) => {
  const json = typeof file === 'string' ? parseJson(file) : file
  if (normalize) {
    normalizePackageData(json)
  }
  return json
}
function readPackageSync({ cwd, normalize = true } = {}) {
  const packageFile = fs$1.readFileSync(getPackagePath(cwd), 'utf8')
  return _readPackage(packageFile, normalize)
}
function readPackageUpSync(options) {
  const filePath = findUpSync('package.json', options)
  if (!filePath) {
    return
  }
  return {
    packageJson: readPackageSync({
      ...options,
      cwd: path$1.dirname(filePath)
    }),
    path: filePath
  }
}
const handlePreserveConsecutiveUppercase = (decamelized, separator) => {
  // Lowercase all single uppercase characters. As we
  // want to preserve uppercase sequences, we cannot
  // simply lowercase the separated string at the end.
  // `data_For_USACounties` → `data_for_USACounties`
  decamelized = decamelized.replace(
    /((?<![\p{Uppercase_Letter}\d])[\p{Uppercase_Letter}\d](?![\p{Uppercase_Letter}\d]))/gu,
    $0 => $0.toLowerCase()
  )
  // Remaining uppercase sequences will be separated from lowercase sequences.
  // `data_For_USACounties` → `data_for_USA_counties`
  return decamelized.replace(
    /(\p{Uppercase_Letter}+)(\p{Uppercase_Letter}\p{Lowercase_Letter}+)/gu,
    (_, $1, $2) => $1 + separator + $2.toLowerCase()
  )
}
function decamelize$2(
  text,
  { separator = '_', preserveConsecutiveUppercase = false } = {}
) {
  if (!(typeof text === 'string' && typeof separator === 'string')) {
    throw new TypeError(
      'The `text` and `separator` arguments should be of type `string`'
    )
  }
  // Checking the second character is done later on. Therefore process shorter strings here.
  if (text.length < 2) {
    return preserveConsecutiveUppercase ? text : text.toLowerCase()
  }
  const replacement = `$1${separator}$2`
  // Split lowercase sequences followed by uppercase character.
  // `dataForUSACounties` → `data_For_USACounties`
  // `myURLstring → `my_URLstring`
  const decamelized = text.replace(
    /([\p{Lowercase_Letter}\d])(\p{Uppercase_Letter})/gu,
    replacement
  )
  if (preserveConsecutiveUppercase) {
    return handlePreserveConsecutiveUppercase(decamelized, separator)
  }
  // Split multiple uppercase characters followed by one or more lowercase characters.
  // `my_URLstring` → `my_ur_lstring`
  return decamelized
    .replace(
      /(\p{Uppercase_Letter})(\p{Uppercase_Letter}\p{Lowercase_Letter}+)/gu,
      replacement
    )
    .toLowerCase()
}
const minimistOptions = {
  exports: {}
}
const toString$1 = Object.prototype.toString
const isPlainObj$1 = function (x) {
  let prototype
  return (
    toString$1.call(x) === '[object Object]' &&
    ((prototype = Object.getPrototypeOf(x)),
    prototype === null || prototype === Object.getPrototypeOf({}))
  )
}
const arrify$1 = function (val) {
  if (val === null || val === undefined) {
    return []
  }
  return Array.isArray(val) ? val : [val]
}
const toString = Object.prototype.toString
const kindOf$1 = function kindOf(val) {
  if (val === void 0) {
    return 'undefined'
  }
  if (val === null) {
    return 'null'
  }
  let type = typeof val
  if (type === 'boolean') {
    return 'boolean'
  }
  if (type === 'string') {
    return 'string'
  }
  if (type === 'number') {
    return 'number'
  }
  if (type === 'symbol') {
    return 'symbol'
  }
  if (type === 'function') {
    return isGeneratorFn(val) ? 'generatorfunction' : 'function'
  }
  if (isArray(val)) {
    return 'array'
  }
  if (isBuffer(val)) {
    return 'buffer'
  }
  if (isArguments(val)) {
    return 'arguments'
  }
  if (isDate(val)) {
    return 'date'
  }
  if (isError(val)) {
    return 'error'
  }
  if (isRegexp(val)) {
    return 'regexp'
  }
  switch (ctorName(val)) {
    case 'Symbol':
      return 'symbol'
    case 'Promise':
      return 'promise'
    // Set, Map, WeakSet, WeakMap
    case 'WeakMap':
      return 'weakmap'
    case 'WeakSet':
      return 'weakset'
    case 'Map':
      return 'map'
    case 'Set':
      return 'set'
    // 8-bit typed arrays
    case 'Int8Array':
      return 'int8array'
    case 'Uint8Array':
      return 'uint8array'
    case 'Uint8ClampedArray':
      return 'uint8clampedarray'
    // 16-bit typed arrays
    case 'Int16Array':
      return 'int16array'
    case 'Uint16Array':
      return 'uint16array'
    // 32-bit typed arrays
    case 'Int32Array':
      return 'int32array'
    case 'Uint32Array':
      return 'uint32array'
    case 'Float32Array':
      return 'float32array'
    case 'Float64Array':
      return 'float64array'
  }
  if (isGeneratorObj(val)) {
    return 'generator'
  }
  // Non-plain objects
  type = toString.call(val)
  switch (type) {
    case '[object Object]':
      return 'object'
    // iterators
    case '[object Map Iterator]':
      return 'mapiterator'
    case '[object Set Iterator]':
      return 'setiterator'
    case '[object String Iterator]':
      return 'stringiterator'
    case '[object Array Iterator]':
      return 'arrayiterator'
  }
  // other
  return type.slice(8, -1).toLowerCase().replace(/\s/g, '')
}
function ctorName(val) {
  return typeof val.constructor === 'function' ? val.constructor.name : null
}
function isArray(val) {
  if (Array.isArray) {
    return Array.isArray(val)
  }
  return val instanceof Array
}
function isError(val) {
  return (
    val instanceof Error ||
    (typeof val.message === 'string' &&
      val.constructor &&
      typeof val.constructor.stackTraceLimit === 'number')
  )
}
function isDate(val) {
  if (val instanceof Date) {
    return true
  }
  return (
    typeof val.toDateString === 'function' &&
    typeof val.getDate === 'function' &&
    typeof val.setDate === 'function'
  )
}
function isRegexp(val) {
  if (val instanceof RegExp) {
    return true
  }
  return (
    typeof val.flags === 'string' &&
    typeof val.ignoreCase === 'boolean' &&
    typeof val.multiline === 'boolean' &&
    typeof val.global === 'boolean'
  )
}
function isGeneratorFn(name, val) {
  return ctorName(name) === 'GeneratorFunction'
}
function isGeneratorObj(val) {
  return (
    typeof val.throw === 'function' &&
    typeof val.return === 'function' &&
    typeof val.next === 'function'
  )
}
function isArguments(val) {
  try {
    if (typeof val.length === 'number' && typeof val.callee === 'function') {
      return true
    }
  } catch (err) {
    if (err.message.indexOf('callee') !== -1) {
      return true
    }
  }
  return false
}
/**
 * If you need to support Safari 5-7 (8-10 yr-old browser),
 * take a look at https://github.com/feross/is-buffer
 */
function isBuffer(val) {
  if (val.constructor && typeof val.constructor.isBuffer === 'function') {
    return val.constructor.isBuffer(val)
  }
  return false
}
const isPlainObject$2 = isPlainObj$1
const arrify = arrify$1
const kindOf = kindOf$1
const push = (obj, prop, value) => {
  if (!obj[prop]) {
    obj[prop] = []
  }
  obj[prop].push(value)
}
const insert = (obj, prop, key, value) => {
  if (!obj[prop]) {
    obj[prop] = {}
  }
  obj[prop][key] = value
}
const prettyPrint = output => {
  return Array.isArray(output)
    ? `[${output.map(prettyPrint).join(', ')}]`
    : kindOf(output) === 'string'
      ? JSON.stringify(output)
      : output
}
const resolveType = value => {
  if (Array.isArray(value) && value.length > 0) {
    const [element] = value
    return `${kindOf(element)}-array`
  }
  return kindOf(value)
}
const normalizeExpectedType = (type, defaultValue) => {
  const inferredType = type === 'array' ? 'string-array' : type
  if (
    arrayTypes.includes(inferredType) &&
    Array.isArray(defaultValue) &&
    defaultValue.length === 0
  ) {
    return 'array'
  }
  return inferredType
}
const passthroughOptions = ['stopEarly', 'unknown', '--']
const primitiveTypes = ['string', 'boolean', 'number']
const arrayTypes = primitiveTypes.map(t => `${t}-array`)
const availableTypes = [...primitiveTypes, 'array', ...arrayTypes]
const buildOptions$1 = options => {
  options = options || {}
  const result = {}
  passthroughOptions.forEach(key => {
    if (options[key]) {
      result[key] = options[key]
    }
  })
  Object.keys(options).forEach(key => {
    let value = options[key]
    if (key === 'arguments') {
      key = '_'
    }
    // If short form is used
    // convert it to long form
    // e.g. { 'name': 'string' }
    if (typeof value === 'string') {
      value = {
        type: value
      }
    }
    if (isPlainObject$2(value)) {
      const props = value
      const { type } = props
      if (type) {
        if (!availableTypes.includes(type)) {
          throw new TypeError(
            `Expected type of "${key}" to be one of ${prettyPrint(availableTypes)}, got ${prettyPrint(type)}`
          )
        }
        if (arrayTypes.includes(type)) {
          const [elementType] = type.split('-')
          push(result, 'array', {
            key,
            [elementType]: true
          })
        } else {
          push(result, type, key)
        }
      }
      if ({}.hasOwnProperty.call(props, 'default')) {
        const { default: defaultValue } = props
        const defaultType = resolveType(defaultValue)
        const expectedType = normalizeExpectedType(type, defaultValue)
        if (expectedType && expectedType !== defaultType) {
          throw new TypeError(
            `Expected "${key}" default value to be of type "${expectedType}", got ${prettyPrint(defaultType)}`
          )
        }
        insert(result, 'default', key, defaultValue)
      }
      arrify(props.alias).forEach(alias => {
        insert(result, 'alias', alias, key)
      })
    }
  })
  return result
}
minimistOptions.exports = buildOptions$1
minimistOptions.exports.default = buildOptions$1
const minimistOptionsExports = minimistOptions.exports
const constructParserOptions = /*@__PURE__*/ getDefaultExportFromCjs(
  minimistOptionsExports
)
const mapObj = {
  exports: {}
}
const isObject$1 = value => typeof value === 'object' && value !== null
const mapObjectSkip = Symbol('skip')
// Customized for this use-case
const isObjectCustom = value =>
  isObject$1(value) &&
  !(value instanceof RegExp) &&
  !(value instanceof Error) &&
  !(value instanceof Date)
const mapObject = (object, mapper, options, isSeen = new WeakMap()) => {
  options = {
    deep: false,
    target: {},
    ...options
  }
  if (isSeen.has(object)) {
    return isSeen.get(object)
  }
  isSeen.set(object, options.target)
  const { target } = options
  delete options.target
  const mapArray = array =>
    array.map(element =>
      isObjectCustom(element)
        ? mapObject(element, mapper, options, isSeen)
        : element
    )
  if (Array.isArray(object)) {
    return mapArray(object)
  }
  for (const [key, value] of Object.entries(object)) {
    const mapResult = mapper(key, value, object)
    if (mapResult === mapObjectSkip) {
      continue
    }
    let [newKey, newValue, { shouldRecurse = true } = {}] = mapResult
    // Drop `__proto__` keys.
    if (newKey === '__proto__') {
      continue
    }
    if (options.deep && shouldRecurse && isObjectCustom(newValue)) {
      newValue = Array.isArray(newValue)
        ? mapArray(newValue)
        : mapObject(newValue, mapper, options, isSeen)
    }
    target[newKey] = newValue
  }
  return target
}
mapObj.exports = (object, mapper, options) => {
  if (!isObject$1(object)) {
    throw new TypeError(
      `Expected an object, got \`${object}\` (${typeof object})`
    )
  }
  return mapObject(object, mapper, options)
}
mapObj.exports.mapObjectSkip = mapObjectSkip
const mapObjExports = mapObj.exports
const mapObject$1 = /*@__PURE__*/ getDefaultExportFromCjs(mapObjExports)
const has = (array, key) =>
  array.some(element => {
    if (typeof element === 'string') {
      return element === key
    }
    element.lastIndex = 0
    return element.test(key)
  })
const cache = new QuickLRU({
  maxSize: 100_000
})
// Reproduces behavior from `map-obj`.
const isObject = value =>
  typeof value === 'object' &&
  value !== null &&
  !(value instanceof RegExp) &&
  !(value instanceof Error) &&
  !(value instanceof Date)
const transform = (input, options = {}) => {
  if (!isObject(input)) {
    return input
  }
  const { separator = '_', exclude, deep = false } = options
  const makeMapper = parentPath => (key, value) => {
    if (deep && isObject(value)) {
      value = mapObject$1(value, makeMapper())
    }
    if (!(exclude && has(exclude, key))) {
      const cacheKey = `${separator}${key}`
      if (cache.has(cacheKey)) {
        key = cache.get(cacheKey)
      } else {
        const returnValue = decamelize$2(key, {
          separator
        })
        if (key.length < 100) {
          // Prevent abuse
          cache.set(cacheKey, returnValue)
        }
        key = returnValue
      }
    }
    return [key, value]
  }
  return mapObject$1(input, makeMapper())
}
function decamelizeKeys(input, options) {
  if (Array.isArray(input)) {
    return Object.keys(input).map(key => transform(input[key], options))
  }
  return transform(input, options)
}

const decamelizeFlagKey = flagKey =>
  `--${decamelize$2(flagKey, {
    separator: '-'
  })}`
const joinFlagKeys = (flagKeys, prefix = '--') =>
  `\`${prefix}${flagKeys.join(`\`, \`${prefix}`)}\``

const validateOptions = options => {
  const invalidOptionFilters = {
    flags: {
      keyContainsDashes: {
        filter: ([flagKey]) => flagKey.includes('-') && flagKey !== '--',
        message: flagKeys =>
          `Flag keys may not contain '-'. Invalid flags: ${joinFlagKeys(flagKeys, '')}`
      },
      aliasIsSet: {
        filter: ([, flag]) => Object.hasOwn(flag, 'alias'),
        message: flagKeys =>
          `The option \`alias\` has been renamed to \`shortFlag\`. The following flags need to be updated: ${joinFlagKeys(flagKeys)}`
      },
      choicesNotAnArray: {
        filter: ([, flag]) =>
          Object.hasOwn(flag, 'choices') && !Array.isArray(flag.choices),
        message: flagKeys =>
          `The option \`choices\` must be an array. Invalid flags: ${joinFlagKeys(flagKeys)}`
      },
      choicesNotMatchFlagType: {
        filter: ([, flag]) =>
          flag.type &&
          Array.isArray(flag.choices) &&
          flag.choices.some(choice => typeof choice !== flag.type),
        message(flagKeys) {
          const flagKeysAndTypes = flagKeys.map(
            flagKey =>
              `(\`${decamelizeFlagKey(flagKey)}\`, type: '${options.flags[flagKey].type}')`
          )
          return `Each value of the option \`choices\` must be of the same type as its flag. Invalid flags: ${flagKeysAndTypes.join(', ')}`
        }
      },
      defaultNotInChoices: {
        filter: ([, flag]) =>
          flag.default &&
          Array.isArray(flag.choices) &&
          ![flag.default].flat().every(value => flag.choices.includes(value)),
        message: flagKeys =>
          `Each value of the option \`default\` must exist within the option \`choices\`. Invalid flags: ${joinFlagKeys(flagKeys)}`
      }
    }
  }
  const errorMessages = []
  for (const [optionKey, filters] of Object.entries(invalidOptionFilters)) {
    const optionEntries = Object.entries(options[optionKey])
    for (const { filter, message } of Object.values(filters)) {
      const invalidOptions = optionEntries.filter(option => filter(option))
      const invalidOptionKeys = invalidOptions.map(([key]) => key)
      if (invalidOptions.length > 0) {
        errorMessages.push(message(invalidOptionKeys))
      }
    }
  }
  if (errorMessages.length > 0) {
    throw new Error(errorMessages.join('\n'))
  }
}
const buildOptions = (helpText, options) => {
  if (typeof helpText !== 'string') {
    options = helpText
    helpText = ''
  }
  if (!options.importMeta?.url) {
    throw new TypeError(
      'The `importMeta` option is required. Its value must be `import.meta`.'
    )
  }
  const foundPackage = readPackageUpSync({
    cwd: path$1.dirname(require$$0$b.fileURLToPath(options.importMeta.url)),
    normalize: false
  })
  const parsedOptions = {
    pkg: foundPackage ? foundPackage.packageJson : {},
    argv: process$2.argv.slice(2),
    flags: {},
    inferType: false,
    input: 'string',
    help: helpText,
    autoHelp: true,
    autoVersion: true,
    booleanDefault: false,
    allowUnknownFlags: true,
    allowParentFlags: true,
    helpIndent: 2,
    ...options
  }
  validateOptions(parsedOptions)
  return parsedOptions
}

const buildParserFlags = ({ flags, booleanDefault }) => {
  const parserFlags = {}
  for (const [flagKey, flagValue] of Object.entries(flags)) {
    const flag = {
      ...flagValue
    }

    // `minimist-options` expects `flag.alias`
    if (flag.shortFlag) {
      flag.alias = flag.shortFlag
      delete flag.shortFlag
    }
    if (
      booleanDefault !== undefined &&
      flag.type === 'boolean' &&
      !Object.hasOwn(flag, 'default')
    ) {
      flag.default = flag.isMultiple ? [booleanDefault] : booleanDefault
    }
    if (flag.isMultiple) {
      flag.type = flag.type ? `${flag.type}-array` : 'array'
      flag.default = flag.default ?? []
      delete flag.isMultiple
    }
    if (Array.isArray(flag.aliases)) {
      if (flag.alias) {
        flag.aliases.push(flag.alias)
      }
      flag.alias = flag.aliases
      delete flag.aliases
    }
    parserFlags[flagKey] = flag
  }
  return parserFlags
}
const buildParserOptions = options => {
  let parserOptions = buildParserFlags(options)
  parserOptions.arguments = options.input
  parserOptions = decamelizeKeys(parserOptions, {
    separator: '-',
    exclude: ['stopEarly', '--']
  })
  if (options.inferType) {
    delete parserOptions.arguments
  }

  // Add --help and --version to known flags if autoHelp or autoVersion are set
  if (!options.allowUnknownFlags) {
    if (options.autoHelp && !parserOptions.help) {
      parserOptions.help = {
        type: 'boolean'
      }
    }
    if (options.autoVersion && !parserOptions.version) {
      parserOptions.version = {
        type: 'boolean'
      }
    }
  }
  parserOptions = constructParserOptions(parserOptions)
  parserOptions.configuration = {
    ...parserOptions.configuration,
    'greedy-arrays': false
  }
  if (parserOptions['--']) {
    parserOptions.configuration['populate--'] = true
  }
  if (!options.allowUnknownFlags) {
    // Collect unknown options in `argv._` to be checked later.
    parserOptions.configuration['unknown-options-as-args'] = true
  }
  return parserOptions
}

const validateFlags = (flags, options) => {
  for (const [flagKey, flagValue] of Object.entries(options.flags)) {
    if (
      flagKey !== '--' &&
      !flagValue.isMultiple &&
      Array.isArray(flags[flagKey])
    ) {
      throw new Error(`The flag --${flagKey} can only be set once.`)
    }
  }
}
const validateChoicesByFlag = (flagKey, flagValue, receivedInput) => {
  const { choices, isRequired } = flagValue
  if (!choices) {
    return
  }
  const valueMustBeOneOf = `Value must be one of: [\`${choices.join('`, `')}\`]`
  if (!receivedInput) {
    if (isRequired) {
      return `Flag \`${decamelizeFlagKey(flagKey)}\` has no value. ${valueMustBeOneOf}`
    }
    return
  }
  if (Array.isArray(receivedInput)) {
    const unknownValues = receivedInput.filter(
      index => !choices.includes(index)
    )
    if (unknownValues.length > 0) {
      const valuesText = unknownValues.length > 1 ? 'values' : 'value'
      return `Unknown ${valuesText} for flag \`${decamelizeFlagKey(flagKey)}\`: \`${unknownValues.join('`, `')}\`. ${valueMustBeOneOf}`
    }
  } else if (!choices.includes(receivedInput)) {
    return `Unknown value for flag \`${decamelizeFlagKey(flagKey)}\`: \`${receivedInput}\`. ${valueMustBeOneOf}`
  }
}
const validateChoices = (flags, receivedFlags) => {
  const errors = []
  for (const [flagKey, flagValue] of Object.entries(flags)) {
    const receivedInput = receivedFlags[flagKey]
    const errorMessage = validateChoicesByFlag(
      flagKey,
      flagValue,
      receivedInput
    )
    if (errorMessage) {
      errors.push(errorMessage)
    }
  }
  if (errors.length > 0) {
    throw new Error(`${errors.join('\n')}`)
  }
}
const validate$1 = (flags, options) => {
  validateFlags(flags, options)
  validateChoices(options.flags, flags)
}
const reportUnknownFlags = unknownFlags => {
  console.error(
    [`Unknown flag${unknownFlags.length > 1 ? 's' : ''}`, ...unknownFlags].join(
      '\n'
    )
  )
}
const checkUnknownFlags = input => {
  const unknownFlags = input.filter(
    item => typeof item === 'string' && item.startsWith('-')
  )
  if (unknownFlags.length > 0) {
    reportUnknownFlags(unknownFlags)
    process$2.exit(2)
  }
}
const isFlagMissing = (flagName, definedFlags, receivedFlags, input) => {
  const flag = definedFlags[flagName]
  let isFlagRequired = true
  if (typeof flag.isRequired === 'function') {
    isFlagRequired = flag.isRequired(receivedFlags, input)
    if (typeof isFlagRequired !== 'boolean') {
      throw new TypeError(
        `Return value for isRequired callback should be of type boolean, but ${typeof isFlagRequired} was returned.`
      )
    }
  }
  if (receivedFlags[flagName] === undefined) {
    return isFlagRequired
  }
  return (
    flag.isMultiple && receivedFlags[flagName].length === 0 && isFlagRequired
  )
}
const reportMissingRequiredFlags = missingRequiredFlags => {
  console.error(
    `Missing required flag${missingRequiredFlags.length > 1 ? 's' : ''}`
  )
  for (const flag of missingRequiredFlags) {
    console.error(
      `\t${decamelizeFlagKey(flag.key)}${flag.shortFlag ? `, -${flag.shortFlag}` : ''}`
    )
  }
}
const checkMissingRequiredFlags = (flags, receivedFlags, input) => {
  const missingRequiredFlags = []
  if (flags === undefined) {
    return []
  }
  for (const flagName of Object.keys(flags)) {
    if (
      flags[flagName].isRequired &&
      isFlagMissing(flagName, flags, receivedFlags, input)
    ) {
      missingRequiredFlags.push({
        key: flagName,
        ...flags[flagName]
      })
    }
  }
  if (missingRequiredFlags.length > 0) {
    reportMissingRequiredFlags(missingRequiredFlags)
    process$2.exit(2)
  }
}

const buildResult = (options, parserOptions) => {
  const { pkg: package_ } = options
  const argv = yargsParser$1(options.argv, parserOptions)
  let help = ''
  if (options.help) {
    help = trimNewlines((options.help || '').replace(/\t+\n*$/, ''))
    if (help.includes('\n')) {
      help = redent(help, options.helpIndent)
    }
    help = `\n${help}`
  }
  normalizePackageData(package_)
  let { description } = options
  if (!description && description !== false) {
    ;({ description } = package_)
  }
  description &&= help
    ? redent(`\n${description}\n`, options.helpIndent)
    : `\n${description}`
  help = `${description || ''}${help}\n`
  const showHelp = code => {
    console.log(help)
    process$2.exit(typeof code === 'number' ? code : 2)
  }
  const showVersion = () => {
    console.log(
      typeof options.version === 'string' ? options.version : package_.version
    )
    process$2.exit(0)
  }
  if (argv._.length === 0 && options.argv.length === 1) {
    if (argv.version === true && options.autoVersion) {
      showVersion()
    } else if (argv.help === true && options.autoHelp) {
      showHelp(0)
    }
  }
  const input = argv._
  delete argv._
  if (!options.allowUnknownFlags) {
    checkUnknownFlags(input)
  }
  const flags = camelcaseKeys(argv, {
    exclude: ['--', /^\w$/]
  })
  const unnormalizedFlags = {
    ...flags
  }
  validate$1(flags, options)
  for (const flagValue of Object.values(options.flags)) {
    if (Array.isArray(flagValue.aliases)) {
      for (const alias of flagValue.aliases) {
        delete flags[alias]
      }
    }
    delete flags[flagValue.shortFlag]
  }
  checkMissingRequiredFlags(options.flags, flags, input)
  return {
    input,
    flags,
    unnormalizedFlags,
    pkg: package_,
    help,
    showHelp,
    showVersion
  }
}
const meow = (helpText, options = {}) => {
  const parsedOptions = buildOptions(helpText, options)
  const parserOptions = buildParserOptions(parsedOptions)
  const result = buildResult(parsedOptions, parserOptions)
  process$2.title = result.pkg.bin
    ? Object.keys(result.pkg.bin).at(0)
    : result.pkg.name
  return result
}

const re = { exports: {} }

let constants$1
let hasRequiredConstants$1
function requireConstants$1() {
  if (hasRequiredConstants$1) {
    return constants$1
  }
  hasRequiredConstants$1 = 1
  // Note: this is the semver.org version of the spec that it implements
  // Not necessarily the package version of this code.
  const SEMVER_SPEC_VERSION = '2.0.0'
  const MAX_LENGTH = 256
  const MAX_SAFE_INTEGER =
    Number.MAX_SAFE_INTEGER || /* istanbul ignore next */ 9007199254740991

  // Max safe segment length for coercion.
  const MAX_SAFE_COMPONENT_LENGTH = 16

  // Max safe length for a build identifier. The max length minus 6 characters for
  // the shortest version with a build 0.0.0+BUILD.
  const MAX_SAFE_BUILD_LENGTH = MAX_LENGTH - 6
  const RELEASE_TYPES = [
    'major',
    'premajor',
    'minor',
    'preminor',
    'patch',
    'prepatch',
    'prerelease'
  ]
  constants$1 = {
    MAX_LENGTH,
    MAX_SAFE_COMPONENT_LENGTH,
    MAX_SAFE_BUILD_LENGTH,
    MAX_SAFE_INTEGER,
    RELEASE_TYPES,
    SEMVER_SPEC_VERSION,
    FLAG_INCLUDE_PRERELEASE: 0b001,
    FLAG_LOOSE: 0b010
  }
  return constants$1
}

let debug_1
let hasRequiredDebug
function requireDebug() {
  if (hasRequiredDebug) {
    return debug_1
  }
  hasRequiredDebug = 1
  const debug =
    typeof process === 'object' &&
    process.env &&
    process.env.NODE_DEBUG &&
    /\bsemver\b/i.test(process.env.NODE_DEBUG)
      ? (...args) => console.error('SEMVER', ...args)
      : () => {}
  debug_1 = debug
  return debug_1
}

let hasRequiredRe
function requireRe() {
  if (hasRequiredRe) {
    return re.exports
  }
  hasRequiredRe = 1
  ;(function (module, exports) {
    const { MAX_SAFE_COMPONENT_LENGTH, MAX_SAFE_BUILD_LENGTH, MAX_LENGTH } =
      requireConstants$1()
    const debug = requireDebug()
    exports = module.exports = {}

    // The actual regexps go on exports.re
    const re = (exports.re = [])
    const safeRe = (exports.safeRe = [])
    const src = (exports.src = [])
    const safeSrc = (exports.safeSrc = [])
    const t = (exports.t = {})
    let R = 0
    const LETTERDASHNUMBER = '[a-zA-Z0-9-]'

    // Replace some greedy regex tokens to prevent regex dos issues. These regex are
    // used internally via the safeRe object since all inputs in this library get
    // normalized first to trim and collapse all extra whitespace. The original
    // regexes are exported for userland consumption and lower level usage. A
    // future breaking change could export the safer regex only with a note that
    // all input should have extra whitespace removed.
    const safeRegexReplacements = [
      ['\\s', 1],
      ['\\d', MAX_LENGTH],
      [LETTERDASHNUMBER, MAX_SAFE_BUILD_LENGTH]
    ]
    const makeSafeRegex = value => {
      for (const [token, max] of safeRegexReplacements) {
        value = value
          .split(`${token}*`)
          .join(`${token}{0,${max}}`)
          .split(`${token}+`)
          .join(`${token}{1,${max}}`)
      }
      return value
    }
    const createToken = (name, value, isGlobal) => {
      const safe = makeSafeRegex(value)
      const index = R++
      debug(name, index, value)
      t[name] = index
      src[index] = value
      safeSrc[index] = safe
      re[index] = new RegExp(value, isGlobal ? 'g' : undefined)
      safeRe[index] = new RegExp(safe, isGlobal ? 'g' : undefined)
    }

    // The following Regular Expressions can be used for tokenizing,
    // validating, and parsing SemVer version strings.

    // ## Numeric Identifier
    // A single `0`, or a non-zero digit followed by zero or more digits.

    createToken('NUMERICIDENTIFIER', '0|[1-9]\\d*')
    createToken('NUMERICIDENTIFIERLOOSE', '\\d+')

    // ## Non-numeric Identifier
    // Zero or more digits, followed by a letter or hyphen, and then zero or
    // more letters, digits, or hyphens.

    createToken('NONNUMERICIDENTIFIER', `\\d*[a-zA-Z-]${LETTERDASHNUMBER}*`)

    // ## Main Version
    // Three dot-separated numeric identifiers.

    createToken(
      'MAINVERSION',
      `(${src[t.NUMERICIDENTIFIER]})\\.` +
        `(${src[t.NUMERICIDENTIFIER]})\\.` +
        `(${src[t.NUMERICIDENTIFIER]})`
    )
    createToken(
      'MAINVERSIONLOOSE',
      `(${src[t.NUMERICIDENTIFIERLOOSE]})\\.` +
        `(${src[t.NUMERICIDENTIFIERLOOSE]})\\.` +
        `(${src[t.NUMERICIDENTIFIERLOOSE]})`
    )

    // ## Pre-release Version Identifier
    // A numeric identifier, or a non-numeric identifier.

    createToken(
      'PRERELEASEIDENTIFIER',
      `(?:${src[t.NUMERICIDENTIFIER]}|${src[t.NONNUMERICIDENTIFIER]})`
    )
    createToken(
      'PRERELEASEIDENTIFIERLOOSE',
      `(?:${src[t.NUMERICIDENTIFIERLOOSE]}|${src[t.NONNUMERICIDENTIFIER]})`
    )

    // ## Pre-release Version
    // Hyphen, followed by one or more dot-separated pre-release version
    // identifiers.

    createToken(
      'PRERELEASE',
      `(?:-(${src[t.PRERELEASEIDENTIFIER]}(?:\\.${src[t.PRERELEASEIDENTIFIER]})*))`
    )
    createToken(
      'PRERELEASELOOSE',
      `(?:-?(${src[t.PRERELEASEIDENTIFIERLOOSE]}(?:\\.${src[t.PRERELEASEIDENTIFIERLOOSE]})*))`
    )

    // ## Build Metadata Identifier
    // Any combination of digits, letters, or hyphens.

    createToken('BUILDIDENTIFIER', `${LETTERDASHNUMBER}+`)

    // ## Build Metadata
    // Plus sign, followed by one or more period-separated build metadata
    // identifiers.

    createToken(
      'BUILD',
      `(?:\\+(${src[t.BUILDIDENTIFIER]}(?:\\.${src[t.BUILDIDENTIFIER]})*))`
    )

    // ## Full Version String
    // A main version, followed optionally by a pre-release version and
    // build metadata.

    // Note that the only major, minor, patch, and pre-release sections of
    // the version string are capturing groups.  The build metadata is not a
    // capturing group, because it should not ever be used in version
    // comparison.

    createToken(
      'FULLPLAIN',
      `v?${src[t.MAINVERSION]}${src[t.PRERELEASE]}?${src[t.BUILD]}?`
    )
    createToken('FULL', `^${src[t.FULLPLAIN]}$`)

    // like full, but allows v1.2.3 and =1.2.3, which people do sometimes.
    // also, 1.0.0alpha1 (prerelease without the hyphen) which is pretty
    // common in the npm registry.
    createToken(
      'LOOSEPLAIN',
      `[v=\\s]*${src[t.MAINVERSIONLOOSE]}${src[t.PRERELEASELOOSE]}?${src[t.BUILD]}?`
    )
    createToken('LOOSE', `^${src[t.LOOSEPLAIN]}$`)
    createToken('GTLT', '((?:<|>)?=?)')

    // Something like "2.*" or "1.2.x".
    // Note that "x.x" is a valid xRange identifer, meaning "any version"
    // Only the first item is strictly required.
    createToken(
      'XRANGEIDENTIFIERLOOSE',
      `${src[t.NUMERICIDENTIFIERLOOSE]}|x|X|\\*`
    )
    createToken('XRANGEIDENTIFIER', `${src[t.NUMERICIDENTIFIER]}|x|X|\\*`)
    createToken(
      'XRANGEPLAIN',
      `[v=\\s]*(${src[t.XRANGEIDENTIFIER]})` +
        `(?:\\.(${src[t.XRANGEIDENTIFIER]})` +
        `(?:\\.(${src[t.XRANGEIDENTIFIER]})` +
        `(?:${src[t.PRERELEASE]})?${src[t.BUILD]}?` +
        `)?)?`
    )
    createToken(
      'XRANGEPLAINLOOSE',
      `[v=\\s]*(${src[t.XRANGEIDENTIFIERLOOSE]})` +
        `(?:\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +
        `(?:\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +
        `(?:${src[t.PRERELEASELOOSE]})?${src[t.BUILD]}?` +
        `)?)?`
    )
    createToken('XRANGE', `^${src[t.GTLT]}\\s*${src[t.XRANGEPLAIN]}$`)
    createToken('XRANGELOOSE', `^${src[t.GTLT]}\\s*${src[t.XRANGEPLAINLOOSE]}$`)

    // Coercion.
    // Extract anything that could conceivably be a part of a valid semver
    createToken(
      'COERCEPLAIN',
      `${'(^|[^\\d])' + '(\\d{1,'}${MAX_SAFE_COMPONENT_LENGTH}})` +
        `(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?` +
        `(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?`
    )
    createToken('COERCE', `${src[t.COERCEPLAIN]}(?:$|[^\\d])`)
    createToken(
      'COERCEFULL',
      src[t.COERCEPLAIN] +
        `(?:${src[t.PRERELEASE]})?` +
        `(?:${src[t.BUILD]})?` +
        `(?:$|[^\\d])`
    )
    createToken('COERCERTL', src[t.COERCE], true)
    createToken('COERCERTLFULL', src[t.COERCEFULL], true)

    // Tilde ranges.
    // Meaning is "reasonably at or greater than"
    createToken('LONETILDE', '(?:~>?)')
    createToken('TILDETRIM', `(\\s*)${src[t.LONETILDE]}\\s+`, true)
    exports.tildeTrimReplace = '$1~'
    createToken('TILDE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAIN]}$`)
    createToken('TILDELOOSE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAINLOOSE]}$`)

    // Caret ranges.
    // Meaning is "at least and backwards compatible with"
    createToken('LONECARET', '(?:\\^)')
    createToken('CARETTRIM', `(\\s*)${src[t.LONECARET]}\\s+`, true)
    exports.caretTrimReplace = '$1^'
    createToken('CARET', `^${src[t.LONECARET]}${src[t.XRANGEPLAIN]}$`)
    createToken('CARETLOOSE', `^${src[t.LONECARET]}${src[t.XRANGEPLAINLOOSE]}$`)

    // A simple gt/lt/eq thing, or just "" to indicate "any version"
    createToken(
      'COMPARATORLOOSE',
      `^${src[t.GTLT]}\\s*(${src[t.LOOSEPLAIN]})$|^$`
    )
    createToken('COMPARATOR', `^${src[t.GTLT]}\\s*(${src[t.FULLPLAIN]})$|^$`)

    // An expression to strip any whitespace between the gtlt and the thing
    // it modifies, so that `> 1.2.3` ==> `>1.2.3`
    createToken(
      'COMPARATORTRIM',
      `(\\s*)${src[t.GTLT]}\\s*(${src[t.LOOSEPLAIN]}|${src[t.XRANGEPLAIN]})`,
      true
    )
    exports.comparatorTrimReplace = '$1$2$3'

    // Something like `1.2.3 - 1.2.4`
    // Note that these all use the loose form, because they'll be
    // checked against either the strict or loose comparator form
    // later.
    createToken(
      'HYPHENRANGE',
      `^\\s*(${src[t.XRANGEPLAIN]})` +
        `\\s+-\\s+` +
        `(${src[t.XRANGEPLAIN]})` +
        `\\s*$`
    )
    createToken(
      'HYPHENRANGELOOSE',
      `^\\s*(${src[t.XRANGEPLAINLOOSE]})` +
        `\\s+-\\s+` +
        `(${src[t.XRANGEPLAINLOOSE]})` +
        `\\s*$`
    )

    // Star ranges basically just allow anything at all.
    createToken('STAR', '(<|>)?=?\\s*\\*')
    // >=0.0.0 is like a star
    createToken('GTE0', '^\\s*>=\\s*0\\.0\\.0\\s*$')
    createToken('GTE0PRE', '^\\s*>=\\s*0\\.0\\.0-0\\s*$')
  })(re, re.exports)
  return re.exports
}

let parseOptions_1
let hasRequiredParseOptions
function requireParseOptions() {
  if (hasRequiredParseOptions) {
    return parseOptions_1
  }
  hasRequiredParseOptions = 1
  // parse out just the options we care about
  const looseOption = Object.freeze({
    loose: true
  })
  const emptyOpts = Object.freeze({})
  const parseOptions = options => {
    if (!options) {
      return emptyOpts
    }
    if (typeof options !== 'object') {
      return looseOption
    }
    return options
  }
  parseOptions_1 = parseOptions
  return parseOptions_1
}

let identifiers
let hasRequiredIdentifiers
function requireIdentifiers() {
  if (hasRequiredIdentifiers) {
    return identifiers
  }
  hasRequiredIdentifiers = 1
  const numeric = /^[0-9]+$/
  const compareIdentifiers = (a, b) => {
    const anum = numeric.test(a)
    const bnum = numeric.test(b)
    if (anum && bnum) {
      a = +a
      b = +b
    }
    return a === b ? 0 : anum && !bnum ? -1 : bnum && !anum ? 1 : a < b ? -1 : 1
  }
  const rcompareIdentifiers = (a, b) => compareIdentifiers(b, a)
  identifiers = {
    compareIdentifiers,
    rcompareIdentifiers
  }
  return identifiers
}

let semver$1
let hasRequiredSemver$1
function requireSemver$1() {
  if (hasRequiredSemver$1) {
    return semver$1
  }
  hasRequiredSemver$1 = 1
  const debug = requireDebug()
  const { MAX_LENGTH, MAX_SAFE_INTEGER } = requireConstants$1()
  const { safeRe: re, safeSrc: src, t } = requireRe()
  const parseOptions = requireParseOptions()
  const { compareIdentifiers } = requireIdentifiers()
  class SemVer {
    constructor(version, options) {
      options = parseOptions(options)
      if (version instanceof SemVer) {
        if (
          version.loose === !!options.loose &&
          version.includePrerelease === !!options.includePrerelease
        ) {
          return version
        } else {
          version = version.version
        }
      } else if (typeof version !== 'string') {
        throw new TypeError(
          `Invalid version. Must be a string. Got type "${typeof version}".`
        )
      }
      if (version.length > MAX_LENGTH) {
        throw new TypeError(`version is longer than ${MAX_LENGTH} characters`)
      }
      debug('SemVer', version, options)
      this.options = options
      this.loose = !!options.loose
      // this isn't actually relevant for versions, but keep it so that we
      // don't run into trouble passing this.options around.
      this.includePrerelease = !!options.includePrerelease
      const m = version.trim().match(options.loose ? re[t.LOOSE] : re[t.FULL])
      if (!m) {
        throw new TypeError(`Invalid Version: ${version}`)
      }
      this.raw = version

      // these are actually numbers
      this.major = +m[1]
      this.minor = +m[2]
      this.patch = +m[3]
      if (this.major > MAX_SAFE_INTEGER || this.major < 0) {
        throw new TypeError('Invalid major version')
      }
      if (this.minor > MAX_SAFE_INTEGER || this.minor < 0) {
        throw new TypeError('Invalid minor version')
      }
      if (this.patch > MAX_SAFE_INTEGER || this.patch < 0) {
        throw new TypeError('Invalid patch version')
      }

      // numberify any prerelease numeric ids
      if (!m[4]) {
        this.prerelease = []
      } else {
        this.prerelease = m[4].split('.').map(id => {
          if (/^[0-9]+$/.test(id)) {
            const num = +id
            if (num >= 0 && num < MAX_SAFE_INTEGER) {
              return num
            }
          }
          return id
        })
      }
      this.build = m[5] ? m[5].split('.') : []
      this.format()
    }
    format() {
      this.version = `${this.major}.${this.minor}.${this.patch}`
      if (this.prerelease.length) {
        this.version += `-${this.prerelease.join('.')}`
      }
      return this.version
    }
    toString() {
      return this.version
    }
    compare(other) {
      debug('SemVer.compare', this.version, this.options, other)
      if (!(other instanceof SemVer)) {
        if (typeof other === 'string' && other === this.version) {
          return 0
        }
        other = new SemVer(other, this.options)
      }
      if (other.version === this.version) {
        return 0
      }
      return this.compareMain(other) || this.comparePre(other)
    }
    compareMain(other) {
      if (!(other instanceof SemVer)) {
        other = new SemVer(other, this.options)
      }
      return (
        compareIdentifiers(this.major, other.major) ||
        compareIdentifiers(this.minor, other.minor) ||
        compareIdentifiers(this.patch, other.patch)
      )
    }
    comparePre(other) {
      if (!(other instanceof SemVer)) {
        other = new SemVer(other, this.options)
      }

      // NOT having a prerelease is > having one
      if (this.prerelease.length && !other.prerelease.length) {
        return -1
      } else if (!this.prerelease.length && other.prerelease.length) {
        return 1
      } else if (!this.prerelease.length && !other.prerelease.length) {
        return 0
      }
      let i = 0
      do {
        const a = this.prerelease[i]
        const b = other.prerelease[i]
        debug('prerelease compare', i, a, b)
        if (a === undefined && b === undefined) {
          return 0
        } else if (b === undefined) {
          return 1
        } else if (a === undefined) {
          return -1
        } else if (a === b) {
          continue
        } else {
          return compareIdentifiers(a, b)
        }
      } while (++i)
    }
    compareBuild(other) {
      if (!(other instanceof SemVer)) {
        other = new SemVer(other, this.options)
      }
      let i = 0
      do {
        const a = this.build[i]
        const b = other.build[i]
        debug('build compare', i, a, b)
        if (a === undefined && b === undefined) {
          return 0
        } else if (b === undefined) {
          return 1
        } else if (a === undefined) {
          return -1
        } else if (a === b) {
          continue
        } else {
          return compareIdentifiers(a, b)
        }
      } while (++i)
    }

    // preminor will bump the version up to the next minor release, and immediately
    // down to pre-release. premajor and prepatch work the same way.
    inc(release, identifier, identifierBase) {
      if (release.startsWith('pre')) {
        if (!identifier && identifierBase === false) {
          throw new Error('invalid increment argument: identifier is empty')
        }
        // Avoid an invalid semver results
        if (identifier) {
          const r = new RegExp(
            `^${this.options.loose ? src[t.PRERELEASELOOSE] : src[t.PRERELEASE]}$`
          )
          const match = `-${identifier}`.match(r)
          if (!match || match[1] !== identifier) {
            throw new Error(`invalid identifier: ${identifier}`)
          }
        }
      }
      switch (release) {
        case 'premajor':
          this.prerelease.length = 0
          this.patch = 0
          this.minor = 0
          this.major++
          this.inc('pre', identifier, identifierBase)
          break
        case 'preminor':
          this.prerelease.length = 0
          this.patch = 0
          this.minor++
          this.inc('pre', identifier, identifierBase)
          break
        case 'prepatch':
          // If this is already a prerelease, it will bump to the next version
          // drop any prereleases that might already exist, since they are not
          // relevant at this point.
          this.prerelease.length = 0
          this.inc('patch', identifier, identifierBase)
          this.inc('pre', identifier, identifierBase)
          break
        // If the input is a non-prerelease version, this acts the same as
        // prepatch.
        case 'prerelease':
          if (this.prerelease.length === 0) {
            this.inc('patch', identifier, identifierBase)
          }
          this.inc('pre', identifier, identifierBase)
          break
        case 'release':
          if (this.prerelease.length === 0) {
            throw new Error(`version ${this.raw} is not a prerelease`)
          }
          this.prerelease.length = 0
          break
        case 'major':
          // If this is a pre-major version, bump up to the same major version.
          // Otherwise increment major.
          // 1.0.0-5 bumps to 1.0.0
          // 1.1.0 bumps to 2.0.0
          if (
            this.minor !== 0 ||
            this.patch !== 0 ||
            this.prerelease.length === 0
          ) {
            this.major++
          }
          this.minor = 0
          this.patch = 0
          this.prerelease = []
          break
        case 'minor':
          // If this is a pre-minor version, bump up to the same minor version.
          // Otherwise increment minor.
          // 1.2.0-5 bumps to 1.2.0
          // 1.2.1 bumps to 1.3.0
          if (this.patch !== 0 || this.prerelease.length === 0) {
            this.minor++
          }
          this.patch = 0
          this.prerelease = []
          break
        case 'patch':
          // If this is not a pre-release version, it will increment the patch.
          // If it is a pre-release it will bump up to the same patch version.
          // 1.2.0-5 patches to 1.2.0
          // 1.2.0 patches to 1.2.1
          if (this.prerelease.length === 0) {
            this.patch++
          }
          this.prerelease = []
          break
        // This probably shouldn't be used publicly.
        // 1.0.0 'pre' would become 1.0.0-0 which is the wrong direction.
        case 'pre': {
          const base = Number(identifierBase) ? 1 : 0
          if (this.prerelease.length === 0) {
            this.prerelease = [base]
          } else {
            let i = this.prerelease.length
            while (--i >= 0) {
              if (typeof this.prerelease[i] === 'number') {
                this.prerelease[i]++
                i = -2
              }
            }
            if (i === -1) {
              // didn't increment anything
              if (
                identifier === this.prerelease.join('.') &&
                identifierBase === false
              ) {
                throw new Error(
                  'invalid increment argument: identifier already exists'
                )
              }
              this.prerelease.push(base)
            }
          }
          if (identifier) {
            // 1.2.0-beta.1 bumps to 1.2.0-beta.2,
            // 1.2.0-beta.fooblz or 1.2.0-beta bumps to 1.2.0-beta.0
            let prerelease = [identifier, base]
            if (identifierBase === false) {
              prerelease = [identifier]
            }
            if (compareIdentifiers(this.prerelease[0], identifier) === 0) {
              if (isNaN(this.prerelease[1])) {
                this.prerelease = prerelease
              }
            } else {
              this.prerelease = prerelease
            }
          }
          break
        }
        default:
          throw new Error(`invalid increment argument: ${release}`)
      }
      this.raw = this.format()
      if (this.build.length) {
        this.raw += `+${this.build.join('.')}`
      }
      return this
    }
  }
  semver$1 = SemVer
  return semver$1
}

let parse_1$1
let hasRequiredParse$2
function requireParse$2() {
  if (hasRequiredParse$2) {
    return parse_1$1
  }
  hasRequiredParse$2 = 1
  const SemVer = requireSemver$1()
  const parse = (version, options, throwErrors = false) => {
    if (version instanceof SemVer) {
      return version
    }
    try {
      return new SemVer(version, options)
    } catch (er) {
      if (!throwErrors) {
        return null
      }
      throw er
    }
  }
  parse_1$1 = parse
  return parse_1$1
}

let valid_1
let hasRequiredValid$1
function requireValid$1() {
  if (hasRequiredValid$1) {
    return valid_1
  }
  hasRequiredValid$1 = 1
  const parse = requireParse$2()
  const valid = (version, options) => {
    const v = parse(version, options)
    return v ? v.version : null
  }
  valid_1 = valid
  return valid_1
}

let clean_1
let hasRequiredClean
function requireClean() {
  if (hasRequiredClean) {
    return clean_1
  }
  hasRequiredClean = 1
  const parse = requireParse$2()
  const clean = (version, options) => {
    const s = parse(version.trim().replace(/^[=v]+/, ''), options)
    return s ? s.version : null
  }
  clean_1 = clean
  return clean_1
}

let inc_1
let hasRequiredInc
function requireInc() {
  if (hasRequiredInc) {
    return inc_1
  }
  hasRequiredInc = 1
  const SemVer = requireSemver$1()
  const inc = (version, release, options, identifier, identifierBase) => {
    if (typeof options === 'string') {
      identifierBase = identifier
      identifier = options
      options = undefined
    }
    try {
      return new SemVer(
        version instanceof SemVer ? version.version : version,
        options
      ).inc(release, identifier, identifierBase).version
    } catch (er) {
      return null
    }
  }
  inc_1 = inc
  return inc_1
}

let diff_1
let hasRequiredDiff
function requireDiff() {
  if (hasRequiredDiff) {
    return diff_1
  }
  hasRequiredDiff = 1
  const parse = requireParse$2()
  const diff = (version1, version2) => {
    const v1 = parse(version1, null, true)
    const v2 = parse(version2, null, true)
    const comparison = v1.compare(v2)
    if (comparison === 0) {
      return null
    }
    const v1Higher = comparison > 0
    const highVersion = v1Higher ? v1 : v2
    const lowVersion = v1Higher ? v2 : v1
    const highHasPre = !!highVersion.prerelease.length
    const lowHasPre = !!lowVersion.prerelease.length
    if (lowHasPre && !highHasPre) {
      // Going from prerelease -> no prerelease requires some special casing

      // If the low version has only a major, then it will always be a major
      // Some examples:
      // 1.0.0-1 -> 1.0.0
      // 1.0.0-1 -> 1.1.1
      // 1.0.0-1 -> 2.0.0
      if (!lowVersion.patch && !lowVersion.minor) {
        return 'major'
      }

      // If the main part has no difference
      if (lowVersion.compareMain(highVersion) === 0) {
        if (lowVersion.minor && !lowVersion.patch) {
          return 'minor'
        }
        return 'patch'
      }
    }

    // add the `pre` prefix if we are going to a prerelease version
    const prefix = highHasPre ? 'pre' : ''
    if (v1.major !== v2.major) {
      return prefix + 'major'
    }
    if (v1.minor !== v2.minor) {
      return prefix + 'minor'
    }
    if (v1.patch !== v2.patch) {
      return prefix + 'patch'
    }

    // high and low are preleases
    return 'prerelease'
  }
  diff_1 = diff
  return diff_1
}

let major_1
let hasRequiredMajor
function requireMajor() {
  if (hasRequiredMajor) {
    return major_1
  }
  hasRequiredMajor = 1
  const SemVer = requireSemver$1()
  const major = (a, loose) => new SemVer(a, loose).major
  major_1 = major
  return major_1
}

let minor_1
let hasRequiredMinor
function requireMinor() {
  if (hasRequiredMinor) {
    return minor_1
  }
  hasRequiredMinor = 1
  const SemVer = requireSemver$1()
  const minor = (a, loose) => new SemVer(a, loose).minor
  minor_1 = minor
  return minor_1
}

let patch_1
let hasRequiredPatch
function requirePatch() {
  if (hasRequiredPatch) {
    return patch_1
  }
  hasRequiredPatch = 1
  const SemVer = requireSemver$1()
  const patch = (a, loose) => new SemVer(a, loose).patch
  patch_1 = patch
  return patch_1
}

let prerelease_1
let hasRequiredPrerelease
function requirePrerelease() {
  if (hasRequiredPrerelease) {
    return prerelease_1
  }
  hasRequiredPrerelease = 1
  const parse = requireParse$2()
  const prerelease = (version, options) => {
    const parsed = parse(version, options)
    return parsed && parsed.prerelease.length ? parsed.prerelease : null
  }
  prerelease_1 = prerelease
  return prerelease_1
}

let compare_1
let hasRequiredCompare
function requireCompare() {
  if (hasRequiredCompare) {
    return compare_1
  }
  hasRequiredCompare = 1
  const SemVer = requireSemver$1()
  const compare = (a, b, loose) =>
    new SemVer(a, loose).compare(new SemVer(b, loose))
  compare_1 = compare
  return compare_1
}

let rcompare_1
let hasRequiredRcompare
function requireRcompare() {
  if (hasRequiredRcompare) {
    return rcompare_1
  }
  hasRequiredRcompare = 1
  const compare = requireCompare()
  const rcompare = (a, b, loose) => compare(b, a, loose)
  rcompare_1 = rcompare
  return rcompare_1
}

let compareLoose_1
let hasRequiredCompareLoose
function requireCompareLoose() {
  if (hasRequiredCompareLoose) {
    return compareLoose_1
  }
  hasRequiredCompareLoose = 1
  const compare = requireCompare()
  const compareLoose = (a, b) => compare(a, b, true)
  compareLoose_1 = compareLoose
  return compareLoose_1
}

let compareBuild_1
let hasRequiredCompareBuild
function requireCompareBuild() {
  if (hasRequiredCompareBuild) {
    return compareBuild_1
  }
  hasRequiredCompareBuild = 1
  const SemVer = requireSemver$1()
  const compareBuild = (a, b, loose) => {
    const versionA = new SemVer(a, loose)
    const versionB = new SemVer(b, loose)
    return versionA.compare(versionB) || versionA.compareBuild(versionB)
  }
  compareBuild_1 = compareBuild
  return compareBuild_1
}

let sort_1
let hasRequiredSort
function requireSort() {
  if (hasRequiredSort) {
    return sort_1
  }
  hasRequiredSort = 1
  const compareBuild = requireCompareBuild()
  const sort = (list, loose) => list.sort((a, b) => compareBuild(a, b, loose))
  sort_1 = sort
  return sort_1
}

let rsort_1
let hasRequiredRsort
function requireRsort() {
  if (hasRequiredRsort) {
    return rsort_1
  }
  hasRequiredRsort = 1
  const compareBuild = requireCompareBuild()
  const rsort = (list, loose) => list.sort((a, b) => compareBuild(b, a, loose))
  rsort_1 = rsort
  return rsort_1
}

let gt_1
let hasRequiredGt
function requireGt() {
  if (hasRequiredGt) {
    return gt_1
  }
  hasRequiredGt = 1
  const compare = requireCompare()
  const gt = (a, b, loose) => compare(a, b, loose) > 0
  gt_1 = gt
  return gt_1
}

let lt_1
let hasRequiredLt
function requireLt() {
  if (hasRequiredLt) {
    return lt_1
  }
  hasRequiredLt = 1
  const compare = requireCompare()
  const lt = (a, b, loose) => compare(a, b, loose) < 0
  lt_1 = lt
  return lt_1
}

let eq_1
let hasRequiredEq
function requireEq() {
  if (hasRequiredEq) {
    return eq_1
  }
  hasRequiredEq = 1
  const compare = requireCompare()
  const eq = (a, b, loose) => compare(a, b, loose) === 0
  eq_1 = eq
  return eq_1
}

let neq_1
let hasRequiredNeq
function requireNeq() {
  if (hasRequiredNeq) {
    return neq_1
  }
  hasRequiredNeq = 1
  const compare = requireCompare()
  const neq = (a, b, loose) => compare(a, b, loose) !== 0
  neq_1 = neq
  return neq_1
}

let gte_1
let hasRequiredGte
function requireGte() {
  if (hasRequiredGte) {
    return gte_1
  }
  hasRequiredGte = 1
  const compare = requireCompare()
  const gte = (a, b, loose) => compare(a, b, loose) >= 0
  gte_1 = gte
  return gte_1
}

let lte_1
let hasRequiredLte
function requireLte() {
  if (hasRequiredLte) {
    return lte_1
  }
  hasRequiredLte = 1
  const compare = requireCompare()
  const lte = (a, b, loose) => compare(a, b, loose) <= 0
  lte_1 = lte
  return lte_1
}

let cmp_1
let hasRequiredCmp
function requireCmp() {
  if (hasRequiredCmp) {
    return cmp_1
  }
  hasRequiredCmp = 1
  const eq = requireEq()
  const neq = requireNeq()
  const gt = requireGt()
  const gte = requireGte()
  const lt = requireLt()
  const lte = requireLte()
  const cmp = (a, op, b, loose) => {
    switch (op) {
      case '===':
        if (typeof a === 'object') {
          a = a.version
        }
        if (typeof b === 'object') {
          b = b.version
        }
        return a === b
      case '!==':
        if (typeof a === 'object') {
          a = a.version
        }
        if (typeof b === 'object') {
          b = b.version
        }
        return a !== b
      case '':
      case '=':
      case '==':
        return eq(a, b, loose)
      case '!=':
        return neq(a, b, loose)
      case '>':
        return gt(a, b, loose)
      case '>=':
        return gte(a, b, loose)
      case '<':
        return lt(a, b, loose)
      case '<=':
        return lte(a, b, loose)
      default:
        throw new TypeError(`Invalid operator: ${op}`)
    }
  }
  cmp_1 = cmp
  return cmp_1
}

let coerce_1
let hasRequiredCoerce
function requireCoerce() {
  if (hasRequiredCoerce) {
    return coerce_1
  }
  hasRequiredCoerce = 1
  const SemVer = requireSemver$1()
  const parse = requireParse$2()
  const { safeRe: re, t } = requireRe()
  const coerce = (version, options) => {
    if (version instanceof SemVer) {
      return version
    }
    if (typeof version === 'number') {
      version = String(version)
    }
    if (typeof version !== 'string') {
      return null
    }
    options = options || {}
    let match = null
    if (!options.rtl) {
      match = version.match(
        options.includePrerelease ? re[t.COERCEFULL] : re[t.COERCE]
      )
    } else {
      // Find the right-most coercible string that does not share
      // a terminus with a more left-ward coercible string.
      // Eg, '1.2.3.4' wants to coerce '2.3.4', not '3.4' or '4'
      // With includePrerelease option set, '1.2.3.4-rc' wants to coerce '2.3.4-rc', not '2.3.4'
      //
      // Walk through the string checking with a /g regexp
      // Manually set the index so as to pick up overlapping matches.
      // Stop when we get a match that ends at the string end, since no
      // coercible string can be more right-ward without the same terminus.
      const coerceRtlRegex = options.includePrerelease
        ? re[t.COERCERTLFULL]
        : re[t.COERCERTL]
      let next
      while (
        (next = coerceRtlRegex.exec(version)) &&
        (!match || match.index + match[0].length !== version.length)
      ) {
        if (
          !match ||
          next.index + next[0].length !== match.index + match[0].length
        ) {
          match = next
        }
        coerceRtlRegex.lastIndex = next.index + next[1].length + next[2].length
      }
      // leave it in a clean state
      coerceRtlRegex.lastIndex = -1
    }
    if (match === null) {
      return null
    }
    const major = match[2]
    const minor = match[3] || '0'
    const patch = match[4] || '0'
    const prerelease =
      options.includePrerelease && match[5] ? `-${match[5]}` : ''
    const build = options.includePrerelease && match[6] ? `+${match[6]}` : ''
    return parse(`${major}.${minor}.${patch}${prerelease}${build}`, options)
  }
  coerce_1 = coerce
  return coerce_1
}

let lrucache
let hasRequiredLrucache
function requireLrucache() {
  if (hasRequiredLrucache) {
    return lrucache
  }
  hasRequiredLrucache = 1
  class LRUCache {
    constructor() {
      this.max = 1000
      this.map = new Map()
    }
    get(key) {
      const value = this.map.get(key)
      if (value === undefined) {
        return undefined
      } else {
        // Remove the key from the map and add it to the end
        this.map.delete(key)
        this.map.set(key, value)
        return value
      }
    }
    delete(key) {
      return this.map.delete(key)
    }
    set(key, value) {
      const deleted = this.delete(key)
      if (!deleted && value !== undefined) {
        // If cache is full, delete the least recently used item
        if (this.map.size >= this.max) {
          const firstKey = this.map.keys().next().value
          this.delete(firstKey)
        }
        this.map.set(key, value)
      }
      return this
    }
  }
  lrucache = LRUCache
  return lrucache
}

let range
let hasRequiredRange
function requireRange() {
  if (hasRequiredRange) {
    return range
  }
  hasRequiredRange = 1
  const SPACE_CHARACTERS = /\s+/g

  // hoisted class for cyclic dependency
  class Range {
    constructor(range, options) {
      options = parseOptions(options)
      if (range instanceof Range) {
        if (
          range.loose === !!options.loose &&
          range.includePrerelease === !!options.includePrerelease
        ) {
          return range
        } else {
          return new Range(range.raw, options)
        }
      }
      if (range instanceof Comparator) {
        // just put it in the set and return
        this.raw = range.value
        this.set = [[range]]
        this.formatted = undefined
        return this
      }
      this.options = options
      this.loose = !!options.loose
      this.includePrerelease = !!options.includePrerelease

      // First reduce all whitespace as much as possible so we do not have to rely
      // on potentially slow regexes like \s*. This is then stored and used for
      // future error messages as well.
      this.raw = range.trim().replace(SPACE_CHARACTERS, ' ')

      // First, split on ||
      this.set = this.raw
        .split('||')
        // map the range to a 2d array of comparators
        .map(r => this.parseRange(r.trim()))
        // throw out any comparator lists that are empty
        // this generally means that it was not a valid range, which is allowed
        // in loose mode, but will still throw if the WHOLE range is invalid.
        .filter(c => c.length)
      if (!this.set.length) {
        throw new TypeError(`Invalid SemVer Range: ${this.raw}`)
      }

      // if we have any that are not the null set, throw out null sets.
      if (this.set.length > 1) {
        // keep the first one, in case they're all null sets
        const first = this.set[0]
        this.set = this.set.filter(c => !isNullSet(c[0]))
        if (this.set.length === 0) {
          this.set = [first]
        } else if (this.set.length > 1) {
          // if we have any that are *, then the range is just *
          for (const c of this.set) {
            if (c.length === 1 && isAny(c[0])) {
              this.set = [c]
              break
            }
          }
        }
      }
      this.formatted = undefined
    }
    get range() {
      if (this.formatted === undefined) {
        this.formatted = ''
        for (let i = 0; i < this.set.length; i++) {
          if (i > 0) {
            this.formatted += '||'
          }
          const comps = this.set[i]
          for (let k = 0; k < comps.length; k++) {
            if (k > 0) {
              this.formatted += ' '
            }
            this.formatted += comps[k].toString().trim()
          }
        }
      }
      return this.formatted
    }
    format() {
      return this.range
    }
    toString() {
      return this.range
    }
    parseRange(range) {
      // memoize range parsing for performance.
      // this is a very hot path, and fully deterministic.
      const memoOpts =
        (this.options.includePrerelease && FLAG_INCLUDE_PRERELEASE) |
        (this.options.loose && FLAG_LOOSE)
      const memoKey = memoOpts + ':' + range
      const cached = cache.get(memoKey)
      if (cached) {
        return cached
      }
      const loose = this.options.loose
      // `1.2.3 - 1.2.4` => `>=1.2.3 <=1.2.4`
      const hr = loose ? re[t.HYPHENRANGELOOSE] : re[t.HYPHENRANGE]
      range = range.replace(hr, hyphenReplace(this.options.includePrerelease))
      debug('hyphen replace', range)

      // `> 1.2.3 < 1.2.5` => `>1.2.3 <1.2.5`
      range = range.replace(re[t.COMPARATORTRIM], comparatorTrimReplace)
      debug('comparator trim', range)

      // `~ 1.2.3` => `~1.2.3`
      range = range.replace(re[t.TILDETRIM], tildeTrimReplace)
      debug('tilde trim', range)

      // `^ 1.2.3` => `^1.2.3`
      range = range.replace(re[t.CARETTRIM], caretTrimReplace)
      debug('caret trim', range)

      // At this point, the range is completely trimmed and
      // ready to be split into comparators.

      let rangeList = range
        .split(' ')
        .map(comp => parseComparator(comp, this.options))
        .join(' ')
        .split(/\s+/)
        // >=0.0.0 is equivalent to *
        .map(comp => replaceGTE0(comp, this.options))
      if (loose) {
        // in loose mode, throw out any that are not valid comparators
        rangeList = rangeList.filter(comp => {
          debug('loose invalid filter', comp, this.options)
          return !!comp.match(re[t.COMPARATORLOOSE])
        })
      }
      debug('range list', rangeList)

      // if any comparators are the null set, then replace with JUST null set
      // if more than one comparator, remove any * comparators
      // also, don't include the same comparator more than once
      const rangeMap = new Map()
      const comparators = rangeList.map(
        comp => new Comparator(comp, this.options)
      )
      for (const comp of comparators) {
        if (isNullSet(comp)) {
          return [comp]
        }
        rangeMap.set(comp.value, comp)
      }
      if (rangeMap.size > 1 && rangeMap.has('')) {
        rangeMap.delete('')
      }
      const result = [...rangeMap.values()]
      cache.set(memoKey, result)
      return result
    }
    intersects(range, options) {
      if (!(range instanceof Range)) {
        throw new TypeError('a Range is required')
      }
      return this.set.some(thisComparators => {
        return (
          isSatisfiable(thisComparators, options) &&
          range.set.some(rangeComparators => {
            return (
              isSatisfiable(rangeComparators, options) &&
              thisComparators.every(thisComparator => {
                return rangeComparators.every(rangeComparator => {
                  return thisComparator.intersects(rangeComparator, options)
                })
              })
            )
          })
        )
      })
    }

    // if ANY of the sets match ALL of its comparators, then pass
    test(version) {
      if (!version) {
        return false
      }
      if (typeof version === 'string') {
        try {
          version = new SemVer(version, this.options)
        } catch (er) {
          return false
        }
      }
      for (let i = 0; i < this.set.length; i++) {
        if (testSet(this.set[i], version, this.options)) {
          return true
        }
      }
      return false
    }
  }
  range = Range
  const LRU = requireLrucache()
  const cache = new LRU()
  const parseOptions = requireParseOptions()
  const Comparator = requireComparator()
  const debug = requireDebug()
  const SemVer = requireSemver$1()
  const {
    safeRe: re,
    t,
    comparatorTrimReplace,
    tildeTrimReplace,
    caretTrimReplace
  } = requireRe()
  const { FLAG_INCLUDE_PRERELEASE, FLAG_LOOSE } = requireConstants$1()
  const isNullSet = c => c.value === '<0.0.0-0'
  const isAny = c => c.value === ''

  // take a set of comparators and determine whether there
  // exists a version which can satisfy it
  const isSatisfiable = (comparators, options) => {
    let result = true
    const remainingComparators = comparators.slice()
    let testComparator = remainingComparators.pop()
    while (result && remainingComparators.length) {
      result = remainingComparators.every(otherComparator => {
        return testComparator.intersects(otherComparator, options)
      })
      testComparator = remainingComparators.pop()
    }
    return result
  }

  // comprised of xranges, tildes, stars, and gtlt's at this point.
  // already replaced the hyphen ranges
  // turn into a set of JUST comparators.
  const parseComparator = (comp, options) => {
    debug('comp', comp, options)
    comp = replaceCarets(comp, options)
    debug('caret', comp)
    comp = replaceTildes(comp, options)
    debug('tildes', comp)
    comp = replaceXRanges(comp, options)
    debug('xrange', comp)
    comp = replaceStars(comp, options)
    debug('stars', comp)
    return comp
  }
  const isX = id => !id || id.toLowerCase() === 'x' || id === '*'

  // ~, ~> --> * (any, kinda silly)
  // ~2, ~2.x, ~2.x.x, ~>2, ~>2.x ~>2.x.x --> >=2.0.0 <3.0.0-0
  // ~2.0, ~2.0.x, ~>2.0, ~>2.0.x --> >=2.0.0 <2.1.0-0
  // ~1.2, ~1.2.x, ~>1.2, ~>1.2.x --> >=1.2.0 <1.3.0-0
  // ~1.2.3, ~>1.2.3 --> >=1.2.3 <1.3.0-0
  // ~1.2.0, ~>1.2.0 --> >=1.2.0 <1.3.0-0
  // ~0.0.1 --> >=0.0.1 <0.1.0-0
  const replaceTildes = (comp, options) => {
    return comp
      .trim()
      .split(/\s+/)
      .map(c => replaceTilde(c, options))
      .join(' ')
  }
  const replaceTilde = (comp, options) => {
    const r = options.loose ? re[t.TILDELOOSE] : re[t.TILDE]
    return comp.replace(r, (_, M, m, p, pr) => {
      debug('tilde', comp, _, M, m, p, pr)
      let ret
      if (isX(M)) {
        ret = ''
      } else if (isX(m)) {
        ret = `>=${M}.0.0 <${+M + 1}.0.0-0`
      } else if (isX(p)) {
        // ~1.2 == >=1.2.0 <1.3.0-0
        ret = `>=${M}.${m}.0 <${M}.${+m + 1}.0-0`
      } else if (pr) {
        debug('replaceTilde pr', pr)
        ret = `>=${M}.${m}.${p}-${pr} <${M}.${+m + 1}.0-0`
      } else {
        // ~1.2.3 == >=1.2.3 <1.3.0-0
        ret = `>=${M}.${m}.${p} <${M}.${+m + 1}.0-0`
      }
      debug('tilde return', ret)
      return ret
    })
  }

  // ^ --> * (any, kinda silly)
  // ^2, ^2.x, ^2.x.x --> >=2.0.0 <3.0.0-0
  // ^2.0, ^2.0.x --> >=2.0.0 <3.0.0-0
  // ^1.2, ^1.2.x --> >=1.2.0 <2.0.0-0
  // ^1.2.3 --> >=1.2.3 <2.0.0-0
  // ^1.2.0 --> >=1.2.0 <2.0.0-0
  // ^0.0.1 --> >=0.0.1 <0.0.2-0
  // ^0.1.0 --> >=0.1.0 <0.2.0-0
  const replaceCarets = (comp, options) => {
    return comp
      .trim()
      .split(/\s+/)
      .map(c => replaceCaret(c, options))
      .join(' ')
  }
  const replaceCaret = (comp, options) => {
    debug('caret', comp, options)
    const r = options.loose ? re[t.CARETLOOSE] : re[t.CARET]
    const z = options.includePrerelease ? '-0' : ''
    return comp.replace(r, (_, M, m, p, pr) => {
      debug('caret', comp, _, M, m, p, pr)
      let ret
      if (isX(M)) {
        ret = ''
      } else if (isX(m)) {
        ret = `>=${M}.0.0${z} <${+M + 1}.0.0-0`
      } else if (isX(p)) {
        if (M === '0') {
          ret = `>=${M}.${m}.0${z} <${M}.${+m + 1}.0-0`
        } else {
          ret = `>=${M}.${m}.0${z} <${+M + 1}.0.0-0`
        }
      } else if (pr) {
        debug('replaceCaret pr', pr)
        if (M === '0') {
          if (m === '0') {
            ret = `>=${M}.${m}.${p}-${pr} <${M}.${m}.${+p + 1}-0`
          } else {
            ret = `>=${M}.${m}.${p}-${pr} <${M}.${+m + 1}.0-0`
          }
        } else {
          ret = `>=${M}.${m}.${p}-${pr} <${+M + 1}.0.0-0`
        }
      } else {
        debug('no pr')
        if (M === '0') {
          if (m === '0') {
            ret = `>=${M}.${m}.${p}${z} <${M}.${m}.${+p + 1}-0`
          } else {
            ret = `>=${M}.${m}.${p}${z} <${M}.${+m + 1}.0-0`
          }
        } else {
          ret = `>=${M}.${m}.${p} <${+M + 1}.0.0-0`
        }
      }
      debug('caret return', ret)
      return ret
    })
  }
  const replaceXRanges = (comp, options) => {
    debug('replaceXRanges', comp, options)
    return comp
      .split(/\s+/)
      .map(c => replaceXRange(c, options))
      .join(' ')
  }
  const replaceXRange = (comp, options) => {
    comp = comp.trim()
    const r = options.loose ? re[t.XRANGELOOSE] : re[t.XRANGE]
    return comp.replace(r, (ret, gtlt, M, m, p, pr) => {
      debug('xRange', comp, ret, gtlt, M, m, p, pr)
      const xM = isX(M)
      const xm = xM || isX(m)
      const xp = xm || isX(p)
      const anyX = xp
      if (gtlt === '=' && anyX) {
        gtlt = ''
      }

      // if we're including prereleases in the match, then we need
      // to fix this to -0, the lowest possible prerelease value
      pr = options.includePrerelease ? '-0' : ''
      if (xM) {
        if (gtlt === '>' || gtlt === '<') {
          // nothing is allowed
          ret = '<0.0.0-0'
        } else {
          // nothing is forbidden
          ret = '*'
        }
      } else if (gtlt && anyX) {
        // we know patch is an x, because we have any x at all.
        // replace X with 0
        if (xm) {
          m = 0
        }
        p = 0
        if (gtlt === '>') {
          // >1 => >=2.0.0
          // >1.2 => >=1.3.0
          gtlt = '>='
          if (xm) {
            M = +M + 1
            m = 0
            p = 0
          } else {
            m = +m + 1
            p = 0
          }
        } else if (gtlt === '<=') {
          // <=0.7.x is actually <0.8.0, since any 0.7.x should
          // pass.  Similarly, <=7.x is actually <8.0.0, etc.
          gtlt = '<'
          if (xm) {
            M = +M + 1
          } else {
            m = +m + 1
          }
        }
        if (gtlt === '<') {
          pr = '-0'
        }
        ret = `${gtlt + M}.${m}.${p}${pr}`
      } else if (xm) {
        ret = `>=${M}.0.0${pr} <${+M + 1}.0.0-0`
      } else if (xp) {
        ret = `>=${M}.${m}.0${pr} <${M}.${+m + 1}.0-0`
      }
      debug('xRange return', ret)
      return ret
    })
  }

  // Because * is AND-ed with everything else in the comparator,
  // and '' means "any version", just remove the *s entirely.
  const replaceStars = (comp, options) => {
    debug('replaceStars', comp, options)
    // Looseness is ignored here.  star is always as loose as it gets!
    return comp.trim().replace(re[t.STAR], '')
  }
  const replaceGTE0 = (comp, options) => {
    debug('replaceGTE0', comp, options)
    return comp
      .trim()
      .replace(re[options.includePrerelease ? t.GTE0PRE : t.GTE0], '')
  }

  // This function is passed to string.replace(re[t.HYPHENRANGE])
  // M, m, patch, prerelease, build
  // 1.2 - 3.4.5 => >=1.2.0 <=3.4.5
  // 1.2.3 - 3.4 => >=1.2.0 <3.5.0-0 Any 3.4.x will do
  // 1.2 - 3.4 => >=1.2.0 <3.5.0-0
  // TODO build?
  const hyphenReplace =
    incPr => ($0, from, fM, fm, fp, fpr, fb, to, tM, tm, tp, tpr) => {
      if (isX(fM)) {
        from = ''
      } else if (isX(fm)) {
        from = `>=${fM}.0.0${incPr ? '-0' : ''}`
      } else if (isX(fp)) {
        from = `>=${fM}.${fm}.0${incPr ? '-0' : ''}`
      } else if (fpr) {
        from = `>=${from}`
      } else {
        from = `>=${from}${incPr ? '-0' : ''}`
      }
      if (isX(tM)) {
        to = ''
      } else if (isX(tm)) {
        to = `<${+tM + 1}.0.0-0`
      } else if (isX(tp)) {
        to = `<${tM}.${+tm + 1}.0-0`
      } else if (tpr) {
        to = `<=${tM}.${tm}.${tp}-${tpr}`
      } else if (incPr) {
        to = `<${tM}.${tm}.${+tp + 1}-0`
      } else {
        to = `<=${to}`
      }
      return `${from} ${to}`.trim()
    }
  const testSet = (set, version, options) => {
    for (let i = 0; i < set.length; i++) {
      if (!set[i].test(version)) {
        return false
      }
    }
    if (version.prerelease.length && !options.includePrerelease) {
      // Find the set of versions that are allowed to have prereleases
      // For example, ^1.2.3-pr.1 desugars to >=1.2.3-pr.1 <2.0.0
      // That should allow `1.2.3-pr.2` to pass.
      // However, `1.2.4-alpha.notready` should NOT be allowed,
      // even though it's within the range set by the comparators.
      for (let i = 0; i < set.length; i++) {
        debug(set[i].semver)
        if (set[i].semver === Comparator.ANY) {
          continue
        }
        if (set[i].semver.prerelease.length > 0) {
          const allowed = set[i].semver
          if (
            allowed.major === version.major &&
            allowed.minor === version.minor &&
            allowed.patch === version.patch
          ) {
            return true
          }
        }
      }

      // Version has a -pre, but it's not one of the ones we like.
      return false
    }
    return true
  }
  return range
}

let comparator
let hasRequiredComparator
function requireComparator() {
  if (hasRequiredComparator) {
    return comparator
  }
  hasRequiredComparator = 1
  const ANY = Symbol('SemVer ANY')
  // hoisted class for cyclic dependency
  class Comparator {
    static get ANY() {
      return ANY
    }
    constructor(comp, options) {
      options = parseOptions(options)
      if (comp instanceof Comparator) {
        if (comp.loose === !!options.loose) {
          return comp
        } else {
          comp = comp.value
        }
      }
      comp = comp.trim().split(/\s+/).join(' ')
      debug('comparator', comp, options)
      this.options = options
      this.loose = !!options.loose
      this.parse(comp)
      if (this.semver === ANY) {
        this.value = ''
      } else {
        this.value = this.operator + this.semver.version
      }
      debug('comp', this)
    }
    parse(comp) {
      const r = this.options.loose ? re[t.COMPARATORLOOSE] : re[t.COMPARATOR]
      const m = comp.match(r)
      if (!m) {
        throw new TypeError(`Invalid comparator: ${comp}`)
      }
      this.operator = m[1] !== undefined ? m[1] : ''
      if (this.operator === '=') {
        this.operator = ''
      }

      // if it literally is just '>' or '' then allow anything.
      if (!m[2]) {
        this.semver = ANY
      } else {
        this.semver = new SemVer(m[2], this.options.loose)
      }
    }
    toString() {
      return this.value
    }
    test(version) {
      debug('Comparator.test', version, this.options.loose)
      if (this.semver === ANY || version === ANY) {
        return true
      }
      if (typeof version === 'string') {
        try {
          version = new SemVer(version, this.options)
        } catch (er) {
          return false
        }
      }
      return cmp(version, this.operator, this.semver, this.options)
    }
    intersects(comp, options) {
      if (!(comp instanceof Comparator)) {
        throw new TypeError('a Comparator is required')
      }
      if (this.operator === '') {
        if (this.value === '') {
          return true
        }
        return new Range(comp.value, options).test(this.value)
      } else if (comp.operator === '') {
        if (comp.value === '') {
          return true
        }
        return new Range(this.value, options).test(comp.semver)
      }
      options = parseOptions(options)

      // Special cases where nothing can possibly be lower
      if (
        options.includePrerelease &&
        (this.value === '<0.0.0-0' || comp.value === '<0.0.0-0')
      ) {
        return false
      }
      if (
        !options.includePrerelease &&
        (this.value.startsWith('<0.0.0') || comp.value.startsWith('<0.0.0'))
      ) {
        return false
      }

      // Same direction increasing (> or >=)
      if (this.operator.startsWith('>') && comp.operator.startsWith('>')) {
        return true
      }
      // Same direction decreasing (< or <=)
      if (this.operator.startsWith('<') && comp.operator.startsWith('<')) {
        return true
      }
      // same SemVer and both sides are inclusive (<= or >=)
      if (
        this.semver.version === comp.semver.version &&
        this.operator.includes('=') &&
        comp.operator.includes('=')
      ) {
        return true
      }
      // opposite directions less than
      if (
        cmp(this.semver, '<', comp.semver, options) &&
        this.operator.startsWith('>') &&
        comp.operator.startsWith('<')
      ) {
        return true
      }
      // opposite directions greater than
      if (
        cmp(this.semver, '>', comp.semver, options) &&
        this.operator.startsWith('<') &&
        comp.operator.startsWith('>')
      ) {
        return true
      }
      return false
    }
  }
  comparator = Comparator
  const parseOptions = requireParseOptions()
  const { safeRe: re, t } = requireRe()
  const cmp = requireCmp()
  const debug = requireDebug()
  const SemVer = requireSemver$1()
  const Range = requireRange()
  return comparator
}

let satisfies_1
let hasRequiredSatisfies
function requireSatisfies() {
  if (hasRequiredSatisfies) {
    return satisfies_1
  }
  hasRequiredSatisfies = 1
  const Range = requireRange()
  const satisfies = (version, range, options) => {
    try {
      range = new Range(range, options)
    } catch (er) {
      return false
    }
    return range.test(version)
  }
  satisfies_1 = satisfies
  return satisfies_1
}

let toComparators_1
let hasRequiredToComparators
function requireToComparators() {
  if (hasRequiredToComparators) {
    return toComparators_1
  }
  hasRequiredToComparators = 1
  const Range = requireRange()

  // Mostly just for testing and legacy API reasons
  const toComparators = (range, options) =>
    new Range(range, options).set.map(comp =>
      comp
        .map(c => c.value)
        .join(' ')
        .trim()
        .split(' ')
    )
  toComparators_1 = toComparators
  return toComparators_1
}

let maxSatisfying_1
let hasRequiredMaxSatisfying
function requireMaxSatisfying() {
  if (hasRequiredMaxSatisfying) {
    return maxSatisfying_1
  }
  hasRequiredMaxSatisfying = 1
  const SemVer = requireSemver$1()
  const Range = requireRange()
  const maxSatisfying = (versions, range, options) => {
    let max = null
    let maxSV = null
    let rangeObj = null
    try {
      rangeObj = new Range(range, options)
    } catch (er) {
      return null
    }
    versions.forEach(v => {
      if (rangeObj.test(v)) {
        // satisfies(v, range, options)
        if (!max || maxSV.compare(v) === -1) {
          // compare(max, v, true)
          max = v
          maxSV = new SemVer(max, options)
        }
      }
    })
    return max
  }
  maxSatisfying_1 = maxSatisfying
  return maxSatisfying_1
}

let minSatisfying_1
let hasRequiredMinSatisfying
function requireMinSatisfying() {
  if (hasRequiredMinSatisfying) {
    return minSatisfying_1
  }
  hasRequiredMinSatisfying = 1
  const SemVer = requireSemver$1()
  const Range = requireRange()
  const minSatisfying = (versions, range, options) => {
    let min = null
    let minSV = null
    let rangeObj = null
    try {
      rangeObj = new Range(range, options)
    } catch (er) {
      return null
    }
    versions.forEach(v => {
      if (rangeObj.test(v)) {
        // satisfies(v, range, options)
        if (!min || minSV.compare(v) === 1) {
          // compare(min, v, true)
          min = v
          minSV = new SemVer(min, options)
        }
      }
    })
    return min
  }
  minSatisfying_1 = minSatisfying
  return minSatisfying_1
}

let minVersion_1
let hasRequiredMinVersion
function requireMinVersion() {
  if (hasRequiredMinVersion) {
    return minVersion_1
  }
  hasRequiredMinVersion = 1
  const SemVer = requireSemver$1()
  const Range = requireRange()
  const gt = requireGt()
  const minVersion = (range, loose) => {
    range = new Range(range, loose)
    let minver = new SemVer('0.0.0')
    if (range.test(minver)) {
      return minver
    }
    minver = new SemVer('0.0.0-0')
    if (range.test(minver)) {
      return minver
    }
    minver = null
    for (let i = 0; i < range.set.length; ++i) {
      const comparators = range.set[i]
      let setMin = null
      comparators.forEach(comparator => {
        // Clone to avoid manipulating the comparator's semver object.
        const compver = new SemVer(comparator.semver.version)
        switch (comparator.operator) {
          case '>':
            if (compver.prerelease.length === 0) {
              compver.patch++
            } else {
              compver.prerelease.push(0)
            }
            compver.raw = compver.format()
          /* fallthrough */
          case '':
          case '>=':
            if (!setMin || gt(compver, setMin)) {
              setMin = compver
            }
            break
          case '<':
          case '<=':
            /* Ignore maximum versions */
            break
          /* istanbul ignore next */
          default:
            throw new Error(`Unexpected operation: ${comparator.operator}`)
        }
      })
      if (setMin && (!minver || gt(minver, setMin))) {
        minver = setMin
      }
    }
    if (minver && range.test(minver)) {
      return minver
    }
    return null
  }
  minVersion_1 = minVersion
  return minVersion_1
}

let valid
let hasRequiredValid
function requireValid() {
  if (hasRequiredValid) {
    return valid
  }
  hasRequiredValid = 1
  const Range = requireRange()
  const validRange = (range, options) => {
    try {
      // Return '*' instead of '' so that truthiness works.
      // This will throw if it's invalid anyway
      return new Range(range, options).range || '*'
    } catch (er) {
      return null
    }
  }
  valid = validRange
  return valid
}

let outside_1
let hasRequiredOutside
function requireOutside() {
  if (hasRequiredOutside) {
    return outside_1
  }
  hasRequiredOutside = 1
  const SemVer = requireSemver$1()
  const Comparator = requireComparator()
  const { ANY } = Comparator
  const Range = requireRange()
  const satisfies = requireSatisfies()
  const gt = requireGt()
  const lt = requireLt()
  const lte = requireLte()
  const gte = requireGte()
  const outside = (version, range, hilo, options) => {
    version = new SemVer(version, options)
    range = new Range(range, options)
    let gtfn, ltefn, ltfn, comp, ecomp
    switch (hilo) {
      case '>':
        gtfn = gt
        ltefn = lte
        ltfn = lt
        comp = '>'
        ecomp = '>='
        break
      case '<':
        gtfn = lt
        ltefn = gte
        ltfn = gt
        comp = '<'
        ecomp = '<='
        break
      default:
        throw new TypeError('Must provide a hilo val of "<" or ">"')
    }

    // If it satisfies the range it is not outside
    if (satisfies(version, range, options)) {
      return false
    }

    // From now on, variable terms are as if we're in "gtr" mode.
    // but note that everything is flipped for the "ltr" function.

    for (let i = 0; i < range.set.length; ++i) {
      const comparators = range.set[i]
      let high = null
      let low = null
      comparators.forEach(comparator => {
        if (comparator.semver === ANY) {
          comparator = new Comparator('>=0.0.0')
        }
        high = high || comparator
        low = low || comparator
        if (gtfn(comparator.semver, high.semver, options)) {
          high = comparator
        } else if (ltfn(comparator.semver, low.semver, options)) {
          low = comparator
        }
      })

      // If the edge version comparator has a operator then our version
      // isn't outside it
      if (high.operator === comp || high.operator === ecomp) {
        return false
      }

      // If the lowest version comparator has an operator and our version
      // is less than it then it isn't higher than the range
      if (
        (!low.operator || low.operator === comp) &&
        ltefn(version, low.semver)
      ) {
        return false
      } else if (low.operator === ecomp && ltfn(version, low.semver)) {
        return false
      }
    }
    return true
  }
  outside_1 = outside
  return outside_1
}

let gtr_1
let hasRequiredGtr
function requireGtr() {
  if (hasRequiredGtr) {
    return gtr_1
  }
  hasRequiredGtr = 1
  // Determine if version is greater than all the versions possible in the range.
  const outside = requireOutside()
  const gtr = (version, range, options) => outside(version, range, '>', options)
  gtr_1 = gtr
  return gtr_1
}

let ltr_1
let hasRequiredLtr
function requireLtr() {
  if (hasRequiredLtr) {
    return ltr_1
  }
  hasRequiredLtr = 1
  const outside = requireOutside()
  // Determine if version is less than all the versions possible in the range
  const ltr = (version, range, options) => outside(version, range, '<', options)
  ltr_1 = ltr
  return ltr_1
}

let intersects_1
let hasRequiredIntersects
function requireIntersects() {
  if (hasRequiredIntersects) {
    return intersects_1
  }
  hasRequiredIntersects = 1
  const Range = requireRange()
  const intersects = (r1, r2, options) => {
    r1 = new Range(r1, options)
    r2 = new Range(r2, options)
    return r1.intersects(r2, options)
  }
  intersects_1 = intersects
  return intersects_1
}

let simplify
let hasRequiredSimplify
function requireSimplify() {
  if (hasRequiredSimplify) {
    return simplify
  }
  hasRequiredSimplify = 1
  // given a set of versions and a range, create a "simplified" range
  // that includes the same versions that the original range does
  // If the original range is shorter than the simplified one, return that.
  const satisfies = requireSatisfies()
  const compare = requireCompare()
  simplify = (versions, range, options) => {
    const set = []
    let first = null
    let prev = null
    const v = versions.sort((a, b) => compare(a, b, options))
    for (const version of v) {
      const included = satisfies(version, range, options)
      if (included) {
        prev = version
        if (!first) {
          first = version
        }
      } else {
        if (prev) {
          set.push([first, prev])
        }
        prev = null
        first = null
      }
    }
    if (first) {
      set.push([first, null])
    }
    const ranges = []
    for (const [min, max] of set) {
      if (min === max) {
        ranges.push(min)
      } else if (!max && min === v[0]) {
        ranges.push('*')
      } else if (!max) {
        ranges.push(`>=${min}`)
      } else if (min === v[0]) {
        ranges.push(`<=${max}`)
      } else {
        ranges.push(`${min} - ${max}`)
      }
    }
    const simplified = ranges.join(' || ')
    const original = typeof range.raw === 'string' ? range.raw : String(range)
    return simplified.length < original.length ? simplified : range
  }
  return simplify
}

let subset_1
let hasRequiredSubset
function requireSubset() {
  if (hasRequiredSubset) {
    return subset_1
  }
  hasRequiredSubset = 1
  const Range = requireRange()
  const Comparator = requireComparator()
  const { ANY } = Comparator
  const satisfies = requireSatisfies()
  const compare = requireCompare()

  // Complex range `r1 || r2 || ...` is a subset of `R1 || R2 || ...` iff:
  // - Every simple range `r1, r2, ...` is a null set, OR
  // - Every simple range `r1, r2, ...` which is not a null set is a subset of
  //   some `R1, R2, ...`
  //
  // Simple range `c1 c2 ...` is a subset of simple range `C1 C2 ...` iff:
  // - If c is only the ANY comparator
  //   - If C is only the ANY comparator, return true
  //   - Else if in prerelease mode, return false
  //   - else replace c with `[>=0.0.0]`
  // - If C is only the ANY comparator
  //   - if in prerelease mode, return true
  //   - else replace C with `[>=0.0.0]`
  // - Let EQ be the set of = comparators in c
  // - If EQ is more than one, return true (null set)
  // - Let GT be the highest > or >= comparator in c
  // - Let LT be the lowest < or <= comparator in c
  // - If GT and LT, and GT.semver > LT.semver, return true (null set)
  // - If any C is a = range, and GT or LT are set, return false
  // - If EQ
  //   - If GT, and EQ does not satisfy GT, return true (null set)
  //   - If LT, and EQ does not satisfy LT, return true (null set)
  //   - If EQ satisfies every C, return true
  //   - Else return false
  // - If GT
  //   - If GT.semver is lower than any > or >= comp in C, return false
  //   - If GT is >=, and GT.semver does not satisfy every C, return false
  //   - If GT.semver has a prerelease, and not in prerelease mode
  //     - If no C has a prerelease and the GT.semver tuple, return false
  // - If LT
  //   - If LT.semver is greater than any < or <= comp in C, return false
  //   - If LT is <=, and LT.semver does not satisfy every C, return false
  //   - If GT.semver has a prerelease, and not in prerelease mode
  //     - If no C has a prerelease and the LT.semver tuple, return false
  // - Else return true

  const subset = (sub, dom, options = {}) => {
    if (sub === dom) {
      return true
    }
    sub = new Range(sub, options)
    dom = new Range(dom, options)
    let sawNonNull = false
    OUTER: for (const simpleSub of sub.set) {
      for (const simpleDom of dom.set) {
        const isSub = simpleSubset(simpleSub, simpleDom, options)
        sawNonNull = sawNonNull || isSub !== null
        if (isSub) {
          continue OUTER
        }
      }
      // the null set is a subset of everything, but null simple ranges in
      // a complex range should be ignored.  so if we saw a non-null range,
      // then we know this isn't a subset, but if EVERY simple range was null,
      // then it is a subset.
      if (sawNonNull) {
        return false
      }
    }
    return true
  }
  const minimumVersionWithPreRelease = [new Comparator('>=0.0.0-0')]
  const minimumVersion = [new Comparator('>=0.0.0')]
  const simpleSubset = (sub, dom, options) => {
    if (sub === dom) {
      return true
    }
    if (sub.length === 1 && sub[0].semver === ANY) {
      if (dom.length === 1 && dom[0].semver === ANY) {
        return true
      } else if (options.includePrerelease) {
        sub = minimumVersionWithPreRelease
      } else {
        sub = minimumVersion
      }
    }
    if (dom.length === 1 && dom[0].semver === ANY) {
      if (options.includePrerelease) {
        return true
      } else {
        dom = minimumVersion
      }
    }
    const eqSet = new Set()
    let gt, lt
    for (const c of sub) {
      if (c.operator === '>' || c.operator === '>=') {
        gt = higherGT(gt, c, options)
      } else if (c.operator === '<' || c.operator === '<=') {
        lt = lowerLT(lt, c, options)
      } else {
        eqSet.add(c.semver)
      }
    }
    if (eqSet.size > 1) {
      return null
    }
    let gtltComp
    if (gt && lt) {
      gtltComp = compare(gt.semver, lt.semver, options)
      if (gtltComp > 0) {
        return null
      } else if (
        gtltComp === 0 &&
        (gt.operator !== '>=' || lt.operator !== '<=')
      ) {
        return null
      }
    }

    // will iterate one or zero times
    for (const eq of eqSet) {
      if (gt && !satisfies(eq, String(gt), options)) {
        return null
      }
      if (lt && !satisfies(eq, String(lt), options)) {
        return null
      }
      for (const c of dom) {
        if (!satisfies(eq, String(c), options)) {
          return false
        }
      }
      return true
    }
    let higher, lower
    let hasDomLT, hasDomGT
    // if the subset has a prerelease, we need a comparator in the superset
    // with the same tuple and a prerelease, or it's not a subset
    let needDomLTPre =
      lt && !options.includePrerelease && lt.semver.prerelease.length
        ? lt.semver
        : false
    let needDomGTPre =
      gt && !options.includePrerelease && gt.semver.prerelease.length
        ? gt.semver
        : false
    // exception: <1.2.3-0 is the same as <1.2.3
    if (
      needDomLTPre &&
      needDomLTPre.prerelease.length === 1 &&
      lt.operator === '<' &&
      needDomLTPre.prerelease[0] === 0
    ) {
      needDomLTPre = false
    }
    for (const c of dom) {
      hasDomGT = hasDomGT || c.operator === '>' || c.operator === '>='
      hasDomLT = hasDomLT || c.operator === '<' || c.operator === '<='
      if (gt) {
        if (needDomGTPre) {
          if (
            c.semver.prerelease &&
            c.semver.prerelease.length &&
            c.semver.major === needDomGTPre.major &&
            c.semver.minor === needDomGTPre.minor &&
            c.semver.patch === needDomGTPre.patch
          ) {
            needDomGTPre = false
          }
        }
        if (c.operator === '>' || c.operator === '>=') {
          higher = higherGT(gt, c, options)
          if (higher === c && higher !== gt) {
            return false
          }
        } else if (
          gt.operator === '>=' &&
          !satisfies(gt.semver, String(c), options)
        ) {
          return false
        }
      }
      if (lt) {
        if (needDomLTPre) {
          if (
            c.semver.prerelease &&
            c.semver.prerelease.length &&
            c.semver.major === needDomLTPre.major &&
            c.semver.minor === needDomLTPre.minor &&
            c.semver.patch === needDomLTPre.patch
          ) {
            needDomLTPre = false
          }
        }
        if (c.operator === '<' || c.operator === '<=') {
          lower = lowerLT(lt, c, options)
          if (lower === c && lower !== lt) {
            return false
          }
        } else if (
          lt.operator === '<=' &&
          !satisfies(lt.semver, String(c), options)
        ) {
          return false
        }
      }
      if (!c.operator && (lt || gt) && gtltComp !== 0) {
        return false
      }
    }

    // if there was a < or >, and nothing in the dom, then must be false
    // UNLESS it was limited by another range in the other direction.
    // Eg, >1.0.0 <1.0.1 is still a subset of <2.0.0
    if (gt && hasDomLT && !lt && gtltComp !== 0) {
      return false
    }
    if (lt && hasDomGT && !gt && gtltComp !== 0) {
      return false
    }

    // we needed a prerelease range in a specific tuple, but didn't get one
    // then this isn't a subset.  eg >=1.2.3-pre is not a subset of >=1.0.0,
    // because it includes prereleases in the 1.2.3 tuple
    if (needDomGTPre || needDomLTPre) {
      return false
    }
    return true
  }

  // >=1.2.3 is lower than >1.2.3
  const higherGT = (a, b, options) => {
    if (!a) {
      return b
    }
    const comp = compare(a.semver, b.semver, options)
    return comp > 0
      ? a
      : comp < 0
        ? b
        : b.operator === '>' && a.operator === '>='
          ? b
          : a
  }

  // <=1.2.3 is higher than <1.2.3
  const lowerLT = (a, b, options) => {
    if (!a) {
      return b
    }
    const comp = compare(a.semver, b.semver, options)
    return comp < 0
      ? a
      : comp > 0
        ? b
        : b.operator === '<' && a.operator === '<='
          ? b
          : a
  }
  subset_1 = subset
  return subset_1
}

let semver
let hasRequiredSemver
function requireSemver() {
  if (hasRequiredSemver) {
    return semver
  }
  hasRequiredSemver = 1
  // just pre-load all the stuff that index.js lazily exports
  const internalRe = requireRe()
  const constants = requireConstants$1()
  const SemVer = requireSemver$1()
  const identifiers = requireIdentifiers()
  const parse = requireParse$2()
  const valid = requireValid$1()
  const clean = requireClean()
  const inc = requireInc()
  const diff = requireDiff()
  const major = requireMajor()
  const minor = requireMinor()
  const patch = requirePatch()
  const prerelease = requirePrerelease()
  const compare = requireCompare()
  const rcompare = requireRcompare()
  const compareLoose = requireCompareLoose()
  const compareBuild = requireCompareBuild()
  const sort = requireSort()
  const rsort = requireRsort()
  const gt = requireGt()
  const lt = requireLt()
  const eq = requireEq()
  const neq = requireNeq()
  const gte = requireGte()
  const lte = requireLte()
  const cmp = requireCmp()
  const coerce = requireCoerce()
  const Comparator = requireComparator()
  const Range = requireRange()
  const satisfies = requireSatisfies()
  const toComparators = requireToComparators()
  const maxSatisfying = requireMaxSatisfying()
  const minSatisfying = requireMinSatisfying()
  const minVersion = requireMinVersion()
  const validRange = requireValid()
  const outside = requireOutside()
  const gtr = requireGtr()
  const ltr = requireLtr()
  const intersects = requireIntersects()
  const simplifyRange = requireSimplify()
  const subset = requireSubset()
  semver = {
    parse,
    valid,
    clean,
    inc,
    diff,
    major,
    minor,
    patch,
    prerelease,
    compare,
    rcompare,
    compareLoose,
    compareBuild,
    sort,
    rsort,
    gt,
    lt,
    eq,
    neq,
    gte,
    lte,
    cmp,
    coerce,
    Comparator,
    Range,
    satisfies,
    toComparators,
    maxSatisfying,
    minSatisfying,
    minVersion,
    validRange,
    outside,
    gtr,
    ltr,
    intersects,
    simplifyRange,
    subset,
    SemVer,
    re: internalRe.re,
    src: internalRe.src,
    tokens: internalRe.t,
    SEMVER_SPEC_VERSION: constants.SEMVER_SPEC_VERSION,
    RELEASE_TYPES: constants.RELEASE_TYPES,
    compareIdentifiers: identifiers.compareIdentifiers,
    rcompareIdentifiers: identifiers.rcompareIdentifiers
  }
  return semver
}

const semverExports = requireSemver()

const terminalLink = { exports: {} }

const ansiEscapes = { exports: {} }

let hasRequiredAnsiEscapes
function requireAnsiEscapes() {
  if (hasRequiredAnsiEscapes) {
    return ansiEscapes.exports
  }
  hasRequiredAnsiEscapes = 1
  ;(function (module) {
    const ansiEscapes = module.exports
    // TODO: remove this in the next major version
    module.exports.default = ansiEscapes
    const ESC = '\u001B['
    const OSC = '\u001B]'
    const BEL = '\u0007'
    const SEP = ';'
    const isTerminalApp = process.env.TERM_PROGRAM === 'Apple_Terminal'
    ansiEscapes.cursorTo = (x, y) => {
      if (typeof x !== 'number') {
        throw new TypeError('The `x` argument is required')
      }
      if (typeof y !== 'number') {
        return ESC + (x + 1) + 'G'
      }
      return ESC + (y + 1) + ';' + (x + 1) + 'H'
    }
    ansiEscapes.cursorMove = (x, y) => {
      if (typeof x !== 'number') {
        throw new TypeError('The `x` argument is required')
      }
      let ret = ''
      if (x < 0) {
        ret += ESC + -x + 'D'
      } else if (x > 0) {
        ret += ESC + x + 'C'
      }
      if (y < 0) {
        ret += ESC + -y + 'A'
      } else if (y > 0) {
        ret += ESC + y + 'B'
      }
      return ret
    }
    ansiEscapes.cursorUp = (count = 1) => ESC + count + 'A'
    ansiEscapes.cursorDown = (count = 1) => ESC + count + 'B'
    ansiEscapes.cursorForward = (count = 1) => ESC + count + 'C'
    ansiEscapes.cursorBackward = (count = 1) => ESC + count + 'D'
    ansiEscapes.cursorLeft = ESC + 'G'
    ansiEscapes.cursorSavePosition = isTerminalApp ? '\u001B7' : ESC + 's'
    ansiEscapes.cursorRestorePosition = isTerminalApp ? '\u001B8' : ESC + 'u'
    ansiEscapes.cursorGetPosition = ESC + '6n'
    ansiEscapes.cursorNextLine = ESC + 'E'
    ansiEscapes.cursorPrevLine = ESC + 'F'
    ansiEscapes.cursorHide = ESC + '?25l'
    ansiEscapes.cursorShow = ESC + '?25h'
    ansiEscapes.eraseLines = count => {
      let clear = ''
      for (let i = 0; i < count; i++) {
        clear +=
          ansiEscapes.eraseLine + (i < count - 1 ? ansiEscapes.cursorUp() : '')
      }
      if (count) {
        clear += ansiEscapes.cursorLeft
      }
      return clear
    }
    ansiEscapes.eraseEndLine = ESC + 'K'
    ansiEscapes.eraseStartLine = ESC + '1K'
    ansiEscapes.eraseLine = ESC + '2K'
    ansiEscapes.eraseDown = ESC + 'J'
    ansiEscapes.eraseUp = ESC + '1J'
    ansiEscapes.eraseScreen = ESC + '2J'
    ansiEscapes.scrollUp = ESC + 'S'
    ansiEscapes.scrollDown = ESC + 'T'
    ansiEscapes.clearScreen = '\u001Bc'
    ansiEscapes.clearTerminal =
      process.platform === 'win32'
        ? `${ansiEscapes.eraseScreen}${ESC}0f`
        : // 1. Erases the screen (Only done in case `2` is not supported)
          // 2. Erases the whole screen including scrollback buffer
          // 3. Moves cursor to the top-left position
          // More info: https://www.real-world-systems.com/docs/ANSIcode.html
          `${ansiEscapes.eraseScreen}${ESC}3J${ESC}H`
    ansiEscapes.beep = BEL
    ansiEscapes.link = (text, url) => {
      return [OSC, '8', SEP, SEP, url, BEL, text, OSC, '8', SEP, SEP, BEL].join(
        ''
      )
    }
    ansiEscapes.image = (buffer, options = {}) => {
      let ret = `${OSC}1337;File=inline=1`
      if (options.width) {
        ret += `;width=${options.width}`
      }
      if (options.height) {
        ret += `;height=${options.height}`
      }
      if (options.preserveAspectRatio === false) {
        ret += ';preserveAspectRatio=0'
      }
      return ret + ':' + buffer.toString('base64') + BEL
    }
    ansiEscapes.iTerm = {
      setCwd: (cwd = process.cwd()) => `${OSC}50;CurrentDir=${cwd}${BEL}`,
      annotation: (message, options = {}) => {
        let ret = `${OSC}1337;`
        const hasX = typeof options.x !== 'undefined'
        const hasY = typeof options.y !== 'undefined'
        if (
          (hasX || hasY) &&
          !(hasX && hasY && typeof options.length !== 'undefined')
        ) {
          throw new Error(
            '`x`, `y` and `length` must be defined when `x` or `y` is defined'
          )
        }
        message = message.replace(/\|/g, '')
        ret += options.isHidden ? 'AddHiddenAnnotation=' : 'AddAnnotation='
        if (options.length > 0) {
          ret += (
            hasX
              ? [message, options.length, options.x, options.y]
              : [options.length, message]
          ).join('|')
        } else {
          ret += message
        }
        return ret + BEL
      }
    }
  })(ansiEscapes)
  return ansiEscapes.exports
}

let hasFlag$1
let hasRequiredHasFlag$1
function requireHasFlag$1() {
  if (hasRequiredHasFlag$1) {
    return hasFlag$1
  }
  hasRequiredHasFlag$1 = 1
  hasFlag$1 = (flag, argv = process.argv) => {
    const prefix = flag.startsWith('-') ? '' : flag.length === 1 ? '-' : '--'
    const position = argv.indexOf(prefix + flag)
    const terminatorPosition = argv.indexOf('--')
    return (
      position !== -1 &&
      (terminatorPosition === -1 || position < terminatorPosition)
    )
  }
  return hasFlag$1
}

let supportsColor_1$1
let hasRequiredSupportsColor$1
function requireSupportsColor$1() {
  if (hasRequiredSupportsColor$1) {
    return supportsColor_1$1
  }
  hasRequiredSupportsColor$1 = 1
  const os = require$$0$c
  const tty = require$$1$6
  const hasFlag = requireHasFlag$1()
  const { env } = process
  let forceColor
  if (
    hasFlag('no-color') ||
    hasFlag('no-colors') ||
    hasFlag('color=false') ||
    hasFlag('color=never')
  ) {
    forceColor = 0
  } else if (
    hasFlag('color') ||
    hasFlag('colors') ||
    hasFlag('color=true') ||
    hasFlag('color=always')
  ) {
    forceColor = 1
  }
  if ('FORCE_COLOR' in env) {
    if (env.FORCE_COLOR === 'true') {
      forceColor = 1
    } else if (env.FORCE_COLOR === 'false') {
      forceColor = 0
    } else {
      forceColor =
        env.FORCE_COLOR.length === 0
          ? 1
          : Math.min(parseInt(env.FORCE_COLOR, 10), 3)
    }
  }
  function translateLevel(level) {
    if (level === 0) {
      return false
    }
    return {
      level,
      hasBasic: true,
      has256: level >= 2,
      has16m: level >= 3
    }
  }
  function supportsColor(haveStream, streamIsTTY) {
    if (forceColor === 0) {
      return 0
    }
    if (
      hasFlag('color=16m') ||
      hasFlag('color=full') ||
      hasFlag('color=truecolor')
    ) {
      return 3
    }
    if (hasFlag('color=256')) {
      return 2
    }
    if (haveStream && !streamIsTTY && forceColor === undefined) {
      return 0
    }
    const min = forceColor || 0
    if (env.TERM === 'dumb') {
      return min
    }
    if (process.platform === 'win32') {
      // Windows 10 build 10586 is the first Windows release that supports 256 colors.
      // Windows 10 build 14931 is the first release that supports 16m/TrueColor.
      const osRelease = os.release().split('.')
      if (Number(osRelease[0]) >= 10 && Number(osRelease[2]) >= 10586) {
        return Number(osRelease[2]) >= 14931 ? 3 : 2
      }
      return 1
    }
    if ('CI' in env) {
      if (
        [
          'TRAVIS',
          'CIRCLECI',
          'APPVEYOR',
          'GITLAB_CI',
          'GITHUB_ACTIONS',
          'BUILDKITE'
        ].some(sign => sign in env) ||
        env.CI_NAME === 'codeship'
      ) {
        return 1
      }
      return min
    }
    if ('TEAMCITY_VERSION' in env) {
      return /^(9\.(0*[1-9]\d*)\.|\d{2,}\.)/.test(env.TEAMCITY_VERSION) ? 1 : 0
    }
    if (env.COLORTERM === 'truecolor') {
      return 3
    }
    if ('TERM_PROGRAM' in env) {
      const version = parseInt(
        (env.TERM_PROGRAM_VERSION || '').split('.')[0],
        10
      )
      switch (env.TERM_PROGRAM) {
        case 'iTerm.app':
          return version >= 3 ? 3 : 2
        case 'Apple_Terminal':
          return 2
        // No default
      }
    }
    if (/-256(color)?$/i.test(env.TERM)) {
      return 2
    }
    if (
      /^screen|^xterm|^vt100|^vt220|^rxvt|color|ansi|cygwin|linux/i.test(
        env.TERM
      )
    ) {
      return 1
    }
    if ('COLORTERM' in env) {
      return 1
    }
    return min
  }
  function getSupportLevel(stream) {
    const level = supportsColor(stream, stream && stream.isTTY)
    return translateLevel(level)
  }
  supportsColor_1$1 = {
    supportsColor: getSupportLevel,
    stdout: translateLevel(supportsColor(true, tty.isatty(1))),
    stderr: translateLevel(supportsColor(true, tty.isatty(2)))
  }
  return supportsColor_1$1
}

let supportsHyperlinks
let hasRequiredSupportsHyperlinks
function requireSupportsHyperlinks() {
  if (hasRequiredSupportsHyperlinks) {
    return supportsHyperlinks
  }
  hasRequiredSupportsHyperlinks = 1
  const supportsColor = requireSupportsColor$1()
  const hasFlag = requireHasFlag$1()
  function parseVersion(versionString) {
    if (/^\d{3,4}$/.test(versionString)) {
      // Env var doesn't always use dots. example: 4601 => 46.1.0
      const m = /(\d{1,2})(\d{2})/.exec(versionString)
      return {
        major: 0,
        minor: parseInt(m[1], 10),
        patch: parseInt(m[2], 10)
      }
    }
    const versions = (versionString || '').split('.').map(n => parseInt(n, 10))
    return {
      major: versions[0],
      minor: versions[1],
      patch: versions[2]
    }
  }
  function supportsHyperlink(stream) {
    const { env } = process
    if ('FORCE_HYPERLINK' in env) {
      return !(
        env.FORCE_HYPERLINK.length > 0 &&
        parseInt(env.FORCE_HYPERLINK, 10) === 0
      )
    }
    if (
      hasFlag('no-hyperlink') ||
      hasFlag('no-hyperlinks') ||
      hasFlag('hyperlink=false') ||
      hasFlag('hyperlink=never')
    ) {
      return false
    }
    if (hasFlag('hyperlink=true') || hasFlag('hyperlink=always')) {
      return true
    }

    // Netlify does not run a TTY, it does not need `supportsColor` check
    if ('NETLIFY' in env) {
      return true
    }

    // If they specify no colors, they probably don't want hyperlinks.
    if (!supportsColor.supportsColor(stream)) {
      return false
    }
    if (stream && !stream.isTTY) {
      return false
    }
    if (process.platform === 'win32') {
      return false
    }
    if ('CI' in env) {
      return false
    }
    if ('TEAMCITY_VERSION' in env) {
      return false
    }
    if ('TERM_PROGRAM' in env) {
      const version = parseVersion(env.TERM_PROGRAM_VERSION)
      switch (env.TERM_PROGRAM) {
        case 'iTerm.app':
          if (version.major === 3) {
            return version.minor >= 1
          }
          return version.major > 3
        case 'WezTerm':
          return version.major >= 20200620
        case 'vscode':
          return (
            version.major > 1 || (version.major === 1 && version.minor >= 72)
          )
        // No default
      }
    }
    if ('VTE_VERSION' in env) {
      // 0.50.0 was supposed to support hyperlinks, but throws a segfault
      if (env.VTE_VERSION === '0.50.0') {
        return false
      }
      const version = parseVersion(env.VTE_VERSION)
      return version.major > 0 || version.minor >= 50
    }
    return false
  }
  supportsHyperlinks = {
    supportsHyperlink,
    stdout: supportsHyperlink(process.stdout),
    stderr: supportsHyperlink(process.stderr)
  }
  return supportsHyperlinks
}

let hasRequiredTerminalLink
function requireTerminalLink() {
  if (hasRequiredTerminalLink) {
    return terminalLink.exports
  }
  hasRequiredTerminalLink = 1
  ;(function (module) {
    const ansiEscapes = requireAnsiEscapes()
    const supportsHyperlinks = requireSupportsHyperlinks()
    const terminalLink = (
      text,
      url,
      { target = 'stdout', ...options } = {}
    ) => {
      if (!supportsHyperlinks[target]) {
        // If the fallback has been explicitly disabled, don't modify the text itself.
        if (options.fallback === false) {
          return text
        }
        return typeof options.fallback === 'function'
          ? options.fallback(text, url)
          : `${text} (\u200B${url}\u200B)`
      }
      return ansiEscapes.link(text, url)
    }
    module.exports = (text, url, options = {}) =>
      terminalLink(text, url, options)
    module.exports.stderr = (text, url, options = {}) =>
      terminalLink(text, url, {
        target: 'stderr',
        ...options
      })
    module.exports.isSupported = supportsHyperlinks.stdout
    module.exports.stderr.isSupported = supportsHyperlinks.stderr
  })(terminalLink)
  return terminalLink.exports
}

const terminalLinkExports = requireTerminalLink()

/**
 * @license
 * Copyright (c) 2016, Contributors
 * SPDX-License-Identifier: ISC
 */
function camelCase(str) {
  // Handle the case where an argument is provided as camel case, e.g., fooBar.
  // by ensuring that the string isn't already mixed case:
  const isCamelCase = str !== str.toLowerCase() && str !== str.toUpperCase()
  if (!isCamelCase) {
    str = str.toLowerCase()
  }
  if (str.indexOf('-') === -1 && str.indexOf('_') === -1) {
    return str
  } else {
    let camelcase = ''
    let nextChrUpper = false
    const leadingHyphens = str.match(/^-+/)
    for (
      let i = leadingHyphens ? leadingHyphens[0].length : 0;
      i < str.length;
      i++
    ) {
      let chr = str.charAt(i)
      if (nextChrUpper) {
        nextChrUpper = false
        chr = chr.toUpperCase()
      }
      if (i !== 0 && (chr === '-' || chr === '_')) {
        nextChrUpper = true
      } else if (chr !== '-' && chr !== '_') {
        camelcase += chr
      }
    }
    return camelcase
  }
}
function decamelize(str, joinString) {
  const lowercase = str.toLowerCase()
  joinString = joinString || '-'
  let notCamelcase = ''
  for (let i = 0; i < str.length; i++) {
    const chrLower = lowercase.charAt(i)
    const chrString = str.charAt(i)
    if (chrLower !== chrString && i > 0) {
      notCamelcase += `${joinString}${lowercase.charAt(i)}`
    } else {
      notCamelcase += chrString
    }
  }
  return notCamelcase
}
function looksLikeNumber(x) {
  if (x === null || x === undefined) {
    return false
  }
  // if loaded from config, may already be a number.
  if (typeof x === 'number') {
    return true
  }
  // hexadecimal.
  if (/^0x[0-9a-f]+$/i.test(x)) {
    return true
  }
  // don't treat 0123 as a number; as it drops the leading '0'.
  if (/^0[^.]/.test(x)) {
    return false
  }
  return /^[-]?(?:\d+(?:\.\d*)?|\.\d+)(e[-+]?\d+)?$/.test(x)
}

/**
 * @license
 * Copyright (c) 2016, Contributors
 * SPDX-License-Identifier: ISC
 */
// take an un-split argv string and tokenize it.
function tokenizeArgString(argString) {
  if (Array.isArray(argString)) {
    return argString.map(e => (typeof e !== 'string' ? e + '' : e))
  }
  argString = argString.trim()
  let i = 0
  let prevC = null
  let c = null
  let opening = null
  const args = []
  for (let ii = 0; ii < argString.length; ii++) {
    prevC = c
    c = argString.charAt(ii)
    // split on spaces unless we're in quotes.
    if (c === ' ' && !opening) {
      if (!(prevC === ' ')) {
        i++
      }
      continue
    }
    // don't split the string if we're in matching
    // opening or closing single and double quotes.
    if (c === opening) {
      opening = null
    } else if ((c === "'" || c === '"') && !opening) {
      opening = c
    }
    if (!args[i]) {
      args[i] = ''
    }
    args[i] += c
  }
  return args
}

/**
 * @license
 * Copyright (c) 2016, Contributors
 * SPDX-License-Identifier: ISC
 */
let DefaultValuesForTypeKey
;(function (DefaultValuesForTypeKey) {
  DefaultValuesForTypeKey['BOOLEAN'] = 'boolean'
  DefaultValuesForTypeKey['STRING'] = 'string'
  DefaultValuesForTypeKey['NUMBER'] = 'number'
  DefaultValuesForTypeKey['ARRAY'] = 'array'
})(DefaultValuesForTypeKey || (DefaultValuesForTypeKey = {}))

/**
 * @license
 * Copyright (c) 2016, Contributors
 * SPDX-License-Identifier: ISC
 */
let mixin
class YargsParser {
  constructor(_mixin) {
    mixin = _mixin
  }
  parse(argsInput, options) {
    const opts = Object.assign(
      {
        alias: undefined,
        array: undefined,
        boolean: undefined,
        config: undefined,
        configObjects: undefined,
        configuration: undefined,
        coerce: undefined,
        count: undefined,
        default: undefined,
        envPrefix: undefined,
        narg: undefined,
        normalize: undefined,
        string: undefined,
        number: undefined,
        __: undefined,
        key: undefined
      },
      options
    )
    // allow a string argument to be passed in rather
    // than an argv array.
    const args = tokenizeArgString(argsInput)
    // tokenizeArgString adds extra quotes to args if argsInput is a string
    // only strip those extra quotes in processValue if argsInput is a string
    const inputIsString = typeof argsInput === 'string'
    // aliases might have transitive relationships, normalize this.
    const aliases = combineAliases(
      Object.assign(Object.create(null), opts.alias)
    )
    const configuration = Object.assign(
      {
        'boolean-negation': true,
        'camel-case-expansion': true,
        'combine-arrays': false,
        'dot-notation': true,
        'duplicate-arguments-array': true,
        'flatten-duplicate-arrays': true,
        'greedy-arrays': true,
        'halt-at-non-option': false,
        'nargs-eats-options': false,
        'negation-prefix': 'no-',
        'parse-numbers': true,
        'parse-positional-numbers': true,
        'populate--': false,
        'set-placeholder-key': false,
        'short-option-groups': true,
        'strip-aliased': false,
        'strip-dashed': false,
        'unknown-options-as-args': false
      },
      opts.configuration
    )
    const defaults = Object.assign(Object.create(null), opts.default)
    const configObjects = opts.configObjects || []
    const envPrefix = opts.envPrefix
    const notFlagsOption = configuration['populate--']
    const notFlagsArgv = notFlagsOption ? '--' : '_'
    const newAliases = Object.create(null)
    const defaulted = Object.create(null)
    // allow a i18n handler to be passed in, default to a fake one (util.format).
    const __ = opts.__ || mixin.format
    const flags = {
      aliases: Object.create(null),
      arrays: Object.create(null),
      bools: Object.create(null),
      strings: Object.create(null),
      numbers: Object.create(null),
      counts: Object.create(null),
      normalize: Object.create(null),
      configs: Object.create(null),
      nargs: Object.create(null),
      coercions: Object.create(null),
      keys: []
    }
    const negative = /^-([0-9]+(\.[0-9]+)?|\.[0-9]+)$/
    const negatedBoolean = new RegExp(
      '^--' + configuration['negation-prefix'] + '(.+)'
    )
    ;[]
      .concat(opts.array || [])
      .filter(Boolean)
      .forEach(function (opt) {
        const key = typeof opt === 'object' ? opt.key : opt
        // assign to flags[bools|strings|numbers]
        const assignment = Object.keys(opt)
          .map(function (key) {
            const arrayFlagKeys = {
              boolean: 'bools',
              string: 'strings',
              number: 'numbers'
            }
            return arrayFlagKeys[key]
          })
          .filter(Boolean)
          .pop()
        // assign key to be coerced
        if (assignment) {
          flags[assignment][key] = true
        }
        flags.arrays[key] = true
        flags.keys.push(key)
      })
    ;[]
      .concat(opts.boolean || [])
      .filter(Boolean)
      .forEach(function (key) {
        flags.bools[key] = true
        flags.keys.push(key)
      })
    ;[]
      .concat(opts.string || [])
      .filter(Boolean)
      .forEach(function (key) {
        flags.strings[key] = true
        flags.keys.push(key)
      })
    ;[]
      .concat(opts.number || [])
      .filter(Boolean)
      .forEach(function (key) {
        flags.numbers[key] = true
        flags.keys.push(key)
      })
    ;[]
      .concat(opts.count || [])
      .filter(Boolean)
      .forEach(function (key) {
        flags.counts[key] = true
        flags.keys.push(key)
      })
    ;[]
      .concat(opts.normalize || [])
      .filter(Boolean)
      .forEach(function (key) {
        flags.normalize[key] = true
        flags.keys.push(key)
      })
    if (typeof opts.narg === 'object') {
      Object.entries(opts.narg).forEach(([key, value]) => {
        if (typeof value === 'number') {
          flags.nargs[key] = value
          flags.keys.push(key)
        }
      })
    }
    if (typeof opts.coerce === 'object') {
      Object.entries(opts.coerce).forEach(([key, value]) => {
        if (typeof value === 'function') {
          flags.coercions[key] = value
          flags.keys.push(key)
        }
      })
    }
    if (typeof opts.config !== 'undefined') {
      if (Array.isArray(opts.config) || typeof opts.config === 'string') {
        ;[]
          .concat(opts.config)
          .filter(Boolean)
          .forEach(function (key) {
            flags.configs[key] = true
          })
      } else if (typeof opts.config === 'object') {
        Object.entries(opts.config).forEach(([key, value]) => {
          if (typeof value === 'boolean' || typeof value === 'function') {
            flags.configs[key] = value
          }
        })
      }
    }
    // create a lookup table that takes into account all
    // combinations of aliases: {f: ['foo'], foo: ['f']}
    extendAliases(opts.key, aliases, opts.default, flags.arrays)
    // apply default values to all aliases.
    Object.keys(defaults).forEach(function (key) {
      ;(flags.aliases[key] || []).forEach(function (alias) {
        defaults[alias] = defaults[key]
      })
    })
    let error = null
    checkConfiguration()
    let notFlags = []
    const argv = Object.assign(Object.create(null), {
      _: []
    })
    // TODO(bcoe): for the first pass at removing object prototype  we didn't
    // remove all prototypes from objects returned by this API, we might want
    // to gradually move towards doing so.
    const argvReturn = {}
    for (let i = 0; i < args.length; i++) {
      const arg = args[i]
      const truncatedArg = arg.replace(/^-{3,}/, '---')
      let broken
      let key
      let letters
      let m
      let next
      let value
      // any unknown option (except for end-of-options, "--")
      if (arg !== '--' && /^-/.test(arg) && isUnknownOptionAsArg(arg)) {
        pushPositional(arg)
        // ---, ---=, ----, etc,
      } else if (truncatedArg.match(/^---+(=|$)/)) {
        // options without key name are invalid.
        pushPositional(arg)
        continue
        // -- separated by =
      } else if (
        arg.match(/^--.+=/) ||
        (!configuration['short-option-groups'] && arg.match(/^-.+=/))
      ) {
        // Using [\s\S] instead of . because js doesn't support the
        // 'dotall' regex modifier. See:
        // http://stackoverflow.com/a/1068308/13216
        m = arg.match(/^--?([^=]+)=([\s\S]*)$/)
        // arrays format = '--f=a b c'
        if (m !== null && Array.isArray(m) && m.length >= 3) {
          if (checkAllAliases(m[1], flags.arrays)) {
            i = eatArray(i, m[1], args, m[2])
          } else if (checkAllAliases(m[1], flags.nargs) !== false) {
            // nargs format = '--f=monkey washing cat'
            i = eatNargs(i, m[1], args, m[2])
          } else {
            setArg(m[1], m[2], true)
          }
        }
      } else if (
        arg.match(negatedBoolean) &&
        configuration['boolean-negation']
      ) {
        m = arg.match(negatedBoolean)
        if (m !== null && Array.isArray(m) && m.length >= 2) {
          key = m[1]
          setArg(key, checkAllAliases(key, flags.arrays) ? [false] : false)
        }
        // -- separated by space.
      } else if (
        arg.match(/^--.+/) ||
        (!configuration['short-option-groups'] && arg.match(/^-[^-]+/))
      ) {
        m = arg.match(/^--?(.+)/)
        if (m !== null && Array.isArray(m) && m.length >= 2) {
          key = m[1]
          if (checkAllAliases(key, flags.arrays)) {
            // array format = '--foo a b c'
            i = eatArray(i, key, args)
          } else if (checkAllAliases(key, flags.nargs) !== false) {
            // nargs format = '--foo a b c'
            // should be truthy even if: flags.nargs[key] === 0
            i = eatNargs(i, key, args)
          } else {
            next = args[i + 1]
            if (
              next !== undefined &&
              (!next.match(/^-/) || next.match(negative)) &&
              !checkAllAliases(key, flags.bools) &&
              !checkAllAliases(key, flags.counts)
            ) {
              setArg(key, next)
              i++
            } else if (/^(true|false)$/.test(next)) {
              setArg(key, next)
              i++
            } else {
              setArg(key, defaultValue(key))
            }
          }
        }
        // dot-notation flag separated by '='.
      } else if (arg.match(/^-.\..+=/)) {
        m = arg.match(/^-([^=]+)=([\s\S]*)$/)
        if (m !== null && Array.isArray(m) && m.length >= 3) {
          setArg(m[1], m[2])
        }
        // dot-notation flag separated by space.
      } else if (arg.match(/^-.\..+/) && !arg.match(negative)) {
        next = args[i + 1]
        m = arg.match(/^-(.\..+)/)
        if (m !== null && Array.isArray(m) && m.length >= 2) {
          key = m[1]
          if (
            next !== undefined &&
            !next.match(/^-/) &&
            !checkAllAliases(key, flags.bools) &&
            !checkAllAliases(key, flags.counts)
          ) {
            setArg(key, next)
            i++
          } else {
            setArg(key, defaultValue(key))
          }
        }
      } else if (arg.match(/^-[^-]+/) && !arg.match(negative)) {
        letters = arg.slice(1, -1).split('')
        broken = false
        for (let j = 0; j < letters.length; j++) {
          next = arg.slice(j + 2)
          if (letters[j + 1] && letters[j + 1] === '=') {
            value = arg.slice(j + 3)
            key = letters[j]
            if (checkAllAliases(key, flags.arrays)) {
              // array format = '-f=a b c'
              i = eatArray(i, key, args, value)
            } else if (checkAllAliases(key, flags.nargs) !== false) {
              // nargs format = '-f=monkey washing cat'
              i = eatNargs(i, key, args, value)
            } else {
              setArg(key, value)
            }
            broken = true
            break
          }
          if (next === '-') {
            setArg(letters[j], next)
            continue
          }
          // current letter is an alphabetic character and next value is a number
          if (
            /[A-Za-z]/.test(letters[j]) &&
            /^-?\d+(\.\d*)?(e-?\d+)?$/.test(next) &&
            checkAllAliases(next, flags.bools) === false
          ) {
            setArg(letters[j], next)
            broken = true
            break
          }
          if (letters[j + 1] && letters[j + 1].match(/\W/)) {
            setArg(letters[j], next)
            broken = true
            break
          } else {
            setArg(letters[j], defaultValue(letters[j]))
          }
        }
        key = arg.slice(-1)[0]
        if (!broken && key !== '-') {
          if (checkAllAliases(key, flags.arrays)) {
            // array format = '-f a b c'
            i = eatArray(i, key, args)
          } else if (checkAllAliases(key, flags.nargs) !== false) {
            // nargs format = '-f a b c'
            // should be truthy even if: flags.nargs[key] === 0
            i = eatNargs(i, key, args)
          } else {
            next = args[i + 1]
            if (
              next !== undefined &&
              (!/^(-|--)[^-]/.test(next) || next.match(negative)) &&
              !checkAllAliases(key, flags.bools) &&
              !checkAllAliases(key, flags.counts)
            ) {
              setArg(key, next)
              i++
            } else if (/^(true|false)$/.test(next)) {
              setArg(key, next)
              i++
            } else {
              setArg(key, defaultValue(key))
            }
          }
        }
      } else if (
        arg.match(/^-[0-9]$/) &&
        arg.match(negative) &&
        checkAllAliases(arg.slice(1), flags.bools)
      ) {
        // single-digit boolean alias, e.g: xargs -0
        key = arg.slice(1)
        setArg(key, defaultValue(key))
      } else if (arg === '--') {
        notFlags = args.slice(i + 1)
        break
      } else if (configuration['halt-at-non-option']) {
        notFlags = args.slice(i)
        break
      } else {
        pushPositional(arg)
      }
    }
    // order of precedence:
    // 1. command line arg
    // 2. value from env var
    // 3. value from config file
    // 4. value from config objects
    // 5. configured default value
    applyEnvVars(argv, true) // special case: check env vars that point to config file
    applyEnvVars(argv, false)
    setConfig(argv)
    setConfigObjects()
    applyDefaultsAndAliases(argv, flags.aliases, defaults, true)
    applyCoercions(argv)
    if (configuration['set-placeholder-key']) {
      setPlaceholderKeys(argv)
    }
    // for any counts either not in args or without an explicit default, set to 0
    Object.keys(flags.counts).forEach(function (key) {
      if (!hasKey(argv, key.split('.'))) {
        setArg(key, 0)
      }
    })
    // '--' defaults to undefined.
    if (notFlagsOption && notFlags.length) {
      argv[notFlagsArgv] = []
    }
    notFlags.forEach(function (key) {
      argv[notFlagsArgv].push(key)
    })
    if (
      configuration['camel-case-expansion'] &&
      configuration['strip-dashed']
    ) {
      Object.keys(argv)
        .filter(key => key !== '--' && key.includes('-'))
        .forEach(key => {
          delete argv[key]
        })
    }
    if (configuration['strip-aliased']) {
      ;[]
        .concat(...Object.keys(aliases).map(k => aliases[k]))
        .forEach(alias => {
          if (configuration['camel-case-expansion'] && alias.includes('-')) {
            delete argv[
              alias
                .split('.')
                .map(prop => camelCase(prop))
                .join('.')
            ]
          }
          delete argv[alias]
        })
    }
    // Push argument into positional array, applying numeric coercion:
    function pushPositional(arg) {
      const maybeCoercedNumber = maybeCoerceNumber('_', arg)
      if (
        typeof maybeCoercedNumber === 'string' ||
        typeof maybeCoercedNumber === 'number'
      ) {
        argv._.push(maybeCoercedNumber)
      }
    }
    // how many arguments should we consume, based
    // on the nargs option?
    function eatNargs(i, key, args, argAfterEqualSign) {
      let ii
      let toEat = checkAllAliases(key, flags.nargs)
      // NaN has a special meaning for the array type, indicating that one or
      // more values are expected.
      toEat = typeof toEat !== 'number' || isNaN(toEat) ? 1 : toEat
      if (toEat === 0) {
        if (!isUndefined(argAfterEqualSign)) {
          error = Error(__('Argument unexpected for: %s', key))
        }
        setArg(key, defaultValue(key))
        return i
      }
      let available = isUndefined(argAfterEqualSign) ? 0 : 1
      if (configuration['nargs-eats-options']) {
        // classic behavior, yargs eats positional and dash arguments.
        if (args.length - (i + 1) + available < toEat) {
          error = Error(__('Not enough arguments following: %s', key))
        }
        available = toEat
      } else {
        // nargs will not consume flag arguments, e.g., -abc, --foo,
        // and terminates when one is observed.
        for (ii = i + 1; ii < args.length; ii++) {
          if (
            !args[ii].match(/^-[^0-9]/) ||
            args[ii].match(negative) ||
            isUnknownOptionAsArg(args[ii])
          ) {
            available++
          } else {
            break
          }
        }
        if (available < toEat) {
          error = Error(__('Not enough arguments following: %s', key))
        }
      }
      let consumed = Math.min(available, toEat)
      if (!isUndefined(argAfterEqualSign) && consumed > 0) {
        setArg(key, argAfterEqualSign)
        consumed--
      }
      for (ii = i + 1; ii < consumed + i + 1; ii++) {
        setArg(key, args[ii])
      }
      return i + consumed
    }
    // if an option is an array, eat all non-hyphenated arguments
    // following it... YUM!
    // e.g., --foo apple banana cat becomes ["apple", "banana", "cat"]
    function eatArray(i, key, args, argAfterEqualSign) {
      let argsToSet = []
      let next = argAfterEqualSign || args[i + 1]
      // If both array and nargs are configured, enforce the nargs count:
      const nargsCount = checkAllAliases(key, flags.nargs)
      if (checkAllAliases(key, flags.bools) && !/^(true|false)$/.test(next)) {
        argsToSet.push(true)
      } else if (
        isUndefined(next) ||
        (isUndefined(argAfterEqualSign) &&
          /^-/.test(next) &&
          !negative.test(next) &&
          !isUnknownOptionAsArg(next))
      ) {
        // for keys without value ==> argsToSet remains an empty []
        // set user default value, if available
        if (defaults[key] !== undefined) {
          const defVal = defaults[key]
          argsToSet = Array.isArray(defVal) ? defVal : [defVal]
        }
      } else {
        // value in --option=value is eaten as is
        if (!isUndefined(argAfterEqualSign)) {
          argsToSet.push(processValue(key, argAfterEqualSign, true))
        }
        for (let ii = i + 1; ii < args.length; ii++) {
          if (
            (!configuration['greedy-arrays'] && argsToSet.length > 0) ||
            (nargsCount &&
              typeof nargsCount === 'number' &&
              argsToSet.length >= nargsCount)
          ) {
            break
          }
          next = args[ii]
          if (
            /^-/.test(next) &&
            !negative.test(next) &&
            !isUnknownOptionAsArg(next)
          ) {
            break
          }
          i = ii
          argsToSet.push(processValue(key, next, inputIsString))
        }
      }
      // If both array and nargs are configured, create an error if less than
      // nargs positionals were found. NaN has special meaning, indicating
      // that at least one value is required (more are okay).
      if (
        typeof nargsCount === 'number' &&
        ((nargsCount && argsToSet.length < nargsCount) ||
          (isNaN(nargsCount) && argsToSet.length === 0))
      ) {
        error = Error(__('Not enough arguments following: %s', key))
      }
      setArg(key, argsToSet)
      return i
    }
    function setArg(key, val, shouldStripQuotes = inputIsString) {
      if (/-/.test(key) && configuration['camel-case-expansion']) {
        const alias = key
          .split('.')
          .map(function (prop) {
            return camelCase(prop)
          })
          .join('.')
        addNewAlias(key, alias)
      }
      const value = processValue(key, val, shouldStripQuotes)
      const splitKey = key.split('.')
      setKey(argv, splitKey, value)
      // handle populating aliases of the full key
      if (flags.aliases[key]) {
        flags.aliases[key].forEach(function (x) {
          const keyProperties = x.split('.')
          setKey(argv, keyProperties, value)
        })
      }
      // handle populating aliases of the first element of the dot-notation key
      if (splitKey.length > 1 && configuration['dot-notation']) {
        ;(flags.aliases[splitKey[0]] || []).forEach(function (x) {
          let keyProperties = x.split('.')
          // expand alias with nested objects in key
          const a = [].concat(splitKey)
          a.shift() // nuke the old key.
          keyProperties = keyProperties.concat(a)
          // populate alias only if is not already an alias of the full key
          // (already populated above)
          if (!(flags.aliases[key] || []).includes(keyProperties.join('.'))) {
            setKey(argv, keyProperties, value)
          }
        })
      }
      // Set normalize getter and setter when key is in 'normalize' but isn't an array
      if (
        checkAllAliases(key, flags.normalize) &&
        !checkAllAliases(key, flags.arrays)
      ) {
        const keys = [key].concat(flags.aliases[key] || [])
        keys.forEach(function (key) {
          Object.defineProperty(argvReturn, key, {
            enumerable: true,
            get() {
              return val
            },
            set(value) {
              val = typeof value === 'string' ? mixin.normalize(value) : value
            }
          })
        })
      }
    }
    function addNewAlias(key, alias) {
      if (!(flags.aliases[key] && flags.aliases[key].length)) {
        flags.aliases[key] = [alias]
        newAliases[alias] = true
      }
      if (!(flags.aliases[alias] && flags.aliases[alias].length)) {
        addNewAlias(alias, key)
      }
    }
    function processValue(key, val, shouldStripQuotes) {
      // strings may be quoted, clean this up as we assign values.
      if (shouldStripQuotes) {
        val = stripQuotes(val)
      }
      // handle parsing boolean arguments --foo=true --bar false.
      if (
        checkAllAliases(key, flags.bools) ||
        checkAllAliases(key, flags.counts)
      ) {
        if (typeof val === 'string') {
          val = val === 'true'
        }
      }
      let value = Array.isArray(val)
        ? val.map(function (v) {
            return maybeCoerceNumber(key, v)
          })
        : maybeCoerceNumber(key, val)
      // increment a count given as arg (either no value or value parsed as boolean)
      if (
        checkAllAliases(key, flags.counts) &&
        (isUndefined(value) || typeof value === 'boolean')
      ) {
        value = increment()
      }
      // Set normalized value when key is in 'normalize' and in 'arrays'
      if (
        checkAllAliases(key, flags.normalize) &&
        checkAllAliases(key, flags.arrays)
      ) {
        if (Array.isArray(val)) {
          value = val.map(val => {
            return mixin.normalize(val)
          })
        } else {
          value = mixin.normalize(val)
        }
      }
      return value
    }
    function maybeCoerceNumber(key, value) {
      if (!configuration['parse-positional-numbers'] && key === '_') {
        return value
      }
      if (
        !checkAllAliases(key, flags.strings) &&
        !checkAllAliases(key, flags.bools) &&
        !Array.isArray(value)
      ) {
        const shouldCoerceNumber =
          looksLikeNumber(value) &&
          configuration['parse-numbers'] &&
          Number.isSafeInteger(Math.floor(parseFloat(`${value}`)))
        if (
          shouldCoerceNumber ||
          (!isUndefined(value) && checkAllAliases(key, flags.numbers))
        ) {
          value = Number(value)
        }
      }
      return value
    }
    // set args from config.json file, this should be
    // applied last so that defaults can be applied.
    function setConfig(argv) {
      const configLookup = Object.create(null)
      // expand defaults/aliases, in-case any happen to reference
      // the config.json file.
      applyDefaultsAndAliases(configLookup, flags.aliases, defaults)
      Object.keys(flags.configs).forEach(function (configKey) {
        const configPath = argv[configKey] || configLookup[configKey]
        if (configPath) {
          try {
            let config = null
            const resolvedConfigPath = mixin.resolve(mixin.cwd(), configPath)
            const resolveConfig = flags.configs[configKey]
            if (typeof resolveConfig === 'function') {
              try {
                config = resolveConfig(resolvedConfigPath)
              } catch (e) {
                config = e
              }
              if (config instanceof Error) {
                error = config
                return
              }
            } else {
              config = mixin.require(resolvedConfigPath)
            }
            setConfigObject(config)
          } catch (ex) {
            // Deno will receive a PermissionDenied error if an attempt is
            // made to load config without the --allow-read flag:
            if (ex.name === 'PermissionDenied') {
              error = ex
            } else if (argv[configKey]) {
              error = Error(__('Invalid JSON config file: %s', configPath))
            }
          }
        }
      })
    }
    // set args from config object.
    // it recursively checks nested objects.
    function setConfigObject(config, prev) {
      Object.keys(config).forEach(function (key) {
        const value = config[key]
        const fullKey = prev ? prev + '.' + key : key
        // if the value is an inner object and we have dot-notation
        // enabled, treat inner objects in config the same as
        // heavily nested dot notations (foo.bar.apple).
        if (
          typeof value === 'object' &&
          value !== null &&
          !Array.isArray(value) &&
          configuration['dot-notation']
        ) {
          // if the value is an object but not an array, check nested object
          setConfigObject(value, fullKey)
        } else {
          // setting arguments via CLI takes precedence over
          // values within the config file.
          if (
            !hasKey(argv, fullKey.split('.')) ||
            (checkAllAliases(fullKey, flags.arrays) &&
              configuration['combine-arrays'])
          ) {
            setArg(fullKey, value)
          }
        }
      })
    }
    // set all config objects passed in opts
    function setConfigObjects() {
      if (typeof configObjects !== 'undefined') {
        configObjects.forEach(function (configObject) {
          setConfigObject(configObject)
        })
      }
    }
    function applyEnvVars(argv, configOnly) {
      if (typeof envPrefix === 'undefined') {
        return
      }
      const prefix = typeof envPrefix === 'string' ? envPrefix : ''
      const env = mixin.env()
      Object.keys(env).forEach(function (envVar) {
        if (prefix === '' || envVar.lastIndexOf(prefix, 0) === 0) {
          // get array of nested keys and convert them to camel case
          const keys = envVar.split('__').map(function (key, i) {
            if (i === 0) {
              key = key.substring(prefix.length)
            }
            return camelCase(key)
          })
          if (
            ((configOnly && flags.configs[keys.join('.')]) || !configOnly) &&
            !hasKey(argv, keys)
          ) {
            setArg(keys.join('.'), env[envVar])
          }
        }
      })
    }
    function applyCoercions(argv) {
      let coerce
      const applied = new Set()
      Object.keys(argv).forEach(function (key) {
        if (!applied.has(key)) {
          // If we haven't already coerced this option via one of its aliases
          coerce = checkAllAliases(key, flags.coercions)
          if (typeof coerce === 'function') {
            try {
              const value = maybeCoerceNumber(key, coerce(argv[key]))
              ;[].concat(flags.aliases[key] || [], key).forEach(ali => {
                applied.add(ali)
                argv[ali] = value
              })
            } catch (err) {
              error = err
            }
          }
        }
      })
    }
    function setPlaceholderKeys(argv) {
      flags.keys.forEach(key => {
        // don't set placeholder keys for dot notation options 'foo.bar'.
        if (~key.indexOf('.')) {
          return
        }
        if (typeof argv[key] === 'undefined') {
          argv[key] = undefined
        }
      })
      return argv
    }
    function applyDefaultsAndAliases(obj, aliases, defaults, canLog = false) {
      Object.keys(defaults).forEach(function (key) {
        if (!hasKey(obj, key.split('.'))) {
          setKey(obj, key.split('.'), defaults[key])
          if (canLog) {
            defaulted[key] = true
          }
          ;(aliases[key] || []).forEach(function (x) {
            if (hasKey(obj, x.split('.'))) {
              return
            }
            setKey(obj, x.split('.'), defaults[key])
          })
        }
      })
    }
    function hasKey(obj, keys) {
      let o = obj
      if (!configuration['dot-notation']) {
        keys = [keys.join('.')]
      }
      keys.slice(0, -1).forEach(function (key) {
        o = o[key] || {}
      })
      const key = keys[keys.length - 1]
      if (typeof o !== 'object') {
        return false
      } else {
        return key in o
      }
    }
    function setKey(obj, keys, value) {
      let o = obj
      if (!configuration['dot-notation']) {
        keys = [keys.join('.')]
      }
      keys.slice(0, -1).forEach(function (key) {
        // TODO(bcoe): in the next major version of yargs, switch to
        // Object.create(null) for dot notation:
        key = sanitizeKey(key)
        if (typeof o === 'object' && o[key] === undefined) {
          o[key] = {}
        }
        if (typeof o[key] !== 'object' || Array.isArray(o[key])) {
          // ensure that o[key] is an array, and that the last item is an empty object.
          if (Array.isArray(o[key])) {
            o[key].push({})
          } else {
            o[key] = [o[key], {}]
          }
          // we want to update the empty object at the end of the o[key] array, so set o to that object
          o = o[key][o[key].length - 1]
        } else {
          o = o[key]
        }
      })
      // TODO(bcoe): in the next major version of yargs, switch to
      // Object.create(null) for dot notation:
      const key = sanitizeKey(keys[keys.length - 1])
      const isTypeArray = checkAllAliases(keys.join('.'), flags.arrays)
      const isValueArray = Array.isArray(value)
      let duplicate = configuration['duplicate-arguments-array']
      // nargs has higher priority than duplicate
      if (!duplicate && checkAllAliases(key, flags.nargs)) {
        duplicate = true
        if (
          (!isUndefined(o[key]) && flags.nargs[key] === 1) ||
          (Array.isArray(o[key]) && o[key].length === flags.nargs[key])
        ) {
          o[key] = undefined
        }
      }
      if (value === increment()) {
        o[key] = increment(o[key])
      } else if (Array.isArray(o[key])) {
        if (duplicate && isTypeArray && isValueArray) {
          o[key] = configuration['flatten-duplicate-arrays']
            ? o[key].concat(value)
            : (Array.isArray(o[key][0]) ? o[key] : [o[key]]).concat([value])
        } else if (
          !duplicate &&
          Boolean(isTypeArray) === Boolean(isValueArray)
        ) {
          o[key] = value
        } else {
          o[key] = o[key].concat([value])
        }
      } else if (o[key] === undefined && isTypeArray) {
        o[key] = isValueArray ? value : [value]
      } else if (
        duplicate &&
        !(
          o[key] === undefined ||
          checkAllAliases(key, flags.counts) ||
          checkAllAliases(key, flags.bools)
        )
      ) {
        o[key] = [o[key], value]
      } else {
        o[key] = value
      }
    }
    // extend the aliases list with inferred aliases.
    function extendAliases(...args) {
      args.forEach(function (obj) {
        Object.keys(obj || {}).forEach(function (key) {
          // short-circuit if we've already added a key
          // to the aliases array, for example it might
          // exist in both 'opts.default' and 'opts.key'.
          if (flags.aliases[key]) {
            return
          }
          flags.aliases[key] = [].concat(aliases[key] || [])
          // For "--option-name", also set argv.optionName
          flags.aliases[key].concat(key).forEach(function (x) {
            if (/-/.test(x) && configuration['camel-case-expansion']) {
              const c = camelCase(x)
              if (c !== key && flags.aliases[key].indexOf(c) === -1) {
                flags.aliases[key].push(c)
                newAliases[c] = true
              }
            }
          })
          // For "--optionName", also set argv['option-name']
          flags.aliases[key].concat(key).forEach(function (x) {
            if (
              x.length > 1 &&
              /[A-Z]/.test(x) &&
              configuration['camel-case-expansion']
            ) {
              const c = decamelize(x, '-')
              if (c !== key && flags.aliases[key].indexOf(c) === -1) {
                flags.aliases[key].push(c)
                newAliases[c] = true
              }
            }
          })
          flags.aliases[key].forEach(function (x) {
            flags.aliases[x] = [key].concat(
              flags.aliases[key].filter(function (y) {
                return x !== y
              })
            )
          })
        })
      })
    }
    function checkAllAliases(key, flag) {
      const toCheck = [].concat(flags.aliases[key] || [], key)
      const keys = Object.keys(flag)
      const setAlias = toCheck.find(key => keys.includes(key))
      return setAlias ? flag[setAlias] : false
    }
    function hasAnyFlag(key) {
      const flagsKeys = Object.keys(flags)
      const toCheck = [].concat(flagsKeys.map(k => flags[k]))
      return toCheck.some(function (flag) {
        return Array.isArray(flag) ? flag.includes(key) : flag[key]
      })
    }
    function hasFlagsMatching(arg, ...patterns) {
      const toCheck = [].concat(...patterns)
      return toCheck.some(function (pattern) {
        const match = arg.match(pattern)
        return match && hasAnyFlag(match[1])
      })
    }
    // based on a simplified version of the short flag group parsing logic
    function hasAllShortFlags(arg) {
      // if this is a negative number, or doesn't start with a single hyphen, it's not a short flag group
      if (arg.match(negative) || !arg.match(/^-[^-]+/)) {
        return false
      }
      let hasAllFlags = true
      let next
      const letters = arg.slice(1).split('')
      for (let j = 0; j < letters.length; j++) {
        next = arg.slice(j + 2)
        if (!hasAnyFlag(letters[j])) {
          hasAllFlags = false
          break
        }
        if (
          (letters[j + 1] && letters[j + 1] === '=') ||
          next === '-' ||
          (/[A-Za-z]/.test(letters[j]) &&
            /^-?\d+(\.\d*)?(e-?\d+)?$/.test(next)) ||
          (letters[j + 1] && letters[j + 1].match(/\W/))
        ) {
          break
        }
      }
      return hasAllFlags
    }
    function isUnknownOptionAsArg(arg) {
      return configuration['unknown-options-as-args'] && isUnknownOption(arg)
    }
    function isUnknownOption(arg) {
      arg = arg.replace(/^-{3,}/, '--')
      // ignore negative numbers
      if (arg.match(negative)) {
        return false
      }
      // if this is a short option group and all of them are configured, it isn't unknown
      if (hasAllShortFlags(arg)) {
        return false
      }
      // e.g. '--count=2'
      const flagWithEquals = /^-+([^=]+?)=[\s\S]*$/
      // e.g. '-a' or '--arg'
      const normalFlag = /^-+([^=]+?)$/
      // e.g. '-a-'
      const flagEndingInHyphen = /^-+([^=]+?)-$/
      // e.g. '-abc123'
      const flagEndingInDigits = /^-+([^=]+?\d+)$/
      // e.g. '-a/usr/local'
      const flagEndingInNonWordCharacters = /^-+([^=]+?)\W+.*$/
      // check the different types of flag styles, including negatedBoolean, a pattern defined near the start of the parse method
      return !hasFlagsMatching(
        arg,
        flagWithEquals,
        negatedBoolean,
        normalFlag,
        flagEndingInHyphen,
        flagEndingInDigits,
        flagEndingInNonWordCharacters
      )
    }
    // make a best effort to pick a default value
    // for an option based on name and type.
    function defaultValue(key) {
      if (
        !checkAllAliases(key, flags.bools) &&
        !checkAllAliases(key, flags.counts) &&
        `${key}` in defaults
      ) {
        return defaults[key]
      } else {
        return defaultForType(guessType(key))
      }
    }
    // return a default value, given the type of a flag.,
    function defaultForType(type) {
      const def = {
        [DefaultValuesForTypeKey.BOOLEAN]: true,
        [DefaultValuesForTypeKey.STRING]: '',
        [DefaultValuesForTypeKey.NUMBER]: undefined,
        [DefaultValuesForTypeKey.ARRAY]: []
      }
      return def[type]
    }
    // given a flag, enforce a default type.
    function guessType(key) {
      let type = DefaultValuesForTypeKey.BOOLEAN
      if (checkAllAliases(key, flags.strings)) {
        type = DefaultValuesForTypeKey.STRING
      } else if (checkAllAliases(key, flags.numbers)) {
        type = DefaultValuesForTypeKey.NUMBER
      } else if (checkAllAliases(key, flags.bools)) {
        type = DefaultValuesForTypeKey.BOOLEAN
      } else if (checkAllAliases(key, flags.arrays)) {
        type = DefaultValuesForTypeKey.ARRAY
      }
      return type
    }
    function isUndefined(num) {
      return num === undefined
    }
    // check user configuration settings for inconsistencies
    function checkConfiguration() {
      // count keys should not be set as array/narg
      Object.keys(flags.counts).find(key => {
        if (checkAllAliases(key, flags.arrays)) {
          error = Error(
            __(
              'Invalid configuration: %s, opts.count excludes opts.array.',
              key
            )
          )
          return true
        } else if (checkAllAliases(key, flags.nargs)) {
          error = Error(
            __('Invalid configuration: %s, opts.count excludes opts.narg.', key)
          )
          return true
        }
        return false
      })
    }
    return {
      aliases: Object.assign({}, flags.aliases),
      argv: Object.assign(argvReturn, argv),
      configuration: configuration,
      defaulted: Object.assign({}, defaulted),
      error: error,
      newAliases: Object.assign({}, newAliases)
    }
  }
}
// if any aliases reference each other, we should
// merge them together.
function combineAliases(aliases) {
  const aliasArrays = []
  const combined = Object.create(null)
  let change = true
  // turn alias lookup hash {key: ['alias1', 'alias2']} into
  // a simple array ['key', 'alias1', 'alias2']
  Object.keys(aliases).forEach(function (key) {
    aliasArrays.push([].concat(aliases[key], key))
  })
  // combine arrays until zero changes are
  // made in an iteration.
  while (change) {
    change = false
    for (let i = 0; i < aliasArrays.length; i++) {
      for (let ii = i + 1; ii < aliasArrays.length; ii++) {
        const intersect = aliasArrays[i].filter(function (v) {
          return aliasArrays[ii].indexOf(v) !== -1
        })
        if (intersect.length) {
          aliasArrays[i] = aliasArrays[i].concat(aliasArrays[ii])
          aliasArrays.splice(ii, 1)
          change = true
          break
        }
      }
    }
  }
  // map arrays back to the hash-lookup (de-dupe while
  // we're at it).
  aliasArrays.forEach(function (aliasArray) {
    aliasArray = aliasArray.filter(function (v, i, self) {
      return self.indexOf(v) === i
    })
    const lastAlias = aliasArray.pop()
    if (lastAlias !== undefined && typeof lastAlias === 'string') {
      combined[lastAlias] = aliasArray
    }
  })
  return combined
}
// this function should only be called when a count is given as an arg
// it is NOT called to set a default value
// thus we can start the count at 1 instead of 0
function increment(orig) {
  return orig !== undefined ? orig + 1 : 1
}
// TODO(bcoe): in the next major version of yargs, switch to
// Object.create(null) for dot notation:
function sanitizeKey(key) {
  if (key === '__proto__') {
    return '___proto___'
  }
  return key
}
function stripQuotes(val) {
  return typeof val === 'string' &&
    (val[0] === "'" || val[0] === '"') &&
    val[val.length - 1] === val[0]
    ? val.substring(1, val.length - 1)
    : val
}

/**
 * @fileoverview Main entrypoint for libraries using yargs-parser in Node.js
 * CJS and ESM environments.
 *
 * @license
 * Copyright (c) 2016, Contributors
 * SPDX-License-Identifier: ISC
 */
let _a, _b, _c
// See https://github.com/yargs/yargs-parser#supported-nodejs-versions for our
// version support policy. The YARGS_MIN_NODE_VERSION is used for testing only.
const minNodeVersion =
  process && process.env && process.env.YARGS_MIN_NODE_VERSION
    ? Number(process.env.YARGS_MIN_NODE_VERSION)
    : 12
const nodeVersion =
  (_b =
    (_a =
      process === null || process === void 0 ? void 0 : process.versions) ===
      null || _a === void 0
      ? void 0
      : _a.node) !== null && _b !== void 0
    ? _b
    : (_c =
          process === null || process === void 0 ? void 0 : process.version) ===
          null || _c === void 0
      ? void 0
      : _c.slice(1)
if (nodeVersion) {
  const major = Number(nodeVersion.match(/^([^.]+)/)[1])
  if (major < minNodeVersion) {
    throw Error(
      `yargs parser supports a minimum Node.js version of ${minNodeVersion}. Read our version support policy: https://github.com/yargs/yargs-parser#supported-nodejs-versions`
    )
  }
}
// Creates a yargs-parser instance using Node.js standard libraries:
const env$1 = process ? process.env : {}
const parser = new YargsParser({
  cwd: process.cwd,
  env: () => {
    return env$1
  },
  format: util$3.format,
  normalize: path$1.normalize,
  resolve: path$1.resolve,
  // TODO: figure  out a  way to combine ESM and CJS coverage, such  that
  // we can exercise all the lines below:
  require: path => {
    if (typeof require !== 'undefined') {
      return require(path)
    } else if (path.match(/\.json$/)) {
      // Addresses: https://github.com/yargs/yargs/issues/2040
      return JSON.parse(fs$1.readFileSync(path, 'utf8'))
    } else {
      throw Error('only .json config files are supported in ESM')
    }
  }
})
const yargsParser = function Parser(args, opts) {
  const result = parser.parse(args.slice(), opts)
  return result.argv
}
yargsParser.detailed = function (args, opts) {
  return parser.parse(args.slice(), opts)
}
yargsParser.camelCase = camelCase
yargsParser.decamelize = decamelize
yargsParser.looksLikeNumber = looksLikeNumber

const toBatchSyntax = {}

let hasRequiredToBatchSyntax
function requireToBatchSyntax() {
  if (hasRequiredToBatchSyntax) {
    return toBatchSyntax
  }
  hasRequiredToBatchSyntax = 1
  toBatchSyntax.replaceDollarWithPercentPair = replaceDollarWithPercentPair
  toBatchSyntax.convertToSetCommand = convertToSetCommand
  toBatchSyntax.convertToSetCommands = convertToSetCommands
  function convertToSetCommand(key, value) {
    let line = ''
    key = key || ''
    key = key.trim()
    value = value || ''
    value = value.trim()
    if (key && value && value.length > 0) {
      line = '@SET ' + key + '=' + replaceDollarWithPercentPair(value) + '\r\n'
    }
    return line
  }
  function extractVariableValuePairs(declarations) {
    const pairs = {}
    declarations.map(function (declaration) {
      const split = declaration.split('=')
      pairs[split[0]] = split[1]
    })
    return pairs
  }
  function convertToSetCommands(variableString) {
    const variableValuePairs = extractVariableValuePairs(
      variableString.split(' ')
    )
    let variableDeclarationsAsBatch = ''
    Object.keys(variableValuePairs).forEach(function (key) {
      variableDeclarationsAsBatch += convertToSetCommand(
        key,
        variableValuePairs[key]
      )
    })
    return variableDeclarationsAsBatch
  }
  function replaceDollarWithPercentPair(value) {
    const dollarExpressions = /\$\{?([^$@#?\- \t{}:]+)\}?/g
    let result = ''
    let startIndex = 0
    do {
      const match = dollarExpressions.exec(value)
      if (match) {
        const betweenMatches = value.substring(startIndex, match.index) || ''
        result += betweenMatches + '%' + match[1] + '%'
        startIndex = dollarExpressions.lastIndex
      }
    } while (dollarExpressions.lastIndex > 0)
    result += value.slice(startIndex)
    return result
  }
  return toBatchSyntax
}

let lib$l
let hasRequiredLib$l
function requireLib$l() {
  if (hasRequiredLib$l) {
    return lib$l
  }
  hasRequiredLib$l = 1
  // On windows, create a .cmd file.
  // Read the #! in the file to see what it uses.  The vast majority
  // of the time, this will be either:
  // "#!/usr/bin/env <prog> <args...>"
  // or:
  // "#!<prog> <args...>"
  //
  // Write a binroot/pkg.bin + ".cmd" file that has this line in it:
  // @<prog> <args...> %dp0%<target> %*

  const { chmod, mkdir, readFile, stat, unlink, writeFile } = require$$1$7
  const { dirname, relative } = require$$0$5
  const toBatchSyntax = requireToBatchSyntax()
  // linting disabled because this regex is really long
  // eslint-disable-next-line max-len
  const shebangExpr =
    /^#!\s*(?:\/usr\/bin\/env\s+(?:-S\s+)?((?:[^ \t=]+=[^ \t=]+\s+)*))?([^ \t]+)(.*)$/
  const cmdShimIfExists = (from, to) =>
    stat(from).then(
      () => cmdShim(from, to),
      () => {}
    )

  // Try to unlink, but ignore errors.
  // Any problems will surface later.
  const rm = path => unlink(path).catch(() => {})
  const cmdShim = (from, to) => stat(from).then(() => cmdShim_(from, to))
  const cmdShim_ = (from, to) =>
    Promise.all([rm(to), rm(to + '.cmd'), rm(to + '.ps1')]).then(() =>
      writeShim(from, to)
    )
  const writeShim = (from, to) =>
    // make a cmd file and a sh script
    // First, check if the bin is a #! of some sort.
    // If not, then assume it's something that'll be compiled, or some other
    // sort of script, and just call it directly.
    mkdir(dirname(to), {
      recursive: true
    })
      .then(() => readFile(from, 'utf8'))
      .then(
        data => {
          const firstLine = data.trim().split(/\r*\n/)[0]
          const shebang = firstLine.match(shebangExpr)
          if (!shebang) {
            return writeShim_(from, to)
          }
          const vars = shebang[1] || ''
          const prog = shebang[2]
          const args = shebang[3] || ''
          return writeShim_(from, to, prog, args, vars)
        },
        () => writeShim_(from, to)
      )
  const writeShim_ = (from, to, prog, args, variables) => {
    let shTarget = relative(dirname(to), from)
    let target = shTarget.split('/').join('\\')
    let longProg
    let shProg = prog && prog.split('\\').join('/')
    let shLongProg
    let pwshProg = shProg && `"${shProg}$exe"`
    let pwshLongProg
    shTarget = shTarget.split('\\').join('/')
    args = args || ''
    variables = variables || ''
    if (!prog) {
      prog = `"%dp0%\\${target}"`
      shProg = `"$basedir/${shTarget}"`
      pwshProg = shProg
      args = ''
      target = ''
      shTarget = ''
    } else {
      longProg = `"%dp0%\\${prog}.exe"`
      shLongProg = `"$basedir/${prog}"`
      pwshLongProg = `"$basedir/${prog}$exe"`
      target = `"%dp0%\\${target}"`
      shTarget = `"$basedir/${shTarget}"`
    }

    // Subroutine trick to fix https://github.com/npm/cmd-shim/issues/10
    // and https://github.com/npm/cli/issues/969
    const head =
      '@ECHO off\r\n' +
      'GOTO start\r\n' +
      ':find_dp0\r\n' +
      'SET dp0=%~dp0\r\n' +
      'EXIT /b\r\n' +
      ':start\r\n' +
      'SETLOCAL\r\n' +
      'CALL :find_dp0\r\n'
    let cmd
    if (longProg) {
      shLongProg = shLongProg.trim()
      args = args.trim()
      const variablesBatch = toBatchSyntax.convertToSetCommands(variables)
      cmd =
        head +
        variablesBatch +
        '\r\n' +
        `IF EXIST ${longProg} (\r\n` +
        `  SET "_prog=${longProg.replace(/(^")|("$)/g, '')}"\r\n` +
        ') ELSE (\r\n' +
        `  SET "_prog=${prog.replace(/(^")|("$)/g, '')}"\r\n` +
        '  SET PATHEXT=%PATHEXT:;.JS;=;%\r\n' +
        ')\r\n' +
        '\r\n' +
        // prevent "Terminate Batch Job? (Y/n)" message
        // https://github.com/npm/cli/issues/969#issuecomment-737496588
        'endLocal & goto #_undefined_# 2>NUL || title %COMSPEC% & ' +
        `"%_prog%" ${args} ${target} %*\r\n`
    } else {
      cmd = `${head}${prog} ${args} ${target} %*\r\n`
    }

    // #!/bin/sh
    // basedir=`dirname "$0"`
    //
    // case `uname` in
    //     *CYGWIN*|*MINGW*|*MSYS*)
    //       if command -v cygpath > /dev/null 2>&1; then
    //           basedir=`cygpath -w "$basedir"`
    //       fi
    //     ;;
    // esac
    //
    // if [ -x "$basedir/node.exe" ]; then
    //   exec "$basedir/node.exe" "$basedir/node_modules/npm/bin/npm-cli.js" "$@"
    // else
    //   exec node "$basedir/node_modules/npm/bin/npm-cli.js" "$@"
    // fi

    let sh = '#!/bin/sh\n'
    sh =
      sh +
      `basedir=$(dirname "$(echo "$0" | sed -e 's,\\\\,/,g')")\n` +
      '\n' +
      'case `uname` in\n' +
      '    *CYGWIN*|*MINGW*|*MSYS*)\n' +
      '        if command -v cygpath > /dev/null 2>&1; then\n' +
      '            basedir=`cygpath -w "$basedir"`\n' +
      '        fi\n' +
      '    ;;\n' +
      'esac\n' +
      '\n'
    if (shLongProg) {
      sh =
        sh +
        `if [ -x ${shLongProg} ]; then\n` +
        `  exec ${variables}${shLongProg} ${args} ${shTarget} "$@"\n` +
        'else \n' +
        `  exec ${variables}${shProg} ${args} ${shTarget} "$@"\n` +
        'fi\n'
    } else {
      sh = sh + `exec ${shProg} ${args} ${shTarget} "$@"\n`
    }

    // #!/usr/bin/env pwsh
    // $basedir=Split-Path $MyInvocation.MyCommand.Definition -Parent
    //
    // $ret=0
    // $exe = ""
    // if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWindows) {
    //   # Fix case when both the Windows and Linux builds of Node
    //   # are installed in the same directory
    //   $exe = ".exe"
    // }
    // if (Test-Path "$basedir/node") {
    //   # Suport pipeline input
    //   if ($MyInvocation.ExpectingInput) {
    //     input | & "$basedir/node$exe" "$basedir/node_modules/npm/bin/npm-cli.js" $args
    //   } else {
    //     & "$basedir/node$exe" "$basedir/node_modules/npm/bin/npm-cli.js" $args
    //   }
    //   $ret=$LASTEXITCODE
    // } else {
    //   # Support pipeline input
    //   if ($MyInvocation.ExpectingInput) {
    //     $input | & "node$exe" "$basedir/node_modules/npm/bin/npm-cli.js" $args
    //   } else {
    //     & "node$exe" "$basedir/node_modules/npm/bin/npm-cli.js" $args
    //   }
    //   $ret=$LASTEXITCODE
    // }
    // exit $ret
    let pwsh =
      '#!/usr/bin/env pwsh\n' +
      '$basedir=Split-Path $MyInvocation.MyCommand.Definition -Parent\n' +
      '\n' +
      '$exe=""\n' +
      'if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWindows) {\n' +
      '  # Fix case when both the Windows and Linux builds of Node\n' +
      '  # are installed in the same directory\n' +
      '  $exe=".exe"\n' +
      '}\n'
    if (shLongProg) {
      pwsh =
        pwsh +
        '$ret=0\n' +
        `if (Test-Path ${pwshLongProg}) {\n` +
        '  # Support pipeline input\n' +
        '  if ($MyInvocation.ExpectingInput) {\n' +
        `    $input | & ${pwshLongProg} ${args} ${shTarget} $args\n` +
        '  } else {\n' +
        `    & ${pwshLongProg} ${args} ${shTarget} $args\n` +
        '  }\n' +
        '  $ret=$LASTEXITCODE\n' +
        '} else {\n' +
        '  # Support pipeline input\n' +
        '  if ($MyInvocation.ExpectingInput) {\n' +
        `    $input | & ${pwshProg} ${args} ${shTarget} $args\n` +
        '  } else {\n' +
        `    & ${pwshProg} ${args} ${shTarget} $args\n` +
        '  }\n' +
        '  $ret=$LASTEXITCODE\n' +
        '}\n' +
        'exit $ret\n'
    } else {
      pwsh =
        pwsh +
        '# Support pipeline input\n' +
        'if ($MyInvocation.ExpectingInput) {\n' +
        `  $input | & ${pwshProg} ${args} ${shTarget} $args\n` +
        '} else {\n' +
        `  & ${pwshProg} ${args} ${shTarget} $args\n` +
        '}\n' +
        'exit $LASTEXITCODE\n'
    }
    return Promise.all([
      writeFile(to + '.ps1', pwsh, 'utf8'),
      writeFile(to + '.cmd', cmd, 'utf8'),
      writeFile(to, sh, 'utf8')
    ]).then(() => chmodShim(to))
  }
  const chmodShim = to =>
    Promise.all([
      chmod(to, 0o755),
      chmod(to + '.cmd', 0o755),
      chmod(to + '.ps1', 0o755)
    ])
  lib$l = cmdShim
  cmdShim.ifExists = cmdShimIfExists
  return lib$l
}

const libExports$4 = requireLib$l()

const cjs$1 = {}

const posix = {}

let hasRequiredPosix
function requirePosix() {
  if (hasRequiredPosix) {
    return posix
  }
  hasRequiredPosix = 1
  /**
   * This is the Posix implementation of isexe, which uses the file
   * mode and uid/gid values.
   *
   * @module
   */
  Object.defineProperty(posix, '__esModule', {
    value: true
  })
  posix.sync = posix.isexe = void 0
  const fs_1 = require$$0$6
  const promises_1 = require$$1$7
  /**
   * Determine whether a path is executable according to the mode and
   * current (or specified) user and group IDs.
   */
  const isexe = async (path, options = {}) => {
    const { ignoreErrors = false } = options
    try {
      return checkStat(await (0, promises_1.stat)(path), options)
    } catch (e) {
      const er = e
      if (ignoreErrors || er.code === 'EACCES') {
        return false
      }
      throw er
    }
  }
  posix.isexe = isexe
  /**
   * Synchronously determine whether a path is executable according to
   * the mode and current (or specified) user and group IDs.
   */
  const sync = (path, options = {}) => {
    const { ignoreErrors = false } = options
    try {
      return checkStat((0, fs_1.statSync)(path), options)
    } catch (e) {
      const er = e
      if (ignoreErrors || er.code === 'EACCES') {
        return false
      }
      throw er
    }
  }
  posix.sync = sync
  const checkStat = (stat, options) => stat.isFile() && checkMode(stat, options)
  const checkMode = (stat, options) => {
    const myUid = options.uid ?? process.getuid?.()
    const myGroups = options.groups ?? process.getgroups?.() ?? []
    const myGid = options.gid ?? process.getgid?.() ?? myGroups[0]
    if (myUid === undefined || myGid === undefined) {
      throw new Error('cannot get uid or gid')
    }
    const groups = new Set([myGid, ...myGroups])
    const mod = stat.mode
    const uid = stat.uid
    const gid = stat.gid
    const u = parseInt('100', 8)
    const g = parseInt('010', 8)
    const o = parseInt('001', 8)
    const ug = u | g
    return !!(
      mod & o ||
      (mod & g && groups.has(gid)) ||
      (mod & u && uid === myUid) ||
      (mod & ug && myUid === 0)
    )
  }
  return posix
}

const win32 = {}

let hasRequiredWin32
function requireWin32() {
  if (hasRequiredWin32) {
    return win32
  }
  hasRequiredWin32 = 1
  /**
   * This is the Windows implementation of isexe, which uses the file
   * extension and PATHEXT setting.
   *
   * @module
   */
  Object.defineProperty(win32, '__esModule', {
    value: true
  })
  win32.sync = win32.isexe = void 0
  const fs_1 = require$$0$6
  const promises_1 = require$$1$7
  /**
   * Determine whether a path is executable based on the file extension
   * and PATHEXT environment variable (or specified pathExt option)
   */
  const isexe = async (path, options = {}) => {
    const { ignoreErrors = false } = options
    try {
      return checkStat(await (0, promises_1.stat)(path), path, options)
    } catch (e) {
      const er = e
      if (ignoreErrors || er.code === 'EACCES') {
        return false
      }
      throw er
    }
  }
  win32.isexe = isexe
  /**
   * Synchronously determine whether a path is executable based on the file
   * extension and PATHEXT environment variable (or specified pathExt option)
   */
  const sync = (path, options = {}) => {
    const { ignoreErrors = false } = options
    try {
      return checkStat((0, fs_1.statSync)(path), path, options)
    } catch (e) {
      const er = e
      if (ignoreErrors || er.code === 'EACCES') {
        return false
      }
      throw er
    }
  }
  win32.sync = sync
  const checkPathExt = (path, options) => {
    const { pathExt = process.env.PATHEXT || '' } = options
    const peSplit = pathExt.split(';')
    if (peSplit.indexOf('') !== -1) {
      return true
    }
    for (let i = 0; i < peSplit.length; i++) {
      const p = peSplit[i].toLowerCase()
      const ext = path.substring(path.length - p.length).toLowerCase()
      if (p && ext === p) {
        return true
      }
    }
    return false
  }
  const checkStat = (stat, path, options) =>
    stat.isFile() && checkPathExt(path, options)
  return win32
}

const options$1 = {}

let hasRequiredOptions$1
function requireOptions$1() {
  if (hasRequiredOptions$1) {
    return options$1
  }
  hasRequiredOptions$1 = 1
  Object.defineProperty(options$1, '__esModule', {
    value: true
  })
  return options$1
}

let hasRequiredCjs$1
function requireCjs$1() {
  if (hasRequiredCjs$1) {
    return cjs$1
  }
  hasRequiredCjs$1 = 1
  ;(function (exports) {
    const __createBinding =
      (this && this.__createBinding) ||
      (Object.create
        ? function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            let desc = Object.getOwnPropertyDescriptor(m, k)
            if (
              !desc ||
              ('get' in desc
                ? !m.__esModule
                : desc.writable || desc.configurable)
            ) {
              desc = {
                enumerable: true,
                get: function () {
                  return m[k]
                }
              }
            }
            Object.defineProperty(o, k2, desc)
          }
        : function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            o[k2] = m[k]
          })
    const __setModuleDefault =
      (this && this.__setModuleDefault) ||
      (Object.create
        ? function (o, v) {
            Object.defineProperty(o, 'default', {
              enumerable: true,
              value: v
            })
          }
        : function (o, v) {
            o['default'] = v
          })
    const __importStar =
      (this && this.__importStar) ||
      function (mod) {
        if (mod && mod.__esModule) {
          return mod
        }
        const result = {}
        if (mod != null) {
          for (var k in mod)
            if (k !== 'default' && Object.prototype.hasOwnProperty.call(mod, k))
              __createBinding(result, mod, k)
        }
        __setModuleDefault(result, mod)
        return result
      }
    const __exportStar =
      (this && this.__exportStar) ||
      function (m, exports) {
        for (const p in m) {
          if (
            p !== 'default' &&
            !Object.prototype.hasOwnProperty.call(exports, p)
          )
            __createBinding(exports, m, p)
        }
      }
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.sync = exports.isexe = exports.posix = exports.win32 = void 0
    const posix = __importStar(requirePosix())
    exports.posix = posix
    const win32 = __importStar(requireWin32())
    exports.win32 = win32
    __exportStar(requireOptions$1(), exports)
    const platform = process.env._ISEXE_TEST_PLATFORM_ || process.platform
    const impl = platform === 'win32' ? win32 : posix
    /**
     * Determine whether a path is executable on the current platform.
     */
    exports.isexe = impl.isexe
    /**
     * Synchronously determine whether a path is executable on the
     * current platform.
     */
    exports.sync = impl.sync
  })(cjs$1)
  return cjs$1
}

let lib$k
let hasRequiredLib$k
function requireLib$k() {
  if (hasRequiredLib$k) {
    return lib$k
  }
  hasRequiredLib$k = 1
  const { isexe, sync: isexeSync } = requireCjs$1()
  const { join, delimiter, sep, posix } = require$$0$5
  const isWindows = process.platform === 'win32'

  // used to check for slashed in commands passed in. always checks for the posix
  // seperator on all platforms, and checks for the current separator when not on
  // a posix platform. don't use the isWindows check for this since that is mocked
  // in tests but we still need the code to actually work when called. that is also
  // why it is ignored from coverage.
  /* istanbul ignore next */
  const rSlash = new RegExp(
    `[${posix.sep}${sep === posix.sep ? '' : sep}]`.replace(/(\\)/g, '\\$1')
  )
  const rRel = new RegExp(`^\\.${rSlash.source}`)
  const getNotFoundError = cmd =>
    Object.assign(new Error(`not found: ${cmd}`), {
      code: 'ENOENT'
    })
  const getPathInfo = (
    cmd,
    {
      path: optPath = process.env.PATH,
      pathExt: optPathExt = process.env.PATHEXT,
      delimiter: optDelimiter = delimiter
    }
  ) => {
    // If it has a slash, then we don't bother searching the pathenv.
    // just check the file itself, and that's it.
    const pathEnv = cmd.match(rSlash)
      ? ['']
      : [
          // windows always checks the cwd first
          ...(isWindows ? [process.cwd()] : []),
          ...(optPath || /* istanbul ignore next: very unusual */ '').split(
            optDelimiter
          )
        ]
    if (isWindows) {
      const pathExtExe =
        optPathExt || ['.EXE', '.CMD', '.BAT', '.COM'].join(optDelimiter)
      const pathExt = pathExtExe
        .split(optDelimiter)
        .flatMap(item => [item, item.toLowerCase()])
      if (cmd.includes('.') && pathExt[0] !== '') {
        pathExt.unshift('')
      }
      return {
        pathEnv,
        pathExt,
        pathExtExe
      }
    }
    return {
      pathEnv,
      pathExt: ['']
    }
  }
  const getPathPart = (raw, cmd) => {
    const pathPart = /^".*"$/.test(raw) ? raw.slice(1, -1) : raw
    const prefix = !pathPart && rRel.test(cmd) ? cmd.slice(0, 2) : ''
    return prefix + join(pathPart, cmd)
  }
  const which = async (cmd, opt = {}) => {
    const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)
    const found = []
    for (const envPart of pathEnv) {
      const p = getPathPart(envPart, cmd)
      for (const ext of pathExt) {
        const withExt = p + ext
        const is = await isexe(withExt, {
          pathExt: pathExtExe,
          ignoreErrors: true
        })
        if (is) {
          if (!opt.all) {
            return withExt
          }
          found.push(withExt)
        }
      }
    }
    if (opt.all && found.length) {
      return found
    }
    if (opt.nothrow) {
      return null
    }
    throw getNotFoundError(cmd)
  }
  const whichSync = (cmd, opt = {}) => {
    const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)
    const found = []
    for (const pathEnvPart of pathEnv) {
      const p = getPathPart(pathEnvPart, cmd)
      for (const ext of pathExt) {
        const withExt = p + ext
        const is = isexeSync(withExt, {
          pathExt: pathExtExe,
          ignoreErrors: true
        })
        if (is) {
          if (!opt.all) {
            return withExt
          }
          found.push(withExt)
        }
      }
    }
    if (opt.all && found.length) {
      return found
    }
    if (opt.nothrow) {
      return null
    }
    throw getNotFoundError(cmd)
  }
  lib$k = which
  which.sync = whichSync
  return lib$k
}

const libExports$3 = requireLib$k()

let isDockerCached
function hasDockerEnv() {
  try {
    fs$1.statSync('/.dockerenv')
    return true
  } catch {
    return false
  }
}
function hasDockerCGroup() {
  try {
    return fs$1.readFileSync('/proc/self/cgroup', 'utf8').includes('docker')
  } catch {
    return false
  }
}
function isDocker() {
  // TODO: Use `??=` when targeting Node.js 16.
  if (isDockerCached === undefined) {
    isDockerCached = hasDockerEnv() || hasDockerCGroup()
  }
  return isDockerCached
}

let cachedResult

// Podman detection
const hasContainerEnv = () => {
  try {
    fs$1.statSync('/run/.containerenv')
    return true
  } catch {
    return false
  }
}
function isInsideContainer() {
  // TODO: Use `??=` when targeting Node.js 16.
  if (cachedResult === undefined) {
    cachedResult = hasContainerEnv() || isDocker()
  }
  return cachedResult
}

const isWsl = () => {
  if (process$2.platform !== 'linux') {
    return false
  }
  if (os$3.release().toLowerCase().includes('microsoft')) {
    if (isInsideContainer()) {
      return false
    }
    return true
  }
  try {
    return fs$1
      .readFileSync('/proc/version', 'utf8')
      .toLowerCase()
      .includes('microsoft')
      ? !isInsideContainer()
      : false
  } catch {
    return false
  }
}
const isWsl$1 = process$2.env.__IS_WSL_TEST__ ? isWsl : isWsl()

function defineLazyProperty(object, propertyName, valueGetter) {
  const define = value =>
    Object.defineProperty(object, propertyName, {
      value,
      enumerable: true,
      writable: true
    })
  Object.defineProperty(object, propertyName, {
    configurable: true,
    enumerable: true,
    get() {
      const result = valueGetter()
      define(result)
      return result
    },
    set(value) {
      define(value)
    }
  })
  return object
}

const execFileAsync$3 = util$3.promisify(childProcess.execFile)
async function defaultBrowserId() {
  if (process$2.platform !== 'darwin') {
    throw new Error('macOS only')
  }
  const { stdout } = await execFileAsync$3('defaults', [
    'read',
    'com.apple.LaunchServices/com.apple.launchservices.secure',
    'LSHandlers'
  ])

  // `(?!-)` is to prevent matching `LSHandlerRoleAll = "-";`.
  const match =
    /LSHandlerRoleAll = "(?!-)(?<id>[^"]+?)";\s+?LSHandlerURLScheme = (?:http|https);/.exec(
      stdout
    )
  return match?.groups.id ?? 'com.apple.Safari'
}

const execFileAsync$2 = util$3.promisify(childProcess.execFile)
async function runAppleScript(script, { humanReadableOutput = true } = {}) {
  if (process$2.platform !== 'darwin') {
    throw new Error('macOS only')
  }
  const outputArguments = humanReadableOutput ? [] : ['-ss']
  const { stdout } = await execFileAsync$2('osascript', [
    '-e',
    script,
    outputArguments
  ])
  return stdout.trim()
}

async function bundleName(bundleId) {
  return runAppleScript(
    `tell application "Finder" to set app_path to application file id "${bundleId}" as string\ntell application "System Events" to get value of property list item "CFBundleName" of property list file (app_path & ":Contents:Info.plist")`
  )
}

const execFileAsync$1 = util$3.promisify(childProcess.execFile)

// Windows doesn't have browser IDs in the same way macOS/Linux does so we give fake
// ones that look real and match the macOS/Linux versions for cross-platform apps.
const windowsBrowserProgIds = {
  AppXq0fevzme2pys62n3e0fbqa7peapykr8v: {
    name: 'Edge',
    id: 'com.microsoft.edge.old'
  },
  MSEdgeDHTML: {
    name: 'Edge',
    id: 'com.microsoft.edge'
  },
  // On macOS, it's "com.microsoft.edgemac"
  MSEdgeHTM: {
    name: 'Edge',
    id: 'com.microsoft.edge'
  },
  // Newer Edge/Win10 releases
  'IE.HTTP': {
    name: 'Internet Explorer',
    id: 'com.microsoft.ie'
  },
  FirefoxURL: {
    name: 'Firefox',
    id: 'org.mozilla.firefox'
  },
  ChromeHTML: {
    name: 'Chrome',
    id: 'com.google.chrome'
  },
  BraveHTML: {
    name: 'Brave',
    id: 'com.brave.Browser'
  },
  BraveBHTML: {
    name: 'Brave Beta',
    id: 'com.brave.Browser.beta'
  },
  BraveSSHTM: {
    name: 'Brave Nightly',
    id: 'com.brave.Browser.nightly'
  }
}
class UnknownBrowserError extends Error {}
async function defaultBrowser$1(_execFileAsync = execFileAsync$1) {
  const { stdout } = await _execFileAsync('reg', [
    'QUERY',
    ' HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\Shell\\Associations\\UrlAssociations\\http\\UserChoice',
    '/v',
    'ProgId'
  ])
  const match = /ProgId\s*REG_SZ\s*(?<id>\S+)/.exec(stdout)
  if (!match) {
    throw new UnknownBrowserError(
      `Cannot find Windows browser in stdout: ${JSON.stringify(stdout)}`
    )
  }
  const { id } = match.groups
  const browser = windowsBrowserProgIds[id]
  if (!browser) {
    throw new UnknownBrowserError(`Unknown browser ID: ${id}`)
  }
  return browser
}

const execFileAsync = util$3.promisify(childProcess.execFile)

// Inlined: https://github.com/sindresorhus/titleize/blob/main/index.js
const titleize = string =>
  string.toLowerCase().replaceAll(/(?:^|\s|-)\S/g, x => x.toUpperCase())
async function defaultBrowser() {
  if (process$2.platform === 'darwin') {
    const id = await defaultBrowserId()
    const name = await bundleName(id)
    return {
      name,
      id
    }
  }
  if (process$2.platform === 'linux') {
    const { stdout } = await execFileAsync('xdg-mime', [
      'query',
      'default',
      'x-scheme-handler/http'
    ])
    const id = stdout.trim()
    const name = titleize(id.replace(/.desktop$/, '').replace('-', ' '))
    return {
      name,
      id
    }
  }
  if (process$2.platform === 'win32') {
    return defaultBrowser$1()
  }
  throw new Error('Only macOS, Linux, and Windows are supported')
}

const execFile = util$3.promisify(childProcess.execFile)

// Path to included `xdg-open`.
const __dirname$1 = path$1.dirname(
  require$$0$b.fileURLToPath(
    typeof document === 'undefined'
      ? require$$2$1.pathToFileURL(__filename).href
      : (_documentCurrentScript &&
          _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' &&
          _documentCurrentScript.src) ||
          new URL('vendor.js', document.baseURI).href
  )
)
const localXdgOpenPath = path$1.join(__dirname$1, 'xdg-open')
const { platform, arch } = process$2

/**
Get the mount point for fixed drives in WSL.

@inner
@returns {string} The mount point.
*/
const getWslDrivesMountPoint = (() => {
  // Default value for "root" param
  // according to https://docs.microsoft.com/en-us/windows/wsl/wsl-config
  const defaultMountPoint = '/mnt/'
  let mountPoint
  return async function () {
    if (mountPoint) {
      // Return memoized mount point value
      return mountPoint
    }
    const configFilePath = '/etc/wsl.conf'
    let isConfigFileExists = false
    try {
      await fs$2.access(configFilePath, fs$2.constants.F_OK)
      isConfigFileExists = true
    } catch {}
    if (!isConfigFileExists) {
      return defaultMountPoint
    }
    const configContent = await fs$2.readFile(configFilePath, {
      encoding: 'utf8'
    })
    const configMountPoint = /(?<!#.*)root\s*=\s*(?<mountPoint>.*)/g.exec(
      configContent
    )
    if (!configMountPoint) {
      return defaultMountPoint
    }
    mountPoint = configMountPoint.groups.mountPoint.trim()
    mountPoint = mountPoint.endsWith('/') ? mountPoint : `${mountPoint}/`
    return mountPoint
  }
})()

/**
Get the PowerShell executable path in WSL environment.

@returns {Promise<string>} The absolute path to the PowerShell executable in WSL.
*/
const getPowershellPathFromWsl = async () => {
  const mountPoint = await getWslDrivesMountPoint()
  return `${mountPoint}c/Windows/System32/WindowsPowerShell/v1.0/powershell.exe`
}

/**
Get the default browser name in Windows from WSL.

@returns {Promise<string>} Browser name.
*/
async function getWindowsDefaultBrowserFromWsl() {
  const powershellPath = await getPowershellPathFromWsl()
  const rawCommand =
    '(Get-ItemProperty -Path "HKCU:\\Software\\Microsoft\\Windows\\Shell\\Associations\\UrlAssociations\\http\\UserChoice").ProgId'
  const encodedCommand = require$$0$3.Buffer.from(
    rawCommand,
    'utf16le'
  ).toString('base64')
  const { stdout } = await execFile(
    powershellPath,
    [
      '-NoProfile',
      '-NonInteractive',
      '-ExecutionPolicy',
      'Bypass',
      '-EncodedCommand',
      encodedCommand
    ],
    {
      encoding: 'utf8'
    }
  )
  const progId = stdout.trim()

  // Map ProgId to browser IDs
  const browserMap = {
    ChromeHTML: 'com.google.chrome',
    MSEdgeHTM: 'com.microsoft.edge',
    FirefoxURL: 'org.mozilla.firefox'
  }
  return browserMap[progId]
    ? {
        id: browserMap[progId]
      }
    : {}
}
const pTryEach = async (array, mapper) => {
  let latestError
  for (const item of array) {
    try {
      return await mapper(item) // eslint-disable-line no-await-in-loop
    } catch (error) {
      latestError = error
    }
  }
  throw latestError
}
const baseOpen = async options => {
  options = {
    wait: false,
    background: false,
    newInstance: false,
    allowNonzeroExitCode: false,
    ...options
  }
  if (Array.isArray(options.app)) {
    return pTryEach(options.app, singleApp =>
      baseOpen({
        ...options,
        app: singleApp
      })
    )
  }
  let { name: app, arguments: appArguments = [] } = options.app ?? {}
  appArguments = [...appArguments]
  if (Array.isArray(app)) {
    return pTryEach(app, appName =>
      baseOpen({
        ...options,
        app: {
          name: appName,
          arguments: appArguments
        }
      })
    )
  }
  if (app === 'browser' || app === 'browserPrivate') {
    // IDs from default-browser for macOS and windows are the same
    const ids = {
      'com.google.chrome': 'chrome',
      'google-chrome.desktop': 'chrome',
      'org.mozilla.firefox': 'firefox',
      'firefox.desktop': 'firefox',
      'com.microsoft.msedge': 'edge',
      'com.microsoft.edge': 'edge',
      'com.microsoft.edgemac': 'edge',
      'microsoft-edge.desktop': 'edge'
    }

    // Incognito flags for each browser in `apps`.
    const flags = {
      chrome: '--incognito',
      firefox: '--private-window',
      edge: '--inPrivate'
    }
    const browser = isWsl$1
      ? await getWindowsDefaultBrowserFromWsl()
      : await defaultBrowser()
    if (browser.id in ids) {
      const browserName = ids[browser.id]
      if (app === 'browserPrivate') {
        appArguments.push(flags[browserName])
      }
      return baseOpen({
        ...options,
        app: {
          name: apps[browserName],
          arguments: appArguments
        }
      })
    }
    throw new Error(`${browser.name} is not supported as a default browser`)
  }
  let command
  const cliArguments = []
  const childProcessOptions = {}
  if (platform === 'darwin') {
    command = 'open'
    if (options.wait) {
      cliArguments.push('--wait-apps')
    }
    if (options.background) {
      cliArguments.push('--background')
    }
    if (options.newInstance) {
      cliArguments.push('--new')
    }
    if (app) {
      cliArguments.push('-a', app)
    }
  } else if (
    platform === 'win32' ||
    (isWsl$1 && !isInsideContainer() && !app)
  ) {
    command = isWsl$1
      ? await getPowershellPathFromWsl()
      : `${process$2.env.SYSTEMROOT || process$2.env.windir || 'C:\\Windows'}\\System32\\WindowsPowerShell\\v1.0\\powershell`
    cliArguments.push(
      '-NoProfile',
      '-NonInteractive',
      '-ExecutionPolicy',
      'Bypass',
      '-EncodedCommand'
    )
    if (!isWsl$1) {
      childProcessOptions.windowsVerbatimArguments = true
    }
    const encodedArguments = ['Start']
    if (options.wait) {
      encodedArguments.push('-Wait')
    }
    if (app) {
      // Double quote with double quotes to ensure the inner quotes are passed through.
      // Inner quotes are delimited for PowerShell interpretation with backticks.
      encodedArguments.push(`"\`"${app}\`""`)
      if (options.target) {
        appArguments.push(options.target)
      }
    } else if (options.target) {
      encodedArguments.push(`"${options.target}"`)
    }
    if (appArguments.length > 0) {
      appArguments = appArguments.map(argument => `"\`"${argument}\`""`)
      encodedArguments.push('-ArgumentList', appArguments.join(','))
    }

    // Using Base64-encoded command, accepted by PowerShell, to allow special characters.
    options.target = require$$0$3.Buffer.from(
      encodedArguments.join(' '),
      'utf16le'
    ).toString('base64')
  } else {
    if (app) {
      command = app
    } else {
      // When bundled by Webpack, there's no actual package file path and no local `xdg-open`.
      const isBundled = !__dirname$1 || __dirname$1 === '/'

      // Check if local `xdg-open` exists and is executable.
      let exeLocalXdgOpen = false
      try {
        await fs$2.access(localXdgOpenPath, fs$2.constants.X_OK)
        exeLocalXdgOpen = true
      } catch {}
      const useSystemXdgOpen =
        process$2.versions.electron ??
        (platform === 'android' || isBundled || !exeLocalXdgOpen)
      command = useSystemXdgOpen ? 'xdg-open' : localXdgOpenPath
    }
    if (appArguments.length > 0) {
      cliArguments.push(...appArguments)
    }
    if (!options.wait) {
      // `xdg-open` will block the process unless stdio is ignored
      // and it's detached from the parent even if it's unref'd.
      childProcessOptions.stdio = 'ignore'
      childProcessOptions.detached = true
    }
  }
  if (platform === 'darwin' && appArguments.length > 0) {
    cliArguments.push('--args', ...appArguments)
  }

  // This has to come after `--args`.
  if (options.target) {
    cliArguments.push(options.target)
  }
  const subprocess = childProcess.spawn(
    command,
    cliArguments,
    childProcessOptions
  )
  if (options.wait) {
    return new Promise((resolve, reject) => {
      subprocess.once('error', reject)
      subprocess.once('close', exitCode => {
        if (!options.allowNonzeroExitCode && exitCode > 0) {
          reject(new Error(`Exited with code ${exitCode}`))
          return
        }
        resolve(subprocess)
      })
    })
  }
  subprocess.unref()
  return subprocess
}
const open = (target, options) => {
  if (typeof target !== 'string') {
    throw new TypeError('Expected a `target`')
  }
  return baseOpen({
    ...options,
    target
  })
}
function detectArchBinary(binary) {
  if (typeof binary === 'string' || Array.isArray(binary)) {
    return binary
  }
  const { [arch]: archBinary } = binary
  if (!archBinary) {
    throw new Error(`${arch} is not supported`)
  }
  return archBinary
}
function detectPlatformBinary({ [platform]: platformBinary }, { wsl }) {
  if (wsl && isWsl$1) {
    return detectArchBinary(wsl)
  }
  if (!platformBinary) {
    throw new Error(`${platform} is not supported`)
  }
  return detectArchBinary(platformBinary)
}
const apps = {}
defineLazyProperty(apps, 'chrome', () =>
  detectPlatformBinary(
    {
      darwin: 'google chrome',
      win32: 'chrome',
      linux: ['google-chrome', 'google-chrome-stable', 'chromium']
    },
    {
      wsl: {
        ia32: '/mnt/c/Program Files (x86)/Google/Chrome/Application/chrome.exe',
        x64: [
          '/mnt/c/Program Files/Google/Chrome/Application/chrome.exe',
          '/mnt/c/Program Files (x86)/Google/Chrome/Application/chrome.exe'
        ]
      }
    }
  )
)
defineLazyProperty(apps, 'firefox', () =>
  detectPlatformBinary(
    {
      darwin: 'firefox',
      win32: 'C:\\Program Files\\Mozilla Firefox\\firefox.exe',
      linux: 'firefox'
    },
    {
      wsl: '/mnt/c/Program Files/Mozilla Firefox/firefox.exe'
    }
  )
)
defineLazyProperty(apps, 'edge', () =>
  detectPlatformBinary(
    {
      darwin: 'microsoft edge',
      win32: 'msedge',
      linux: ['microsoft-edge', 'microsoft-edge-dev']
    },
    {
      wsl: '/mnt/c/Program Files (x86)/Microsoft/Edge/Application/msedge.exe'
    }
  )
)
defineLazyProperty(apps, 'browser', () => 'browser')
defineLazyProperty(apps, 'browserPrivate', () => 'browserPrivate')

const chalk = { exports: {} }

let escapeStringRegexp
let hasRequiredEscapeStringRegexp
function requireEscapeStringRegexp() {
  if (hasRequiredEscapeStringRegexp) {
    return escapeStringRegexp
  }
  hasRequiredEscapeStringRegexp = 1
  const matchOperatorsRe = /[|\\{}()[\]^$+*?.]/g
  escapeStringRegexp = function (str) {
    if (typeof str !== 'string') {
      throw new TypeError('Expected a string')
    }
    return str.replace(matchOperatorsRe, '\\$&')
  }
  return escapeStringRegexp
}

const ansiStyles = { exports: {} }

const conversions = { exports: {} }

let colorName
let hasRequiredColorName
function requireColorName() {
  if (hasRequiredColorName) {
    return colorName
  }
  hasRequiredColorName = 1
  colorName = {
    aliceblue: [240, 248, 255],
    antiquewhite: [250, 235, 215],
    aqua: [0, 255, 255],
    aquamarine: [127, 255, 212],
    azure: [240, 255, 255],
    beige: [245, 245, 220],
    bisque: [255, 228, 196],
    black: [0, 0, 0],
    blanchedalmond: [255, 235, 205],
    blue: [0, 0, 255],
    blueviolet: [138, 43, 226],
    brown: [165, 42, 42],
    burlywood: [222, 184, 135],
    cadetblue: [95, 158, 160],
    chartreuse: [127, 255, 0],
    chocolate: [210, 105, 30],
    coral: [255, 127, 80],
    cornflowerblue: [100, 149, 237],
    cornsilk: [255, 248, 220],
    crimson: [220, 20, 60],
    cyan: [0, 255, 255],
    darkblue: [0, 0, 139],
    darkcyan: [0, 139, 139],
    darkgoldenrod: [184, 134, 11],
    darkgray: [169, 169, 169],
    darkgreen: [0, 100, 0],
    darkgrey: [169, 169, 169],
    darkkhaki: [189, 183, 107],
    darkmagenta: [139, 0, 139],
    darkolivegreen: [85, 107, 47],
    darkorange: [255, 140, 0],
    darkorchid: [153, 50, 204],
    darkred: [139, 0, 0],
    darksalmon: [233, 150, 122],
    darkseagreen: [143, 188, 143],
    darkslateblue: [72, 61, 139],
    darkslategray: [47, 79, 79],
    darkslategrey: [47, 79, 79],
    darkturquoise: [0, 206, 209],
    darkviolet: [148, 0, 211],
    deeppink: [255, 20, 147],
    deepskyblue: [0, 191, 255],
    dimgray: [105, 105, 105],
    dimgrey: [105, 105, 105],
    dodgerblue: [30, 144, 255],
    firebrick: [178, 34, 34],
    floralwhite: [255, 250, 240],
    forestgreen: [34, 139, 34],
    fuchsia: [255, 0, 255],
    gainsboro: [220, 220, 220],
    ghostwhite: [248, 248, 255],
    gold: [255, 215, 0],
    goldenrod: [218, 165, 32],
    gray: [128, 128, 128],
    green: [0, 128, 0],
    greenyellow: [173, 255, 47],
    grey: [128, 128, 128],
    honeydew: [240, 255, 240],
    hotpink: [255, 105, 180],
    indianred: [205, 92, 92],
    indigo: [75, 0, 130],
    ivory: [255, 255, 240],
    khaki: [240, 230, 140],
    lavender: [230, 230, 250],
    lavenderblush: [255, 240, 245],
    lawngreen: [124, 252, 0],
    lemonchiffon: [255, 250, 205],
    lightblue: [173, 216, 230],
    lightcoral: [240, 128, 128],
    lightcyan: [224, 255, 255],
    lightgoldenrodyellow: [250, 250, 210],
    lightgray: [211, 211, 211],
    lightgreen: [144, 238, 144],
    lightgrey: [211, 211, 211],
    lightpink: [255, 182, 193],
    lightsalmon: [255, 160, 122],
    lightseagreen: [32, 178, 170],
    lightskyblue: [135, 206, 250],
    lightslategray: [119, 136, 153],
    lightslategrey: [119, 136, 153],
    lightsteelblue: [176, 196, 222],
    lightyellow: [255, 255, 224],
    lime: [0, 255, 0],
    limegreen: [50, 205, 50],
    linen: [250, 240, 230],
    magenta: [255, 0, 255],
    maroon: [128, 0, 0],
    mediumaquamarine: [102, 205, 170],
    mediumblue: [0, 0, 205],
    mediumorchid: [186, 85, 211],
    mediumpurple: [147, 112, 219],
    mediumseagreen: [60, 179, 113],
    mediumslateblue: [123, 104, 238],
    mediumspringgreen: [0, 250, 154],
    mediumturquoise: [72, 209, 204],
    mediumvioletred: [199, 21, 133],
    midnightblue: [25, 25, 112],
    mintcream: [245, 255, 250],
    mistyrose: [255, 228, 225],
    moccasin: [255, 228, 181],
    navajowhite: [255, 222, 173],
    navy: [0, 0, 128],
    oldlace: [253, 245, 230],
    olive: [128, 128, 0],
    olivedrab: [107, 142, 35],
    orange: [255, 165, 0],
    orangered: [255, 69, 0],
    orchid: [218, 112, 214],
    palegoldenrod: [238, 232, 170],
    palegreen: [152, 251, 152],
    paleturquoise: [175, 238, 238],
    palevioletred: [219, 112, 147],
    papayawhip: [255, 239, 213],
    peachpuff: [255, 218, 185],
    peru: [205, 133, 63],
    pink: [255, 192, 203],
    plum: [221, 160, 221],
    powderblue: [176, 224, 230],
    purple: [128, 0, 128],
    rebeccapurple: [102, 51, 153],
    red: [255, 0, 0],
    rosybrown: [188, 143, 143],
    royalblue: [65, 105, 225],
    saddlebrown: [139, 69, 19],
    salmon: [250, 128, 114],
    sandybrown: [244, 164, 96],
    seagreen: [46, 139, 87],
    seashell: [255, 245, 238],
    sienna: [160, 82, 45],
    silver: [192, 192, 192],
    skyblue: [135, 206, 235],
    slateblue: [106, 90, 205],
    slategray: [112, 128, 144],
    slategrey: [112, 128, 144],
    snow: [255, 250, 250],
    springgreen: [0, 255, 127],
    steelblue: [70, 130, 180],
    tan: [210, 180, 140],
    teal: [0, 128, 128],
    thistle: [216, 191, 216],
    tomato: [255, 99, 71],
    turquoise: [64, 224, 208],
    violet: [238, 130, 238],
    wheat: [245, 222, 179],
    white: [255, 255, 255],
    whitesmoke: [245, 245, 245],
    yellow: [255, 255, 0],
    yellowgreen: [154, 205, 50]
  }
  return colorName
}

/* MIT license */
let hasRequiredConversions
function requireConversions() {
  if (hasRequiredConversions) {
    return conversions.exports
  }
  hasRequiredConversions = 1
  const cssKeywords = requireColorName()

  // NOTE: conversions should only return primitive values (i.e. arrays, or
  //       values that give correct `typeof` results).
  //       do not use box values types (i.e. Number(), String(), etc.)

  const reverseKeywords = {}
  for (const key in cssKeywords) {
    if (cssKeywords.hasOwnProperty(key)) {
      reverseKeywords[cssKeywords[key]] = key
    }
  }
  const convert = (conversions.exports = {
    rgb: {
      channels: 3,
      labels: 'rgb'
    },
    hsl: {
      channels: 3,
      labels: 'hsl'
    },
    hsv: {
      channels: 3,
      labels: 'hsv'
    },
    hwb: {
      channels: 3,
      labels: 'hwb'
    },
    cmyk: {
      channels: 4,
      labels: 'cmyk'
    },
    xyz: {
      channels: 3,
      labels: 'xyz'
    },
    lab: {
      channels: 3,
      labels: 'lab'
    },
    lch: {
      channels: 3,
      labels: 'lch'
    },
    hex: {
      channels: 1,
      labels: ['hex']
    },
    keyword: {
      channels: 1,
      labels: ['keyword']
    },
    ansi16: {
      channels: 1,
      labels: ['ansi16']
    },
    ansi256: {
      channels: 1,
      labels: ['ansi256']
    },
    hcg: {
      channels: 3,
      labels: ['h', 'c', 'g']
    },
    apple: {
      channels: 3,
      labels: ['r16', 'g16', 'b16']
    },
    gray: {
      channels: 1,
      labels: ['gray']
    }
  })

  // hide .channels and .labels properties
  for (const model in convert) {
    if (convert.hasOwnProperty(model)) {
      if (!('channels' in convert[model])) {
        throw new Error('missing channels property: ' + model)
      }
      if (!('labels' in convert[model])) {
        throw new Error('missing channel labels property: ' + model)
      }
      if (convert[model].labels.length !== convert[model].channels) {
        throw new Error('channel and label counts mismatch: ' + model)
      }
      const channels = convert[model].channels
      const labels = convert[model].labels
      delete convert[model].channels
      delete convert[model].labels
      Object.defineProperty(convert[model], 'channels', {
        value: channels
      })
      Object.defineProperty(convert[model], 'labels', {
        value: labels
      })
    }
  }
  convert.rgb.hsl = function (rgb) {
    const r = rgb[0] / 255
    const g = rgb[1] / 255
    const b = rgb[2] / 255
    const min = Math.min(r, g, b)
    const max = Math.max(r, g, b)
    const delta = max - min
    let h
    let s
    let l
    if (max === min) {
      h = 0
    } else if (r === max) {
      h = (g - b) / delta
    } else if (g === max) {
      h = 2 + (b - r) / delta
    } else if (b === max) {
      h = 4 + (r - g) / delta
    }
    h = Math.min(h * 60, 360)
    if (h < 0) {
      h += 360
    }
    l = (min + max) / 2
    if (max === min) {
      s = 0
    } else if (l <= 0.5) {
      s = delta / (max + min)
    } else {
      s = delta / (2 - max - min)
    }
    return [h, s * 100, l * 100]
  }
  convert.rgb.hsv = function (rgb) {
    let rdif
    let gdif
    let bdif
    let h
    let s
    const r = rgb[0] / 255
    const g = rgb[1] / 255
    const b = rgb[2] / 255
    const v = Math.max(r, g, b)
    const diff = v - Math.min(r, g, b)
    const diffc = function (c) {
      return (v - c) / 6 / diff + 1 / 2
    }
    if (diff === 0) {
      h = s = 0
    } else {
      s = diff / v
      rdif = diffc(r)
      gdif = diffc(g)
      bdif = diffc(b)
      if (r === v) {
        h = bdif - gdif
      } else if (g === v) {
        h = 1 / 3 + rdif - bdif
      } else if (b === v) {
        h = 2 / 3 + gdif - rdif
      }
      if (h < 0) {
        h += 1
      } else if (h > 1) {
        h -= 1
      }
    }
    return [h * 360, s * 100, v * 100]
  }
  convert.rgb.hwb = function (rgb) {
    const r = rgb[0]
    const g = rgb[1]
    let b = rgb[2]
    const h = convert.rgb.hsl(rgb)[0]
    const w = (1 / 255) * Math.min(r, Math.min(g, b))
    b = 1 - (1 / 255) * Math.max(r, Math.max(g, b))
    return [h, w * 100, b * 100]
  }
  convert.rgb.cmyk = function (rgb) {
    const r = rgb[0] / 255
    const g = rgb[1] / 255
    const b = rgb[2] / 255
    let c
    let m
    let y
    let k
    k = Math.min(1 - r, 1 - g, 1 - b)
    c = (1 - r - k) / (1 - k) || 0
    m = (1 - g - k) / (1 - k) || 0
    y = (1 - b - k) / (1 - k) || 0
    return [c * 100, m * 100, y * 100, k * 100]
  }

  /**
   * See https://en.m.wikipedia.org/wiki/Euclidean_distance#Squared_Euclidean_distance
   * */
  function comparativeDistance(x, y) {
    return (
      Math.pow(x[0] - y[0], 2) +
      Math.pow(x[1] - y[1], 2) +
      Math.pow(x[2] - y[2], 2)
    )
  }
  convert.rgb.keyword = function (rgb) {
    const reversed = reverseKeywords[rgb]
    if (reversed) {
      return reversed
    }
    let currentClosestDistance = Infinity
    let currentClosestKeyword
    for (const keyword in cssKeywords) {
      if (cssKeywords.hasOwnProperty(keyword)) {
        const value = cssKeywords[keyword]

        // Compute comparative distance
        const distance = comparativeDistance(rgb, value)

        // Check if its less, if so set as closest
        if (distance < currentClosestDistance) {
          currentClosestDistance = distance
          currentClosestKeyword = keyword
        }
      }
    }
    return currentClosestKeyword
  }
  convert.keyword.rgb = function (keyword) {
    return cssKeywords[keyword]
  }
  convert.rgb.xyz = function (rgb) {
    let r = rgb[0] / 255
    let g = rgb[1] / 255
    let b = rgb[2] / 255

    // assume sRGB
    r = r > 0.04045 ? Math.pow((r + 0.055) / 1.055, 2.4) : r / 12.92
    g = g > 0.04045 ? Math.pow((g + 0.055) / 1.055, 2.4) : g / 12.92
    b = b > 0.04045 ? Math.pow((b + 0.055) / 1.055, 2.4) : b / 12.92
    const x = r * 0.4124 + g * 0.3576 + b * 0.1805
    const y = r * 0.2126 + g * 0.7152 + b * 0.0722
    const z = r * 0.0193 + g * 0.1192 + b * 0.9505
    return [x * 100, y * 100, z * 100]
  }
  convert.rgb.lab = function (rgb) {
    const xyz = convert.rgb.xyz(rgb)
    let x = xyz[0]
    let y = xyz[1]
    let z = xyz[2]
    let l
    let a
    let b
    x /= 95.047
    y /= 100
    z /= 108.883
    x = x > 0.008856 ? Math.pow(x, 1 / 3) : 7.787 * x + 16 / 116
    y = y > 0.008856 ? Math.pow(y, 1 / 3) : 7.787 * y + 16 / 116
    z = z > 0.008856 ? Math.pow(z, 1 / 3) : 7.787 * z + 16 / 116
    l = 116 * y - 16
    a = 500 * (x - y)
    b = 200 * (y - z)
    return [l, a, b]
  }
  convert.hsl.rgb = function (hsl) {
    const h = hsl[0] / 360
    const s = hsl[1] / 100
    const l = hsl[2] / 100
    let t1
    let t2
    let t3
    let rgb
    let val
    if (s === 0) {
      val = l * 255
      return [val, val, val]
    }
    if (l < 0.5) {
      t2 = l * (1 + s)
    } else {
      t2 = l + s - l * s
    }
    t1 = 2 * l - t2
    rgb = [0, 0, 0]
    for (let i = 0; i < 3; i++) {
      t3 = h + (1 / 3) * -(i - 1)
      if (t3 < 0) {
        t3++
      }
      if (t3 > 1) {
        t3--
      }
      if (6 * t3 < 1) {
        val = t1 + (t2 - t1) * 6 * t3
      } else if (2 * t3 < 1) {
        val = t2
      } else if (3 * t3 < 2) {
        val = t1 + (t2 - t1) * (2 / 3 - t3) * 6
      } else {
        val = t1
      }
      rgb[i] = val * 255
    }
    return rgb
  }
  convert.hsl.hsv = function (hsl) {
    const h = hsl[0]
    let s = hsl[1] / 100
    let l = hsl[2] / 100
    let smin = s
    const lmin = Math.max(l, 0.01)
    let sv
    let v
    l *= 2
    s *= l <= 1 ? l : 2 - l
    smin *= lmin <= 1 ? lmin : 2 - lmin
    v = (l + s) / 2
    sv = l === 0 ? (2 * smin) / (lmin + smin) : (2 * s) / (l + s)
    return [h, sv * 100, v * 100]
  }
  convert.hsv.rgb = function (hsv) {
    const h = hsv[0] / 60
    const s = hsv[1] / 100
    let v = hsv[2] / 100
    const hi = Math.floor(h) % 6
    const f = h - Math.floor(h)
    const p = 255 * v * (1 - s)
    const q = 255 * v * (1 - s * f)
    const t = 255 * v * (1 - s * (1 - f))
    v *= 255
    switch (hi) {
      case 0:
        return [v, t, p]
      case 1:
        return [q, v, p]
      case 2:
        return [p, v, t]
      case 3:
        return [p, q, v]
      case 4:
        return [t, p, v]
      case 5:
        return [v, p, q]
    }
  }
  convert.hsv.hsl = function (hsv) {
    const h = hsv[0]
    const s = hsv[1] / 100
    const v = hsv[2] / 100
    const vmin = Math.max(v, 0.01)
    let lmin
    let sl
    let l
    l = (2 - s) * v
    lmin = (2 - s) * vmin
    sl = s * vmin
    sl /= lmin <= 1 ? lmin : 2 - lmin
    sl = sl || 0
    l /= 2
    return [h, sl * 100, l * 100]
  }

  // http://dev.w3.org/csswg/css-color/#hwb-to-rgb
  convert.hwb.rgb = function (hwb) {
    const h = hwb[0] / 360
    let wh = hwb[1] / 100
    let bl = hwb[2] / 100
    const ratio = wh + bl
    let i
    let v
    let f
    let n

    // wh + bl cant be > 1
    if (ratio > 1) {
      wh /= ratio
      bl /= ratio
    }
    i = Math.floor(6 * h)
    v = 1 - bl
    f = 6 * h - i
    if ((i & 0x01) !== 0) {
      f = 1 - f
    }
    n = wh + f * (v - wh) // linear interpolation

    let r
    let g
    let b
    switch (i) {
      default:
      case 6:
      case 0:
        r = v
        g = n
        b = wh
        break
      case 1:
        r = n
        g = v
        b = wh
        break
      case 2:
        r = wh
        g = v
        b = n
        break
      case 3:
        r = wh
        g = n
        b = v
        break
      case 4:
        r = n
        g = wh
        b = v
        break
      case 5:
        r = v
        g = wh
        b = n
        break
    }
    return [r * 255, g * 255, b * 255]
  }
  convert.cmyk.rgb = function (cmyk) {
    const c = cmyk[0] / 100
    const m = cmyk[1] / 100
    const y = cmyk[2] / 100
    const k = cmyk[3] / 100
    let r
    let g
    let b
    r = 1 - Math.min(1, c * (1 - k) + k)
    g = 1 - Math.min(1, m * (1 - k) + k)
    b = 1 - Math.min(1, y * (1 - k) + k)
    return [r * 255, g * 255, b * 255]
  }
  convert.xyz.rgb = function (xyz) {
    const x = xyz[0] / 100
    const y = xyz[1] / 100
    const z = xyz[2] / 100
    let r
    let g
    let b
    r = x * 3.2406 + y * -1.5372 + z * -0.4986
    g = x * -0.9689 + y * 1.8758 + z * 0.0415
    b = x * 0.0557 + y * -0.204 + z * 1.057

    // assume sRGB
    r = r > 0.0031308 ? 1.055 * Math.pow(r, 1.0 / 2.4) - 0.055 : r * 12.92
    g = g > 0.0031308 ? 1.055 * Math.pow(g, 1.0 / 2.4) - 0.055 : g * 12.92
    b = b > 0.0031308 ? 1.055 * Math.pow(b, 1.0 / 2.4) - 0.055 : b * 12.92
    r = Math.min(Math.max(0, r), 1)
    g = Math.min(Math.max(0, g), 1)
    b = Math.min(Math.max(0, b), 1)
    return [r * 255, g * 255, b * 255]
  }
  convert.xyz.lab = function (xyz) {
    let x = xyz[0]
    let y = xyz[1]
    let z = xyz[2]
    let l
    let a
    let b
    x /= 95.047
    y /= 100
    z /= 108.883
    x = x > 0.008856 ? Math.pow(x, 1 / 3) : 7.787 * x + 16 / 116
    y = y > 0.008856 ? Math.pow(y, 1 / 3) : 7.787 * y + 16 / 116
    z = z > 0.008856 ? Math.pow(z, 1 / 3) : 7.787 * z + 16 / 116
    l = 116 * y - 16
    a = 500 * (x - y)
    b = 200 * (y - z)
    return [l, a, b]
  }
  convert.lab.xyz = function (lab) {
    const l = lab[0]
    const a = lab[1]
    const b = lab[2]
    let x
    let y
    let z
    y = (l + 16) / 116
    x = a / 500 + y
    z = y - b / 200
    const y2 = Math.pow(y, 3)
    const x2 = Math.pow(x, 3)
    const z2 = Math.pow(z, 3)
    y = y2 > 0.008856 ? y2 : (y - 16 / 116) / 7.787
    x = x2 > 0.008856 ? x2 : (x - 16 / 116) / 7.787
    z = z2 > 0.008856 ? z2 : (z - 16 / 116) / 7.787
    x *= 95.047
    y *= 100
    z *= 108.883
    return [x, y, z]
  }
  convert.lab.lch = function (lab) {
    const l = lab[0]
    const a = lab[1]
    const b = lab[2]
    let hr
    let h
    let c
    hr = Math.atan2(b, a)
    h = (hr * 360) / 2 / Math.PI
    if (h < 0) {
      h += 360
    }
    c = Math.sqrt(a * a + b * b)
    return [l, c, h]
  }
  convert.lch.lab = function (lch) {
    const l = lch[0]
    const c = lch[1]
    const h = lch[2]
    let a
    let b
    let hr
    hr = (h / 360) * 2 * Math.PI
    a = c * Math.cos(hr)
    b = c * Math.sin(hr)
    return [l, a, b]
  }
  convert.rgb.ansi16 = function (args) {
    const r = args[0]
    const g = args[1]
    const b = args[2]
    let value = 1 in arguments ? arguments[1] : convert.rgb.hsv(args)[2] // hsv -> ansi16 optimization

    value = Math.round(value / 50)
    if (value === 0) {
      return 30
    }
    let ansi =
      30 +
      ((Math.round(b / 255) << 2) |
        (Math.round(g / 255) << 1) |
        Math.round(r / 255))
    if (value === 2) {
      ansi += 60
    }
    return ansi
  }
  convert.hsv.ansi16 = function (args) {
    // optimization here; we already know the value and don't need to get
    // it converted for us.
    return convert.rgb.ansi16(convert.hsv.rgb(args), args[2])
  }
  convert.rgb.ansi256 = function (args) {
    const r = args[0]
    const g = args[1]
    const b = args[2]

    // we use the extended greyscale palette here, with the exception of
    // black and white. normal palette only has 4 greyscale shades.
    if (r === g && g === b) {
      if (r < 8) {
        return 16
      }
      if (r > 248) {
        return 231
      }
      return Math.round(((r - 8) / 247) * 24) + 232
    }
    const ansi =
      16 +
      36 * Math.round((r / 255) * 5) +
      6 * Math.round((g / 255) * 5) +
      Math.round((b / 255) * 5)
    return ansi
  }
  convert.ansi16.rgb = function (args) {
    let color = args % 10

    // handle greyscale
    if (color === 0 || color === 7) {
      if (args > 50) {
        color += 3.5
      }
      color = (color / 10.5) * 255
      return [color, color, color]
    }
    const mult = (~~(args > 50) + 1) * 0.5
    const r = (color & 1) * mult * 255
    const g = ((color >> 1) & 1) * mult * 255
    const b = ((color >> 2) & 1) * mult * 255
    return [r, g, b]
  }
  convert.ansi256.rgb = function (args) {
    // handle greyscale
    if (args >= 232) {
      const c = (args - 232) * 10 + 8
      return [c, c, c]
    }
    args -= 16
    let rem
    const r = (Math.floor(args / 36) / 5) * 255
    const g = (Math.floor((rem = args % 36) / 6) / 5) * 255
    const b = ((rem % 6) / 5) * 255
    return [r, g, b]
  }
  convert.rgb.hex = function (args) {
    const integer =
      ((Math.round(args[0]) & 0xff) << 16) +
      ((Math.round(args[1]) & 0xff) << 8) +
      (Math.round(args[2]) & 0xff)
    const string = integer.toString(16).toUpperCase()
    return '000000'.substring(string.length) + string
  }
  convert.hex.rgb = function (args) {
    const match = args.toString(16).match(/[a-f0-9]{6}|[a-f0-9]{3}/i)
    if (!match) {
      return [0, 0, 0]
    }
    let colorString = match[0]
    if (match[0].length === 3) {
      colorString = colorString
        .split('')
        .map(function (char) {
          return char + char
        })
        .join('')
    }
    const integer = parseInt(colorString, 16)
    const r = (integer >> 16) & 0xff
    const g = (integer >> 8) & 0xff
    const b = integer & 0xff
    return [r, g, b]
  }
  convert.rgb.hcg = function (rgb) {
    const r = rgb[0] / 255
    const g = rgb[1] / 255
    const b = rgb[2] / 255
    const max = Math.max(Math.max(r, g), b)
    const min = Math.min(Math.min(r, g), b)
    const chroma = max - min
    let grayscale
    let hue
    if (chroma < 1) {
      grayscale = min / (1 - chroma)
    } else {
      grayscale = 0
    }
    if (chroma <= 0) {
      hue = 0
    } else if (max === r) {
      hue = ((g - b) / chroma) % 6
    } else if (max === g) {
      hue = 2 + (b - r) / chroma
    } else {
      hue = 4 + (r - g) / chroma + 4
    }
    hue /= 6
    hue %= 1
    return [hue * 360, chroma * 100, grayscale * 100]
  }
  convert.hsl.hcg = function (hsl) {
    const s = hsl[1] / 100
    const l = hsl[2] / 100
    let c = 1
    let f = 0
    if (l < 0.5) {
      c = 2.0 * s * l
    } else {
      c = 2.0 * s * (1.0 - l)
    }
    if (c < 1.0) {
      f = (l - 0.5 * c) / (1.0 - c)
    }
    return [hsl[0], c * 100, f * 100]
  }
  convert.hsv.hcg = function (hsv) {
    const s = hsv[1] / 100
    const v = hsv[2] / 100
    const c = s * v
    let f = 0
    if (c < 1.0) {
      f = (v - c) / (1 - c)
    }
    return [hsv[0], c * 100, f * 100]
  }
  convert.hcg.rgb = function (hcg) {
    const h = hcg[0] / 360
    const c = hcg[1] / 100
    const g = hcg[2] / 100
    if (c === 0.0) {
      return [g * 255, g * 255, g * 255]
    }
    const pure = [0, 0, 0]
    const hi = (h % 1) * 6
    const v = hi % 1
    const w = 1 - v
    let mg = 0
    switch (Math.floor(hi)) {
      case 0:
        pure[0] = 1
        pure[1] = v
        pure[2] = 0
        break
      case 1:
        pure[0] = w
        pure[1] = 1
        pure[2] = 0
        break
      case 2:
        pure[0] = 0
        pure[1] = 1
        pure[2] = v
        break
      case 3:
        pure[0] = 0
        pure[1] = w
        pure[2] = 1
        break
      case 4:
        pure[0] = v
        pure[1] = 0
        pure[2] = 1
        break
      default:
        pure[0] = 1
        pure[1] = 0
        pure[2] = w
    }
    mg = (1.0 - c) * g
    return [
      (c * pure[0] + mg) * 255,
      (c * pure[1] + mg) * 255,
      (c * pure[2] + mg) * 255
    ]
  }
  convert.hcg.hsv = function (hcg) {
    const c = hcg[1] / 100
    const g = hcg[2] / 100
    const v = c + g * (1.0 - c)
    let f = 0
    if (v > 0.0) {
      f = c / v
    }
    return [hcg[0], f * 100, v * 100]
  }
  convert.hcg.hsl = function (hcg) {
    const c = hcg[1] / 100
    const g = hcg[2] / 100
    const l = g * (1.0 - c) + 0.5 * c
    let s = 0
    if (l > 0.0 && l < 0.5) {
      s = c / (2 * l)
    } else if (l >= 0.5 && l < 1.0) {
      s = c / (2 * (1 - l))
    }
    return [hcg[0], s * 100, l * 100]
  }
  convert.hcg.hwb = function (hcg) {
    const c = hcg[1] / 100
    const g = hcg[2] / 100
    const v = c + g * (1.0 - c)
    return [hcg[0], (v - c) * 100, (1 - v) * 100]
  }
  convert.hwb.hcg = function (hwb) {
    const w = hwb[1] / 100
    const b = hwb[2] / 100
    const v = 1 - b
    const c = v - w
    let g = 0
    if (c < 1) {
      g = (v - c) / (1 - c)
    }
    return [hwb[0], c * 100, g * 100]
  }
  convert.apple.rgb = function (apple) {
    return [
      (apple[0] / 65535) * 255,
      (apple[1] / 65535) * 255,
      (apple[2] / 65535) * 255
    ]
  }
  convert.rgb.apple = function (rgb) {
    return [
      (rgb[0] / 255) * 65535,
      (rgb[1] / 255) * 65535,
      (rgb[2] / 255) * 65535
    ]
  }
  convert.gray.rgb = function (args) {
    return [(args[0] / 100) * 255, (args[0] / 100) * 255, (args[0] / 100) * 255]
  }
  convert.gray.hsl = convert.gray.hsv = function (args) {
    return [0, 0, args[0]]
  }
  convert.gray.hwb = function (gray) {
    return [0, 100, gray[0]]
  }
  convert.gray.cmyk = function (gray) {
    return [0, 0, 0, gray[0]]
  }
  convert.gray.lab = function (gray) {
    return [gray[0], 0, 0]
  }
  convert.gray.hex = function (gray) {
    const val = Math.round((gray[0] / 100) * 255) & 0xff
    const integer = (val << 16) + (val << 8) + val
    const string = integer.toString(16).toUpperCase()
    return '000000'.substring(string.length) + string
  }
  convert.rgb.gray = function (rgb) {
    const val = (rgb[0] + rgb[1] + rgb[2]) / 3
    return [(val / 255) * 100]
  }
  return conversions.exports
}

let route
let hasRequiredRoute
function requireRoute() {
  if (hasRequiredRoute) {
    return route
  }
  hasRequiredRoute = 1
  const conversions = requireConversions()

  /*
  	this function routes a model to all other models.
  		all functions that are routed have a property `.conversion` attached
  	to the returned synthetic function. This property is an array
  	of strings, each with the steps in between the 'from' and 'to'
  	color models (inclusive).
  		conversions that are not possible simply are not included.
  */

  function buildGraph() {
    const graph = {}
    // https://jsperf.com/object-keys-vs-for-in-with-closure/3
    const models = Object.keys(conversions)
    for (let len = models.length, i = 0; i < len; i++) {
      graph[models[i]] = {
        // http://jsperf.com/1-vs-infinity
        // micro-opt, but this is simple.
        distance: -1,
        parent: null
      }
    }
    return graph
  }

  // https://en.wikipedia.org/wiki/Breadth-first_search
  function deriveBFS(fromModel) {
    const graph = buildGraph()
    const queue = [fromModel] // unshift -> queue -> pop

    graph[fromModel].distance = 0
    while (queue.length) {
      const current = queue.pop()
      const adjacents = Object.keys(conversions[current])
      for (let len = adjacents.length, i = 0; i < len; i++) {
        const adjacent = adjacents[i]
        const node = graph[adjacent]
        if (node.distance === -1) {
          node.distance = graph[current].distance + 1
          node.parent = current
          queue.unshift(adjacent)
        }
      }
    }
    return graph
  }
  function link(from, to) {
    return function (args) {
      return to(from(args))
    }
  }
  function wrapConversion(toModel, graph) {
    const path = [graph[toModel].parent, toModel]
    let fn = conversions[graph[toModel].parent][toModel]
    let cur = graph[toModel].parent
    while (graph[cur].parent) {
      path.unshift(graph[cur].parent)
      fn = link(conversions[graph[cur].parent][cur], fn)
      cur = graph[cur].parent
    }
    fn.conversion = path
    return fn
  }
  route = function (fromModel) {
    const graph = deriveBFS(fromModel)
    const conversion = {}
    const models = Object.keys(graph)
    for (let len = models.length, i = 0; i < len; i++) {
      const toModel = models[i]
      const node = graph[toModel]
      if (node.parent === null) {
        // no possible conversion, or this node is the source model.
        continue
      }
      conversion[toModel] = wrapConversion(toModel, graph)
    }
    return conversion
  }
  return route
}

let colorConvert
let hasRequiredColorConvert
function requireColorConvert() {
  if (hasRequiredColorConvert) {
    return colorConvert
  }
  hasRequiredColorConvert = 1
  const conversions = requireConversions()
  const route = requireRoute()
  const convert = {}
  const models = Object.keys(conversions)
  function wrapRaw(fn) {
    const wrappedFn = function (args) {
      if (args === undefined || args === null) {
        return args
      }
      if (arguments.length > 1) {
        args = Array.prototype.slice.call(arguments)
      }
      return fn(args)
    }

    // preserve .conversion property if there is one
    if ('conversion' in fn) {
      wrappedFn.conversion = fn.conversion
    }
    return wrappedFn
  }
  function wrapRounded(fn) {
    const wrappedFn = function (args) {
      if (args === undefined || args === null) {
        return args
      }
      if (arguments.length > 1) {
        args = Array.prototype.slice.call(arguments)
      }
      const result = fn(args)

      // we're assuming the result is an array here.
      // see notice in conversions.js; don't use box types
      // in conversion functions.
      if (typeof result === 'object') {
        for (let len = result.length, i = 0; i < len; i++) {
          result[i] = Math.round(result[i])
        }
      }
      return result
    }

    // preserve .conversion property if there is one
    if ('conversion' in fn) {
      wrappedFn.conversion = fn.conversion
    }
    return wrappedFn
  }
  models.forEach(function (fromModel) {
    convert[fromModel] = {}
    Object.defineProperty(convert[fromModel], 'channels', {
      value: conversions[fromModel].channels
    })
    Object.defineProperty(convert[fromModel], 'labels', {
      value: conversions[fromModel].labels
    })
    const routes = route(fromModel)
    const routeModels = Object.keys(routes)
    routeModels.forEach(function (toModel) {
      const fn = routes[toModel]
      convert[fromModel][toModel] = wrapRounded(fn)
      convert[fromModel][toModel].raw = wrapRaw(fn)
    })
  })
  colorConvert = convert
  return colorConvert
}

ansiStyles.exports
let hasRequiredAnsiStyles
function requireAnsiStyles() {
  if (hasRequiredAnsiStyles) {
    return ansiStyles.exports
  }
  hasRequiredAnsiStyles = 1
  ;(function (module) {
    const colorConvert = requireColorConvert()
    const wrapAnsi16 = (fn, offset) =>
      function () {
        const code = fn.apply(colorConvert, arguments)
        return `\u001B[${code + offset}m`
      }
    const wrapAnsi256 = (fn, offset) =>
      function () {
        const code = fn.apply(colorConvert, arguments)
        return `\u001B[${38 + offset};5;${code}m`
      }
    const wrapAnsi16m = (fn, offset) =>
      function () {
        const rgb = fn.apply(colorConvert, arguments)
        return `\u001B[${38 + offset};2;${rgb[0]};${rgb[1]};${rgb[2]}m`
      }
    function assembleStyles() {
      const codes = new Map()
      const styles = {
        modifier: {
          reset: [0, 0],
          // 21 isn't widely supported and 22 does the same thing
          bold: [1, 22],
          dim: [2, 22],
          italic: [3, 23],
          underline: [4, 24],
          inverse: [7, 27],
          hidden: [8, 28],
          strikethrough: [9, 29]
        },
        color: {
          black: [30, 39],
          red: [31, 39],
          green: [32, 39],
          yellow: [33, 39],
          blue: [34, 39],
          magenta: [35, 39],
          cyan: [36, 39],
          white: [37, 39],
          gray: [90, 39],
          // Bright color
          redBright: [91, 39],
          greenBright: [92, 39],
          yellowBright: [93, 39],
          blueBright: [94, 39],
          magentaBright: [95, 39],
          cyanBright: [96, 39],
          whiteBright: [97, 39]
        },
        bgColor: {
          bgBlack: [40, 49],
          bgRed: [41, 49],
          bgGreen: [42, 49],
          bgYellow: [43, 49],
          bgBlue: [44, 49],
          bgMagenta: [45, 49],
          bgCyan: [46, 49],
          bgWhite: [47, 49],
          // Bright color
          bgBlackBright: [100, 49],
          bgRedBright: [101, 49],
          bgGreenBright: [102, 49],
          bgYellowBright: [103, 49],
          bgBlueBright: [104, 49],
          bgMagentaBright: [105, 49],
          bgCyanBright: [106, 49],
          bgWhiteBright: [107, 49]
        }
      }

      // Fix humans
      styles.color.grey = styles.color.gray
      for (const groupName of Object.keys(styles)) {
        const group = styles[groupName]
        for (const styleName of Object.keys(group)) {
          const style = group[styleName]
          styles[styleName] = {
            open: `\u001B[${style[0]}m`,
            close: `\u001B[${style[1]}m`
          }
          group[styleName] = styles[styleName]
          codes.set(style[0], style[1])
        }
        Object.defineProperty(styles, groupName, {
          value: group,
          enumerable: false
        })
        Object.defineProperty(styles, 'codes', {
          value: codes,
          enumerable: false
        })
      }
      const ansi2ansi = n => n
      const rgb2rgb = (r, g, b) => [r, g, b]
      styles.color.close = '\u001B[39m'
      styles.bgColor.close = '\u001B[49m'
      styles.color.ansi = {
        ansi: wrapAnsi16(ansi2ansi, 0)
      }
      styles.color.ansi256 = {
        ansi256: wrapAnsi256(ansi2ansi, 0)
      }
      styles.color.ansi16m = {
        rgb: wrapAnsi16m(rgb2rgb, 0)
      }
      styles.bgColor.ansi = {
        ansi: wrapAnsi16(ansi2ansi, 10)
      }
      styles.bgColor.ansi256 = {
        ansi256: wrapAnsi256(ansi2ansi, 10)
      }
      styles.bgColor.ansi16m = {
        rgb: wrapAnsi16m(rgb2rgb, 10)
      }
      for (let key of Object.keys(colorConvert)) {
        if (typeof colorConvert[key] !== 'object') {
          continue
        }
        const suite = colorConvert[key]
        if (key === 'ansi16') {
          key = 'ansi'
        }
        if ('ansi16' in suite) {
          styles.color.ansi[key] = wrapAnsi16(suite.ansi16, 0)
          styles.bgColor.ansi[key] = wrapAnsi16(suite.ansi16, 10)
        }
        if ('ansi256' in suite) {
          styles.color.ansi256[key] = wrapAnsi256(suite.ansi256, 0)
          styles.bgColor.ansi256[key] = wrapAnsi256(suite.ansi256, 10)
        }
        if ('rgb' in suite) {
          styles.color.ansi16m[key] = wrapAnsi16m(suite.rgb, 0)
          styles.bgColor.ansi16m[key] = wrapAnsi16m(suite.rgb, 10)
        }
      }
      return styles
    }

    // Make the export immutable
    Object.defineProperty(module, 'exports', {
      enumerable: true,
      get: assembleStyles
    })
  })(ansiStyles)
  return ansiStyles.exports
}

let hasFlag
let hasRequiredHasFlag
function requireHasFlag() {
  if (hasRequiredHasFlag) {
    return hasFlag
  }
  hasRequiredHasFlag = 1
  hasFlag = (flag, argv) => {
    argv = argv || process.argv
    const prefix = flag.startsWith('-') ? '' : flag.length === 1 ? '-' : '--'
    const pos = argv.indexOf(prefix + flag)
    const terminatorPos = argv.indexOf('--')
    return pos !== -1 && (terminatorPos === -1 ? true : pos < terminatorPos)
  }
  return hasFlag
}

let supportsColor_1
let hasRequiredSupportsColor
function requireSupportsColor() {
  if (hasRequiredSupportsColor) {
    return supportsColor_1
  }
  hasRequiredSupportsColor = 1
  const os = require$$0$c
  const hasFlag = requireHasFlag()
  const env = process.env
  let forceColor
  if (hasFlag('no-color') || hasFlag('no-colors') || hasFlag('color=false')) {
    forceColor = false
  } else if (
    hasFlag('color') ||
    hasFlag('colors') ||
    hasFlag('color=true') ||
    hasFlag('color=always')
  ) {
    forceColor = true
  }
  if ('FORCE_COLOR' in env) {
    forceColor =
      env.FORCE_COLOR.length === 0 || parseInt(env.FORCE_COLOR, 10) !== 0
  }
  function translateLevel(level) {
    if (level === 0) {
      return false
    }
    return {
      level,
      hasBasic: true,
      has256: level >= 2,
      has16m: level >= 3
    }
  }
  function supportsColor(stream) {
    if (forceColor === false) {
      return 0
    }
    if (
      hasFlag('color=16m') ||
      hasFlag('color=full') ||
      hasFlag('color=truecolor')
    ) {
      return 3
    }
    if (hasFlag('color=256')) {
      return 2
    }
    if (stream && !stream.isTTY && forceColor !== true) {
      return 0
    }
    const min = forceColor ? 1 : 0
    if (process.platform === 'win32') {
      // Node.js 7.5.0 is the first version of Node.js to include a patch to
      // libuv that enables 256 color output on Windows. Anything earlier and it
      // won't work. However, here we target Node.js 8 at minimum as it is an LTS
      // release, and Node.js 7 is not. Windows 10 build 10586 is the first Windows
      // release that supports 256 colors. Windows 10 build 14931 is the first release
      // that supports 16m/TrueColor.
      const osRelease = os.release().split('.')
      if (
        Number(process.versions.node.split('.')[0]) >= 8 &&
        Number(osRelease[0]) >= 10 &&
        Number(osRelease[2]) >= 10586
      ) {
        return Number(osRelease[2]) >= 14931 ? 3 : 2
      }
      return 1
    }
    if ('CI' in env) {
      if (
        ['TRAVIS', 'CIRCLECI', 'APPVEYOR', 'GITLAB_CI'].some(
          sign => sign in env
        ) ||
        env.CI_NAME === 'codeship'
      ) {
        return 1
      }
      return min
    }
    if ('TEAMCITY_VERSION' in env) {
      return /^(9\.(0*[1-9]\d*)\.|\d{2,}\.)/.test(env.TEAMCITY_VERSION) ? 1 : 0
    }
    if (env.COLORTERM === 'truecolor') {
      return 3
    }
    if ('TERM_PROGRAM' in env) {
      const version = parseInt(
        (env.TERM_PROGRAM_VERSION || '').split('.')[0],
        10
      )
      switch (env.TERM_PROGRAM) {
        case 'iTerm.app':
          return version >= 3 ? 3 : 2
        case 'Apple_Terminal':
          return 2
        // No default
      }
    }
    if (/-256(color)?$/i.test(env.TERM)) {
      return 2
    }
    if (
      /^screen|^xterm|^vt100|^vt220|^rxvt|color|ansi|cygwin|linux/i.test(
        env.TERM
      )
    ) {
      return 1
    }
    if ('COLORTERM' in env) {
      return 1
    }
    if (env.TERM === 'dumb') {
      return min
    }
    return min
  }
  function getSupportLevel(stream) {
    const level = supportsColor(stream)
    return translateLevel(level)
  }
  supportsColor_1 = {
    supportsColor: getSupportLevel,
    stdout: getSupportLevel(process.stdout),
    stderr: getSupportLevel(process.stderr)
  }
  return supportsColor_1
}

let templates
let hasRequiredTemplates
function requireTemplates() {
  if (hasRequiredTemplates) {
    return templates
  }
  hasRequiredTemplates = 1
  const TEMPLATE_REGEX =
    /(?:\\(u[a-f\d]{4}|x[a-f\d]{2}|.))|(?:\{(~)?(\w+(?:\([^)]*\))?(?:\.\w+(?:\([^)]*\))?)*)(?:[ \t]|(?=\r?\n)))|(\})|((?:.|[\r\n\f])+?)/gi
  const STYLE_REGEX = /(?:^|\.)(\w+)(?:\(([^)]*)\))?/g
  const STRING_REGEX = /^(['"])((?:\\.|(?!\1)[^\\])*)\1$/
  const ESCAPE_REGEX = /\\(u[a-f\d]{4}|x[a-f\d]{2}|.)|([^\\])/gi
  const ESCAPES = new Map([
    ['n', '\n'],
    ['r', '\r'],
    ['t', '\t'],
    ['b', '\b'],
    ['f', '\f'],
    ['v', '\v'],
    ['0', '\0'],
    ['\\', '\\'],
    ['e', '\u001B'],
    ['a', '\u0007']
  ])
  function unescape(c) {
    if ((c[0] === 'u' && c.length === 5) || (c[0] === 'x' && c.length === 3)) {
      return String.fromCharCode(parseInt(c.slice(1), 16))
    }
    return ESCAPES.get(c) || c
  }
  function parseArguments(name, args) {
    const results = []
    const chunks = args.trim().split(/\s*,\s*/g)
    let matches
    for (const chunk of chunks) {
      if (!isNaN(chunk)) {
        results.push(Number(chunk))
      } else if ((matches = chunk.match(STRING_REGEX))) {
        results.push(
          matches[2].replace(ESCAPE_REGEX, (m, escape, chr) =>
            escape ? unescape(escape) : chr
          )
        )
      } else {
        throw new Error(
          `Invalid Chalk template style argument: ${chunk} (in style '${name}')`
        )
      }
    }
    return results
  }
  function parseStyle(style) {
    STYLE_REGEX.lastIndex = 0
    const results = []
    let matches
    while ((matches = STYLE_REGEX.exec(style)) !== null) {
      const name = matches[1]
      if (matches[2]) {
        const args = parseArguments(name, matches[2])
        results.push([name].concat(args))
      } else {
        results.push([name])
      }
    }
    return results
  }
  function buildStyle(chalk, styles) {
    const enabled = {}
    for (const layer of styles) {
      for (const style of layer.styles) {
        enabled[style[0]] = layer.inverse ? null : style.slice(1)
      }
    }
    let current = chalk
    for (const styleName of Object.keys(enabled)) {
      if (Array.isArray(enabled[styleName])) {
        if (!(styleName in current)) {
          throw new Error(`Unknown Chalk style: ${styleName}`)
        }
        if (enabled[styleName].length > 0) {
          current = current[styleName].apply(current, enabled[styleName])
        } else {
          current = current[styleName]
        }
      }
    }
    return current
  }
  templates = (chalk, tmp) => {
    const styles = []
    const chunks = []
    let chunk = []

    // eslint-disable-next-line max-params
    tmp.replace(TEMPLATE_REGEX, (m, escapeChar, inverse, style, close, chr) => {
      if (escapeChar) {
        chunk.push(unescape(escapeChar))
      } else if (style) {
        const str = chunk.join('')
        chunk = []
        chunks.push(styles.length === 0 ? str : buildStyle(chalk, styles)(str))
        styles.push({
          inverse,
          styles: parseStyle(style)
        })
      } else if (close) {
        if (styles.length === 0) {
          throw new Error('Found extraneous } in Chalk template literal')
        }
        chunks.push(buildStyle(chalk, styles)(chunk.join('')))
        chunk = []
        styles.pop()
      } else {
        chunk.push(chr)
      }
    })
    chunks.push(chunk.join(''))
    if (styles.length > 0) {
      const errMsg = `Chalk template literal is missing ${styles.length} closing bracket${styles.length === 1 ? '' : 's'} (\`}\`)`
      throw new Error(errMsg)
    }
    return chunks.join('')
  }
  return templates
}

let hasRequiredChalk
function requireChalk() {
  if (hasRequiredChalk) {
    return chalk.exports
  }
  hasRequiredChalk = 1
  ;(function (module) {
    const escapeStringRegexp = requireEscapeStringRegexp()
    const ansiStyles = requireAnsiStyles()
    const stdoutColor = requireSupportsColor().stdout
    const template = requireTemplates()
    const isSimpleWindowsTerm =
      process.platform === 'win32' &&
      !(process.env.TERM || '').toLowerCase().startsWith('xterm')

    // `supportsColor.level` → `ansiStyles.color[name]` mapping
    const levelMapping = ['ansi', 'ansi', 'ansi256', 'ansi16m']

    // `color-convert` models to exclude from the Chalk API due to conflicts and such
    const skipModels = new Set(['gray'])
    const styles = Object.create(null)
    function applyOptions(obj, options) {
      options = options || {}

      // Detect level if not set manually
      const scLevel = stdoutColor ? stdoutColor.level : 0
      obj.level = options.level === undefined ? scLevel : options.level
      obj.enabled = 'enabled' in options ? options.enabled : obj.level > 0
    }
    function Chalk(options) {
      // We check for this.template here since calling `chalk.constructor()`
      // by itself will have a `this` of a previously constructed chalk object
      if (!this || !(this instanceof Chalk) || this.template) {
        const chalk = {}
        applyOptions(chalk, options)
        chalk.template = function () {
          const args = [].slice.call(arguments)
          return chalkTag.apply(null, [chalk.template].concat(args))
        }
        Object.setPrototypeOf(chalk, Chalk.prototype)
        Object.setPrototypeOf(chalk.template, chalk)
        chalk.template.constructor = Chalk
        return chalk.template
      }
      applyOptions(this, options)
    }

    // Use bright blue on Windows as the normal blue color is illegible
    if (isSimpleWindowsTerm) {
      ansiStyles.blue.open = '\u001B[94m'
    }
    for (const key of Object.keys(ansiStyles)) {
      ansiStyles[key].closeRe = new RegExp(
        escapeStringRegexp(ansiStyles[key].close),
        'g'
      )
      styles[key] = {
        get() {
          const codes = ansiStyles[key]
          return build.call(
            this,
            this._styles ? this._styles.concat(codes) : [codes],
            this._empty,
            key
          )
        }
      }
    }
    styles.visible = {
      get() {
        return build.call(this, this._styles || [], true, 'visible')
      }
    }
    ansiStyles.color.closeRe = new RegExp(
      escapeStringRegexp(ansiStyles.color.close),
      'g'
    )
    for (const model of Object.keys(ansiStyles.color.ansi)) {
      if (skipModels.has(model)) {
        continue
      }
      styles[model] = {
        get() {
          const level = this.level
          return function () {
            const open = ansiStyles.color[levelMapping[level]][model].apply(
              null,
              arguments
            )
            const codes = {
              open,
              close: ansiStyles.color.close,
              closeRe: ansiStyles.color.closeRe
            }
            return build.call(
              this,
              this._styles ? this._styles.concat(codes) : [codes],
              this._empty,
              model
            )
          }
        }
      }
    }
    ansiStyles.bgColor.closeRe = new RegExp(
      escapeStringRegexp(ansiStyles.bgColor.close),
      'g'
    )
    for (const model of Object.keys(ansiStyles.bgColor.ansi)) {
      if (skipModels.has(model)) {
        continue
      }
      const bgModel = 'bg' + model[0].toUpperCase() + model.slice(1)
      styles[bgModel] = {
        get() {
          const level = this.level
          return function () {
            const open = ansiStyles.bgColor[levelMapping[level]][model].apply(
              null,
              arguments
            )
            const codes = {
              open,
              close: ansiStyles.bgColor.close,
              closeRe: ansiStyles.bgColor.closeRe
            }
            return build.call(
              this,
              this._styles ? this._styles.concat(codes) : [codes],
              this._empty,
              model
            )
          }
        }
      }
    }
    const proto = Object.defineProperties(() => {}, styles)
    function build(_styles, _empty, key) {
      const builder = function () {
        return applyStyle.apply(builder, arguments)
      }
      builder._styles = _styles
      builder._empty = _empty
      const self = this
      Object.defineProperty(builder, 'level', {
        enumerable: true,
        get() {
          return self.level
        },
        set(level) {
          self.level = level
        }
      })
      Object.defineProperty(builder, 'enabled', {
        enumerable: true,
        get() {
          return self.enabled
        },
        set(enabled) {
          self.enabled = enabled
        }
      })

      // See below for fix regarding invisible grey/dim combination on Windows
      builder.hasGrey = this.hasGrey || key === 'gray' || key === 'grey'

      // `__proto__` is used because we must return a function, but there is
      // no way to create a function with a different prototype
      Object.setPrototypeOf(builder, proto) // eslint-disable-line no-proto
      return builder
    }
    function applyStyle() {
      // Support varags, but simply cast to string in case there's only one arg
      const args = arguments
      const argsLen = args.length
      let str = String(arguments[0])
      if (argsLen === 0) {
        return ''
      }
      if (argsLen > 1) {
        // Don't slice `arguments`, it prevents V8 optimizations
        for (let a = 1; a < argsLen; a++) {
          str += ' ' + args[a]
        }
      }
      if (!this.enabled || this.level <= 0 || !str) {
        return this._empty ? '' : str
      }

      // Turns out that on Windows dimmed gray text becomes invisible in cmd.exe,
      // see https://github.com/chalk/chalk/issues/58
      // If we're on Windows and we're dealing with a gray color, temporarily make 'dim' a noop.
      const originalDim = ansiStyles.dim.open
      if (isSimpleWindowsTerm && this.hasGrey) {
        ansiStyles.dim.open = ''
      }
      for (const code of this._styles.slice().reverse()) {
        // Replace any instances already present with a re-opening code
        // otherwise only the part of the string until said closing code
        // will be colored, and the rest will simply be 'plain'.
        str = code.open + str.replace(code.closeRe, code.open) + code.close

        // Close the styling before a linebreak and reopen
        // after next line to fix a bleed issue on macOS
        // https://github.com/chalk/chalk/pull/92
        str = str.replace(/\r?\n/g, `${code.close}$&${code.open}`)
      }

      // Reset the original `dim` if we changed it to work around the Windows dimmed gray issue
      ansiStyles.dim.open = originalDim
      return str
    }
    function chalkTag(chalk, strings) {
      if (!Array.isArray(strings)) {
        // If chalk() was called by itself or with a string,
        // return the string itself as a string.
        return [].slice.call(arguments, 1).join(' ')
      }
      const args = [].slice.call(arguments, 2)
      const parts = [strings.raw[0]]
      for (let i = 1; i < strings.length; i++) {
        parts.push(String(args[i - 1]).replace(/[{}\\]/g, '\\$&'))
        parts.push(String(strings.raw[i]))
      }
      return template(chalk, parts.join(''))
    }
    Object.defineProperties(Chalk.prototype, styles)
    module.exports = Chalk() // eslint-disable-line new-cap
    module.exports.supportsColor = stdoutColor
    module.exports.default = module.exports // For TypeScript
  })(chalk)
  return chalk.exports
}

const stripAnsi = { exports: {} }

let ansiRegex
let hasRequiredAnsiRegex
function requireAnsiRegex() {
  if (hasRequiredAnsiRegex) {
    return ansiRegex
  }
  hasRequiredAnsiRegex = 1
  ansiRegex = options => {
    options = Object.assign(
      {
        onlyFirst: false
      },
      options
    )
    const pattern = [
      '[\\u001B\\u009B][[\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\d\\/#&.:=?%@~_]+)*|[a-zA-Z\\d]+(?:;[-a-zA-Z\\d\\/#&.:=?%@~_]*)*)?\\u0007)',
      '(?:(?:\\d{1,4}(?:;\\d{0,4})*)?[\\dA-PR-TZcf-ntqry=><~]))'
    ].join('|')
    return new RegExp(pattern, options.onlyFirst ? undefined : 'g')
  }
  return ansiRegex
}

let hasRequiredStripAnsi
function requireStripAnsi() {
  if (hasRequiredStripAnsi) {
    return stripAnsi.exports
  }
  hasRequiredStripAnsi = 1
  const ansiRegex = requireAnsiRegex()
  const stripAnsi$1 = string =>
    typeof string === 'string' ? string.replace(ansiRegex(), '') : string
  stripAnsi.exports = stripAnsi$1
  stripAnsi.exports.default = stripAnsi$1
  return stripAnsi.exports
}

let src
let hasRequiredSrc
function requireSrc() {
  if (hasRequiredSrc) {
    return src
  }
  hasRequiredSrc = 1
  const chalk = requireChalk()
  const stripAnsi = requireStripAnsi()
  src = (options, data) => {
    const pad = (text, length) => {
      if (typeof text === 'undefined') {
        text = ''
      }
      return (
        '' +
        text +
        new Array(Math.max(length - stripAnsi('' + text).length + 1, 0)).join(
          ' '
        )
      )
    }
    if (typeof options === 'object' && Array.isArray(options)) {
      const tmp = data
      data = options
      options = tmp
    }
    if (!options) {
      options = {}
    }
    if (!options.intersectionCharacter) {
      options.intersectionCharacter = '+'
    }
    let columns
    if (options.columns) {
      columns = options.columns
    } else {
      columns = []
      data.forEach(e =>
        Object.keys(e)
          .filter(k => {
            return columns.indexOf(k) === -1
          })
          .forEach(k => {
            columns.push(k)
          })
      )
    }
    columns = columns.map(e => {
      if (typeof e === 'string') {
        e = {
          name: e,
          field: e
        }
      }
      e.name = chalk.bold(e.name)
      e.width = stripAnsi(e.name).length
      return e
    })
    data.forEach(e =>
      columns.forEach(column => {
        if (typeof e[column.field] === 'undefined') {
          return
        }
        column.width = Math.max(
          column.width,
          ('' + stripAnsi(e[column.field])).length
        )
      })
    )
    let output = []
    const separator = ['']
      .concat(columns.map(e => new Array(e.width + 1).join('-')))
      .concat([''])
      .join('-' + options.intersectionCharacter + '-')
    output.push(separator)
    output.push(
      ['']
        .concat(columns.map(e => pad(e.name, e.width)))
        .concat([''])
        .join(' | ')
    )
    output.push(separator)
    data.forEach(row => {
      output.push(
        ['']
          .concat(columns.map(column => pad(row[column.field], column.width)))
          .concat([''])
          .join(' | ')
      )
    })
    output.push(separator)
    const leftPad = ' '.repeat(options.leftPad) || ''
    return (
      leftPad +
      output
        .map(e => e.replace(/^[ -]/, '').replace(/[ -]$/, ''))
        .join('\n' + leftPad)
    )
  }
  return src
}

const srcExports = requireSrc()

let error$2
let hasRequiredError$2
function requireError$2() {
  if (hasRequiredError$2) {
    return error$2
  }
  hasRequiredError$2 = 1
  function formatPurlErrorMessage(message = '') {
    const { length } = message
    let formatted = ''
    if (length) {
      // Lower case start of message.
      const code0 = message.charCodeAt(0)
      formatted =
        code0 >= 65 /*'A'*/ || code0 <= 90 /*'Z'*/
          ? `${message[0].toLowerCase()}${message.slice(1)}`
          : message
      // Remove period from end of message.
      if (
        length > 1 &&
        message.charCodeAt(length - 1) === 46 /*'.'*/ &&
        message.charCodeAt(length - 2) !== 46
      ) {
        formatted = formatted.slice(0, -1)
      }
    }
    return `Invalid purl: ${formatted}`
  }
  class PurlError extends Error {
    constructor(message) {
      super(formatPurlErrorMessage(message))
    }
  }
  error$2 = {
    formatPurlErrorMessage,
    PurlError
  }
  return error$2
}

let decode
let hasRequiredDecode
function requireDecode() {
  if (hasRequiredDecode) {
    return decode
  }
  hasRequiredDecode = 1
  const { PurlError } = /*@__PURE__*/ requireError$2()
  const { decodeURIComponent: decodeComponent } = globalThis
  function decodePurlComponent(comp, encodedComponent) {
    try {
      return decodeComponent(encodedComponent)
    } catch {}
    throw new PurlError(`unable to decode "${comp}" component`)
  }
  decode = {
    decodePurlComponent
  }
  return decode
}

let constants
let hasRequiredConstants
function requireConstants() {
  if (hasRequiredConstants) {
    return constants
  }
  hasRequiredConstants = 1
  const LOOP_SENTINEL = 1_000_000
  const REUSED_SEARCH_PARAMS = new URLSearchParams()
  const REUSED_SEARCH_PARAMS_KEY = '_'
  const REUSED_SEARCH_PARAMS_OFFSET = 2 // '_='.length

  constants = {
    LOOP_SENTINEL,
    REUSED_SEARCH_PARAMS,
    REUSED_SEARCH_PARAMS_KEY,
    REUSED_SEARCH_PARAMS_OFFSET
  }
  return constants
}

let objects
let hasRequiredObjects
function requireObjects() {
  if (hasRequiredObjects) {
    return objects
  }
  hasRequiredObjects = 1
  const { LOOP_SENTINEL } = /*@__PURE__*/ requireConstants()
  function isObject(value) {
    return value !== null && typeof value === 'object'
  }
  function recursiveFreeze(value_) {
    if (
      value_ === null ||
      !(typeof value_ === 'object' || typeof value_ === 'function') ||
      Object.isFrozen(value_)
    ) {
      return value_
    }
    const queue = [value_]
    let { length: queueLength } = queue
    let pos = 0
    while (pos < queueLength) {
      if (pos === LOOP_SENTINEL) {
        throw new Error(
          'Detected infinite loop in object crawl of recursiveFreeze'
        )
      }
      const obj = queue[pos++]
      Object.freeze(obj)
      if (Array.isArray(obj)) {
        for (let i = 0, { length } = obj; i < length; i += 1) {
          const item = obj[i]
          if (
            item !== null &&
            (typeof item === 'object' || typeof item === 'function') &&
            !Object.isFrozen(item)
          ) {
            queue[queueLength++] = item
          }
        }
      } else {
        const keys = Reflect.ownKeys(obj)
        for (let i = 0, { length } = keys; i < length; i += 1) {
          const propValue = obj[keys[i]]
          if (
            propValue !== null &&
            (typeof propValue === 'object' ||
              typeof propValue === 'function') &&
            !Object.isFrozen(propValue)
          ) {
            queue[queueLength++] = propValue
          }
        }
      }
    }
    return value_
  }
  objects = {
    isObject,
    recursiveFreeze
  }
  return objects
}

let strings
let hasRequiredStrings
function requireStrings() {
  if (hasRequiredStrings) {
    return strings
  }
  hasRequiredStrings = 1

  // Intl.Collator is faster than String#localeCompare
  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/localeCompare:
  // > When comparing large numbers of strings, such as in sorting large arrays,
  // > it is better to create an Intl.Collator object and use the function provided
  // > by its compare() method.
  let _localeCompare
  function localeCompare(x, y) {
    if (_localeCompare === undefined) {
      // Lazily call new Intl.Collator() because in Node it can take 10-14ms.
      _localeCompare = new Intl.Collator().compare
    }
    return _localeCompare(x, y)
  }

  // This regexp is valid as of 2024-08-01.
  // https://semver.org/#is-there-a-suggested-regular-expression-regex-to-check-a-semver-string
  const regexSemverNumberedGroups =
    /^(0|[1-9]\d*)\.(0|[1-9]\d*)\.(0|[1-9]\d*)(?:-((?:0|[1-9]\d*|\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\.(?:0|[1-9]\d*|\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\+([0-9a-zA-Z-]+(?:\.[0-9a-zA-Z-]+)*))?$/
  function isBlank(str) {
    for (let i = 0, { length } = str; i < length; i += 1) {
      const code = str.charCodeAt(i)
      // biome-ignore format:
      if (!(
      // Whitespace characters according to ECMAScript spec:
      // https://tc39.es/ecma262/#sec-white-space

      code === 0x0020 ||
      // Space
      code === 0x0009 ||
      // Tab
      code === 0x000a ||
      // Line Feed
      code === 0x000b ||
      // Vertical Tab
      code === 0x000c ||
      // Form Feed
      code === 0x000d ||
      // Carriage Return
      code === 0x00a0 ||
      // No-Break Space
      code === 0x1680 ||
      // Ogham Space Mark
      code === 0x2000 ||
      // En Quad
      code === 0x2001 ||
      // Em Quad
      code === 0x2002 ||
      // En Space
      code === 0x2003 ||
      // Em Space
      code === 0x2004 ||
      // Three-Per-Em Space
      code === 0x2005 ||
      // Four-Per-Em Space
      code === 0x2006 ||
      // Six-Per-Em Space
      code === 0x2007 ||
      // Figure Space
      code === 0x2008 ||
      // Punctuation Space
      code === 0x2009 ||
      // Thin Space
      code === 0x200a ||
      // Hair Space
      code === 0x2028 ||
      // Line Separator
      code === 0x2029 ||
      // Paragraph Separator
      code === 0x202f ||
      // Narrow No-Break Space
      code === 0x205f ||
      // Medium Mathematical Space
      code === 0x3000 ||
      // Ideographic Space
      code === 0xfeff // Byte Order Mark
      )) {
        return false;
      }
    }
    return true
  }
  function isNonEmptyString(value) {
    return typeof value === 'string' && value.length > 0
  }
  function isSemverString(value) {
    return typeof value === 'string' && regexSemverNumberedGroups.test(value)
  }
  function lowerName(purl) {
    purl.name = purl.name.toLowerCase()
  }
  function lowerNamespace(purl) {
    const { namespace } = purl
    if (typeof namespace === 'string') {
      purl.namespace = namespace.toLowerCase()
    }
  }
  function lowerVersion(purl) {
    const { version } = purl
    if (typeof version === 'string') {
      purl.version = version.toLowerCase()
    }
  }
  function replaceDashesWithUnderscores(str) {
    // Replace all "-" with "_"
    let result = ''
    let fromIndex = 0
    let index = 0
    while ((index = str.indexOf('-', fromIndex)) !== -1) {
      result = result + str.slice(fromIndex, index) + '_'
      fromIndex = index + 1
    }
    return fromIndex ? result + str.slice(fromIndex) : str
  }
  function replaceUnderscoresWithDashes(str) {
    // Replace all "_" with "-"
    let result = ''
    let fromIndex = 0
    let index = 0
    while ((index = str.indexOf('_', fromIndex)) !== -1) {
      result = result + str.slice(fromIndex, index) + '-'
      fromIndex = index + 1
    }
    return fromIndex ? result + str.slice(fromIndex) : str
  }
  function trimLeadingSlashes(str) {
    let start = 0
    while (str.charCodeAt(start) === 47 /*'/'*/) {
      start += 1
    }
    return start === 0 ? str : str.slice(start)
  }
  strings = {
    isBlank,
    isNonEmptyString,
    isSemverString,
    localeCompare,
    lowerName,
    lowerNamespace,
    lowerVersion,
    replaceDashesWithUnderscores,
    replaceUnderscoresWithDashes,
    trimLeadingSlashes
  }
  return strings
}

let encode
let hasRequiredEncode
function requireEncode() {
  if (hasRequiredEncode) {
    return encode
  }
  hasRequiredEncode = 1
  const {
    REUSED_SEARCH_PARAMS,
    REUSED_SEARCH_PARAMS_KEY,
    REUSED_SEARCH_PARAMS_OFFSET
  } = /*@__PURE__*/ requireConstants()
  const { isObject } = /*@__PURE__*/ requireObjects()
  const { isNonEmptyString } = /*@__PURE__*/ requireStrings()
  const { encodeURIComponent: encodeComponent } = globalThis
  function encodeName(name) {
    return isNonEmptyString(name)
      ? encodeComponent(name).replace(/%3A/g, ':')
      : ''
  }
  function encodeNamespace(namespace) {
    return isNonEmptyString(namespace)
      ? encodeComponent(namespace).replace(/%3A/g, ':').replace(/%2F/g, '/')
      : ''
  }
  function encodeQualifierParam(param) {
    if (isNonEmptyString(param)) {
      // Param key and value are encoded with `percentEncodeSet` of
      // 'application/x-www-form-urlencoded' and `spaceAsPlus` of `true`.
      // https://url.spec.whatwg.org/#urlencoded-serializing
      REUSED_SEARCH_PARAMS.set(REUSED_SEARCH_PARAMS_KEY, param)
      return replacePlusSignWithPercentEncodedSpace(
        REUSED_SEARCH_PARAMS.toString().slice(REUSED_SEARCH_PARAMS_OFFSET)
      )
    }
    return ''
  }
  function encodeQualifiers(qualifiers) {
    if (isObject(qualifiers)) {
      // Sort this list of qualifier strings lexicographically.
      const qualifiersKeys = Object.keys(qualifiers).sort()
      const searchParams = new URLSearchParams()
      for (let i = 0, { length } = qualifiersKeys; i < length; i += 1) {
        const key = qualifiersKeys[i]
        searchParams.set(key, qualifiers[key])
      }
      return replacePlusSignWithPercentEncodedSpace(searchParams.toString())
    }
    return ''
  }
  function encodeSubpath(subpath) {
    return isNonEmptyString(subpath)
      ? encodeComponent(subpath).replace(/%2F/g, '/')
      : ''
  }
  function encodeVersion(version) {
    return isNonEmptyString(version)
      ? encodeComponent(version).replace(/%3A/g, ':').replace(/%2B/g, '+')
      : ''
  }
  function replacePlusSignWithPercentEncodedSpace(str) {
    // Convert plus signs to %20 for better portability.
    return str.replace(/\+/g, '%20')
  }
  encode = {
    encodeComponent,
    encodeName,
    encodeNamespace,
    encodeVersion,
    encodeQualifiers,
    encodeQualifierParam,
    encodeSubpath
  }
  return encode
}

let helpers
let hasRequiredHelpers
function requireHelpers() {
  if (hasRequiredHelpers) {
    return helpers
  }
  hasRequiredHelpers = 1
  function createHelpersNamespaceObject(helpers, options_ = {}) {
    const { comparator, ...defaults } = {
      __proto__: null,
      ...options_
    }
    const helperNames = Object.keys(helpers).sort()
    const propNames = [
      ...new Set(Object.values(helpers).map(Object.keys).flat())
    ].sort(comparator)
    const nsObject = Object.create(null)
    for (let i = 0, { length } = propNames; i < length; i += 1) {
      const propName = propNames[i]
      const helpersForProp = Object.create(null)
      for (
        let j = 0, { length: length_j } = helperNames;
        j < length_j;
        j += 1
      ) {
        const helperName = helperNames[j]
        const helperValue =
          helpers[helperName][propName] ?? defaults[helperName]
        if (helperValue !== undefined) {
          helpersForProp[helperName] = helperValue
        }
      }
      nsObject[propName] = helpersForProp
    }
    return nsObject
  }
  helpers = {
    createHelpersNamespaceObject
  }
  return helpers
}

let normalize
let hasRequiredNormalize
function requireNormalize() {
  if (hasRequiredNormalize) {
    return normalize
  }
  hasRequiredNormalize = 1
  const { isObject } = /*@__PURE__*/ requireObjects()
  const { isBlank } = /*@__PURE__*/ requireStrings()
  function normalizeName(rawName) {
    return typeof rawName === 'string' ? rawName.trim() : undefined
  }
  function normalizeNamespace(rawNamespace) {
    return typeof rawNamespace === 'string'
      ? normalizePath(rawNamespace)
      : undefined
  }
  function normalizePath(pathname, callback) {
    let collapsed = ''
    let start = 0
    // Leading and trailing slashes, i.e. '/', are not significant and should be
    // stripped in the canonical form.
    while (pathname.charCodeAt(start) === 47 /*'/'*/) {
      start += 1
    }
    let nextIndex = pathname.indexOf('/', start)
    if (nextIndex === -1) {
      return pathname.slice(start)
    }
    // Discard any empty string segments by collapsing repeated segment
    // separator slashes, i.e. '/'.
    while (nextIndex !== -1) {
      const segment = pathname.slice(start, nextIndex)
      if (callback === undefined || callback(segment)) {
        collapsed = collapsed + (collapsed.length === 0 ? '' : '/') + segment
      }
      start = nextIndex + 1
      while (pathname.charCodeAt(start) === 47) {
        start += 1
      }
      nextIndex = pathname.indexOf('/', start)
    }
    const lastSegment = pathname.slice(start)
    if (
      lastSegment.length !== 0 &&
      (callback === undefined || callback(lastSegment))
    ) {
      collapsed = collapsed + '/' + lastSegment
    }
    return collapsed
  }
  function normalizeQualifiers(rawQualifiers) {
    let qualifiers
    for (const { 0: key, 1: value } of qualifiersToEntries(rawQualifiers)) {
      const strValue = typeof value === 'string' ? value : String(value)
      const trimmed = strValue.trim()
      // A key=value pair with an empty value is the same as no key/value
      // at all for this key.
      if (trimmed.length === 0) {
        continue
      }
      if (qualifiers === undefined) {
        qualifiers = {
          __proto__: null
        }
      }
      // A key is case insensitive. The canonical form is lowercase.
      qualifiers[key.toLowerCase()] = trimmed
    }
    return qualifiers
  }
  function normalizeSubpath(rawSubpath) {
    return typeof rawSubpath === 'string'
      ? normalizePath(rawSubpath, subpathFilter)
      : undefined
  }
  function normalizeType(rawType) {
    // The type must NOT be percent-encoded.
    // The type is case insensitive. The canonical form is lowercase.
    return typeof rawType === 'string'
      ? rawType.trim().toLowerCase()
      : undefined
  }
  function normalizeVersion(rawVersion) {
    return typeof rawVersion === 'string' ? rawVersion.trim() : undefined
  }
  function qualifiersToEntries(rawQualifiers) {
    if (isObject(rawQualifiers)) {
      return rawQualifiers instanceof URLSearchParams
        ? rawQualifiers.entries()
        : Object.entries(rawQualifiers)
    }
    return typeof rawQualifiers === 'string'
      ? new URLSearchParams(rawQualifiers).entries()
      : Object.entries({})
  }
  function subpathFilter(segment) {
    // When percent-decoded, a segment
    //   - must not be any of '.' or '..'
    //   - must not be empty
    const { length } = segment
    if (length === 1 && segment.charCodeAt(0) === 46 /*'.'*/) {
      return false
    }
    if (
      length === 2 &&
      segment.charCodeAt(0) === 46 &&
      segment.charCodeAt(1) === 46
    ) {
      return false
    }
    return !isBlank(segment)
  }
  normalize = {
    normalizeName,
    normalizeNamespace,
    normalizePath,
    normalizeQualifiers,
    normalizeSubpath,
    normalizeType,
    normalizeVersion
  }
  return normalize
}

let lang
let hasRequiredLang
function requireLang() {
  if (hasRequiredLang) {
    return lang
  }
  hasRequiredLang = 1
  function isNullishOrEmptyString(value) {
    return (
      value === null ||
      value === undefined ||
      (typeof value === 'string' && value.length === 0)
    )
  }
  lang = {
    isNullishOrEmptyString
  }
  return lang
}

let validate
let hasRequiredValidate
function requireValidate() {
  if (hasRequiredValidate) {
    return validate
  }
  hasRequiredValidate = 1
  const { PurlError } = /*@__PURE__*/ requireError$2()
  const { isNullishOrEmptyString } = /*@__PURE__*/ requireLang()
  const { isNonEmptyString } = /*@__PURE__*/ requireStrings()
  function validateEmptyByType(type, name, value, throws) {
    if (!isNullishOrEmptyString(value)) {
      if (throws) {
        throw new PurlError(`${type} "${name}" component must be empty`)
      }
      return false
    }
    return true
  }
  function validateName(name, throws) {
    return (
      validateRequired('name', name, throws) &&
      validateStrings('name', name, throws)
    )
  }
  function validateNamespace(namespace, throws) {
    return validateStrings('namespace', namespace, throws)
  }
  function validateQualifiers(qualifiers, throws) {
    if (qualifiers === null || qualifiers === undefined) {
      return true
    }
    if (typeof qualifiers !== 'object') {
      if (throws) {
        throw new PurlError('"qualifiers" must be an object')
      }
      return false
    }
    const keysIterable =
      // URL searchParams have an "keys" method that returns an iterator.
      typeof qualifiers.keys === 'function'
        ? qualifiers.keys()
        : Object.keys(qualifiers)
    for (const key of keysIterable) {
      if (!validateQualifierKey(key, throws)) {
        return false
      }
    }
    return true
  }
  function validateQualifierKey(key, throws) {
    // A key cannot start with a number.
    if (!validateStartsWithoutNumber('qualifier', key, throws)) {
      return false
    }
    // The key must be composed only of ASCII letters and numbers,
    // '.', '-' and '_' (period, dash and underscore).
    for (let i = 0, { length } = key; i < length; i += 1) {
      const code = key.charCodeAt(i)
      // biome-ignore format:
      if (!(code >= 48 && code <= 57 ||
      // 0-9
      code >= 65 && code <= 90 ||
      // A-Z
      code >= 97 && code <= 122 ||
      // a-z
      code === 46 ||
      // .
      code === 45 ||
      // -
      code === 95 // _
      )) {
        if (throws) {
          throw new PurlError(`qualifier "${key}" contains an illegal character`);
        }
        return false;
      }
    }
    return true
  }
  function validateRequired(name, value, throws) {
    if (isNullishOrEmptyString(value)) {
      if (throws) {
        throw new PurlError(`"${name}" is a required component`)
      }
      return false
    }
    return true
  }
  function validateRequiredByType(type, name, value, throws) {
    if (isNullishOrEmptyString(value)) {
      if (throws) {
        throw new PurlError(`${type} requires a "${name}" component`)
      }
      return false
    }
    return true
  }
  function validateStartsWithoutNumber(name, value, throws) {
    if (isNonEmptyString(value)) {
      const code = value.charCodeAt(0)
      if (code >= 48 /*'0'*/ && code <= 57 /*'9'*/) {
        if (throws) {
          throw new PurlError(`${name} "${value}" cannot start with a number`)
        }
        return false
      }
    }
    return true
  }
  function validateStrings(name, value, throws) {
    if (value === null || value === undefined || typeof value === 'string') {
      return true
    }
    if (throws) {
      throw new PurlError(`"'${name}" must be a string`)
    }
    return false
  }
  function validateSubpath(subpath, throws) {
    return validateStrings('subpath', subpath, throws)
  }
  function validateType(type, throws) {
    // The type cannot be nullish, an empty string, or start with a number.
    if (
      !validateRequired('type', type, throws) ||
      !validateStrings('type', type, throws) ||
      !validateStartsWithoutNumber('type', type, throws)
    ) {
      return false
    }
    // The package type is composed only of ASCII letters and numbers,
    // '.', '+' and '-' (period, plus, and dash)
    for (let i = 0, { length } = type; i < length; i += 1) {
      const code = type.charCodeAt(i)
      // biome-ignore format:
      if (!(code >= 48 && code <= 57 ||
      // 0-9
      code >= 65 && code <= 90 ||
      // A-Z
      code >= 97 && code <= 122 ||
      // a-z
      code === 46 ||
      // .
      code === 43 ||
      // +
      code === 45 // -
      )) {
        if (throws) {
          throw new PurlError(`type "${type}" contains an illegal character`);
        }
        return false;
      }
    }
    return true
  }
  function validateVersion(version, throws) {
    return validateStrings('version', version, throws)
  }
  validate = {
    validateEmptyByType,
    validateName,
    validateNamespace,
    validateQualifiers,
    validateQualifierKey,
    validateRequired,
    validateRequiredByType,
    validateStartsWithoutNumber,
    validateStrings,
    validateSubpath,
    validateType,
    validateVersion
  }
  return validate
}

let purlComponent
let hasRequiredPurlComponent
function requirePurlComponent() {
  if (hasRequiredPurlComponent) {
    return purlComponent
  }
  hasRequiredPurlComponent = 1
  const {
    encodeComponent,
    encodeName,
    encodeNamespace,
    encodeQualifierParam,
    encodeQualifiers,
    encodeSubpath,
    encodeVersion
  } = /*@__PURE__*/ requireEncode()
  const { createHelpersNamespaceObject } = /*@__PURE__*/ requireHelpers()
  const {
    normalizeName,
    normalizeNamespace,
    normalizeQualifiers,
    normalizeSubpath,
    normalizeType,
    normalizeVersion
  } = /*@__PURE__*/ requireNormalize()
  const { isNonEmptyString, localeCompare } = /*@__PURE__*/ requireStrings()
  const {
    validateName,
    validateNamespace,
    validateQualifierKey,
    validateQualifiers,
    validateSubpath,
    validateType,
    validateVersion
  } = /*@__PURE__*/ requireValidate()
  const PurlComponentEncoder = comp =>
    isNonEmptyString(comp) ? encodeComponent(comp) : ''
  const PurlComponentStringNormalizer = comp =>
    typeof comp === 'string' ? comp : undefined
  const PurlComponentValidator = (_comp, _throws) => true
  const componentSortOrderLookup = {
    __proto__: null,
    type: 0,
    namespace: 1,
    name: 2,
    version: 3,
    qualifiers: 4,
    qualifierKey: 5,
    qualifierValue: 6,
    subpath: 7
  }
  function componentSortOrder(comp) {
    return componentSortOrderLookup[comp] ?? comp
  }
  function componentComparator(compA, compB) {
    return localeCompare(componentSortOrder(compA), componentSortOrder(compB))
  }
  purlComponent = {
    // Rules for each purl component:
    // https://github.com/package-url/purl-spec/blob/master/PURL-SPECIFICATION.rst#rules-for-each-purl-component
    PurlComponent: createHelpersNamespaceObject(
      {
        encode: {
          name: encodeName,
          namespace: encodeNamespace,
          version: encodeVersion,
          qualifiers: encodeQualifiers,
          qualifierKey: encodeQualifierParam,
          qualifierValue: encodeQualifierParam,
          subpath: encodeSubpath
        },
        normalize: {
          type: normalizeType,
          namespace: normalizeNamespace,
          name: normalizeName,
          version: normalizeVersion,
          qualifiers: normalizeQualifiers,
          subpath: normalizeSubpath
        },
        validate: {
          type: validateType,
          namespace: validateNamespace,
          name: validateName,
          version: validateVersion,
          qualifierKey: validateQualifierKey,
          qualifiers: validateQualifiers,
          subpath: validateSubpath
        }
      },
      {
        comparator: componentComparator,
        encode: PurlComponentEncoder,
        normalize: PurlComponentStringNormalizer,
        validate: PurlComponentValidator
      }
    )
  }
  return purlComponent
}

let purlQualifierNames
let hasRequiredPurlQualifierNames
function requirePurlQualifierNames() {
  if (hasRequiredPurlQualifierNames) {
    return purlQualifierNames
  }
  hasRequiredPurlQualifierNames = 1
  purlQualifierNames = {
    // Known qualifiers:
    // https://github.com/package-url/purl-spec/blob/master/PURL-SPECIFICATION.rst#known-qualifiers-keyvalue-pairs
    PurlQualifierNames: {
      __proto__: null,
      RepositoryUrl: 'repository_url',
      DownloadUrl: 'download_url',
      VcsUrl: 'vcs_url',
      FileName: 'file_name',
      Checksum: 'checksum'
    }
  }
  return purlQualifierNames
}

const purlType = { exports: {} }

const require$$6 = [
  '_http_agent',
  '_http_client',
  '_http_common',
  '_http_incoming',
  '_http_outgoing',
  '_http_server',
  '_stream_duplex',
  '_stream_passthrough',
  '_stream_readable',
  '_stream_transform',
  '_stream_wrap',
  '_stream_writable',
  '_tls_common',
  '_tls_wrap',
  'assert',
  'assert/strict',
  'async_hooks',
  'buffer',
  'child_process',
  'cluster',
  'console',
  'constants',
  'crypto',
  'dgram',
  'diagnostics_channel',
  'dns',
  'dns/promises',
  'domain',
  'events',
  'fs',
  'fs/promises',
  'http',
  'http2',
  'https',
  'inspector',
  'inspector/promises',
  'module',
  'net',
  'os',
  'path',
  'path/posix',
  'path/win32',
  'perf_hooks',
  'process',
  'punycode',
  'querystring',
  'readline',
  'readline/promises',
  'repl',
  'stream',
  'stream/consumers',
  'stream/promises',
  'stream/web',
  'string_decoder',
  'sys',
  'timers',
  'timers/promises',
  'tls',
  'trace_events',
  'tty',
  'url',
  'util',
  'util/types',
  'v8',
  'vm',
  'wasi',
  'worker_threads',
  'zlib'
]

const require$$7 = [
  '@antoinerey/comp-Fetch',
  '@antoinerey/comp-VideoPlayer',
  '@beisen/Accordion',
  '@beisen/Approve',
  '@beisen/AreaSelector',
  '@beisen/AutoComplete',
  '@beisen/AutoTree',
  '@beisen/BaseButton',
  '@beisen/Beaute',
  '@beisen/BeisenCloudMobile',
  '@beisen/BeisenCloudUI',
  '@beisen/ButtonGroup',
  '@beisen/ChaosUI',
  '@beisen/ChaosUI-V1',
  '@beisen/CheckboxList',
  '@beisen/CommonMount',
  '@beisen/CommonPop',
  '@beisen/DataGrid',
  '@beisen/DateTime',
  '@beisen/DropDownButton',
  '@beisen/DropDownList',
  '@beisen/ExtendComponent',
  '@beisen/FormUploader',
  '@beisen/IconButton',
  '@beisen/Loading',
  '@beisen/MultiSelect',
  '@beisen/NaDeStyle',
  '@beisen/Paging',
  '@beisen/PopLayer',
  '@beisen/RadioList',
  '@beisen/ReactTransformTenchmark',
  '@beisen/Search',
  '@beisen/selectedComponent',
  '@beisen/Sidebar',
  '@beisen/StaticFormLabel',
  '@beisen/TabComponent',
  '@beisen/Textarea',
  '@beisen/Textbox',
  '@beisen/TimePicker',
  '@beisen/TitaFeed',
  '@beisen/ToolTip',
  '@beisen/Transfer',
  '@beisen/Tree',
  '@beisen/UserSelector',
  '@chasidic/tsSchema',
  '@chymz/DaStrap',
  '@chymz/DaUsers',
  '@claviska/jquery-ajaxSubmit',
  '@cryptolize/FileSaver',
  '@djforth/I18n_helper',
  '@dostolu/baseController',
  '@dostolu/exctractIntl',
  '@dostolu/mongooseSlug',
  '@dostolu/validationTransformer',
  '@opam-alpha/ANSITerminal',
  '@opam-alpha/BetterErrors',
  '@opam-alpha/reactiveData',
  '@pioug/MidiConvert',
  '@smuuf/idleCat',
  '@sycoraxya/validateJS',
  '@tempest/endWhen',
  '@tempest/fromPromise',
  '@tempest/replaceError',
  '@tempest/startWith',
  '@tempest/throwError',
  '@yuanhao/draft-js-mentionHashtag-plugin',
  '3dBinPack',
  '3DViewerComponent',
  '4meFirst-github-example',
  '9Wares-js',
  '37FIS',
  'A',
  'ABAValidator',
  'ABCEnd',
  'AbokyBot',
  'Accessor',
  'Accessor_MongoDB',
  'Accessor_MySQL',
  'Accessor_Singleton',
  'Account',
  'accumulateArray',
  'ACCUPLACERClient',
  'AccuplacerClient',
  'Acid',
  'activaDocs',
  'ActiveResource.js',
  'ADBCordovaAnalytics',
  'addTimeout',
  'AdultJS',
  'AesUtil',
  'AgentX',
  'AirBridgePlugin',
  'airLogger',
  'ajiThird',
  'alaGDK',
  'AlarmClock',
  'alarmClock',
  'Alchemyst',
  'AlertLogic',
  'alertsXYZ',
  'ali-topSdk',
  'AliceBot',
  'alinkRNTest',
  'aliOcrIdCard',
  'AllCal.WebApp',
  'alpacaDash',
  'AmateurJS',
  'AMD',
  'AMGCryptLib',
  'AmILate',
  'AmILateAnand',
  'amitTest',
  'AmpCoreApi',
  'amProductsearch',
  'amqpWrapper',
  'amrToMp3',
  'angular-autoFields-bootstrap',
  'angular-dateParser',
  'angular-GAPI',
  'angular-PubSub',
  'Angular-test-child',
  'Angular1',
  'Angular2',
  'angular2-Library',
  'angular2-localStorage',
  'angular2-Menu',
  'angular2-quickstart-ngSemantic',
  'angularApp',
  'angularCubicColorPicker',
  'angularjs-ES6-brunch-seed',
  'angularjsSlider',
  'AngularStompDK',
  'Animated_GIF',
  'animateJs',
  'animateSCSS',
  'AnimationFrame',
  'AnimIt',
  'Anirudhnodeapp',
  'Anjali',
  'annoteJS',
  'ANSIdom',
  'antFB',
  'antFB-init',
  'antFB-mobile',
  'antFB-router-redux-ie8',
  'AntMobileUI',
  'AnToast',
  'Antony',
  'aoIoHw90B5sE1wG9',
  'API-Documentation',
  'APIConnect',
  'APICreatorSDK',
  'APlan',
  'APM-mouse',
  'APM.P2H',
  'apMigStats',
  'AporaPushNotification',
  'App2App',
  'applqpakTest',
  'AppTracker',
  'AQ',
  'ArcusNode',
  'AriesNode',
  'array_handler_liz_Li',
  'Array.prototype.forEachAsync',
  'ArrayBuffer-shim',
  'arrayFuncs',
  'ArrowAulaExpress',
  'Article-collider-packages',
  'Arunkumar-Angular-Trial',
  'asEvented',
  'asJam',
  'ASP.NET',
  'assert',
  'AssetPipeline',
  'assignment2-BW',
  'Assignment6',
  'async_hooks',
  'asyncBuilder',
  'asyncEJS',
  'AsyncHttpRequest-CordovaPlugin',
  'AsyncProxy',
  'AsyncStorage',
  'asyncStorage',
  'atom-C',
  'atom-Fe',
  'atom-Ge',
  'atom-K',
  'atom-Li',
  'atom-Na',
  'atom-Pb',
  'atom-Rb',
  'atom-Si',
  'atom-Sn',
  'AulaExpress',
  'austin-vertebraeTest',
  'authorStats',
  'AutoFixture',
  'autoLoader',
  'AutoReact',
  'AutoTasks',
  'Autowebpcss',
  'Avifors',
  'AVNjs',
  'AwesomeProject',
  'AWSS3Drive',
  'ax-rmdirRecursive',
  'b_Tap',
  'Babel',
  'babel-preset-reactTeam',
  'Bablic_Seo_SDK',
  'BablicLogger',
  'Backbone-Collection-Predefined-Filters',
  'Backbone.Aggregator',
  'backbone.browserStorage',
  'Backbone.Chosen',
  'Backbone.Marionette.Handlebars',
  'Backbone.Mutators',
  'Backbone.Overview',
  'Backbone.Rpc',
  'Backbone.Subset',
  'baDataModel',
  'Bag',
  'BaiduMapManager',
  'BandGravity',
  'bangDM',
  'banking-Josh-demo',
  'BankWebservice',
  'bannerFlip',
  'BaremetricsCalendar',
  'Barfer',
  'BarneyRubble',
  'Base',
  'Base64',
  'baseProject',
  'Basic-Material-framework',
  'BasicCredentials',
  'basicFFmpeg',
  'bbArray',
  'Beegee',
  'begineer_Practice',
  'beijingDate',
  'bem-countMaster',
  'bem-countSlave',
  'bem-getHistory',
  'Bestpack',
  'betterMatch',
  'BetterRegExp',
  'Bhellyer',
  'BHP_MSD',
  'BiDirectionalScrollingTable',
  'BigAssFansAPI',
  'BigInt',
  'BIMserverWrapper',
  'Binary-search-tree',
  'binarySearch',
  'bindAll',
  'BinHeap',
  'biojs-vis-RDFSchema',
  'Biolac',
  'Birbal',
  'BitSetModule',
  'BizzStream',
  'Blackfeather',
  'BlackMirror',
  'Blacksmith',
  'blacktea.jsonTemplates',
  'Blaggie-System',
  'BlankUp',
  'Blink1Control2',
  'blitzLib',
  'Blob',
  'BlobBuilder',
  'BlobBuilder-browser',
  'Blog',
  'BlueOcean',
  'BlueOps',
  'Blueprint-Sugar',
  'bluthLBC',
  'blya!',
  'BMFE_scaffold',
  'Bmodule',
  'Bo-colors-project',
  'Boilerpipe-Scraper',
  'Bondlib',
  'bonTemplate',
  'BootSideMenu',
  'bornCordova',
  'Botcord',
  'Bottr-cli',
  'Brackets',
  'brain***_games***',
  'Brave',
  'BrewCore',
  'BrianPingPong',
  'BrianSuperComponents',
  'BrickPlus',
  'Brocket',
  'Brosec',
  'browserProxy',
  'browserType',
  'brush-Makefile',
  'bTap',
  'BtMacAddress',
  'BubbleJS',
  'Buffer',
  'buffer',
  'BufferList',
  'Bugay',
  'Build',
  'BuildBox',
  'Builder',
  'Builders',
  'BuildWithJavascript',
  'BusinessObjects',
  'Button',
  'Buttons',
  'Bynd',
  'ByteBuffer',
  'C9js',
  'Cache-Service-Collector',
  'Cacher',
  'callbackQueue',
  'CallbackRouter',
  'callBlock-plugin',
  'callBlock.plugin',
  'camcardPlugin',
  'CameraPreview',
  'Canteen',
  'canvas-toBlob',
  'canvasColorPicker',
  'Caoutchouc',
  'Cap',
  'Carbon',
  'cardsJS',
  'Cartogram-Utils',
  'cascadeDrop',
  'Cashew',
  'Cat4D',
  'catchTender',
  'CategoryJS',
  'catl-deploySSH',
  'cbNetwork',
  'CbolaInfra',
  'CBQueue',
  'CBuffer',
  'ccNetViz',
  'ccPagination',
  'ccTpl',
  'censoreMio',
  'Censorify',
  'censorify_Publish20160706',
  'censorify_Vincent_Choe',
  'censorifyAD',
  'censorifyAshes',
  'censorifyGuangyi',
  'censorifyKatKat',
  'censorifyRayL',
  'censorifyTM',
  'CETEIcean',
  'cfUtilityService',
  'CFViews',
  'chadschwComponentTest0001',
  'changelogFDV',
  'Changling-dom',
  'CharLS.js',
  'Chart.Annotation.js',
  'Chart.CallBack.js',
  'Chart.Crosshairs.js',
  'Chart.HorizontalBar.js',
  'Chart.Smith.js',
  'Chart.Zoom.drag.js',
  'Chart.Zoom.js',
  'ChartTime',
  'chatSocketIo',
  'ChattingRoom',
  'checkForModuleDuplicates',
  'cheferizeIt',
  'chenouTestNode',
  'child_process',
  'chowYen',
  'chrome-localIp',
  'ChuckCSS',
  'ChuckNorrisException',
  'chunkArray',
  'cjdsComponents',
  'Class',
  'Classy',
  'clearInterval',
  'ClearSilver',
  'clearTimeout',
  'CLI-todo',
  'CLI-UI',
  'cliappRafa',
  'clientFrontEnd',
  'ClientStorage',
  'clipDouban',
  'ClipJS',
  'CloudMusicCover',
  'CloudStore',
  'Cls',
  'cluster',
  'CM-react-native-document-picker',
  'CM1',
  'coberturaJS',
  'codeStr',
  'Coeus',
  'COFFEENODE',
  'Coflux',
  'colegislate-DynamoDbEventRepository',
  'ColeTownsend',
  'collabProvidesModules',
  'CollectionMap',
  'colWidth.js',
  'com.emsaeng.cordova.plugin.AdMob',
  'com.nickreed.cordova.plugin.brotherPrinter',
  'com.none.alarmClock',
  'com.zwchen.firstPlugin',
  'com.zwchen.qqAdvice',
  'combineJS',
  'CometJS',
  'Comfy',
  'Comments',
  'CommentsJS',
  'comp-Fetch',
  'Company',
  'compareStrings',
  'CompassSM',
  'Complex',
  'componentDoc',
  'componentDoc-cli',
  'CompoundSignal',
  'Compress-CSS',
  'Compression',
  'concatAll',
  'Concur',
  'ConfluencePageAttacher',
  'ConnectTheDotsDesktop',
  'Console',
  'console',
  'constants',
  'constelation-Animate_',
  'constelation-BackgroundImage',
  'constelation-Block',
  'constelation-Button',
  'constelation-Col',
  'constelation-Event_',
  'constelation-Flex',
  'constelation-Inline',
  'constelation-InlineBlock',
  'constelation-InlineCol',
  'constelation-InlineFlex',
  'constelation-InlineRow',
  'constelation-Painter',
  'constelation-Row',
  'constelation-Style_',
  'constelation-Text',
  'constelation-Video',
  'constelation-View',
  'ConstraintNetwork',
  'ContactMe',
  'ContentEdit',
  'ContentSelect',
  'ContentTools',
  'convertPinyin',
  'CoolBeans',
  'Coolhelper',
  'copyMe',
  'cordova-plugin-adPlayCafebazaar',
  'cordova-plugin-adPlayPushe',
  'cordova-plugin-bluetoothClassic-serial',
  'cordova-plugin-coolFunction',
  'cordova-plugin-euroart93-smartConfig',
  'cordova-plugin-ios-android-IAP',
  'cordova-plugin-LineLogin',
  'Cordova-Plugin-OpenTok-JBS',
  'cordova-plugin-permissionScope',
  'cordova-plugin-SchaffrathWebviewer',
  'cordova-plugin-SDKAW',
  'Cordova-Plugin-SystemBarDimmer',
  'cordova-plugin-YtopPlugin',
  'Cordova-react-redux-boilerplate',
  'cordova-StarIO-plugin',
  'CordovaSMS',
  'CordovaWebSocketClientCert',
  'coreApi',
  'CornerCut',
  'CornerJob',
  'CorrespondenceAnalysis',
  'cosBuffer',
  'cosTask',
  'Couch-cleaner',
  'Couchbase-sync-gateway-REST',
  'CouchCover',
  'CouchDBChanges',
  'CouchDBExternal',
  'CountAdd_000001',
  'cPlayer',
  'cqjPack',
  'Crawler',
  'Create-React-App-SCSS-HMR',
  'createClass',
  'createDOC',
  'createNpm',
  'createServer',
  'CRMWebAPI',
  'crockpot-fromBinary',
  'crockpot-fromEnglish',
  'crockpot-fromRoman',
  'crockpot-toEnglish',
  'crockpot-toRoman',
  'Cron',
  'CropSr',
  'crypto',
  'CSDebug',
  'CSDLParser',
  'CSLogger',
  'CSSMatrix',
  'CSSselect',
  'Csster',
  'CSSwhat',
  'CSV-JS',
  'CTP_MARKET_DATA',
  'cttv.bubblesView',
  'cttv.diseaseGraph',
  'cttv.expansionView',
  'cttv.flowerView',
  'cttv.speciesIcons',
  'cttv.targetAssociationsBubbles',
  'cttv.targetAssociationsTree',
  'cttv.targetGeneTree',
  'Cuber',
  'cubicColorPicker',
  'Cui-Dialog',
  'CustomCamera',
  'customComponent',
  'customLibrary',
  'CustomPlugin',
  'CustomWebView',
  'cuteLogger',
  'cwebp-binLocal',
  'CyberJS',
  'D',
  'd-fordeYoutube',
  'D-Stats',
  'D.Va',
  'd3-bboxCollide',
  'd3-pathLayout',
  'd3.geoTile',
  'D3.TimeSlider',
  'Daja',
  'Daniel_NPM_Library_Test',
  'Dante2',
  'DanTroy-utils',
  'Dashboard',
  'Dasher',
  'dashr-widget-Weather',
  'dashr-widget-World-Pool-Championships',
  'Data-CSS',
  'Data-Same-Height',
  'dataAccess',
  'Database-Jones',
  'DataManager',
  'dataStream',
  'dateFormat-kwen',
  'dateFormatW',
  'DateHuatingzi',
  'DateMaskr',
  'dateModule',
  'DatePicker',
  'Datepicker.js',
  'Dateselect',
  'DateValidator',
  'DateZ',
  'Datum',
  'Davis',
  'dd-rc-mStock',
  'DDEvents',
  'deBijenkorf-protractor-tests',
  'Debug-Tracker',
  'Deci-mal',
  'DeCurtis-Logger',
  'deepEqualsWith',
  'deepPick',
  'defaultStr',
  'Deferred',
  'deferredEventEmitter',
  'defineClass',
  'defineJS',
  'DelegateListener',
  'deleteMoudles',
  'Demo',
  'Demo1',
  'demoNeeeew',
  'demoWei',
  'demoYTC',
  'Deneme',
  'derivco-SoundJS',
  'derpModule',
  'DeskSet',
  'Desktop-command',
  'Devbridge-FrontEnd',
  'Developer',
  'deviousknightFirstNpm',
  'devisPattern',
  'devProxy',
  'DFP',
  'dgram',
  'dgURI',
  'diagnostics_channel',
  'Dial',
  'DiggernautAPI',
  'Diogenes',
  'DirScanner',
  'dirStat',
  'DirWatcher',
  'Discord-Webhook',
  'DiscordForge',
  'diveSync',
  'dkastner-JSONPath',
  'DM.NodeJS',
  'dns',
  'Dock-command',
  'docxtemplaterCopy',
  'doLink',
  'DOM',
  'Domai.nr',
  'domain',
  'DOMArray',
  'DOMBuilder',
  'DOMino',
  'DOMtastic',
  'DOMtastic-npm',
  'dotFormat',
  'dotJS',
  'DoubleCheck',
  'Dove.js',
  'downloadAPI',
  'downLoadFile',
  'DownloadManager',
  'DownloadProxy',
  'DPS',
  'DQ',
  'draftjsToHTML',
  'dragOnZone',
  'drakovNew',
  'Draper',
  'DrawPDF',
  'Dribble',
  'Drupal-Node.js',
  'DT',
  'Duckface',
  'Dui',
  'DVA',
  'DvA',
  'dVa',
  'DXIV2Inst',
  'DynamicBuffer',
  'dynamoDB',
  'DynamoDBStream',
  'DynWorker',
  'Easy-Peasy-Slide',
  'easyCache',
  'easyFe',
  'easyRestWithABL',
  'EasyUI',
  'eavesTool',
  'EBI-Icon-fonts',
  'echartsEx',
  'EclipseScroll',
  'ECMASquasher',
  'edfToHtmlConverter',
  'edGoogleApi',
  'edGraham',
  'EfemerideList',
  'efemerideList',
  'efficientLoad',
  'eFishCrawler',
  'EhanAreesha',
  'Elastic-Beanstalk-Sample-App',
  'ElasticSlider-core',
  'electron-isDev',
  'ElectronAppUpdater',
  'ElectronRouter',
  'elementsJS',
  'Elixirx',
  'Elm-0.17-Gulp-Coffeescript-Stylus-Lodash-Browserify-Boilerplate',
  'EmailClient',
  'ember-cli-fullPagejs',
  'ember-leaflet-geoJSON',
  'emoJiS-interpreter',
  'Empite',
  'EmpiteApp',
  'emptyObject',
  'emptyString-loader',
  'Encloud',
  'encodeBase64',
  'encodeID',
  'energyCalculator-browser',
  'EnglishTranslator',
  'ensureDir',
  'Enumjs',
  'Environment.js',
  'ep_disableChat',
  'EPO_OPS_WRAPPER',
  'equalViews-comparative-selection',
  'eRx-build',
  'ES-poc',
  'es6-DOM-closest',
  'eSlider',
  'eslint-plugin-elemMods',
  'EsmalteMx.ProductApi.Lambdas',
  'Estro',
  'ETag',
  'eValue-bs',
  'EVE',
  'EventDispatcher',
  'eventDrops',
  'EventEmitter',
  'EventField',
  'EventFire',
  'EventFire.js',
  'EventHub',
  'EventRelayEmitter',
  'events',
  'EventServer',
  'eventstore.mongoDb',
  'EventtownProject',
  'EventUtil',
  'EVEoj',
  'EverCookie',
  'ewdDOM',
  'ewdGateway',
  'ExBuffer',
  'execSync',
  'exFrame-configuration',
  'exFrame-core',
  'exFrame-generator',
  'exFrame-logger',
  'exFrame-mq',
  'exFrame-rest',
  'exFrame-rpc',
  'exFrame-security',
  'ExifEditor',
  'Exitent',
  'expectThat.jasmine-node',
  'expectThat.mocha',
  'Express',
  'Express-web-app',
  'expressApi',
  'ExpressCart',
  'ExpressCheckout',
  'expressingFounder',
  'ExpressMVC',
  'ExpressNode',
  'expressOne',
  'expressSite',
  'expressWeb',
  'ExtraInfo',
  'extraRedis',
  'Eyas',
  'EzetechT',
  'EZVersion',
  'F',
  'F-chronus',
  'f*',
  'FabioPluginiUno',
  'Facebook_Graph_API',
  'facebookPhotos',
  'FacebookYarn',
  'factor-bundle-WA64',
  'FAEN',
  'Faker',
  'Falcon',
  'fast-artDialog',
  'fastA_node',
  'FastLegS',
  'Fayer',
  'fbRecursiveRequest',
  'FeedbackModuleTest',
  'feedBum',
  'fenix-ui-DataEditor',
  'fenix-ui-DSDEditor',
  'Fermi-UI',
  'FetchCallLog',
  'fieldsValidator',
  'fig-Componts',
  'File',
  'File_Reader_solly',
  'FileBrowser',
  'FileError',
  'fileGlue',
  'FileList',
  'fileLog',
  'FilePicker-Phonegap-iOS-Plugin',
  'FileReader',
  'FileSaver',
  'FileSync',
  'FileWriter',
  'FileWriterSync',
  'Finder-command',
  'FirstApp',
  'FirstCustomPlugin',
  'firstModule',
  'firstNodejsModule',
  'firstYarn',
  'fis-parse-requireAsyncRes',
  'fis-postpackager-inCSSToWebP',
  'fis3SmartyTool',
  'FitText-UMD',
  'Flamingo',
  'flatToTrees',
  'fleschDe',
  'Flex-With-Benefits',
  'FlickrJS',
  'flipPage',
  'Florence',
  'FlowerPassword',
  'flowMap',
  'FLTEST',
  'fnProxy',
  'FontAwesome-webpack',
  'fontEnd',
  'FontLoader',
  'foo!',
  'foo~',
  'forAsync',
  'ForceCode',
  'forceLock',
  'forChangeFilesName',
  'forEachAsync',
  'formAnimation',
  'formatDate',
  'formBuilder',
  'FormData',
  'Formless',
  'formValidate',
  'FrameGenerator',
  'freightCrane',
  'French-stemmer',
  'Frenchpress',
  'FreshDocs',
  'friendsOfTrowel-buttons-component',
  'friendsOfTrowel-dropdowns-component',
  'friendsOfTrowel-Forms-component',
  'friendsOfTrowel-Layouts-component',
  'Friggeri.net',
  'Frog',
  'frontBuild',
  'Frontend-starter',
  'FrontEndCentral-documentation',
  'FrontJSON',
  'FrontPress',
  'Frozor-Logger',
  'Fruma',
  'fs',
  'fs-uTool',
  'FSM',
  'FT232H',
  'fuck!',
  'Fuell',
  'FuellDocTest',
  'FuellSys',
  'FuellTest',
  'FullStack',
  'FunDemo2',
  'FURI',
  'Fury',
  'futSearch',
  'futureDocBuilder',
  'FyreWorks-Node',
  'fzmFE',
  'Gaiam',
  'Ganescha-Bot-Jokes',
  'gaoboHello',
  'Garrett-pokemon',
  'gatesJs',
  'Gauge',
  'gaugeJS',
  'gaussianMixture',
  'gbL-jsMop',
  'GC-Sequence-Viewer',
  'gdBuildLogs',
  'gdBuilds',
  'Gems.PairedDeviceClient',
  'genData',
  'generateIndex',
  'generator-entityV2-widgets',
  'generator-kittJS',
  'generator-qccr-startKit',
  'generator-reactpackSample',
  'generator-zillionAngular',
  'Gengar',
  'GeoMatrix',
  'GeosysDroid',
  'GeosysTest',
  'Gerardo',
  'getDateformat',
  'getExtPath',
  'getSignature',
  'GettyEmbeddy',
  'ghostTools',
  'GhostTube',
  'GiftEditor',
  'GirlJS',
  'GitAzure',
  'gitbook-plugin-prism-ASH',
  'gitbook-plugin-specialText',
  'gitbook-start-heroku-P8-josue-nayra',
  'gitbook-start-heroku-P9-josue-nayra',
  'gitForge',
  'gitHub',
  'GitHub-Network-Graph',
  'GitHubTrending',
  'gitProvider',
  'gl-flyCamera',
  'gl-simpleTextureGenerator',
  'glMath',
  'GLORB',
  'glslCanvas',
  'glslEditor',
  'glslGallery',
  'GLSlideshow',
  'Glue',
  'GMP',
  'golbalModule',
  'Goldfish',
  'Gon',
  'Google_Plus_API',
  'Google_Plus_Server_Library',
  'Google-Chrome-command',
  'GoogleDrive',
  'googleOAuthServer',
  'googlePlaceAutocomplete',
  'GoogleService-NodeJs',
  'Gord',
  'gPagesJS',
  'Gps2zip',
  'GRAD_leaveNotes',
  'GRAD_makeFire',
  'grad-customGear',
  'grad-factions-VR',
  'grad-leaveNotes',
  'grad-makeFire',
  'Grafar',
  'Graph',
  'graphLock.custom.plugin',
  'graphQl-Mysql-Server',
  'GridFS',
  'GridManager',
  'gridminCss',
  'Gridtacular',
  'GroupePSAConnectedCar',
  'Grow.js',
  'Grunt-build',
  'grunt-checkFileSize',
  'grunt-cmd-handlebarsWrap',
  'grunt-ftp-getComponent',
  'grunt-httpTohttps',
  'grunt-latexTOpdf-conversion',
  'grunt-Npm-grunts',
  'grunt-po2mo-multiFiles',
  'grunt-Replacebyrefs',
  'grunt-syncFolder',
  'grunt-urlCacheBuster',
  'guideJs',
  'gulp-addSuffix',
  'gulp-combineHtml',
  'gulp-imgToBase64',
  'gulp-lowerCase',
  'gulp-phpWebserver',
  'gulp-spacingWord',
  'Gulp-Tasks',
  'GumbaJS',
  'Gusto',
  'gz2qiCalcModule',
  'h2oUIKit',
  'H5UI',
  'H666',
  'habibtestPublish',
  'HackBuffer',
  'handleStr',
  'HansontableComponent',
  'Haraka',
  'HariVignesh',
  'harmonyHubCLI',
  'HarryPotterParty',
  'harsh-Test-Module',
  'Harshil',
  'hash!',
  'hashPage',
  'hashTranslate',
  'HASWallpaperManager',
  'hasWord',
  'HeartBeatWoT_pi',
  'Hello',
  'hello_test_spade69XXX',
  'Hello_World',
  'HelloBot',
  'helloBySoo',
  'helloDevelopersnodejs',
  'HelloExpress',
  'helloModule',
  'HelloWorld',
  'helloWorld',
  'HelloWorld_hlhl_040',
  'HelloWorldComponent',
  'HelloWorldNodeJS',
  'helloYJ',
  'helpBy',
  'helpCenter',
  'herokuRun',
  'Hesiir-components',
  'HHello',
  'Hidash',
  'HiddenMarkovModel',
  'hideShowPassword',
  'highcharts-*',
  'HighlightP',
  'Highway',
  'Hinclude',
  'Hipmob',
  'Hiraku',
  'hm_firstPackage',
  'HMTraining',
  'homebridge-anelPowerControl',
  'homebridge-bigAssFans',
  'homebridge-CurrentAmbientLightLevel',
  'homebridge-Homeseer',
  'homebridge-LEDStrip',
  'homebridge-MotionSensor',
  'homebridge-RFbulb',
  'Homematic-Hue-Interface',
  'hoshiCustomContent',
  'hoshiImageLoader',
  'HotJS',
  'Hotshot',
  'hoverifyBootnav',
  'howToNPM',
  'Hppy',
  'Hpy',
  'htmlCutter',
  'htmlKompressor',
  'HTMLString',
  'htmlToTree',
  'http',
  'http2',
  'HTTPRequest',
  'https',
  'httpShell',
  'httpTohttps',
  'Hubik',
  'Hubik-Demo',
  'Hubik-Platform',
  'Hubik-Platform-Chrome',
  'Hubik-Plugin',
  'Hubik-Plugin-Memory',
  'Hubik-Plugin-Network',
  'Hubik-Plugin-Rendering',
  'Hubik-Util',
  'hubot-yigeAi',
  'HuK',
  'hybridCrypto',
  'i18next.mongoDb',
  'Ian_Chu',
  'IArray',
  'Ibis.js',
  'iCompute',
  'iEnhance',
  'IENotification',
  'iFrameAPI',
  'IFY-gulp-kit',
  'II',
  'IIF',
  'iIndexed',
  'iKeyed',
  'iM880-serial-comm',
  'imageCDN-webpack-loader',
  'imageMagick',
  'Imager',
  'Imageresizer',
  'imageTool',
  'ImageViewer',
  'iMagPay',
  'iMemoized',
  'iMessageModule',
  'Imovie',
  'Imp',
  'Incheon',
  'Index',
  'indexedStore',
  'inferModule-jsdoc-plugin',
  'infieldLabel',
  'Influxer',
  'inputcheckMemo',
  'inspector',
  'INSPINIA',
  'Insplash',
  'inStyle',
  'interactiveConsole',
  'Interval',
  'IO',
  'IObject',
  'ionic-gulp-browserify-typescript-postTransform',
  'IonicSocket',
  'iOS-HelloWorld',
  'IOTSDK',
  'iotsol-app-FAN',
  'iotsol-app-test-Node-RED',
  'iotsol-service-string-upperCase',
  'IQVIS',
  'Iris',
  'iRobo-react-modal',
  'iSecured',
  'isElementInViewport',
  'isEqual',
  'iSeries',
  'isFirefoxOrIE',
  'isHolidayInChina',
  'iSocketService',
  'isPureFunction',
  'iStorable',
  'iTransactable',
  'iTunes-command',
  'iValidated',
  'iWeYou',
  'iZettle',
  'iziModal',
  'JabroniJS',
  'jaCodeMap',
  'Jade-Sass-Gulp-Starter',
  'jadeBundler',
  'jadiTest',
  'jAlert',
  'JamSwitch',
  'JASON',
  'JavaScript-101',
  'JazzScript',
  'jcarouselSwipe',
  'jDataView',
  'jDate',
  'jetsExt',
  'Jimmy-Johns',
  'jingwenTest',
  'JMSList',
  'JMSlist.js',
  'Jody',
  'joi-dataURI',
  'joi-string-dataURI',
  'jordenAngular',
  'jordenAngular2',
  'JorupeCore',
  'JorupeInstance',
  'JOSS',
  'JotihuntReact',
  'Journaling-Hash',
  'jpaCreate',
  'jParser',
  'JPath',
  'jPlotter',
  'jPlugins',
  'JQ',
  'jQ-validation-laravel-extras',
  'JQDeferred',
  'jQGA',
  'jqGrid',
  'jqNode',
  'jqPaginator',
  'jqplot.donutRenderer',
  'jqPromise4node',
  'jqTreeGridWithPagination',
  'jQuery',
  'jquery-adaptText',
  'jquery-asAccordion',
  'jquery-asBgPicker',
  'jquery-asBreadcrumbs',
  'jquery-asCheck',
  'jquery-asChoice',
  'jquery-asColor',
  'jquery-asColorPicker',
  'jquery-asDropdown',
  'jquery-asFontEditor',
  'jquery-asGalleryPicker',
  'jquery-asGmap',
  'jquery-asGradient',
  'jquery-asHoverScroll',
  'jquery-asIconPicker',
  'jquery-asImagePicker',
  'jquery-asItemList',
  'jquery-asModal',
  'jquery-asOffset',
  'jquery-asPaginator',
  'jquery-asPieProgress',
  'jquery-asProgress',
  'jquery-asRange',
  'jquery-asScroll',
  'jquery-asScrollable',
  'jquery-asScrollbar',
  'jquery-asSelect',
  'jquery-asSpinner',
  'jquery-asSwitch',
  'jquery-asTooltip',
  'jquery-asTree',
  'jQuery-by-selector',
  'jquery-dynamicNumber',
  'jquery-idleTimeout-plus',
  'jquery-loadingModal',
  'jquery-navToSelect',
  'jQuery-QueryBuilder',
  'jquery-rsLiteGrid',
  'jquery-rsRefPointer',
  'jquery-rsSlideIt',
  'jQuery-Scanner-Detection',
  'jquery-scrollTo',
  'jquery-scrollToTop',
  'jquery-slidePanel',
  'jQuery.component',
  'jquery.customSelect',
  'jquery.dataTables.min.js',
  'jquery.Jcrop.js',
  'jQuery.keyboard',
  'jQuery.mmenu-less',
  'jQuery.print',
  'jquery.rsLiteGrid',
  'jquery.rsOverview',
  'jquery.rsRefPointer',
  'jquery.rsSlideIt',
  'jquery.rsSliderLens',
  'jQuery.toggleModifier',
  'jquery.waitforChild',
  'jqueryPro',
  'js-build-RomainTrouillard',
  'JS-Entities',
  'JS-string-minimization',
  'JS.Responsive',
  'jSaBOT',
  'jsCicada',
  'jsConcat',
  'JSCPP',
  'jsDAV',
  'JSDev',
  'jsdoc-TENSOR',
  'jsDocGenFromJson',
  'jsDump',
  'jSelect',
  'JSErrorMonitor',
  'JSErrorMonitor-server',
  'jsFeed',
  'jsFiddleDownloader',
  'JSFramework',
  'JSLint-commonJS',
  'JSLintCli',
  'JSLogger',
  'JSON',
  'JSON-Splora',
  'JSON.sh',
  'JSON2',
  'json8-isArray',
  'json8-isBoolean',
  'json8-isJSON',
  'json8-isNull',
  'json8-isNumber',
  'json8-isObject',
  'json8-isPrimitive',
  'json8-isString',
  'json8-isStructure',
  'JSON2016',
  'JSONloops',
  'JSONPath',
  'JSONPathCLI',
  'JSONRpc',
  'JSONSelect',
  'JSONStream',
  'JsonUri',
  'JSONUtil',
  'jsonX',
  'JSplay',
  'jspolyfill-array.prototype.findIndex',
  'JSPP',
  'JSpring',
  'jsQueue',
  'jsSourceCodeParser',
  'jStat',
  'JSUS',
  'JSV',
  'JSX',
  'jsz-isType',
  'JTemplate',
  'JTmpl',
  'jTool',
  'JuliaStyles',
  'JumanjiJS',
  'Jupyter-Git-Extension',
  'justifiedGallery',
  'justJenker',
  'JustMy.scss',
  'JWBootstrapSwitchDirective',
  'jWorkflow',
  'jxLoader',
  'JYF_restrict',
  'K_Tasks',
  'K--Ajax',
  'K-Report',
  'KAB.Client',
  'Kahana',
  'Kapsel-project',
  'Katy',
  'Kayzen-GS',
  'KB',
  'KB_Model',
  'kelTool',
  'kelTool2',
  'KenjutsuUI',
  'KevinLobo3377-node',
  'KFui',
  'kickoff-fluidVideo.css',
  'Kid',
  'kingBuilder',
  'kiranApp',
  'Kirk',
  'Kissui',
  'kittJS',
  'Kiwoom-Helper',
  'KLC3377-node',
  'knockout.ajaxTemplateEngine',
  'koa-artTemplate',
  'koa-Router',
  'koaPlus',
  'koaVue',
  'KonggeIm',
  'kpPublicPerson',
  'kpPublicVideo',
  'krawlerWash',
  'ktPlayer',
  'kylpo-BackgroundImage',
  'kylpo-Block',
  'kylpo-Button',
  'kylpo-Col',
  'kylpo-Flex',
  'kylpo-Inline',
  'kylpo-InlineBlock',
  'kylpo-InlineCol',
  'kylpo-InlineFlex',
  'kylpo-InlineRow',
  'kylpo-Paint',
  'kylpo-Painter',
  'kylpo-Row',
  'kylpo-Text',
  'kylpo-View',
  'kzFormDaimyo',
  'L.TileLayer.Kartverket',
  'L7',
  'labBuilder',
  'Lactate',
  'Lade',
  'laravel-jQvalidation',
  'Large',
  'lark-PM',
  'LasStreamReader',
  'latte_web_ladeView',
  'latte_webServer4',
  'lavaK',
  'layaIdecode',
  'Layar',
  'Layout',
  'LazyBoy',
  'lazyBum',
  'lazyConnections',
  'lazyLoadingGrid',
  'lcAudioPlayer',
  'LCM',
  'LDAP',
  'Leaf.js',
  'Leaflet-MovingMaker',
  'Leaflet.AutoLayers',
  'Leaflet.Deflate',
  'Leaflet.GeoJSON.Encoded',
  'Leaflet.GreatCircle',
  'Leaflet.MultiOptionsPolyline',
  'Leaflet.TileLayer.MBTiles',
  'Leaflet.vector-markers',
  'leapShell',
  'LearningNPM',
  'learnnode_by_HHM',
  'leFunc',
  'Legos',
  'Libby-Client',
  'LightCinematic',
  'lihuanxiangNpm1',
  'limitedQueue',
  'linearJs',
  'lineReader',
  'Lingo',
  'LinkedList',
  'linkIt',
  'LISP.js',
  'liteParse',
  'liuchengjunOrder0414',
  'LiveController',
  'LiveDocument',
  'LiveScript',
  'LiveScript-brunch',
  'LiveView',
  'liweiUitl',
  'lizaorenqingTool',
  'lmONE',
  'LMUI',
  'LMX-Data',
  'LNS_weixin_h5',
  'localeMaker_v1',
  'localforage-memoryStorageDriver',
  'LocalRecord',
  'localStorage',
  'localStorage-info',
  'localStorage-mock',
  'LoDashfromScratch',
  'lofterG',
  'Loganalyzer',
  'LogbookMessageCreator',
  'Logger',
  'Logging',
  'Loggy',
  'logic2UI',
  'LogosDistort',
  'LogStorage.js',
  'logStream',
  'LOL',
  'lolAJ',
  'LongestCommonSubstring',
  'loop-setTimeout',
  'loopback-connector-rest-addCookie',
  'lopataJs',
  'Lorem',
  'Losas',
  'LP_test_task',
  'Lucy',
  'LUIS',
  'LUIS_FB',
  'Lumenize',
  'Lush.js',
  'LykkeFramework',
  'M66_math_example',
  'mac-cropSr',
  'MacGyver',
  'Mad.js',
  'magentoExt',
  'Maggi.js',
  'Maggi.js-0.1',
  'MagpieUI',
  'MALjs',
  'Mambo-UI',
  'mangoSlugfy',
  'mapleTree',
  'mappumBot',
  'Marionette-Require-Boilerplate',
  'markupDiff',
  'marryB',
  'MasterDetailApplication',
  'MaterialAngularWithNodeJS',
  'Math',
  'math_example_20160505163300BR',
  'math_example_Hala',
  'math_example_myown_ve-01119310520_V2',
  'math_exampleCJG',
  'math_exampleII',
  'math_exampleX',
  'math_ThisIsMe',
  'math-Murasame',
  'Math1105',
  'mathAdd',
  'mathExample',
  'MathJax-node',
  'MathJS',
  'mathMagic',
  'MathTest1',
  'MatPack',
  'Mavigator',
  'MAX-AVT-homebridge-led',
  'MAXAVTDemo',
  'MAXIMjs',
  'MaxUPS',
  'MCom',
  'MD5',
  'MDLCOMPONENT',
  'mdlReact',
  'mdPickers',
  'mdRangeSlider',
  'mdToPdf',
  'MEAN',
  'MeanApp1',
  'MeCab',
  'mediaCheck',
  'Mediany',
  'medicalHistory',
  'Mercury',
  'Meridix-WebAPI-JS',
  'Mers',
  'MessageBus',
  'MetaEditor',
  'Meteor-Test-Installer',
  'MetroTenerife',
  'MFL-ng',
  'MFRC522-node',
  'mglib-GAMS.WEBCLIENT2',
  'MIA',
  'MicroServices',
  'Midgard',
  'midhunthomas_Test',
  'mihoo_fileUpload',
  'mini-fileSystem-WebServer',
  'Mini-test',
  'MiniAppOne',
  'MiniAppTwo',
  'minibuyCommonality',
  'miniJsonp',
  'MiniManager',
  'MiniMVC',
  'MinionCI',
  'Minju003',
  'Mirador',
  'Misho_math_example',
  'MJackpots',
  'mjb44-playground-module-exporting-interface-and-type-method-B',
  'mjb44-playground-module-exporting-interface-and-type-method-C',
  'Mkoa',
  'Mkoa-pg-session',
  'MKOUpload',
  'mlm603Test',
  'mmAnimate',
  'mmDux',
  'MMM-alexa',
  'mmRequest',
  'mmRouter',
  'mNotes',
  'Mockery',
  'modalDemo',
  'modalDemo1',
  'modalWin.js',
  'module',
  'ModuleBinder',
  'modulebyAKB',
  'ModuleC',
  'moduleLoader',
  'moduleTest',
  'MoEventEmitter',
  'Mokr',
  'Mole',
  'mon-appNon0',
  'MonApp',
  'MongoDAL',
  'mongoose-schema-to-graphQL',
  'mongooseSchema-to-graphQL',
  'Monik',
  'MonikCommon',
  'MoniqueWeb',
  'Monorail.js',
  'Mopidy-Spotmop',
  'mosesCheckIn',
  'MovieJS',
  'mOxie',
  'MoxtraPlugin_1.1',
  'MoxtraPlugin_1.2.1',
  'mPortalUI',
  'MQTTClient',
  'Mr.Array',
  'Mr.Async',
  'Mr.Coverage',
  'mraaStub',
  'MrsYu',
  'MrsYu1',
  'msGetStarted',
  'mSite',
  'msJackson',
  'mSnackbar',
  'Mu',
  'Muffin',
  'MultiSlider',
  'musuAppsas',
  'MWS_Automation',
  'my-awesome-nodejs-moduleHL',
  'my-componentAnimesh',
  'My-First-Module',
  'My-first-Package',
  'My-Fist-Project',
  'my-HLabib',
  'My1ink',
  'MyAngularGruntt',
  'MyAnimalModule',
  'myappSriniAppala',
  'myappUSBankExample',
  'myAries',
  'MyBlog',
  'myCalclator',
  'myDate',
  'myDialog',
  'myDu2',
  'myDVA',
  'myFirst-Nodejs-Module',
  'MyFirstContribution',
  'myfirstDemo',
  'myFirstModule',
  'myFirstNodeModule',
  'myFirstNpm',
  'myFirstPluginAji',
  'myFirstProject',
  'myFirstPub',
  'myLib',
  'myMath',
  'MYMODAL',
  'MyModule',
  'myModule',
  'myNodeJs',
  'myNodeJsApp',
  'myNodejsApp',
  'myNpm',
  'MYnpm1',
  'myNpm0001',
  'myNpm2',
  'myNpm5',
  'myNpm10',
  'myNpm11',
  'myNpm111',
  'myNpm999',
  'myNpmfei',
  'myNpmfei1',
  'myNpml',
  'myNpmModule',
  'myNpmrz1',
  'MyPlugin',
  'MyProject',
  'MyProjNode',
  'myPromise',
  'myrikGoodModule',
  'Mysql-Assistant',
  'mysupermoduleXXX',
  'myTest',
  'Mytest_module',
  'mytPieChart',
  'N',
  'N3-components',
  'NA1',
  'NageshTestapplication',
  'NAME',
  'Nameless13',
  'NaNNaNBatman.js',
  'nanoTest',
  'NasimBotPlatform',
  'NativeAds',
  'NativeCall',
  'NativeProject',
  'nativescript-CallLog',
  'nativescript-GMImagePicker',
  'nativescript-logEntries',
  'NavExercise',
  'nCinoRabbit',
  'ncURL',
  'NDDB',
  'neouiReact-button',
  'Neptune',
  'NERDERY.JS.NAT',
  'nestedSortable',
  'net',
  'NeteaseCloudMusicApi',
  'neteaseMusicApi',
  'Netflow',
  'Netlifer',
  'NetMatch',
  'NetOS',
  'netOS',
  'Netpath-Test',
  'Neuro',
  'Neuro-Company',
  'NewModule1',
  'newmsPong',
  'newPackage',
  'newPioneer',
  'newStart',
  'newtouchCloud',
  'NewWebview',
  'NexManager',
  'NexmoJS',
  'NFO-Generator',
  'ng2-clockTST',
  'ng2-dodo-materialTypeTransfer',
  'ng2-QppWs',
  'ng2GifPreview',
  'NG2TableView',
  'ngBrowserNotification',
  'ngCart',
  'ngChatScroller',
  'ngComponentRouter-patched',
  'ngCurrentGeolocation',
  'ngDfp',
  'ngDrag',
  'ngFileReader',
  'ngGen',
  'ngGeolocation',
  'ngHyperVideo',
  'ngIceberg',
  'ngImgHandler',
  'ngIntercom',
  'ngKit',
  'ngPicker',
  'ngPluralizeFilter',
  'ngPluralizeFilter2',
  'ngProgress-browserify',
  'ngScroll',
  'ngSinaEmoji',
  'ngSmoothScroll',
  'ngSqlite',
  'ngTile',
  'ngTimeInput',
  'ngTreeView',
  'ngUpload',
  'ngUpload-forked',
  'Nguyen_test',
  'ngVue',
  'ngYamlConfig',
  'nHttpInterceptor',
  'Nick_calc',
  'NickSam_CGD',
  'NightPro-Web',
  'nightwatchGui',
  'Nikmo',
  'nImage',
  'Nitish',
  'nitish.kumar.IDS-LOGIC',
  'NlpTextArea',
  'nltco-lgpt-clean-A',
  'nltco-lgpt-clean-B',
  'nltco-lgpt-dedupe-simple-A',
  'nltco-lgpt-dedupe-simple-B',
  'nMingle',
  'nmPhone',
  'nMysql',
  'NoCR',
  'NODE',
  'Node_POC',
  'node-CORSproxy',
  'Node-FacebookMessenger',
  'Node-HelloWorld-Demo',
  'node-iDR',
  'node-iOS',
  'Node-JavaScript-Preprocessor',
  'node-localStorage',
  'Node-Log',
  'Node-Module-Test',
  'node-myPow',
  'node-red-contrib-samsungTV',
  'node-red-contrib-wwsNodes',
  'node-red-StefanoTest',
  'node-TBD',
  'NodeApp',
  'nodeApp',
  'nodeAuth',
  'nodeBase',
  'NodeBonocarmiol',
  'nodeCalcPax',
  'nodeCombo',
  'nodeDemo9.26',
  'nodeDocs',
  'nodeEventedCommand',
  'NodeFileBrowser',
  'NodeFQL',
  'nodeHCC',
  'nodeInterface',
  'NodeInterval',
  'nodeIRCbot',
  'nodeJS',
  'NodeJS_Tutorial',
  'nodeJs-zip',
  'NodejsAgent',
  'NodeJsApplication',
  'nodejsFramework',
  'nodejsLessons',
  'NodeJsNote',
  'NodeJsPractice',
  'nodeJsPrograms',
  'Nodejsricardo',
  'NodeJSTraining-demo-9823742',
  'nodejsTutorial',
  'NodejsWebApp1',
  'nodejsWorkSpace',
  'NodeKeynote',
  'nodeLearning',
  'nodeMarvin',
  'nodeMarvin2',
  'NodeMini',
  'nodeMysqlWrapper',
  'nodeNES',
  'nodeos-boot-multiUser',
  'nodeos-boot-singleUser',
  'nodeos-boot-singleUserMount',
  'nodepackageBoopathi',
  'nodePhpSessions',
  'NodePlugwise',
  'NodePlugwiseAPI',
  'nodeQuery',
  'nodes_Samples',
  'NodeSDK-Base',
  'NodeServerExtJS',
  'NodeSSH',
  'nodeSSO',
  'NodeSTEP',
  'nodeTest',
  'NodeTestDee',
  'nodeTTT',
  'nodeTut',
  'NoDevent',
  'NodeView',
  'nodeWebsite',
  'NodObjC',
  'Nonsense',
  'NoobConfig',
  'NoobHTTP',
  'normalizeName',
  'NORRIS',
  'nOSCSender',
  'Note.js',
  'NotificationPushsafer',
  'Notifly',
  'Npm',
  'npm-Demo',
  'Npm-Doc-Study',
  'npm-mydemo-pkgTest',
  'npm-setArray',
  'npm-wwmTest',
  'npmCalc',
  'npmFile',
  'npmModel',
  'npmModel1',
  'npmModel2',
  'npmTest',
  'npmToying',
  'npmTutorial',
  'NPR_Test',
  'nrRenamer',
  'nStoreSession',
  'nTPL',
  'nTunes',
  'NudeJS',
  'nunjucks-includeData',
  'O',
  'O_o',
  'o_O',
  'O2-countdown',
  'O2-tap',
  'objectFitPolyfill',
  'ObjectSnapshot',
  'ObjJ-Node',
  'ObservableQueue',
  'OCA-api',
  'ocamlAlpha',
  'ocamlBetterErrors',
  'OcamlBytes',
  'ocamlBytes',
  'ocamlRe',
  'OhMyCache',
  'OK-GOOGLE',
  'Olive',
  'onBoarding',
  'OnCollect',
  'OneDollar.js',
  'oneTest',
  'OpenBazaar-cli',
  'OpenDolphin',
  'OpenJPEG.js',
  'openWeather',
  'OperatorUI',
  'OPFCORS',
  'OPFSalesforce',
  'OptionParser',
  'OrangeTree',
  'Orchestrator',
  'Order',
  'ORIENTALASIAN',
  'os',
  'Osifo-package',
  'osu-ModPropertiesCalculator',
  'OTPAutoVerification',
  'overloadedFunction',
  'OwnMicroService',
  'OwnNormalizer',
  'OwnPubSub',
  'OwnPubSubClient',
  'OwnPubSubServer',
  'p2Pixi',
  'PaasyMcPaasFace',
  'pacemakerJS',
  'packAdmin',
  'Package',
  'packageNodeCR-Jeff.json',
  'packagePublished',
  'packageTesting',
  'Packery-rows',
  'packing-template-artTemplate',
  'Paddinator',
  'Paginate',
  'palindromeCalcPax',
  'palindromePax',
  'PanPG',
  'Panzer',
  'parameterBag',
  'paramsValidator',
  'Parse-Server-phone-number-auth',
  'parseArgs',
  'Parser',
  'parseUri',
  'Particle',
  'Particleground.js',
  'PassiveRedis',
  'path',
  'PatternLabStarter',
  'patternReplacer',
  'paytmGratify',
  'PayzenJS',
  'pDebug',
  'pdf-to-dataURL',
  'pdfTOthumbnail_convert',
  'PeA_nut',
  'Peek',
  'PeepJS',
  'Pega.IO',
  'Peggy.js',
  'Percolator',
  'perf_hooks',
  'performJs',
  'pgnToJSON',
  'PHibernate',
  'phoeNix-cli',
  'phoenixCLI',
  'PhonegapAnalytics',
  'PhonegapBeacon',
  'PhonegapFeeds',
  'PhonegapGeofence',
  'PhonegapGrowth',
  'PhonegapLocations',
  'PhonegapPush',
  'picardForTynt',
  'PicoMachine',
  'Pictionary',
  'Pintu',
  'pjEmojiTest',
  'PJsonCouch',
  'PK',
  'PL8',
  'placeHolder.js',
  'PLATO',
  'PlayStream',
  'pluginCreater',
  'pluginHelloWorld',
  'pluginHelloworld',
  'pluginTest',
  'PlugMan',
  'pluuuuHeader',
  'PoistueJS',
  'Pokeball-Scanner',
  'PokeChat',
  'PokedexJS',
  'PokemonGoBot',
  'PokemonGoNodeDashboard',
  'polar-cookieParser',
  'pollUntil',
  'Polymer',
  'POM',
  'pomeloGlobalChannel',
  'pomeloScale',
  'portal-fe-devServer',
  'PostgresClient',
  'Postlog',
  'PowerPlanDisplay',
  'powerPlug',
  'PP',
  'ppublishDemo',
  'Pre',
  'Preprocessor',
  'PrettyCSS',
  'prettyJson',
  'PrimaryJS',
  'primerNodo',
  'primo-explore-LinkedData',
  'primo-explore-prmFacetsToLeft',
  'primo-explore-prmFullViewAfter',
  'primo-explore-prmLogoAfter',
  'primo-explore-prmSearchBarAfter',
  'PrimoEsempio',
  'Printer',
  'Prism',
  'prjTemplate',
  'Probes.js',
  'process',
  'proInterface',
  'Project-A-VK',
  'Prometheus',
  'Promise',
  'Promise.js',
  'PromiseContext',
  'promisify-syncStore',
  'PropagAPISpecification',
  'propCheckers',
  'Propeller',
  'properJSONify',
  'Proto',
  'proton-quark-rabbitMQ',
  'ProtVista',
  'ProUI-Utils',
  'ProvaSimone',
  'provinceCity.js',
  'PSNjs',
  'PTC-Creator',
  'ptyzhuTest_20160813',
  'PublishDemo',
  'publishDigitalCrafts2016',
  'PubSub',
  'pubsubJS',
  'pulsarDivya',
  'punycode',
  'PupaFM',
  'Puppet.svg',
  'PureBox',
  'PureBox-Gallery-PlayEngine',
  'purePlayer',
  'PushMessage',
  'PushPanel',
  'PushPlugin_V2',
  'pybee!batavia',
  'Q',
  'q-mod-cliElements',
  'q-mod-cliPrinter',
  'QAP-cli',
  'QAP-SDK',
  'Qarticles',
  'QnA_Fore',
  'QNtest',
  'qqMap',
  'qTip2',
  'QuadMap',
  'QuantumExperimentService',
  'querystring',
  'R',
  'R.js',
  'R2',
  'RAD.js',
  'Radical',
  'raehoweNode',
  'Rajas',
  'random-fullName',
  'randomCaddress',
  'randomCname',
  'randomCname.js',
  'randomLib',
  'randomNickname',
  'RandomSelection',
  'randomTestOne',
  'randString',
  'randString.js',
  'Range.js',
  'Rannalhi',
  'rAppid.js',
  'rAppid.js-server',
  'rAppid.js-sprd',
  'Rapydscriptify',
  'RaspiKids',
  'raZerdummy',
  'RCTMessageUI',
  'React_Components',
  'React-Carousel',
  'react-countTo',
  'react-creditCard',
  'React-ES5-To-ES6-Checklist',
  'react-input-dateTime',
  'react-InputText-component',
  'react-komposer-watchQuery',
  'react-materialUI-components',
  'react-native-accountKit',
  'react-native-cascadeGrid',
  'react-native-checkBox',
  'react-native-DebugServerHost',
  'React-Native-Form-Field',
  'react-native-isDeviceRooted',
  'react-native-LoopAnimation',
  'react-native-MultiSlider',
  'react-native-portableView',
  'react-native-swRefresh',
  'react-PPT',
  'React-Redux-Docker-Ngnix-Seed',
  'react-refresh-infinite-tableView',
  'React-Select-Country',
  'React-Tabs',
  'React-UI-Notification',
  'react-uploadFile',
  'reactClass',
  'reactcordovaApp',
  'ReactEslint',
  'reactFormComponentTest1',
  'reactGallery',
  'reactHeaderComponentTest1',
  'ReactHero',
  'reactIntlJson-loader',
  'ReactNaitveImagePreviewer',
  'ReactNative-checkbox',
  'reactNative-checkbox',
  'reactNativeDatepicker',
  'reactNativeLoading',
  'ReactNativeNavbar',
  'ReactNativeSlideyTabs',
  'ReactNativeSocialLogin',
  'ReactNativeStarterKit',
  'ReactNativeToastAndroid',
  'reactTwo',
  'ReactUploader',
  'readabilitySAX',
  'ReadableFeeds',
  'readline',
  'ReadSettings',
  'Reality3D',
  'reallySimpleWeather',
  'ReApp',
  'ReasonDB',
  'RecastAI-Library-JavaScript',
  'recordType',
  'recordWebsite',
  'RedisCacheEngine',
  'redisHelper',
  'reDIx',
  'RefreshMedia',
  'registerSendMsg',
  'reloadOnUpdate',
  'remoteFileToS3',
  'RemoteTestService',
  'removeNPMAbsolutePaths',
  'RentalAdvantage',
  'repl',
  'Replace',
  'Replace2.0',
  'Replen-FrontEnd',
  'replNetServer',
  'Require',
  'requireAsync',
  'Resin',
  'resolveDependencies',
  'responseHostInfo',
  'ReST-API',
  'RESTful-API',
  'Restifytest',
  'Restlastic',
  'RESTLoader',
  'Reston',
  'RestTest',
  'RetreveNumbers',
  'rgbToHexa',
  'RhinoStyle',
  'Richard',
  'richardUtils',
  'rinuts-nodeunitDriver',
  'Risks-Tables',
  'RNBaiduMap',
  'RNCommon',
  'RNSVG',
  'RNSwiftHealthkit',
  'rNums',
  'RobinGitHub',
  'Robusta',
  'RockSelect',
  'Router',
  'RP_Limpezas_Industriais',
  'Rpm',
  'RSK-Router',
  'RT-react-toolbox',
  'Rubytool',
  'runQuery',
  'runStormTest',
  'runTestScenario',
  'RunwayLogger',
  'RWD-Table-Patterns',
  'RWPromise',
  'Safari-command',
  'SafeObject.js',
  'Safood-Parse',
  'SaFood-Parse',
  'sahibindenServer',
  'salgueirimTeste',
  'samepleMicroservice',
  'samjs-mongo-isOwner',
  'Sample',
  'SamplePlugIn',
  'SandboxTools',
  'sandcastle_multiApp',
  'Sanitizer.js',
  'sanitizer.unescapeEntities',
  'Sardines',
  'Sass-Boost',
  'Sass-JSON',
  'Sass-layout',
  'Saturday',
  'SauceBreak',
  'sayHelloByone',
  'sbg-queueManager',
  'sbUtils',
  'SC-Expense-Plugin',
  'Scaffolding',
  'scalejs.metadataFactory',
  'ScgiClient',
  'Scheduler.js',
  'schema-inspector-anyOf',
  'scp-cleanRedis',
  'Scrap',
  'scriptTools',
  'scrollAnimation',
  'scrollPointerEvents',
  'ScrollShow',
  'Sdp-App',
  'seaModel',
  'searchBox.js',
  'SecChat',
  'SecureKeyStore',
  'segnoJS',
  'Seguranca',
  'SegurancaBrasilcard',
  'Select2',
  'selfAsync',
  'selfAutocomplete',
  'SelfieJS',
  'SenseJs',
  'SenseOrm',
  'Sentimental',
  'SeptemTool',
  'seqFlow',
  'SerialDownloader',
  'serveItQuick',
  'Server',
  'Service-Discovery-DLNA-SSDP',
  'serviceDiscovery',
  'SessionWebSocket',
  'Set',
  'setInterval',
  'setRafTimeout',
  'setTimeout',
  'SexyJS',
  'sfaClient',
  'sgBase',
  'sgCore',
  'sgFramework',
  'sgLayers',
  'sgSay',
  'Sharder',
  'ShareSDK',
  'SharingCMS',
  'Shave',
  'Sheet',
  'SHI-Shire',
  'sHistory',
  'ShowNativeContact',
  'SHPS4Node-auth',
  'SHPS4Node-cache',
  'SHPS4Node-commandline',
  'SHPS4Node-Config',
  'SHPS4Node-config',
  'SHPS4Node-cookie',
  'SHPS4Node-CSS',
  'SHPS4Node-dependency',
  'SHPS4Node-error',
  'SHPS4Node-file',
  'SHPS4Node-frontend',
  'SHPS4Node-init',
  'SHPS4Node-language',
  'SHPS4Node-log',
  'SHPS4Node-make',
  'SHPS4Node-optimize',
  'SHPS4Node-parallel',
  'SHPS4Node-plugin',
  'SHPS4Node-sandbox',
  'SHPS4Node-schedule',
  'SHPS4Node-session',
  'SHPS4Node-SQL',
  'shwang1aPackage1',
  'shy-Do',
  'shy-static-imgJoin',
  'SignaturePrinter',
  'Silvera',
  'simoneDays',
  'Simple',
  'Simple-Cache',
  'simple-hello-world-apiClientsideTest',
  'simple-jQuery-slider',
  'simpleArgsParser',
  'simpleCsvToJson',
  'SimpleHtdigest',
  'SimpleQueue',
  'SimpleRPC',
  'Simplog',
  'SingularityUI',
  'sip.js-mnQf2Q2R',
  'Sisense-node-schedule',
  'SITA-JS-Wrapper',
  'siteBuild',
  'Skadi',
  'SkelEktron',
  'SKRCensorText',
  'SkyLabels.js',
  'Skype-command',
  'slgComponents',
  'Slidebars',
  'Slidebars-legacy',
  'slidePage',
  'Slither-Server',
  'sLog',
  'slush-initPro',
  'Smaller4You',
  'Smart-Web-Proxy',
  'SmartConfig',
  'SmartyGrid',
  'SMValidator',
  'smyNpm1',
  'Snake.js',
  'SnipIt',
  'SnsShare',
  'SocialDig.js',
  'Socialight',
  'socketGW',
  'SocketIPC',
  'sortBy.js',
  'Soumen',
  'SoundCloud_Node_API',
  'SpaceMagic',
  'SpeechJS',
  'Speedco',
  'Speedonetzer',
  'Sphero-Node-SDK',
  'Spores',
  'Spot',
  'spotifyCurrentlyPlaying.js',
  'SpotlightJS',
  'Spring',
  'SPUtility.js',
  'SQLClient',
  'SQProject',
  'SquareOfNumber',
  'Squirrel',
  'squishMenu',
  'Sslac',
  'SSO',
  'SSSDemoNPM7oct',
  'SSuperSchool',
  'StaceFlow',
  'StanLee-WPTheme-Generator',
  'star-initReact',
  'Starr',
  'startInt',
  'starW-names',
  'StaticServer',
  'staticServer',
  'staticSync',
  'StatusBar',
  'StdJSBuilder',
  'steamAPI',
  'STEPNode',
  'Stewed',
  'stickUp',
  'stickyNavbar.js',
  'stickyStack',
  'StimShopPlugin',
  'storeJSON',
  'storkSQL',
  'stormClient',
  'Str.js',
  'Stratagem',
  'stream',
  'string_decoder',
  'String_module',
  'string-DLL',
  'string.prototype.htmlDecode',
  'string.prototype.htmlEntityDecode',
  'StringDistanceTS',
  'StringMultiplier',
  'StringScanner',
  'STRUCT',
  'Suckle',
  'sudokuMaker',
  'sudoTracker',
  'SUI-Angular2-Modal',
  'superClipBoard',
  'SuperDank',
  'superJoy',
  'Supermodule',
  'supermoduleBugay',
  'supermoduleLyu',
  'supermoduleNik',
  'supermoduleShulumba',
  'Supersonic',
  'superUsingMod',
  'svgSprite',
  'swimCoachStopwatch',
  'SwitchBoard',
  'synchro_ByJoker',
  'SyncRun',
  'Syndication',
  'Synergy',
  'sys',
  'Sysdate',
  'sytemMonitor-client',
  'szxPack',
  'T_T',
  'T-Box',
  'table-Q',
  'tableComponent',
  'Tachyon',
  'TagCloud',
  'tagOf',
  'TagSelect.js',
  'TalkerNode',
  'TALQS',
  'talquingApp',
  'TangramDocs',
  'tap-linux-2BA',
  'tap-win-2BA',
  'tap-win-C94',
  'Targis',
  'Tattletale',
  'Tayr',
  'tbCLI',
  'TDTwitterStream',
  'Tea',
  'TeamBuilder',
  'TechNode',
  'TechnoLib',
  'TeeChart',
  'Templ8',
  'Template',
  'Tempus',
  'Ter',
  'Tereshkovmodule',
  'Terminal-command',
  'test_helloWorld',
  'Test-7',
  'test-A',
  'test-naamat-Al-Aswad',
  'Test-Project',
  'TestAmILate',
  'testApi',
  'testApp',
  'Testchai2',
  'Testchai21',
  'testContrast',
  'TESTdelete123',
  'testDEMOABCD',
  'testDirJackAtherton',
  'Teste2',
  'testeRealTime',
  'testForThis',
  'testMe',
  'testModule',
  'testModule-hui',
  'testNode',
  'TestNodeJsApplication',
  'testPackage',
  'testPackage2',
  'TestPlugin',
  'testPlugin',
  'TestProject',
  'testProject',
  'testPublish',
  'testPublisha',
  'testPublishNpmModule',
  'TFWhatIs',
  'Thairon-node',
  'Thanatos_pack',
  'ThanhNV',
  'Theater',
  'TheGiver',
  'Thimble',
  'Thing.js',
  'thingHolder',
  'think-paymentService',
  'think-qiniuService',
  'think-quotationService',
  'think-wechatService',
  'ThinkHub',
  'ThinkInsteon',
  'ThirtyDaysOfReactNative',
  'threadHandler',
  'threejs-htmlRenderer',
  'ThrustFS',
  'ThumborJS',
  'TigraphBot',
  'tilejsonHttpShim',
  'Time-Tracker-Cli',
  'Timelined',
  'Timeliner.Core',
  'Timeliner.Index',
  'Timepass',
  'timers',
  'timeTraveller',
  'timeUtils',
  'tiNanta',
  'TinyAnimate',
  'tinyChat',
  'tinyEmiter',
  'tinyFrame',
  'tinyImages',
  'tinyLoger',
  'Titan',
  'TJAngular',
  'tls',
  'tm-apps-poolApi',
  'tmSensor',
  'toBin',
  'toDataURL',
  'toDoList',
  'toDots',
  'Toji',
  'tokenAndAuthorizationManager',
  'tokenAndAuthorizationManger',
  'Tom',
  'tomloprodModal',
  'Tool-bluej-gulp',
  'Toolshed-Client',
  'topSdk',
  'TopuNet-AMD-modules',
  'TopuNet-BaiduMap',
  'TopuNet-CalendarScroller',
  'TopuNet-dropDownLoad',
  'TopuNet-GrayScale',
  'TopuNet-ImageCropCompressorH5',
  'TopuNet-JRoll',
  'TopuNet-js-functions',
  'TopuNet-JsHint4Sublime',
  'TopuNet-JsHintify',
  'TopuNet-Landscape_mask',
  'TopuNet-Landscape-Mask',
  'TopuNet-LayerShow',
  'TopuNet-mobile-stop-moved',
  'TopuNet-node-functions',
  'TopuNet-Pic-code',
  'TopuNet-PromptLayer-JS',
  'TopuNet-QueueLazyLoad',
  'TopuNet-RequireJS',
  'TopuNet-RotatingBanner',
  'TopuNet-WaterFall',
  'TopuNet-weixin-node',
  'TorrentBeam',
  'TorrentCollection',
  'toSrc',
  'toString',
  'touchController',
  'toYaml',
  'TPA',
  'tr-O64',
  'trace_events',
  'TradeJS',
  'Trains',
  'TrainsController',
  'TrainsModel',
  'TramiteDocumentarioFront',
  'TransactionRelay',
  'transformConfigJson',
  'transitionEnd',
  'translateFzn',
  'Travis',
  'TrixCSS',
  'truncateFilename',
  'tslint-jasmine-noSkipOrFocus',
  'TSN',
  'ttm-Testing',
  'tty',
  'Tuio.js',
  'Turntable',
  'tuTrabajo-client',
  'TweenTime',
  'TwigJS',
  'twitterApiWrapper',
  'txtObj',
  'Tyche',
  'TypeCast',
  'typedCj.js',
  'TypedFunc',
  'typescript-demo-MATC-Andrew',
  'typography-theme-Wikipedia',
  'typopro-web-TypoPRO-AmaticSC',
  'typopro-web-TypoPRO-AnonymousPro',
  'typopro-web-TypoPRO-Asap',
  'typopro-web-TypoPRO-Astloch',
  'typopro-web-TypoPRO-BebasNeue',
  'typopro-web-TypoPRO-Bitter',
  'typopro-web-TypoPRO-Chawp',
  'typopro-web-TypoPRO-ComingSoon',
  'typopro-web-TypoPRO-Cousine',
  'typopro-web-TypoPRO-Coustard',
  'typopro-web-TypoPRO-CraftyGirls',
  'typopro-web-TypoPRO-Cuprum',
  'typopro-web-TypoPRO-Damion',
  'typopro-web-TypoPRO-DancingScript',
  'typopro-web-TypoPRO-Delius',
  'typopro-web-TypoPRO-Gidole',
  'typopro-web-TypoPRO-GiveYouGlory',
  'typopro-web-TypoPRO-GrandHotel',
  'typopro-web-TypoPRO-GreatVibes',
  'typopro-web-TypoPRO-Handlee',
  'typopro-web-TypoPRO-HHSamuel',
  'typopro-web-TypoPRO-Inconsolata',
  'typopro-web-TypoPRO-IndieFlower',
  'typopro-web-TypoPRO-Junction',
  'typopro-web-TypoPRO-Kalam',
  'typopro-web-TypoPRO-KingthingsPetrock',
  'typopro-web-TypoPRO-Kreon',
  'typopro-web-TypoPRO-LeagueGothic',
  'typopro-web-TypoPRO-Lekton',
  'typopro-web-TypoPRO-LibreBaskerville',
  'typopro-web-TypoPRO-Milonga',
  'typopro-web-TypoPRO-Montserrat',
  'typopro-web-TypoPRO-Nickainley',
  'typopro-web-TypoPRO-Oxygen',
  'typopro-web-TypoPRO-Pacifico',
  'typopro-web-TypoPRO-PatuaOne',
  'typopro-web-TypoPRO-Poetsen',
  'typopro-web-TypoPRO-Pompiere',
  'typopro-web-TypoPRO-PTMono',
  'typopro-web-TypoPRO-Rosario',
  'typopro-web-TypoPRO-SansitaOne',
  'typopro-web-TypoPRO-Satisfy',
  'typopro-web-TypoPRO-Signika',
  'typopro-web-TypoPRO-Slabo',
  'typopro-web-TypoPRO-TopSecret',
  'typopro-web-TypoPRO-Unifraktur',
  'typopro-web-TypoPRO-Vegur',
  'typopro-web-TypoPRO-VeteranTypewriter',
  'typopro-web-TypoPRO-WeblySleek',
  'typopro-web-TypoPRO-Yellowtail',
  'Ubertesters',
  'Ubi',
  'UbibotSensor',
  'UbidotsMoscaServer',
  'UbiName',
  'uDom',
  'ueberDB',
  'ueberDB-couch',
  'ueberRemoteStorage',
  'ugcFore',
  'UIjson',
  'UkGeoTool',
  'UltraServerIO',
  'UM007',
  'uMech',
  'uMicro',
  'uMicro-invoke',
  'UMiracleButton',
  'uncaughtException',
  'Underscore-1',
  'UnderscoreKit',
  'UnderscoreMatchersForJasmine',
  'underscorePlus',
  'underscoreWithTypings',
  'Uniform',
  'Unit-Bezier',
  'unity-kjXmol-1',
  'UniversalRoute',
  'Up2Bucket',
  'UParams',
  'UploadCore',
  'Uploader',
  'URIjs',
  'url',
  'URLON',
  'urlParser',
  'urlWatch',
  'USAJOBS',
  'USAJOBS_Help_Center',
  'UserID',
  'userModule1123455',
  'util',
  'utilityFileSystem',
  'utilityTool',
  'Utils',
  'uTool',
  'uTool2',
  'uvCharts',
  'v8',
  'Validate',
  'Validator',
  'VardeminChat',
  'vc-buttonGroup',
  'vcPagination',
  'vdGlslCanvas',
  'VDU-web',
  'Vector',
  'Velvet',
  'vericredClient',
  'VerifyInput.js',
  'Videobox-MODX',
  'videoBoxer',
  'VideoStream',
  'Vidzy',
  'ViewAbility',
  'ViewPort',
  'ViewTest',
  'vintageJS',
  'Virsical',
  'VK-Promise',
  'VLC-command',
  'vm',
  'VmosoApiClient',
  'vmSFTP',
  'VoiceIt',
  'voiceLive',
  'Votesy',
  'VoxFeed',
  'Voyager-search',
  'vPromise',
  'vQ',
  'vQMgArq1o4U1',
  'vsGoogleAutocomplete',
  'vue-dS',
  'vue-scrollTo',
  'vueLoadingBar',
  'VueProject',
  'VueProjectES5',
  'VueTree',
  'Vuk',
  'W2G2',
  'w5cValidator',
  'w11k-dropdownToggle',
  'Wamble',
  'wamTool',
  'Wanderer',
  'wangeditorForReact',
  'wantu-nodejsSDK',
  'wasabiD',
  'wasabiH',
  'wasi',
  'WasteOfTime',
  'WatchWorker',
  'watsonWebSocketSTTwrapper',
  'wb-Wisteria',
  'wBitmask',
  'wColor',
  'wColor256',
  'wConsequence',
  'wCopyable',
  'WCordova',
  'wDeployer',
  'Web_GUI_Core',
  'web3.onChange',
  'Web4.0',
  'webarrancoStarter',
  'WebConsoleUI',
  'Webcord',
  'webdriverNode',
  'webext-getBytesInUse-polyfill',
  'WebHook',
  'WebODF',
  'webpack-dev-server-getApp',
  'webpack-dynamicHash',
  'webpack-Minimount-starter',
  'WebParrot',
  'webpay-webserviceAPI',
  'webStart',
  'WebStencil',
  'webStorage',
  'wechat-enterprise-for-kfService',
  'wEventHandler',
  'wFiles',
  'wGluCal',
  'WhereThingsHappened',
  'WhiteRabbit',
  'WigGLe',
  'Wilson_U',
  'Wilson_Util',
  'WiredPanels',
  'wkhtmltopdfWrapper',
  'wLogger',
  'Wmhao',
  'WNdb',
  'WoD-Dice',
  'WolfyEventEmitter',
  'woodwoodnine_FirstTest',
  'wordCounting',
  'WordDuelConstants',
  'wPath',
  'wProto',
  'wqProj-cli',
  'wRegexpObject',
  'WSBroker',
  'wscn-tilesetQuote-component',
  'wsxRest',
  'wTemplate',
  'wTesting',
  'WTGeo',
  'wTools',
  'wy-checkBrowser',
  'X-date',
  'X-editable',
  'xBEM',
  'xlsTjson',
  'xlsxParser',
  'xmlToJsonTs',
  'Xnpmtools',
  'xSpinner',
  'xStore',
  'xui-vue-WorkflowArrow',
  'Xunfei',
  'xuNpm',
  'XWindow',
  'xwjApp',
  'xxxDemo',
  'yaDeferred',
  'YAEventEmitter',
  'yaMap',
  'yamQuery-excel',
  'yamQuery-excelAnalizer',
  'YamYam',
  'yang-testingNPM',
  'YaoXiaoMi',
  'Yeezy-Case',
  'Yggdrasil',
  'YJS',
  'YmpleCommerce',
  'YouAreDaChef',
  'YouSlackBot',
  'yrdLmz',
  'yuanMath',
  'YuicompressorValidator',
  'Yummy',
  'Yummy-Yummy',
  'YunUI',
  'Yworkcli',
  'Yworkshell',
  'z-lib-structure-dqIndex',
  'zhb_helloTest',
  'Zhengzx',
  'zigZag',
  'Ziz',
  'ZJJPackage',
  'zkModules',
  'zlib',
  'zmqConnector',
  'ZooKeeper',
  'zzcBridge',
  'zzcCopy',
  'zzcDownloadApp'
]

let hasRequiredPurlType
function requirePurlType() {
  if (hasRequiredPurlType) {
    return purlType.exports
  }
  hasRequiredPurlType = 1
  ;(function (module) {
    const { encodeComponent } = /*@__PURE__*/ requireEncode()
    const { PurlError } = /*@__PURE__*/ requireError$2()
    const { createHelpersNamespaceObject } = /*@__PURE__*/ requireHelpers()
    const { isNullishOrEmptyString } = /*@__PURE__*/ requireLang()
    const {
      isSemverString,
      lowerName,
      lowerNamespace,
      lowerVersion,
      replaceDashesWithUnderscores,
      replaceUnderscoresWithDashes
    } = /*@__PURE__*/ requireStrings()
    const { validateEmptyByType, validateRequiredByType } =
      /*@__PURE__*/ requireValidate()
    const PurlTypNormalizer = purl => purl
    const PurlTypeValidator = (_purl, _throws) => true
    const getNpmBuiltinNames = (() => {
      let builtinNames
      return () => {
        if (builtinNames === undefined) {
          builtinNames =
            // Avoid a require('node:module') call directly so folks can bundle
            // for the browser without issues.
            (module !== null && module.constructor?.builtinModules) ||
            require$$6
        }
        return builtinNames
      }
    })()
    const getNpmLegacyNames = (() => {
      let legacyNames
      return () => {
        if (legacyNames === undefined) {
          legacyNames = require$$7
        }
        return legacyNames
      }
    })()
    function getNpmId(purl) {
      const { name, namespace } = purl
      return `${namespace?.length > 0 ? `${namespace}/` : ''}${name}`
    }
    const isNpmBuiltinName = id =>
      getNpmBuiltinNames().includes(id.toLowerCase())
    const isNpmLegacyName = id => getNpmLegacyNames().includes(id)
    module.exports = {
      // PURL types:
      // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst
      PurlType: createHelpersNamespaceObject(
        {
          normalize: {
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#alpm
            alpm(purl) {
              lowerNamespace(purl)
              lowerName(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#apk
            apk(purl) {
              lowerNamespace(purl)
              lowerName(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#bitbucket
            bitbucket(purl) {
              lowerNamespace(purl)
              lowerName(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#bitnami
            bitnami(purl) {
              lowerName(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#composer
            composer(purl) {
              lowerNamespace(purl)
              lowerName(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#deb
            deb(purl) {
              lowerNamespace(purl)
              lowerName(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#other-candidate-types-to-define
            gitlab(purl) {
              lowerNamespace(purl)
              lowerName(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#github
            github(purl) {
              lowerNamespace(purl)
              lowerName(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#golang
            // golang(purl) {
            //     // Ignore case-insensitive rule because go.mod are case-sensitive.
            //     // Pending spec change: https://github.com/package-url/purl-spec/pull/196
            //     lowerNamespace(purl)
            //     lowerName(purl)
            //     return purl
            // },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#hex
            hex(purl) {
              lowerNamespace(purl)
              lowerName(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#huggingface
            huggingface(purl) {
              lowerVersion(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#mlflow
            mlflow(purl) {
              if (purl.qualifiers?.repository_url?.includes('databricks')) {
                lowerName(purl)
              }
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#npm
            npm(purl) {
              lowerNamespace(purl)
              // Ignore lowercasing legacy names because they could be mixed case.
              // https://github.com/npm/validate-npm-package-name/tree/v6.0.0?tab=readme-ov-file#legacy-names
              if (!isNpmLegacyName(getNpmId(purl))) {
                lowerName(purl)
              }
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#luarocks
            luarocks(purl) {
              lowerVersion(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#oci
            oci(purl) {
              lowerName(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#pub
            pub(purl) {
              lowerName(purl)
              purl.name = replaceDashesWithUnderscores(purl.name)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#pypi
            pypi(purl) {
              lowerNamespace(purl)
              lowerName(purl)
              purl.name = replaceUnderscoresWithDashes(purl.name)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#qpkg
            qpkg(purl) {
              lowerNamespace(purl)
              return purl
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#rpm
            rpm(purl) {
              lowerNamespace(purl)
              return purl
            }
          },
          validate: {
            // TODO: cocoapods name validation
            // TODO: cpan namespace validation
            // TODO: swid qualifier validation
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#conan
            conan(purl, throws) {
              if (isNullishOrEmptyString(purl.namespace)) {
                if (purl.qualifiers?.channel) {
                  if (throws) {
                    throw new PurlError(
                      'conan requires a "namespace" component when a "channel" qualifier is present'
                    )
                  }
                  return false
                }
              } else if (isNullishOrEmptyString(purl.qualifiers)) {
                if (throws) {
                  throw new PurlError(
                    'conan requires a "qualifiers" component when a namespace is present'
                  )
                }
                return false
              }
              return true
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#cran
            cran(purl, throws) {
              return validateRequiredByType(
                'cran',
                'version',
                purl.version,
                throws
              )
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#golang
            golang(purl, throws) {
              // Still being lenient here since the standard changes aren't official.
              // Pending spec change: https://github.com/package-url/purl-spec/pull/196
              const { version } = purl
              const length = typeof version === 'string' ? version.length : 0
              // If the version starts with a "v" then ensure its a valid semver version.
              // This, by semver semantics, also supports pseudo-version number.
              // https://go.dev/doc/modules/version-numbers#pseudo-version-number
              if (
                length &&
                version.charCodeAt(0) === 118 /*'v'*/ &&
                !isSemverString(version.slice(1))
              ) {
                if (throws) {
                  throw new PurlError(
                    'golang "version" component starting with a "v" must be followed by a valid semver version'
                  )
                }
                return false
              }
              return true
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#maven
            maven(purl, throws) {
              return validateRequiredByType(
                'maven',
                'namespace',
                purl.namespace,
                throws
              )
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#mlflow
            mlflow(purl, throws) {
              return validateEmptyByType(
                'mlflow',
                'namespace',
                purl.namespace,
                throws
              )
            },
            // Validation based on
            // https://github.com/npm/validate-npm-package-name/tree/v6.0.0
            // ISC License
            // Copyright (c) 2015, npm, Inc
            npm(purl, throws) {
              const { name, namespace } = purl
              const hasNs = namespace?.length > 0
              const id = getNpmId(purl)
              const code0 = id.charCodeAt(0)
              const compName = hasNs ? 'namespace' : 'name'
              if (code0 === 46 /*'.'*/) {
                if (throws) {
                  throw new PurlError(
                    `npm "${compName}" component cannot start with a period`
                  )
                }
                return false
              }
              if (code0 === 95 /*'_'*/) {
                if (throws) {
                  throw new PurlError(
                    `npm "${compName}" component cannot start with an underscore`
                  )
                }
                return false
              }
              if (name.trim() !== name) {
                if (throws) {
                  throw new PurlError(
                    'npm "name" component cannot contain leading or trailing spaces'
                  )
                }
                return false
              }
              if (encodeComponent(name) !== name) {
                if (throws) {
                  throw new PurlError(
                    `npm "name" component can only contain URL-friendly characters`
                  )
                }
                return false
              }
              if (hasNs) {
                if (namespace.trim() !== namespace) {
                  if (throws) {
                    throw new PurlError(
                      'npm "namespace" component cannot contain leading or trailing spaces'
                    )
                  }
                  return false
                }
                if (code0 !== 64 /*'@'*/) {
                  throw new PurlError(
                    `npm "namespace" component must start with an "@" character`
                  )
                }
                const namespaceWithoutAtSign = namespace.slice(1)
                if (
                  encodeComponent(namespaceWithoutAtSign) !==
                  namespaceWithoutAtSign
                ) {
                  if (throws) {
                    throw new PurlError(
                      `npm "namespace" component can only contain URL-friendly characters`
                    )
                  }
                  return false
                }
              }
              const loweredId = id.toLowerCase()
              if (loweredId === 'node_modules' || loweredId === 'favicon.ico') {
                if (throws) {
                  throw new PurlError(
                    `npm "${compName}" component of "${loweredId}" is not allowed`
                  )
                }
                return false
              }
              // The remaining checks are only for modern names.
              // https://github.com/npm/validate-npm-package-name/tree/v6.0.0?tab=readme-ov-file#naming-rules
              if (!isNpmLegacyName(id)) {
                if (id.length > 214) {
                  if (throws) {
                    throw new PurlError(
                      `npm "namespace" and "name" components can not collectively be more than 214 characters`
                    )
                  }
                  return false
                }
                if (loweredId !== id) {
                  if (throws) {
                    throw new PurlError(
                      `npm "name" component can not contain capital letters`
                    )
                  }
                  return false
                }
                if (/[~'!()*]/.test(name)) {
                  if (throws) {
                    throw new PurlError(
                      `npm "name" component can not contain special characters ("~'!()*")`
                    )
                  }
                  return false
                }
                if (isNpmBuiltinName(id)) {
                  if (throws) {
                    throw new PurlError(
                      'npm "name" component can not be a core module name'
                    )
                  }
                  return false
                }
              }
              return true
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#oci
            oci(purl, throws) {
              return validateEmptyByType(
                'oci',
                'namespace',
                purl.namespace,
                throws
              )
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#pub
            pub(purl, throws) {
              const { name } = purl
              for (let i = 0, { length } = name; i < length; i += 1) {
                const code = name.charCodeAt(i)
                // biome-ignore format:
                if (!(code >= 48 && code <= 57 ||
              // 0-9
              code >= 97 && code <= 122 ||
              // a-z
              code === 95 // _
              )) {
                if (throws) {
                  throw new PurlError('pub "name" component may only contain [a-z0-9_] characters');
                }
                return false;
              }
              }
              return true
            },
            // https://github.com/package-url/purl-spec/blob/master/PURL-TYPES.rst#swift
            swift(purl, throws) {
              return (
                validateRequiredByType(
                  'swift',
                  'namespace',
                  purl.namespace,
                  throws
                ) &&
                validateRequiredByType('swift', 'version', purl.version, throws)
              )
            }
          }
        },
        {
          normalize: PurlTypNormalizer,
          validate: PurlTypeValidator
        }
      )
    }
  })(purlType)
  return purlType.exports
}

/*!
Copyright (c) the purl authors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
*/
let packageUrl
let hasRequiredPackageUrl
function requirePackageUrl() {
  if (hasRequiredPackageUrl) {
    return packageUrl
  }
  hasRequiredPackageUrl = 1
  const { decodePurlComponent } = /*@__PURE__*/ requireDecode()
  const { PurlError } = /*@__PURE__*/ requireError$2()
  const { isObject, recursiveFreeze } = /*@__PURE__*/ requireObjects()
  const { PurlComponent } = /*@__PURE__*/ requirePurlComponent()
  const { PurlQualifierNames } = /*@__PURE__*/ requirePurlQualifierNames()
  const { PurlType } = /*@__PURE__*/ requirePurlType()
  const { isBlank, isNonEmptyString, trimLeadingSlashes } =
    /*@__PURE__*/ requireStrings()
  class PackageURL {
    static Component = recursiveFreeze(PurlComponent)
    static KnownQualifierNames = recursiveFreeze(PurlQualifierNames)
    static Type = recursiveFreeze(PurlType)
    constructor(
      rawType,
      rawNamespace,
      rawName,
      rawVersion,
      rawQualifiers,
      rawSubpath
    ) {
      const type = isNonEmptyString(rawType)
        ? PurlComponent.type.normalize(rawType)
        : rawType
      PurlComponent.type.validate(type, true)
      const namespace = isNonEmptyString(rawNamespace)
        ? PurlComponent.namespace.normalize(rawNamespace)
        : rawNamespace
      PurlComponent.namespace.validate(namespace, true)
      const name = isNonEmptyString(rawName)
        ? PurlComponent.name.normalize(rawName)
        : rawName
      PurlComponent.name.validate(name, true)
      const version = isNonEmptyString(rawVersion)
        ? PurlComponent.version.normalize(rawVersion)
        : rawVersion
      PurlComponent.version.validate(version, true)
      const qualifiers =
        typeof rawQualifiers === 'string' || isObject(rawQualifiers)
          ? PurlComponent.qualifiers.normalize(rawQualifiers)
          : rawQualifiers
      PurlComponent.qualifiers.validate(qualifiers, true)
      const subpath = isNonEmptyString(rawSubpath)
        ? PurlComponent.subpath.normalize(rawSubpath)
        : rawSubpath
      PurlComponent.subpath.validate(subpath, true)
      this.type = type
      this.name = name
      this.namespace = namespace ?? undefined
      this.version = version ?? undefined
      this.qualifiers = qualifiers ?? undefined
      this.subpath = subpath ?? undefined
      const typeHelpers = PurlType[type]
      if (typeHelpers) {
        typeHelpers.normalize(this)
        typeHelpers.validate(this, true)
      }
    }
    toString() {
      const { name, namespace, qualifiers, subpath, type, version } = this
      let purlStr = `pkg:${PurlComponent.type.encode(type)}/`
      if (namespace) {
        purlStr = `${purlStr}${PurlComponent.namespace.encode(namespace)}/`
      }
      purlStr = `${purlStr}${PurlComponent.name.encode(name)}`
      if (version) {
        purlStr = `${purlStr}@${PurlComponent.version.encode(version)}`
      }
      if (qualifiers) {
        purlStr = `${purlStr}?${PurlComponent.qualifiers.encode(qualifiers)}`
      }
      if (subpath) {
        purlStr = `${purlStr}#${PurlComponent.subpath.encode(subpath)}`
      }
      return purlStr
    }
    static fromString(purlStr) {
      return new PackageURL(...PackageURL.parseString(purlStr))
    }
    static parseString(purlStr) {
      // https://github.com/package-url/purl-spec/blob/master/PURL-SPECIFICATION.rst#how-to-parse-a-purl-string-in-its-components
      if (typeof purlStr !== 'string') {
        throw new Error('A purl string argument is required.')
      }
      if (isBlank(purlStr)) {
        return [
          undefined,
          undefined,
          undefined,
          undefined,
          undefined,
          undefined
        ]
      }

      // Split the remainder once from left on ':'.
      const colonIndex = purlStr.indexOf(':')
      // Use WHATWG URL to split up the purl string.
      //   - Split the purl string once from right on '#'
      //   - Split the remainder once from right on '?'
      //   - Split the remainder once from left on ':'
      let url
      let maybeUrlWithAuth
      if (colonIndex !== -1) {
        try {
          // Since a purl never contains a URL Authority, its scheme
          // must not be suffixed with double slash as in 'pkg://'
          // and should use instead 'pkg:'. Purl parsers must accept
          // URLs such as 'pkg://' and must ignore the '//'
          const beforeColon = purlStr.slice(0, colonIndex)
          const afterColon = purlStr.slice(colonIndex + 1)
          const trimmedAfterColon = trimLeadingSlashes(afterColon)
          url = new URL(`${beforeColon}:${trimmedAfterColon}`)
          maybeUrlWithAuth =
            afterColon.length === trimmedAfterColon.length
              ? url
              : new URL(purlStr)
        } catch (e) {
          throw new PurlError('failed to parse as URL', {
            cause: e
          })
        }
      }
      // The scheme is a constant with the value "pkg".
      if (url?.protocol !== 'pkg:') {
        throw new PurlError('missing required "pkg" scheme component')
      }
      // A purl must NOT contain a URL Authority i.e. there is no support for
      // username, password, host and port components.
      if (
        maybeUrlWithAuth.username !== '' ||
        maybeUrlWithAuth.password !== ''
      ) {
        throw new PurlError('cannot contain a "user:pass@host:port"')
      }
      const { pathname } = url
      const firstSlashIndex = pathname.indexOf('/')
      const rawType = decodePurlComponent(
        'type',
        firstSlashIndex === -1 ? pathname : pathname.slice(0, firstSlashIndex)
      )
      if (firstSlashIndex < 1) {
        return [rawType, undefined, undefined, undefined, undefined, undefined]
      }
      let rawVersion
      let atSignIndex =
        rawType === 'npm'
          ? // Deviate from the specification to handle a special npm purl type case for
            // pnpm ids such as 'pkg:npm/next@14.2.10(react-dom@18.3.1(react@18.3.1))(react@18.3.1)'.
            pathname.indexOf('@', firstSlashIndex + 2)
          : pathname.lastIndexOf('@')
      // When a forward slash ('/') is directly preceding an '@' symbol,
      // then the '@' symbol is NOT considered a version separator.
      if (
        atSignIndex !== -1 &&
        pathname.charCodeAt(atSignIndex - 1) === 47 /*'/'*/
      ) {
        atSignIndex = -1
      }
      const beforeVersion = pathname.slice(
        rawType.length + 1,
        atSignIndex === -1 ? pathname.length : atSignIndex
      )
      if (atSignIndex !== -1) {
        // Split the remainder once from right on '@'.
        rawVersion = decodePurlComponent(
          'version',
          pathname.slice(atSignIndex + 1)
        )
      }
      let rawNamespace
      let rawName
      const lastSlashIndex = beforeVersion.lastIndexOf('/')
      if (lastSlashIndex === -1) {
        // Split the remainder once from right on '/'.
        rawName = decodePurlComponent('name', beforeVersion)
      } else {
        // Split the remainder once from right on '/'.
        rawName = decodePurlComponent(
          'name',
          beforeVersion.slice(lastSlashIndex + 1)
        )
        // Split the remainder on '/'.
        rawNamespace = decodePurlComponent(
          'namespace',
          beforeVersion.slice(0, lastSlashIndex)
        )
      }
      let rawQualifiers
      const { searchParams } = url
      if (searchParams.size !== 0) {
        searchParams.forEach(value => decodePurlComponent('qualifiers', value))
        // Split the remainder once from right on '?'.
        rawQualifiers = searchParams
      }
      let rawSubpath
      const { hash } = url
      if (hash.length !== 0) {
        // Split the purl string once from right on '#'.
        rawSubpath = decodePurlComponent('subpath', hash.slice(1))
      }
      return [
        rawType,
        rawNamespace,
        rawName,
        rawVersion,
        rawQualifiers,
        rawSubpath
      ]
    }
  }
  for (const staticProp of ['Component', 'KnownQualifierNames', 'Type']) {
    Reflect.defineProperty(PackageURL, staticProp, {
      ...Reflect.getOwnPropertyDescriptor(PackageURL, staticProp),
      writable: false
    })
  }
  Reflect.setPrototypeOf(PackageURL.prototype, null)
  packageUrl = {
    PackageURL,
    PurlComponent,
    PurlQualifierNames,
    PurlType
  }
  return packageUrl
}

/*!
Copyright (c) the purl authors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
*/
let packageurlJs
let hasRequiredPackageurlJs
function requirePackageurlJs() {
  if (hasRequiredPackageurlJs) {
    return packageurlJs
  }
  hasRequiredPackageurlJs = 1
  const { PackageURL, PurlComponent, PurlQualifierNames, PurlType } =
    /*@__PURE__*/ requirePackageUrl()
  packageurlJs = {
    PackageURL,
    PurlComponent,
    PurlQualifierNames,
    PurlType
  }
  return packageurlJs
}

const packageurlJsExports = /*@__PURE__*/ requirePackageurlJs()

function getUserAgent() {
  if (typeof navigator === 'object' && 'userAgent' in navigator) {
    return navigator.userAgent
  }
  if (typeof process === 'object' && process.version !== undefined) {
    return `Node.js/${process.version.substr(1)} (${process.platform}; ${process.arch})`
  }
  return '<environment undetectable>'
}

// pkg/dist-src/defaults.js

// pkg/dist-src/version.js
const VERSION$7 = '0.0.0-development'

// pkg/dist-src/defaults.js
const userAgent = `octokit-endpoint.js/${VERSION$7} ${getUserAgent()}`
const DEFAULTS = {
  method: 'GET',
  baseUrl: 'https://api.github.com',
  headers: {
    accept: 'application/vnd.github.v3+json',
    'user-agent': userAgent
  },
  mediaType: {
    format: ''
  }
}

// pkg/dist-src/util/lowercase-keys.js
function lowercaseKeys(object) {
  if (!object) {
    return {}
  }
  return Object.keys(object).reduce((newObj, key) => {
    newObj[key.toLowerCase()] = object[key]
    return newObj
  }, {})
}

// pkg/dist-src/util/is-plain-object.js
function isPlainObject$1(value) {
  if (typeof value !== 'object' || value === null) {
    return false
  }
  if (Object.prototype.toString.call(value) !== '[object Object]') {
    return false
  }
  const proto = Object.getPrototypeOf(value)
  if (proto === null) {
    return true
  }
  const Ctor =
    Object.prototype.hasOwnProperty.call(proto, 'constructor') &&
    proto.constructor
  return (
    typeof Ctor === 'function' &&
    Ctor instanceof Ctor &&
    Function.prototype.call(Ctor) === Function.prototype.call(value)
  )
}

// pkg/dist-src/util/merge-deep.js
function mergeDeep(defaults, options) {
  const result = Object.assign({}, defaults)
  Object.keys(options).forEach(key => {
    if (isPlainObject$1(options[key])) {
      if (!(key in defaults)) {
        Object.assign(result, {
          [key]: options[key]
        })
      } else {
        result[key] = mergeDeep(defaults[key], options[key])
      }
    } else {
      Object.assign(result, {
        [key]: options[key]
      })
    }
  })
  return result
}

// pkg/dist-src/util/remove-undefined-properties.js
function removeUndefinedProperties(obj) {
  for (const key in obj) {
    if (obj[key] === void 0) {
      delete obj[key]
    }
  }
  return obj
}

// pkg/dist-src/merge.js
function merge$1(defaults, route, options) {
  if (typeof route === 'string') {
    let [method, url] = route.split(' ')
    options = Object.assign(
      url
        ? {
            method,
            url
          }
        : {
            url: method
          },
      options
    )
  } else {
    options = Object.assign({}, route)
  }
  options.headers = lowercaseKeys(options.headers)
  removeUndefinedProperties(options)
  removeUndefinedProperties(options.headers)
  const mergedOptions = mergeDeep(defaults || {}, options)
  if (options.url === '/graphql') {
    if (defaults && defaults.mediaType.previews?.length) {
      mergedOptions.mediaType.previews = defaults.mediaType.previews
        .filter(preview => !mergedOptions.mediaType.previews.includes(preview))
        .concat(mergedOptions.mediaType.previews)
    }
    mergedOptions.mediaType.previews = (
      mergedOptions.mediaType.previews || []
    ).map(preview => preview.replace(/-preview/, ''))
  }
  return mergedOptions
}

// pkg/dist-src/util/add-query-parameters.js
function addQueryParameters(url, parameters) {
  const separator = /\?/.test(url) ? '&' : '?'
  const names = Object.keys(parameters)
  if (names.length === 0) {
    return url
  }
  return (
    url +
    separator +
    names
      .map(name => {
        if (name === 'q') {
          return (
            'q=' + parameters.q.split('+').map(encodeURIComponent).join('+')
          )
        }
        return `${name}=${encodeURIComponent(parameters[name])}`
      })
      .join('&')
  )
}

// pkg/dist-src/util/extract-url-variable-names.js
const urlVariableRegex = /\{[^{}}]+\}/g
function removeNonChars(variableName) {
  return variableName.replace(/(?:^\W+)|(?:(?<!\W)\W+$)/g, '').split(/,/)
}
function extractUrlVariableNames(url) {
  const matches = url.match(urlVariableRegex)
  if (!matches) {
    return []
  }
  return matches.map(removeNonChars).reduce((a, b) => a.concat(b), [])
}

// pkg/dist-src/util/omit.js
function omit(object, keysToOmit) {
  const result = {
    __proto__: null
  }
  for (const key of Object.keys(object)) {
    if (keysToOmit.indexOf(key) === -1) {
      result[key] = object[key]
    }
  }
  return result
}

// pkg/dist-src/util/url-template.js
function encodeReserved(str) {
  return str
    .split(/(%[0-9A-Fa-f]{2})/g)
    .map(function (part) {
      if (!/%[0-9A-Fa-f]/.test(part)) {
        part = encodeURI(part).replace(/%5B/g, '[').replace(/%5D/g, ']')
      }
      return part
    })
    .join('')
}
function encodeUnreserved(str) {
  return encodeURIComponent(str).replace(/[!'()*]/g, function (c) {
    return '%' + c.charCodeAt(0).toString(16).toUpperCase()
  })
}
function encodeValue(operator, value, key) {
  value =
    operator === '+' || operator === '#'
      ? encodeReserved(value)
      : encodeUnreserved(value)
  if (key) {
    return encodeUnreserved(key) + '=' + value
  } else {
    return value
  }
}
function isDefined(value) {
  return value !== void 0 && value !== null
}
function isKeyOperator(operator) {
  return operator === ';' || operator === '&' || operator === '?'
}
function getValues(context, operator, key, modifier) {
  let value = context[key],
    result = []
  if (isDefined(value) && value !== '') {
    if (
      typeof value === 'string' ||
      typeof value === 'number' ||
      typeof value === 'boolean'
    ) {
      value = value.toString()
      if (modifier && modifier !== '*') {
        value = value.substring(0, parseInt(modifier, 10))
      }
      result.push(
        encodeValue(operator, value, isKeyOperator(operator) ? key : '')
      )
    } else {
      if (modifier === '*') {
        if (Array.isArray(value)) {
          value.filter(isDefined).forEach(function (value2) {
            result.push(
              encodeValue(operator, value2, isKeyOperator(operator) ? key : '')
            )
          })
        } else {
          Object.keys(value).forEach(function (k) {
            if (isDefined(value[k])) {
              result.push(encodeValue(operator, value[k], k))
            }
          })
        }
      } else {
        const tmp = []
        if (Array.isArray(value)) {
          value.filter(isDefined).forEach(function (value2) {
            tmp.push(encodeValue(operator, value2))
          })
        } else {
          Object.keys(value).forEach(function (k) {
            if (isDefined(value[k])) {
              tmp.push(encodeUnreserved(k))
              tmp.push(encodeValue(operator, value[k].toString()))
            }
          })
        }
        if (isKeyOperator(operator)) {
          result.push(encodeUnreserved(key) + '=' + tmp.join(','))
        } else if (tmp.length !== 0) {
          result.push(tmp.join(','))
        }
      }
    }
  } else {
    if (operator === ';') {
      if (isDefined(value)) {
        result.push(encodeUnreserved(key))
      }
    } else if (value === '' && (operator === '&' || operator === '?')) {
      result.push(encodeUnreserved(key) + '=')
    } else if (value === '') {
      result.push('')
    }
  }
  return result
}
function parseUrl$1(template) {
  return {
    expand: expand.bind(null, template)
  }
}
function expand(template, context) {
  const operators = ['+', '#', '.', '/', ';', '?', '&']
  template = template.replace(
    /\{([^{}]+)\}|([^{}]+)/g,
    function (_, expression, literal) {
      if (expression) {
        let operator = ''
        const values = []
        if (operators.indexOf(expression.charAt(0)) !== -1) {
          operator = expression.charAt(0)
          expression = expression.substr(1)
        }
        expression.split(/,/g).forEach(function (variable) {
          const tmp = /([^:*]*)(?::(\d+)|(\*))?/.exec(variable)
          values.push(getValues(context, operator, tmp[1], tmp[2] || tmp[3]))
        })
        if (operator && operator !== '+') {
          let separator = ','
          if (operator === '?') {
            separator = '&'
          } else if (operator !== '#') {
            separator = operator
          }
          return (values.length !== 0 ? operator : '') + values.join(separator)
        } else {
          return values.join(',')
        }
      } else {
        return encodeReserved(literal)
      }
    }
  )
  if (template === '/') {
    return template
  } else {
    return template.replace(/\/$/, '')
  }
}

// pkg/dist-src/parse.js
function parse$1(options) {
  let method = options.method.toUpperCase()
  let url = (options.url || '/').replace(/:([a-z]\w+)/g, '{$1}')
  let headers = Object.assign({}, options.headers)
  let body
  let parameters = omit(options, [
    'method',
    'baseUrl',
    'url',
    'headers',
    'request',
    'mediaType'
  ])
  const urlVariableNames = extractUrlVariableNames(url)
  url = parseUrl$1(url).expand(parameters)
  if (!/^http/.test(url)) {
    url = options.baseUrl + url
  }
  const omittedParameters = Object.keys(options)
    .filter(option => urlVariableNames.includes(option))
    .concat('baseUrl')
  const remainingParameters = omit(parameters, omittedParameters)
  const isBinaryRequest = /application\/octet-stream/i.test(headers.accept)
  if (!isBinaryRequest) {
    if (options.mediaType.format) {
      headers.accept = headers.accept
        .split(/,/)
        .map(format =>
          format.replace(
            /application\/vnd(\.\w+)(\.v3)?(\.\w+)?(\+json)?$/,
            `application/vnd$1$2.${options.mediaType.format}`
          )
        )
        .join(',')
    }
    if (url.endsWith('/graphql')) {
      if (options.mediaType.previews?.length) {
        const previewsFromAcceptHeader =
          headers.accept.match(/(?<![\w-])[\w-]+(?=-preview)/g) || []
        headers.accept = previewsFromAcceptHeader
          .concat(options.mediaType.previews)
          .map(preview => {
            const format = options.mediaType.format
              ? `.${options.mediaType.format}`
              : '+json'
            return `application/vnd.github.${preview}-preview${format}`
          })
          .join(',')
      }
    }
  }
  if (['GET', 'HEAD'].includes(method)) {
    url = addQueryParameters(url, remainingParameters)
  } else {
    if ('data' in remainingParameters) {
      body = remainingParameters.data
    } else {
      if (Object.keys(remainingParameters).length) {
        body = remainingParameters
      }
    }
  }
  if (!headers['content-type'] && typeof body !== 'undefined') {
    headers['content-type'] = 'application/json; charset=utf-8'
  }
  if (['PATCH', 'PUT'].includes(method) && typeof body === 'undefined') {
    body = ''
  }
  return Object.assign(
    {
      method,
      url,
      headers
    },
    typeof body !== 'undefined'
      ? {
          body
        }
      : null,
    options.request
      ? {
          request: options.request
        }
      : null
  )
}

// pkg/dist-src/endpoint-with-defaults.js
function endpointWithDefaults(defaults, route, options) {
  return parse$1(merge$1(defaults, route, options))
}

// pkg/dist-src/with-defaults.js
function withDefaults$2(oldDefaults, newDefaults) {
  const DEFAULTS2 = merge$1(oldDefaults, newDefaults)
  const endpoint2 = endpointWithDefaults.bind(null, DEFAULTS2)
  return Object.assign(endpoint2, {
    DEFAULTS: DEFAULTS2,
    defaults: withDefaults$2.bind(null, DEFAULTS2),
    merge: merge$1.bind(null, DEFAULTS2),
    parse: parse$1
  })
}

// pkg/dist-src/index.js
const endpoint = withDefaults$2(null, DEFAULTS)

const fastContentTypeParse = {}

let hasRequiredFastContentTypeParse
function requireFastContentTypeParse() {
  if (hasRequiredFastContentTypeParse) {
    return fastContentTypeParse
  }
  hasRequiredFastContentTypeParse = 1
  const NullObject = function NullObject() {}
  NullObject.prototype = Object.create(null)

  /**
   * RegExp to match *( ";" parameter ) in RFC 7231 sec 3.1.1.1
   *
   * parameter     = token "=" ( token / quoted-string )
   * token         = 1*tchar
   * tchar         = "!" / "#" / "$" / "%" / "&" / "'" / "*"
   *               / "+" / "-" / "." / "^" / "_" / "`" / "|" / "~"
   *               / DIGIT / ALPHA
   *               ; any VCHAR, except delimiters
   * quoted-string = DQUOTE *( qdtext / quoted-pair ) DQUOTE
   * qdtext        = HTAB / SP / %x21 / %x23-5B / %x5D-7E / obs-text
   * obs-text      = %x80-FF
   * quoted-pair   = "\" ( HTAB / SP / VCHAR / obs-text )
   */
  const paramRE =
    /; *([!#$%&'*+.^\w`|~-]+)=("(?:[\v\u0020\u0021\u0023-\u005b\u005d-\u007e\u0080-\u00ff]|\\[\v\u0020-\u00ff])*"|[!#$%&'*+.^\w`|~-]+) */gu

  /**
   * RegExp to match quoted-pair in RFC 7230 sec 3.2.6
   *
   * quoted-pair = "\" ( HTAB / SP / VCHAR / obs-text )
   * obs-text    = %x80-FF
   */
  const quotedPairRE = /\\([\v\u0020-\u00ff])/gu

  /**
   * RegExp to match type in RFC 7231 sec 3.1.1.1
   *
   * media-type = type "/" subtype
   * type       = token
   * subtype    = token
   */
  const mediaTypeRE = /^[!#$%&'*+.^\w|~-]+\/[!#$%&'*+.^\w|~-]+$/u

  // default ContentType to prevent repeated object creation
  const defaultContentType = {
    type: '',
    parameters: new NullObject()
  }
  Object.freeze(defaultContentType.parameters)
  Object.freeze(defaultContentType)

  /**
   * Parse media type to object.
   *
   * @param {string|object} header
   * @return {Object}
   * @public
   */

  function parse(header) {
    if (typeof header !== 'string') {
      throw new TypeError('argument header is required and must be a string')
    }
    let index = header.indexOf(';')
    const type = index !== -1 ? header.slice(0, index).trim() : header.trim()
    if (mediaTypeRE.test(type) === false) {
      throw new TypeError('invalid media type')
    }
    const result = {
      type: type.toLowerCase(),
      parameters: new NullObject()
    }

    // parse parameters
    if (index === -1) {
      return result
    }
    let key
    let match
    let value
    paramRE.lastIndex = index
    while ((match = paramRE.exec(header))) {
      if (match.index !== index) {
        throw new TypeError('invalid parameter format')
      }
      index += match[0].length
      key = match[1].toLowerCase()
      value = match[2]
      if (value[0] === '"') {
        // remove quotes and escapes
        value = value.slice(1, value.length - 1)
        quotedPairRE.test(value) && (value = value.replace(quotedPairRE, '$1'))
      }
      result.parameters[key] = value
    }
    if (index !== header.length) {
      throw new TypeError('invalid parameter format')
    }
    return result
  }
  function safeParse(header) {
    if (typeof header !== 'string') {
      return defaultContentType
    }
    let index = header.indexOf(';')
    const type = index !== -1 ? header.slice(0, index).trim() : header.trim()
    if (mediaTypeRE.test(type) === false) {
      return defaultContentType
    }
    const result = {
      type: type.toLowerCase(),
      parameters: new NullObject()
    }

    // parse parameters
    if (index === -1) {
      return result
    }
    let key
    let match
    let value
    paramRE.lastIndex = index
    while ((match = paramRE.exec(header))) {
      if (match.index !== index) {
        return defaultContentType
      }
      index += match[0].length
      key = match[1].toLowerCase()
      value = match[2]
      if (value[0] === '"') {
        // remove quotes and escapes
        value = value.slice(1, value.length - 1)
        quotedPairRE.test(value) && (value = value.replace(quotedPairRE, '$1'))
      }
      result.parameters[key] = value
    }
    if (index !== header.length) {
      return defaultContentType
    }
    return result
  }
  fastContentTypeParse.default = {
    parse,
    safeParse
  }
  fastContentTypeParse.parse = parse
  fastContentTypeParse.safeParse = safeParse
  fastContentTypeParse.defaultContentType = defaultContentType
  return fastContentTypeParse
}

const fastContentTypeParseExports = requireFastContentTypeParse()

class RequestError extends Error {
  name
  /**
   * http status code
   */
  status
  /**
   * Request options that lead to the error.
   */
  request
  /**
   * Response object if a response was received
   */
  response
  constructor(message, statusCode, options) {
    super(message)
    this.name = 'HttpError'
    this.status = Number.parseInt(statusCode)
    if (Number.isNaN(this.status)) {
      this.status = 0
    }
    if ('response' in options) {
      this.response = options.response
    }
    const requestCopy = Object.assign({}, options.request)
    if (options.request.headers.authorization) {
      requestCopy.headers = Object.assign({}, options.request.headers, {
        authorization: options.request.headers.authorization.replace(
          /(?<! ) .*$/,
          ' [REDACTED]'
        )
      })
    }
    requestCopy.url = requestCopy.url
      .replace(/\bclient_secret=\w+/g, 'client_secret=[REDACTED]')
      .replace(/\baccess_token=\w+/g, 'access_token=[REDACTED]')
    this.request = requestCopy
  }
}

// pkg/dist-src/index.js

// pkg/dist-src/version.js
const VERSION$6 = '0.0.0-development'

// pkg/dist-src/defaults.js
const defaults_default = {
  headers: {
    'user-agent': `octokit-request.js/${VERSION$6} ${getUserAgent()}`
  }
}

// pkg/dist-src/is-plain-object.js
function isPlainObject(value) {
  if (typeof value !== 'object' || value === null) {
    return false
  }
  if (Object.prototype.toString.call(value) !== '[object Object]') {
    return false
  }
  const proto = Object.getPrototypeOf(value)
  if (proto === null) {
    return true
  }
  const Ctor =
    Object.prototype.hasOwnProperty.call(proto, 'constructor') &&
    proto.constructor
  return (
    typeof Ctor === 'function' &&
    Ctor instanceof Ctor &&
    Function.prototype.call(Ctor) === Function.prototype.call(value)
  )
}
async function fetchWrapper(requestOptions) {
  const fetch = requestOptions.request?.fetch || globalThis.fetch
  if (!fetch) {
    throw new Error(
      'fetch is not set. Please pass a fetch implementation as new Octokit({ request: { fetch }}). Learn more at https://github.com/octokit/octokit.js/#fetch-missing'
    )
  }
  const log = requestOptions.request?.log || console
  const parseSuccessResponseBody =
    requestOptions.request?.parseSuccessResponseBody !== false
  const body =
    isPlainObject(requestOptions.body) || Array.isArray(requestOptions.body)
      ? JSON.stringify(requestOptions.body)
      : requestOptions.body
  const requestHeaders = Object.fromEntries(
    Object.entries(requestOptions.headers).map(([name, value]) => [
      name,
      String(value)
    ])
  )
  let fetchResponse
  try {
    fetchResponse = await fetch(requestOptions.url, {
      method: requestOptions.method,
      body,
      redirect: requestOptions.request?.redirect,
      headers: requestHeaders,
      signal: requestOptions.request?.signal,
      // duplex must be set if request.body is ReadableStream or Async Iterables.
      // See https://fetch.spec.whatwg.org/#dom-requestinit-duplex.
      ...(requestOptions.body && {
        duplex: 'half'
      })
    })
  } catch (error) {
    let message = 'Unknown Error'
    if (error instanceof Error) {
      if (error.name === 'AbortError') {
        error.status = 500
        throw error
      }
      message = error.message
      if (error.name === 'TypeError' && 'cause' in error) {
        if (error.cause instanceof Error) {
          message = error.cause.message
        } else if (typeof error.cause === 'string') {
          message = error.cause
        }
      }
    }
    const requestError = new RequestError(message, 500, {
      request: requestOptions
    })
    requestError.cause = error
    throw requestError
  }
  const status = fetchResponse.status
  const url = fetchResponse.url
  const responseHeaders = {}
  for (const [key, value] of fetchResponse.headers) {
    responseHeaders[key] = value
  }
  const octokitResponse = {
    url,
    status,
    headers: responseHeaders,
    data: ''
  }
  if ('deprecation' in responseHeaders) {
    const matches =
      responseHeaders.link &&
      responseHeaders.link.match(/<([^<>]+)>; rel="deprecation"/)
    const deprecationLink = matches && matches.pop()
    log.warn(
      `[@octokit/request] "${requestOptions.method} ${requestOptions.url}" is deprecated. It is scheduled to be removed on ${responseHeaders.sunset}${deprecationLink ? `. See ${deprecationLink}` : ''}`
    )
  }
  if (status === 204 || status === 205) {
    return octokitResponse
  }
  if (requestOptions.method === 'HEAD') {
    if (status < 400) {
      return octokitResponse
    }
    throw new RequestError(fetchResponse.statusText, status, {
      response: octokitResponse,
      request: requestOptions
    })
  }
  if (status === 304) {
    octokitResponse.data = await getResponseData(fetchResponse)
    throw new RequestError('Not modified', status, {
      response: octokitResponse,
      request: requestOptions
    })
  }
  if (status >= 400) {
    octokitResponse.data = await getResponseData(fetchResponse)
    throw new RequestError(toErrorMessage(octokitResponse.data), status, {
      response: octokitResponse,
      request: requestOptions
    })
  }
  octokitResponse.data = parseSuccessResponseBody
    ? await getResponseData(fetchResponse)
    : fetchResponse.body
  return octokitResponse
}
async function getResponseData(response) {
  const contentType = response.headers.get('content-type')
  if (!contentType) {
    return response.text().catch(() => '')
  }
  const mimetype = fastContentTypeParseExports.safeParse(contentType)
  if (isJSONResponse(mimetype)) {
    let text = ''
    try {
      text = await response.text()
      return JSON.parse(text)
    } catch (err) {
      return text
    }
  } else if (
    mimetype.type.startsWith('text/') ||
    mimetype.parameters.charset?.toLowerCase() === 'utf-8'
  ) {
    return response.text().catch(() => '')
  } else {
    return response.arrayBuffer().catch(() => new ArrayBuffer(0))
  }
}
function isJSONResponse(mimetype) {
  return (
    mimetype.type === 'application/json' ||
    mimetype.type === 'application/scim+json'
  )
}
function toErrorMessage(data) {
  if (typeof data === 'string') {
    return data
  }
  if (data instanceof ArrayBuffer) {
    return 'Unknown error'
  }
  if ('message' in data) {
    const suffix =
      'documentation_url' in data ? ` - ${data.documentation_url}` : ''
    return Array.isArray(data.errors)
      ? `${data.message}: ${data.errors.map(v => JSON.stringify(v)).join(', ')}${suffix}`
      : `${data.message}${suffix}`
  }
  return `Unknown error: ${JSON.stringify(data)}`
}

// pkg/dist-src/with-defaults.js
function withDefaults$1(oldEndpoint, newDefaults) {
  const endpoint2 = oldEndpoint.defaults(newDefaults)
  const newApi = function (route, parameters) {
    const endpointOptions = endpoint2.merge(route, parameters)
    if (!endpointOptions.request || !endpointOptions.request.hook) {
      return fetchWrapper(endpoint2.parse(endpointOptions))
    }
    const request2 = (route2, parameters2) => {
      return fetchWrapper(endpoint2.parse(endpoint2.merge(route2, parameters2)))
    }
    Object.assign(request2, {
      endpoint: endpoint2,
      defaults: withDefaults$1.bind(null, endpoint2)
    })
    return endpointOptions.request.hook(request2, endpointOptions)
  }
  return Object.assign(newApi, {
    endpoint: endpoint2,
    defaults: withDefaults$1.bind(null, endpoint2)
  })
}

// pkg/dist-src/index.js
const request = withDefaults$1(endpoint, defaults_default)

// pkg/dist-src/index.js

// pkg/dist-src/version.js
const VERSION$5 = '0.0.0-development'

// pkg/dist-src/error.js
function _buildMessageForResponseErrors(data) {
  return (
    `Request failed due to following response errors:
` + data.errors.map(e => ` - ${e.message}`).join('\n')
  )
}
const GraphqlResponseError = class extends Error {
  constructor(request2, headers, response) {
    super(_buildMessageForResponseErrors(response))
    this.request = request2
    this.headers = headers
    this.response = response
    this.errors = response.errors
    this.data = response.data
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, this.constructor)
    }
  }
  name = 'GraphqlResponseError'
  errors
  data
}

// pkg/dist-src/graphql.js
const NON_VARIABLE_OPTIONS = [
  'method',
  'baseUrl',
  'url',
  'headers',
  'request',
  'query',
  'mediaType',
  'operationName'
]
const FORBIDDEN_VARIABLE_OPTIONS = ['query', 'method', 'url']
const GHES_V3_SUFFIX_REGEX = /\/api\/v3\/?$/
function graphql(request2, query, options) {
  if (options) {
    if (typeof query === 'string' && 'query' in options) {
      return Promise.reject(
        new Error(`[@octokit/graphql] "query" cannot be used as variable name`)
      )
    }
    for (const key in options) {
      if (!FORBIDDEN_VARIABLE_OPTIONS.includes(key)) {
        continue
      }
      return Promise.reject(
        new Error(`[@octokit/graphql] "${key}" cannot be used as variable name`)
      )
    }
  }
  const parsedOptions =
    typeof query === 'string'
      ? Object.assign(
          {
            query
          },
          options
        )
      : query
  const requestOptions = Object.keys(parsedOptions).reduce((result, key) => {
    if (NON_VARIABLE_OPTIONS.includes(key)) {
      result[key] = parsedOptions[key]
      return result
    }
    if (!result.variables) {
      result.variables = {}
    }
    result.variables[key] = parsedOptions[key]
    return result
  }, {})
  const baseUrl = parsedOptions.baseUrl || request2.endpoint.DEFAULTS.baseUrl
  if (GHES_V3_SUFFIX_REGEX.test(baseUrl)) {
    requestOptions.url = baseUrl.replace(GHES_V3_SUFFIX_REGEX, '/api/graphql')
  }
  return request2(requestOptions).then(response => {
    if (response.data.errors) {
      const headers = {}
      for (const key of Object.keys(response.headers)) {
        headers[key] = response.headers[key]
      }
      throw new GraphqlResponseError(requestOptions, headers, response.data)
    }
    return response.data.data
  })
}

// pkg/dist-src/with-defaults.js
function withDefaults(request2, newDefaults) {
  const newRequest = request2.defaults(newDefaults)
  const newApi = (query, options) => {
    return graphql(newRequest, query, options)
  }
  return Object.assign(newApi, {
    defaults: withDefaults.bind(null, newRequest),
    endpoint: newRequest.endpoint
  })
}

// pkg/dist-src/index.js
const graphql2 = withDefaults(request, {
  headers: {
    'user-agent': `octokit-graphql.js/${VERSION$5} ${getUserAgent()}`
  },
  method: 'POST',
  url: '/graphql'
})
function withCustomRequest(customRequest) {
  return withDefaults(customRequest, {
    method: 'POST',
    url: '/graphql'
  })
}

// @ts-check

function register(state, name, method, options) {
  if (typeof method !== 'function') {
    throw new Error('method for before hook must be a function')
  }
  if (!options) {
    options = {}
  }
  if (Array.isArray(name)) {
    return name.reverse().reduce((callback, name) => {
      return register.bind(null, state, name, callback, options)
    }, method)()
  }
  return Promise.resolve().then(() => {
    if (!state.registry[name]) {
      return method(options)
    }
    return state.registry[name].reduce((method, registered) => {
      return registered.hook.bind(null, method, options)
    }, method)()
  })
}

// @ts-check

function addHook(state, kind, name, hook) {
  const orig = hook
  if (!state.registry[name]) {
    state.registry[name] = []
  }
  if (kind === 'before') {
    hook = (method, options) => {
      return Promise.resolve()
        .then(orig.bind(null, options))
        .then(method.bind(null, options))
    }
  }
  if (kind === 'after') {
    hook = (method, options) => {
      let result
      return Promise.resolve()
        .then(method.bind(null, options))
        .then(result_ => {
          result = result_
          return orig(result, options)
        })
        .then(() => {
          return result
        })
    }
  }
  if (kind === 'error') {
    hook = (method, options) => {
      return Promise.resolve()
        .then(method.bind(null, options))
        .catch(error => {
          return orig(error, options)
        })
    }
  }
  state.registry[name].push({
    hook: hook,
    orig: orig
  })
}

// @ts-check

function removeHook(state, name, method) {
  if (!state.registry[name]) {
    return
  }
  const index = state.registry[name]
    .map(registered => {
      return registered.orig
    })
    .indexOf(method)
  if (index === -1) {
    return
  }
  state.registry[name].splice(index, 1)
}

// @ts-check

// bind with array of arguments: https://stackoverflow.com/a/21792913
const bind = Function.bind
const bindable = bind.bind(bind)
function bindApi(hook, state, name) {
  const removeHookRef = bindable(removeHook, null).apply(null, [state])
  hook.api = {
    remove: removeHookRef
  }
  hook.remove = removeHookRef
  ;['before', 'error', 'after', 'wrap'].forEach(kind => {
    const args = [state, kind]
    hook[kind] = hook.api[kind] = bindable(addHook, null).apply(null, args)
  })
}
function Collection() {
  const state = {
    registry: {}
  }
  const hook = register.bind(null, state)
  bindApi(hook, state)
  return hook
}
const Hook = {
  Collection
}

// pkg/dist-src/is-jwt.js
const b64url = '(?:[a-zA-Z0-9_-]+)'
const sep = '\\.'
const jwtRE = new RegExp(`^${b64url}${sep}${b64url}${sep}${b64url}$`)
const isJWT = jwtRE.test.bind(jwtRE)

// pkg/dist-src/auth.js
async function auth(token) {
  const isApp = isJWT(token)
  const isInstallation = token.startsWith('v1.') || token.startsWith('ghs_')
  const isUserToServer = token.startsWith('ghu_')
  const tokenType = isApp
    ? 'app'
    : isInstallation
      ? 'installation'
      : isUserToServer
        ? 'user-to-server'
        : 'oauth'
  return {
    type: 'token',
    token,
    tokenType
  }
}

// pkg/dist-src/with-authorization-prefix.js
function withAuthorizationPrefix(token) {
  if (token.split(/\./).length === 3) {
    return `bearer ${token}`
  }
  return `token ${token}`
}

// pkg/dist-src/hook.js
async function hook(token, request, route, parameters) {
  const endpoint = request.endpoint.merge(route, parameters)
  endpoint.headers.authorization = withAuthorizationPrefix(token)
  return request(endpoint)
}

// pkg/dist-src/index.js
const createTokenAuth = function createTokenAuth2(token) {
  if (!token) {
    throw new Error('[@octokit/auth-token] No token passed to createTokenAuth')
  }
  if (typeof token !== 'string') {
    throw new Error(
      '[@octokit/auth-token] Token passed to createTokenAuth is not a string'
    )
  }
  token = token.replace(/^(token|bearer) +/i, '')
  return Object.assign(auth.bind(null, token), {
    hook: hook.bind(null, token)
  })
}

const VERSION$4 = '6.1.5'

const noop = () => {}
const consoleWarn = console.warn.bind(console)
const consoleError = console.error.bind(console)
const userAgentTrail = `octokit-core.js/${VERSION$4} ${getUserAgent()}`
let Octokit$1 = class Octokit {
  static VERSION = VERSION$4
  static defaults(defaults) {
    const OctokitWithDefaults = class extends this {
      constructor(...args) {
        const options = args[0] || {}
        if (typeof defaults === 'function') {
          super(defaults(options))
          return
        }
        super(
          Object.assign(
            {},
            defaults,
            options,
            options.userAgent && defaults.userAgent
              ? {
                  userAgent: `${options.userAgent} ${defaults.userAgent}`
                }
              : null
          )
        )
      }
    }
    return OctokitWithDefaults
  }
  static plugins = []
  /**
   * Attach a plugin (or many) to your Octokit instance.
   *
   * @example
   * const API = Octokit.plugin(plugin1, plugin2, plugin3, ...)
   */
  static plugin(...newPlugins) {
    const currentPlugins = this.plugins
    const NewOctokit = class extends this {
      static plugins = currentPlugins.concat(
        newPlugins.filter(plugin => !currentPlugins.includes(plugin))
      )
    }
    return NewOctokit
  }
  constructor(options = {}) {
    const hook = new Hook.Collection()
    const requestDefaults = {
      baseUrl: request.endpoint.DEFAULTS.baseUrl,
      headers: {},
      request: Object.assign({}, options.request, {
        // @ts-ignore internal usage only, no need to type
        hook: hook.bind(null, 'request')
      }),
      mediaType: {
        previews: [],
        format: ''
      }
    }
    requestDefaults.headers['user-agent'] = options.userAgent
      ? `${options.userAgent} ${userAgentTrail}`
      : userAgentTrail
    if (options.baseUrl) {
      requestDefaults.baseUrl = options.baseUrl
    }
    if (options.previews) {
      requestDefaults.mediaType.previews = options.previews
    }
    if (options.timeZone) {
      requestDefaults.headers['time-zone'] = options.timeZone
    }
    this.request = request.defaults(requestDefaults)
    this.graphql = withCustomRequest(this.request).defaults(requestDefaults)
    this.log = Object.assign(
      {
        debug: noop,
        info: noop,
        warn: consoleWarn,
        error: consoleError
      },
      options.log
    )
    this.hook = hook
    if (!options.authStrategy) {
      if (!options.auth) {
        this.auth = async () => ({
          type: 'unauthenticated'
        })
      } else {
        const auth = createTokenAuth(options.auth)
        hook.wrap('request', auth.hook)
        this.auth = auth
      }
    } else {
      const { authStrategy, ...otherOptions } = options
      const auth = authStrategy(
        Object.assign(
          {
            request: this.request,
            log: this.log,
            // we pass the current octokit instance as well as its constructor options
            // to allow for authentication strategies that return a new octokit instance
            // that shares the same internal state as the current one. The original
            // requirement for this was the "event-octokit" authentication strategy
            // of https://github.com/probot/octokit-auth-probot.
            octokit: this,
            octokitOptions: otherOptions
          },
          options.auth
        )
      )
      hook.wrap('request', auth.hook)
      this.auth = auth
    }
    const classConstructor = this.constructor
    for (let i = 0; i < classConstructor.plugins.length; ++i) {
      Object.assign(this, classConstructor.plugins[i](this, options))
    }
  }
  // assigned during constructor
  request
  graphql
  log
  hook
  // TODO: type `octokit.auth` based on passed options.authStrategy
  auth
}

const VERSION$3 = '5.3.1'

function requestLog(octokit) {
  octokit.hook.wrap('request', (request, options) => {
    octokit.log.debug('request', options)
    const start = Date.now()
    const requestOptions = octokit.request.endpoint.parse(options)
    const path = requestOptions.url.replace(options.baseUrl, '')
    return request(options)
      .then(response => {
        const requestId = response.headers['x-github-request-id']
        octokit.log.info(
          `${requestOptions.method} ${path} - ${response.status} with id ${requestId} in ${Date.now() - start}ms`
        )
        return response
      })
      .catch(error => {
        const requestId =
          error.response?.headers['x-github-request-id'] || 'UNKNOWN'
        octokit.log.error(
          `${requestOptions.method} ${path} - ${error.status} with id ${requestId} in ${Date.now() - start}ms`
        )
        throw error
      })
  })
}
requestLog.VERSION = VERSION$3

// pkg/dist-src/version.js
const VERSION$2 = '0.0.0-development'

// pkg/dist-src/normalize-paginated-list-response.js
function normalizePaginatedListResponse(response) {
  if (!response.data) {
    return {
      ...response,
      data: []
    }
  }
  const responseNeedsNormalization =
    'total_count' in response.data && !('url' in response.data)
  if (!responseNeedsNormalization) {
    return response
  }
  const incompleteResults = response.data.incomplete_results
  const repositorySelection = response.data.repository_selection
  const totalCount = response.data.total_count
  delete response.data.incomplete_results
  delete response.data.repository_selection
  delete response.data.total_count
  const namespaceKey = Object.keys(response.data)[0]
  const data = response.data[namespaceKey]
  response.data = data
  if (typeof incompleteResults !== 'undefined') {
    response.data.incomplete_results = incompleteResults
  }
  if (typeof repositorySelection !== 'undefined') {
    response.data.repository_selection = repositorySelection
  }
  response.data.total_count = totalCount
  return response
}

// pkg/dist-src/iterator.js
function iterator(octokit, route, parameters) {
  const options =
    typeof route === 'function'
      ? route.endpoint(parameters)
      : octokit.request.endpoint(route, parameters)
  const requestMethod = typeof route === 'function' ? route : octokit.request
  const method = options.method
  const headers = options.headers
  let url = options.url
  return {
    [Symbol.asyncIterator]: () => ({
      async next() {
        if (!url) {
          return {
            done: true
          }
        }
        try {
          const response = await requestMethod({
            method,
            url,
            headers
          })
          const normalizedResponse = normalizePaginatedListResponse(response)
          url = ((normalizedResponse.headers.link || '').match(
            /<([^<>]+)>;\s*rel="next"/
          ) || [])[1]
          return {
            value: normalizedResponse
          }
        } catch (error) {
          if (error.status !== 409) {
            throw error
          }
          url = ''
          return {
            value: {
              status: 200,
              headers: {},
              data: []
            }
          }
        }
      }
    })
  }
}

// pkg/dist-src/paginate.js
function paginate(octokit, route, parameters, mapFn) {
  if (typeof parameters === 'function') {
    mapFn = parameters
    parameters = void 0
  }
  return gather(
    octokit,
    [],
    iterator(octokit, route, parameters)[Symbol.asyncIterator](),
    mapFn
  )
}
function gather(octokit, results, iterator2, mapFn) {
  return iterator2.next().then(result => {
    if (result.done) {
      return results
    }
    let earlyExit = false
    function done() {
      earlyExit = true
    }
    results = results.concat(
      mapFn ? mapFn(result.value, done) : result.value.data
    )
    if (earlyExit) {
      return results
    }
    return gather(octokit, results, iterator2, mapFn)
  })
}

// pkg/dist-src/compose-paginate.js
Object.assign(paginate, {
  iterator
})

// pkg/dist-src/index.js
function paginateRest(octokit) {
  return {
    paginate: Object.assign(paginate.bind(null, octokit), {
      iterator: iterator.bind(null, octokit)
    })
  }
}
paginateRest.VERSION = VERSION$2

const VERSION$1 = '13.5.0'

const Endpoints = {
  actions: {
    addCustomLabelsToSelfHostedRunnerForOrg: [
      'POST /orgs/{org}/actions/runners/{runner_id}/labels'
    ],
    addCustomLabelsToSelfHostedRunnerForRepo: [
      'POST /repos/{owner}/{repo}/actions/runners/{runner_id}/labels'
    ],
    addRepoAccessToSelfHostedRunnerGroupInOrg: [
      'PUT /orgs/{org}/actions/runner-groups/{runner_group_id}/repositories/{repository_id}'
    ],
    addSelectedRepoToOrgSecret: [
      'PUT /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}'
    ],
    addSelectedRepoToOrgVariable: [
      'PUT /orgs/{org}/actions/variables/{name}/repositories/{repository_id}'
    ],
    approveWorkflowRun: [
      'POST /repos/{owner}/{repo}/actions/runs/{run_id}/approve'
    ],
    cancelWorkflowRun: [
      'POST /repos/{owner}/{repo}/actions/runs/{run_id}/cancel'
    ],
    createEnvironmentVariable: [
      'POST /repos/{owner}/{repo}/environments/{environment_name}/variables'
    ],
    createHostedRunnerForOrg: ['POST /orgs/{org}/actions/hosted-runners'],
    createOrUpdateEnvironmentSecret: [
      'PUT /repos/{owner}/{repo}/environments/{environment_name}/secrets/{secret_name}'
    ],
    createOrUpdateOrgSecret: ['PUT /orgs/{org}/actions/secrets/{secret_name}'],
    createOrUpdateRepoSecret: [
      'PUT /repos/{owner}/{repo}/actions/secrets/{secret_name}'
    ],
    createOrgVariable: ['POST /orgs/{org}/actions/variables'],
    createRegistrationTokenForOrg: [
      'POST /orgs/{org}/actions/runners/registration-token'
    ],
    createRegistrationTokenForRepo: [
      'POST /repos/{owner}/{repo}/actions/runners/registration-token'
    ],
    createRemoveTokenForOrg: ['POST /orgs/{org}/actions/runners/remove-token'],
    createRemoveTokenForRepo: [
      'POST /repos/{owner}/{repo}/actions/runners/remove-token'
    ],
    createRepoVariable: ['POST /repos/{owner}/{repo}/actions/variables'],
    createWorkflowDispatch: [
      'POST /repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches'
    ],
    deleteActionsCacheById: [
      'DELETE /repos/{owner}/{repo}/actions/caches/{cache_id}'
    ],
    deleteActionsCacheByKey: [
      'DELETE /repos/{owner}/{repo}/actions/caches{?key,ref}'
    ],
    deleteArtifact: [
      'DELETE /repos/{owner}/{repo}/actions/artifacts/{artifact_id}'
    ],
    deleteEnvironmentSecret: [
      'DELETE /repos/{owner}/{repo}/environments/{environment_name}/secrets/{secret_name}'
    ],
    deleteEnvironmentVariable: [
      'DELETE /repos/{owner}/{repo}/environments/{environment_name}/variables/{name}'
    ],
    deleteHostedRunnerForOrg: [
      'DELETE /orgs/{org}/actions/hosted-runners/{hosted_runner_id}'
    ],
    deleteOrgSecret: ['DELETE /orgs/{org}/actions/secrets/{secret_name}'],
    deleteOrgVariable: ['DELETE /orgs/{org}/actions/variables/{name}'],
    deleteRepoSecret: [
      'DELETE /repos/{owner}/{repo}/actions/secrets/{secret_name}'
    ],
    deleteRepoVariable: [
      'DELETE /repos/{owner}/{repo}/actions/variables/{name}'
    ],
    deleteSelfHostedRunnerFromOrg: [
      'DELETE /orgs/{org}/actions/runners/{runner_id}'
    ],
    deleteSelfHostedRunnerFromRepo: [
      'DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}'
    ],
    deleteWorkflowRun: ['DELETE /repos/{owner}/{repo}/actions/runs/{run_id}'],
    deleteWorkflowRunLogs: [
      'DELETE /repos/{owner}/{repo}/actions/runs/{run_id}/logs'
    ],
    disableSelectedRepositoryGithubActionsOrganization: [
      'DELETE /orgs/{org}/actions/permissions/repositories/{repository_id}'
    ],
    disableWorkflow: [
      'PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/disable'
    ],
    downloadArtifact: [
      'GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}/{archive_format}'
    ],
    downloadJobLogsForWorkflowRun: [
      'GET /repos/{owner}/{repo}/actions/jobs/{job_id}/logs'
    ],
    downloadWorkflowRunAttemptLogs: [
      'GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}/logs'
    ],
    downloadWorkflowRunLogs: [
      'GET /repos/{owner}/{repo}/actions/runs/{run_id}/logs'
    ],
    enableSelectedRepositoryGithubActionsOrganization: [
      'PUT /orgs/{org}/actions/permissions/repositories/{repository_id}'
    ],
    enableWorkflow: [
      'PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/enable'
    ],
    forceCancelWorkflowRun: [
      'POST /repos/{owner}/{repo}/actions/runs/{run_id}/force-cancel'
    ],
    generateRunnerJitconfigForOrg: [
      'POST /orgs/{org}/actions/runners/generate-jitconfig'
    ],
    generateRunnerJitconfigForRepo: [
      'POST /repos/{owner}/{repo}/actions/runners/generate-jitconfig'
    ],
    getActionsCacheList: ['GET /repos/{owner}/{repo}/actions/caches'],
    getActionsCacheUsage: ['GET /repos/{owner}/{repo}/actions/cache/usage'],
    getActionsCacheUsageByRepoForOrg: [
      'GET /orgs/{org}/actions/cache/usage-by-repository'
    ],
    getActionsCacheUsageForOrg: ['GET /orgs/{org}/actions/cache/usage'],
    getAllowedActionsOrganization: [
      'GET /orgs/{org}/actions/permissions/selected-actions'
    ],
    getAllowedActionsRepository: [
      'GET /repos/{owner}/{repo}/actions/permissions/selected-actions'
    ],
    getArtifact: ['GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}'],
    getCustomOidcSubClaimForRepo: [
      'GET /repos/{owner}/{repo}/actions/oidc/customization/sub'
    ],
    getEnvironmentPublicKey: [
      'GET /repos/{owner}/{repo}/environments/{environment_name}/secrets/public-key'
    ],
    getEnvironmentSecret: [
      'GET /repos/{owner}/{repo}/environments/{environment_name}/secrets/{secret_name}'
    ],
    getEnvironmentVariable: [
      'GET /repos/{owner}/{repo}/environments/{environment_name}/variables/{name}'
    ],
    getGithubActionsDefaultWorkflowPermissionsOrganization: [
      'GET /orgs/{org}/actions/permissions/workflow'
    ],
    getGithubActionsDefaultWorkflowPermissionsRepository: [
      'GET /repos/{owner}/{repo}/actions/permissions/workflow'
    ],
    getGithubActionsPermissionsOrganization: [
      'GET /orgs/{org}/actions/permissions'
    ],
    getGithubActionsPermissionsRepository: [
      'GET /repos/{owner}/{repo}/actions/permissions'
    ],
    getHostedRunnerForOrg: [
      'GET /orgs/{org}/actions/hosted-runners/{hosted_runner_id}'
    ],
    getHostedRunnersGithubOwnedImagesForOrg: [
      'GET /orgs/{org}/actions/hosted-runners/images/github-owned'
    ],
    getHostedRunnersLimitsForOrg: [
      'GET /orgs/{org}/actions/hosted-runners/limits'
    ],
    getHostedRunnersMachineSpecsForOrg: [
      'GET /orgs/{org}/actions/hosted-runners/machine-sizes'
    ],
    getHostedRunnersPartnerImagesForOrg: [
      'GET /orgs/{org}/actions/hosted-runners/images/partner'
    ],
    getHostedRunnersPlatformsForOrg: [
      'GET /orgs/{org}/actions/hosted-runners/platforms'
    ],
    getJobForWorkflowRun: ['GET /repos/{owner}/{repo}/actions/jobs/{job_id}'],
    getOrgPublicKey: ['GET /orgs/{org}/actions/secrets/public-key'],
    getOrgSecret: ['GET /orgs/{org}/actions/secrets/{secret_name}'],
    getOrgVariable: ['GET /orgs/{org}/actions/variables/{name}'],
    getPendingDeploymentsForRun: [
      'GET /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments'
    ],
    getRepoPermissions: [
      'GET /repos/{owner}/{repo}/actions/permissions',
      {},
      {
        renamed: ['actions', 'getGithubActionsPermissionsRepository']
      }
    ],
    getRepoPublicKey: ['GET /repos/{owner}/{repo}/actions/secrets/public-key'],
    getRepoSecret: ['GET /repos/{owner}/{repo}/actions/secrets/{secret_name}'],
    getRepoVariable: ['GET /repos/{owner}/{repo}/actions/variables/{name}'],
    getReviewsForRun: [
      'GET /repos/{owner}/{repo}/actions/runs/{run_id}/approvals'
    ],
    getSelfHostedRunnerForOrg: ['GET /orgs/{org}/actions/runners/{runner_id}'],
    getSelfHostedRunnerForRepo: [
      'GET /repos/{owner}/{repo}/actions/runners/{runner_id}'
    ],
    getWorkflow: ['GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}'],
    getWorkflowAccessToRepository: [
      'GET /repos/{owner}/{repo}/actions/permissions/access'
    ],
    getWorkflowRun: ['GET /repos/{owner}/{repo}/actions/runs/{run_id}'],
    getWorkflowRunAttempt: [
      'GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}'
    ],
    getWorkflowRunUsage: [
      'GET /repos/{owner}/{repo}/actions/runs/{run_id}/timing'
    ],
    getWorkflowUsage: [
      'GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/timing'
    ],
    listArtifactsForRepo: ['GET /repos/{owner}/{repo}/actions/artifacts'],
    listEnvironmentSecrets: [
      'GET /repos/{owner}/{repo}/environments/{environment_name}/secrets'
    ],
    listEnvironmentVariables: [
      'GET /repos/{owner}/{repo}/environments/{environment_name}/variables'
    ],
    listGithubHostedRunnersInGroupForOrg: [
      'GET /orgs/{org}/actions/runner-groups/{runner_group_id}/hosted-runners'
    ],
    listHostedRunnersForOrg: ['GET /orgs/{org}/actions/hosted-runners'],
    listJobsForWorkflowRun: [
      'GET /repos/{owner}/{repo}/actions/runs/{run_id}/jobs'
    ],
    listJobsForWorkflowRunAttempt: [
      'GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}/jobs'
    ],
    listLabelsForSelfHostedRunnerForOrg: [
      'GET /orgs/{org}/actions/runners/{runner_id}/labels'
    ],
    listLabelsForSelfHostedRunnerForRepo: [
      'GET /repos/{owner}/{repo}/actions/runners/{runner_id}/labels'
    ],
    listOrgSecrets: ['GET /orgs/{org}/actions/secrets'],
    listOrgVariables: ['GET /orgs/{org}/actions/variables'],
    listRepoOrganizationSecrets: [
      'GET /repos/{owner}/{repo}/actions/organization-secrets'
    ],
    listRepoOrganizationVariables: [
      'GET /repos/{owner}/{repo}/actions/organization-variables'
    ],
    listRepoSecrets: ['GET /repos/{owner}/{repo}/actions/secrets'],
    listRepoVariables: ['GET /repos/{owner}/{repo}/actions/variables'],
    listRepoWorkflows: ['GET /repos/{owner}/{repo}/actions/workflows'],
    listRunnerApplicationsForOrg: ['GET /orgs/{org}/actions/runners/downloads'],
    listRunnerApplicationsForRepo: [
      'GET /repos/{owner}/{repo}/actions/runners/downloads'
    ],
    listSelectedReposForOrgSecret: [
      'GET /orgs/{org}/actions/secrets/{secret_name}/repositories'
    ],
    listSelectedReposForOrgVariable: [
      'GET /orgs/{org}/actions/variables/{name}/repositories'
    ],
    listSelectedRepositoriesEnabledGithubActionsOrganization: [
      'GET /orgs/{org}/actions/permissions/repositories'
    ],
    listSelfHostedRunnersForOrg: ['GET /orgs/{org}/actions/runners'],
    listSelfHostedRunnersForRepo: ['GET /repos/{owner}/{repo}/actions/runners'],
    listWorkflowRunArtifacts: [
      'GET /repos/{owner}/{repo}/actions/runs/{run_id}/artifacts'
    ],
    listWorkflowRuns: [
      'GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs'
    ],
    listWorkflowRunsForRepo: ['GET /repos/{owner}/{repo}/actions/runs'],
    reRunJobForWorkflowRun: [
      'POST /repos/{owner}/{repo}/actions/jobs/{job_id}/rerun'
    ],
    reRunWorkflow: ['POST /repos/{owner}/{repo}/actions/runs/{run_id}/rerun'],
    reRunWorkflowFailedJobs: [
      'POST /repos/{owner}/{repo}/actions/runs/{run_id}/rerun-failed-jobs'
    ],
    removeAllCustomLabelsFromSelfHostedRunnerForOrg: [
      'DELETE /orgs/{org}/actions/runners/{runner_id}/labels'
    ],
    removeAllCustomLabelsFromSelfHostedRunnerForRepo: [
      'DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}/labels'
    ],
    removeCustomLabelFromSelfHostedRunnerForOrg: [
      'DELETE /orgs/{org}/actions/runners/{runner_id}/labels/{name}'
    ],
    removeCustomLabelFromSelfHostedRunnerForRepo: [
      'DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}/labels/{name}'
    ],
    removeSelectedRepoFromOrgSecret: [
      'DELETE /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}'
    ],
    removeSelectedRepoFromOrgVariable: [
      'DELETE /orgs/{org}/actions/variables/{name}/repositories/{repository_id}'
    ],
    reviewCustomGatesForRun: [
      'POST /repos/{owner}/{repo}/actions/runs/{run_id}/deployment_protection_rule'
    ],
    reviewPendingDeploymentsForRun: [
      'POST /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments'
    ],
    setAllowedActionsOrganization: [
      'PUT /orgs/{org}/actions/permissions/selected-actions'
    ],
    setAllowedActionsRepository: [
      'PUT /repos/{owner}/{repo}/actions/permissions/selected-actions'
    ],
    setCustomLabelsForSelfHostedRunnerForOrg: [
      'PUT /orgs/{org}/actions/runners/{runner_id}/labels'
    ],
    setCustomLabelsForSelfHostedRunnerForRepo: [
      'PUT /repos/{owner}/{repo}/actions/runners/{runner_id}/labels'
    ],
    setCustomOidcSubClaimForRepo: [
      'PUT /repos/{owner}/{repo}/actions/oidc/customization/sub'
    ],
    setGithubActionsDefaultWorkflowPermissionsOrganization: [
      'PUT /orgs/{org}/actions/permissions/workflow'
    ],
    setGithubActionsDefaultWorkflowPermissionsRepository: [
      'PUT /repos/{owner}/{repo}/actions/permissions/workflow'
    ],
    setGithubActionsPermissionsOrganization: [
      'PUT /orgs/{org}/actions/permissions'
    ],
    setGithubActionsPermissionsRepository: [
      'PUT /repos/{owner}/{repo}/actions/permissions'
    ],
    setSelectedReposForOrgSecret: [
      'PUT /orgs/{org}/actions/secrets/{secret_name}/repositories'
    ],
    setSelectedReposForOrgVariable: [
      'PUT /orgs/{org}/actions/variables/{name}/repositories'
    ],
    setSelectedRepositoriesEnabledGithubActionsOrganization: [
      'PUT /orgs/{org}/actions/permissions/repositories'
    ],
    setWorkflowAccessToRepository: [
      'PUT /repos/{owner}/{repo}/actions/permissions/access'
    ],
    updateEnvironmentVariable: [
      'PATCH /repos/{owner}/{repo}/environments/{environment_name}/variables/{name}'
    ],
    updateHostedRunnerForOrg: [
      'PATCH /orgs/{org}/actions/hosted-runners/{hosted_runner_id}'
    ],
    updateOrgVariable: ['PATCH /orgs/{org}/actions/variables/{name}'],
    updateRepoVariable: ['PATCH /repos/{owner}/{repo}/actions/variables/{name}']
  },
  activity: {
    checkRepoIsStarredByAuthenticatedUser: ['GET /user/starred/{owner}/{repo}'],
    deleteRepoSubscription: ['DELETE /repos/{owner}/{repo}/subscription'],
    deleteThreadSubscription: [
      'DELETE /notifications/threads/{thread_id}/subscription'
    ],
    getFeeds: ['GET /feeds'],
    getRepoSubscription: ['GET /repos/{owner}/{repo}/subscription'],
    getThread: ['GET /notifications/threads/{thread_id}'],
    getThreadSubscriptionForAuthenticatedUser: [
      'GET /notifications/threads/{thread_id}/subscription'
    ],
    listEventsForAuthenticatedUser: ['GET /users/{username}/events'],
    listNotificationsForAuthenticatedUser: ['GET /notifications'],
    listOrgEventsForAuthenticatedUser: [
      'GET /users/{username}/events/orgs/{org}'
    ],
    listPublicEvents: ['GET /events'],
    listPublicEventsForRepoNetwork: ['GET /networks/{owner}/{repo}/events'],
    listPublicEventsForUser: ['GET /users/{username}/events/public'],
    listPublicOrgEvents: ['GET /orgs/{org}/events'],
    listReceivedEventsForUser: ['GET /users/{username}/received_events'],
    listReceivedPublicEventsForUser: [
      'GET /users/{username}/received_events/public'
    ],
    listRepoEvents: ['GET /repos/{owner}/{repo}/events'],
    listRepoNotificationsForAuthenticatedUser: [
      'GET /repos/{owner}/{repo}/notifications'
    ],
    listReposStarredByAuthenticatedUser: ['GET /user/starred'],
    listReposStarredByUser: ['GET /users/{username}/starred'],
    listReposWatchedByUser: ['GET /users/{username}/subscriptions'],
    listStargazersForRepo: ['GET /repos/{owner}/{repo}/stargazers'],
    listWatchedReposForAuthenticatedUser: ['GET /user/subscriptions'],
    listWatchersForRepo: ['GET /repos/{owner}/{repo}/subscribers'],
    markNotificationsAsRead: ['PUT /notifications'],
    markRepoNotificationsAsRead: ['PUT /repos/{owner}/{repo}/notifications'],
    markThreadAsDone: ['DELETE /notifications/threads/{thread_id}'],
    markThreadAsRead: ['PATCH /notifications/threads/{thread_id}'],
    setRepoSubscription: ['PUT /repos/{owner}/{repo}/subscription'],
    setThreadSubscription: [
      'PUT /notifications/threads/{thread_id}/subscription'
    ],
    starRepoForAuthenticatedUser: ['PUT /user/starred/{owner}/{repo}'],
    unstarRepoForAuthenticatedUser: ['DELETE /user/starred/{owner}/{repo}']
  },
  apps: {
    addRepoToInstallation: [
      'PUT /user/installations/{installation_id}/repositories/{repository_id}',
      {},
      {
        renamed: ['apps', 'addRepoToInstallationForAuthenticatedUser']
      }
    ],
    addRepoToInstallationForAuthenticatedUser: [
      'PUT /user/installations/{installation_id}/repositories/{repository_id}'
    ],
    checkToken: ['POST /applications/{client_id}/token'],
    createFromManifest: ['POST /app-manifests/{code}/conversions'],
    createInstallationAccessToken: [
      'POST /app/installations/{installation_id}/access_tokens'
    ],
    deleteAuthorization: ['DELETE /applications/{client_id}/grant'],
    deleteInstallation: ['DELETE /app/installations/{installation_id}'],
    deleteToken: ['DELETE /applications/{client_id}/token'],
    getAuthenticated: ['GET /app'],
    getBySlug: ['GET /apps/{app_slug}'],
    getInstallation: ['GET /app/installations/{installation_id}'],
    getOrgInstallation: ['GET /orgs/{org}/installation'],
    getRepoInstallation: ['GET /repos/{owner}/{repo}/installation'],
    getSubscriptionPlanForAccount: [
      'GET /marketplace_listing/accounts/{account_id}'
    ],
    getSubscriptionPlanForAccountStubbed: [
      'GET /marketplace_listing/stubbed/accounts/{account_id}'
    ],
    getUserInstallation: ['GET /users/{username}/installation'],
    getWebhookConfigForApp: ['GET /app/hook/config'],
    getWebhookDelivery: ['GET /app/hook/deliveries/{delivery_id}'],
    listAccountsForPlan: ['GET /marketplace_listing/plans/{plan_id}/accounts'],
    listAccountsForPlanStubbed: [
      'GET /marketplace_listing/stubbed/plans/{plan_id}/accounts'
    ],
    listInstallationReposForAuthenticatedUser: [
      'GET /user/installations/{installation_id}/repositories'
    ],
    listInstallationRequestsForAuthenticatedApp: [
      'GET /app/installation-requests'
    ],
    listInstallations: ['GET /app/installations'],
    listInstallationsForAuthenticatedUser: ['GET /user/installations'],
    listPlans: ['GET /marketplace_listing/plans'],
    listPlansStubbed: ['GET /marketplace_listing/stubbed/plans'],
    listReposAccessibleToInstallation: ['GET /installation/repositories'],
    listSubscriptionsForAuthenticatedUser: ['GET /user/marketplace_purchases'],
    listSubscriptionsForAuthenticatedUserStubbed: [
      'GET /user/marketplace_purchases/stubbed'
    ],
    listWebhookDeliveries: ['GET /app/hook/deliveries'],
    redeliverWebhookDelivery: [
      'POST /app/hook/deliveries/{delivery_id}/attempts'
    ],
    removeRepoFromInstallation: [
      'DELETE /user/installations/{installation_id}/repositories/{repository_id}',
      {},
      {
        renamed: ['apps', 'removeRepoFromInstallationForAuthenticatedUser']
      }
    ],
    removeRepoFromInstallationForAuthenticatedUser: [
      'DELETE /user/installations/{installation_id}/repositories/{repository_id}'
    ],
    resetToken: ['PATCH /applications/{client_id}/token'],
    revokeInstallationAccessToken: ['DELETE /installation/token'],
    scopeToken: ['POST /applications/{client_id}/token/scoped'],
    suspendInstallation: ['PUT /app/installations/{installation_id}/suspended'],
    unsuspendInstallation: [
      'DELETE /app/installations/{installation_id}/suspended'
    ],
    updateWebhookConfigForApp: ['PATCH /app/hook/config']
  },
  billing: {
    getGithubActionsBillingOrg: ['GET /orgs/{org}/settings/billing/actions'],
    getGithubActionsBillingUser: [
      'GET /users/{username}/settings/billing/actions'
    ],
    getGithubBillingUsageReportOrg: [
      'GET /organizations/{org}/settings/billing/usage'
    ],
    getGithubPackagesBillingOrg: ['GET /orgs/{org}/settings/billing/packages'],
    getGithubPackagesBillingUser: [
      'GET /users/{username}/settings/billing/packages'
    ],
    getSharedStorageBillingOrg: [
      'GET /orgs/{org}/settings/billing/shared-storage'
    ],
    getSharedStorageBillingUser: [
      'GET /users/{username}/settings/billing/shared-storage'
    ]
  },
  checks: {
    create: ['POST /repos/{owner}/{repo}/check-runs'],
    createSuite: ['POST /repos/{owner}/{repo}/check-suites'],
    get: ['GET /repos/{owner}/{repo}/check-runs/{check_run_id}'],
    getSuite: ['GET /repos/{owner}/{repo}/check-suites/{check_suite_id}'],
    listAnnotations: [
      'GET /repos/{owner}/{repo}/check-runs/{check_run_id}/annotations'
    ],
    listForRef: ['GET /repos/{owner}/{repo}/commits/{ref}/check-runs'],
    listForSuite: [
      'GET /repos/{owner}/{repo}/check-suites/{check_suite_id}/check-runs'
    ],
    listSuitesForRef: ['GET /repos/{owner}/{repo}/commits/{ref}/check-suites'],
    rerequestRun: [
      'POST /repos/{owner}/{repo}/check-runs/{check_run_id}/rerequest'
    ],
    rerequestSuite: [
      'POST /repos/{owner}/{repo}/check-suites/{check_suite_id}/rerequest'
    ],
    setSuitesPreferences: [
      'PATCH /repos/{owner}/{repo}/check-suites/preferences'
    ],
    update: ['PATCH /repos/{owner}/{repo}/check-runs/{check_run_id}']
  },
  codeScanning: {
    commitAutofix: [
      'POST /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/autofix/commits'
    ],
    createAutofix: [
      'POST /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/autofix'
    ],
    createVariantAnalysis: [
      'POST /repos/{owner}/{repo}/code-scanning/codeql/variant-analyses'
    ],
    deleteAnalysis: [
      'DELETE /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}{?confirm_delete}'
    ],
    deleteCodeqlDatabase: [
      'DELETE /repos/{owner}/{repo}/code-scanning/codeql/databases/{language}'
    ],
    getAlert: [
      'GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}',
      {},
      {
        renamedParameters: {
          alert_id: 'alert_number'
        }
      }
    ],
    getAnalysis: [
      'GET /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}'
    ],
    getAutofix: [
      'GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/autofix'
    ],
    getCodeqlDatabase: [
      'GET /repos/{owner}/{repo}/code-scanning/codeql/databases/{language}'
    ],
    getDefaultSetup: ['GET /repos/{owner}/{repo}/code-scanning/default-setup'],
    getSarif: ['GET /repos/{owner}/{repo}/code-scanning/sarifs/{sarif_id}'],
    getVariantAnalysis: [
      'GET /repos/{owner}/{repo}/code-scanning/codeql/variant-analyses/{codeql_variant_analysis_id}'
    ],
    getVariantAnalysisRepoTask: [
      'GET /repos/{owner}/{repo}/code-scanning/codeql/variant-analyses/{codeql_variant_analysis_id}/repos/{repo_owner}/{repo_name}'
    ],
    listAlertInstances: [
      'GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances'
    ],
    listAlertsForOrg: ['GET /orgs/{org}/code-scanning/alerts'],
    listAlertsForRepo: ['GET /repos/{owner}/{repo}/code-scanning/alerts'],
    listAlertsInstances: [
      'GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances',
      {},
      {
        renamed: ['codeScanning', 'listAlertInstances']
      }
    ],
    listCodeqlDatabases: [
      'GET /repos/{owner}/{repo}/code-scanning/codeql/databases'
    ],
    listRecentAnalyses: ['GET /repos/{owner}/{repo}/code-scanning/analyses'],
    updateAlert: [
      'PATCH /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}'
    ],
    updateDefaultSetup: [
      'PATCH /repos/{owner}/{repo}/code-scanning/default-setup'
    ],
    uploadSarif: ['POST /repos/{owner}/{repo}/code-scanning/sarifs']
  },
  codeSecurity: {
    attachConfiguration: [
      'POST /orgs/{org}/code-security/configurations/{configuration_id}/attach'
    ],
    attachEnterpriseConfiguration: [
      'POST /enterprises/{enterprise}/code-security/configurations/{configuration_id}/attach'
    ],
    createConfiguration: ['POST /orgs/{org}/code-security/configurations'],
    createConfigurationForEnterprise: [
      'POST /enterprises/{enterprise}/code-security/configurations'
    ],
    deleteConfiguration: [
      'DELETE /orgs/{org}/code-security/configurations/{configuration_id}'
    ],
    deleteConfigurationForEnterprise: [
      'DELETE /enterprises/{enterprise}/code-security/configurations/{configuration_id}'
    ],
    detachConfiguration: [
      'DELETE /orgs/{org}/code-security/configurations/detach'
    ],
    getConfiguration: [
      'GET /orgs/{org}/code-security/configurations/{configuration_id}'
    ],
    getConfigurationForRepository: [
      'GET /repos/{owner}/{repo}/code-security-configuration'
    ],
    getConfigurationsForEnterprise: [
      'GET /enterprises/{enterprise}/code-security/configurations'
    ],
    getConfigurationsForOrg: ['GET /orgs/{org}/code-security/configurations'],
    getDefaultConfigurations: [
      'GET /orgs/{org}/code-security/configurations/defaults'
    ],
    getDefaultConfigurationsForEnterprise: [
      'GET /enterprises/{enterprise}/code-security/configurations/defaults'
    ],
    getRepositoriesForConfiguration: [
      'GET /orgs/{org}/code-security/configurations/{configuration_id}/repositories'
    ],
    getRepositoriesForEnterpriseConfiguration: [
      'GET /enterprises/{enterprise}/code-security/configurations/{configuration_id}/repositories'
    ],
    getSingleConfigurationForEnterprise: [
      'GET /enterprises/{enterprise}/code-security/configurations/{configuration_id}'
    ],
    setConfigurationAsDefault: [
      'PUT /orgs/{org}/code-security/configurations/{configuration_id}/defaults'
    ],
    setConfigurationAsDefaultForEnterprise: [
      'PUT /enterprises/{enterprise}/code-security/configurations/{configuration_id}/defaults'
    ],
    updateConfiguration: [
      'PATCH /orgs/{org}/code-security/configurations/{configuration_id}'
    ],
    updateEnterpriseConfiguration: [
      'PATCH /enterprises/{enterprise}/code-security/configurations/{configuration_id}'
    ]
  },
  codesOfConduct: {
    getAllCodesOfConduct: ['GET /codes_of_conduct'],
    getConductCode: ['GET /codes_of_conduct/{key}']
  },
  codespaces: {
    addRepositoryForSecretForAuthenticatedUser: [
      'PUT /user/codespaces/secrets/{secret_name}/repositories/{repository_id}'
    ],
    addSelectedRepoToOrgSecret: [
      'PUT /orgs/{org}/codespaces/secrets/{secret_name}/repositories/{repository_id}'
    ],
    checkPermissionsForDevcontainer: [
      'GET /repos/{owner}/{repo}/codespaces/permissions_check'
    ],
    codespaceMachinesForAuthenticatedUser: [
      'GET /user/codespaces/{codespace_name}/machines'
    ],
    createForAuthenticatedUser: ['POST /user/codespaces'],
    createOrUpdateOrgSecret: [
      'PUT /orgs/{org}/codespaces/secrets/{secret_name}'
    ],
    createOrUpdateRepoSecret: [
      'PUT /repos/{owner}/{repo}/codespaces/secrets/{secret_name}'
    ],
    createOrUpdateSecretForAuthenticatedUser: [
      'PUT /user/codespaces/secrets/{secret_name}'
    ],
    createWithPrForAuthenticatedUser: [
      'POST /repos/{owner}/{repo}/pulls/{pull_number}/codespaces'
    ],
    createWithRepoForAuthenticatedUser: [
      'POST /repos/{owner}/{repo}/codespaces'
    ],
    deleteForAuthenticatedUser: ['DELETE /user/codespaces/{codespace_name}'],
    deleteFromOrganization: [
      'DELETE /orgs/{org}/members/{username}/codespaces/{codespace_name}'
    ],
    deleteOrgSecret: ['DELETE /orgs/{org}/codespaces/secrets/{secret_name}'],
    deleteRepoSecret: [
      'DELETE /repos/{owner}/{repo}/codespaces/secrets/{secret_name}'
    ],
    deleteSecretForAuthenticatedUser: [
      'DELETE /user/codespaces/secrets/{secret_name}'
    ],
    exportForAuthenticatedUser: [
      'POST /user/codespaces/{codespace_name}/exports'
    ],
    getCodespacesForUserInOrg: [
      'GET /orgs/{org}/members/{username}/codespaces'
    ],
    getExportDetailsForAuthenticatedUser: [
      'GET /user/codespaces/{codespace_name}/exports/{export_id}'
    ],
    getForAuthenticatedUser: ['GET /user/codespaces/{codespace_name}'],
    getOrgPublicKey: ['GET /orgs/{org}/codespaces/secrets/public-key'],
    getOrgSecret: ['GET /orgs/{org}/codespaces/secrets/{secret_name}'],
    getPublicKeyForAuthenticatedUser: [
      'GET /user/codespaces/secrets/public-key'
    ],
    getRepoPublicKey: [
      'GET /repos/{owner}/{repo}/codespaces/secrets/public-key'
    ],
    getRepoSecret: [
      'GET /repos/{owner}/{repo}/codespaces/secrets/{secret_name}'
    ],
    getSecretForAuthenticatedUser: [
      'GET /user/codespaces/secrets/{secret_name}'
    ],
    listDevcontainersInRepositoryForAuthenticatedUser: [
      'GET /repos/{owner}/{repo}/codespaces/devcontainers'
    ],
    listForAuthenticatedUser: ['GET /user/codespaces'],
    listInOrganization: [
      'GET /orgs/{org}/codespaces',
      {},
      {
        renamedParameters: {
          org_id: 'org'
        }
      }
    ],
    listInRepositoryForAuthenticatedUser: [
      'GET /repos/{owner}/{repo}/codespaces'
    ],
    listOrgSecrets: ['GET /orgs/{org}/codespaces/secrets'],
    listRepoSecrets: ['GET /repos/{owner}/{repo}/codespaces/secrets'],
    listRepositoriesForSecretForAuthenticatedUser: [
      'GET /user/codespaces/secrets/{secret_name}/repositories'
    ],
    listSecretsForAuthenticatedUser: ['GET /user/codespaces/secrets'],
    listSelectedReposForOrgSecret: [
      'GET /orgs/{org}/codespaces/secrets/{secret_name}/repositories'
    ],
    preFlightWithRepoForAuthenticatedUser: [
      'GET /repos/{owner}/{repo}/codespaces/new'
    ],
    publishForAuthenticatedUser: [
      'POST /user/codespaces/{codespace_name}/publish'
    ],
    removeRepositoryForSecretForAuthenticatedUser: [
      'DELETE /user/codespaces/secrets/{secret_name}/repositories/{repository_id}'
    ],
    removeSelectedRepoFromOrgSecret: [
      'DELETE /orgs/{org}/codespaces/secrets/{secret_name}/repositories/{repository_id}'
    ],
    repoMachinesForAuthenticatedUser: [
      'GET /repos/{owner}/{repo}/codespaces/machines'
    ],
    setRepositoriesForSecretForAuthenticatedUser: [
      'PUT /user/codespaces/secrets/{secret_name}/repositories'
    ],
    setSelectedReposForOrgSecret: [
      'PUT /orgs/{org}/codespaces/secrets/{secret_name}/repositories'
    ],
    startForAuthenticatedUser: ['POST /user/codespaces/{codespace_name}/start'],
    stopForAuthenticatedUser: ['POST /user/codespaces/{codespace_name}/stop'],
    stopInOrganization: [
      'POST /orgs/{org}/members/{username}/codespaces/{codespace_name}/stop'
    ],
    updateForAuthenticatedUser: ['PATCH /user/codespaces/{codespace_name}']
  },
  copilot: {
    addCopilotSeatsForTeams: [
      'POST /orgs/{org}/copilot/billing/selected_teams'
    ],
    addCopilotSeatsForUsers: [
      'POST /orgs/{org}/copilot/billing/selected_users'
    ],
    cancelCopilotSeatAssignmentForTeams: [
      'DELETE /orgs/{org}/copilot/billing/selected_teams'
    ],
    cancelCopilotSeatAssignmentForUsers: [
      'DELETE /orgs/{org}/copilot/billing/selected_users'
    ],
    copilotMetricsForOrganization: ['GET /orgs/{org}/copilot/metrics'],
    copilotMetricsForTeam: ['GET /orgs/{org}/team/{team_slug}/copilot/metrics'],
    getCopilotOrganizationDetails: ['GET /orgs/{org}/copilot/billing'],
    getCopilotSeatDetailsForUser: [
      'GET /orgs/{org}/members/{username}/copilot'
    ],
    listCopilotSeats: ['GET /orgs/{org}/copilot/billing/seats'],
    usageMetricsForOrg: ['GET /orgs/{org}/copilot/usage'],
    usageMetricsForTeam: ['GET /orgs/{org}/team/{team_slug}/copilot/usage']
  },
  dependabot: {
    addSelectedRepoToOrgSecret: [
      'PUT /orgs/{org}/dependabot/secrets/{secret_name}/repositories/{repository_id}'
    ],
    createOrUpdateOrgSecret: [
      'PUT /orgs/{org}/dependabot/secrets/{secret_name}'
    ],
    createOrUpdateRepoSecret: [
      'PUT /repos/{owner}/{repo}/dependabot/secrets/{secret_name}'
    ],
    deleteOrgSecret: ['DELETE /orgs/{org}/dependabot/secrets/{secret_name}'],
    deleteRepoSecret: [
      'DELETE /repos/{owner}/{repo}/dependabot/secrets/{secret_name}'
    ],
    getAlert: ['GET /repos/{owner}/{repo}/dependabot/alerts/{alert_number}'],
    getOrgPublicKey: ['GET /orgs/{org}/dependabot/secrets/public-key'],
    getOrgSecret: ['GET /orgs/{org}/dependabot/secrets/{secret_name}'],
    getRepoPublicKey: [
      'GET /repos/{owner}/{repo}/dependabot/secrets/public-key'
    ],
    getRepoSecret: [
      'GET /repos/{owner}/{repo}/dependabot/secrets/{secret_name}'
    ],
    listAlertsForEnterprise: [
      'GET /enterprises/{enterprise}/dependabot/alerts'
    ],
    listAlertsForOrg: ['GET /orgs/{org}/dependabot/alerts'],
    listAlertsForRepo: ['GET /repos/{owner}/{repo}/dependabot/alerts'],
    listOrgSecrets: ['GET /orgs/{org}/dependabot/secrets'],
    listRepoSecrets: ['GET /repos/{owner}/{repo}/dependabot/secrets'],
    listSelectedReposForOrgSecret: [
      'GET /orgs/{org}/dependabot/secrets/{secret_name}/repositories'
    ],
    removeSelectedRepoFromOrgSecret: [
      'DELETE /orgs/{org}/dependabot/secrets/{secret_name}/repositories/{repository_id}'
    ],
    setSelectedReposForOrgSecret: [
      'PUT /orgs/{org}/dependabot/secrets/{secret_name}/repositories'
    ],
    updateAlert: [
      'PATCH /repos/{owner}/{repo}/dependabot/alerts/{alert_number}'
    ]
  },
  dependencyGraph: {
    createRepositorySnapshot: [
      'POST /repos/{owner}/{repo}/dependency-graph/snapshots'
    ],
    diffRange: [
      'GET /repos/{owner}/{repo}/dependency-graph/compare/{basehead}'
    ],
    exportSbom: ['GET /repos/{owner}/{repo}/dependency-graph/sbom']
  },
  emojis: {
    get: ['GET /emojis']
  },
  gists: {
    checkIsStarred: ['GET /gists/{gist_id}/star'],
    create: ['POST /gists'],
    createComment: ['POST /gists/{gist_id}/comments'],
    delete: ['DELETE /gists/{gist_id}'],
    deleteComment: ['DELETE /gists/{gist_id}/comments/{comment_id}'],
    fork: ['POST /gists/{gist_id}/forks'],
    get: ['GET /gists/{gist_id}'],
    getComment: ['GET /gists/{gist_id}/comments/{comment_id}'],
    getRevision: ['GET /gists/{gist_id}/{sha}'],
    list: ['GET /gists'],
    listComments: ['GET /gists/{gist_id}/comments'],
    listCommits: ['GET /gists/{gist_id}/commits'],
    listForUser: ['GET /users/{username}/gists'],
    listForks: ['GET /gists/{gist_id}/forks'],
    listPublic: ['GET /gists/public'],
    listStarred: ['GET /gists/starred'],
    star: ['PUT /gists/{gist_id}/star'],
    unstar: ['DELETE /gists/{gist_id}/star'],
    update: ['PATCH /gists/{gist_id}'],
    updateComment: ['PATCH /gists/{gist_id}/comments/{comment_id}']
  },
  git: {
    createBlob: ['POST /repos/{owner}/{repo}/git/blobs'],
    createCommit: ['POST /repos/{owner}/{repo}/git/commits'],
    createRef: ['POST /repos/{owner}/{repo}/git/refs'],
    createTag: ['POST /repos/{owner}/{repo}/git/tags'],
    createTree: ['POST /repos/{owner}/{repo}/git/trees'],
    deleteRef: ['DELETE /repos/{owner}/{repo}/git/refs/{ref}'],
    getBlob: ['GET /repos/{owner}/{repo}/git/blobs/{file_sha}'],
    getCommit: ['GET /repos/{owner}/{repo}/git/commits/{commit_sha}'],
    getRef: ['GET /repos/{owner}/{repo}/git/ref/{ref}'],
    getTag: ['GET /repos/{owner}/{repo}/git/tags/{tag_sha}'],
    getTree: ['GET /repos/{owner}/{repo}/git/trees/{tree_sha}'],
    listMatchingRefs: ['GET /repos/{owner}/{repo}/git/matching-refs/{ref}'],
    updateRef: ['PATCH /repos/{owner}/{repo}/git/refs/{ref}']
  },
  gitignore: {
    getAllTemplates: ['GET /gitignore/templates'],
    getTemplate: ['GET /gitignore/templates/{name}']
  },
  hostedCompute: {
    createNetworkConfigurationForOrg: [
      'POST /orgs/{org}/settings/network-configurations'
    ],
    deleteNetworkConfigurationFromOrg: [
      'DELETE /orgs/{org}/settings/network-configurations/{network_configuration_id}'
    ],
    getNetworkConfigurationForOrg: [
      'GET /orgs/{org}/settings/network-configurations/{network_configuration_id}'
    ],
    getNetworkSettingsForOrg: [
      'GET /orgs/{org}/settings/network-settings/{network_settings_id}'
    ],
    listNetworkConfigurationsForOrg: [
      'GET /orgs/{org}/settings/network-configurations'
    ],
    updateNetworkConfigurationForOrg: [
      'PATCH /orgs/{org}/settings/network-configurations/{network_configuration_id}'
    ]
  },
  interactions: {
    getRestrictionsForAuthenticatedUser: ['GET /user/interaction-limits'],
    getRestrictionsForOrg: ['GET /orgs/{org}/interaction-limits'],
    getRestrictionsForRepo: ['GET /repos/{owner}/{repo}/interaction-limits'],
    getRestrictionsForYourPublicRepos: [
      'GET /user/interaction-limits',
      {},
      {
        renamed: ['interactions', 'getRestrictionsForAuthenticatedUser']
      }
    ],
    removeRestrictionsForAuthenticatedUser: ['DELETE /user/interaction-limits'],
    removeRestrictionsForOrg: ['DELETE /orgs/{org}/interaction-limits'],
    removeRestrictionsForRepo: [
      'DELETE /repos/{owner}/{repo}/interaction-limits'
    ],
    removeRestrictionsForYourPublicRepos: [
      'DELETE /user/interaction-limits',
      {},
      {
        renamed: ['interactions', 'removeRestrictionsForAuthenticatedUser']
      }
    ],
    setRestrictionsForAuthenticatedUser: ['PUT /user/interaction-limits'],
    setRestrictionsForOrg: ['PUT /orgs/{org}/interaction-limits'],
    setRestrictionsForRepo: ['PUT /repos/{owner}/{repo}/interaction-limits'],
    setRestrictionsForYourPublicRepos: [
      'PUT /user/interaction-limits',
      {},
      {
        renamed: ['interactions', 'setRestrictionsForAuthenticatedUser']
      }
    ]
  },
  issues: {
    addAssignees: [
      'POST /repos/{owner}/{repo}/issues/{issue_number}/assignees'
    ],
    addLabels: ['POST /repos/{owner}/{repo}/issues/{issue_number}/labels'],
    addSubIssue: [
      'POST /repos/{owner}/{repo}/issues/{issue_number}/sub_issues'
    ],
    checkUserCanBeAssigned: ['GET /repos/{owner}/{repo}/assignees/{assignee}'],
    checkUserCanBeAssignedToIssue: [
      'GET /repos/{owner}/{repo}/issues/{issue_number}/assignees/{assignee}'
    ],
    create: ['POST /repos/{owner}/{repo}/issues'],
    createComment: [
      'POST /repos/{owner}/{repo}/issues/{issue_number}/comments'
    ],
    createLabel: ['POST /repos/{owner}/{repo}/labels'],
    createMilestone: ['POST /repos/{owner}/{repo}/milestones'],
    deleteComment: [
      'DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}'
    ],
    deleteLabel: ['DELETE /repos/{owner}/{repo}/labels/{name}'],
    deleteMilestone: [
      'DELETE /repos/{owner}/{repo}/milestones/{milestone_number}'
    ],
    get: ['GET /repos/{owner}/{repo}/issues/{issue_number}'],
    getComment: ['GET /repos/{owner}/{repo}/issues/comments/{comment_id}'],
    getEvent: ['GET /repos/{owner}/{repo}/issues/events/{event_id}'],
    getLabel: ['GET /repos/{owner}/{repo}/labels/{name}'],
    getMilestone: ['GET /repos/{owner}/{repo}/milestones/{milestone_number}'],
    list: ['GET /issues'],
    listAssignees: ['GET /repos/{owner}/{repo}/assignees'],
    listComments: ['GET /repos/{owner}/{repo}/issues/{issue_number}/comments'],
    listCommentsForRepo: ['GET /repos/{owner}/{repo}/issues/comments'],
    listEvents: ['GET /repos/{owner}/{repo}/issues/{issue_number}/events'],
    listEventsForRepo: ['GET /repos/{owner}/{repo}/issues/events'],
    listEventsForTimeline: [
      'GET /repos/{owner}/{repo}/issues/{issue_number}/timeline'
    ],
    listForAuthenticatedUser: ['GET /user/issues'],
    listForOrg: ['GET /orgs/{org}/issues'],
    listForRepo: ['GET /repos/{owner}/{repo}/issues'],
    listLabelsForMilestone: [
      'GET /repos/{owner}/{repo}/milestones/{milestone_number}/labels'
    ],
    listLabelsForRepo: ['GET /repos/{owner}/{repo}/labels'],
    listLabelsOnIssue: [
      'GET /repos/{owner}/{repo}/issues/{issue_number}/labels'
    ],
    listMilestones: ['GET /repos/{owner}/{repo}/milestones'],
    listSubIssues: [
      'GET /repos/{owner}/{repo}/issues/{issue_number}/sub_issues'
    ],
    lock: ['PUT /repos/{owner}/{repo}/issues/{issue_number}/lock'],
    removeAllLabels: [
      'DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels'
    ],
    removeAssignees: [
      'DELETE /repos/{owner}/{repo}/issues/{issue_number}/assignees'
    ],
    removeLabel: [
      'DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels/{name}'
    ],
    removeSubIssue: [
      'DELETE /repos/{owner}/{repo}/issues/{issue_number}/sub_issue'
    ],
    reprioritizeSubIssue: [
      'PATCH /repos/{owner}/{repo}/issues/{issue_number}/sub_issues/priority'
    ],
    setLabels: ['PUT /repos/{owner}/{repo}/issues/{issue_number}/labels'],
    unlock: ['DELETE /repos/{owner}/{repo}/issues/{issue_number}/lock'],
    update: ['PATCH /repos/{owner}/{repo}/issues/{issue_number}'],
    updateComment: ['PATCH /repos/{owner}/{repo}/issues/comments/{comment_id}'],
    updateLabel: ['PATCH /repos/{owner}/{repo}/labels/{name}'],
    updateMilestone: [
      'PATCH /repos/{owner}/{repo}/milestones/{milestone_number}'
    ]
  },
  licenses: {
    get: ['GET /licenses/{license}'],
    getAllCommonlyUsed: ['GET /licenses'],
    getForRepo: ['GET /repos/{owner}/{repo}/license']
  },
  markdown: {
    render: ['POST /markdown'],
    renderRaw: [
      'POST /markdown/raw',
      {
        headers: {
          'content-type': 'text/plain; charset=utf-8'
        }
      }
    ]
  },
  meta: {
    get: ['GET /meta'],
    getAllVersions: ['GET /versions'],
    getOctocat: ['GET /octocat'],
    getZen: ['GET /zen'],
    root: ['GET /']
  },
  migrations: {
    deleteArchiveForAuthenticatedUser: [
      'DELETE /user/migrations/{migration_id}/archive'
    ],
    deleteArchiveForOrg: [
      'DELETE /orgs/{org}/migrations/{migration_id}/archive'
    ],
    downloadArchiveForOrg: [
      'GET /orgs/{org}/migrations/{migration_id}/archive'
    ],
    getArchiveForAuthenticatedUser: [
      'GET /user/migrations/{migration_id}/archive'
    ],
    getStatusForAuthenticatedUser: ['GET /user/migrations/{migration_id}'],
    getStatusForOrg: ['GET /orgs/{org}/migrations/{migration_id}'],
    listForAuthenticatedUser: ['GET /user/migrations'],
    listForOrg: ['GET /orgs/{org}/migrations'],
    listReposForAuthenticatedUser: [
      'GET /user/migrations/{migration_id}/repositories'
    ],
    listReposForOrg: ['GET /orgs/{org}/migrations/{migration_id}/repositories'],
    listReposForUser: [
      'GET /user/migrations/{migration_id}/repositories',
      {},
      {
        renamed: ['migrations', 'listReposForAuthenticatedUser']
      }
    ],
    startForAuthenticatedUser: ['POST /user/migrations'],
    startForOrg: ['POST /orgs/{org}/migrations'],
    unlockRepoForAuthenticatedUser: [
      'DELETE /user/migrations/{migration_id}/repos/{repo_name}/lock'
    ],
    unlockRepoForOrg: [
      'DELETE /orgs/{org}/migrations/{migration_id}/repos/{repo_name}/lock'
    ]
  },
  oidc: {
    getOidcCustomSubTemplateForOrg: [
      'GET /orgs/{org}/actions/oidc/customization/sub'
    ],
    updateOidcCustomSubTemplateForOrg: [
      'PUT /orgs/{org}/actions/oidc/customization/sub'
    ]
  },
  orgs: {
    addSecurityManagerTeam: [
      'PUT /orgs/{org}/security-managers/teams/{team_slug}',
      {},
      {
        deprecated:
          'octokit.rest.orgs.addSecurityManagerTeam() is deprecated, see https://docs.github.com/rest/orgs/security-managers#add-a-security-manager-team'
      }
    ],
    assignTeamToOrgRole: [
      'PUT /orgs/{org}/organization-roles/teams/{team_slug}/{role_id}'
    ],
    assignUserToOrgRole: [
      'PUT /orgs/{org}/organization-roles/users/{username}/{role_id}'
    ],
    blockUser: ['PUT /orgs/{org}/blocks/{username}'],
    cancelInvitation: ['DELETE /orgs/{org}/invitations/{invitation_id}'],
    checkBlockedUser: ['GET /orgs/{org}/blocks/{username}'],
    checkMembershipForUser: ['GET /orgs/{org}/members/{username}'],
    checkPublicMembershipForUser: ['GET /orgs/{org}/public_members/{username}'],
    convertMemberToOutsideCollaborator: [
      'PUT /orgs/{org}/outside_collaborators/{username}'
    ],
    createInvitation: ['POST /orgs/{org}/invitations'],
    createIssueType: ['POST /orgs/{org}/issue-types'],
    createOrUpdateCustomProperties: ['PATCH /orgs/{org}/properties/schema'],
    createOrUpdateCustomPropertiesValuesForRepos: [
      'PATCH /orgs/{org}/properties/values'
    ],
    createOrUpdateCustomProperty: [
      'PUT /orgs/{org}/properties/schema/{custom_property_name}'
    ],
    createWebhook: ['POST /orgs/{org}/hooks'],
    delete: ['DELETE /orgs/{org}'],
    deleteIssueType: ['DELETE /orgs/{org}/issue-types/{issue_type_id}'],
    deleteWebhook: ['DELETE /orgs/{org}/hooks/{hook_id}'],
    enableOrDisableSecurityProductOnAllOrgRepos: [
      'POST /orgs/{org}/{security_product}/{enablement}',
      {},
      {
        deprecated:
          'octokit.rest.orgs.enableOrDisableSecurityProductOnAllOrgRepos() is deprecated, see https://docs.github.com/rest/orgs/orgs#enable-or-disable-a-security-feature-for-an-organization'
      }
    ],
    get: ['GET /orgs/{org}'],
    getAllCustomProperties: ['GET /orgs/{org}/properties/schema'],
    getCustomProperty: [
      'GET /orgs/{org}/properties/schema/{custom_property_name}'
    ],
    getMembershipForAuthenticatedUser: ['GET /user/memberships/orgs/{org}'],
    getMembershipForUser: ['GET /orgs/{org}/memberships/{username}'],
    getOrgRole: ['GET /orgs/{org}/organization-roles/{role_id}'],
    getOrgRulesetHistory: ['GET /orgs/{org}/rulesets/{ruleset_id}/history'],
    getOrgRulesetVersion: [
      'GET /orgs/{org}/rulesets/{ruleset_id}/history/{version_id}'
    ],
    getWebhook: ['GET /orgs/{org}/hooks/{hook_id}'],
    getWebhookConfigForOrg: ['GET /orgs/{org}/hooks/{hook_id}/config'],
    getWebhookDelivery: [
      'GET /orgs/{org}/hooks/{hook_id}/deliveries/{delivery_id}'
    ],
    list: ['GET /organizations'],
    listAppInstallations: ['GET /orgs/{org}/installations'],
    listAttestations: ['GET /orgs/{org}/attestations/{subject_digest}'],
    listBlockedUsers: ['GET /orgs/{org}/blocks'],
    listCustomPropertiesValuesForRepos: ['GET /orgs/{org}/properties/values'],
    listFailedInvitations: ['GET /orgs/{org}/failed_invitations'],
    listForAuthenticatedUser: ['GET /user/orgs'],
    listForUser: ['GET /users/{username}/orgs'],
    listInvitationTeams: ['GET /orgs/{org}/invitations/{invitation_id}/teams'],
    listIssueTypes: ['GET /orgs/{org}/issue-types'],
    listMembers: ['GET /orgs/{org}/members'],
    listMembershipsForAuthenticatedUser: ['GET /user/memberships/orgs'],
    listOrgRoleTeams: ['GET /orgs/{org}/organization-roles/{role_id}/teams'],
    listOrgRoleUsers: ['GET /orgs/{org}/organization-roles/{role_id}/users'],
    listOrgRoles: ['GET /orgs/{org}/organization-roles'],
    listOrganizationFineGrainedPermissions: [
      'GET /orgs/{org}/organization-fine-grained-permissions'
    ],
    listOutsideCollaborators: ['GET /orgs/{org}/outside_collaborators'],
    listPatGrantRepositories: [
      'GET /orgs/{org}/personal-access-tokens/{pat_id}/repositories'
    ],
    listPatGrantRequestRepositories: [
      'GET /orgs/{org}/personal-access-token-requests/{pat_request_id}/repositories'
    ],
    listPatGrantRequests: ['GET /orgs/{org}/personal-access-token-requests'],
    listPatGrants: ['GET /orgs/{org}/personal-access-tokens'],
    listPendingInvitations: ['GET /orgs/{org}/invitations'],
    listPublicMembers: ['GET /orgs/{org}/public_members'],
    listSecurityManagerTeams: [
      'GET /orgs/{org}/security-managers',
      {},
      {
        deprecated:
          'octokit.rest.orgs.listSecurityManagerTeams() is deprecated, see https://docs.github.com/rest/orgs/security-managers#list-security-manager-teams'
      }
    ],
    listWebhookDeliveries: ['GET /orgs/{org}/hooks/{hook_id}/deliveries'],
    listWebhooks: ['GET /orgs/{org}/hooks'],
    pingWebhook: ['POST /orgs/{org}/hooks/{hook_id}/pings'],
    redeliverWebhookDelivery: [
      'POST /orgs/{org}/hooks/{hook_id}/deliveries/{delivery_id}/attempts'
    ],
    removeCustomProperty: [
      'DELETE /orgs/{org}/properties/schema/{custom_property_name}'
    ],
    removeMember: ['DELETE /orgs/{org}/members/{username}'],
    removeMembershipForUser: ['DELETE /orgs/{org}/memberships/{username}'],
    removeOutsideCollaborator: [
      'DELETE /orgs/{org}/outside_collaborators/{username}'
    ],
    removePublicMembershipForAuthenticatedUser: [
      'DELETE /orgs/{org}/public_members/{username}'
    ],
    removeSecurityManagerTeam: [
      'DELETE /orgs/{org}/security-managers/teams/{team_slug}',
      {},
      {
        deprecated:
          'octokit.rest.orgs.removeSecurityManagerTeam() is deprecated, see https://docs.github.com/rest/orgs/security-managers#remove-a-security-manager-team'
      }
    ],
    reviewPatGrantRequest: [
      'POST /orgs/{org}/personal-access-token-requests/{pat_request_id}'
    ],
    reviewPatGrantRequestsInBulk: [
      'POST /orgs/{org}/personal-access-token-requests'
    ],
    revokeAllOrgRolesTeam: [
      'DELETE /orgs/{org}/organization-roles/teams/{team_slug}'
    ],
    revokeAllOrgRolesUser: [
      'DELETE /orgs/{org}/organization-roles/users/{username}'
    ],
    revokeOrgRoleTeam: [
      'DELETE /orgs/{org}/organization-roles/teams/{team_slug}/{role_id}'
    ],
    revokeOrgRoleUser: [
      'DELETE /orgs/{org}/organization-roles/users/{username}/{role_id}'
    ],
    setMembershipForUser: ['PUT /orgs/{org}/memberships/{username}'],
    setPublicMembershipForAuthenticatedUser: [
      'PUT /orgs/{org}/public_members/{username}'
    ],
    unblockUser: ['DELETE /orgs/{org}/blocks/{username}'],
    update: ['PATCH /orgs/{org}'],
    updateIssueType: ['PUT /orgs/{org}/issue-types/{issue_type_id}'],
    updateMembershipForAuthenticatedUser: [
      'PATCH /user/memberships/orgs/{org}'
    ],
    updatePatAccess: ['POST /orgs/{org}/personal-access-tokens/{pat_id}'],
    updatePatAccesses: ['POST /orgs/{org}/personal-access-tokens'],
    updateWebhook: ['PATCH /orgs/{org}/hooks/{hook_id}'],
    updateWebhookConfigForOrg: ['PATCH /orgs/{org}/hooks/{hook_id}/config']
  },
  packages: {
    deletePackageForAuthenticatedUser: [
      'DELETE /user/packages/{package_type}/{package_name}'
    ],
    deletePackageForOrg: [
      'DELETE /orgs/{org}/packages/{package_type}/{package_name}'
    ],
    deletePackageForUser: [
      'DELETE /users/{username}/packages/{package_type}/{package_name}'
    ],
    deletePackageVersionForAuthenticatedUser: [
      'DELETE /user/packages/{package_type}/{package_name}/versions/{package_version_id}'
    ],
    deletePackageVersionForOrg: [
      'DELETE /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}'
    ],
    deletePackageVersionForUser: [
      'DELETE /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}'
    ],
    getAllPackageVersionsForAPackageOwnedByAnOrg: [
      'GET /orgs/{org}/packages/{package_type}/{package_name}/versions',
      {},
      {
        renamed: ['packages', 'getAllPackageVersionsForPackageOwnedByOrg']
      }
    ],
    getAllPackageVersionsForAPackageOwnedByTheAuthenticatedUser: [
      'GET /user/packages/{package_type}/{package_name}/versions',
      {},
      {
        renamed: [
          'packages',
          'getAllPackageVersionsForPackageOwnedByAuthenticatedUser'
        ]
      }
    ],
    getAllPackageVersionsForPackageOwnedByAuthenticatedUser: [
      'GET /user/packages/{package_type}/{package_name}/versions'
    ],
    getAllPackageVersionsForPackageOwnedByOrg: [
      'GET /orgs/{org}/packages/{package_type}/{package_name}/versions'
    ],
    getAllPackageVersionsForPackageOwnedByUser: [
      'GET /users/{username}/packages/{package_type}/{package_name}/versions'
    ],
    getPackageForAuthenticatedUser: [
      'GET /user/packages/{package_type}/{package_name}'
    ],
    getPackageForOrganization: [
      'GET /orgs/{org}/packages/{package_type}/{package_name}'
    ],
    getPackageForUser: [
      'GET /users/{username}/packages/{package_type}/{package_name}'
    ],
    getPackageVersionForAuthenticatedUser: [
      'GET /user/packages/{package_type}/{package_name}/versions/{package_version_id}'
    ],
    getPackageVersionForOrganization: [
      'GET /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}'
    ],
    getPackageVersionForUser: [
      'GET /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}'
    ],
    listDockerMigrationConflictingPackagesForAuthenticatedUser: [
      'GET /user/docker/conflicts'
    ],
    listDockerMigrationConflictingPackagesForOrganization: [
      'GET /orgs/{org}/docker/conflicts'
    ],
    listDockerMigrationConflictingPackagesForUser: [
      'GET /users/{username}/docker/conflicts'
    ],
    listPackagesForAuthenticatedUser: ['GET /user/packages'],
    listPackagesForOrganization: ['GET /orgs/{org}/packages'],
    listPackagesForUser: ['GET /users/{username}/packages'],
    restorePackageForAuthenticatedUser: [
      'POST /user/packages/{package_type}/{package_name}/restore{?token}'
    ],
    restorePackageForOrg: [
      'POST /orgs/{org}/packages/{package_type}/{package_name}/restore{?token}'
    ],
    restorePackageForUser: [
      'POST /users/{username}/packages/{package_type}/{package_name}/restore{?token}'
    ],
    restorePackageVersionForAuthenticatedUser: [
      'POST /user/packages/{package_type}/{package_name}/versions/{package_version_id}/restore'
    ],
    restorePackageVersionForOrg: [
      'POST /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}/restore'
    ],
    restorePackageVersionForUser: [
      'POST /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}/restore'
    ]
  },
  privateRegistries: {
    createOrgPrivateRegistry: ['POST /orgs/{org}/private-registries'],
    deleteOrgPrivateRegistry: [
      'DELETE /orgs/{org}/private-registries/{secret_name}'
    ],
    getOrgPrivateRegistry: ['GET /orgs/{org}/private-registries/{secret_name}'],
    getOrgPublicKey: ['GET /orgs/{org}/private-registries/public-key'],
    listOrgPrivateRegistries: ['GET /orgs/{org}/private-registries'],
    updateOrgPrivateRegistry: [
      'PATCH /orgs/{org}/private-registries/{secret_name}'
    ]
  },
  projects: {
    addCollaborator: [
      'PUT /projects/{project_id}/collaborators/{username}',
      {},
      {
        deprecated:
          'octokit.rest.projects.addCollaborator() is deprecated, see https://docs.github.com/rest/projects/collaborators#add-project-collaborator'
      }
    ],
    createCard: [
      'POST /projects/columns/{column_id}/cards',
      {},
      {
        deprecated:
          'octokit.rest.projects.createCard() is deprecated, see https://docs.github.com/rest/projects/cards#create-a-project-card'
      }
    ],
    createColumn: [
      'POST /projects/{project_id}/columns',
      {},
      {
        deprecated:
          'octokit.rest.projects.createColumn() is deprecated, see https://docs.github.com/rest/projects/columns#create-a-project-column'
      }
    ],
    createForAuthenticatedUser: [
      'POST /user/projects',
      {},
      {
        deprecated:
          'octokit.rest.projects.createForAuthenticatedUser() is deprecated, see https://docs.github.com/rest/projects/projects#create-a-user-project'
      }
    ],
    createForOrg: [
      'POST /orgs/{org}/projects',
      {},
      {
        deprecated:
          'octokit.rest.projects.createForOrg() is deprecated, see https://docs.github.com/rest/projects/projects#create-an-organization-project'
      }
    ],
    createForRepo: [
      'POST /repos/{owner}/{repo}/projects',
      {},
      {
        deprecated:
          'octokit.rest.projects.createForRepo() is deprecated, see https://docs.github.com/rest/projects/projects#create-a-repository-project'
      }
    ],
    delete: [
      'DELETE /projects/{project_id}',
      {},
      {
        deprecated:
          'octokit.rest.projects.delete() is deprecated, see https://docs.github.com/rest/projects/projects#delete-a-project'
      }
    ],
    deleteCard: [
      'DELETE /projects/columns/cards/{card_id}',
      {},
      {
        deprecated:
          'octokit.rest.projects.deleteCard() is deprecated, see https://docs.github.com/rest/projects/cards#delete-a-project-card'
      }
    ],
    deleteColumn: [
      'DELETE /projects/columns/{column_id}',
      {},
      {
        deprecated:
          'octokit.rest.projects.deleteColumn() is deprecated, see https://docs.github.com/rest/projects/columns#delete-a-project-column'
      }
    ],
    get: [
      'GET /projects/{project_id}',
      {},
      {
        deprecated:
          'octokit.rest.projects.get() is deprecated, see https://docs.github.com/rest/projects/projects#get-a-project'
      }
    ],
    getCard: [
      'GET /projects/columns/cards/{card_id}',
      {},
      {
        deprecated:
          'octokit.rest.projects.getCard() is deprecated, see https://docs.github.com/rest/projects/cards#get-a-project-card'
      }
    ],
    getColumn: [
      'GET /projects/columns/{column_id}',
      {},
      {
        deprecated:
          'octokit.rest.projects.getColumn() is deprecated, see https://docs.github.com/rest/projects/columns#get-a-project-column'
      }
    ],
    getPermissionForUser: [
      'GET /projects/{project_id}/collaborators/{username}/permission',
      {},
      {
        deprecated:
          'octokit.rest.projects.getPermissionForUser() is deprecated, see https://docs.github.com/rest/projects/collaborators#get-project-permission-for-a-user'
      }
    ],
    listCards: [
      'GET /projects/columns/{column_id}/cards',
      {},
      {
        deprecated:
          'octokit.rest.projects.listCards() is deprecated, see https://docs.github.com/rest/projects/cards#list-project-cards'
      }
    ],
    listCollaborators: [
      'GET /projects/{project_id}/collaborators',
      {},
      {
        deprecated:
          'octokit.rest.projects.listCollaborators() is deprecated, see https://docs.github.com/rest/projects/collaborators#list-project-collaborators'
      }
    ],
    listColumns: [
      'GET /projects/{project_id}/columns',
      {},
      {
        deprecated:
          'octokit.rest.projects.listColumns() is deprecated, see https://docs.github.com/rest/projects/columns#list-project-columns'
      }
    ],
    listForOrg: [
      'GET /orgs/{org}/projects',
      {},
      {
        deprecated:
          'octokit.rest.projects.listForOrg() is deprecated, see https://docs.github.com/rest/projects/projects#list-organization-projects'
      }
    ],
    listForRepo: [
      'GET /repos/{owner}/{repo}/projects',
      {},
      {
        deprecated:
          'octokit.rest.projects.listForRepo() is deprecated, see https://docs.github.com/rest/projects/projects#list-repository-projects'
      }
    ],
    listForUser: [
      'GET /users/{username}/projects',
      {},
      {
        deprecated:
          'octokit.rest.projects.listForUser() is deprecated, see https://docs.github.com/rest/projects/projects#list-user-projects'
      }
    ],
    moveCard: [
      'POST /projects/columns/cards/{card_id}/moves',
      {},
      {
        deprecated:
          'octokit.rest.projects.moveCard() is deprecated, see https://docs.github.com/rest/projects/cards#move-a-project-card'
      }
    ],
    moveColumn: [
      'POST /projects/columns/{column_id}/moves',
      {},
      {
        deprecated:
          'octokit.rest.projects.moveColumn() is deprecated, see https://docs.github.com/rest/projects/columns#move-a-project-column'
      }
    ],
    removeCollaborator: [
      'DELETE /projects/{project_id}/collaborators/{username}',
      {},
      {
        deprecated:
          'octokit.rest.projects.removeCollaborator() is deprecated, see https://docs.github.com/rest/projects/collaborators#remove-user-as-a-collaborator'
      }
    ],
    update: [
      'PATCH /projects/{project_id}',
      {},
      {
        deprecated:
          'octokit.rest.projects.update() is deprecated, see https://docs.github.com/rest/projects/projects#update-a-project'
      }
    ],
    updateCard: [
      'PATCH /projects/columns/cards/{card_id}',
      {},
      {
        deprecated:
          'octokit.rest.projects.updateCard() is deprecated, see https://docs.github.com/rest/projects/cards#update-an-existing-project-card'
      }
    ],
    updateColumn: [
      'PATCH /projects/columns/{column_id}',
      {},
      {
        deprecated:
          'octokit.rest.projects.updateColumn() is deprecated, see https://docs.github.com/rest/projects/columns#update-an-existing-project-column'
      }
    ]
  },
  pulls: {
    checkIfMerged: ['GET /repos/{owner}/{repo}/pulls/{pull_number}/merge'],
    create: ['POST /repos/{owner}/{repo}/pulls'],
    createReplyForReviewComment: [
      'POST /repos/{owner}/{repo}/pulls/{pull_number}/comments/{comment_id}/replies'
    ],
    createReview: ['POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews'],
    createReviewComment: [
      'POST /repos/{owner}/{repo}/pulls/{pull_number}/comments'
    ],
    deletePendingReview: [
      'DELETE /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}'
    ],
    deleteReviewComment: [
      'DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}'
    ],
    dismissReview: [
      'PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/dismissals'
    ],
    get: ['GET /repos/{owner}/{repo}/pulls/{pull_number}'],
    getReview: [
      'GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}'
    ],
    getReviewComment: ['GET /repos/{owner}/{repo}/pulls/comments/{comment_id}'],
    list: ['GET /repos/{owner}/{repo}/pulls'],
    listCommentsForReview: [
      'GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/comments'
    ],
    listCommits: ['GET /repos/{owner}/{repo}/pulls/{pull_number}/commits'],
    listFiles: ['GET /repos/{owner}/{repo}/pulls/{pull_number}/files'],
    listRequestedReviewers: [
      'GET /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers'
    ],
    listReviewComments: [
      'GET /repos/{owner}/{repo}/pulls/{pull_number}/comments'
    ],
    listReviewCommentsForRepo: ['GET /repos/{owner}/{repo}/pulls/comments'],
    listReviews: ['GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews'],
    merge: ['PUT /repos/{owner}/{repo}/pulls/{pull_number}/merge'],
    removeRequestedReviewers: [
      'DELETE /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers'
    ],
    requestReviewers: [
      'POST /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers'
    ],
    submitReview: [
      'POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/events'
    ],
    update: ['PATCH /repos/{owner}/{repo}/pulls/{pull_number}'],
    updateBranch: [
      'PUT /repos/{owner}/{repo}/pulls/{pull_number}/update-branch'
    ],
    updateReview: [
      'PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}'
    ],
    updateReviewComment: [
      'PATCH /repos/{owner}/{repo}/pulls/comments/{comment_id}'
    ]
  },
  rateLimit: {
    get: ['GET /rate_limit']
  },
  reactions: {
    createForCommitComment: [
      'POST /repos/{owner}/{repo}/comments/{comment_id}/reactions'
    ],
    createForIssue: [
      'POST /repos/{owner}/{repo}/issues/{issue_number}/reactions'
    ],
    createForIssueComment: [
      'POST /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions'
    ],
    createForPullRequestReviewComment: [
      'POST /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions'
    ],
    createForRelease: [
      'POST /repos/{owner}/{repo}/releases/{release_id}/reactions'
    ],
    createForTeamDiscussionCommentInOrg: [
      'POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions'
    ],
    createForTeamDiscussionInOrg: [
      'POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions'
    ],
    deleteForCommitComment: [
      'DELETE /repos/{owner}/{repo}/comments/{comment_id}/reactions/{reaction_id}'
    ],
    deleteForIssue: [
      'DELETE /repos/{owner}/{repo}/issues/{issue_number}/reactions/{reaction_id}'
    ],
    deleteForIssueComment: [
      'DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions/{reaction_id}'
    ],
    deleteForPullRequestComment: [
      'DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions/{reaction_id}'
    ],
    deleteForRelease: [
      'DELETE /repos/{owner}/{repo}/releases/{release_id}/reactions/{reaction_id}'
    ],
    deleteForTeamDiscussion: [
      'DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions/{reaction_id}'
    ],
    deleteForTeamDiscussionComment: [
      'DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions/{reaction_id}'
    ],
    listForCommitComment: [
      'GET /repos/{owner}/{repo}/comments/{comment_id}/reactions'
    ],
    listForIssue: ['GET /repos/{owner}/{repo}/issues/{issue_number}/reactions'],
    listForIssueComment: [
      'GET /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions'
    ],
    listForPullRequestReviewComment: [
      'GET /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions'
    ],
    listForRelease: [
      'GET /repos/{owner}/{repo}/releases/{release_id}/reactions'
    ],
    listForTeamDiscussionCommentInOrg: [
      'GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions'
    ],
    listForTeamDiscussionInOrg: [
      'GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions'
    ]
  },
  repos: {
    acceptInvitation: [
      'PATCH /user/repository_invitations/{invitation_id}',
      {},
      {
        renamed: ['repos', 'acceptInvitationForAuthenticatedUser']
      }
    ],
    acceptInvitationForAuthenticatedUser: [
      'PATCH /user/repository_invitations/{invitation_id}'
    ],
    addAppAccessRestrictions: [
      'POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps',
      {},
      {
        mapToData: 'apps'
      }
    ],
    addCollaborator: ['PUT /repos/{owner}/{repo}/collaborators/{username}'],
    addStatusCheckContexts: [
      'POST /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts',
      {},
      {
        mapToData: 'contexts'
      }
    ],
    addTeamAccessRestrictions: [
      'POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams',
      {},
      {
        mapToData: 'teams'
      }
    ],
    addUserAccessRestrictions: [
      'POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users',
      {},
      {
        mapToData: 'users'
      }
    ],
    cancelPagesDeployment: [
      'POST /repos/{owner}/{repo}/pages/deployments/{pages_deployment_id}/cancel'
    ],
    checkAutomatedSecurityFixes: [
      'GET /repos/{owner}/{repo}/automated-security-fixes'
    ],
    checkCollaborator: ['GET /repos/{owner}/{repo}/collaborators/{username}'],
    checkPrivateVulnerabilityReporting: [
      'GET /repos/{owner}/{repo}/private-vulnerability-reporting'
    ],
    checkVulnerabilityAlerts: [
      'GET /repos/{owner}/{repo}/vulnerability-alerts'
    ],
    codeownersErrors: ['GET /repos/{owner}/{repo}/codeowners/errors'],
    compareCommits: ['GET /repos/{owner}/{repo}/compare/{base}...{head}'],
    compareCommitsWithBasehead: [
      'GET /repos/{owner}/{repo}/compare/{basehead}'
    ],
    createAttestation: ['POST /repos/{owner}/{repo}/attestations'],
    createAutolink: ['POST /repos/{owner}/{repo}/autolinks'],
    createCommitComment: [
      'POST /repos/{owner}/{repo}/commits/{commit_sha}/comments'
    ],
    createCommitSignatureProtection: [
      'POST /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures'
    ],
    createCommitStatus: ['POST /repos/{owner}/{repo}/statuses/{sha}'],
    createDeployKey: ['POST /repos/{owner}/{repo}/keys'],
    createDeployment: ['POST /repos/{owner}/{repo}/deployments'],
    createDeploymentBranchPolicy: [
      'POST /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies'
    ],
    createDeploymentProtectionRule: [
      'POST /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules'
    ],
    createDeploymentStatus: [
      'POST /repos/{owner}/{repo}/deployments/{deployment_id}/statuses'
    ],
    createDispatchEvent: ['POST /repos/{owner}/{repo}/dispatches'],
    createForAuthenticatedUser: ['POST /user/repos'],
    createFork: ['POST /repos/{owner}/{repo}/forks'],
    createInOrg: ['POST /orgs/{org}/repos'],
    createOrUpdateCustomPropertiesValues: [
      'PATCH /repos/{owner}/{repo}/properties/values'
    ],
    createOrUpdateEnvironment: [
      'PUT /repos/{owner}/{repo}/environments/{environment_name}'
    ],
    createOrUpdateFileContents: ['PUT /repos/{owner}/{repo}/contents/{path}'],
    createOrgRuleset: ['POST /orgs/{org}/rulesets'],
    createPagesDeployment: ['POST /repos/{owner}/{repo}/pages/deployments'],
    createPagesSite: ['POST /repos/{owner}/{repo}/pages'],
    createRelease: ['POST /repos/{owner}/{repo}/releases'],
    createRepoRuleset: ['POST /repos/{owner}/{repo}/rulesets'],
    createUsingTemplate: [
      'POST /repos/{template_owner}/{template_repo}/generate'
    ],
    createWebhook: ['POST /repos/{owner}/{repo}/hooks'],
    declineInvitation: [
      'DELETE /user/repository_invitations/{invitation_id}',
      {},
      {
        renamed: ['repos', 'declineInvitationForAuthenticatedUser']
      }
    ],
    declineInvitationForAuthenticatedUser: [
      'DELETE /user/repository_invitations/{invitation_id}'
    ],
    delete: ['DELETE /repos/{owner}/{repo}'],
    deleteAccessRestrictions: [
      'DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions'
    ],
    deleteAdminBranchProtection: [
      'DELETE /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins'
    ],
    deleteAnEnvironment: [
      'DELETE /repos/{owner}/{repo}/environments/{environment_name}'
    ],
    deleteAutolink: ['DELETE /repos/{owner}/{repo}/autolinks/{autolink_id}'],
    deleteBranchProtection: [
      'DELETE /repos/{owner}/{repo}/branches/{branch}/protection'
    ],
    deleteCommitComment: ['DELETE /repos/{owner}/{repo}/comments/{comment_id}'],
    deleteCommitSignatureProtection: [
      'DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures'
    ],
    deleteDeployKey: ['DELETE /repos/{owner}/{repo}/keys/{key_id}'],
    deleteDeployment: [
      'DELETE /repos/{owner}/{repo}/deployments/{deployment_id}'
    ],
    deleteDeploymentBranchPolicy: [
      'DELETE /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}'
    ],
    deleteFile: ['DELETE /repos/{owner}/{repo}/contents/{path}'],
    deleteInvitation: [
      'DELETE /repos/{owner}/{repo}/invitations/{invitation_id}'
    ],
    deleteOrgRuleset: ['DELETE /orgs/{org}/rulesets/{ruleset_id}'],
    deletePagesSite: ['DELETE /repos/{owner}/{repo}/pages'],
    deletePullRequestReviewProtection: [
      'DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews'
    ],
    deleteRelease: ['DELETE /repos/{owner}/{repo}/releases/{release_id}'],
    deleteReleaseAsset: [
      'DELETE /repos/{owner}/{repo}/releases/assets/{asset_id}'
    ],
    deleteRepoRuleset: ['DELETE /repos/{owner}/{repo}/rulesets/{ruleset_id}'],
    deleteWebhook: ['DELETE /repos/{owner}/{repo}/hooks/{hook_id}'],
    disableAutomatedSecurityFixes: [
      'DELETE /repos/{owner}/{repo}/automated-security-fixes'
    ],
    disableDeploymentProtectionRule: [
      'DELETE /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/{protection_rule_id}'
    ],
    disablePrivateVulnerabilityReporting: [
      'DELETE /repos/{owner}/{repo}/private-vulnerability-reporting'
    ],
    disableVulnerabilityAlerts: [
      'DELETE /repos/{owner}/{repo}/vulnerability-alerts'
    ],
    downloadArchive: [
      'GET /repos/{owner}/{repo}/zipball/{ref}',
      {},
      {
        renamed: ['repos', 'downloadZipballArchive']
      }
    ],
    downloadTarballArchive: ['GET /repos/{owner}/{repo}/tarball/{ref}'],
    downloadZipballArchive: ['GET /repos/{owner}/{repo}/zipball/{ref}'],
    enableAutomatedSecurityFixes: [
      'PUT /repos/{owner}/{repo}/automated-security-fixes'
    ],
    enablePrivateVulnerabilityReporting: [
      'PUT /repos/{owner}/{repo}/private-vulnerability-reporting'
    ],
    enableVulnerabilityAlerts: [
      'PUT /repos/{owner}/{repo}/vulnerability-alerts'
    ],
    generateReleaseNotes: [
      'POST /repos/{owner}/{repo}/releases/generate-notes'
    ],
    get: ['GET /repos/{owner}/{repo}'],
    getAccessRestrictions: [
      'GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions'
    ],
    getAdminBranchProtection: [
      'GET /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins'
    ],
    getAllDeploymentProtectionRules: [
      'GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules'
    ],
    getAllEnvironments: ['GET /repos/{owner}/{repo}/environments'],
    getAllStatusCheckContexts: [
      'GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts'
    ],
    getAllTopics: ['GET /repos/{owner}/{repo}/topics'],
    getAppsWithAccessToProtectedBranch: [
      'GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps'
    ],
    getAutolink: ['GET /repos/{owner}/{repo}/autolinks/{autolink_id}'],
    getBranch: ['GET /repos/{owner}/{repo}/branches/{branch}'],
    getBranchProtection: [
      'GET /repos/{owner}/{repo}/branches/{branch}/protection'
    ],
    getBranchRules: ['GET /repos/{owner}/{repo}/rules/branches/{branch}'],
    getClones: ['GET /repos/{owner}/{repo}/traffic/clones'],
    getCodeFrequencyStats: ['GET /repos/{owner}/{repo}/stats/code_frequency'],
    getCollaboratorPermissionLevel: [
      'GET /repos/{owner}/{repo}/collaborators/{username}/permission'
    ],
    getCombinedStatusForRef: ['GET /repos/{owner}/{repo}/commits/{ref}/status'],
    getCommit: ['GET /repos/{owner}/{repo}/commits/{ref}'],
    getCommitActivityStats: ['GET /repos/{owner}/{repo}/stats/commit_activity'],
    getCommitComment: ['GET /repos/{owner}/{repo}/comments/{comment_id}'],
    getCommitSignatureProtection: [
      'GET /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures'
    ],
    getCommunityProfileMetrics: ['GET /repos/{owner}/{repo}/community/profile'],
    getContent: ['GET /repos/{owner}/{repo}/contents/{path}'],
    getContributorsStats: ['GET /repos/{owner}/{repo}/stats/contributors'],
    getCustomDeploymentProtectionRule: [
      'GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/{protection_rule_id}'
    ],
    getCustomPropertiesValues: ['GET /repos/{owner}/{repo}/properties/values'],
    getDeployKey: ['GET /repos/{owner}/{repo}/keys/{key_id}'],
    getDeployment: ['GET /repos/{owner}/{repo}/deployments/{deployment_id}'],
    getDeploymentBranchPolicy: [
      'GET /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}'
    ],
    getDeploymentStatus: [
      'GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses/{status_id}'
    ],
    getEnvironment: [
      'GET /repos/{owner}/{repo}/environments/{environment_name}'
    ],
    getLatestPagesBuild: ['GET /repos/{owner}/{repo}/pages/builds/latest'],
    getLatestRelease: ['GET /repos/{owner}/{repo}/releases/latest'],
    getOrgRuleSuite: ['GET /orgs/{org}/rulesets/rule-suites/{rule_suite_id}'],
    getOrgRuleSuites: ['GET /orgs/{org}/rulesets/rule-suites'],
    getOrgRuleset: ['GET /orgs/{org}/rulesets/{ruleset_id}'],
    getOrgRulesets: ['GET /orgs/{org}/rulesets'],
    getPages: ['GET /repos/{owner}/{repo}/pages'],
    getPagesBuild: ['GET /repos/{owner}/{repo}/pages/builds/{build_id}'],
    getPagesDeployment: [
      'GET /repos/{owner}/{repo}/pages/deployments/{pages_deployment_id}'
    ],
    getPagesHealthCheck: ['GET /repos/{owner}/{repo}/pages/health'],
    getParticipationStats: ['GET /repos/{owner}/{repo}/stats/participation'],
    getPullRequestReviewProtection: [
      'GET /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews'
    ],
    getPunchCardStats: ['GET /repos/{owner}/{repo}/stats/punch_card'],
    getReadme: ['GET /repos/{owner}/{repo}/readme'],
    getReadmeInDirectory: ['GET /repos/{owner}/{repo}/readme/{dir}'],
    getRelease: ['GET /repos/{owner}/{repo}/releases/{release_id}'],
    getReleaseAsset: ['GET /repos/{owner}/{repo}/releases/assets/{asset_id}'],
    getReleaseByTag: ['GET /repos/{owner}/{repo}/releases/tags/{tag}'],
    getRepoRuleSuite: [
      'GET /repos/{owner}/{repo}/rulesets/rule-suites/{rule_suite_id}'
    ],
    getRepoRuleSuites: ['GET /repos/{owner}/{repo}/rulesets/rule-suites'],
    getRepoRuleset: ['GET /repos/{owner}/{repo}/rulesets/{ruleset_id}'],
    getRepoRulesetHistory: [
      'GET /repos/{owner}/{repo}/rulesets/{ruleset_id}/history'
    ],
    getRepoRulesetVersion: [
      'GET /repos/{owner}/{repo}/rulesets/{ruleset_id}/history/{version_id}'
    ],
    getRepoRulesets: ['GET /repos/{owner}/{repo}/rulesets'],
    getStatusChecksProtection: [
      'GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks'
    ],
    getTeamsWithAccessToProtectedBranch: [
      'GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams'
    ],
    getTopPaths: ['GET /repos/{owner}/{repo}/traffic/popular/paths'],
    getTopReferrers: ['GET /repos/{owner}/{repo}/traffic/popular/referrers'],
    getUsersWithAccessToProtectedBranch: [
      'GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users'
    ],
    getViews: ['GET /repos/{owner}/{repo}/traffic/views'],
    getWebhook: ['GET /repos/{owner}/{repo}/hooks/{hook_id}'],
    getWebhookConfigForRepo: [
      'GET /repos/{owner}/{repo}/hooks/{hook_id}/config'
    ],
    getWebhookDelivery: [
      'GET /repos/{owner}/{repo}/hooks/{hook_id}/deliveries/{delivery_id}'
    ],
    listActivities: ['GET /repos/{owner}/{repo}/activity'],
    listAttestations: [
      'GET /repos/{owner}/{repo}/attestations/{subject_digest}'
    ],
    listAutolinks: ['GET /repos/{owner}/{repo}/autolinks'],
    listBranches: ['GET /repos/{owner}/{repo}/branches'],
    listBranchesForHeadCommit: [
      'GET /repos/{owner}/{repo}/commits/{commit_sha}/branches-where-head'
    ],
    listCollaborators: ['GET /repos/{owner}/{repo}/collaborators'],
    listCommentsForCommit: [
      'GET /repos/{owner}/{repo}/commits/{commit_sha}/comments'
    ],
    listCommitCommentsForRepo: ['GET /repos/{owner}/{repo}/comments'],
    listCommitStatusesForRef: [
      'GET /repos/{owner}/{repo}/commits/{ref}/statuses'
    ],
    listCommits: ['GET /repos/{owner}/{repo}/commits'],
    listContributors: ['GET /repos/{owner}/{repo}/contributors'],
    listCustomDeploymentRuleIntegrations: [
      'GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/apps'
    ],
    listDeployKeys: ['GET /repos/{owner}/{repo}/keys'],
    listDeploymentBranchPolicies: [
      'GET /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies'
    ],
    listDeploymentStatuses: [
      'GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses'
    ],
    listDeployments: ['GET /repos/{owner}/{repo}/deployments'],
    listForAuthenticatedUser: ['GET /user/repos'],
    listForOrg: ['GET /orgs/{org}/repos'],
    listForUser: ['GET /users/{username}/repos'],
    listForks: ['GET /repos/{owner}/{repo}/forks'],
    listInvitations: ['GET /repos/{owner}/{repo}/invitations'],
    listInvitationsForAuthenticatedUser: ['GET /user/repository_invitations'],
    listLanguages: ['GET /repos/{owner}/{repo}/languages'],
    listPagesBuilds: ['GET /repos/{owner}/{repo}/pages/builds'],
    listPublic: ['GET /repositories'],
    listPullRequestsAssociatedWithCommit: [
      'GET /repos/{owner}/{repo}/commits/{commit_sha}/pulls'
    ],
    listReleaseAssets: [
      'GET /repos/{owner}/{repo}/releases/{release_id}/assets'
    ],
    listReleases: ['GET /repos/{owner}/{repo}/releases'],
    listTags: ['GET /repos/{owner}/{repo}/tags'],
    listTeams: ['GET /repos/{owner}/{repo}/teams'],
    listWebhookDeliveries: [
      'GET /repos/{owner}/{repo}/hooks/{hook_id}/deliveries'
    ],
    listWebhooks: ['GET /repos/{owner}/{repo}/hooks'],
    merge: ['POST /repos/{owner}/{repo}/merges'],
    mergeUpstream: ['POST /repos/{owner}/{repo}/merge-upstream'],
    pingWebhook: ['POST /repos/{owner}/{repo}/hooks/{hook_id}/pings'],
    redeliverWebhookDelivery: [
      'POST /repos/{owner}/{repo}/hooks/{hook_id}/deliveries/{delivery_id}/attempts'
    ],
    removeAppAccessRestrictions: [
      'DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps',
      {},
      {
        mapToData: 'apps'
      }
    ],
    removeCollaborator: [
      'DELETE /repos/{owner}/{repo}/collaborators/{username}'
    ],
    removeStatusCheckContexts: [
      'DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts',
      {},
      {
        mapToData: 'contexts'
      }
    ],
    removeStatusCheckProtection: [
      'DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks'
    ],
    removeTeamAccessRestrictions: [
      'DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams',
      {},
      {
        mapToData: 'teams'
      }
    ],
    removeUserAccessRestrictions: [
      'DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users',
      {},
      {
        mapToData: 'users'
      }
    ],
    renameBranch: ['POST /repos/{owner}/{repo}/branches/{branch}/rename'],
    replaceAllTopics: ['PUT /repos/{owner}/{repo}/topics'],
    requestPagesBuild: ['POST /repos/{owner}/{repo}/pages/builds'],
    setAdminBranchProtection: [
      'POST /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins'
    ],
    setAppAccessRestrictions: [
      'PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps',
      {},
      {
        mapToData: 'apps'
      }
    ],
    setStatusCheckContexts: [
      'PUT /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts',
      {},
      {
        mapToData: 'contexts'
      }
    ],
    setTeamAccessRestrictions: [
      'PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams',
      {},
      {
        mapToData: 'teams'
      }
    ],
    setUserAccessRestrictions: [
      'PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users',
      {},
      {
        mapToData: 'users'
      }
    ],
    testPushWebhook: ['POST /repos/{owner}/{repo}/hooks/{hook_id}/tests'],
    transfer: ['POST /repos/{owner}/{repo}/transfer'],
    update: ['PATCH /repos/{owner}/{repo}'],
    updateBranchProtection: [
      'PUT /repos/{owner}/{repo}/branches/{branch}/protection'
    ],
    updateCommitComment: ['PATCH /repos/{owner}/{repo}/comments/{comment_id}'],
    updateDeploymentBranchPolicy: [
      'PUT /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}'
    ],
    updateInformationAboutPagesSite: ['PUT /repos/{owner}/{repo}/pages'],
    updateInvitation: [
      'PATCH /repos/{owner}/{repo}/invitations/{invitation_id}'
    ],
    updateOrgRuleset: ['PUT /orgs/{org}/rulesets/{ruleset_id}'],
    updatePullRequestReviewProtection: [
      'PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews'
    ],
    updateRelease: ['PATCH /repos/{owner}/{repo}/releases/{release_id}'],
    updateReleaseAsset: [
      'PATCH /repos/{owner}/{repo}/releases/assets/{asset_id}'
    ],
    updateRepoRuleset: ['PUT /repos/{owner}/{repo}/rulesets/{ruleset_id}'],
    updateStatusCheckPotection: [
      'PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks',
      {},
      {
        renamed: ['repos', 'updateStatusCheckProtection']
      }
    ],
    updateStatusCheckProtection: [
      'PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks'
    ],
    updateWebhook: ['PATCH /repos/{owner}/{repo}/hooks/{hook_id}'],
    updateWebhookConfigForRepo: [
      'PATCH /repos/{owner}/{repo}/hooks/{hook_id}/config'
    ],
    uploadReleaseAsset: [
      'POST /repos/{owner}/{repo}/releases/{release_id}/assets{?name,label}',
      {
        baseUrl: 'https://uploads.github.com'
      }
    ]
  },
  search: {
    code: ['GET /search/code'],
    commits: ['GET /search/commits'],
    issuesAndPullRequests: [
      'GET /search/issues',
      {},
      {
        deprecated:
          'octokit.rest.search.issuesAndPullRequests() is deprecated, see https://docs.github.com/rest/search/search#search-issues-and-pull-requests'
      }
    ],
    labels: ['GET /search/labels'],
    repos: ['GET /search/repositories'],
    topics: ['GET /search/topics'],
    users: ['GET /search/users']
  },
  secretScanning: {
    createPushProtectionBypass: [
      'POST /repos/{owner}/{repo}/secret-scanning/push-protection-bypasses'
    ],
    getAlert: [
      'GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}'
    ],
    getScanHistory: ['GET /repos/{owner}/{repo}/secret-scanning/scan-history'],
    listAlertsForEnterprise: [
      'GET /enterprises/{enterprise}/secret-scanning/alerts'
    ],
    listAlertsForOrg: ['GET /orgs/{org}/secret-scanning/alerts'],
    listAlertsForRepo: ['GET /repos/{owner}/{repo}/secret-scanning/alerts'],
    listLocationsForAlert: [
      'GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}/locations'
    ],
    updateAlert: [
      'PATCH /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}'
    ]
  },
  securityAdvisories: {
    createFork: [
      'POST /repos/{owner}/{repo}/security-advisories/{ghsa_id}/forks'
    ],
    createPrivateVulnerabilityReport: [
      'POST /repos/{owner}/{repo}/security-advisories/reports'
    ],
    createRepositoryAdvisory: [
      'POST /repos/{owner}/{repo}/security-advisories'
    ],
    createRepositoryAdvisoryCveRequest: [
      'POST /repos/{owner}/{repo}/security-advisories/{ghsa_id}/cve'
    ],
    getGlobalAdvisory: ['GET /advisories/{ghsa_id}'],
    getRepositoryAdvisory: [
      'GET /repos/{owner}/{repo}/security-advisories/{ghsa_id}'
    ],
    listGlobalAdvisories: ['GET /advisories'],
    listOrgRepositoryAdvisories: ['GET /orgs/{org}/security-advisories'],
    listRepositoryAdvisories: ['GET /repos/{owner}/{repo}/security-advisories'],
    updateRepositoryAdvisory: [
      'PATCH /repos/{owner}/{repo}/security-advisories/{ghsa_id}'
    ]
  },
  teams: {
    addOrUpdateMembershipForUserInOrg: [
      'PUT /orgs/{org}/teams/{team_slug}/memberships/{username}'
    ],
    addOrUpdateProjectPermissionsInOrg: [
      'PUT /orgs/{org}/teams/{team_slug}/projects/{project_id}',
      {},
      {
        deprecated:
          'octokit.rest.teams.addOrUpdateProjectPermissionsInOrg() is deprecated, see https://docs.github.com/rest/teams/teams#add-or-update-team-project-permissions'
      }
    ],
    addOrUpdateProjectPermissionsLegacy: [
      'PUT /teams/{team_id}/projects/{project_id}',
      {},
      {
        deprecated:
          'octokit.rest.teams.addOrUpdateProjectPermissionsLegacy() is deprecated, see https://docs.github.com/rest/teams/teams#add-or-update-team-project-permissions-legacy'
      }
    ],
    addOrUpdateRepoPermissionsInOrg: [
      'PUT /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}'
    ],
    checkPermissionsForProjectInOrg: [
      'GET /orgs/{org}/teams/{team_slug}/projects/{project_id}',
      {},
      {
        deprecated:
          'octokit.rest.teams.checkPermissionsForProjectInOrg() is deprecated, see https://docs.github.com/rest/teams/teams#check-team-permissions-for-a-project'
      }
    ],
    checkPermissionsForProjectLegacy: [
      'GET /teams/{team_id}/projects/{project_id}',
      {},
      {
        deprecated:
          'octokit.rest.teams.checkPermissionsForProjectLegacy() is deprecated, see https://docs.github.com/rest/teams/teams#check-team-permissions-for-a-project-legacy'
      }
    ],
    checkPermissionsForRepoInOrg: [
      'GET /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}'
    ],
    create: ['POST /orgs/{org}/teams'],
    createDiscussionCommentInOrg: [
      'POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments'
    ],
    createDiscussionInOrg: ['POST /orgs/{org}/teams/{team_slug}/discussions'],
    deleteDiscussionCommentInOrg: [
      'DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}'
    ],
    deleteDiscussionInOrg: [
      'DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}'
    ],
    deleteInOrg: ['DELETE /orgs/{org}/teams/{team_slug}'],
    getByName: ['GET /orgs/{org}/teams/{team_slug}'],
    getDiscussionCommentInOrg: [
      'GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}'
    ],
    getDiscussionInOrg: [
      'GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}'
    ],
    getMembershipForUserInOrg: [
      'GET /orgs/{org}/teams/{team_slug}/memberships/{username}'
    ],
    list: ['GET /orgs/{org}/teams'],
    listChildInOrg: ['GET /orgs/{org}/teams/{team_slug}/teams'],
    listDiscussionCommentsInOrg: [
      'GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments'
    ],
    listDiscussionsInOrg: ['GET /orgs/{org}/teams/{team_slug}/discussions'],
    listForAuthenticatedUser: ['GET /user/teams'],
    listMembersInOrg: ['GET /orgs/{org}/teams/{team_slug}/members'],
    listPendingInvitationsInOrg: [
      'GET /orgs/{org}/teams/{team_slug}/invitations'
    ],
    listProjectsInOrg: [
      'GET /orgs/{org}/teams/{team_slug}/projects',
      {},
      {
        deprecated:
          'octokit.rest.teams.listProjectsInOrg() is deprecated, see https://docs.github.com/rest/teams/teams#list-team-projects'
      }
    ],
    listProjectsLegacy: [
      'GET /teams/{team_id}/projects',
      {},
      {
        deprecated:
          'octokit.rest.teams.listProjectsLegacy() is deprecated, see https://docs.github.com/rest/teams/teams#list-team-projects-legacy'
      }
    ],
    listReposInOrg: ['GET /orgs/{org}/teams/{team_slug}/repos'],
    removeMembershipForUserInOrg: [
      'DELETE /orgs/{org}/teams/{team_slug}/memberships/{username}'
    ],
    removeProjectInOrg: [
      'DELETE /orgs/{org}/teams/{team_slug}/projects/{project_id}',
      {},
      {
        deprecated:
          'octokit.rest.teams.removeProjectInOrg() is deprecated, see https://docs.github.com/rest/teams/teams#remove-a-project-from-a-team'
      }
    ],
    removeProjectLegacy: [
      'DELETE /teams/{team_id}/projects/{project_id}',
      {},
      {
        deprecated:
          'octokit.rest.teams.removeProjectLegacy() is deprecated, see https://docs.github.com/rest/teams/teams#remove-a-project-from-a-team-legacy'
      }
    ],
    removeRepoInOrg: [
      'DELETE /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}'
    ],
    updateDiscussionCommentInOrg: [
      'PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}'
    ],
    updateDiscussionInOrg: [
      'PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}'
    ],
    updateInOrg: ['PATCH /orgs/{org}/teams/{team_slug}']
  },
  users: {
    addEmailForAuthenticated: [
      'POST /user/emails',
      {},
      {
        renamed: ['users', 'addEmailForAuthenticatedUser']
      }
    ],
    addEmailForAuthenticatedUser: ['POST /user/emails'],
    addSocialAccountForAuthenticatedUser: ['POST /user/social_accounts'],
    block: ['PUT /user/blocks/{username}'],
    checkBlocked: ['GET /user/blocks/{username}'],
    checkFollowingForUser: ['GET /users/{username}/following/{target_user}'],
    checkPersonIsFollowedByAuthenticated: ['GET /user/following/{username}'],
    createGpgKeyForAuthenticated: [
      'POST /user/gpg_keys',
      {},
      {
        renamed: ['users', 'createGpgKeyForAuthenticatedUser']
      }
    ],
    createGpgKeyForAuthenticatedUser: ['POST /user/gpg_keys'],
    createPublicSshKeyForAuthenticated: [
      'POST /user/keys',
      {},
      {
        renamed: ['users', 'createPublicSshKeyForAuthenticatedUser']
      }
    ],
    createPublicSshKeyForAuthenticatedUser: ['POST /user/keys'],
    createSshSigningKeyForAuthenticatedUser: ['POST /user/ssh_signing_keys'],
    deleteEmailForAuthenticated: [
      'DELETE /user/emails',
      {},
      {
        renamed: ['users', 'deleteEmailForAuthenticatedUser']
      }
    ],
    deleteEmailForAuthenticatedUser: ['DELETE /user/emails'],
    deleteGpgKeyForAuthenticated: [
      'DELETE /user/gpg_keys/{gpg_key_id}',
      {},
      {
        renamed: ['users', 'deleteGpgKeyForAuthenticatedUser']
      }
    ],
    deleteGpgKeyForAuthenticatedUser: ['DELETE /user/gpg_keys/{gpg_key_id}'],
    deletePublicSshKeyForAuthenticated: [
      'DELETE /user/keys/{key_id}',
      {},
      {
        renamed: ['users', 'deletePublicSshKeyForAuthenticatedUser']
      }
    ],
    deletePublicSshKeyForAuthenticatedUser: ['DELETE /user/keys/{key_id}'],
    deleteSocialAccountForAuthenticatedUser: ['DELETE /user/social_accounts'],
    deleteSshSigningKeyForAuthenticatedUser: [
      'DELETE /user/ssh_signing_keys/{ssh_signing_key_id}'
    ],
    follow: ['PUT /user/following/{username}'],
    getAuthenticated: ['GET /user'],
    getById: ['GET /user/{account_id}'],
    getByUsername: ['GET /users/{username}'],
    getContextForUser: ['GET /users/{username}/hovercard'],
    getGpgKeyForAuthenticated: [
      'GET /user/gpg_keys/{gpg_key_id}',
      {},
      {
        renamed: ['users', 'getGpgKeyForAuthenticatedUser']
      }
    ],
    getGpgKeyForAuthenticatedUser: ['GET /user/gpg_keys/{gpg_key_id}'],
    getPublicSshKeyForAuthenticated: [
      'GET /user/keys/{key_id}',
      {},
      {
        renamed: ['users', 'getPublicSshKeyForAuthenticatedUser']
      }
    ],
    getPublicSshKeyForAuthenticatedUser: ['GET /user/keys/{key_id}'],
    getSshSigningKeyForAuthenticatedUser: [
      'GET /user/ssh_signing_keys/{ssh_signing_key_id}'
    ],
    list: ['GET /users'],
    listAttestations: ['GET /users/{username}/attestations/{subject_digest}'],
    listBlockedByAuthenticated: [
      'GET /user/blocks',
      {},
      {
        renamed: ['users', 'listBlockedByAuthenticatedUser']
      }
    ],
    listBlockedByAuthenticatedUser: ['GET /user/blocks'],
    listEmailsForAuthenticated: [
      'GET /user/emails',
      {},
      {
        renamed: ['users', 'listEmailsForAuthenticatedUser']
      }
    ],
    listEmailsForAuthenticatedUser: ['GET /user/emails'],
    listFollowedByAuthenticated: [
      'GET /user/following',
      {},
      {
        renamed: ['users', 'listFollowedByAuthenticatedUser']
      }
    ],
    listFollowedByAuthenticatedUser: ['GET /user/following'],
    listFollowersForAuthenticatedUser: ['GET /user/followers'],
    listFollowersForUser: ['GET /users/{username}/followers'],
    listFollowingForUser: ['GET /users/{username}/following'],
    listGpgKeysForAuthenticated: [
      'GET /user/gpg_keys',
      {},
      {
        renamed: ['users', 'listGpgKeysForAuthenticatedUser']
      }
    ],
    listGpgKeysForAuthenticatedUser: ['GET /user/gpg_keys'],
    listGpgKeysForUser: ['GET /users/{username}/gpg_keys'],
    listPublicEmailsForAuthenticated: [
      'GET /user/public_emails',
      {},
      {
        renamed: ['users', 'listPublicEmailsForAuthenticatedUser']
      }
    ],
    listPublicEmailsForAuthenticatedUser: ['GET /user/public_emails'],
    listPublicKeysForUser: ['GET /users/{username}/keys'],
    listPublicSshKeysForAuthenticated: [
      'GET /user/keys',
      {},
      {
        renamed: ['users', 'listPublicSshKeysForAuthenticatedUser']
      }
    ],
    listPublicSshKeysForAuthenticatedUser: ['GET /user/keys'],
    listSocialAccountsForAuthenticatedUser: ['GET /user/social_accounts'],
    listSocialAccountsForUser: ['GET /users/{username}/social_accounts'],
    listSshSigningKeysForAuthenticatedUser: ['GET /user/ssh_signing_keys'],
    listSshSigningKeysForUser: ['GET /users/{username}/ssh_signing_keys'],
    setPrimaryEmailVisibilityForAuthenticated: [
      'PATCH /user/email/visibility',
      {},
      {
        renamed: ['users', 'setPrimaryEmailVisibilityForAuthenticatedUser']
      }
    ],
    setPrimaryEmailVisibilityForAuthenticatedUser: [
      'PATCH /user/email/visibility'
    ],
    unblock: ['DELETE /user/blocks/{username}'],
    unfollow: ['DELETE /user/following/{username}'],
    updateAuthenticated: ['PATCH /user']
  }
}
const endpoints_default = Endpoints

const endpointMethodsMap = /* @__PURE__ */ new Map()
for (const [scope, endpoints] of Object.entries(endpoints_default)) {
  for (const [methodName, endpoint] of Object.entries(endpoints)) {
    const [route, defaults, decorations] = endpoint
    const [method, url] = route.split(/ /)
    const endpointDefaults = Object.assign(
      {
        method,
        url
      },
      defaults
    )
    if (!endpointMethodsMap.has(scope)) {
      endpointMethodsMap.set(scope, /* @__PURE__ */ new Map())
    }
    endpointMethodsMap.get(scope).set(methodName, {
      scope,
      methodName,
      endpointDefaults,
      decorations
    })
  }
}
const handler = {
  has({ scope }, methodName) {
    return endpointMethodsMap.get(scope).has(methodName)
  },
  getOwnPropertyDescriptor(target, methodName) {
    return {
      value: this.get(target, methodName),
      // ensures method is in the cache
      configurable: true,
      writable: true,
      enumerable: true
    }
  },
  defineProperty(target, methodName, descriptor) {
    Object.defineProperty(target.cache, methodName, descriptor)
    return true
  },
  deleteProperty(target, methodName) {
    delete target.cache[methodName]
    return true
  },
  ownKeys({ scope }) {
    return [...endpointMethodsMap.get(scope).keys()]
  },
  set(target, methodName, value) {
    return (target.cache[methodName] = value)
  },
  get({ octokit, scope, cache }, methodName) {
    if (cache[methodName]) {
      return cache[methodName]
    }
    const method = endpointMethodsMap.get(scope).get(methodName)
    if (!method) {
      return void 0
    }
    const { endpointDefaults, decorations } = method
    if (decorations) {
      cache[methodName] = decorate(
        octokit,
        scope,
        methodName,
        endpointDefaults,
        decorations
      )
    } else {
      cache[methodName] = octokit.request.defaults(endpointDefaults)
    }
    return cache[methodName]
  }
}
function endpointsToMethods(octokit) {
  const newMethods = {}
  for (const scope of endpointMethodsMap.keys()) {
    newMethods[scope] = new Proxy(
      {
        octokit,
        scope,
        cache: {}
      },
      handler
    )
  }
  return newMethods
}
function decorate(octokit, scope, methodName, defaults, decorations) {
  const requestWithDefaults = octokit.request.defaults(defaults)
  function withDecorations(...args) {
    let options = requestWithDefaults.endpoint.merge(...args)
    if (decorations.mapToData) {
      options = Object.assign({}, options, {
        data: options[decorations.mapToData],
        [decorations.mapToData]: void 0
      })
      return requestWithDefaults(options)
    }
    if (decorations.renamed) {
      const [newScope, newMethodName] = decorations.renamed
      octokit.log.warn(
        `octokit.${scope}.${methodName}() has been renamed to octokit.${newScope}.${newMethodName}()`
      )
    }
    if (decorations.deprecated) {
      octokit.log.warn(decorations.deprecated)
    }
    if (decorations.renamedParameters) {
      const options2 = requestWithDefaults.endpoint.merge(...args)
      for (const [name, alias] of Object.entries(
        decorations.renamedParameters
      )) {
        if (name in options2) {
          octokit.log.warn(
            `"${name}" parameter is deprecated for "octokit.${scope}.${methodName}()". Use "${alias}" instead`
          )
          if (!(alias in options2)) {
            options2[alias] = options2[name]
          }
          delete options2[name]
        }
      }
      return requestWithDefaults(options2)
    }
    return requestWithDefaults(...args)
  }
  return Object.assign(withDecorations, requestWithDefaults)
}

function legacyRestEndpointMethods(octokit) {
  const api = endpointsToMethods(octokit)
  return {
    ...api,
    rest: api
  }
}
legacyRestEndpointMethods.VERSION = VERSION$1

const VERSION = '21.1.1'

const Octokit = Octokit$1.plugin(
  requestLog,
  legacyRestEndpointMethods,
  paginateRest
).defaults({
  userAgent: `octokit-rest.js/${VERSION}`
})

let indentString
let hasRequiredIndentString

function requireIndentString() {
  if (hasRequiredIndentString) {
    return indentString
  }
  hasRequiredIndentString = 1

  indentString = function indentString(string, count = 1, options) {
    const { includeEmptyLines = false, indent = ' ' } = {
      __proto__: null,
      ...options
    }
    if (typeof string !== 'string') {
      throw new TypeError(
        `Expected \`input\` to be a \`string\`, got \`${typeof string}\``
      )
    }
    if (typeof count !== 'number') {
      throw new TypeError(
        `Expected \`count\` to be a \`number\`, got \`${typeof count}\``
      )
    }
    if (count < 0) {
      throw new RangeError(
        `Expected \`count\` to be at least 0, got \`${count}\``
      )
    }
    if (typeof indent !== 'string') {
      throw new TypeError(
        `Expected \`options.indent\` to be a \`string\`, got \`${typeof indent}\``
      )
    }
    if (count === 0) {
      return string
    }
    const regex = includeEmptyLines ? /^/gm : /^(?!\s*$)/gm
    return string.replace(regex, indent.repeat(count))
  }
  return indentString
}

const indentStringExports = /*@__PURE__*/ requireIndentString()

const npa = { exports: {} }

const commonjs$1 = {}

let hasRequiredCommonjs$1
function requireCommonjs$1() {
  if (hasRequiredCommonjs$1) {
    return commonjs$1
  }
  hasRequiredCommonjs$1 = 1
  /**
   * @module LRUCache
   */
  Object.defineProperty(commonjs$1, '__esModule', {
    value: true
  })
  commonjs$1.LRUCache = void 0
  const perf =
    typeof performance === 'object' &&
    performance &&
    typeof performance.now === 'function'
      ? performance
      : Date
  const warned = new Set()
  /* c8 ignore start */
  const PROCESS = typeof process === 'object' && !!process ? process : {}
  /* c8 ignore start */
  const emitWarning = (msg, type, code, fn) => {
    typeof PROCESS.emitWarning === 'function'
      ? PROCESS.emitWarning(msg, type, code, fn)
      : console.error(`[${code}] ${type}: ${msg}`)
  }
  let AC = globalThis.AbortController
  let AS = globalThis.AbortSignal
  /* c8 ignore start */
  if (typeof AC === 'undefined') {
    //@ts-ignore
    AS = class AbortSignal {
      onabort
      _onabort = []
      reason
      aborted = false
      addEventListener(_, fn) {
        this._onabort.push(fn)
      }
    }
    //@ts-ignore
    AC = class AbortController {
      constructor() {
        warnACPolyfill()
      }
      signal = new AS()
      abort(reason) {
        if (this.signal.aborted) {
          return
        }
        //@ts-ignore
        this.signal.reason = reason
        //@ts-ignore
        this.signal.aborted = true
        //@ts-ignore
        for (const fn of this.signal._onabort) {
          fn(reason)
        }
        this.signal.onabort?.(reason)
      }
    }
    let printACPolyfillWarning =
      PROCESS.env?.LRU_CACHE_IGNORE_AC_WARNING !== '1'
    const warnACPolyfill = () => {
      if (!printACPolyfillWarning) {
        return
      }
      printACPolyfillWarning = false
      emitWarning(
        'AbortController is not defined. If using lru-cache in ' +
          'node 14, load an AbortController polyfill from the ' +
          '`node-abort-controller` package. A minimal polyfill is ' +
          'provided for use by LRUCache.fetch(), but it should not be ' +
          'relied upon in other contexts (eg, passing it to other APIs that ' +
          'use AbortController/AbortSignal might have undesirable effects). ' +
          'You may disable this with LRU_CACHE_IGNORE_AC_WARNING=1 in the env.',
        'NO_ABORT_CONTROLLER',
        'ENOTSUP',
        warnACPolyfill
      )
    }
  }
  /* c8 ignore stop */
  const shouldWarn = code => !warned.has(code)
  const isPosInt = n => n && n === Math.floor(n) && n > 0 && isFinite(n)
  /* c8 ignore start */
  // This is a little bit ridiculous, tbh.
  // The maximum array length is 2^32-1 or thereabouts on most JS impls.
  // And well before that point, you're caching the entire world, I mean,
  // that's ~32GB of just integers for the next/prev links, plus whatever
  // else to hold that many keys and values.  Just filling the memory with
  // zeroes at init time is brutal when you get that big.
  // But why not be complete?
  // Maybe in the future, these limits will have expanded.
  const getUintArray = max =>
    !isPosInt(max)
      ? null
      : max <= Math.pow(2, 8)
        ? Uint8Array
        : max <= Math.pow(2, 16)
          ? Uint16Array
          : max <= Math.pow(2, 32)
            ? Uint32Array
            : max <= Number.MAX_SAFE_INTEGER
              ? ZeroArray
              : null
  /* c8 ignore stop */
  class ZeroArray extends Array {
    constructor(size) {
      super(size)
      this.fill(0)
    }
  }
  class Stack {
    heap
    length
    // private constructor
    static #constructing = false
    static create(max) {
      const HeapCls = getUintArray(max)
      if (!HeapCls) {
        return []
      }
      Stack.#constructing = true
      const s = new Stack(max, HeapCls)
      Stack.#constructing = false
      return s
    }
    constructor(max, HeapCls) {
      /* c8 ignore start */
      if (!Stack.#constructing) {
        throw new TypeError('instantiate Stack using Stack.create(n)')
      }
      /* c8 ignore stop */
      this.heap = new HeapCls(max)
      this.length = 0
    }
    push(n) {
      this.heap[this.length++] = n
    }
    pop() {
      return this.heap[--this.length]
    }
  }
  /**
   * Default export, the thing you're using this module to get.
   *
   * The `K` and `V` types define the key and value types, respectively. The
   * optional `FC` type defines the type of the `context` object passed to
   * `cache.fetch()` and `cache.memo()`.
   *
   * Keys and values **must not** be `null` or `undefined`.
   *
   * All properties from the options object (with the exception of `max`,
   * `maxSize`, `fetchMethod`, `memoMethod`, `dispose` and `disposeAfter`) are
   * added as normal public members. (The listed options are read-only getters.)
   *
   * Changing any of these will alter the defaults for subsequent method calls.
   */
  class LRUCache {
    // options that cannot be changed without disaster
    #max
    #maxSize
    #dispose
    #disposeAfter
    #fetchMethod
    #memoMethod
    /**
     * {@link LRUCache.OptionsBase.ttl}
     */
    ttl
    /**
     * {@link LRUCache.OptionsBase.ttlResolution}
     */
    ttlResolution
    /**
     * {@link LRUCache.OptionsBase.ttlAutopurge}
     */
    ttlAutopurge
    /**
     * {@link LRUCache.OptionsBase.updateAgeOnGet}
     */
    updateAgeOnGet
    /**
     * {@link LRUCache.OptionsBase.updateAgeOnHas}
     */
    updateAgeOnHas
    /**
     * {@link LRUCache.OptionsBase.allowStale}
     */
    allowStale
    /**
     * {@link LRUCache.OptionsBase.noDisposeOnSet}
     */
    noDisposeOnSet
    /**
     * {@link LRUCache.OptionsBase.noUpdateTTL}
     */
    noUpdateTTL
    /**
     * {@link LRUCache.OptionsBase.maxEntrySize}
     */
    maxEntrySize
    /**
     * {@link LRUCache.OptionsBase.sizeCalculation}
     */
    sizeCalculation
    /**
     * {@link LRUCache.OptionsBase.noDeleteOnFetchRejection}
     */
    noDeleteOnFetchRejection
    /**
     * {@link LRUCache.OptionsBase.noDeleteOnStaleGet}
     */
    noDeleteOnStaleGet
    /**
     * {@link LRUCache.OptionsBase.allowStaleOnFetchAbort}
     */
    allowStaleOnFetchAbort
    /**
     * {@link LRUCache.OptionsBase.allowStaleOnFetchRejection}
     */
    allowStaleOnFetchRejection
    /**
     * {@link LRUCache.OptionsBase.ignoreFetchAbort}
     */
    ignoreFetchAbort
    // computed properties
    #size
    #calculatedSize
    #keyMap
    #keyList
    #valList
    #next
    #prev
    #head
    #tail
    #free
    #disposed
    #sizes
    #starts
    #ttls
    #hasDispose
    #hasFetchMethod
    #hasDisposeAfter
    /**
     * Do not call this method unless you need to inspect the
     * inner workings of the cache.  If anything returned by this
     * object is modified in any way, strange breakage may occur.
     *
     * These fields are private for a reason!
     *
     * @internal
     */
    static unsafeExposeInternals(c) {
      return {
        // properties
        starts: c.#starts,
        ttls: c.#ttls,
        sizes: c.#sizes,
        keyMap: c.#keyMap,
        keyList: c.#keyList,
        valList: c.#valList,
        next: c.#next,
        prev: c.#prev,
        get head() {
          return c.#head
        },
        get tail() {
          return c.#tail
        },
        free: c.#free,
        // methods
        isBackgroundFetch: p => c.#isBackgroundFetch(p),
        backgroundFetch: (k, index, options, context) =>
          c.#backgroundFetch(k, index, options, context),
        moveToTail: index => c.#moveToTail(index),
        indexes: options => c.#indexes(options),
        rindexes: options => c.#rindexes(options),
        isStale: index => c.#isStale(index)
      }
    }
    // Protected read-only members
    /**
     * {@link LRUCache.OptionsBase.max} (read-only)
     */
    get max() {
      return this.#max
    }
    /**
     * {@link LRUCache.OptionsBase.maxSize} (read-only)
     */
    get maxSize() {
      return this.#maxSize
    }
    /**
     * The total computed size of items in the cache (read-only)
     */
    get calculatedSize() {
      return this.#calculatedSize
    }
    /**
     * The number of items stored in the cache (read-only)
     */
    get size() {
      return this.#size
    }
    /**
     * {@link LRUCache.OptionsBase.fetchMethod} (read-only)
     */
    get fetchMethod() {
      return this.#fetchMethod
    }
    get memoMethod() {
      return this.#memoMethod
    }
    /**
     * {@link LRUCache.OptionsBase.dispose} (read-only)
     */
    get dispose() {
      return this.#dispose
    }
    /**
     * {@link LRUCache.OptionsBase.disposeAfter} (read-only)
     */
    get disposeAfter() {
      return this.#disposeAfter
    }
    constructor(options) {
      const {
        max = 0,
        ttl,
        ttlResolution = 1,
        ttlAutopurge,
        updateAgeOnGet,
        updateAgeOnHas,
        allowStale,
        dispose,
        disposeAfter,
        noDisposeOnSet,
        noUpdateTTL,
        maxSize = 0,
        maxEntrySize = 0,
        sizeCalculation,
        fetchMethod,
        memoMethod,
        noDeleteOnFetchRejection,
        noDeleteOnStaleGet,
        allowStaleOnFetchRejection,
        allowStaleOnFetchAbort,
        ignoreFetchAbort
      } = options
      if (max !== 0 && !isPosInt(max)) {
        throw new TypeError('max option must be a nonnegative integer')
      }
      const UintArray = max ? getUintArray(max) : Array
      if (!UintArray) {
        throw new Error('invalid max value: ' + max)
      }
      this.#max = max
      this.#maxSize = maxSize
      this.maxEntrySize = maxEntrySize || this.#maxSize
      this.sizeCalculation = sizeCalculation
      if (this.sizeCalculation) {
        if (!this.#maxSize && !this.maxEntrySize) {
          throw new TypeError(
            'cannot set sizeCalculation without setting maxSize or maxEntrySize'
          )
        }
        if (typeof this.sizeCalculation !== 'function') {
          throw new TypeError('sizeCalculation set to non-function')
        }
      }
      if (memoMethod !== undefined && typeof memoMethod !== 'function') {
        throw new TypeError('memoMethod must be a function if defined')
      }
      this.#memoMethod = memoMethod
      if (fetchMethod !== undefined && typeof fetchMethod !== 'function') {
        throw new TypeError('fetchMethod must be a function if specified')
      }
      this.#fetchMethod = fetchMethod
      this.#hasFetchMethod = !!fetchMethod
      this.#keyMap = new Map()
      this.#keyList = new Array(max).fill(undefined)
      this.#valList = new Array(max).fill(undefined)
      this.#next = new UintArray(max)
      this.#prev = new UintArray(max)
      this.#head = 0
      this.#tail = 0
      this.#free = Stack.create(max)
      this.#size = 0
      this.#calculatedSize = 0
      if (typeof dispose === 'function') {
        this.#dispose = dispose
      }
      if (typeof disposeAfter === 'function') {
        this.#disposeAfter = disposeAfter
        this.#disposed = []
      } else {
        this.#disposeAfter = undefined
        this.#disposed = undefined
      }
      this.#hasDispose = !!this.#dispose
      this.#hasDisposeAfter = !!this.#disposeAfter
      this.noDisposeOnSet = !!noDisposeOnSet
      this.noUpdateTTL = !!noUpdateTTL
      this.noDeleteOnFetchRejection = !!noDeleteOnFetchRejection
      this.allowStaleOnFetchRejection = !!allowStaleOnFetchRejection
      this.allowStaleOnFetchAbort = !!allowStaleOnFetchAbort
      this.ignoreFetchAbort = !!ignoreFetchAbort
      // NB: maxEntrySize is set to maxSize if it's set
      if (this.maxEntrySize !== 0) {
        if (this.#maxSize !== 0) {
          if (!isPosInt(this.#maxSize)) {
            throw new TypeError(
              'maxSize must be a positive integer if specified'
            )
          }
        }
        if (!isPosInt(this.maxEntrySize)) {
          throw new TypeError(
            'maxEntrySize must be a positive integer if specified'
          )
        }
        this.#initializeSizeTracking()
      }
      this.allowStale = !!allowStale
      this.noDeleteOnStaleGet = !!noDeleteOnStaleGet
      this.updateAgeOnGet = !!updateAgeOnGet
      this.updateAgeOnHas = !!updateAgeOnHas
      this.ttlResolution =
        isPosInt(ttlResolution) || ttlResolution === 0 ? ttlResolution : 1
      this.ttlAutopurge = !!ttlAutopurge
      this.ttl = ttl || 0
      if (this.ttl) {
        if (!isPosInt(this.ttl)) {
          throw new TypeError('ttl must be a positive integer if specified')
        }
        this.#initializeTTLTracking()
      }
      // do not allow completely unbounded caches
      if (this.#max === 0 && this.ttl === 0 && this.#maxSize === 0) {
        throw new TypeError('At least one of max, maxSize, or ttl is required')
      }
      if (!this.ttlAutopurge && !this.#max && !this.#maxSize) {
        const code = 'LRU_CACHE_UNBOUNDED'
        if (shouldWarn(code)) {
          warned.add(code)
          const msg =
            'TTL caching without ttlAutopurge, max, or maxSize can ' +
            'result in unbounded memory consumption.'
          emitWarning(msg, 'UnboundedCacheWarning', code, LRUCache)
        }
      }
    }
    /**
     * Return the number of ms left in the item's TTL. If item is not in cache,
     * returns `0`. Returns `Infinity` if item is in cache without a defined TTL.
     */
    getRemainingTTL(key) {
      return this.#keyMap.has(key) ? Infinity : 0
    }
    #initializeTTLTracking() {
      const ttls = new ZeroArray(this.#max)
      const starts = new ZeroArray(this.#max)
      this.#ttls = ttls
      this.#starts = starts
      this.#setItemTTL = (index, ttl, start = perf.now()) => {
        starts[index] = ttl !== 0 ? start : 0
        ttls[index] = ttl
        if (ttl !== 0 && this.ttlAutopurge) {
          const t = setTimeout(() => {
            if (this.#isStale(index)) {
              this.#delete(this.#keyList[index], 'expire')
            }
          }, ttl + 1)
          // unref() not supported on all platforms
          /* c8 ignore start */
          if (t.unref) {
            t.unref()
          }
          /* c8 ignore stop */
        }
      }
      this.#updateItemAge = index => {
        starts[index] = ttls[index] !== 0 ? perf.now() : 0
      }
      this.#statusTTL = (status, index) => {
        if (ttls[index]) {
          const ttl = ttls[index]
          const start = starts[index]
          /* c8 ignore next */
          if (!ttl || !start) {
            return
          }
          status.ttl = ttl
          status.start = start
          status.now = cachedNow || getNow()
          const age = status.now - start
          status.remainingTTL = ttl - age
        }
      }
      // debounce calls to perf.now() to 1s so we're not hitting
      // that costly call repeatedly.
      let cachedNow = 0
      const getNow = () => {
        const n = perf.now()
        if (this.ttlResolution > 0) {
          cachedNow = n
          const t = setTimeout(() => (cachedNow = 0), this.ttlResolution)
          // not available on all platforms
          /* c8 ignore start */
          if (t.unref) {
            t.unref()
          }
          /* c8 ignore stop */
        }
        return n
      }
      this.getRemainingTTL = key => {
        const index = this.#keyMap.get(key)
        if (index === undefined) {
          return 0
        }
        const ttl = ttls[index]
        const start = starts[index]
        if (!ttl || !start) {
          return Infinity
        }
        const age = (cachedNow || getNow()) - start
        return ttl - age
      }
      this.#isStale = index => {
        const s = starts[index]
        const t = ttls[index]
        return !!t && !!s && (cachedNow || getNow()) - s > t
      }
    }
    // conditionally set private methods related to TTL
    #updateItemAge = () => {}
    #statusTTL = () => {}
    #setItemTTL = () => {}
    /* c8 ignore stop */
    #isStale = () => false
    #initializeSizeTracking() {
      const sizes = new ZeroArray(this.#max)
      this.#calculatedSize = 0
      this.#sizes = sizes
      this.#removeItemSize = index => {
        this.#calculatedSize -= sizes[index]
        sizes[index] = 0
      }
      this.#requireSize = (k, v, size, sizeCalculation) => {
        // provisionally accept background fetches.
        // actual value size will be checked when they return.
        if (this.#isBackgroundFetch(v)) {
          return 0
        }
        if (!isPosInt(size)) {
          if (sizeCalculation) {
            if (typeof sizeCalculation !== 'function') {
              throw new TypeError('sizeCalculation must be a function')
            }
            size = sizeCalculation(v, k)
            if (!isPosInt(size)) {
              throw new TypeError(
                'sizeCalculation return invalid (expect positive integer)'
              )
            }
          } else {
            throw new TypeError(
              'invalid size value (must be positive integer). ' +
                'When maxSize or maxEntrySize is used, sizeCalculation ' +
                'or size must be set.'
            )
          }
        }
        return size
      }
      this.#addItemSize = (index, size, status) => {
        sizes[index] = size
        if (this.#maxSize) {
          const maxSize = this.#maxSize - sizes[index]
          while (this.#calculatedSize > maxSize) {
            this.#evict(true)
          }
        }
        this.#calculatedSize += sizes[index]
        if (status) {
          status.entrySize = size
          status.totalCalculatedSize = this.#calculatedSize
        }
      }
    }
    #removeItemSize = _i => {}
    #addItemSize = (_i, _s, _st) => {}
    #requireSize = (_k, _v, size, sizeCalculation) => {
      if (size || sizeCalculation) {
        throw new TypeError(
          'cannot set size without setting maxSize or maxEntrySize on cache'
        )
      }
      return 0
    };
    *#indexes({ allowStale = this.allowStale } = {}) {
      if (this.#size) {
        for (let i = this.#tail; true; ) {
          if (!this.#isValidIndex(i)) {
            break
          }
          if (allowStale || !this.#isStale(i)) {
            yield i
          }
          if (i === this.#head) {
            break
          } else {
            i = this.#prev[i]
          }
        }
      }
    }
    *#rindexes({ allowStale = this.allowStale } = {}) {
      if (this.#size) {
        for (let i = this.#head; true; ) {
          if (!this.#isValidIndex(i)) {
            break
          }
          if (allowStale || !this.#isStale(i)) {
            yield i
          }
          if (i === this.#tail) {
            break
          } else {
            i = this.#next[i]
          }
        }
      }
    }
    #isValidIndex(index) {
      return (
        index !== undefined && this.#keyMap.get(this.#keyList[index]) === index
      )
    }
    /**
     * Return a generator yielding `[key, value]` pairs,
     * in order from most recently used to least recently used.
     */
    *entries() {
      for (const i of this.#indexes()) {
        if (
          this.#valList[i] !== undefined &&
          this.#keyList[i] !== undefined &&
          !this.#isBackgroundFetch(this.#valList[i])
        ) {
          yield [this.#keyList[i], this.#valList[i]]
        }
      }
    }
    /**
     * Inverse order version of {@link LRUCache.entries}
     *
     * Return a generator yielding `[key, value]` pairs,
     * in order from least recently used to most recently used.
     */
    *rentries() {
      for (const i of this.#rindexes()) {
        if (
          this.#valList[i] !== undefined &&
          this.#keyList[i] !== undefined &&
          !this.#isBackgroundFetch(this.#valList[i])
        ) {
          yield [this.#keyList[i], this.#valList[i]]
        }
      }
    }
    /**
     * Return a generator yielding the keys in the cache,
     * in order from most recently used to least recently used.
     */
    *keys() {
      for (const i of this.#indexes()) {
        const k = this.#keyList[i]
        if (k !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
          yield k
        }
      }
    }
    /**
     * Inverse order version of {@link LRUCache.keys}
     *
     * Return a generator yielding the keys in the cache,
     * in order from least recently used to most recently used.
     */
    *rkeys() {
      for (const i of this.#rindexes()) {
        const k = this.#keyList[i]
        if (k !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
          yield k
        }
      }
    }
    /**
     * Return a generator yielding the values in the cache,
     * in order from most recently used to least recently used.
     */
    *values() {
      for (const i of this.#indexes()) {
        const v = this.#valList[i]
        if (v !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
          yield this.#valList[i]
        }
      }
    }
    /**
     * Inverse order version of {@link LRUCache.values}
     *
     * Return a generator yielding the values in the cache,
     * in order from least recently used to most recently used.
     */
    *rvalues() {
      for (const i of this.#rindexes()) {
        const v = this.#valList[i]
        if (v !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
          yield this.#valList[i]
        }
      }
    }
    /**
     * Iterating over the cache itself yields the same results as
     * {@link LRUCache.entries}
     */
    [Symbol.iterator]() {
      return this.entries()
    }
    /**
     * A String value that is used in the creation of the default string
     * description of an object. Called by the built-in method
     * `Object.prototype.toString`.
     */
    [Symbol.toStringTag] = 'LRUCache'
    /**
     * Find a value for which the supplied fn method returns a truthy value,
     * similar to `Array.find()`. fn is called as `fn(value, key, cache)`.
     */
    find(fn, getOptions = {}) {
      for (const i of this.#indexes()) {
        const v = this.#valList[i]
        const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
        if (value === undefined) {
          continue
        }
        if (fn(value, this.#keyList[i], this)) {
          return this.get(this.#keyList[i], getOptions)
        }
      }
    }
    /**
     * Call the supplied function on each item in the cache, in order from most
     * recently used to least recently used.
     *
     * `fn` is called as `fn(value, key, cache)`.
     *
     * If `thisp` is provided, function will be called in the `this`-context of
     * the provided object, or the cache if no `thisp` object is provided.
     *
     * Does not update age or recenty of use, or iterate over stale values.
     */
    forEach(fn, thisp = this) {
      for (const i of this.#indexes()) {
        const v = this.#valList[i]
        const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
        if (value === undefined) {
          continue
        }
        fn.call(thisp, value, this.#keyList[i], this)
      }
    }
    /**
     * The same as {@link LRUCache.forEach} but items are iterated over in
     * reverse order.  (ie, less recently used items are iterated over first.)
     */
    rforEach(fn, thisp = this) {
      for (const i of this.#rindexes()) {
        const v = this.#valList[i]
        const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
        if (value === undefined) {
          continue
        }
        fn.call(thisp, value, this.#keyList[i], this)
      }
    }
    /**
     * Delete any stale entries. Returns true if anything was removed,
     * false otherwise.
     */
    purgeStale() {
      let deleted = false
      for (const i of this.#rindexes({
        allowStale: true
      })) {
        if (this.#isStale(i)) {
          this.#delete(this.#keyList[i], 'expire')
          deleted = true
        }
      }
      return deleted
    }
    /**
     * Get the extended info about a given entry, to get its value, size, and
     * TTL info simultaneously. Returns `undefined` if the key is not present.
     *
     * Unlike {@link LRUCache#dump}, which is designed to be portable and survive
     * serialization, the `start` value is always the current timestamp, and the
     * `ttl` is a calculated remaining time to live (negative if expired).
     *
     * Always returns stale values, if their info is found in the cache, so be
     * sure to check for expirations (ie, a negative {@link LRUCache.Entry#ttl})
     * if relevant.
     */
    info(key) {
      const i = this.#keyMap.get(key)
      if (i === undefined) {
        return undefined
      }
      const v = this.#valList[i]
      const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
      if (value === undefined) {
        return undefined
      }
      const entry = {
        value
      }
      if (this.#ttls && this.#starts) {
        const ttl = this.#ttls[i]
        const start = this.#starts[i]
        if (ttl && start) {
          const remain = ttl - (perf.now() - start)
          entry.ttl = remain
          entry.start = Date.now()
        }
      }
      if (this.#sizes) {
        entry.size = this.#sizes[i]
      }
      return entry
    }
    /**
     * Return an array of [key, {@link LRUCache.Entry}] tuples which can be
     * passed to {@link LRLUCache#load}.
     *
     * The `start` fields are calculated relative to a portable `Date.now()`
     * timestamp, even if `performance.now()` is available.
     *
     * Stale entries are always included in the `dump`, even if
     * {@link LRUCache.OptionsBase.allowStale} is false.
     *
     * Note: this returns an actual array, not a generator, so it can be more
     * easily passed around.
     */
    dump() {
      const arr = []
      for (const i of this.#indexes({
        allowStale: true
      })) {
        const key = this.#keyList[i]
        const v = this.#valList[i]
        const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
        if (value === undefined || key === undefined) {
          continue
        }
        const entry = {
          value
        }
        if (this.#ttls && this.#starts) {
          entry.ttl = this.#ttls[i]
          // always dump the start relative to a portable timestamp
          // it's ok for this to be a bit slow, it's a rare operation.
          const age = perf.now() - this.#starts[i]
          entry.start = Math.floor(Date.now() - age)
        }
        if (this.#sizes) {
          entry.size = this.#sizes[i]
        }
        arr.unshift([key, entry])
      }
      return arr
    }
    /**
     * Reset the cache and load in the items in entries in the order listed.
     *
     * The shape of the resulting cache may be different if the same options are
     * not used in both caches.
     *
     * The `start` fields are assumed to be calculated relative to a portable
     * `Date.now()` timestamp, even if `performance.now()` is available.
     */
    load(arr) {
      this.clear()
      for (const [key, entry] of arr) {
        if (entry.start) {
          // entry.start is a portable timestamp, but we may be using
          // node's performance.now(), so calculate the offset, so that
          // we get the intended remaining TTL, no matter how long it's
          // been on ice.
          //
          // it's ok for this to be a bit slow, it's a rare operation.
          const age = Date.now() - entry.start
          entry.start = perf.now() - age
        }
        this.set(key, entry.value, entry)
      }
    }
    /**
     * Add a value to the cache.
     *
     * Note: if `undefined` is specified as a value, this is an alias for
     * {@link LRUCache#delete}
     *
     * Fields on the {@link LRUCache.SetOptions} options param will override
     * their corresponding values in the constructor options for the scope
     * of this single `set()` operation.
     *
     * If `start` is provided, then that will set the effective start
     * time for the TTL calculation. Note that this must be a previous
     * value of `performance.now()` if supported, or a previous value of
     * `Date.now()` if not.
     *
     * Options object may also include `size`, which will prevent
     * calling the `sizeCalculation` function and just use the specified
     * number if it is a positive integer, and `noDisposeOnSet` which
     * will prevent calling a `dispose` function in the case of
     * overwrites.
     *
     * If the `size` (or return value of `sizeCalculation`) for a given
     * entry is greater than `maxEntrySize`, then the item will not be
     * added to the cache.
     *
     * Will update the recency of the entry.
     *
     * If the value is `undefined`, then this is an alias for
     * `cache.delete(key)`. `undefined` is never stored in the cache.
     */
    set(k, v, setOptions = {}) {
      if (v === undefined) {
        this.delete(k)
        return this
      }
      const {
        ttl = this.ttl,
        start,
        noDisposeOnSet = this.noDisposeOnSet,
        sizeCalculation = this.sizeCalculation,
        status
      } = setOptions
      let { noUpdateTTL = this.noUpdateTTL } = setOptions
      const size = this.#requireSize(
        k,
        v,
        setOptions.size || 0,
        sizeCalculation
      )
      // if the item doesn't fit, don't do anything
      // NB: maxEntrySize set to maxSize by default
      if (this.maxEntrySize && size > this.maxEntrySize) {
        if (status) {
          status.set = 'miss'
          status.maxEntrySizeExceeded = true
        }
        // have to delete, in case something is there already.
        this.#delete(k, 'set')
        return this
      }
      let index = this.#size === 0 ? undefined : this.#keyMap.get(k)
      if (index === undefined) {
        // addition
        index =
          this.#size === 0
            ? this.#tail
            : this.#free.length !== 0
              ? this.#free.pop()
              : this.#size === this.#max
                ? this.#evict(false)
                : this.#size
        this.#keyList[index] = k
        this.#valList[index] = v
        this.#keyMap.set(k, index)
        this.#next[this.#tail] = index
        this.#prev[index] = this.#tail
        this.#tail = index
        this.#size++
        this.#addItemSize(index, size, status)
        if (status) {
          status.set = 'add'
        }
        noUpdateTTL = false
      } else {
        // update
        this.#moveToTail(index)
        const oldVal = this.#valList[index]
        if (v !== oldVal) {
          if (this.#hasFetchMethod && this.#isBackgroundFetch(oldVal)) {
            oldVal.__abortController.abort(new Error('replaced'))
            const { __staleWhileFetching: s } = oldVal
            if (s !== undefined && !noDisposeOnSet) {
              if (this.#hasDispose) {
                this.#dispose?.(s, k, 'set')
              }
              if (this.#hasDisposeAfter) {
                this.#disposed?.push([s, k, 'set'])
              }
            }
          } else if (!noDisposeOnSet) {
            if (this.#hasDispose) {
              this.#dispose?.(oldVal, k, 'set')
            }
            if (this.#hasDisposeAfter) {
              this.#disposed?.push([oldVal, k, 'set'])
            }
          }
          this.#removeItemSize(index)
          this.#addItemSize(index, size, status)
          this.#valList[index] = v
          if (status) {
            status.set = 'replace'
            const oldValue =
              oldVal && this.#isBackgroundFetch(oldVal)
                ? oldVal.__staleWhileFetching
                : oldVal
            if (oldValue !== undefined) {
              status.oldValue = oldValue
            }
          }
        } else if (status) {
          status.set = 'update'
        }
      }
      if (ttl !== 0 && !this.#ttls) {
        this.#initializeTTLTracking()
      }
      if (this.#ttls) {
        if (!noUpdateTTL) {
          this.#setItemTTL(index, ttl, start)
        }
        if (status) {
          this.#statusTTL(status, index)
        }
      }
      if (!noDisposeOnSet && this.#hasDisposeAfter && this.#disposed) {
        const dt = this.#disposed
        let task
        while ((task = dt?.shift())) {
          this.#disposeAfter?.(...task)
        }
      }
      return this
    }
    /**
     * Evict the least recently used item, returning its value or
     * `undefined` if cache is empty.
     */
    pop() {
      try {
        while (this.#size) {
          const val = this.#valList[this.#head]
          this.#evict(true)
          if (this.#isBackgroundFetch(val)) {
            if (val.__staleWhileFetching) {
              return val.__staleWhileFetching
            }
          } else if (val !== undefined) {
            return val
          }
        }
      } finally {
        if (this.#hasDisposeAfter && this.#disposed) {
          const dt = this.#disposed
          let task
          while ((task = dt?.shift())) {
            this.#disposeAfter?.(...task)
          }
        }
      }
    }
    #evict(free) {
      const head = this.#head
      const k = this.#keyList[head]
      const v = this.#valList[head]
      if (this.#hasFetchMethod && this.#isBackgroundFetch(v)) {
        v.__abortController.abort(new Error('evicted'))
      } else if (this.#hasDispose || this.#hasDisposeAfter) {
        if (this.#hasDispose) {
          this.#dispose?.(v, k, 'evict')
        }
        if (this.#hasDisposeAfter) {
          this.#disposed?.push([v, k, 'evict'])
        }
      }
      this.#removeItemSize(head)
      // if we aren't about to use the index, then null these out
      if (free) {
        this.#keyList[head] = undefined
        this.#valList[head] = undefined
        this.#free.push(head)
      }
      if (this.#size === 1) {
        this.#head = this.#tail = 0
        this.#free.length = 0
      } else {
        this.#head = this.#next[head]
      }
      this.#keyMap.delete(k)
      this.#size--
      return head
    }
    /**
     * Check if a key is in the cache, without updating the recency of use.
     * Will return false if the item is stale, even though it is technically
     * in the cache.
     *
     * Check if a key is in the cache, without updating the recency of
     * use. Age is updated if {@link LRUCache.OptionsBase.updateAgeOnHas} is set
     * to `true` in either the options or the constructor.
     *
     * Will return `false` if the item is stale, even though it is technically in
     * the cache. The difference can be determined (if it matters) by using a
     * `status` argument, and inspecting the `has` field.
     *
     * Will not update item age unless
     * {@link LRUCache.OptionsBase.updateAgeOnHas} is set.
     */
    has(k, hasOptions = {}) {
      const { updateAgeOnHas = this.updateAgeOnHas, status } = hasOptions
      const index = this.#keyMap.get(k)
      if (index !== undefined) {
        const v = this.#valList[index]
        if (
          this.#isBackgroundFetch(v) &&
          v.__staleWhileFetching === undefined
        ) {
          return false
        }
        if (!this.#isStale(index)) {
          if (updateAgeOnHas) {
            this.#updateItemAge(index)
          }
          if (status) {
            status.has = 'hit'
            this.#statusTTL(status, index)
          }
          return true
        } else if (status) {
          status.has = 'stale'
          this.#statusTTL(status, index)
        }
      } else if (status) {
        status.has = 'miss'
      }
      return false
    }
    /**
     * Like {@link LRUCache#get} but doesn't update recency or delete stale
     * items.
     *
     * Returns `undefined` if the item is stale, unless
     * {@link LRUCache.OptionsBase.allowStale} is set.
     */
    peek(k, peekOptions = {}) {
      const { allowStale = this.allowStale } = peekOptions
      const index = this.#keyMap.get(k)
      if (index === undefined || (!allowStale && this.#isStale(index))) {
        return
      }
      const v = this.#valList[index]
      // either stale and allowed, or forcing a refresh of non-stale value
      return this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
    }
    #backgroundFetch(k, index, options, context) {
      const v = index === undefined ? undefined : this.#valList[index]
      if (this.#isBackgroundFetch(v)) {
        return v
      }
      const ac = new AC()
      const { signal } = options
      // when/if our AC signals, then stop listening to theirs.
      signal?.addEventListener('abort', () => ac.abort(signal.reason), {
        signal: ac.signal
      })
      const fetchOpts = {
        signal: ac.signal,
        options,
        context
      }
      const cb = (v, updateCache = false) => {
        const { aborted } = ac.signal
        const ignoreAbort = options.ignoreFetchAbort && v !== undefined
        if (options.status) {
          if (aborted && !updateCache) {
            options.status.fetchAborted = true
            options.status.fetchError = ac.signal.reason
            if (ignoreAbort) {
              options.status.fetchAbortIgnored = true
            }
          } else {
            options.status.fetchResolved = true
          }
        }
        if (aborted && !ignoreAbort && !updateCache) {
          return fetchFail(ac.signal.reason)
        }
        // either we didn't abort, and are still here, or we did, and ignored
        const bf = p
        if (this.#valList[index] === p) {
          if (v === undefined) {
            if (bf.__staleWhileFetching) {
              this.#valList[index] = bf.__staleWhileFetching
            } else {
              this.#delete(k, 'fetch')
            }
          } else {
            if (options.status) {
              options.status.fetchUpdated = true
            }
            this.set(k, v, fetchOpts.options)
          }
        }
        return v
      }
      const eb = er => {
        if (options.status) {
          options.status.fetchRejected = true
          options.status.fetchError = er
        }
        return fetchFail(er)
      }
      const fetchFail = er => {
        const { aborted } = ac.signal
        const allowStaleAborted = aborted && options.allowStaleOnFetchAbort
        const allowStale =
          allowStaleAborted || options.allowStaleOnFetchRejection
        const noDelete = allowStale || options.noDeleteOnFetchRejection
        const bf = p
        if (this.#valList[index] === p) {
          // if we allow stale on fetch rejections, then we need to ensure that
          // the stale value is not removed from the cache when the fetch fails.
          const del = !noDelete || bf.__staleWhileFetching === undefined
          if (del) {
            this.#delete(k, 'fetch')
          } else if (!allowStaleAborted) {
            // still replace the *promise* with the stale value,
            // since we are done with the promise at this point.
            // leave it untouched if we're still waiting for an
            // aborted background fetch that hasn't yet returned.
            this.#valList[index] = bf.__staleWhileFetching
          }
        }
        if (allowStale) {
          if (options.status && bf.__staleWhileFetching !== undefined) {
            options.status.returnedStale = true
          }
          return bf.__staleWhileFetching
        } else if (bf.__returned === bf) {
          throw er
        }
      }
      const pcall = (res, rej) => {
        const fmp = this.#fetchMethod?.(k, v, fetchOpts)
        if (fmp && fmp instanceof Promise) {
          fmp.then(v => res(v === undefined ? undefined : v), rej)
        }
        // ignored, we go until we finish, regardless.
        // defer check until we are actually aborting,
        // so fetchMethod can override.
        ac.signal.addEventListener('abort', () => {
          if (!options.ignoreFetchAbort || options.allowStaleOnFetchAbort) {
            res(undefined)
            // when it eventually resolves, update the cache.
            if (options.allowStaleOnFetchAbort) {
              res = v => cb(v, true)
            }
          }
        })
      }
      if (options.status) {
        options.status.fetchDispatched = true
      }
      const p = new Promise(pcall).then(cb, eb)
      const bf = Object.assign(p, {
        __abortController: ac,
        __staleWhileFetching: v,
        __returned: undefined
      })
      if (index === undefined) {
        // internal, don't expose status.
        this.set(k, bf, {
          ...fetchOpts.options,
          status: undefined
        })
        index = this.#keyMap.get(k)
      } else {
        this.#valList[index] = bf
      }
      return bf
    }
    #isBackgroundFetch(p) {
      if (!this.#hasFetchMethod) {
        return false
      }
      const b = p
      return (
        !!b &&
        b instanceof Promise &&
        b.hasOwnProperty('__staleWhileFetching') &&
        b.__abortController instanceof AC
      )
    }
    async fetch(k, fetchOptions = {}) {
      const {
        // get options
        allowStale = this.allowStale,
        updateAgeOnGet = this.updateAgeOnGet,
        noDeleteOnStaleGet = this.noDeleteOnStaleGet,
        // set options
        ttl = this.ttl,
        noDisposeOnSet = this.noDisposeOnSet,
        size = 0,
        sizeCalculation = this.sizeCalculation,
        noUpdateTTL = this.noUpdateTTL,
        // fetch exclusive options
        noDeleteOnFetchRejection = this.noDeleteOnFetchRejection,
        allowStaleOnFetchRejection = this.allowStaleOnFetchRejection,
        ignoreFetchAbort = this.ignoreFetchAbort,
        allowStaleOnFetchAbort = this.allowStaleOnFetchAbort,
        context,
        forceRefresh = false,
        status,
        signal
      } = fetchOptions
      if (!this.#hasFetchMethod) {
        if (status) {
          status.fetch = 'get'
        }
        return this.get(k, {
          allowStale,
          updateAgeOnGet,
          noDeleteOnStaleGet,
          status
        })
      }
      const options = {
        allowStale,
        updateAgeOnGet,
        noDeleteOnStaleGet,
        ttl,
        noDisposeOnSet,
        size,
        sizeCalculation,
        noUpdateTTL,
        noDeleteOnFetchRejection,
        allowStaleOnFetchRejection,
        allowStaleOnFetchAbort,
        ignoreFetchAbort,
        status,
        signal
      }
      let index = this.#keyMap.get(k)
      if (index === undefined) {
        if (status) {
          status.fetch = 'miss'
        }
        const p = this.#backgroundFetch(k, index, options, context)
        return (p.__returned = p)
      } else {
        // in cache, maybe already fetching
        const v = this.#valList[index]
        if (this.#isBackgroundFetch(v)) {
          const stale = allowStale && v.__staleWhileFetching !== undefined
          if (status) {
            status.fetch = 'inflight'
            if (stale) {
              status.returnedStale = true
            }
          }
          return stale ? v.__staleWhileFetching : (v.__returned = v)
        }
        // if we force a refresh, that means do NOT serve the cached value,
        // unless we are already in the process of refreshing the cache.
        const isStale = this.#isStale(index)
        if (!forceRefresh && !isStale) {
          if (status) {
            status.fetch = 'hit'
          }
          this.#moveToTail(index)
          if (updateAgeOnGet) {
            this.#updateItemAge(index)
          }
          if (status) {
            this.#statusTTL(status, index)
          }
          return v
        }
        // ok, it is stale or a forced refresh, and not already fetching.
        // refresh the cache.
        const p = this.#backgroundFetch(k, index, options, context)
        const hasStale = p.__staleWhileFetching !== undefined
        const staleVal = hasStale && allowStale
        if (status) {
          status.fetch = isStale ? 'stale' : 'refresh'
          if (staleVal && isStale) {
            status.returnedStale = true
          }
        }
        return staleVal ? p.__staleWhileFetching : (p.__returned = p)
      }
    }
    async forceFetch(k, fetchOptions = {}) {
      const v = await this.fetch(k, fetchOptions)
      if (v === undefined) {
        throw new Error('fetch() returned undefined')
      }
      return v
    }
    memo(k, memoOptions = {}) {
      const memoMethod = this.#memoMethod
      if (!memoMethod) {
        throw new Error('no memoMethod provided to constructor')
      }
      const { context, forceRefresh, ...options } = memoOptions
      const v = this.get(k, options)
      if (!forceRefresh && v !== undefined) {
        return v
      }
      const vv = memoMethod(k, v, {
        options,
        context
      })
      this.set(k, vv, options)
      return vv
    }
    /**
     * Return a value from the cache. Will update the recency of the cache
     * entry found.
     *
     * If the key is not found, get() will return `undefined`.
     */
    get(k, getOptions = {}) {
      const {
        allowStale = this.allowStale,
        updateAgeOnGet = this.updateAgeOnGet,
        noDeleteOnStaleGet = this.noDeleteOnStaleGet,
        status
      } = getOptions
      const index = this.#keyMap.get(k)
      if (index !== undefined) {
        const value = this.#valList[index]
        const fetching = this.#isBackgroundFetch(value)
        if (status) {
          this.#statusTTL(status, index)
        }
        if (this.#isStale(index)) {
          if (status) {
            status.get = 'stale'
          }
          // delete only if not an in-flight background fetch
          if (!fetching) {
            if (!noDeleteOnStaleGet) {
              this.#delete(k, 'expire')
            }
            if (status && allowStale) {
              status.returnedStale = true
            }
            return allowStale ? value : undefined
          } else {
            if (
              status &&
              allowStale &&
              value.__staleWhileFetching !== undefined
            ) {
              status.returnedStale = true
            }
            return allowStale ? value.__staleWhileFetching : undefined
          }
        } else {
          if (status) {
            status.get = 'hit'
          }
          // if we're currently fetching it, we don't actually have it yet
          // it's not stale, which means this isn't a staleWhileRefetching.
          // If it's not stale, and fetching, AND has a __staleWhileFetching
          // value, then that means the user fetched with {forceRefresh:true},
          // so it's safe to return that value.
          if (fetching) {
            return value.__staleWhileFetching
          }
          this.#moveToTail(index)
          if (updateAgeOnGet) {
            this.#updateItemAge(index)
          }
          return value
        }
      } else if (status) {
        status.get = 'miss'
      }
    }
    #connect(p, n) {
      this.#prev[n] = p
      this.#next[p] = n
    }
    #moveToTail(index) {
      // if tail already, nothing to do
      // if head, move head to next[index]
      // else
      //   move next[prev[index]] to next[index] (head has no prev)
      //   move prev[next[index]] to prev[index]
      // prev[index] = tail
      // next[tail] = index
      // tail = index
      if (index !== this.#tail) {
        if (index === this.#head) {
          this.#head = this.#next[index]
        } else {
          this.#connect(this.#prev[index], this.#next[index])
        }
        this.#connect(this.#tail, index)
        this.#tail = index
      }
    }
    /**
     * Deletes a key out of the cache.
     *
     * Returns true if the key was deleted, false otherwise.
     */
    delete(k) {
      return this.#delete(k, 'delete')
    }
    #delete(k, reason) {
      let deleted = false
      if (this.#size !== 0) {
        const index = this.#keyMap.get(k)
        if (index !== undefined) {
          deleted = true
          if (this.#size === 1) {
            this.#clear(reason)
          } else {
            this.#removeItemSize(index)
            const v = this.#valList[index]
            if (this.#isBackgroundFetch(v)) {
              v.__abortController.abort(new Error('deleted'))
            } else if (this.#hasDispose || this.#hasDisposeAfter) {
              if (this.#hasDispose) {
                this.#dispose?.(v, k, reason)
              }
              if (this.#hasDisposeAfter) {
                this.#disposed?.push([v, k, reason])
              }
            }
            this.#keyMap.delete(k)
            this.#keyList[index] = undefined
            this.#valList[index] = undefined
            if (index === this.#tail) {
              this.#tail = this.#prev[index]
            } else if (index === this.#head) {
              this.#head = this.#next[index]
            } else {
              const pi = this.#prev[index]
              this.#next[pi] = this.#next[index]
              const ni = this.#next[index]
              this.#prev[ni] = this.#prev[index]
            }
            this.#size--
            this.#free.push(index)
          }
        }
      }
      if (this.#hasDisposeAfter && this.#disposed?.length) {
        const dt = this.#disposed
        let task
        while ((task = dt?.shift())) {
          this.#disposeAfter?.(...task)
        }
      }
      return deleted
    }
    /**
     * Clear the cache entirely, throwing away all values.
     */
    clear() {
      return this.#clear('delete')
    }
    #clear(reason) {
      for (const index of this.#rindexes({
        allowStale: true
      })) {
        const v = this.#valList[index]
        if (this.#isBackgroundFetch(v)) {
          v.__abortController.abort(new Error('deleted'))
        } else {
          const k = this.#keyList[index]
          if (this.#hasDispose) {
            this.#dispose?.(v, k, reason)
          }
          if (this.#hasDisposeAfter) {
            this.#disposed?.push([v, k, reason])
          }
        }
      }
      this.#keyMap.clear()
      this.#valList.fill(undefined)
      this.#keyList.fill(undefined)
      if (this.#ttls && this.#starts) {
        this.#ttls.fill(0)
        this.#starts.fill(0)
      }
      if (this.#sizes) {
        this.#sizes.fill(0)
      }
      this.#head = 0
      this.#tail = 0
      this.#free.length = 0
      this.#calculatedSize = 0
      this.#size = 0
      if (this.#hasDisposeAfter && this.#disposed) {
        const dt = this.#disposed
        let task
        while ((task = dt?.shift())) {
          this.#disposeAfter?.(...task)
        }
      }
    }
  }
  commonjs$1.LRUCache = LRUCache
  return commonjs$1
}

/* eslint-disable max-len */
let hosts_1
let hasRequiredHosts
function requireHosts() {
  if (hasRequiredHosts) {
    return hosts_1
  }
  hasRequiredHosts = 1
  const maybeJoin = (...args) => (args.every(arg => arg) ? args.join('') : '')
  const maybeEncode = arg => (arg ? encodeURIComponent(arg) : '')
  const formatHashFragment = f =>
    f
      .toLowerCase()
      .replace(/^\W+/g, '') // strip leading non-characters
      .replace(/(?<!\W)\W+$/, '') // strip trailing non-characters
      .replace(/\//g, '') // strip all slashes
      .replace(/\W+/g, '-') // replace remaining non-characters with '-'

  const defaults = {
    sshtemplate: ({ domain, user, project, committish }) =>
      `git@${domain}:${user}/${project}.git${maybeJoin('#', committish)}`,
    sshurltemplate: ({ domain, user, project, committish }) =>
      `git+ssh://git@${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
    edittemplate: ({ domain, user, project, committish, editpath, path }) =>
      `https://${domain}/${user}/${project}${maybeJoin('/', editpath, '/', maybeEncode(committish || 'HEAD'), '/', path)}`,
    browsetemplate: ({ domain, user, project, committish, treepath }) =>
      `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish))}`,
    browsetreetemplate: ({
      domain,
      user,
      project,
      committish,
      treepath,
      path,
      fragment,
      hashformat
    }) =>
      `https://${domain}/${user}/${project}/${treepath}/${maybeEncode(committish || 'HEAD')}/${path}${maybeJoin('#', hashformat(fragment || ''))}`,
    browseblobtemplate: ({
      domain,
      user,
      project,
      committish,
      blobpath,
      path,
      fragment,
      hashformat
    }) =>
      `https://${domain}/${user}/${project}/${blobpath}/${maybeEncode(committish || 'HEAD')}/${path}${maybeJoin('#', hashformat(fragment || ''))}`,
    docstemplate: ({ domain, user, project, treepath, committish }) =>
      `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish))}#readme`,
    httpstemplate: ({ auth, domain, user, project, committish }) =>
      `git+https://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
    filetemplate: ({ domain, user, project, committish, path }) =>
      `https://${domain}/${user}/${project}/raw/${maybeEncode(committish || 'HEAD')}/${path}`,
    shortcuttemplate: ({ type, user, project, committish }) =>
      `${type}:${user}/${project}${maybeJoin('#', committish)}`,
    pathtemplate: ({ user, project, committish }) =>
      `${user}/${project}${maybeJoin('#', committish)}`,
    bugstemplate: ({ domain, user, project }) =>
      `https://${domain}/${user}/${project}/issues`,
    hashformat: formatHashFragment
  }
  const hosts = {}
  hosts.github = {
    // First two are insecure and generally shouldn't be used any more, but
    // they are still supported.
    protocols: ['git:', 'http:', 'git+ssh:', 'git+https:', 'ssh:', 'https:'],
    domain: 'github.com',
    treepath: 'tree',
    blobpath: 'blob',
    editpath: 'edit',
    filetemplate: ({ auth, user, project, committish, path }) =>
      `https://${maybeJoin(auth, '@')}raw.githubusercontent.com/${user}/${project}/${maybeEncode(committish || 'HEAD')}/${path}`,
    gittemplate: ({ auth, domain, user, project, committish }) =>
      `git://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
    tarballtemplate: ({ domain, user, project, committish }) =>
      `https://codeload.${domain}/${user}/${project}/tar.gz/${maybeEncode(committish || 'HEAD')}`,
    extract: url => {
      let [, user, project, type, committish] = url.pathname.split('/', 5)
      if (type && type !== 'tree') {
        return
      }
      if (!type) {
        committish = url.hash.slice(1)
      }
      if (project && project.endsWith('.git')) {
        project = project.slice(0, -4)
      }
      if (!user || !project) {
        return
      }
      return {
        user,
        project,
        committish
      }
    }
  }
  hosts.bitbucket = {
    protocols: ['git+ssh:', 'git+https:', 'ssh:', 'https:'],
    domain: 'bitbucket.org',
    treepath: 'src',
    blobpath: 'src',
    editpath: '?mode=edit',
    edittemplate: ({
      domain,
      user,
      project,
      committish,
      treepath,
      path,
      editpath
    }) =>
      `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish || 'HEAD'), '/', path, editpath)}`,
    tarballtemplate: ({ domain, user, project, committish }) =>
      `https://${domain}/${user}/${project}/get/${maybeEncode(committish || 'HEAD')}.tar.gz`,
    extract: url => {
      let [, user, project, aux] = url.pathname.split('/', 4)
      if (['get'].includes(aux)) {
        return
      }
      if (project && project.endsWith('.git')) {
        project = project.slice(0, -4)
      }
      if (!user || !project) {
        return
      }
      return {
        user,
        project,
        committish: url.hash.slice(1)
      }
    }
  }
  hosts.gitlab = {
    protocols: ['git+ssh:', 'git+https:', 'ssh:', 'https:'],
    domain: 'gitlab.com',
    treepath: 'tree',
    blobpath: 'tree',
    editpath: '-/edit',
    httpstemplate: ({ auth, domain, user, project, committish }) =>
      `git+https://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
    tarballtemplate: ({ domain, user, project, committish }) =>
      `https://${domain}/${user}/${project}/repository/archive.tar.gz?ref=${maybeEncode(committish || 'HEAD')}`,
    extract: url => {
      const path = url.pathname.slice(1)
      if (path.includes('/-/') || path.includes('/archive.tar.gz')) {
        return
      }
      const segments = path.split('/')
      let project = segments.pop()
      if (project.endsWith('.git')) {
        project = project.slice(0, -4)
      }
      const user = segments.join('/')
      if (!user || !project) {
        return
      }
      return {
        user,
        project,
        committish: url.hash.slice(1)
      }
    }
  }
  hosts.gist = {
    protocols: ['git:', 'git+ssh:', 'git+https:', 'ssh:', 'https:'],
    domain: 'gist.github.com',
    editpath: 'edit',
    sshtemplate: ({ domain, project, committish }) =>
      `git@${domain}:${project}.git${maybeJoin('#', committish)}`,
    sshurltemplate: ({ domain, project, committish }) =>
      `git+ssh://git@${domain}/${project}.git${maybeJoin('#', committish)}`,
    edittemplate: ({ domain, user, project, committish, editpath }) =>
      `https://${domain}/${user}/${project}${maybeJoin('/', maybeEncode(committish))}/${editpath}`,
    browsetemplate: ({ domain, project, committish }) =>
      `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}`,
    browsetreetemplate: ({ domain, project, committish, path, hashformat }) =>
      `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}${maybeJoin('#', hashformat(path))}`,
    browseblobtemplate: ({ domain, project, committish, path, hashformat }) =>
      `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}${maybeJoin('#', hashformat(path))}`,
    docstemplate: ({ domain, project, committish }) =>
      `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}`,
    httpstemplate: ({ domain, project, committish }) =>
      `git+https://${domain}/${project}.git${maybeJoin('#', committish)}`,
    filetemplate: ({ user, project, committish, path }) =>
      `https://gist.githubusercontent.com/${user}/${project}/raw${maybeJoin('/', maybeEncode(committish))}/${path}`,
    shortcuttemplate: ({ type, project, committish }) =>
      `${type}:${project}${maybeJoin('#', committish)}`,
    pathtemplate: ({ project, committish }) =>
      `${project}${maybeJoin('#', committish)}`,
    bugstemplate: ({ domain, project }) => `https://${domain}/${project}`,
    gittemplate: ({ domain, project, committish }) =>
      `git://${domain}/${project}.git${maybeJoin('#', committish)}`,
    tarballtemplate: ({ project, committish }) =>
      `https://codeload.github.com/gist/${project}/tar.gz/${maybeEncode(committish || 'HEAD')}`,
    extract: url => {
      let [, user, project, aux] = url.pathname.split('/', 4)
      if (aux === 'raw') {
        return
      }
      if (!project) {
        if (!user) {
          return
        }
        project = user
        user = null
      }
      if (project.endsWith('.git')) {
        project = project.slice(0, -4)
      }
      return {
        user,
        project,
        committish: url.hash.slice(1)
      }
    },
    hashformat: function (fragment) {
      return fragment && 'file-' + formatHashFragment(fragment)
    }
  }
  hosts.sourcehut = {
    protocols: ['git+ssh:', 'https:'],
    domain: 'git.sr.ht',
    treepath: 'tree',
    blobpath: 'tree',
    filetemplate: ({ domain, user, project, committish, path }) =>
      `https://${domain}/${user}/${project}/blob/${maybeEncode(committish) || 'HEAD'}/${path}`,
    httpstemplate: ({ domain, user, project, committish }) =>
      `https://${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
    tarballtemplate: ({ domain, user, project, committish }) =>
      `https://${domain}/${user}/${project}/archive/${maybeEncode(committish) || 'HEAD'}.tar.gz`,
    bugstemplate: () => null,
    extract: url => {
      let [, user, project, aux] = url.pathname.split('/', 4)

      // tarball url
      if (['archive'].includes(aux)) {
        return
      }
      if (project && project.endsWith('.git')) {
        project = project.slice(0, -4)
      }
      if (!user || !project) {
        return
      }
      return {
        user,
        project,
        committish: url.hash.slice(1)
      }
    }
  }
  for (const [name, host] of Object.entries(hosts)) {
    hosts[name] = Object.assign({}, defaults, host)
  }
  hosts_1 = hosts
  return hosts_1
}

let parseUrl
let hasRequiredParseUrl
function requireParseUrl() {
  if (hasRequiredParseUrl) {
    return parseUrl
  }
  hasRequiredParseUrl = 1
  const url = require$$2$1
  const lastIndexOfBefore = (str, char, beforeChar) => {
    const startPosition = str.indexOf(beforeChar)
    return str.lastIndexOf(char, startPosition > -1 ? startPosition : Infinity)
  }
  const safeUrl = u => {
    try {
      return new url.URL(u)
    } catch {
      // this fn should never throw
    }
  }

  // accepts input like git:github.com:user/repo and inserts the // after the first :
  const correctProtocol = (arg, protocols) => {
    const firstColon = arg.indexOf(':')
    const proto = arg.slice(0, firstColon + 1)
    if (Object.prototype.hasOwnProperty.call(protocols, proto)) {
      return arg
    }
    const firstAt = arg.indexOf('@')
    if (firstAt > -1) {
      if (firstAt > firstColon) {
        return `git+ssh://${arg}`
      } else {
        return arg
      }
    }
    const doubleSlash = arg.indexOf('//')
    if (doubleSlash === firstColon + 1) {
      return arg
    }
    return `${arg.slice(0, firstColon + 1)}//${arg.slice(firstColon + 1)}`
  }

  // attempt to correct an scp style url so that it will parse with `new URL()`
  const correctUrl = giturl => {
    // ignore @ that come after the first hash since the denotes the start
    // of a committish which can contain @ characters
    const firstAt = lastIndexOfBefore(giturl, '@', '#')
    // ignore colons that come after the hash since that could include colons such as:
    // git@github.com:user/package-2#semver:^1.0.0
    const lastColonBeforeHash = lastIndexOfBefore(giturl, ':', '#')
    if (lastColonBeforeHash > firstAt) {
      // the last : comes after the first @ (or there is no @)
      // like it would in:
      // proto://hostname.com:user/repo
      // username@hostname.com:user/repo
      // :password@hostname.com:user/repo
      // username:password@hostname.com:user/repo
      // proto://username@hostname.com:user/repo
      // proto://:password@hostname.com:user/repo
      // proto://username:password@hostname.com:user/repo
      // then we replace the last : with a / to create a valid path
      giturl =
        giturl.slice(0, lastColonBeforeHash) +
        '/' +
        giturl.slice(lastColonBeforeHash + 1)
    }
    if (
      lastIndexOfBefore(giturl, ':', '#') === -1 &&
      giturl.indexOf('//') === -1
    ) {
      // we have no : at all
      // as it would be in:
      // username@hostname.com/user/repo
      // then we prepend a protocol
      giturl = `git+ssh://${giturl}`
    }
    return giturl
  }
  parseUrl = (giturl, protocols) => {
    const withProtocol = protocols ? correctProtocol(giturl, protocols) : giturl
    return safeUrl(withProtocol) || safeUrl(correctUrl(withProtocol))
  }
  return parseUrl
}

let fromUrl
let hasRequiredFromUrl
function requireFromUrl() {
  if (hasRequiredFromUrl) {
    return fromUrl
  }
  hasRequiredFromUrl = 1
  const parseUrl = requireParseUrl()

  // look for github shorthand inputs, such as npm/cli
  const isGitHubShorthand = arg => {
    // it cannot contain whitespace before the first #
    // it cannot start with a / because that's probably an absolute file path
    // but it must include a slash since repos are username/repository
    // it cannot start with a . because that's probably a relative file path
    // it cannot start with an @ because that's a scoped package if it passes the other tests
    // it cannot contain a : before a # because that tells us that there's a protocol
    // a second / may not exist before a #
    const firstHash = arg.indexOf('#')
    const firstSlash = arg.indexOf('/')
    const secondSlash = arg.indexOf('/', firstSlash + 1)
    const firstColon = arg.indexOf(':')
    const firstSpace = /\s/.exec(arg)
    const firstAt = arg.indexOf('@')
    const spaceOnlyAfterHash =
      !firstSpace || (firstHash > -1 && firstSpace.index > firstHash)
    const atOnlyAfterHash =
      firstAt === -1 || (firstHash > -1 && firstAt > firstHash)
    const colonOnlyAfterHash =
      firstColon === -1 || (firstHash > -1 && firstColon > firstHash)
    const secondSlashOnlyAfterHash =
      secondSlash === -1 || (firstHash > -1 && secondSlash > firstHash)
    const hasSlash = firstSlash > 0
    // if a # is found, what we really want to know is that the character
    // immediately before # is not a /
    const doesNotEndWithSlash =
      firstHash > -1 ? arg[firstHash - 1] !== '/' : !arg.endsWith('/')
    const doesNotStartWithDot = !arg.startsWith('.')
    return (
      spaceOnlyAfterHash &&
      hasSlash &&
      doesNotEndWithSlash &&
      doesNotStartWithDot &&
      atOnlyAfterHash &&
      colonOnlyAfterHash &&
      secondSlashOnlyAfterHash
    )
  }
  fromUrl = (giturl, opts, { gitHosts, protocols }) => {
    if (!giturl) {
      return
    }
    const correctedUrl = isGitHubShorthand(giturl) ? `github:${giturl}` : giturl
    const parsed = parseUrl(correctedUrl, protocols)
    if (!parsed) {
      return
    }
    const gitHostShortcut = gitHosts.byShortcut[parsed.protocol]
    const gitHostDomain =
      gitHosts.byDomain[
        parsed.hostname.startsWith('www.')
          ? parsed.hostname.slice(4)
          : parsed.hostname
      ]
    const gitHostName = gitHostShortcut || gitHostDomain
    if (!gitHostName) {
      return
    }
    const gitHostInfo = gitHosts[gitHostShortcut || gitHostDomain]
    let auth = null
    if (
      protocols[parsed.protocol]?.auth &&
      (parsed.username || parsed.password)
    ) {
      auth = `${parsed.username}${parsed.password ? ':' + parsed.password : ''}`
    }
    let committish = null
    let user = null
    let project = null
    let defaultRepresentation = null
    try {
      if (gitHostShortcut) {
        let pathname = parsed.pathname.startsWith('/')
          ? parsed.pathname.slice(1)
          : parsed.pathname
        const firstAt = pathname.indexOf('@')
        // we ignore auth for shortcuts, so just trim it out
        if (firstAt > -1) {
          pathname = pathname.slice(firstAt + 1)
        }
        const lastSlash = pathname.lastIndexOf('/')
        if (lastSlash > -1) {
          user = decodeURIComponent(pathname.slice(0, lastSlash))
          // we want nulls only, never empty strings
          if (!user) {
            user = null
          }
          project = decodeURIComponent(pathname.slice(lastSlash + 1))
        } else {
          project = decodeURIComponent(pathname)
        }
        if (project.endsWith('.git')) {
          project = project.slice(0, -4)
        }
        if (parsed.hash) {
          committish = decodeURIComponent(parsed.hash.slice(1))
        }
        defaultRepresentation = 'shortcut'
      } else {
        if (!gitHostInfo.protocols.includes(parsed.protocol)) {
          return
        }
        const segments = gitHostInfo.extract(parsed)
        if (!segments) {
          return
        }
        user = segments.user && decodeURIComponent(segments.user)
        project = decodeURIComponent(segments.project)
        committish = decodeURIComponent(segments.committish)
        defaultRepresentation =
          protocols[parsed.protocol]?.name || parsed.protocol.slice(0, -1)
      }
    } catch (err) {
      /* istanbul ignore else */
      if (err instanceof URIError) {
        return
      } else {
        throw err
      }
    }
    return [
      gitHostName,
      user,
      auth,
      project,
      committish,
      defaultRepresentation,
      opts
    ]
  }
  return fromUrl
}

let lib$j
let hasRequiredLib$j
function requireLib$j() {
  if (hasRequiredLib$j) {
    return lib$j
  }
  hasRequiredLib$j = 1
  const { LRUCache } = /*@__PURE__*/ requireCommonjs$1()
  const hosts = requireHosts()
  const fromUrl = requireFromUrl()
  const parseUrl = requireParseUrl()
  const cache = new LRUCache({
    max: 1000
  })
  function unknownHostedUrl(url) {
    try {
      const { protocol, hostname, pathname } = new URL(url)
      if (!hostname) {
        return null
      }
      const proto = /(?:git\+)http:$/.test(protocol) ? 'http:' : 'https:'
      const path = pathname.replace(/\.git$/, '')
      return `${proto}//${hostname}${path}`
    } catch {
      return null
    }
  }
  class GitHost {
    constructor(
      type,
      user,
      auth,
      project,
      committish,
      defaultRepresentation,
      opts = {}
    ) {
      Object.assign(this, GitHost.#gitHosts[type], {
        type,
        user,
        auth,
        project,
        committish,
        default: defaultRepresentation,
        opts
      })
    }
    static #gitHosts = {
      byShortcut: {},
      byDomain: {}
    }
    static #protocols = {
      'git+ssh:': {
        name: 'sshurl'
      },
      'ssh:': {
        name: 'sshurl'
      },
      'git+https:': {
        name: 'https',
        auth: true
      },
      'git:': {
        auth: true
      },
      'http:': {
        auth: true
      },
      'https:': {
        auth: true
      },
      'git+http:': {
        auth: true
      }
    }
    static addHost(name, host) {
      GitHost.#gitHosts[name] = host
      GitHost.#gitHosts.byDomain[host.domain] = name
      GitHost.#gitHosts.byShortcut[`${name}:`] = name
      GitHost.#protocols[`${name}:`] = {
        name
      }
    }
    static fromUrl(giturl, opts) {
      if (typeof giturl !== 'string') {
        return
      }
      const key = giturl + JSON.stringify(opts || {})
      if (!cache.has(key)) {
        const hostArgs = fromUrl(giturl, opts, {
          gitHosts: GitHost.#gitHosts,
          protocols: GitHost.#protocols
        })
        cache.set(key, hostArgs ? new GitHost(...hostArgs) : undefined)
      }
      return cache.get(key)
    }
    static fromManifest(manifest, opts = {}) {
      if (!manifest || typeof manifest !== 'object') {
        return
      }
      const r = manifest.repository
      // TODO: look into also checking the `bugs`/`homepage` URLs

      const rurl =
        r &&
        (typeof r === 'string'
          ? r
          : typeof r === 'object' && typeof r.url === 'string'
            ? r.url
            : null)
      if (!rurl) {
        throw new Error('no repository')
      }
      const info =
        (rurl && GitHost.fromUrl(rurl.replace(/^git\+/, ''), opts)) || null
      if (info) {
        return info
      }
      const unk = unknownHostedUrl(rurl)
      return GitHost.fromUrl(unk, opts) || unk
    }
    static parseUrl(url) {
      return parseUrl(url)
    }
    #fill(template, opts) {
      if (typeof template !== 'function') {
        return null
      }
      const options = {
        ...this,
        ...this.opts,
        ...opts
      }

      // the path should always be set so we don't end up with 'undefined' in urls
      if (!options.path) {
        options.path = ''
      }

      // template functions will insert the leading slash themselves
      if (options.path.startsWith('/')) {
        options.path = options.path.slice(1)
      }
      if (options.noCommittish) {
        options.committish = null
      }
      const result = template(options)
      return options.noGitPlus && result.startsWith('git+')
        ? result.slice(4)
        : result
    }
    hash() {
      return this.committish ? `#${this.committish}` : ''
    }
    ssh(opts) {
      return this.#fill(this.sshtemplate, opts)
    }
    sshurl(opts) {
      return this.#fill(this.sshurltemplate, opts)
    }
    browse(path, ...args) {
      // not a string, treat path as opts
      if (typeof path !== 'string') {
        return this.#fill(this.browsetemplate, path)
      }
      if (typeof args[0] !== 'string') {
        return this.#fill(this.browsetreetemplate, {
          ...args[0],
          path
        })
      }
      return this.#fill(this.browsetreetemplate, {
        ...args[1],
        fragment: args[0],
        path
      })
    }

    // If the path is known to be a file, then browseFile should be used. For some hosts
    // the url is the same as browse, but for others like GitHub a file can use both `/tree/`
    // and `/blob/` in the path. When using a default committish of `HEAD` then the `/tree/`
    // path will redirect to a specific commit. Using the `/blob/` path avoids this and
    // does not redirect to a different commit.
    browseFile(path, ...args) {
      if (typeof args[0] !== 'string') {
        return this.#fill(this.browseblobtemplate, {
          ...args[0],
          path
        })
      }
      return this.#fill(this.browseblobtemplate, {
        ...args[1],
        fragment: args[0],
        path
      })
    }
    docs(opts) {
      return this.#fill(this.docstemplate, opts)
    }
    bugs(opts) {
      return this.#fill(this.bugstemplate, opts)
    }
    https(opts) {
      return this.#fill(this.httpstemplate, opts)
    }
    git(opts) {
      return this.#fill(this.gittemplate, opts)
    }
    shortcut(opts) {
      return this.#fill(this.shortcuttemplate, opts)
    }
    path(opts) {
      return this.#fill(this.pathtemplate, opts)
    }
    tarball(opts) {
      return this.#fill(this.tarballtemplate, {
        ...opts,
        noCommittish: false
      })
    }
    file(path, opts) {
      return this.#fill(this.filetemplate, {
        ...opts,
        path
      })
    }
    edit(path, opts) {
      return this.#fill(this.edittemplate, {
        ...opts,
        path
      })
    }
    getDefaultRepresentation() {
      return this.default
    }
    toString(opts) {
      if (this.default && typeof this[this.default] === 'function') {
        return this[this.default](opts)
      }
      return this.sshurl(opts)
    }
  }
  for (const [name, host] of Object.entries(hosts)) {
    GitHost.addHost(name, host)
  }
  lib$j = GitHost
  return lib$j
}

let lib$i
let hasRequiredLib$i
function requireLib$i() {
  if (hasRequiredLib$i) {
    return lib$i
  }
  hasRequiredLib$i = 1
  const { builtinModules: builtins } = require$$0$d
  const scopedPackagePattern = new RegExp('^(?:@([^/]+?)[/])?([^/]+?)$')
  const blacklist = ['node_modules', 'favicon.ico']
  function validate(name) {
    const warnings = []
    const errors = []
    if (name === null) {
      errors.push('name cannot be null')
      return done(warnings, errors)
    }
    if (name === undefined) {
      errors.push('name cannot be undefined')
      return done(warnings, errors)
    }
    if (typeof name !== 'string') {
      errors.push('name must be a string')
      return done(warnings, errors)
    }
    if (!name.length) {
      errors.push('name length must be greater than zero')
    }
    if (name.match(/^\./)) {
      errors.push('name cannot start with a period')
    }
    if (name.match(/^_/)) {
      errors.push('name cannot start with an underscore')
    }
    if (name.trim() !== name) {
      errors.push('name cannot contain leading or trailing spaces')
    }

    // No funny business
    blacklist.forEach(function (blacklistedName) {
      if (name.toLowerCase() === blacklistedName) {
        errors.push(blacklistedName + ' is a blacklisted name')
      }
    })

    // Generate warnings for stuff that used to be allowed

    // core module names like http, events, util, etc
    if (builtins.includes(name.toLowerCase())) {
      warnings.push(name + ' is a core module name')
    }
    if (name.length > 214) {
      warnings.push('name can no longer contain more than 214 characters')
    }

    // mIxeD CaSe nAMEs
    if (name.toLowerCase() !== name) {
      warnings.push('name can no longer contain capital letters')
    }
    if (/[~'!()*]/.test(name.split('/').slice(-1)[0])) {
      warnings.push('name can no longer contain special characters ("~\'!()*")')
    }
    if (encodeURIComponent(name) !== name) {
      // Maybe it's a scoped package name, like @user/package
      const nameMatch = name.match(scopedPackagePattern)
      if (nameMatch) {
        const user = nameMatch[1]
        const pkg = nameMatch[2]
        if (
          encodeURIComponent(user) === user &&
          encodeURIComponent(pkg) === pkg
        ) {
          return done(warnings, errors)
        }
      }
      errors.push('name can only contain URL-friendly characters')
    }
    return done(warnings, errors)
  }
  const done = function (warnings, errors) {
    const result = {
      validForNewPackages: errors.length === 0 && warnings.length === 0,
      validForOldPackages: errors.length === 0,
      warnings: warnings,
      errors: errors
    }
    if (!result.warnings.length) {
      delete result.warnings
    }
    if (!result.errors.length) {
      delete result.errors
    }
    return result
  }
  lib$i = validate
  return lib$i
}

let lib$h
let hasRequiredLib$h
function requireLib$h() {
  if (hasRequiredLib$h) {
    return lib$h
  }
  hasRequiredLib$h = 1
  const META = Symbol('proc-log.meta')
  lib$h = {
    META: META,
    output: {
      LEVELS: ['standard', 'error', 'buffer', 'flush'],
      KEYS: {
        standard: 'standard',
        error: 'error',
        buffer: 'buffer',
        flush: 'flush'
      },
      standard: function (...args) {
        return process.emit('output', 'standard', ...args)
      },
      error: function (...args) {
        return process.emit('output', 'error', ...args)
      },
      buffer: function (...args) {
        return process.emit('output', 'buffer', ...args)
      },
      flush: function (...args) {
        return process.emit('output', 'flush', ...args)
      }
    },
    log: {
      LEVELS: [
        'notice',
        'error',
        'warn',
        'info',
        'verbose',
        'http',
        'silly',
        'timing',
        'pause',
        'resume'
      ],
      KEYS: {
        notice: 'notice',
        error: 'error',
        warn: 'warn',
        info: 'info',
        verbose: 'verbose',
        http: 'http',
        silly: 'silly',
        timing: 'timing',
        pause: 'pause',
        resume: 'resume'
      },
      error: function (...args) {
        return process.emit('log', 'error', ...args)
      },
      notice: function (...args) {
        return process.emit('log', 'notice', ...args)
      },
      warn: function (...args) {
        return process.emit('log', 'warn', ...args)
      },
      info: function (...args) {
        return process.emit('log', 'info', ...args)
      },
      verbose: function (...args) {
        return process.emit('log', 'verbose', ...args)
      },
      http: function (...args) {
        return process.emit('log', 'http', ...args)
      },
      silly: function (...args) {
        return process.emit('log', 'silly', ...args)
      },
      timing: function (...args) {
        return process.emit('log', 'timing', ...args)
      },
      pause: function () {
        return process.emit('log', 'pause')
      },
      resume: function () {
        return process.emit('log', 'resume')
      }
    },
    time: {
      LEVELS: ['start', 'end'],
      KEYS: {
        start: 'start',
        end: 'end'
      },
      start: function (name, fn) {
        process.emit('time', 'start', name)
        function end() {
          return process.emit('time', 'end', name)
        }
        if (typeof fn === 'function') {
          const res = fn()
          if (res && res.finally) {
            return res.finally(end)
          }
          end()
          return res
        }
        return end
      },
      end: function (name) {
        return process.emit('time', 'end', name)
      }
    },
    input: {
      LEVELS: ['start', 'end', 'read'],
      KEYS: {
        start: 'start',
        end: 'end',
        read: 'read'
      },
      start: function (fn) {
        process.emit('input', 'start')
        function end() {
          return process.emit('input', 'end')
        }
        if (typeof fn === 'function') {
          const res = fn()
          if (res && res.finally) {
            return res.finally(end)
          }
          end()
          return res
        }
        return end
      },
      end: function () {
        return process.emit('input', 'end')
      },
      read: function (...args) {
        let resolve, reject
        const promise = new Promise((_resolve, _reject) => {
          resolve = _resolve
          reject = _reject
        })
        process.emit('input', 'read', resolve, reject, ...args)
        return promise
      }
    }
  }
  return lib$h
}

let hasRequiredNpa
function requireNpa() {
  if (hasRequiredNpa) {
    return npa.exports
  }
  hasRequiredNpa = 1
  const isWindows = process.platform === 'win32'
  const { URL } = require$$0$b
  // We need to use path/win32 so that we get consistent results in tests, but this also means we need to manually convert backslashes to forward slashes when generating file: urls with paths.
  const path = isWindows ? require$$1$8 : path$1
  const { homedir } = os$3
  const HostedGit = requireLib$j()
  const semver = requireSemver()
  const validatePackageName = requireLib$i()
  const { log } = requireLib$h()
  const hasSlashes = isWindows ? /\\|[/]/ : /[/]/
  const isURL = /^(?:git[+])?[a-z]+:/i
  const isGit = /^[^@]+@[^:.]+\.[^:]+:.+$/i
  const isFileType = /[.](?:tgz|tar.gz|tar)$/i
  const isPortNumber = /:[0-9]+(\/|$)/i
  const isWindowsFile = /^(?:[.]|~[/]|[/\\]|[a-zA-Z]:)/
  const isPosixFile = /^(?:[.]|~[/]|[/]|[a-zA-Z]:)/
  const defaultRegistry = 'https://registry.npmjs.org'
  function npa$1(arg, where) {
    let name
    let spec
    if (typeof arg === 'object') {
      if (arg instanceof Result && (!where || where === arg.where)) {
        return arg
      } else if (arg.name && arg.rawSpec) {
        return npa$1.resolve(arg.name, arg.rawSpec, where || arg.where)
      } else {
        return npa$1(arg.raw, where || arg.where)
      }
    }
    const nameEndsAt = arg.indexOf('@', 1) // Skip possible leading @
    const namePart = nameEndsAt > 0 ? arg.slice(0, nameEndsAt) : arg
    if (isURL.test(arg)) {
      spec = arg
    } else if (isGit.test(arg)) {
      spec = `git+ssh://${arg}`
      // eslint-disable-next-line max-len
    } else if (
      !namePart.startsWith('@') &&
      (hasSlashes.test(namePart) || isFileType.test(namePart))
    ) {
      spec = arg
    } else if (nameEndsAt > 0) {
      name = namePart
      spec = arg.slice(nameEndsAt + 1) || '*'
    } else {
      const valid = validatePackageName(arg)
      if (valid.validForOldPackages) {
        name = arg
        spec = '*'
      } else {
        spec = arg
      }
    }
    return resolve(name, spec, where, arg)
  }
  function isFileSpec(spec) {
    if (!spec) {
      return false
    }
    if (spec.toLowerCase().startsWith('file:')) {
      return true
    }
    if (isWindows) {
      return isWindowsFile.test(spec)
    }
    // We never hit this in windows tests, obviously
    /* istanbul ignore next */
    return isPosixFile.test(spec)
  }
  function isAliasSpec(spec) {
    if (!spec) {
      return false
    }
    return spec.toLowerCase().startsWith('npm:')
  }
  function resolve(name, spec, where, arg) {
    const res = new Result({
      raw: arg,
      name: name,
      rawSpec: spec,
      fromArgument: arg != null
    })
    if (name) {
      res.name = name
    }
    if (!where) {
      where = process.cwd()
    }
    if (isFileSpec(spec)) {
      return fromFile(res, where)
    } else if (isAliasSpec(spec)) {
      return fromAlias(res, where)
    }
    const hosted = HostedGit.fromUrl(spec, {
      noGitPlus: true,
      noCommittish: true
    })
    if (hosted) {
      return fromHostedGit(res, hosted)
    } else if (spec && isURL.test(spec)) {
      return fromURL(res)
    } else if (spec && (hasSlashes.test(spec) || isFileType.test(spec))) {
      return fromFile(res, where)
    } else {
      return fromRegistry(res)
    }
  }
  function toPurl(arg, reg = defaultRegistry) {
    const res = npa$1(arg)
    if (res.type !== 'version') {
      throw invalidPurlType(res.type, res.raw)
    }

    // URI-encode leading @ of scoped packages
    let purl = 'pkg:npm/' + res.name.replace(/^@/, '%40') + '@' + res.rawSpec
    if (reg !== defaultRegistry) {
      purl += '?repository_url=' + reg
    }
    return purl
  }
  function invalidPackageName(name, valid, raw) {
    // eslint-disable-next-line max-len
    const err = new Error(
      `Invalid package name "${name}" of package "${raw}": ${valid.errors.join('; ')}.`
    )
    err.code = 'EINVALIDPACKAGENAME'
    return err
  }
  function invalidTagName(name, raw) {
    // eslint-disable-next-line max-len
    const err = new Error(
      `Invalid tag name "${name}" of package "${raw}": Tags may not have any characters that encodeURIComponent encodes.`
    )
    err.code = 'EINVALIDTAGNAME'
    return err
  }
  function invalidPurlType(type, raw) {
    // eslint-disable-next-line max-len
    const err = new Error(
      `Invalid type "${type}" of package "${raw}": Purl can only be generated for "version" types.`
    )
    err.code = 'EINVALIDPURLTYPE'
    return err
  }
  class Result {
    constructor(opts) {
      this.type = opts.type
      this.registry = opts.registry
      this.where = opts.where
      if (opts.raw == null) {
        this.raw = opts.name ? `${opts.name}@${opts.rawSpec}` : opts.rawSpec
      } else {
        this.raw = opts.raw
      }
      this.name = undefined
      this.escapedName = undefined
      this.scope = undefined
      this.rawSpec = opts.rawSpec || ''
      this.saveSpec = opts.saveSpec
      this.fetchSpec = opts.fetchSpec
      if (opts.name) {
        this.setName(opts.name)
      }
      this.gitRange = opts.gitRange
      this.gitCommittish = opts.gitCommittish
      this.gitSubdir = opts.gitSubdir
      this.hosted = opts.hosted
    }

    // TODO move this to a getter/setter in a semver major
    setName(name) {
      const valid = validatePackageName(name)
      if (!valid.validForOldPackages) {
        throw invalidPackageName(name, valid, this.raw)
      }
      this.name = name
      this.scope =
        name[0] === '@' ? name.slice(0, name.indexOf('/')) : undefined
      // scoped packages in couch must have slash url-encoded, e.g. @foo%2Fbar
      this.escapedName = name.replace('/', '%2f')
      return this
    }
    toString() {
      const full = []
      if (this.name != null && this.name !== '') {
        full.push(this.name)
      }
      const spec = this.saveSpec || this.fetchSpec || this.rawSpec
      if (spec != null && spec !== '') {
        full.push(spec)
      }
      return full.length ? full.join('@') : this.raw
    }
    toJSON() {
      const result = Object.assign({}, this)
      delete result.hosted
      return result
    }
  }

  // sets res.gitCommittish, res.gitRange, and res.gitSubdir
  function setGitAttrs(res, committish) {
    if (!committish) {
      res.gitCommittish = null
      return
    }

    // for each :: separated item:
    for (const part of committish.split('::')) {
      // if the item has no : the n it is a commit-ish
      if (!part.includes(':')) {
        if (res.gitRange) {
          throw new Error(
            'cannot override existing semver range with a committish'
          )
        }
        if (res.gitCommittish) {
          throw new Error(
            'cannot override existing committish with a second committish'
          )
        }
        res.gitCommittish = part
        continue
      }
      // split on name:value
      const [name, value] = part.split(':')
      // if name is semver do semver lookup of ref or tag
      if (name === 'semver') {
        if (res.gitCommittish) {
          throw new Error(
            'cannot override existing committish with a semver range'
          )
        }
        if (res.gitRange) {
          throw new Error(
            'cannot override existing semver range with a second semver range'
          )
        }
        res.gitRange = decodeURIComponent(value)
        continue
      }
      if (name === 'path') {
        if (res.gitSubdir) {
          throw new Error('cannot override existing path with a second path')
        }
        res.gitSubdir = `/${value}`
        continue
      }
      log.warn('npm-package-arg', `ignoring unknown key "${name}"`)
    }
  }

  // Taken from: EncodePathChars and lookup_table in src/node_url.cc
  // url.pathToFileURL only returns absolute references.  We can't use it to encode paths.
  // encodeURI mangles windows paths. We can't use it to encode paths.
  // Under the hood, url.pathToFileURL does a limited set of encoding, with an extra windows step, and then calls path.resolve.
  // The encoding node does without path.resolve is not available outside of the source, so we are recreating it here.
  const encodedPathChars = new Map([
    ['\0', '%00'],
    ['\t', '%09'],
    ['\n', '%0A'],
    ['\r', '%0D'],
    [' ', '%20'],
    ['"', '%22'],
    ['#', '%23'],
    ['%', '%25'],
    ['?', '%3F'],
    ['[', '%5B'],
    ['\\', isWindows ? '/' : '%5C'],
    [']', '%5D'],
    ['^', '%5E'],
    ['|', '%7C'],
    ['~', '%7E']
  ])
  function pathToFileURL(str) {
    let result = ''
    for (let i = 0; i < str.length; i++) {
      result = `${result}${encodedPathChars.get(str[i]) ?? str[i]}`
    }
    if (result.startsWith('file:')) {
      return result
    }
    return `file:${result}`
  }
  function fromFile(res, where) {
    res.type = isFileType.test(res.rawSpec) ? 'file' : 'directory'
    res.where = where
    let rawSpec = pathToFileURL(res.rawSpec)
    if (rawSpec.startsWith('file:/')) {
      // XXX backwards compatibility lack of compliance with RFC 8089

      // turn file://path into file:/path
      if (/^file:\/\/[^/]/.test(rawSpec)) {
        rawSpec = `file:/${rawSpec.slice(5)}`
      }

      // turn file:/../path into file:../path
      // for 1 or 3 leading slashes (2 is already ruled out from handling file:// explicitly above)
      if (/^\/{1,3}\.\.?(\/|$)/.test(rawSpec.slice(5))) {
        rawSpec = rawSpec.replace(/^file:\/{1,3}/, 'file:')
      }
    }
    let resolvedUrl
    let specUrl
    try {
      // always put the '/' on "where", or else file:foo from /path/to/bar goes to /path/to/foo, when we want it to be /path/to/bar/foo
      resolvedUrl = new URL(rawSpec, `${pathToFileURL(path.resolve(where))}/`)
      specUrl = new URL(rawSpec)
    } catch (originalError) {
      const er = new Error('Invalid file: URL, must comply with RFC 8089')
      throw Object.assign(er, {
        raw: res.rawSpec,
        spec: res,
        where,
        originalError
      })
    }

    // turn /C:/blah into just C:/blah on windows
    let specPath = decodeURIComponent(specUrl.pathname)
    let resolvedPath = decodeURIComponent(resolvedUrl.pathname)
    if (isWindows) {
      specPath = specPath.replace(/^\/+([a-z]:\/)/i, '$1')
      resolvedPath = resolvedPath.replace(/^\/+([a-z]:\/)/i, '$1')
    }

    // replace ~ with homedir, but keep the ~ in the saveSpec
    // otherwise, make it relative to where param
    if (/^\/~(\/|$)/.test(specPath)) {
      res.saveSpec = `file:${specPath.substr(1)}`
      resolvedPath = path.resolve(homedir(), specPath.substr(3))
    } else if (!path.isAbsolute(rawSpec.slice(5))) {
      res.saveSpec = `file:${path.relative(where, resolvedPath)}`
    } else {
      res.saveSpec = `file:${path.resolve(resolvedPath)}`
    }
    res.fetchSpec = path.resolve(where, resolvedPath)
    // re-normalize the slashes in saveSpec due to node:path/win32 behavior in windows
    res.saveSpec = res.saveSpec.split('\\').join('/')
    // Ignoring because this only happens in windows
    /* istanbul ignore next */
    if (res.saveSpec.startsWith('file://')) {
      // normalization of \\win32\root paths can cause a double / which we don't want
      res.saveSpec = `file:/${res.saveSpec.slice(7)}`
    }
    return res
  }
  function fromHostedGit(res, hosted) {
    res.type = 'git'
    res.hosted = hosted
    res.saveSpec = hosted.toString({
      noGitPlus: false,
      noCommittish: false
    })
    res.fetchSpec =
      hosted.getDefaultRepresentation() === 'shortcut'
        ? null
        : hosted.toString()
    setGitAttrs(res, hosted.committish)
    return res
  }
  function unsupportedURLType(protocol, spec) {
    const err = new Error(`Unsupported URL Type "${protocol}": ${spec}`)
    err.code = 'EUNSUPPORTEDPROTOCOL'
    return err
  }
  function fromURL(res) {
    let rawSpec = res.rawSpec
    res.saveSpec = rawSpec
    if (rawSpec.startsWith('git+ssh:')) {
      // git ssh specifiers are overloaded to also use scp-style git
      // specifiers, so we have to parse those out and treat them special.
      // They are NOT true URIs, so we can't hand them to URL.

      // This regex looks for things that look like:
      // git+ssh://git@my.custom.git.com:username/project.git#deadbeef
      // ...and various combinations. The username in the beginning is *required*.
      const matched = rawSpec.match(
        /^git\+ssh:\/\/([^:#]+:[^#]+(?:\.git)?)(?:#(.*))?$/i
      )
      // Filter out all-number "usernames" which are really port numbers
      // They can either be :1234 :1234/ or :1234/path but not :12abc
      if (matched && !matched[1].match(isPortNumber)) {
        res.type = 'git'
        setGitAttrs(res, matched[2])
        res.fetchSpec = matched[1]
        return res
      }
    } else if (rawSpec.startsWith('git+file://')) {
      // URL can't handle windows paths
      rawSpec = rawSpec.replace(/\\/g, '/')
    }
    const parsedUrl = new URL(rawSpec)
    // check the protocol, and then see if it's git or not
    switch (parsedUrl.protocol) {
      case 'git:':
      case 'git+http:':
      case 'git+https:':
      case 'git+rsync:':
      case 'git+ftp:':
      case 'git+file:':
      case 'git+ssh:':
        res.type = 'git'
        setGitAttrs(res, parsedUrl.hash.slice(1))
        if (
          parsedUrl.protocol === 'git+file:' &&
          /^git\+file:\/\/[a-z]:/i.test(rawSpec)
        ) {
          // URL can't handle drive letters on windows file paths, the host can't contain a :
          res.fetchSpec = `git+file://${parsedUrl.host.toLowerCase()}:${parsedUrl.pathname}`
        } else {
          parsedUrl.hash = ''
          res.fetchSpec = parsedUrl.toString()
        }
        if (res.fetchSpec.startsWith('git+')) {
          res.fetchSpec = res.fetchSpec.slice(4)
        }
        break
      case 'http:':
      case 'https:':
        res.type = 'remote'
        res.fetchSpec = res.saveSpec
        break
      default:
        throw unsupportedURLType(parsedUrl.protocol, rawSpec)
    }
    return res
  }
  function fromAlias(res, where) {
    const subSpec = npa$1(res.rawSpec.substr(4), where)
    if (subSpec.type === 'alias') {
      throw new Error('nested aliases not supported')
    }
    if (!subSpec.registry) {
      throw new Error('aliases only work for registry deps')
    }
    if (!subSpec.name) {
      throw new Error('aliases must have a name')
    }
    res.subSpec = subSpec
    res.registry = true
    res.type = 'alias'
    res.saveSpec = null
    res.fetchSpec = null
    return res
  }
  function fromRegistry(res) {
    res.registry = true
    const spec = res.rawSpec.trim()
    // no save spec for registry components as we save based on the fetched
    // version, not on the argument so this can't compute that.
    res.saveSpec = null
    res.fetchSpec = spec
    const version = semver.valid(spec, true)
    const range = semver.validRange(spec, true)
    if (version) {
      res.type = 'version'
    } else if (range) {
      res.type = 'range'
    } else {
      if (encodeURIComponent(spec) !== spec) {
        throw invalidTagName(spec, res.raw)
      }
      res.type = 'tag'
    }
    return res
  }
  npa.exports = npa$1
  npa.exports.resolve = resolve
  npa.exports.toPurl = toPurl
  npa.exports.Result = Result
  return npa.exports
}

const npaExports = requireNpa()

const lib$g = {}

const lib$f = {}

const lib$e = {}

let hasRequiredLib$g
function requireLib$g() {
  if (hasRequiredLib$g) {
    return lib$e
  }
  hasRequiredLib$g = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(lib$e, '__esModule', {
    value: true
  })
  lib$e.hash = void 0
  const crypto_1 = __importDefault(require$$0$e)
  lib$e.hash =
    // @ts-expect-error -- crypto.hash is supported in Node 21.7.0+, 20.12.0+
    crypto_1.default.hash ??
    ((algorithm, data, outputEncoding) =>
      crypto_1.default
        .createHash(algorithm)
        .update(data)
        .digest(outputEncoding))
  return lib$e
}

const lib$d = {}

let polyfills
let hasRequiredPolyfills
function requirePolyfills() {
  if (hasRequiredPolyfills) {
    return polyfills
  }
  hasRequiredPolyfills = 1
  const constants = require$$0$f
  const origCwd = process.cwd
  let cwd = null
  const platform = process.env.GRACEFUL_FS_PLATFORM || process.platform
  process.cwd = function () {
    if (!cwd) {
      cwd = origCwd.call(process)
    }
    return cwd
  }
  try {
    process.cwd()
  } catch (er) {}

  // This check is needed until node.js 12 is required
  if (typeof process.chdir === 'function') {
    const chdir = process.chdir
    process.chdir = function (d) {
      cwd = null
      chdir.call(process, d)
    }
    if (Object.setPrototypeOf) {
      Object.setPrototypeOf(process.chdir, chdir)
    }
  }
  polyfills = patch
  function patch(fs) {
    // (re-)implement some things that are known busted or missing.

    // lchmod, broken prior to 0.6.2
    // back-port the fix here.
    if (
      constants.hasOwnProperty('O_SYMLINK') &&
      process.version.match(/^v0\.6\.[0-2]|^v0\.5\./)
    ) {
      patchLchmod(fs)
    }

    // lutimes implementation, or no-op
    if (!fs.lutimes) {
      patchLutimes(fs)
    }

    // https://github.com/isaacs/node-graceful-fs/issues/4
    // Chown should not fail on einval or eperm if non-root.
    // It should not fail on enosys ever, as this just indicates
    // that a fs doesn't support the intended operation.

    fs.chown = chownFix(fs.chown)
    fs.fchown = chownFix(fs.fchown)
    fs.lchown = chownFix(fs.lchown)
    fs.chmod = chmodFix(fs.chmod)
    fs.fchmod = chmodFix(fs.fchmod)
    fs.lchmod = chmodFix(fs.lchmod)
    fs.chownSync = chownFixSync(fs.chownSync)
    fs.fchownSync = chownFixSync(fs.fchownSync)
    fs.lchownSync = chownFixSync(fs.lchownSync)
    fs.chmodSync = chmodFixSync(fs.chmodSync)
    fs.fchmodSync = chmodFixSync(fs.fchmodSync)
    fs.lchmodSync = chmodFixSync(fs.lchmodSync)
    fs.stat = statFix(fs.stat)
    fs.fstat = statFix(fs.fstat)
    fs.lstat = statFix(fs.lstat)
    fs.statSync = statFixSync(fs.statSync)
    fs.fstatSync = statFixSync(fs.fstatSync)
    fs.lstatSync = statFixSync(fs.lstatSync)

    // if lchmod/lchown do not exist, then make them no-ops
    if (fs.chmod && !fs.lchmod) {
      fs.lchmod = function (path, mode, cb) {
        if (cb) {
          process.nextTick(cb)
        }
      }
      fs.lchmodSync = function () {}
    }
    if (fs.chown && !fs.lchown) {
      fs.lchown = function (path, uid, gid, cb) {
        if (cb) {
          process.nextTick(cb)
        }
      }
      fs.lchownSync = function () {}
    }

    // on Windows, A/V software can lock the directory, causing this
    // to fail with an EACCES or EPERM if the directory contains newly
    // created files.  Try again on failure, for up to 60 seconds.

    // Set the timeout this long because some Windows Anti-Virus, such as Parity
    // bit9, may lock files for up to a minute, causing npm package install
    // failures. Also, take care to yield the scheduler. Windows scheduling gives
    // CPU to a busy looping process, which can cause the program causing the lock
    // contention to be starved of CPU by node, so the contention doesn't resolve.
    if (platform === 'win32') {
      fs.rename =
        typeof fs.rename !== 'function'
          ? fs.rename
          : (function (fs$rename) {
              function rename(from, to, cb) {
                const start = Date.now()
                let backoff = 0
                fs$rename(from, to, function CB(er) {
                  if (
                    er &&
                    (er.code === 'EACCES' ||
                      er.code === 'EPERM' ||
                      er.code === 'EBUSY') &&
                    Date.now() - start < 60000
                  ) {
                    setTimeout(function () {
                      fs.stat(to, function (stater, st) {
                        if (stater && stater.code === 'ENOENT') {
                          fs$rename(from, to, CB)
                        } else {
                          cb(er)
                        }
                      })
                    }, backoff)
                    if (backoff < 100) {
                      backoff += 10
                    }
                    return
                  }
                  if (cb) {
                    cb(er)
                  }
                })
              }
              if (Object.setPrototypeOf) {
                Object.setPrototypeOf(rename, fs$rename)
              }
              return rename
            })(fs.rename)
    }

    // if read() returns EAGAIN, then just try it again.
    fs.read =
      typeof fs.read !== 'function'
        ? fs.read
        : (function (fs$read) {
            function read(fd, buffer, offset, length, position, callback_) {
              let callback
              if (callback_ && typeof callback_ === 'function') {
                let eagCounter = 0
                callback = function (er, _, __) {
                  if (er && er.code === 'EAGAIN' && eagCounter < 10) {
                    eagCounter++
                    return fs$read.call(
                      fs,
                      fd,
                      buffer,
                      offset,
                      length,
                      position,
                      callback
                    )
                  }
                  callback_.apply(this, arguments)
                }
              }
              return fs$read.call(
                fs,
                fd,
                buffer,
                offset,
                length,
                position,
                callback
              )
            }

            // This ensures `util.promisify` works as it does for native `fs.read`.
            if (Object.setPrototypeOf) {
              Object.setPrototypeOf(read, fs$read)
            }
            return read
          })(fs.read)
    fs.readSync =
      typeof fs.readSync !== 'function'
        ? fs.readSync
        : (function (fs$readSync) {
            return function (fd, buffer, offset, length, position) {
              let eagCounter = 0
              while (true) {
                try {
                  return fs$readSync.call(
                    fs,
                    fd,
                    buffer,
                    offset,
                    length,
                    position
                  )
                } catch (er) {
                  if (er.code === 'EAGAIN' && eagCounter < 10) {
                    eagCounter++
                    continue
                  }
                  throw er
                }
              }
            }
          })(fs.readSync)
    function patchLchmod(fs) {
      fs.lchmod = function (path, mode, callback) {
        fs.open(
          path,
          constants.O_WRONLY | constants.O_SYMLINK,
          mode,
          function (err, fd) {
            if (err) {
              if (callback) {
                callback(err)
              }
              return
            }
            // prefer to return the chmod error, if one occurs,
            // but still try to close, and report closing errors if they occur.
            fs.fchmod(fd, mode, function (err) {
              fs.close(fd, function (err2) {
                if (callback) {
                  callback(err || err2)
                }
              })
            })
          }
        )
      }
      fs.lchmodSync = function (path, mode) {
        const fd = fs.openSync(
          path,
          constants.O_WRONLY | constants.O_SYMLINK,
          mode
        )

        // prefer to return the chmod error, if one occurs,
        // but still try to close, and report closing errors if they occur.
        let threw = true
        let ret
        try {
          ret = fs.fchmodSync(fd, mode)
          threw = false
        } finally {
          if (threw) {
            try {
              fs.closeSync(fd)
            } catch (er) {}
          } else {
            fs.closeSync(fd)
          }
        }
        return ret
      }
    }
    function patchLutimes(fs) {
      if (constants.hasOwnProperty('O_SYMLINK') && fs.futimes) {
        fs.lutimes = function (path, at, mt, cb) {
          fs.open(path, constants.O_SYMLINK, function (er, fd) {
            if (er) {
              if (cb) {
                cb(er)
              }
              return
            }
            fs.futimes(fd, at, mt, function (er) {
              fs.close(fd, function (er2) {
                if (cb) {
                  cb(er || er2)
                }
              })
            })
          })
        }
        fs.lutimesSync = function (path, at, mt) {
          const fd = fs.openSync(path, constants.O_SYMLINK)
          let ret
          let threw = true
          try {
            ret = fs.futimesSync(fd, at, mt)
            threw = false
          } finally {
            if (threw) {
              try {
                fs.closeSync(fd)
              } catch (er) {}
            } else {
              fs.closeSync(fd)
            }
          }
          return ret
        }
      } else if (fs.futimes) {
        fs.lutimes = function (_a, _b, _c, cb) {
          if (cb) {
            process.nextTick(cb)
          }
        }
        fs.lutimesSync = function () {}
      }
    }
    function chmodFix(orig) {
      if (!orig) {
        return orig
      }
      return function (target, mode, cb) {
        return orig.call(fs, target, mode, function (er) {
          if (chownErOk(er)) {
            er = null
          }
          if (cb) {
            cb.apply(this, arguments)
          }
        })
      }
    }
    function chmodFixSync(orig) {
      if (!orig) {
        return orig
      }
      return function (target, mode) {
        try {
          return orig.call(fs, target, mode)
        } catch (er) {
          if (!chownErOk(er)) {
            throw er
          }
        }
      }
    }
    function chownFix(orig) {
      if (!orig) {
        return orig
      }
      return function (target, uid, gid, cb) {
        return orig.call(fs, target, uid, gid, function (er) {
          if (chownErOk(er)) {
            er = null
          }
          if (cb) {
            cb.apply(this, arguments)
          }
        })
      }
    }
    function chownFixSync(orig) {
      if (!orig) {
        return orig
      }
      return function (target, uid, gid) {
        try {
          return orig.call(fs, target, uid, gid)
        } catch (er) {
          if (!chownErOk(er)) {
            throw er
          }
        }
      }
    }
    function statFix(orig) {
      if (!orig) {
        return orig
      }
      // Older versions of Node erroneously returned signed integers for
      // uid + gid.
      return function (target, options, cb) {
        if (typeof options === 'function') {
          cb = options
          options = null
        }
        function callback(er, stats) {
          if (stats) {
            if (stats.uid < 0) {
              stats.uid += 0x100000000
            }
            if (stats.gid < 0) {
              stats.gid += 0x100000000
            }
          }
          if (cb) {
            cb.apply(this, arguments)
          }
        }
        return options
          ? orig.call(fs, target, options, callback)
          : orig.call(fs, target, callback)
      }
    }
    function statFixSync(orig) {
      if (!orig) {
        return orig
      }
      // Older versions of Node erroneously returned signed integers for
      // uid + gid.
      return function (target, options) {
        const stats = options
          ? orig.call(fs, target, options)
          : orig.call(fs, target)
        if (stats) {
          if (stats.uid < 0) {
            stats.uid += 0x100000000
          }
          if (stats.gid < 0) {
            stats.gid += 0x100000000
          }
        }
        return stats
      }
    }

    // ENOSYS means that the fs doesn't support the op. Just ignore
    // that, because it doesn't matter.
    //
    // if there's no getuid, or if getuid() is something other
    // than 0, and the error is EINVAL or EPERM, then just ignore
    // it.
    //
    // This specific case is a silent failure in cp, install, tar,
    // and most other unix tools that manage permissions.
    //
    // When running as root, or if other types of errors are
    // encountered, then it's strict.
    function chownErOk(er) {
      if (!er) {
        return true
      }
      if (er.code === 'ENOSYS') {
        return true
      }
      const nonroot = !process.getuid || process.getuid() !== 0
      if (nonroot) {
        if (er.code === 'EINVAL' || er.code === 'EPERM') {
          return true
        }
      }
      return false
    }
  }
  return polyfills
}

let legacyStreams
let hasRequiredLegacyStreams
function requireLegacyStreams() {
  if (hasRequiredLegacyStreams) {
    return legacyStreams
  }
  hasRequiredLegacyStreams = 1
  const Stream = require$$0$g.Stream
  legacyStreams = legacy
  function legacy(fs) {
    return {
      ReadStream: ReadStream,
      WriteStream: WriteStream
    }
    function ReadStream(path, options) {
      if (!(this instanceof ReadStream)) {
        return new ReadStream(path, options)
      }
      Stream.call(this)
      const self = this
      this.path = path
      this.fd = null
      this.readable = true
      this.paused = false
      this.flags = 'r'
      this.mode = 438 /*=0666*/
      this.bufferSize = 64 * 1024
      options = options || {}

      // Mixin options into this
      const keys = Object.keys(options)
      for (let index = 0, length = keys.length; index < length; index++) {
        const key = keys[index]
        this[key] = options[key]
      }
      if (this.encoding) {
        this.setEncoding(this.encoding)
      }
      if (this.start !== undefined) {
        if ('number' !== typeof this.start) {
          throw TypeError('start must be a Number')
        }
        if (this.end === undefined) {
          this.end = Infinity
        } else if ('number' !== typeof this.end) {
          throw TypeError('end must be a Number')
        }
        if (this.start > this.end) {
          throw new Error('start must be <= end')
        }
        this.pos = this.start
      }
      if (this.fd !== null) {
        process.nextTick(function () {
          self._read()
        })
        return
      }
      fs.open(this.path, this.flags, this.mode, function (err, fd) {
        if (err) {
          self.emit('error', err)
          self.readable = false
          return
        }
        self.fd = fd
        self.emit('open', fd)
        self._read()
      })
    }
    function WriteStream(path, options) {
      if (!(this instanceof WriteStream)) {
        return new WriteStream(path, options)
      }
      Stream.call(this)
      this.path = path
      this.fd = null
      this.writable = true
      this.flags = 'w'
      this.encoding = 'binary'
      this.mode = 438 /*=0666*/
      this.bytesWritten = 0
      options = options || {}

      // Mixin options into this
      const keys = Object.keys(options)
      for (let index = 0, length = keys.length; index < length; index++) {
        const key = keys[index]
        this[key] = options[key]
      }
      if (this.start !== undefined) {
        if ('number' !== typeof this.start) {
          throw TypeError('start must be a Number')
        }
        if (this.start < 0) {
          throw new Error('start must be >= zero')
        }
        this.pos = this.start
      }
      this.busy = false
      this._queue = []
      if (this.fd === null) {
        this._open = fs.open
        this._queue.push([
          this._open,
          this.path,
          this.flags,
          this.mode,
          undefined
        ])
        this.flush()
      }
    }
  }
  return legacyStreams
}

let clone_1
let hasRequiredClone
function requireClone() {
  if (hasRequiredClone) {
    return clone_1
  }
  hasRequiredClone = 1
  clone_1 = clone
  const getPrototypeOf =
    Object.getPrototypeOf ||
    function (obj) {
      return obj.__proto__
    }
  function clone(obj) {
    if (obj === null || typeof obj !== 'object') {
      return obj
    }
    const copy =
      obj instanceof Object
        ? {
            __proto__: getPrototypeOf(obj)
          }
        : Object.create(null)
    Object.getOwnPropertyNames(obj).forEach(function (key) {
      Object.defineProperty(
        copy,
        key,
        Object.getOwnPropertyDescriptor(obj, key)
      )
    })
    return copy
  }
  return clone_1
}

let gracefulFs
let hasRequiredGracefulFs
function requireGracefulFs() {
  if (hasRequiredGracefulFs) {
    return gracefulFs
  }
  hasRequiredGracefulFs = 1
  const fs = require$$0$6
  const polyfills = requirePolyfills()
  const legacy = requireLegacyStreams()
  const clone = requireClone()
  const util = require$$0$4

  /* istanbul ignore next - node 0.x polyfill */
  let gracefulQueue
  let previousSymbol

  /* istanbul ignore else - node 0.x polyfill */
  if (typeof Symbol === 'function' && typeof Symbol.for === 'function') {
    gracefulQueue = Symbol.for('graceful-fs.queue')
    // This is used in testing by future versions
    previousSymbol = Symbol.for('graceful-fs.previous')
  } else {
    gracefulQueue = '___graceful-fs.queue'
    previousSymbol = '___graceful-fs.previous'
  }
  function noop() {}
  function publishQueue(context, queue) {
    Object.defineProperty(context, gracefulQueue, {
      get: function () {
        return queue
      }
    })
  }
  let debug = noop
  if (util.debuglog) {
    debug = util.debuglog('gfs4')
  } else if (/\bgfs4\b/i.test(process.env.NODE_DEBUG || '')) {
    debug = function () {
      var m = util.format.apply(util, arguments)
      m = 'GFS4: ' + m.split(/\n/).join('\nGFS4: ')
      console.error(m)
    }
  }

  // Once time initialization
  if (!fs[gracefulQueue]) {
    // This queue can be shared by multiple loaded instances
    const queue = global[gracefulQueue] || []
    publishQueue(fs, queue)

    // Patch fs.close/closeSync to shared queue version, because we need
    // to retry() whenever a close happens *anywhere* in the program.
    // This is essential when multiple graceful-fs instances are
    // in play at the same time.
    fs.close = (function (fs$close) {
      function close(fd, cb) {
        return fs$close.call(fs, fd, function (err) {
          // This function uses the graceful-fs shared queue
          if (!err) {
            resetQueue()
          }
          if (typeof cb === 'function') {
            cb.apply(this, arguments)
          }
        })
      }
      Object.defineProperty(close, previousSymbol, {
        value: fs$close
      })
      return close
    })(fs.close)
    fs.closeSync = (function (fs$closeSync) {
      function closeSync(fd) {
        // This function uses the graceful-fs shared queue
        fs$closeSync.apply(fs, arguments)
        resetQueue()
      }
      Object.defineProperty(closeSync, previousSymbol, {
        value: fs$closeSync
      })
      return closeSync
    })(fs.closeSync)
    if (/\bgfs4\b/i.test(process.env.NODE_DEBUG || '')) {
      process.on('exit', function () {
        debug(fs[gracefulQueue])
        require$$5$1.equal(fs[gracefulQueue].length, 0)
      })
    }
  }
  if (!global[gracefulQueue]) {
    publishQueue(global, fs[gracefulQueue])
  }
  gracefulFs = patch(clone(fs))
  if (process.env.TEST_GRACEFUL_FS_GLOBAL_PATCH && !fs.__patched) {
    gracefulFs = patch(fs)
    fs.__patched = true
  }
  function patch(fs) {
    // Everything that references the open() function needs to be in here
    polyfills(fs)
    fs.gracefulify = patch
    fs.createReadStream = createReadStream
    fs.createWriteStream = createWriteStream
    const fs$readFile = fs.readFile
    fs.readFile = readFile
    function readFile(path, options, cb) {
      if (typeof options === 'function') {
        ;(cb = options), (options = null)
      }
      return go$readFile(path, options, cb)
      function go$readFile(path, options, cb, startTime) {
        return fs$readFile(path, options, function (err) {
          if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) {
            enqueue([
              go$readFile,
              [path, options, cb],
              err,
              startTime || Date.now(),
              Date.now()
            ])
          } else {
            if (typeof cb === 'function') {
              cb.apply(this, arguments)
            }
          }
        })
      }
    }
    const fs$writeFile = fs.writeFile
    fs.writeFile = writeFile
    function writeFile(path, data, options, cb) {
      if (typeof options === 'function') {
        ;(cb = options), (options = null)
      }
      return go$writeFile(path, data, options, cb)
      function go$writeFile(path, data, options, cb, startTime) {
        return fs$writeFile(path, data, options, function (err) {
          if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) {
            enqueue([
              go$writeFile,
              [path, data, options, cb],
              err,
              startTime || Date.now(),
              Date.now()
            ])
          } else {
            if (typeof cb === 'function') {
              cb.apply(this, arguments)
            }
          }
        })
      }
    }
    const fs$appendFile = fs.appendFile
    if (fs$appendFile) {
      fs.appendFile = appendFile
    }
    function appendFile(path, data, options, cb) {
      if (typeof options === 'function') {
        ;(cb = options), (options = null)
      }
      return go$appendFile(path, data, options, cb)
      function go$appendFile(path, data, options, cb, startTime) {
        return fs$appendFile(path, data, options, function (err) {
          if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) {
            enqueue([
              go$appendFile,
              [path, data, options, cb],
              err,
              startTime || Date.now(),
              Date.now()
            ])
          } else {
            if (typeof cb === 'function') {
              cb.apply(this, arguments)
            }
          }
        })
      }
    }
    const fs$copyFile = fs.copyFile
    if (fs$copyFile) {
      fs.copyFile = copyFile
    }
    function copyFile(src, dest, flags, cb) {
      if (typeof flags === 'function') {
        cb = flags
        flags = 0
      }
      return go$copyFile(src, dest, flags, cb)
      function go$copyFile(src, dest, flags, cb, startTime) {
        return fs$copyFile(src, dest, flags, function (err) {
          if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) {
            enqueue([
              go$copyFile,
              [src, dest, flags, cb],
              err,
              startTime || Date.now(),
              Date.now()
            ])
          } else {
            if (typeof cb === 'function') {
              cb.apply(this, arguments)
            }
          }
        })
      }
    }
    const fs$readdir = fs.readdir
    fs.readdir = readdir
    const noReaddirOptionVersions = /^v[0-5]\./
    function readdir(path, options, cb) {
      if (typeof options === 'function') {
        ;(cb = options), (options = null)
      }
      const go$readdir = noReaddirOptionVersions.test(process.version)
        ? function go$readdir(path, options, cb, startTime) {
            return fs$readdir(
              path,
              fs$readdirCallback(path, options, cb, startTime)
            )
          }
        : function go$readdir(path, options, cb, startTime) {
            return fs$readdir(
              path,
              options,
              fs$readdirCallback(path, options, cb, startTime)
            )
          }
      return go$readdir(path, options, cb)
      function fs$readdirCallback(path, options, cb, startTime) {
        return function (err, files) {
          if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) {
            enqueue([
              go$readdir,
              [path, options, cb],
              err,
              startTime || Date.now(),
              Date.now()
            ])
          } else {
            if (files && files.sort) {
              files.sort()
            }
            if (typeof cb === 'function') {
              cb.call(this, err, files)
            }
          }
        }
      }
    }
    if (process.version.substr(0, 4) === 'v0.8') {
      const legStreams = legacy(fs)
      ReadStream = legStreams.ReadStream
      WriteStream = legStreams.WriteStream
    }
    const fs$ReadStream = fs.ReadStream
    if (fs$ReadStream) {
      ReadStream.prototype = Object.create(fs$ReadStream.prototype)
      ReadStream.prototype.open = ReadStream$open
    }
    const fs$WriteStream = fs.WriteStream
    if (fs$WriteStream) {
      WriteStream.prototype = Object.create(fs$WriteStream.prototype)
      WriteStream.prototype.open = WriteStream$open
    }
    Object.defineProperty(fs, 'ReadStream', {
      get: function () {
        return ReadStream
      },
      set: function (val) {
        ReadStream = val
      },
      enumerable: true,
      configurable: true
    })
    Object.defineProperty(fs, 'WriteStream', {
      get: function () {
        return WriteStream
      },
      set: function (val) {
        WriteStream = val
      },
      enumerable: true,
      configurable: true
    })

    // legacy names
    let FileReadStream = ReadStream
    Object.defineProperty(fs, 'FileReadStream', {
      get: function () {
        return FileReadStream
      },
      set: function (val) {
        FileReadStream = val
      },
      enumerable: true,
      configurable: true
    })
    let FileWriteStream = WriteStream
    Object.defineProperty(fs, 'FileWriteStream', {
      get: function () {
        return FileWriteStream
      },
      set: function (val) {
        FileWriteStream = val
      },
      enumerable: true,
      configurable: true
    })
    function ReadStream(path, options) {
      if (this instanceof ReadStream) {
        return fs$ReadStream.apply(this, arguments), this
      } else {
        return ReadStream.apply(Object.create(ReadStream.prototype), arguments)
      }
    }
    function ReadStream$open() {
      const that = this
      open(that.path, that.flags, that.mode, function (err, fd) {
        if (err) {
          if (that.autoClose) {
            that.destroy()
          }
          that.emit('error', err)
        } else {
          that.fd = fd
          that.emit('open', fd)
          that.read()
        }
      })
    }
    function WriteStream(path, options) {
      if (this instanceof WriteStream) {
        return fs$WriteStream.apply(this, arguments), this
      } else {
        return WriteStream.apply(
          Object.create(WriteStream.prototype),
          arguments
        )
      }
    }
    function WriteStream$open() {
      const that = this
      open(that.path, that.flags, that.mode, function (err, fd) {
        if (err) {
          that.destroy()
          that.emit('error', err)
        } else {
          that.fd = fd
          that.emit('open', fd)
        }
      })
    }
    function createReadStream(path, options) {
      return new fs.ReadStream(path, options)
    }
    function createWriteStream(path, options) {
      return new fs.WriteStream(path, options)
    }
    const fs$open = fs.open
    fs.open = open
    function open(path, flags, mode, cb) {
      if (typeof mode === 'function') {
        ;(cb = mode), (mode = null)
      }
      return go$open(path, flags, mode, cb)
      function go$open(path, flags, mode, cb, startTime) {
        return fs$open(path, flags, mode, function (err, fd) {
          if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) {
            enqueue([
              go$open,
              [path, flags, mode, cb],
              err,
              startTime || Date.now(),
              Date.now()
            ])
          } else {
            if (typeof cb === 'function') {
              cb.apply(this, arguments)
            }
          }
        })
      }
    }
    return fs
  }
  function enqueue(elem) {
    debug('ENQUEUE', elem[0].name, elem[1])
    fs[gracefulQueue].push(elem)
    retry()
  }

  // keep track of the timeout between retry() calls
  let retryTimer

  // reset the startTime and lastTime to now
  // this resets the start of the 60 second overall timeout as well as the
  // delay between attempts so that we'll retry these jobs sooner
  function resetQueue() {
    const now = Date.now()
    for (let i = 0; i < fs[gracefulQueue].length; ++i) {
      // entries that are only a length of 2 are from an older version, don't
      // bother modifying those since they'll be retried anyway.
      if (fs[gracefulQueue][i].length > 2) {
        fs[gracefulQueue][i][3] = now // startTime
        fs[gracefulQueue][i][4] = now // lastTime
      }
    }
    // call retry to make sure we're actively processing the queue
    retry()
  }
  function retry() {
    // clear the timer and remove it to help prevent unintended concurrency
    clearTimeout(retryTimer)
    retryTimer = undefined
    if (fs[gracefulQueue].length === 0) {
      return
    }
    const elem = fs[gracefulQueue].shift()
    const fn = elem[0]
    const args = elem[1]
    // these items may be unset if they were added by an older graceful-fs
    const err = elem[2]
    const startTime = elem[3]
    const lastTime = elem[4]

    // if we don't have a startTime we have no way of knowing if we've waited
    // long enough, so go ahead and retry this item now
    if (startTime === undefined) {
      debug('RETRY', fn.name, args)
      fn.apply(null, args)
    } else if (Date.now() - startTime >= 60000) {
      // it's been more than 60 seconds total, bail now
      debug('TIMEOUT', fn.name, args)
      const cb = args.pop()
      if (typeof cb === 'function') {
        cb.call(null, err)
      }
    } else {
      // the amount of time between the last attempt and right now
      const sinceAttempt = Date.now() - lastTime
      // the amount of time between when we first tried, and when we last tried
      // rounded up to at least 1
      const sinceStart = Math.max(lastTime - startTime, 1)
      // backoff. wait longer than the total time we've been retrying, but only
      // up to a maximum of 100ms
      const desiredDelay = Math.min(sinceStart * 1.2, 100)
      // it's been long enough since the last retry, do it again
      if (sinceAttempt >= desiredDelay) {
        debug('RETRY', fn.name, args)
        fn.apply(null, args.concat([startTime]))
      } else {
        // if we can't do this job yet, push it to the end of the queue
        // and let the next iteration check again
        fs[gracefulQueue].push(elem)
      }
    }

    // schedule our next run if one isn't already scheduled
    if (retryTimer === undefined) {
      retryTimer = setTimeout(retry, 0)
    }
  }
  return gracefulFs
}

let hasRequiredLib$f
function requireLib$f() {
  if (hasRequiredLib$f) {
    return lib$d
  }
  hasRequiredLib$f = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(lib$d, '__esModule', {
    value: true
  })
  const util_1 = require$$0$4
  const graceful_fs_1 = __importDefault(requireGracefulFs())
  lib$d.default = {
    copyFile: (0, util_1.promisify)(graceful_fs_1.default.copyFile),
    copyFileSync: graceful_fs_1.default.copyFileSync,
    createReadStream: graceful_fs_1.default.createReadStream,
    link: (0, util_1.promisify)(graceful_fs_1.default.link),
    linkSync: graceful_fs_1.default.linkSync,
    readFile: (0, util_1.promisify)(graceful_fs_1.default.readFile),
    readFileSync: graceful_fs_1.default.readFileSync,
    readdirSync: graceful_fs_1.default.readdirSync,
    stat: (0, util_1.promisify)(graceful_fs_1.default.stat),
    statSync: graceful_fs_1.default.statSync,
    unlinkSync: graceful_fs_1.default.unlinkSync,
    writeFile: (0, util_1.promisify)(graceful_fs_1.default.writeFile),
    writeFileSync: graceful_fs_1.default.writeFileSync
  }
  return lib$d
}

const lib$c = {}

const commonjs = {}

let hasRequiredCommonjs
function requireCommonjs() {
  if (hasRequiredCommonjs) {
    return commonjs
  }
  hasRequiredCommonjs = 1
  ;(function (exports) {
    const __importDefault =
      (this && this.__importDefault) ||
      function (mod) {
        return mod && mod.__esModule
          ? mod
          : {
              default: mod
            }
      }
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.Minipass =
      exports.isWritable =
      exports.isReadable =
      exports.isStream =
        void 0
    const proc =
      typeof process === 'object' && process
        ? process
        : {
            stdout: null,
            stderr: null
          }
    const node_events_1 = require$$0$a
    const node_stream_1 = __importDefault(require$$1$9)
    const node_string_decoder_1 = require$$2$3
    /**
     * Return true if the argument is a Minipass stream, Node stream, or something
     * else that Minipass can interact with.
     */
    const isStream = s =>
      !!s &&
      typeof s === 'object' &&
      (s instanceof Minipass ||
        s instanceof node_stream_1.default ||
        (0, exports.isReadable)(s) ||
        (0, exports.isWritable)(s))
    exports.isStream = isStream
    /**
     * Return true if the argument is a valid {@link Minipass.Readable}
     */
    const isReadable = s =>
      !!s &&
      typeof s === 'object' &&
      s instanceof node_events_1.EventEmitter &&
      typeof s.pipe === 'function' &&
      // node core Writable streams have a pipe() method, but it throws
      s.pipe !== node_stream_1.default.Writable.prototype.pipe
    exports.isReadable = isReadable
    /**
     * Return true if the argument is a valid {@link Minipass.Writable}
     */
    const isWritable = s =>
      !!s &&
      typeof s === 'object' &&
      s instanceof node_events_1.EventEmitter &&
      typeof s.write === 'function' &&
      typeof s.end === 'function'
    exports.isWritable = isWritable
    const EOF = Symbol('EOF')
    const MAYBE_EMIT_END = Symbol('maybeEmitEnd')
    const EMITTED_END = Symbol('emittedEnd')
    const EMITTING_END = Symbol('emittingEnd')
    const EMITTED_ERROR = Symbol('emittedError')
    const CLOSED = Symbol('closed')
    const READ = Symbol('read')
    const FLUSH = Symbol('flush')
    const FLUSHCHUNK = Symbol('flushChunk')
    const ENCODING = Symbol('encoding')
    const DECODER = Symbol('decoder')
    const FLOWING = Symbol('flowing')
    const PAUSED = Symbol('paused')
    const RESUME = Symbol('resume')
    const BUFFER = Symbol('buffer')
    const PIPES = Symbol('pipes')
    const BUFFERLENGTH = Symbol('bufferLength')
    const BUFFERPUSH = Symbol('bufferPush')
    const BUFFERSHIFT = Symbol('bufferShift')
    const OBJECTMODE = Symbol('objectMode')
    // internal event when stream is destroyed
    const DESTROYED = Symbol('destroyed')
    // internal event when stream has an error
    const ERROR = Symbol('error')
    const EMITDATA = Symbol('emitData')
    const EMITEND = Symbol('emitEnd')
    const EMITEND2 = Symbol('emitEnd2')
    const ASYNC = Symbol('async')
    const ABORT = Symbol('abort')
    const ABORTED = Symbol('aborted')
    const SIGNAL = Symbol('signal')
    const DATALISTENERS = Symbol('dataListeners')
    const DISCARDED = Symbol('discarded')
    const defer = fn => Promise.resolve().then(fn)
    const nodefer = fn => fn()
    const isEndish = ev => ev === 'end' || ev === 'finish' || ev === 'prefinish'
    const isArrayBufferLike = b =>
      b instanceof ArrayBuffer ||
      (!!b &&
        typeof b === 'object' &&
        b.constructor &&
        b.constructor.name === 'ArrayBuffer' &&
        b.byteLength >= 0)
    const isArrayBufferView = b => !Buffer.isBuffer(b) && ArrayBuffer.isView(b)
    /**
     * Internal class representing a pipe to a destination stream.
     *
     * @internal
     */
    class Pipe {
      src
      dest
      opts
      ondrain
      constructor(src, dest, opts) {
        this.src = src
        this.dest = dest
        this.opts = opts
        this.ondrain = () => src[RESUME]()
        this.dest.on('drain', this.ondrain)
      }
      unpipe() {
        this.dest.removeListener('drain', this.ondrain)
      }
      // only here for the prototype
      /* c8 ignore start */
      proxyErrors(_er) {}
      /* c8 ignore stop */
      end() {
        this.unpipe()
        if (this.opts.end) {
          this.dest.end()
        }
      }
    }
    /**
     * Internal class representing a pipe to a destination stream where
     * errors are proxied.
     *
     * @internal
     */
    class PipeProxyErrors extends Pipe {
      unpipe() {
        this.src.removeListener('error', this.proxyErrors)
        super.unpipe()
      }
      constructor(src, dest, opts) {
        super(src, dest, opts)
        this.proxyErrors = er => dest.emit('error', er)
        src.on('error', this.proxyErrors)
      }
    }
    const isObjectModeOptions = o => !!o.objectMode
    const isEncodingOptions = o =>
      !o.objectMode && !!o.encoding && o.encoding !== 'buffer'
    /**
     * Main export, the Minipass class
     *
     * `RType` is the type of data emitted, defaults to Buffer
     *
     * `WType` is the type of data to be written, if RType is buffer or string,
     * then any {@link Minipass.ContiguousData} is allowed.
     *
     * `Events` is the set of event handler signatures that this object
     * will emit, see {@link Minipass.Events}
     */
    class Minipass extends node_events_1.EventEmitter {
      [FLOWING] = false;
      [PAUSED] = false;
      [PIPES] = [];
      [BUFFER] = [];
      [OBJECTMODE];
      [ENCODING];
      [ASYNC];
      [DECODER];
      [EOF] = false;
      [EMITTED_END] = false;
      [EMITTING_END] = false;
      [CLOSED] = false;
      [EMITTED_ERROR] = null;
      [BUFFERLENGTH] = 0;
      [DESTROYED] = false;
      [SIGNAL];
      [ABORTED] = false;
      [DATALISTENERS] = 0;
      [DISCARDED] = false
      /**
       * true if the stream can be written
       */
      writable = true
      /**
       * true if the stream can be read
       */
      readable = true
      /**
       * If `RType` is Buffer, then options do not need to be provided.
       * Otherwise, an options object must be provided to specify either
       * {@link Minipass.SharedOptions.objectMode} or
       * {@link Minipass.SharedOptions.encoding}, as appropriate.
       */
      constructor(...args) {
        const options = args[0] || {}
        super()
        if (options.objectMode && typeof options.encoding === 'string') {
          throw new TypeError(
            'Encoding and objectMode may not be used together'
          )
        }
        if (isObjectModeOptions(options)) {
          this[OBJECTMODE] = true
          this[ENCODING] = null
        } else if (isEncodingOptions(options)) {
          this[ENCODING] = options.encoding
          this[OBJECTMODE] = false
        } else {
          this[OBJECTMODE] = false
          this[ENCODING] = null
        }
        this[ASYNC] = !!options.async
        this[DECODER] = this[ENCODING]
          ? new node_string_decoder_1.StringDecoder(this[ENCODING])
          : null
        //@ts-ignore - private option for debugging and testing
        if (options && options.debugExposeBuffer === true) {
          Object.defineProperty(this, 'buffer', {
            get: () => this[BUFFER]
          })
        }
        //@ts-ignore - private option for debugging and testing
        if (options && options.debugExposePipes === true) {
          Object.defineProperty(this, 'pipes', {
            get: () => this[PIPES]
          })
        }
        const { signal } = options
        if (signal) {
          this[SIGNAL] = signal
          if (signal.aborted) {
            this[ABORT]()
          } else {
            signal.addEventListener('abort', () => this[ABORT]())
          }
        }
      }
      /**
       * The amount of data stored in the buffer waiting to be read.
       *
       * For Buffer strings, this will be the total byte length.
       * For string encoding streams, this will be the string character length,
       * according to JavaScript's `string.length` logic.
       * For objectMode streams, this is a count of the items waiting to be
       * emitted.
       */
      get bufferLength() {
        return this[BUFFERLENGTH]
      }
      /**
       * The `BufferEncoding` currently in use, or `null`
       */
      get encoding() {
        return this[ENCODING]
      }
      /**
       * @deprecated - This is a read only property
       */
      set encoding(_enc) {
        throw new Error('Encoding must be set at instantiation time')
      }
      /**
       * @deprecated - Encoding may only be set at instantiation time
       */
      setEncoding(_enc) {
        throw new Error('Encoding must be set at instantiation time')
      }
      /**
       * True if this is an objectMode stream
       */
      get objectMode() {
        return this[OBJECTMODE]
      }
      /**
       * @deprecated - This is a read-only property
       */
      set objectMode(_om) {
        throw new Error('objectMode must be set at instantiation time')
      }
      /**
       * true if this is an async stream
       */
      get ['async']() {
        return this[ASYNC]
      }
      /**
       * Set to true to make this stream async.
       *
       * Once set, it cannot be unset, as this would potentially cause incorrect
       * behavior.  Ie, a sync stream can be made async, but an async stream
       * cannot be safely made sync.
       */
      set ['async'](a) {
        this[ASYNC] = this[ASYNC] || !!a
      }
      // drop everything and get out of the flow completely
      [ABORT]() {
        this[ABORTED] = true
        this.emit('abort', this[SIGNAL]?.reason)
        this.destroy(this[SIGNAL]?.reason)
      }
      /**
       * True if the stream has been aborted.
       */
      get aborted() {
        return this[ABORTED]
      }
      /**
       * No-op setter. Stream aborted status is set via the AbortSignal provided
       * in the constructor options.
       */
      set aborted(_) {}
      write(chunk, encoding, cb) {
        if (this[ABORTED]) {
          return false
        }
        if (this[EOF]) {
          throw new Error('write after end')
        }
        if (this[DESTROYED]) {
          this.emit(
            'error',
            Object.assign(
              new Error('Cannot call write after a stream was destroyed'),
              {
                code: 'ERR_STREAM_DESTROYED'
              }
            )
          )
          return true
        }
        if (typeof encoding === 'function') {
          cb = encoding
          encoding = 'utf8'
        }
        if (!encoding) {
          encoding = 'utf8'
        }
        const fn = this[ASYNC] ? defer : nodefer
        // convert array buffers and typed array views into buffers
        // at some point in the future, we may want to do the opposite!
        // leave strings and buffers as-is
        // anything is only allowed if in object mode, so throw
        if (!this[OBJECTMODE] && !Buffer.isBuffer(chunk)) {
          if (isArrayBufferView(chunk)) {
            //@ts-ignore - sinful unsafe type changing
            chunk = Buffer.from(
              chunk.buffer,
              chunk.byteOffset,
              chunk.byteLength
            )
          } else if (isArrayBufferLike(chunk)) {
            //@ts-ignore - sinful unsafe type changing
            chunk = Buffer.from(chunk)
          } else if (typeof chunk !== 'string') {
            throw new Error(
              'Non-contiguous data written to non-objectMode stream'
            )
          }
        }
        // handle object mode up front, since it's simpler
        // this yields better performance, fewer checks later.
        if (this[OBJECTMODE]) {
          // maybe impossible?
          /* c8 ignore start */
          if (this[FLOWING] && this[BUFFERLENGTH] !== 0) {
            this[FLUSH](true)
          }
          /* c8 ignore stop */
          if (this[FLOWING]) {
            this.emit('data', chunk)
          } else {
            this[BUFFERPUSH](chunk)
          }
          if (this[BUFFERLENGTH] !== 0) {
            this.emit('readable')
          }
          if (cb) {
            fn(cb)
          }
          return this[FLOWING]
        }
        // at this point the chunk is a buffer or string
        // don't buffer it up or send it to the decoder
        if (!chunk.length) {
          if (this[BUFFERLENGTH] !== 0) {
            this.emit('readable')
          }
          if (cb) {
            fn(cb)
          }
          return this[FLOWING]
        }
        // fast-path writing strings of same encoding to a stream with
        // an empty buffer, skipping the buffer/decoder dance
        if (
          typeof chunk === 'string' &&
          // unless it is a string already ready for us to use
          !(encoding === this[ENCODING] && !this[DECODER]?.lastNeed)
        ) {
          //@ts-ignore - sinful unsafe type change
          chunk = Buffer.from(chunk, encoding)
        }
        if (Buffer.isBuffer(chunk) && this[ENCODING]) {
          //@ts-ignore - sinful unsafe type change
          chunk = this[DECODER].write(chunk)
        }
        // Note: flushing CAN potentially switch us into not-flowing mode
        if (this[FLOWING] && this[BUFFERLENGTH] !== 0) {
          this[FLUSH](true)
        }
        if (this[FLOWING]) {
          this.emit('data', chunk)
        } else {
          this[BUFFERPUSH](chunk)
        }
        if (this[BUFFERLENGTH] !== 0) {
          this.emit('readable')
        }
        if (cb) {
          fn(cb)
        }
        return this[FLOWING]
      }
      /**
       * Low-level explicit read method.
       *
       * In objectMode, the argument is ignored, and one item is returned if
       * available.
       *
       * `n` is the number of bytes (or in the case of encoding streams,
       * characters) to consume. If `n` is not provided, then the entire buffer
       * is returned, or `null` is returned if no data is available.
       *
       * If `n` is greater that the amount of data in the internal buffer,
       * then `null` is returned.
       */
      read(n) {
        if (this[DESTROYED]) {
          return null
        }
        this[DISCARDED] = false
        if (
          this[BUFFERLENGTH] === 0 ||
          n === 0 ||
          (n && n > this[BUFFERLENGTH])
        ) {
          this[MAYBE_EMIT_END]()
          return null
        }
        if (this[OBJECTMODE]) {
          n = null
        }
        if (this[BUFFER].length > 1 && !this[OBJECTMODE]) {
          // not object mode, so if we have an encoding, then RType is string
          // otherwise, must be Buffer
          this[BUFFER] = [
            this[ENCODING]
              ? this[BUFFER].join('')
              : Buffer.concat(this[BUFFER], this[BUFFERLENGTH])
          ]
        }
        const ret = this[READ](n || null, this[BUFFER][0])
        this[MAYBE_EMIT_END]()
        return ret
      }
      [READ](n, chunk) {
        if (this[OBJECTMODE]) {
          this[BUFFERSHIFT]()
        } else {
          const c = chunk
          if (n === c.length || n === null) {
            this[BUFFERSHIFT]()
          } else if (typeof c === 'string') {
            this[BUFFER][0] = c.slice(n)
            chunk = c.slice(0, n)
            this[BUFFERLENGTH] -= n
          } else {
            this[BUFFER][0] = c.subarray(n)
            chunk = c.subarray(0, n)
            this[BUFFERLENGTH] -= n
          }
        }
        this.emit('data', chunk)
        if (!this[BUFFER].length && !this[EOF]) {
          this.emit('drain')
        }
        return chunk
      }
      end(chunk, encoding, cb) {
        if (typeof chunk === 'function') {
          cb = chunk
          chunk = undefined
        }
        if (typeof encoding === 'function') {
          cb = encoding
          encoding = 'utf8'
        }
        if (chunk !== undefined) {
          this.write(chunk, encoding)
        }
        if (cb) {
          this.once('end', cb)
        }
        this[EOF] = true
        this.writable = false
        // if we haven't written anything, then go ahead and emit,
        // even if we're not reading.
        // we'll re-emit if a new 'end' listener is added anyway.
        // This makes MP more suitable to write-only use cases.
        if (this[FLOWING] || !this[PAUSED]) {
          this[MAYBE_EMIT_END]()
        }
        return this
      }
      // don't let the internal resume be overwritten
      [RESUME]() {
        if (this[DESTROYED]) {
          return
        }
        if (!this[DATALISTENERS] && !this[PIPES].length) {
          this[DISCARDED] = true
        }
        this[PAUSED] = false
        this[FLOWING] = true
        this.emit('resume')
        if (this[BUFFER].length) {
          this[FLUSH]()
        } else if (this[EOF]) {
          this[MAYBE_EMIT_END]()
        } else {
          this.emit('drain')
        }
      }
      /**
       * Resume the stream if it is currently in a paused state
       *
       * If called when there are no pipe destinations or `data` event listeners,
       * this will place the stream in a "discarded" state, where all data will
       * be thrown away. The discarded state is removed if a pipe destination or
       * data handler is added, if pause() is called, or if any synchronous or
       * asynchronous iteration is started.
       */
      resume() {
        return this[RESUME]()
      }
      /**
       * Pause the stream
       */
      pause() {
        this[FLOWING] = false
        this[PAUSED] = true
        this[DISCARDED] = false
      }
      /**
       * true if the stream has been forcibly destroyed
       */
      get destroyed() {
        return this[DESTROYED]
      }
      /**
       * true if the stream is currently in a flowing state, meaning that
       * any writes will be immediately emitted.
       */
      get flowing() {
        return this[FLOWING]
      }
      /**
       * true if the stream is currently in a paused state
       */
      get paused() {
        return this[PAUSED]
      }
      [BUFFERPUSH](chunk) {
        if (this[OBJECTMODE]) {
          this[BUFFERLENGTH] += 1
        } else {
          this[BUFFERLENGTH] += chunk.length
        }
        this[BUFFER].push(chunk)
      }
      [BUFFERSHIFT]() {
        if (this[OBJECTMODE]) {
          this[BUFFERLENGTH] -= 1
        } else {
          this[BUFFERLENGTH] -= this[BUFFER][0].length
        }
        return this[BUFFER].shift()
      }
      [FLUSH](noDrain = false) {
        do {} while (
          this[FLUSHCHUNK](this[BUFFERSHIFT]()) &&
          this[BUFFER].length
        )
        if (!noDrain && !this[BUFFER].length && !this[EOF]) {
          this.emit('drain')
        }
      }
      [FLUSHCHUNK](chunk) {
        this.emit('data', chunk)
        return this[FLOWING]
      }
      /**
       * Pipe all data emitted by this stream into the destination provided.
       *
       * Triggers the flow of data.
       */
      pipe(dest, opts) {
        if (this[DESTROYED]) {
          return dest
        }
        this[DISCARDED] = false
        const ended = this[EMITTED_END]
        opts = opts || {}
        if (dest === proc.stdout || dest === proc.stderr) {
          opts.end = false
        } else {
          opts.end = opts.end !== false
        }
        opts.proxyErrors = !!opts.proxyErrors
        // piping an ended stream ends immediately
        if (ended) {
          if (opts.end) {
            dest.end()
          }
        } else {
          // "as" here just ignores the WType, which pipes don't care about,
          // since they're only consuming from us, and writing to the dest
          this[PIPES].push(
            !opts.proxyErrors
              ? new Pipe(this, dest, opts)
              : new PipeProxyErrors(this, dest, opts)
          )
          if (this[ASYNC]) {
            defer(() => this[RESUME]())
          } else {
            this[RESUME]()
          }
        }
        return dest
      }
      /**
       * Fully unhook a piped destination stream.
       *
       * If the destination stream was the only consumer of this stream (ie,
       * there are no other piped destinations or `'data'` event listeners)
       * then the flow of data will stop until there is another consumer or
       * {@link Minipass#resume} is explicitly called.
       */
      unpipe(dest) {
        const p = this[PIPES].find(p => p.dest === dest)
        if (p) {
          if (this[PIPES].length === 1) {
            if (this[FLOWING] && this[DATALISTENERS] === 0) {
              this[FLOWING] = false
            }
            this[PIPES] = []
          } else {
            this[PIPES].splice(this[PIPES].indexOf(p), 1)
          }
          p.unpipe()
        }
      }
      /**
       * Alias for {@link Minipass#on}
       */
      addListener(ev, handler) {
        return this.on(ev, handler)
      }
      /**
       * Mostly identical to `EventEmitter.on`, with the following
       * behavior differences to prevent data loss and unnecessary hangs:
       *
       * - Adding a 'data' event handler will trigger the flow of data
       *
       * - Adding a 'readable' event handler when there is data waiting to be read
       *   will cause 'readable' to be emitted immediately.
       *
       * - Adding an 'endish' event handler ('end', 'finish', etc.) which has
       *   already passed will cause the event to be emitted immediately and all
       *   handlers removed.
       *
       * - Adding an 'error' event handler after an error has been emitted will
       *   cause the event to be re-emitted immediately with the error previously
       *   raised.
       */
      on(ev, handler) {
        const ret = super.on(ev, handler)
        if (ev === 'data') {
          this[DISCARDED] = false
          this[DATALISTENERS]++
          if (!this[PIPES].length && !this[FLOWING]) {
            this[RESUME]()
          }
        } else if (ev === 'readable' && this[BUFFERLENGTH] !== 0) {
          super.emit('readable')
        } else if (isEndish(ev) && this[EMITTED_END]) {
          super.emit(ev)
          this.removeAllListeners(ev)
        } else if (ev === 'error' && this[EMITTED_ERROR]) {
          const h = handler
          if (this[ASYNC]) {
            defer(() => h.call(this, this[EMITTED_ERROR]))
          } else {
            h.call(this, this[EMITTED_ERROR])
          }
        }
        return ret
      }
      /**
       * Alias for {@link Minipass#off}
       */
      removeListener(ev, handler) {
        return this.off(ev, handler)
      }
      /**
       * Mostly identical to `EventEmitter.off`
       *
       * If a 'data' event handler is removed, and it was the last consumer
       * (ie, there are no pipe destinations or other 'data' event listeners),
       * then the flow of data will stop until there is another consumer or
       * {@link Minipass#resume} is explicitly called.
       */
      off(ev, handler) {
        const ret = super.off(ev, handler)
        // if we previously had listeners, and now we don't, and we don't
        // have any pipes, then stop the flow, unless it's been explicitly
        // put in a discarded flowing state via stream.resume().
        if (ev === 'data') {
          this[DATALISTENERS] = this.listeners('data').length
          if (
            this[DATALISTENERS] === 0 &&
            !this[DISCARDED] &&
            !this[PIPES].length
          ) {
            this[FLOWING] = false
          }
        }
        return ret
      }
      /**
       * Mostly identical to `EventEmitter.removeAllListeners`
       *
       * If all 'data' event handlers are removed, and they were the last consumer
       * (ie, there are no pipe destinations), then the flow of data will stop
       * until there is another consumer or {@link Minipass#resume} is explicitly
       * called.
       */
      removeAllListeners(ev) {
        const ret = super.removeAllListeners(ev)
        if (ev === 'data' || ev === undefined) {
          this[DATALISTENERS] = 0
          if (!this[DISCARDED] && !this[PIPES].length) {
            this[FLOWING] = false
          }
        }
        return ret
      }
      /**
       * true if the 'end' event has been emitted
       */
      get emittedEnd() {
        return this[EMITTED_END]
      }
      [MAYBE_EMIT_END]() {
        if (
          !this[EMITTING_END] &&
          !this[EMITTED_END] &&
          !this[DESTROYED] &&
          this[BUFFER].length === 0 &&
          this[EOF]
        ) {
          this[EMITTING_END] = true
          this.emit('end')
          this.emit('prefinish')
          this.emit('finish')
          if (this[CLOSED]) {
            this.emit('close')
          }
          this[EMITTING_END] = false
        }
      }
      /**
       * Mostly identical to `EventEmitter.emit`, with the following
       * behavior differences to prevent data loss and unnecessary hangs:
       *
       * If the stream has been destroyed, and the event is something other
       * than 'close' or 'error', then `false` is returned and no handlers
       * are called.
       *
       * If the event is 'end', and has already been emitted, then the event
       * is ignored. If the stream is in a paused or non-flowing state, then
       * the event will be deferred until data flow resumes. If the stream is
       * async, then handlers will be called on the next tick rather than
       * immediately.
       *
       * If the event is 'close', and 'end' has not yet been emitted, then
       * the event will be deferred until after 'end' is emitted.
       *
       * If the event is 'error', and an AbortSignal was provided for the stream,
       * and there are no listeners, then the event is ignored, matching the
       * behavior of node core streams in the presense of an AbortSignal.
       *
       * If the event is 'finish' or 'prefinish', then all listeners will be
       * removed after emitting the event, to prevent double-firing.
       */
      emit(ev, ...args) {
        const data = args[0]
        // error and close are only events allowed after calling destroy()
        if (
          ev !== 'error' &&
          ev !== 'close' &&
          ev !== DESTROYED &&
          this[DESTROYED]
        ) {
          return false
        } else if (ev === 'data') {
          return !this[OBJECTMODE] && !data
            ? false
            : this[ASYNC]
              ? (defer(() => this[EMITDATA](data)), true)
              : this[EMITDATA](data)
        } else if (ev === 'end') {
          return this[EMITEND]()
        } else if (ev === 'close') {
          this[CLOSED] = true
          // don't emit close before 'end' and 'finish'
          if (!this[EMITTED_END] && !this[DESTROYED]) {
            return false
          }
          const ret = super.emit('close')
          this.removeAllListeners('close')
          return ret
        } else if (ev === 'error') {
          this[EMITTED_ERROR] = data
          super.emit(ERROR, data)
          const ret =
            !this[SIGNAL] || this.listeners('error').length
              ? super.emit('error', data)
              : false
          this[MAYBE_EMIT_END]()
          return ret
        } else if (ev === 'resume') {
          const ret = super.emit('resume')
          this[MAYBE_EMIT_END]()
          return ret
        } else if (ev === 'finish' || ev === 'prefinish') {
          const ret = super.emit(ev)
          this.removeAllListeners(ev)
          return ret
        }
        // Some other unknown event
        const ret = super.emit(ev, ...args)
        this[MAYBE_EMIT_END]()
        return ret
      }
      [EMITDATA](data) {
        for (const p of this[PIPES]) {
          if (p.dest.write(data) === false) {
            this.pause()
          }
        }
        const ret = this[DISCARDED] ? false : super.emit('data', data)
        this[MAYBE_EMIT_END]()
        return ret
      }
      [EMITEND]() {
        if (this[EMITTED_END]) {
          return false
        }
        this[EMITTED_END] = true
        this.readable = false
        return this[ASYNC]
          ? (defer(() => this[EMITEND2]()), true)
          : this[EMITEND2]()
      }
      [EMITEND2]() {
        if (this[DECODER]) {
          const data = this[DECODER].end()
          if (data) {
            for (const p of this[PIPES]) {
              p.dest.write(data)
            }
            if (!this[DISCARDED]) {
              super.emit('data', data)
            }
          }
        }
        for (const p of this[PIPES]) {
          p.end()
        }
        const ret = super.emit('end')
        this.removeAllListeners('end')
        return ret
      }
      /**
       * Return a Promise that resolves to an array of all emitted data once
       * the stream ends.
       */
      async collect() {
        const buf = Object.assign([], {
          dataLength: 0
        })
        if (!this[OBJECTMODE]) {
          buf.dataLength = 0
        }
        // set the promise first, in case an error is raised
        // by triggering the flow here.
        const p = this.promise()
        this.on('data', c => {
          buf.push(c)
          if (!this[OBJECTMODE]) {
            buf.dataLength += c.length
          }
        })
        await p
        return buf
      }
      /**
       * Return a Promise that resolves to the concatenation of all emitted data
       * once the stream ends.
       *
       * Not allowed on objectMode streams.
       */
      async concat() {
        if (this[OBJECTMODE]) {
          throw new Error('cannot concat in objectMode')
        }
        const buf = await this.collect()
        return this[ENCODING]
          ? buf.join('')
          : Buffer.concat(buf, buf.dataLength)
      }
      /**
       * Return a void Promise that resolves once the stream ends.
       */
      async promise() {
        return new Promise((resolve, reject) => {
          this.on(DESTROYED, () => reject(new Error('stream destroyed')))
          this.on('error', er => reject(er))
          this.on('end', () => resolve())
        })
      }
      /**
       * Asynchronous `for await of` iteration.
       *
       * This will continue emitting all chunks until the stream terminates.
       */
      [Symbol.asyncIterator]() {
        // set this up front, in case the consumer doesn't call next()
        // right away.
        this[DISCARDED] = false
        let stopped = false
        const stop = async () => {
          this.pause()
          stopped = true
          return {
            value: undefined,
            done: true
          }
        }
        const next = () => {
          if (stopped) {
            return stop()
          }
          const res = this.read()
          if (res !== null) {
            return Promise.resolve({
              done: false,
              value: res
            })
          }
          if (this[EOF]) {
            return stop()
          }
          let resolve
          let reject
          const onerr = er => {
            this.off('data', ondata)
            this.off('end', onend)
            this.off(DESTROYED, ondestroy)
            stop()
            reject(er)
          }
          const ondata = value => {
            this.off('error', onerr)
            this.off('end', onend)
            this.off(DESTROYED, ondestroy)
            this.pause()
            resolve({
              value,
              done: !!this[EOF]
            })
          }
          const onend = () => {
            this.off('error', onerr)
            this.off('data', ondata)
            this.off(DESTROYED, ondestroy)
            stop()
            resolve({
              done: true,
              value: undefined
            })
          }
          const ondestroy = () => onerr(new Error('stream destroyed'))
          return new Promise((res, rej) => {
            reject = rej
            resolve = res
            this.once(DESTROYED, ondestroy)
            this.once('error', onerr)
            this.once('end', onend)
            this.once('data', ondata)
          })
        }
        return {
          next,
          throw: stop,
          return: stop,
          [Symbol.asyncIterator]() {
            return this
          }
        }
      }
      /**
       * Synchronous `for of` iteration.
       *
       * The iteration will terminate when the internal buffer runs out, even
       * if the stream has not yet terminated.
       */
      [Symbol.iterator]() {
        // set this up front, in case the consumer doesn't call next()
        // right away.
        this[DISCARDED] = false
        let stopped = false
        const stop = () => {
          this.pause()
          this.off(ERROR, stop)
          this.off(DESTROYED, stop)
          this.off('end', stop)
          stopped = true
          return {
            done: true,
            value: undefined
          }
        }
        const next = () => {
          if (stopped) {
            return stop()
          }
          const value = this.read()
          return value === null
            ? stop()
            : {
                done: false,
                value
              }
        }
        this.once('end', stop)
        this.once(ERROR, stop)
        this.once(DESTROYED, stop)
        return {
          next,
          throw: stop,
          return: stop,
          [Symbol.iterator]() {
            return this
          }
        }
      }
      /**
       * Destroy a stream, preventing it from being used for any further purpose.
       *
       * If the stream has a `close()` method, then it will be called on
       * destruction.
       *
       * After destruction, any attempt to write data, read data, or emit most
       * events will be ignored.
       *
       * If an error argument is provided, then it will be emitted in an
       * 'error' event.
       */
      destroy(er) {
        if (this[DESTROYED]) {
          if (er) {
            this.emit('error', er)
          } else {
            this.emit(DESTROYED)
          }
          return this
        }
        this[DESTROYED] = true
        this[DISCARDED] = true
        // throw away all buffered data, it's never coming out
        this[BUFFER].length = 0
        this[BUFFERLENGTH] = 0
        const wc = this
        if (typeof wc.close === 'function' && !this[CLOSED]) {
          wc.close()
        }
        if (er) {
          this.emit('error', er)
        }
        // if no error to emit, still reject pending promises
        else {
          this.emit(DESTROYED)
        }
        return this
      }
      /**
       * Alias for {@link isStream}
       *
       * Former export location, maintained for backwards compatibility.
       *
       * @deprecated
       */
      static get isStream() {
        return exports.isStream
      }
    }
    exports.Minipass = Minipass
  })(commonjs)
  return commonjs
}

let hasRequiredLib$e
function requireLib$e() {
  if (hasRequiredLib$e) {
    return lib$c
  }
  hasRequiredLib$e = 1
  const crypto = require$$0$e
  const { Minipass } = requireCommonjs()
  const SPEC_ALGORITHMS = ['sha512', 'sha384', 'sha256']
  const DEFAULT_ALGORITHMS = ['sha512']

  // TODO: this should really be a hardcoded list of algorithms we support,
  // rather than [a-z0-9].
  const BASE64_REGEX = /^[a-z0-9+/]+(?:=?=?)$/i
  const SRI_REGEX = /^([a-z0-9]+)-([^?]+)([?\S*]*)$/
  const STRICT_SRI_REGEX =
    /^([a-z0-9]+)-([A-Za-z0-9+/=]{44,88})(\?[\x21-\x7E]*)?$/
  const VCHAR_REGEX = /^[\x21-\x7E]+$/
  const getOptString = options =>
    options?.length ? `?${options.join('?')}` : ''
  class IntegrityStream extends Minipass {
    #emittedIntegrity
    #emittedSize
    #emittedVerified
    constructor(opts) {
      super()
      this.size = 0
      this.opts = opts

      // may be overridden later, but set now for class consistency
      this.#getOptions()

      // options used for calculating stream.  can't be changed.
      if (opts?.algorithms) {
        this.algorithms = [...opts.algorithms]
      } else {
        this.algorithms = [...DEFAULT_ALGORITHMS]
      }
      if (
        this.algorithm !== null &&
        !this.algorithms.includes(this.algorithm)
      ) {
        this.algorithms.push(this.algorithm)
      }
      this.hashes = this.algorithms.map(crypto.createHash)
    }
    #getOptions() {
      // For verification
      this.sri = this.opts?.integrity
        ? parse(this.opts?.integrity, this.opts)
        : null
      this.expectedSize = this.opts?.size
      if (!this.sri) {
        this.algorithm = null
      } else if (this.sri.isHash) {
        this.goodSri = true
        this.algorithm = this.sri.algorithm
      } else {
        this.goodSri = !this.sri.isEmpty()
        this.algorithm = this.sri.pickAlgorithm(this.opts)
      }
      this.digests = this.goodSri ? this.sri[this.algorithm] : null
      this.optString = getOptString(this.opts?.options)
    }
    on(ev, handler) {
      if (ev === 'size' && this.#emittedSize) {
        return handler(this.#emittedSize)
      }
      if (ev === 'integrity' && this.#emittedIntegrity) {
        return handler(this.#emittedIntegrity)
      }
      if (ev === 'verified' && this.#emittedVerified) {
        return handler(this.#emittedVerified)
      }
      return super.on(ev, handler)
    }
    emit(ev, data) {
      if (ev === 'end') {
        this.#onEnd()
      }
      return super.emit(ev, data)
    }
    write(data) {
      this.size += data.length
      this.hashes.forEach(h => h.update(data))
      return super.write(data)
    }
    #onEnd() {
      if (!this.goodSri) {
        this.#getOptions()
      }
      const newSri = parse(
        this.hashes
          .map((h, i) => {
            return `${this.algorithms[i]}-${h.digest('base64')}${this.optString}`
          })
          .join(' '),
        this.opts
      )
      // Integrity verification mode
      const match = this.goodSri && newSri.match(this.sri, this.opts)
      if (
        typeof this.expectedSize === 'number' &&
        this.size !== this.expectedSize
      ) {
        /* eslint-disable-next-line max-len */
        const err = new Error(
          `stream size mismatch when checking ${this.sri}.\n  Wanted: ${this.expectedSize}\n  Found: ${this.size}`
        )
        err.code = 'EBADSIZE'
        err.found = this.size
        err.expected = this.expectedSize
        err.sri = this.sri
        this.emit('error', err)
      } else if (this.sri && !match) {
        /* eslint-disable-next-line max-len */
        const err = new Error(
          `${this.sri} integrity checksum failed when using ${this.algorithm}: wanted ${this.digests} but got ${newSri}. (${this.size} bytes)`
        )
        err.code = 'EINTEGRITY'
        err.found = newSri
        err.expected = this.digests
        err.algorithm = this.algorithm
        err.sri = this.sri
        this.emit('error', err)
      } else {
        this.#emittedSize = this.size
        this.emit('size', this.size)
        this.#emittedIntegrity = newSri
        this.emit('integrity', newSri)
        if (match) {
          this.#emittedVerified = match
          this.emit('verified', match)
        }
      }
    }
  }
  class Hash {
    get isHash() {
      return true
    }
    constructor(hash, opts) {
      const strict = opts?.strict
      this.source = hash.trim()

      // set default values so that we make V8 happy to
      // always see a familiar object template.
      this.digest = ''
      this.algorithm = ''
      this.options = []

      // 3.1. Integrity metadata (called "Hash" by ssri)
      // https://w3c.github.io/webappsec-subresource-integrity/#integrity-metadata-description
      const match = this.source.match(strict ? STRICT_SRI_REGEX : SRI_REGEX)
      if (!match) {
        return
      }
      if (strict && !SPEC_ALGORITHMS.includes(match[1])) {
        return
      }
      this.algorithm = match[1]
      this.digest = match[2]
      const rawOpts = match[3]
      if (rawOpts) {
        this.options = rawOpts.slice(1).split('?')
      }
    }
    hexDigest() {
      return this.digest && Buffer.from(this.digest, 'base64').toString('hex')
    }
    toJSON() {
      return this.toString()
    }
    match(integrity, opts) {
      const other = parse(integrity, opts)
      if (!other) {
        return false
      }
      if (other.isIntegrity) {
        const algo = other.pickAlgorithm(opts, [this.algorithm])
        if (!algo) {
          return false
        }
        const foundHash = other[algo].find(hash => hash.digest === this.digest)
        if (foundHash) {
          return foundHash
        }
        return false
      }
      return other.digest === this.digest ? other : false
    }
    toString(opts) {
      if (opts?.strict) {
        // Strict mode enforces the standard as close to the foot of the
        // letter as it can.
        if (
          !(
            // The spec has very restricted productions for algorithms.
            // https://www.w3.org/TR/CSP2/#source-list-syntax
            (
              SPEC_ALGORITHMS.includes(this.algorithm) &&
              // Usually, if someone insists on using a "different" base64, we
              // leave it as-is, since there's multiple standards, and the
              // specified is not a URL-safe variant.
              // https://www.w3.org/TR/CSP2/#base64_value
              this.digest.match(BASE64_REGEX) &&
              // Option syntax is strictly visual chars.
              // https://w3c.github.io/webappsec-subresource-integrity/#grammardef-option-expression
              // https://tools.ietf.org/html/rfc5234#appendix-B.1
              this.options.every(opt => opt.match(VCHAR_REGEX))
            )
          )
        ) {
          return ''
        }
      }
      return `${this.algorithm}-${this.digest}${getOptString(this.options)}`
    }
  }
  function integrityHashToString(toString, sep, opts, hashes) {
    const toStringIsNotEmpty = toString !== ''
    let shouldAddFirstSep = false
    let complement = ''
    const lastIndex = hashes.length - 1
    for (let i = 0; i < lastIndex; i++) {
      const hashString = Hash.prototype.toString.call(hashes[i], opts)
      if (hashString) {
        shouldAddFirstSep = true
        complement += hashString
        complement += sep
      }
    }
    const finalHashString = Hash.prototype.toString.call(
      hashes[lastIndex],
      opts
    )
    if (finalHashString) {
      shouldAddFirstSep = true
      complement += finalHashString
    }
    if (toStringIsNotEmpty && shouldAddFirstSep) {
      return toString + sep + complement
    }
    return toString + complement
  }
  class Integrity {
    get isIntegrity() {
      return true
    }
    toJSON() {
      return this.toString()
    }
    isEmpty() {
      return Object.keys(this).length === 0
    }
    toString(opts) {
      let sep = opts?.sep || ' '
      let toString = ''
      if (opts?.strict) {
        // Entries must be separated by whitespace, according to spec.
        sep = sep.replace(/\S+/g, ' ')
        for (const hash of SPEC_ALGORITHMS) {
          if (this[hash]) {
            toString = integrityHashToString(toString, sep, opts, this[hash])
          }
        }
      } else {
        for (const hash of Object.keys(this)) {
          toString = integrityHashToString(toString, sep, opts, this[hash])
        }
      }
      return toString
    }
    concat(integrity, opts) {
      const other =
        typeof integrity === 'string' ? integrity : stringify(integrity, opts)
      return parse(`${this.toString(opts)} ${other}`, opts)
    }
    hexDigest() {
      return parse(this, {
        single: true
      }).hexDigest()
    }

    // add additional hashes to an integrity value, but prevent
    // *changing* an existing integrity hash.
    merge(integrity, opts) {
      const other = parse(integrity, opts)
      for (const algo in other) {
        if (this[algo]) {
          if (
            !this[algo].find(hash =>
              other[algo].find(otherhash => hash.digest === otherhash.digest)
            )
          ) {
            throw new Error('hashes do not match, cannot update integrity')
          }
        } else {
          this[algo] = other[algo]
        }
      }
    }
    match(integrity, opts) {
      const other = parse(integrity, opts)
      if (!other) {
        return false
      }
      const algo = other.pickAlgorithm(opts, Object.keys(this))
      return (
        (!!algo &&
          this[algo] &&
          other[algo] &&
          this[algo].find(hash =>
            other[algo].find(otherhash => hash.digest === otherhash.digest)
          )) ||
        false
      )
    }

    // Pick the highest priority algorithm present, optionally also limited to a
    // set of hashes found in another integrity.  When limiting it may return
    // nothing.
    pickAlgorithm(opts, hashes) {
      const pickAlgorithm = opts?.pickAlgorithm || getPrioritizedHash
      const keys = Object.keys(this).filter(k => {
        if (hashes?.length) {
          return hashes.includes(k)
        }
        return true
      })
      if (keys.length) {
        return keys.reduce((acc, algo) => pickAlgorithm(acc, algo) || acc)
      }
      // no intersection between this and hashes,
      return null
    }
  }
  lib$c.parse = parse
  function parse(sri, opts) {
    if (!sri) {
      return null
    }
    if (typeof sri === 'string') {
      return _parse(sri, opts)
    } else if (sri.algorithm && sri.digest) {
      const fullSri = new Integrity()
      fullSri[sri.algorithm] = [sri]
      return _parse(stringify(fullSri, opts), opts)
    } else {
      return _parse(stringify(sri, opts), opts)
    }
  }
  function _parse(integrity, opts) {
    // 3.4.3. Parse metadata
    // https://w3c.github.io/webappsec-subresource-integrity/#parse-metadata
    if (opts?.single) {
      return new Hash(integrity, opts)
    }
    const hashes = integrity
      .trim()
      .split(/\s+/)
      .reduce((acc, string) => {
        const hash = new Hash(string, opts)
        if (hash.algorithm && hash.digest) {
          const algo = hash.algorithm
          if (!acc[algo]) {
            acc[algo] = []
          }
          acc[algo].push(hash)
        }
        return acc
      }, new Integrity())
    return hashes.isEmpty() ? null : hashes
  }
  lib$c.stringify = stringify
  function stringify(obj, opts) {
    if (obj.algorithm && obj.digest) {
      return Hash.prototype.toString.call(obj, opts)
    } else if (typeof obj === 'string') {
      return stringify(parse(obj, opts), opts)
    } else {
      return Integrity.prototype.toString.call(obj, opts)
    }
  }
  lib$c.fromHex = fromHex
  function fromHex(hexDigest, algorithm, opts) {
    const optString = getOptString(opts?.options)
    return parse(
      `${algorithm}-${Buffer.from(hexDigest, 'hex').toString('base64')}${optString}`,
      opts
    )
  }
  lib$c.fromData = fromData
  function fromData(data, opts) {
    const algorithms = opts?.algorithms || [...DEFAULT_ALGORITHMS]
    const optString = getOptString(opts?.options)
    return algorithms.reduce((acc, algo) => {
      const digest = crypto.createHash(algo).update(data).digest('base64')
      const hash = new Hash(`${algo}-${digest}${optString}`, opts)
      /* istanbul ignore else - it would be VERY strange if the string we
       * just calculated with an algo did not have an algo or digest.
       */
      if (hash.algorithm && hash.digest) {
        const hashAlgo = hash.algorithm
        if (!acc[hashAlgo]) {
          acc[hashAlgo] = []
        }
        acc[hashAlgo].push(hash)
      }
      return acc
    }, new Integrity())
  }
  lib$c.fromStream = fromStream
  function fromStream(stream, opts) {
    const istream = integrityStream(opts)
    return new Promise((resolve, reject) => {
      stream.pipe(istream)
      stream.on('error', reject)
      istream.on('error', reject)
      let sri
      istream.on('integrity', s => {
        sri = s
      })
      istream.on('end', () => resolve(sri))
      istream.resume()
    })
  }
  lib$c.checkData = checkData
  function checkData(data, sri, opts) {
    sri = parse(sri, opts)
    if (!sri || !Object.keys(sri).length) {
      if (opts?.error) {
        throw Object.assign(
          new Error('No valid integrity hashes to check against'),
          {
            code: 'EINTEGRITY'
          }
        )
      } else {
        return false
      }
    }
    const algorithm = sri.pickAlgorithm(opts)
    const digest = crypto.createHash(algorithm).update(data).digest('base64')
    const newSri = parse({
      algorithm,
      digest
    })
    const match = newSri.match(sri, opts)
    opts = opts || {}
    if (match || !opts.error) {
      return match
    } else if (typeof opts.size === 'number' && data.length !== opts.size) {
      /* eslint-disable-next-line max-len */
      const err = new Error(
        `data size mismatch when checking ${sri}.\n  Wanted: ${opts.size}\n  Found: ${data.length}`
      )
      err.code = 'EBADSIZE'
      err.found = data.length
      err.expected = opts.size
      err.sri = sri
      throw err
    } else {
      /* eslint-disable-next-line max-len */
      const err = new Error(
        `Integrity checksum failed when using ${algorithm}: Wanted ${sri}, but got ${newSri}. (${data.length} bytes)`
      )
      err.code = 'EINTEGRITY'
      err.found = newSri
      err.expected = sri
      err.algorithm = algorithm
      err.sri = sri
      throw err
    }
  }
  lib$c.checkStream = checkStream
  function checkStream(stream, sri, opts) {
    opts = opts || Object.create(null)
    opts.integrity = sri
    sri = parse(sri, opts)
    if (!sri || !Object.keys(sri).length) {
      return Promise.reject(
        Object.assign(new Error('No valid integrity hashes to check against'), {
          code: 'EINTEGRITY'
        })
      )
    }
    const checker = integrityStream(opts)
    return new Promise((resolve, reject) => {
      stream.pipe(checker)
      stream.on('error', reject)
      checker.on('error', reject)
      let verified
      checker.on('verified', s => {
        verified = s
      })
      checker.on('end', () => resolve(verified))
      checker.resume()
    })
  }
  lib$c.integrityStream = integrityStream
  function integrityStream(opts = Object.create(null)) {
    return new IntegrityStream(opts)
  }
  lib$c.create = createIntegrity
  function createIntegrity(opts) {
    const algorithms = opts?.algorithms || [...DEFAULT_ALGORITHMS]
    const optString = getOptString(opts?.options)
    const hashes = algorithms.map(crypto.createHash)
    return {
      update: function (chunk, enc) {
        hashes.forEach(h => h.update(chunk, enc))
        return this
      },
      digest: function (enc) {
        const integrity = algorithms.reduce((acc, algo) => {
          const digest = hashes.shift().digest('base64')
          const hash = new Hash(`${algo}-${digest}${optString}`, opts)
          /* istanbul ignore else - it would be VERY strange if the hash we
           * just calculated with an algo did not have an algo or digest.
           */
          if (hash.algorithm && hash.digest) {
            const hashAlgo = hash.algorithm
            if (!acc[hashAlgo]) {
              acc[hashAlgo] = []
            }
            acc[hashAlgo].push(hash)
          }
          return acc
        }, new Integrity())
        return integrity
      }
    }
  }
  const NODE_HASHES = crypto.getHashes()

  // This is a Best Effort™ at a reasonable priority for hash algos
  const DEFAULT_PRIORITY = [
    'md5',
    'whirlpool',
    'sha1',
    'sha224',
    'sha256',
    'sha384',
    'sha512',
    // TODO - it's unclear _which_ of these Node will actually use as its name
    //        for the algorithm, so we guesswork it based on the OpenSSL names.
    'sha3',
    'sha3-256',
    'sha3-384',
    'sha3-512',
    'sha3_256',
    'sha3_384',
    'sha3_512'
  ].filter(algo => NODE_HASHES.includes(algo))
  function getPrioritizedHash(algo1, algo2) {
    /* eslint-disable-next-line max-len */
    return DEFAULT_PRIORITY.indexOf(algo1.toLowerCase()) >=
      DEFAULT_PRIORITY.indexOf(algo2.toLowerCase())
      ? algo1
      : algo2
  }
  return lib$c
}

let hasRequiredLib$d
function requireLib$d() {
  if (hasRequiredLib$d) {
    return lib$f
  }
  hasRequiredLib$d = 1
  const __createBinding =
    (this && this.__createBinding) ||
    (Object.create
      ? function (o, m, k, k2) {
          if (k2 === undefined) {
            k2 = k
          }
          let desc = Object.getOwnPropertyDescriptor(m, k)
          if (
            !desc ||
            ('get' in desc ? !m.__esModule : desc.writable || desc.configurable)
          ) {
            desc = {
              enumerable: true,
              get: function () {
                return m[k]
              }
            }
          }
          Object.defineProperty(o, k2, desc)
        }
      : function (o, m, k, k2) {
          if (k2 === undefined) {
            k2 = k
          }
          o[k2] = m[k]
        })
  const __setModuleDefault =
    (this && this.__setModuleDefault) ||
    (Object.create
      ? function (o, v) {
          Object.defineProperty(o, 'default', {
            enumerable: true,
            value: v
          })
        }
      : function (o, v) {
          o['default'] = v
        })
  const __importStar =
    (this && this.__importStar) ||
    function (mod) {
      if (mod && mod.__esModule) {
        return mod
      }
      const result = {}
      if (mod != null) {
        for (var k in mod)
          if (k !== 'default' && Object.prototype.hasOwnProperty.call(mod, k))
            __createBinding(result, mod, k)
      }
      __setModuleDefault(result, mod)
      return result
    }
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(lib$f, '__esModule', {
    value: true
  })
  lib$f.createShortHash = createShortHash
  lib$f.createHexHash = createHexHash
  lib$f.createHash = createHash
  lib$f.createHashFromFile = createHashFromFile
  lib$f.createHexHashFromFile = createHexHashFromFile
  lib$f.getTarballIntegrity = getTarballIntegrity
  const crypto = __importStar(requireLib$g())
  const fs_1 = __importDefault(require$$0$6)
  const graceful_fs_1 = __importDefault(requireLib$f())
  const ssri_1 = __importDefault(requireLib$e())
  function createShortHash(input) {
    return createHexHash(input).substring(0, 32)
  }
  function createHexHash(input) {
    return crypto.hash('sha256', input, 'hex')
  }
  function createHash(input) {
    return `sha256-${crypto.hash('sha256', input, 'base64')}`
  }
  async function createHashFromFile(file) {
    return createHash(await readNormalizedFile(file))
  }
  async function createHexHashFromFile(file) {
    return createHexHash(await readNormalizedFile(file))
  }
  async function readNormalizedFile(file) {
    const content = await fs_1.default.promises.readFile(file, 'utf8')
    return content.split('\r\n').join('\n')
  }
  async function getTarballIntegrity(filename) {
    return (
      await ssri_1.default.fromStream(
        graceful_fs_1.default.createReadStream(filename)
      )
    ).toString()
  }
  return lib$f
}

let hasRequiredLib$c
function requireLib$c() {
  if (hasRequiredLib$c) {
    return lib$g
  }
  hasRequiredLib$c = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(lib$g, '__esModule', {
    value: true
  })
  lib$g.isAbsolute = isAbsolute
  lib$g.indexOfPeersSuffix = indexOfPeersSuffix
  lib$g.parseDepPath = parseDepPath
  lib$g.removeSuffix = removeSuffix
  lib$g.getPkgIdWithPatchHash = getPkgIdWithPatchHash
  lib$g.tryGetPackageId = tryGetPackageId
  lib$g.getRegistryByPackageName = getRegistryByPackageName
  lib$g.refToRelative = refToRelative
  lib$g.parse = parse
  lib$g.depPathToFilename = depPathToFilename
  lib$g.createPeersDirSuffix = createPeersDirSuffix
  const crypto_hash_1 = requireLib$d()
  const semver_1 = __importDefault(requireSemver())
  function isAbsolute(dependencyPath) {
    return dependencyPath[0] !== '/'
  }
  function indexOfPeersSuffix(depPath) {
    if (!depPath.endsWith(')')) {
      return {
        peersIndex: -1,
        patchHashIndex: -1
      }
    }
    let open = 1
    for (let i = depPath.length - 2; i >= 0; i--) {
      if (depPath[i] === '(') {
        open--
      } else if (depPath[i] === ')') {
        open++
      } else if (!open) {
        if (depPath.substring(i + 1).startsWith('(patch_hash=')) {
          return {
            patchHashIndex: i + 1,
            peersIndex: depPath.indexOf('(', i + 2)
          }
        }
        return {
          patchHashIndex: -1,
          peersIndex: i + 1
        }
      }
    }
    return {
      peersIndex: -1,
      patchHashIndex: -1
    }
  }
  function parseDepPath(relDepPath) {
    const { peersIndex } = indexOfPeersSuffix(relDepPath)
    if (peersIndex !== -1) {
      return {
        id: relDepPath.substring(0, peersIndex),
        peersSuffix: relDepPath.substring(peersIndex)
      }
    }
    return {
      id: relDepPath,
      peersSuffix: ''
    }
  }
  function removeSuffix(relDepPath) {
    const { peersIndex, patchHashIndex } = indexOfPeersSuffix(relDepPath)
    if (patchHashIndex !== -1) {
      return relDepPath.substring(0, patchHashIndex)
    }
    if (peersIndex !== -1) {
      return relDepPath.substring(0, peersIndex)
    }
    return relDepPath
  }
  function getPkgIdWithPatchHash(depPath) {
    let pkgId = depPath
    const { peersIndex: sepIndex } = indexOfPeersSuffix(pkgId)
    if (sepIndex !== -1) {
      pkgId = pkgId.substring(0, sepIndex)
    }
    if (pkgId.includes(':')) {
      pkgId = pkgId.substring(pkgId.indexOf('@', 1) + 1)
    }
    return pkgId
  }
  function tryGetPackageId(relDepPath) {
    let pkgId = relDepPath
    const { peersIndex, patchHashIndex } = indexOfPeersSuffix(pkgId)
    const sepIndex = patchHashIndex === -1 ? peersIndex : patchHashIndex
    if (sepIndex !== -1) {
      pkgId = pkgId.substring(0, sepIndex)
    }
    if (pkgId.includes(':')) {
      pkgId = pkgId.substring(pkgId.indexOf('@', 1) + 1)
    }
    return pkgId
  }
  function getRegistryByPackageName(registries, packageName) {
    if (packageName[0] !== '@') {
      return registries.default
    }
    const scope = packageName.substring(0, packageName.indexOf('/'))
    return registries[scope] || registries.default
  }
  function refToRelative(reference, pkgName) {
    if (reference.startsWith('link:')) {
      return null
    }
    if (reference.startsWith('@')) {
      return reference
    }
    const atIndex = reference.indexOf('@')
    if (atIndex === -1) {
      return `${pkgName}@${reference}`
    }
    const colonIndex = reference.indexOf(':')
    const bracketIndex = reference.indexOf('(')
    if (
      (colonIndex === -1 || atIndex < colonIndex) &&
      (bracketIndex === -1 || atIndex < bracketIndex)
    ) {
      return reference
    }
    return `${pkgName}@${reference}`
  }
  function parse(dependencyPath) {
    // eslint-disable-next-line: strict-type-predicates
    if (typeof dependencyPath !== 'string') {
      throw new TypeError(
        `Expected \`dependencyPath\` to be of type \`string\`, got \`${
          // eslint-disable-next-line: strict-type-predicates
          dependencyPath === null ? 'null' : typeof dependencyPath
        }\``
      )
    }
    const sepIndex = dependencyPath.indexOf('@', 1)
    if (sepIndex === -1) {
      return {}
    }
    const name = dependencyPath.substring(0, sepIndex)
    let version = dependencyPath.substring(sepIndex + 1)
    if (version) {
      let peersSuffix
      let patchHash
      const { peersIndex, patchHashIndex } = indexOfPeersSuffix(version)
      if (peersIndex !== -1 || patchHashIndex !== -1) {
        if (peersIndex === -1) {
          patchHash = version.substring(patchHashIndex)
          version = version.substring(0, patchHashIndex)
        } else if (patchHashIndex === -1) {
          peersSuffix = version.substring(peersIndex)
          version = version.substring(0, peersIndex)
        } else {
          patchHash = version.substring(patchHashIndex, peersIndex)
          peersSuffix = version.substring(peersIndex)
          version = version.substring(0, patchHashIndex)
        }
      }
      if (semver_1.default.valid(version)) {
        return {
          name,
          peersSuffix,
          version,
          patchHash
        }
      }
      return {
        name,
        nonSemverVersion: version,
        peersSuffix,
        patchHash
      }
    }
    return {}
  }
  function depPathToFilename(depPath, maxLengthWithoutHash) {
    let filename = depPathToFilenameUnescaped(depPath).replace(
      /[\\/:*?"<>|#]/g,
      '+'
    )
    if (filename.includes('(')) {
      filename = filename.replace(/\)$/, '').replace(/\)\(|\(|\)/g, '_')
    }
    if (
      filename.length > maxLengthWithoutHash ||
      (filename !== filename.toLowerCase() && !filename.startsWith('file+'))
    ) {
      return `${filename.substring(0, maxLengthWithoutHash - 33)}_${(0, crypto_hash_1.createShortHash)(filename)}`
    }
    return filename
  }
  function depPathToFilenameUnescaped(depPath) {
    if (depPath.indexOf('file:') !== 0) {
      if (depPath[0] === '/') {
        depPath = depPath.substring(1)
      }
      const index = depPath.indexOf('@', 1)
      if (index === -1) {
        return depPath
      }
      return `${depPath.substring(0, index)}@${depPath.slice(index + 1)}`
    }
    return depPath.replace(':', '+')
  }
  function createPeersDirSuffix(peerIds, maxLength = 1000) {
    let dirName = peerIds
      .map(peerId => {
        if (typeof peerId !== 'string') {
          return `${peerId.name}@${peerId.version}`
        }
        if (peerId.startsWith('/')) {
          return peerId.substring(1)
        }
        return peerId
      })
      .sort()
      .join(')(')
    if (dirName.length > maxLength) {
      dirName = (0, crypto_hash_1.createShortHash)(dirName)
    }
    return `(${dirName})`
  }
  return lib$g
}

const libExports$2 = requireLib$c()

const lib$b = {}

let hasRequiredLib$b
function requireLib$b() {
  if (hasRequiredLib$b) {
    return lib$b
  }
  hasRequiredLib$b = 1
  const __createBinding =
    (this && this.__createBinding) ||
    (Object.create
      ? function (o, m, k, k2) {
          if (k2 === undefined) {
            k2 = k
          }
          let desc = Object.getOwnPropertyDescriptor(m, k)
          if (
            !desc ||
            ('get' in desc ? !m.__esModule : desc.writable || desc.configurable)
          ) {
            desc = {
              enumerable: true,
              get: function () {
                return m[k]
              }
            }
          }
          Object.defineProperty(o, k2, desc)
        }
      : function (o, m, k, k2) {
          if (k2 === undefined) {
            k2 = k
          }
          o[k2] = m[k]
        })
  const __setModuleDefault =
    (this && this.__setModuleDefault) ||
    (Object.create
      ? function (o, v) {
          Object.defineProperty(o, 'default', {
            enumerable: true,
            value: v
          })
        }
      : function (o, v) {
          o['default'] = v
        })
  const __importStar =
    (this && this.__importStar) ||
    function (mod) {
      if (mod && mod.__esModule) {
        return mod
      }
      const result = {}
      if (mod != null) {
        for (var k in mod)
          if (k !== 'default' && Object.prototype.hasOwnProperty.call(mod, k))
            __createBinding(result, mod, k)
      }
      __setModuleDefault(result, mod)
      return result
    }
  Object.defineProperty(lib$b, '__esModule', {
    value: true
  })
  lib$b.DepType = void 0
  lib$b.detectDepTypes = detectDepTypes
  const dp = __importStar(requireLib$c())
  let DepType
  ;(function (DepType) {
    DepType[(DepType['DevOnly'] = 0)] = 'DevOnly'
    DepType[(DepType['DevAndProd'] = 1)] = 'DevAndProd'
    DepType[(DepType['ProdOnly'] = 2)] = 'ProdOnly'
  })(DepType || (lib$b.DepType = DepType = {}))
  function detectDepTypes(lockfile) {
    const dev = {}
    const devDepPaths = Object.values(lockfile.importers)
      .map(deps => resolvedDepsToDepPaths(deps.devDependencies ?? {}))
      .flat()
    const optionalDepPaths = Object.values(lockfile.importers)
      .map(deps => resolvedDepsToDepPaths(deps.optionalDependencies ?? {}))
      .flat()
    const prodDepPaths = Object.values(lockfile.importers)
      .map(deps => resolvedDepsToDepPaths(deps.dependencies ?? {}))
      .flat()
    const ctx = {
      packages: lockfile.packages ?? {},
      walked: new Set(),
      notProdOnly: new Set(),
      dev
    }
    detectDepTypesInSubGraph(ctx, devDepPaths, {
      dev: true
    })
    detectDepTypesInSubGraph(ctx, optionalDepPaths, {
      dev: false
    })
    detectDepTypesInSubGraph(ctx, prodDepPaths, {
      dev: false
    })
    return dev
  }
  function detectDepTypesInSubGraph(ctx, depPaths, opts) {
    for (const depPath of depPaths) {
      const key = `${depPath}:${opts.dev.toString()}`
      if (ctx.walked.has(key)) {
        continue
      }
      ctx.walked.add(key)
      if (!ctx.packages[depPath]) {
        continue
      }
      if (opts.dev) {
        ctx.notProdOnly.add(depPath)
        ctx.dev[depPath] = DepType.DevOnly
      } else if (ctx.dev[depPath] === DepType.DevOnly) {
        // keeping if dev is explicitly false
        ctx.dev[depPath] = DepType.DevAndProd
      } else if (
        ctx.dev[depPath] === undefined &&
        !ctx.notProdOnly.has(depPath)
      ) {
        ctx.dev[depPath] = DepType.ProdOnly
      }
      const depLockfile = ctx.packages[depPath]
      const newDependencies = resolvedDepsToDepPaths(
        depLockfile.dependencies ?? {}
      )
      detectDepTypesInSubGraph(ctx, newDependencies, opts)
      const newOptionalDependencies = resolvedDepsToDepPaths(
        depLockfile.optionalDependencies ?? {}
      )
      detectDepTypesInSubGraph(ctx, newOptionalDependencies, {
        dev: opts.dev
      })
    }
  }
  function resolvedDepsToDepPaths(deps) {
    return Object.entries(deps)
      .map(([alias, ref]) => dp.refToRelative(ref, alias))
      .filter(depPath => depPath !== null)
  }
  return lib$b
}

const libExports$1 = requireLib$b()

const lib$a = {}

const write = {}

const lib$9 = {}

let hasRequiredLib$a
function requireLib$a() {
  if (hasRequiredLib$a) {
    return lib$9
  }
  hasRequiredLib$a = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.USEFUL_NON_ROOT_PNPM_FIELDS =
      exports.FULL_FILTERED_META_DIR =
      exports.FULL_META_DIR =
      exports.ABBREVIATED_META_DIR =
      exports.WORKSPACE_MANIFEST_FILENAME =
      exports.STORE_VERSION =
      exports.LAYOUT_VERSION =
      exports.ENGINE_NAME =
      exports.MANIFEST_BASE_NAMES =
      exports.LOCKFILE_VERSION =
      exports.LOCKFILE_MAJOR_VERSION =
      exports.WANTED_LOCKFILE =
        void 0
    exports.WANTED_LOCKFILE = 'pnpm-lock.yaml'
    exports.LOCKFILE_MAJOR_VERSION = '9'
    exports.LOCKFILE_VERSION = `${exports.LOCKFILE_MAJOR_VERSION}.0`
    exports.MANIFEST_BASE_NAMES = [
      'package.json',
      'package.json5',
      'package.yaml'
    ]
    exports.ENGINE_NAME = `${process.platform};${process.arch};node${process.version.split('.')[0].substring(1)}`
    exports.LAYOUT_VERSION = 5
    exports.STORE_VERSION = 'v10'
    exports.WORKSPACE_MANIFEST_FILENAME = 'pnpm-workspace.yaml'
    // This file contains meta information
    // about all the packages published by the same name, not just the manifest
    // of one package/version
    exports.ABBREVIATED_META_DIR = 'metadata-v1.3'
    exports.FULL_META_DIR = 'metadata-full-v1.3' // This is currently not used at all
    exports.FULL_FILTERED_META_DIR = 'metadata-v1.3'
    exports.USEFUL_NON_ROOT_PNPM_FIELDS = ['executionEnv']
  })(lib$9)
  return lib$9
}

const rimraf = { exports: {} }

let hasRequiredRimraf
function requireRimraf() {
  if (hasRequiredRimraf) {
    return rimraf.exports
  }
  hasRequiredRimraf = 1
  const fs = require$$0$6
  rimraf.exports = async p => {
    try {
      await fs.promises.rm(p, {
        recursive: true,
        force: true,
        maxRetries: 3
      })
    } catch (err) {
      if (err.code === 'ENOENT') {
        return
      }
      throw err
    }
  }
  rimraf.exports.sync = p => {
    try {
      fs.rmSync(p, {
        recursive: true,
        force: true,
        maxRetries: 3
      })
    } catch (err) {
      if (err.code === 'ENOENT') {
        return
      }
      throw err
    }
  }
  return rimraf.exports
}

const jsYaml = {}

const loader = {}

const common = {}

let hasRequiredCommon
function requireCommon() {
  if (hasRequiredCommon) {
    return common
  }
  hasRequiredCommon = 1
  function isNothing(subject) {
    return typeof subject === 'undefined' || subject === null
  }
  function isObject(subject) {
    return typeof subject === 'object' && subject !== null
  }
  function toArray(sequence) {
    if (Array.isArray(sequence)) {
      return sequence
    } else if (isNothing(sequence)) {
      return []
    }
    return [sequence]
  }
  function extend(target, source) {
    let index, length, key, sourceKeys
    if (source) {
      sourceKeys = Object.keys(source)
      for (index = 0, length = sourceKeys.length; index < length; index += 1) {
        key = sourceKeys[index]
        target[key] = source[key]
      }
    }
    return target
  }
  function repeat(string, count) {
    let result = '',
      cycle
    for (cycle = 0; cycle < count; cycle += 1) {
      result += string
    }
    return result
  }
  function isNegativeZero(number) {
    return number === 0 && Number.NEGATIVE_INFINITY === 1 / number
  }
  common.isNothing = isNothing
  common.isObject = isObject
  common.toArray = toArray
  common.repeat = repeat
  common.isNegativeZero = isNegativeZero
  common.extend = extend
  return common
}

let exception
let hasRequiredException
function requireException() {
  if (hasRequiredException) {
    return exception
  }
  hasRequiredException = 1
  function formatError(exception, compact) {
    let where = '',
      message = exception.reason || '(unknown reason)'
    if (!exception.mark) {
      return message
    }
    if (exception.mark.name) {
      where += 'in "' + exception.mark.name + '" '
    }
    where +=
      '(' + (exception.mark.line + 1) + ':' + (exception.mark.column + 1) + ')'
    if (!compact && exception.mark.snippet) {
      where += '\n\n' + exception.mark.snippet
    }
    return message + ' ' + where
  }
  function YAMLException(reason, mark) {
    // Super constructor
    Error.call(this)
    this.name = 'YAMLException'
    this.reason = reason
    this.mark = mark
    this.message = formatError(this, false)

    // Include stack trace in error object
    if (Error.captureStackTrace) {
      // Chrome and NodeJS
      Error.captureStackTrace(this, this.constructor)
    } else {
      // FF, IE 10+ and Safari 6+. Fallback for others
      this.stack = new Error().stack || ''
    }
  }

  // Inherit from Error
  YAMLException.prototype = Object.create(Error.prototype)
  YAMLException.prototype.constructor = YAMLException
  YAMLException.prototype.toString = function toString(compact) {
    return this.name + ': ' + formatError(this, compact)
  }
  exception = YAMLException
  return exception
}

let snippet
let hasRequiredSnippet
function requireSnippet() {
  if (hasRequiredSnippet) {
    return snippet
  }
  hasRequiredSnippet = 1
  const common = requireCommon()

  // get snippet for a single line, respecting maxLength
  function getLine(buffer, lineStart, lineEnd, position, maxLineLength) {
    let head = ''
    let tail = ''
    const maxHalfLength = Math.floor(maxLineLength / 2) - 1
    if (position - lineStart > maxHalfLength) {
      head = ' ... '
      lineStart = position - maxHalfLength + head.length
    }
    if (lineEnd - position > maxHalfLength) {
      tail = ' ...'
      lineEnd = position + maxHalfLength - tail.length
    }
    return {
      str: head + buffer.slice(lineStart, lineEnd).replace(/\t/g, '→') + tail,
      pos: position - lineStart + head.length // relative position
    }
  }
  function padStart(string, max) {
    return common.repeat(' ', max - string.length) + string
  }
  function makeSnippet(mark, options) {
    options = Object.create(options || null)
    if (!mark.buffer) {
      return null
    }
    if (!options.maxLength) {
      options.maxLength = 79
    }
    if (typeof options.indent !== 'number') {
      options.indent = 1
    }
    if (typeof options.linesBefore !== 'number') {
      options.linesBefore = 3
    }
    if (typeof options.linesAfter !== 'number') {
      options.linesAfter = 2
    }
    const re = /\r?\n|\r|\0/g
    const lineStarts = [0]
    const lineEnds = []
    let match
    let foundLineNo = -1
    while ((match = re.exec(mark.buffer))) {
      lineEnds.push(match.index)
      lineStarts.push(match.index + match[0].length)
      if (mark.position <= match.index && foundLineNo < 0) {
        foundLineNo = lineStarts.length - 2
      }
    }
    if (foundLineNo < 0) {
      foundLineNo = lineStarts.length - 1
    }
    let result = '',
      i,
      line
    const lineNoLength = Math.min(
      mark.line + options.linesAfter,
      lineEnds.length
    ).toString().length
    const maxLineLength =
      options.maxLength - (options.indent + lineNoLength + 3)
    for (i = 1; i <= options.linesBefore; i++) {
      if (foundLineNo - i < 0) {
        break
      }
      line = getLine(
        mark.buffer,
        lineStarts[foundLineNo - i],
        lineEnds[foundLineNo - i],
        mark.position - (lineStarts[foundLineNo] - lineStarts[foundLineNo - i]),
        maxLineLength
      )
      result =
        common.repeat(' ', options.indent) +
        padStart((mark.line - i + 1).toString(), lineNoLength) +
        ' | ' +
        line.str +
        '\n' +
        result
    }
    line = getLine(
      mark.buffer,
      lineStarts[foundLineNo],
      lineEnds[foundLineNo],
      mark.position,
      maxLineLength
    )
    result +=
      common.repeat(' ', options.indent) +
      padStart((mark.line + 1).toString(), lineNoLength) +
      ' | ' +
      line.str +
      '\n'
    result +=
      common.repeat('-', options.indent + lineNoLength + 3 + line.pos) +
      '^' +
      '\n'
    for (i = 1; i <= options.linesAfter; i++) {
      if (foundLineNo + i >= lineEnds.length) {
        break
      }
      line = getLine(
        mark.buffer,
        lineStarts[foundLineNo + i],
        lineEnds[foundLineNo + i],
        mark.position - (lineStarts[foundLineNo] - lineStarts[foundLineNo + i]),
        maxLineLength
      )
      result +=
        common.repeat(' ', options.indent) +
        padStart((mark.line + i + 1).toString(), lineNoLength) +
        ' | ' +
        line.str +
        '\n'
    }
    return result.replace(/\n$/, '')
  }
  snippet = makeSnippet
  return snippet
}

let type
let hasRequiredType$1
function requireType$1() {
  if (hasRequiredType$1) {
    return type
  }
  hasRequiredType$1 = 1
  const YAMLException = requireException()
  const TYPE_CONSTRUCTOR_OPTIONS = [
    'kind',
    'multi',
    'resolve',
    'construct',
    'instanceOf',
    'predicate',
    'represent',
    'representName',
    'defaultStyle',
    'styleAliases'
  ]
  const YAML_NODE_KINDS = ['scalar', 'sequence', 'mapping']
  function compileStyleAliases(map) {
    const result = {}
    if (map !== null) {
      Object.keys(map).forEach(function (style) {
        map[style].forEach(function (alias) {
          result[String(alias)] = style
        })
      })
    }
    return result
  }
  function Type(tag, options) {
    options = options || {}
    Object.keys(options).forEach(function (name) {
      if (TYPE_CONSTRUCTOR_OPTIONS.indexOf(name) === -1) {
        throw new YAMLException(
          'Unknown option "' +
            name +
            '" is met in definition of "' +
            tag +
            '" YAML type.'
        )
      }
    })

    // TODO: Add tag format check.
    this.tag = tag
    this.kind = options['kind'] || null
    this.resolve =
      options['resolve'] ||
      function () {
        return true
      }
    this.construct =
      options['construct'] ||
      function (data) {
        return data
      }
    this.instanceOf = options['instanceOf'] || null
    this.predicate = options['predicate'] || null
    this.represent = options['represent'] || null
    this.representName = options['representName'] || null
    this.defaultStyle = options['defaultStyle'] || null
    this.multi = options['multi'] || false
    this.styleAliases = compileStyleAliases(options['styleAliases'] || null)
    if (YAML_NODE_KINDS.indexOf(this.kind) === -1) {
      throw new YAMLException(
        'Unknown kind "' +
          this.kind +
          '" is specified for "' +
          tag +
          '" YAML type.'
      )
    }
  }
  type = Type
  return type
}

let schema
let hasRequiredSchema
function requireSchema() {
  if (hasRequiredSchema) {
    return schema
  }
  hasRequiredSchema = 1

  /*eslint-disable max-len*/

  const YAMLException = requireException()
  const Type = requireType$1()
  function compileList(schema, name, result) {
    const exclude = []
    schema[name].forEach(function (currentType) {
      result.forEach(function (previousType, previousIndex) {
        if (
          previousType.tag === currentType.tag &&
          previousType.kind === currentType.kind &&
          previousType.multi === currentType.multi
        ) {
          exclude.push(previousIndex)
        }
      })
      result.push(currentType)
    })
    return result.filter(function (type, index) {
      return exclude.indexOf(index) === -1
    })
  }
  function compileMap(/* lists... */) {
    let result = {
        scalar: {},
        sequence: {},
        mapping: {},
        fallback: {},
        multi: {
          scalar: [],
          sequence: [],
          mapping: [],
          fallback: []
        }
      },
      index,
      length
    function collectType(type) {
      if (type.multi) {
        result.multi[type.kind].push(type)
        result.multi['fallback'].push(type)
      } else {
        result[type.kind][type.tag] = result['fallback'][type.tag] = type
      }
    }
    for (index = 0, length = arguments.length; index < length; index += 1) {
      arguments[index].forEach(collectType)
    }
    return result
  }
  function Schema(definition) {
    return this.extend(definition)
  }
  Schema.prototype.extend = function extend(definition) {
    let implicit = []
    let explicit = []
    if (definition instanceof Type) {
      // Schema.extend(type)
      explicit.push(definition)
    } else if (Array.isArray(definition)) {
      // Schema.extend([ type1, type2, ... ])
      explicit = explicit.concat(definition)
    } else if (
      definition &&
      (Array.isArray(definition.implicit) || Array.isArray(definition.explicit))
    ) {
      // Schema.extend({ explicit: [ type1, type2, ... ], implicit: [ type1, type2, ... ] })
      if (definition.implicit) {
        implicit = implicit.concat(definition.implicit)
      }
      if (definition.explicit) {
        explicit = explicit.concat(definition.explicit)
      }
    } else {
      throw new YAMLException(
        'Schema.extend argument should be a Type, [ Type ], ' +
          'or a schema definition ({ implicit: [...], explicit: [...] })'
      )
    }
    implicit.forEach(function (type) {
      if (!(type instanceof Type)) {
        throw new YAMLException(
          'Specified list of YAML types (or a single Type object) contains a non-Type object.'
        )
      }
      if (type.loadKind && type.loadKind !== 'scalar') {
        throw new YAMLException(
          'There is a non-scalar type in the implicit list of a schema. Implicit resolving of such types is not supported.'
        )
      }
      if (type.multi) {
        throw new YAMLException(
          'There is a multi type in the implicit list of a schema. Multi tags can only be listed as explicit.'
        )
      }
    })
    explicit.forEach(function (type) {
      if (!(type instanceof Type)) {
        throw new YAMLException(
          'Specified list of YAML types (or a single Type object) contains a non-Type object.'
        )
      }
    })
    const result = Object.create(Schema.prototype)
    result.implicit = (this.implicit || []).concat(implicit)
    result.explicit = (this.explicit || []).concat(explicit)
    result.compiledImplicit = compileList(result, 'implicit', [])
    result.compiledExplicit = compileList(result, 'explicit', [])
    result.compiledTypeMap = compileMap(
      result.compiledImplicit,
      result.compiledExplicit
    )
    return result
  }
  schema = Schema
  return schema
}

let str
let hasRequiredStr
function requireStr() {
  if (hasRequiredStr) {
    return str
  }
  hasRequiredStr = 1
  const Type = requireType$1()
  str = new Type('tag:yaml.org,2002:str', {
    kind: 'scalar',
    construct: function (data) {
      return data !== null ? data : ''
    }
  })
  return str
}

let seq
let hasRequiredSeq
function requireSeq() {
  if (hasRequiredSeq) {
    return seq
  }
  hasRequiredSeq = 1
  const Type = requireType$1()
  seq = new Type('tag:yaml.org,2002:seq', {
    kind: 'sequence',
    construct: function (data) {
      return data !== null ? data : []
    }
  })
  return seq
}

let map
let hasRequiredMap$1
function requireMap$1() {
  if (hasRequiredMap$1) {
    return map
  }
  hasRequiredMap$1 = 1
  const Type = requireType$1()
  map = new Type('tag:yaml.org,2002:map', {
    kind: 'mapping',
    construct: function (data) {
      return data !== null ? data : {}
    }
  })
  return map
}

let failsafe
let hasRequiredFailsafe
function requireFailsafe() {
  if (hasRequiredFailsafe) {
    return failsafe
  }
  hasRequiredFailsafe = 1
  const Schema = requireSchema()
  failsafe = new Schema({
    explicit: [requireStr(), requireSeq(), requireMap$1()]
  })
  return failsafe
}

let _null
let hasRequired_null
function require_null() {
  if (hasRequired_null) {
    return _null
  }
  hasRequired_null = 1
  const Type = requireType$1()
  function resolveYamlNull(data) {
    if (data === null) {
      return true
    }
    const max = data.length
    return (
      (max === 1 && data === '~') ||
      (max === 4 && (data === 'null' || data === 'Null' || data === 'NULL'))
    )
  }
  function constructYamlNull() {
    return null
  }
  function isNull(object) {
    return object === null
  }
  _null = new Type('tag:yaml.org,2002:null', {
    kind: 'scalar',
    resolve: resolveYamlNull,
    construct: constructYamlNull,
    predicate: isNull,
    represent: {
      canonical: function () {
        return '~'
      },
      lowercase: function () {
        return 'null'
      },
      uppercase: function () {
        return 'NULL'
      },
      camelcase: function () {
        return 'Null'
      },
      empty: function () {
        return ''
      }
    },
    defaultStyle: 'lowercase'
  })
  return _null
}

let bool
let hasRequiredBool
function requireBool() {
  if (hasRequiredBool) {
    return bool
  }
  hasRequiredBool = 1
  const Type = requireType$1()
  function resolveYamlBoolean(data) {
    if (data === null) {
      return false
    }
    const max = data.length
    return (
      (max === 4 && (data === 'true' || data === 'True' || data === 'TRUE')) ||
      (max === 5 && (data === 'false' || data === 'False' || data === 'FALSE'))
    )
  }
  function constructYamlBoolean(data) {
    return data === 'true' || data === 'True' || data === 'TRUE'
  }
  function isBoolean(object) {
    return Object.prototype.toString.call(object) === '[object Boolean]'
  }
  bool = new Type('tag:yaml.org,2002:bool', {
    kind: 'scalar',
    resolve: resolveYamlBoolean,
    construct: constructYamlBoolean,
    predicate: isBoolean,
    represent: {
      lowercase: function (object) {
        return object ? 'true' : 'false'
      },
      uppercase: function (object) {
        return object ? 'TRUE' : 'FALSE'
      },
      camelcase: function (object) {
        return object ? 'True' : 'False'
      }
    },
    defaultStyle: 'lowercase'
  })
  return bool
}

let int
let hasRequiredInt
function requireInt() {
  if (hasRequiredInt) {
    return int
  }
  hasRequiredInt = 1
  const common = requireCommon()
  const Type = requireType$1()
  function isHexCode(c) {
    return (
      (0x30 /* 0 */ <= c && c <= 0x39) /* 9 */ ||
      (0x41 /* A */ <= c && c <= 0x46) /* F */ ||
      (0x61 /* a */ <= c && c <= 0x66) /* f */
    )
  }
  function isOctCode(c) {
    return 0x30 /* 0 */ <= c && c <= 0x37 /* 7 */
  }
  function isDecCode(c) {
    return 0x30 /* 0 */ <= c && c <= 0x39 /* 9 */
  }
  function resolveYamlInteger(data) {
    if (data === null) {
      return false
    }
    let max = data.length,
      index = 0,
      hasDigits = false,
      ch
    if (!max) {
      return false
    }
    ch = data[index]

    // sign
    if (ch === '-' || ch === '+') {
      ch = data[++index]
    }
    if (ch === '0') {
      // 0
      if (index + 1 === max) {
        return true
      }
      ch = data[++index]

      // base 2, base 8, base 16

      if (ch === 'b') {
        // base 2
        index++
        for (; index < max; index++) {
          ch = data[index]
          if (ch === '_') {
            continue
          }
          if (ch !== '0' && ch !== '1') {
            return false
          }
          hasDigits = true
        }
        return hasDigits && ch !== '_'
      }
      if (ch === 'x') {
        // base 16
        index++
        for (; index < max; index++) {
          ch = data[index]
          if (ch === '_') {
            continue
          }
          if (!isHexCode(data.charCodeAt(index))) {
            return false
          }
          hasDigits = true
        }
        return hasDigits && ch !== '_'
      }
      if (ch === 'o') {
        // base 8
        index++
        for (; index < max; index++) {
          ch = data[index]
          if (ch === '_') {
            continue
          }
          if (!isOctCode(data.charCodeAt(index))) {
            return false
          }
          hasDigits = true
        }
        return hasDigits && ch !== '_'
      }
    }

    // base 10 (except 0)

    // value should not start with `_`;
    if (ch === '_') {
      return false
    }
    for (; index < max; index++) {
      ch = data[index]
      if (ch === '_') {
        continue
      }
      if (!isDecCode(data.charCodeAt(index))) {
        return false
      }
      hasDigits = true
    }

    // Should have digits and should not end with `_`
    if (!hasDigits || ch === '_') {
      return false
    }
    return true
  }
  function constructYamlInteger(data) {
    let value = data,
      sign = 1,
      ch
    if (value.indexOf('_') !== -1) {
      value = value.replace(/_/g, '')
    }
    ch = value[0]
    if (ch === '-' || ch === '+') {
      if (ch === '-') {
        sign = -1
      }
      value = value.slice(1)
      ch = value[0]
    }
    if (value === '0') {
      return 0
    }
    if (ch === '0') {
      if (value[1] === 'b') {
        return sign * parseInt(value.slice(2), 2)
      }
      if (value[1] === 'x') {
        return sign * parseInt(value.slice(2), 16)
      }
      if (value[1] === 'o') {
        return sign * parseInt(value.slice(2), 8)
      }
    }
    return sign * parseInt(value, 10)
  }
  function isInteger(object) {
    return (
      Object.prototype.toString.call(object) === '[object Number]' &&
      object % 1 === 0 &&
      !common.isNegativeZero(object)
    )
  }
  int = new Type('tag:yaml.org,2002:int', {
    kind: 'scalar',
    resolve: resolveYamlInteger,
    construct: constructYamlInteger,
    predicate: isInteger,
    represent: {
      binary: function (obj) {
        return obj >= 0
          ? '0b' + obj.toString(2)
          : '-0b' + obj.toString(2).slice(1)
      },
      octal: function (obj) {
        return obj >= 0
          ? '0o' + obj.toString(8)
          : '-0o' + obj.toString(8).slice(1)
      },
      decimal: function (obj) {
        return obj.toString(10)
      },
      /* eslint-disable max-len */
      hexadecimal: function (obj) {
        return obj >= 0
          ? '0x' + obj.toString(16).toUpperCase()
          : '-0x' + obj.toString(16).toUpperCase().slice(1)
      }
    },
    defaultStyle: 'decimal',
    styleAliases: {
      binary: [2, 'bin'],
      octal: [8, 'oct'],
      decimal: [10, 'dec'],
      hexadecimal: [16, 'hex']
    }
  })
  return int
}

let float
let hasRequiredFloat
function requireFloat() {
  if (hasRequiredFloat) {
    return float
  }
  hasRequiredFloat = 1
  const common = requireCommon()
  const Type = requireType$1()
  const YAML_FLOAT_PATTERN = new RegExp(
    // 2.5e4, 2.5 and integers
    '^(?:[-+]?(?:[0-9][0-9_]*)(?:\\.[0-9_]*)?(?:[eE][-+]?[0-9]+)?' +
      // .2e4, .2
      // special case, seems not from spec
      '|\\.[0-9_]+(?:[eE][-+]?[0-9]+)?' +
      // .inf
      '|[-+]?\\.(?:inf|Inf|INF)' +
      // .nan
      '|\\.(?:nan|NaN|NAN))$'
  )
  function resolveYamlFloat(data) {
    if (data === null) {
      return false
    }
    if (
      !YAML_FLOAT_PATTERN.test(data) ||
      // Quick hack to not allow integers end with `_`
      // Probably should update regexp & check speed
      data[data.length - 1] === '_'
    ) {
      return false
    }
    return true
  }
  function constructYamlFloat(data) {
    let value, sign
    value = data.replace(/_/g, '').toLowerCase()
    sign = value[0] === '-' ? -1 : 1
    if ('+-'.indexOf(value[0]) >= 0) {
      value = value.slice(1)
    }
    if (value === '.inf') {
      return sign === 1 ? Number.POSITIVE_INFINITY : Number.NEGATIVE_INFINITY
    } else if (value === '.nan') {
      return NaN
    }
    return sign * parseFloat(value, 10)
  }
  const SCIENTIFIC_WITHOUT_DOT = /^[-+]?[0-9]+e/
  function representYamlFloat(object, style) {
    let res
    if (isNaN(object)) {
      switch (style) {
        case 'lowercase':
          return '.nan'
        case 'uppercase':
          return '.NAN'
        case 'camelcase':
          return '.NaN'
      }
    } else if (Number.POSITIVE_INFINITY === object) {
      switch (style) {
        case 'lowercase':
          return '.inf'
        case 'uppercase':
          return '.INF'
        case 'camelcase':
          return '.Inf'
      }
    } else if (Number.NEGATIVE_INFINITY === object) {
      switch (style) {
        case 'lowercase':
          return '-.inf'
        case 'uppercase':
          return '-.INF'
        case 'camelcase':
          return '-.Inf'
      }
    } else if (common.isNegativeZero(object)) {
      return '-0.0'
    }
    res = object.toString(10)

    // JS stringifier can build scientific format without dots: 5e-100,
    // while YAML requres dot: 5.e-100. Fix it with simple hack

    return SCIENTIFIC_WITHOUT_DOT.test(res) ? res.replace('e', '.e') : res
  }
  function isFloat(object) {
    return (
      Object.prototype.toString.call(object) === '[object Number]' &&
      (object % 1 !== 0 || common.isNegativeZero(object))
    )
  }
  float = new Type('tag:yaml.org,2002:float', {
    kind: 'scalar',
    resolve: resolveYamlFloat,
    construct: constructYamlFloat,
    predicate: isFloat,
    represent: representYamlFloat,
    defaultStyle: 'lowercase'
  })
  return float
}

let json
let hasRequiredJson
function requireJson() {
  if (hasRequiredJson) {
    return json
  }
  hasRequiredJson = 1
  json = requireFailsafe().extend({
    implicit: [require_null(), requireBool(), requireInt(), requireFloat()]
  })
  return json
}

let core$1
let hasRequiredCore$1
function requireCore$1() {
  if (hasRequiredCore$1) {
    return core$1
  }
  hasRequiredCore$1 = 1
  core$1 = requireJson()
  return core$1
}

let timestamp
let hasRequiredTimestamp
function requireTimestamp() {
  if (hasRequiredTimestamp) {
    return timestamp
  }
  hasRequiredTimestamp = 1
  const Type = requireType$1()
  const YAML_DATE_REGEXP = new RegExp(
    '^([0-9][0-9][0-9][0-9])' +
      // [1] year
      '-([0-9][0-9])' +
      // [2] month
      '-([0-9][0-9])$'
  ) // [3] day

  const YAML_TIMESTAMP_REGEXP = new RegExp(
    '^([0-9][0-9][0-9][0-9])' +
      // [1] year
      '-([0-9][0-9]?)' +
      // [2] month
      '-([0-9][0-9]?)' +
      // [3] day
      '(?:[Tt]|[ \\t]+)' +
      // ...
      '([0-9][0-9]?)' +
      // [4] hour
      ':([0-9][0-9])' +
      // [5] minute
      ':([0-9][0-9])' +
      // [6] second
      '(?:\\.([0-9]*))?' +
      // [7] fraction
      '(?:[ \\t]*(Z|([-+])([0-9][0-9]?)' +
      // [8] tz [9] tz_sign [10] tz_hour
      '(?::([0-9][0-9]))?))?$'
  ) // [11] tz_minute

  function resolveYamlTimestamp(data) {
    if (data === null) {
      return false
    }
    if (YAML_DATE_REGEXP.exec(data) !== null) {
      return true
    }
    if (YAML_TIMESTAMP_REGEXP.exec(data) !== null) {
      return true
    }
    return false
  }
  function constructYamlTimestamp(data) {
    let match,
      year,
      month,
      day,
      hour,
      minute,
      second,
      fraction = 0,
      delta = null,
      tz_hour,
      tz_minute,
      date
    match = YAML_DATE_REGEXP.exec(data)
    if (match === null) {
      match = YAML_TIMESTAMP_REGEXP.exec(data)
    }
    if (match === null) {
      throw new Error('Date resolve error')
    }

    // match: [1] year [2] month [3] day

    year = +match[1]
    month = +match[2] - 1 // JS month starts with 0
    day = +match[3]
    if (!match[4]) {
      // no hour
      return new Date(Date.UTC(year, month, day))
    }

    // match: [4] hour [5] minute [6] second [7] fraction

    hour = +match[4]
    minute = +match[5]
    second = +match[6]
    if (match[7]) {
      fraction = match[7].slice(0, 3)
      while (fraction.length < 3) {
        // milli-seconds
        fraction += '0'
      }
      fraction = +fraction
    }

    // match: [8] tz [9] tz_sign [10] tz_hour [11] tz_minute

    if (match[9]) {
      tz_hour = +match[10]
      tz_minute = +(match[11] || 0)
      delta = (tz_hour * 60 + tz_minute) * 60000 // delta in mili-seconds
      if (match[9] === '-') {
        delta = -delta
      }
    }
    date = new Date(Date.UTC(year, month, day, hour, minute, second, fraction))
    if (delta) {
      date.setTime(date.getTime() - delta)
    }
    return date
  }
  function representYamlTimestamp(object /*, style*/) {
    return object.toISOString()
  }
  timestamp = new Type('tag:yaml.org,2002:timestamp', {
    kind: 'scalar',
    resolve: resolveYamlTimestamp,
    construct: constructYamlTimestamp,
    instanceOf: Date,
    represent: representYamlTimestamp
  })
  return timestamp
}

let merge
let hasRequiredMerge
function requireMerge() {
  if (hasRequiredMerge) {
    return merge
  }
  hasRequiredMerge = 1
  const Type = requireType$1()
  function resolveYamlMerge(data) {
    return data === '<<' || data === null
  }
  merge = new Type('tag:yaml.org,2002:merge', {
    kind: 'scalar',
    resolve: resolveYamlMerge
  })
  return merge
}

let binary
let hasRequiredBinary
function requireBinary() {
  if (hasRequiredBinary) {
    return binary
  }
  hasRequiredBinary = 1

  /*eslint-disable no-bitwise*/

  const Type = requireType$1()

  // [ 64, 65, 66 ] -> [ padding, CR, LF ]
  const BASE64_MAP =
    'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=\n\r'
  function resolveYamlBinary(data) {
    if (data === null) {
      return false
    }
    let code,
      idx,
      bitlen = 0,
      max = data.length,
      map = BASE64_MAP

    // Convert one by one.
    for (idx = 0; idx < max; idx++) {
      code = map.indexOf(data.charAt(idx))

      // Skip CR/LF
      if (code > 64) {
        continue
      }

      // Fail on illegal characters
      if (code < 0) {
        return false
      }
      bitlen += 6
    }

    // If there are any bits left, source was corrupted
    return bitlen % 8 === 0
  }
  function constructYamlBinary(data) {
    let idx,
      tailbits,
      input = data.replace(/[\r\n=]/g, ''),
      // remove CR/LF & padding to simplify scan
      max = input.length,
      map = BASE64_MAP,
      bits = 0,
      result = []

    // Collect by 6*4 bits (3 bytes)

    for (idx = 0; idx < max; idx++) {
      if (idx % 4 === 0 && idx) {
        result.push((bits >> 16) & 0xff)
        result.push((bits >> 8) & 0xff)
        result.push(bits & 0xff)
      }
      bits = (bits << 6) | map.indexOf(input.charAt(idx))
    }

    // Dump tail

    tailbits = (max % 4) * 6
    if (tailbits === 0) {
      result.push((bits >> 16) & 0xff)
      result.push((bits >> 8) & 0xff)
      result.push(bits & 0xff)
    } else if (tailbits === 18) {
      result.push((bits >> 10) & 0xff)
      result.push((bits >> 2) & 0xff)
    } else if (tailbits === 12) {
      result.push((bits >> 4) & 0xff)
    }
    return new Uint8Array(result)
  }
  function representYamlBinary(object /*, style*/) {
    let result = '',
      bits = 0,
      idx,
      tail,
      max = object.length,
      map = BASE64_MAP

    // Convert every three bytes to 4 ASCII characters.

    for (idx = 0; idx < max; idx++) {
      if (idx % 3 === 0 && idx) {
        result += map[(bits >> 18) & 0x3f]
        result += map[(bits >> 12) & 0x3f]
        result += map[(bits >> 6) & 0x3f]
        result += map[bits & 0x3f]
      }
      bits = (bits << 8) + object[idx]
    }

    // Dump tail

    tail = max % 3
    if (tail === 0) {
      result += map[(bits >> 18) & 0x3f]
      result += map[(bits >> 12) & 0x3f]
      result += map[(bits >> 6) & 0x3f]
      result += map[bits & 0x3f]
    } else if (tail === 2) {
      result += map[(bits >> 10) & 0x3f]
      result += map[(bits >> 4) & 0x3f]
      result += map[(bits << 2) & 0x3f]
      result += map[64]
    } else if (tail === 1) {
      result += map[(bits >> 2) & 0x3f]
      result += map[(bits << 4) & 0x3f]
      result += map[64]
      result += map[64]
    }
    return result
  }
  function isBinary(obj) {
    return Object.prototype.toString.call(obj) === '[object Uint8Array]'
  }
  binary = new Type('tag:yaml.org,2002:binary', {
    kind: 'scalar',
    resolve: resolveYamlBinary,
    construct: constructYamlBinary,
    predicate: isBinary,
    represent: representYamlBinary
  })
  return binary
}

let omap
let hasRequiredOmap
function requireOmap() {
  if (hasRequiredOmap) {
    return omap
  }
  hasRequiredOmap = 1
  const Type = requireType$1()
  const _hasOwnProperty = Object.prototype.hasOwnProperty
  const _toString = Object.prototype.toString
  function resolveYamlOmap(data) {
    if (data === null) {
      return true
    }
    let objectKeys = [],
      index,
      length,
      pair,
      pairKey,
      pairHasKey,
      object = data
    for (index = 0, length = object.length; index < length; index += 1) {
      pair = object[index]
      pairHasKey = false
      if (_toString.call(pair) !== '[object Object]') {
        return false
      }
      for (pairKey in pair) {
        if (_hasOwnProperty.call(pair, pairKey)) {
          if (!pairHasKey) {
            pairHasKey = true
          } else {
            return false
          }
        }
      }
      if (!pairHasKey) {
        return false
      }
      if (objectKeys.indexOf(pairKey) === -1) {
        objectKeys.push(pairKey)
      } else {
        return false
      }
    }
    return true
  }
  function constructYamlOmap(data) {
    return data !== null ? data : []
  }
  omap = new Type('tag:yaml.org,2002:omap', {
    kind: 'sequence',
    resolve: resolveYamlOmap,
    construct: constructYamlOmap
  })
  return omap
}

let pairs
let hasRequiredPairs
function requirePairs() {
  if (hasRequiredPairs) {
    return pairs
  }
  hasRequiredPairs = 1
  const Type = requireType$1()
  const _toString = Object.prototype.toString
  function resolveYamlPairs(data) {
    if (data === null) {
      return true
    }
    let index,
      length,
      pair,
      keys,
      result,
      object = data
    result = new Array(object.length)
    for (index = 0, length = object.length; index < length; index += 1) {
      pair = object[index]
      if (_toString.call(pair) !== '[object Object]') {
        return false
      }
      keys = Object.keys(pair)
      if (keys.length !== 1) {
        return false
      }
      result[index] = [keys[0], pair[keys[0]]]
    }
    return true
  }
  function constructYamlPairs(data) {
    if (data === null) {
      return []
    }
    let index,
      length,
      pair,
      keys,
      result,
      object = data
    result = new Array(object.length)
    for (index = 0, length = object.length; index < length; index += 1) {
      pair = object[index]
      keys = Object.keys(pair)
      result[index] = [keys[0], pair[keys[0]]]
    }
    return result
  }
  pairs = new Type('tag:yaml.org,2002:pairs', {
    kind: 'sequence',
    resolve: resolveYamlPairs,
    construct: constructYamlPairs
  })
  return pairs
}

let set
let hasRequiredSet
function requireSet() {
  if (hasRequiredSet) {
    return set
  }
  hasRequiredSet = 1
  const Type = requireType$1()
  const _hasOwnProperty = Object.prototype.hasOwnProperty
  function resolveYamlSet(data) {
    if (data === null) {
      return true
    }
    let key,
      object = data
    for (key in object) {
      if (_hasOwnProperty.call(object, key)) {
        if (object[key] !== null) {
          return false
        }
      }
    }
    return true
  }
  function constructYamlSet(data) {
    return data !== null ? data : {}
  }
  set = new Type('tag:yaml.org,2002:set', {
    kind: 'mapping',
    resolve: resolveYamlSet,
    construct: constructYamlSet
  })
  return set
}

let _default
let hasRequired_default
function require_default() {
  if (hasRequired_default) {
    return _default
  }
  hasRequired_default = 1
  _default = requireCore$1().extend({
    implicit: [requireTimestamp(), requireMerge()],
    explicit: [requireBinary(), requireOmap(), requirePairs(), requireSet()]
  })
  return _default
}

let hasRequiredLoader
function requireLoader() {
  if (hasRequiredLoader) {
    return loader
  }
  hasRequiredLoader = 1

  /*eslint-disable max-len,no-use-before-define*/

  const common = requireCommon()
  const YAMLException = requireException()
  const makeSnippet = requireSnippet()
  const DEFAULT_SCHEMA = require_default()
  const _hasOwnProperty = Object.prototype.hasOwnProperty
  const CONTEXT_FLOW_IN = 1
  const CONTEXT_FLOW_OUT = 2
  const CONTEXT_BLOCK_IN = 3
  const CONTEXT_BLOCK_OUT = 4
  const CHOMPING_CLIP = 1
  const CHOMPING_STRIP = 2
  const CHOMPING_KEEP = 3
  const PATTERN_NON_PRINTABLE =
    /[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x84\x86-\x9F\uFFFE\uFFFF]|[\uD800-\uDBFF](?![\uDC00-\uDFFF])|(?:[^\uD800-\uDBFF]|^)[\uDC00-\uDFFF]/
  const PATTERN_NON_ASCII_LINE_BREAKS = /[\x85\u2028\u2029]/
  const PATTERN_FLOW_INDICATORS = /[,[\]{}]/
  const PATTERN_TAG_HANDLE = /^(?:!|!!|![a-z-]+!)$/i
  const PATTERN_TAG_URI =
    /^(?:!|[^,[\]{}])(?:%[0-9a-f]{2}|[0-9a-z\-#;/?:@&=+$,_.!~*'()[\]])*$/i
  function _class(obj) {
    return Object.prototype.toString.call(obj)
  }
  function is_EOL(c) {
    return c === 0x0a /* LF */ || c === 0x0d /* CR */
  }
  function is_WHITE_SPACE(c) {
    return c === 0x09 /* Tab */ || c === 0x20 /* Space */
  }
  function is_WS_OR_EOL(c) {
    return (
      c === 0x09 /* Tab */ ||
      c === 0x20 /* Space */ ||
      c === 0x0a /* LF */ ||
      c === 0x0d /* CR */
    )
  }
  function is_FLOW_INDICATOR(c) {
    return (
      c === 0x2c /* , */ ||
      c === 0x5b /* [ */ ||
      c === 0x5d /* ] */ ||
      c === 0x7b /* { */ ||
      c === 0x7d /* } */
    )
  }
  function fromHexCode(c) {
    let lc
    if (0x30 /* 0 */ <= c && c <= 0x39 /* 9 */) {
      return c - 0x30
    }

    /*eslint-disable no-bitwise*/
    lc = c | 0x20
    if (0x61 /* a */ <= lc && lc <= 0x66 /* f */) {
      return lc - 0x61 + 10
    }
    return -1
  }
  function escapedHexLen(c) {
    if (c === 0x78 /* x */) {
      return 2
    }
    if (c === 0x75 /* u */) {
      return 4
    }
    if (c === 0x55 /* U */) {
      return 8
    }
    return 0
  }
  function fromDecimalCode(c) {
    if (0x30 /* 0 */ <= c && c <= 0x39 /* 9 */) {
      return c - 0x30
    }
    return -1
  }
  function simpleEscapeSequence(c) {
    /* eslint-disable indent */
    return c === 0x30 /* 0 */
      ? '\x00'
      : c === 0x61 /* a */
        ? '\x07'
        : c === 0x62 /* b */
          ? '\x08'
          : c === 0x74 /* t */
            ? '\x09'
            : c === 0x09 /* Tab */
              ? '\x09'
              : c === 0x6e /* n */
                ? '\x0A'
                : c === 0x76 /* v */
                  ? '\x0B'
                  : c === 0x66 /* f */
                    ? '\x0C'
                    : c === 0x72 /* r */
                      ? '\x0D'
                      : c === 0x65 /* e */
                        ? '\x1B'
                        : c === 0x20 /* Space */
                          ? ' '
                          : c === 0x22 /* " */
                            ? '\x22'
                            : c === 0x2f /* / */
                              ? '/'
                              : c === 0x5c /* \ */
                                ? '\x5C'
                                : c === 0x4e /* N */
                                  ? '\x85'
                                  : c === 0x5f /* _ */
                                    ? '\xA0'
                                    : c === 0x4c /* L */
                                      ? '\u2028'
                                      : c === 0x50 /* P */
                                        ? '\u2029'
                                        : ''
  }
  function charFromCodepoint(c) {
    if (c <= 0xffff) {
      return String.fromCharCode(c)
    }
    // Encode UTF-16 surrogate pair
    // https://en.wikipedia.org/wiki/UTF-16#Code_points_U.2B010000_to_U.2B10FFFF
    return String.fromCharCode(
      ((c - 0x010000) >> 10) + 0xd800,
      ((c - 0x010000) & 0x03ff) + 0xdc00
    )
  }
  const simpleEscapeCheck = new Array(256) // integer, for fast access
  const simpleEscapeMap = new Array(256)
  for (let i = 0; i < 256; i++) {
    simpleEscapeCheck[i] = simpleEscapeSequence(i) ? 1 : 0
    simpleEscapeMap[i] = simpleEscapeSequence(i)
  }
  function State(input, options) {
    this.input = input
    this.filename = options['filename'] || null
    this.schema = options['schema'] || DEFAULT_SCHEMA
    this.onWarning = options['onWarning'] || null
    // (Hidden) Remove? makes the loader to expect YAML 1.1 documents
    // if such documents have no explicit %YAML directive
    this.legacy = options['legacy'] || false
    this.json = options['json'] || false
    this.listener = options['listener'] || null
    this.implicitTypes = this.schema.compiledImplicit
    this.typeMap = this.schema.compiledTypeMap
    this.length = input.length
    this.position = 0
    this.line = 0
    this.lineStart = 0
    this.lineIndent = 0

    // position of first leading tab in the current line,
    // used to make sure there are no tabs in the indentation
    this.firstTabInLine = -1
    this.documents = []

    /*
    this.version;
    this.checkLineBreaks;
    this.tagMap;
    this.anchorMap;
    this.tag;
    this.anchor;
    this.kind;
    this.result;*/
  }
  function generateError(state, message) {
    const mark = {
      name: state.filename,
      buffer: state.input.slice(0, -1),
      // omit trailing \0
      position: state.position,
      line: state.line,
      column: state.position - state.lineStart
    }
    mark.snippet = makeSnippet(mark)
    return new YAMLException(message, mark)
  }
  function throwError(state, message) {
    throw generateError(state, message)
  }
  function throwWarning(state, message) {
    if (state.onWarning) {
      state.onWarning.call(null, generateError(state, message))
    }
  }
  const directiveHandlers = {
    YAML: function handleYamlDirective(state, name, args) {
      let match, major, minor
      if (state.version !== null) {
        throwError(state, 'duplication of %YAML directive')
      }
      if (args.length !== 1) {
        throwError(state, 'YAML directive accepts exactly one argument')
      }
      match = /^([0-9]+)\.([0-9]+)$/.exec(args[0])
      if (match === null) {
        throwError(state, 'ill-formed argument of the YAML directive')
      }
      major = parseInt(match[1], 10)
      minor = parseInt(match[2], 10)
      if (major !== 1) {
        throwError(state, 'unacceptable YAML version of the document')
      }
      state.version = args[0]
      state.checkLineBreaks = minor < 2
      if (minor !== 1 && minor !== 2) {
        throwWarning(state, 'unsupported YAML version of the document')
      }
    },
    TAG: function handleTagDirective(state, name, args) {
      let handle, prefix
      if (args.length !== 2) {
        throwError(state, 'TAG directive accepts exactly two arguments')
      }
      handle = args[0]
      prefix = args[1]
      if (!PATTERN_TAG_HANDLE.test(handle)) {
        throwError(
          state,
          'ill-formed tag handle (first argument) of the TAG directive'
        )
      }
      if (_hasOwnProperty.call(state.tagMap, handle)) {
        throwError(
          state,
          'there is a previously declared suffix for "' +
            handle +
            '" tag handle'
        )
      }
      if (!PATTERN_TAG_URI.test(prefix)) {
        throwError(
          state,
          'ill-formed tag prefix (second argument) of the TAG directive'
        )
      }
      try {
        prefix = decodeURIComponent(prefix)
      } catch (err) {
        throwError(state, 'tag prefix is malformed: ' + prefix)
      }
      state.tagMap[handle] = prefix
    }
  }
  function captureSegment(state, start, end, checkJson) {
    let _position, _length, _character, _result
    if (start < end) {
      _result = state.input.slice(start, end)
      if (checkJson) {
        for (
          _position = 0, _length = _result.length;
          _position < _length;
          _position += 1
        ) {
          _character = _result.charCodeAt(_position)
          if (
            !(
              _character === 0x09 ||
              (0x20 <= _character && _character <= 0x10ffff)
            )
          ) {
            throwError(state, 'expected valid JSON character')
          }
        }
      } else if (PATTERN_NON_PRINTABLE.test(_result)) {
        throwError(state, 'the stream contains non-printable characters')
      }
      state.result += _result
    }
  }
  function mergeMappings(state, destination, source, overridableKeys) {
    let sourceKeys, key, index, quantity
    if (!common.isObject(source)) {
      throwError(
        state,
        'cannot merge mappings; the provided source object is unacceptable'
      )
    }
    sourceKeys = Object.keys(source)
    for (
      index = 0, quantity = sourceKeys.length;
      index < quantity;
      index += 1
    ) {
      key = sourceKeys[index]
      if (!_hasOwnProperty.call(destination, key)) {
        destination[key] = source[key]
        overridableKeys[key] = true
      }
    }
  }
  function storeMappingPair(
    state,
    _result,
    overridableKeys,
    keyTag,
    keyNode,
    valueNode,
    startLine,
    startLineStart,
    startPos
  ) {
    let index, quantity

    // The output is a plain object here, so keys can only be strings.
    // We need to convert keyNode to a string, but doing so can hang the process
    // (deeply nested arrays that explode exponentially using aliases).
    if (Array.isArray(keyNode)) {
      keyNode = Array.prototype.slice.call(keyNode)
      for (index = 0, quantity = keyNode.length; index < quantity; index += 1) {
        if (Array.isArray(keyNode[index])) {
          throwError(state, 'nested arrays are not supported inside keys')
        }
        if (
          typeof keyNode === 'object' &&
          _class(keyNode[index]) === '[object Object]'
        ) {
          keyNode[index] = '[object Object]'
        }
      }
    }

    // Avoid code execution in load() via toString property
    // (still use its own toString for arrays, timestamps,
    // and whatever user schema extensions happen to have @@toStringTag)
    if (typeof keyNode === 'object' && _class(keyNode) === '[object Object]') {
      keyNode = '[object Object]'
    }
    keyNode = String(keyNode)
    if (_result === null) {
      _result = {}
    }
    if (keyTag === 'tag:yaml.org,2002:merge') {
      if (Array.isArray(valueNode)) {
        for (
          index = 0, quantity = valueNode.length;
          index < quantity;
          index += 1
        ) {
          mergeMappings(state, _result, valueNode[index], overridableKeys)
        }
      } else {
        mergeMappings(state, _result, valueNode, overridableKeys)
      }
    } else {
      if (
        !state.json &&
        !_hasOwnProperty.call(overridableKeys, keyNode) &&
        _hasOwnProperty.call(_result, keyNode)
      ) {
        state.line = startLine || state.line
        state.lineStart = startLineStart || state.lineStart
        state.position = startPos || state.position
        throwError(state, 'duplicated mapping key')
      }

      // used for this specific key only because Object.defineProperty is slow
      if (keyNode === '__proto__') {
        Object.defineProperty(_result, keyNode, {
          configurable: true,
          enumerable: true,
          writable: true,
          value: valueNode
        })
      } else {
        _result[keyNode] = valueNode
      }
      delete overridableKeys[keyNode]
    }
    return _result
  }
  function readLineBreak(state) {
    let ch
    ch = state.input.charCodeAt(state.position)
    if (ch === 0x0a /* LF */) {
      state.position++
    } else if (ch === 0x0d /* CR */) {
      state.position++
      if (state.input.charCodeAt(state.position) === 0x0a /* LF */) {
        state.position++
      }
    } else {
      throwError(state, 'a line break is expected')
    }
    state.line += 1
    state.lineStart = state.position
    state.firstTabInLine = -1
  }
  function skipSeparationSpace(state, allowComments, checkIndent) {
    let lineBreaks = 0,
      ch = state.input.charCodeAt(state.position)
    while (ch !== 0) {
      while (is_WHITE_SPACE(ch)) {
        if (ch === 0x09 /* Tab */ && state.firstTabInLine === -1) {
          state.firstTabInLine = state.position
        }
        ch = state.input.charCodeAt(++state.position)
      }
      if (allowComments && ch === 0x23 /* # */) {
        do {
          ch = state.input.charCodeAt(++state.position)
        } while (ch !== 0x0a /* LF */ && ch !== 0x0d /* CR */ && ch !== 0)
      }
      if (is_EOL(ch)) {
        readLineBreak(state)
        ch = state.input.charCodeAt(state.position)
        lineBreaks++
        state.lineIndent = 0
        while (ch === 0x20 /* Space */) {
          state.lineIndent++
          ch = state.input.charCodeAt(++state.position)
        }
      } else {
        break
      }
    }
    if (
      checkIndent !== -1 &&
      lineBreaks !== 0 &&
      state.lineIndent < checkIndent
    ) {
      throwWarning(state, 'deficient indentation')
    }
    return lineBreaks
  }
  function testDocumentSeparator(state) {
    let _position = state.position,
      ch
    ch = state.input.charCodeAt(_position)

    // Condition state.position === state.lineStart is tested
    // in parent on each call, for efficiency. No needs to test here again.
    if (
      (ch === 0x2d /* - */ || ch === 0x2e) /* . */ &&
      ch === state.input.charCodeAt(_position + 1) &&
      ch === state.input.charCodeAt(_position + 2)
    ) {
      _position += 3
      ch = state.input.charCodeAt(_position)
      if (ch === 0 || is_WS_OR_EOL(ch)) {
        return true
      }
    }
    return false
  }
  function writeFoldedLines(state, count) {
    if (count === 1) {
      state.result += ' '
    } else if (count > 1) {
      state.result += common.repeat('\n', count - 1)
    }
  }
  function readPlainScalar(state, nodeIndent, withinFlowCollection) {
    let preceding,
      following,
      captureStart,
      captureEnd,
      hasPendingContent,
      _line,
      _lineStart,
      _lineIndent,
      _kind = state.kind,
      _result = state.result,
      ch
    ch = state.input.charCodeAt(state.position)
    if (
      is_WS_OR_EOL(ch) ||
      is_FLOW_INDICATOR(ch) ||
      ch === 0x23 /* # */ ||
      ch === 0x26 /* & */ ||
      ch === 0x2a /* * */ ||
      ch === 0x21 /* ! */ ||
      ch === 0x7c /* | */ ||
      ch === 0x3e /* > */ ||
      ch === 0x27 /* ' */ ||
      ch === 0x22 /* " */ ||
      ch === 0x25 /* % */ ||
      ch === 0x40 /* @ */ ||
      ch === 0x60 /* ` */
    ) {
      return false
    }
    if (ch === 0x3f /* ? */ || ch === 0x2d /* - */) {
      following = state.input.charCodeAt(state.position + 1)
      if (
        is_WS_OR_EOL(following) ||
        (withinFlowCollection && is_FLOW_INDICATOR(following))
      ) {
        return false
      }
    }
    state.kind = 'scalar'
    state.result = ''
    captureStart = captureEnd = state.position
    hasPendingContent = false
    while (ch !== 0) {
      if (ch === 0x3a /* : */) {
        following = state.input.charCodeAt(state.position + 1)
        if (
          is_WS_OR_EOL(following) ||
          (withinFlowCollection && is_FLOW_INDICATOR(following))
        ) {
          break
        }
      } else if (ch === 0x23 /* # */) {
        preceding = state.input.charCodeAt(state.position - 1)
        if (is_WS_OR_EOL(preceding)) {
          break
        }
      } else if (
        (state.position === state.lineStart && testDocumentSeparator(state)) ||
        (withinFlowCollection && is_FLOW_INDICATOR(ch))
      ) {
        break
      } else if (is_EOL(ch)) {
        _line = state.line
        _lineStart = state.lineStart
        _lineIndent = state.lineIndent
        skipSeparationSpace(state, false, -1)
        if (state.lineIndent >= nodeIndent) {
          hasPendingContent = true
          ch = state.input.charCodeAt(state.position)
          continue
        } else {
          state.position = captureEnd
          state.line = _line
          state.lineStart = _lineStart
          state.lineIndent = _lineIndent
          break
        }
      }
      if (hasPendingContent) {
        captureSegment(state, captureStart, captureEnd, false)
        writeFoldedLines(state, state.line - _line)
        captureStart = captureEnd = state.position
        hasPendingContent = false
      }
      if (!is_WHITE_SPACE(ch)) {
        captureEnd = state.position + 1
      }
      ch = state.input.charCodeAt(++state.position)
    }
    captureSegment(state, captureStart, captureEnd, false)
    if (state.result) {
      return true
    }
    state.kind = _kind
    state.result = _result
    return false
  }
  function readSingleQuotedScalar(state, nodeIndent) {
    let ch, captureStart, captureEnd
    ch = state.input.charCodeAt(state.position)
    if (ch !== 0x27 /* ' */) {
      return false
    }
    state.kind = 'scalar'
    state.result = ''
    state.position++
    captureStart = captureEnd = state.position
    while ((ch = state.input.charCodeAt(state.position)) !== 0) {
      if (ch === 0x27 /* ' */) {
        captureSegment(state, captureStart, state.position, true)
        ch = state.input.charCodeAt(++state.position)
        if (ch === 0x27 /* ' */) {
          captureStart = state.position
          state.position++
          captureEnd = state.position
        } else {
          return true
        }
      } else if (is_EOL(ch)) {
        captureSegment(state, captureStart, captureEnd, true)
        writeFoldedLines(state, skipSeparationSpace(state, false, nodeIndent))
        captureStart = captureEnd = state.position
      } else if (
        state.position === state.lineStart &&
        testDocumentSeparator(state)
      ) {
        throwError(
          state,
          'unexpected end of the document within a single quoted scalar'
        )
      } else {
        state.position++
        captureEnd = state.position
      }
    }
    throwError(
      state,
      'unexpected end of the stream within a single quoted scalar'
    )
  }
  function readDoubleQuotedScalar(state, nodeIndent) {
    let captureStart, captureEnd, hexLength, hexResult, tmp, ch
    ch = state.input.charCodeAt(state.position)
    if (ch !== 0x22 /* " */) {
      return false
    }
    state.kind = 'scalar'
    state.result = ''
    state.position++
    captureStart = captureEnd = state.position
    while ((ch = state.input.charCodeAt(state.position)) !== 0) {
      if (ch === 0x22 /* " */) {
        captureSegment(state, captureStart, state.position, true)
        state.position++
        return true
      } else if (ch === 0x5c /* \ */) {
        captureSegment(state, captureStart, state.position, true)
        ch = state.input.charCodeAt(++state.position)
        if (is_EOL(ch)) {
          skipSeparationSpace(state, false, nodeIndent)

          // TODO: rework to inline fn with no type cast?
        } else if (ch < 256 && simpleEscapeCheck[ch]) {
          state.result += simpleEscapeMap[ch]
          state.position++
        } else if ((tmp = escapedHexLen(ch)) > 0) {
          hexLength = tmp
          hexResult = 0
          for (; hexLength > 0; hexLength--) {
            ch = state.input.charCodeAt(++state.position)
            if ((tmp = fromHexCode(ch)) >= 0) {
              hexResult = (hexResult << 4) + tmp
            } else {
              throwError(state, 'expected hexadecimal character')
            }
          }
          state.result += charFromCodepoint(hexResult)
          state.position++
        } else {
          throwError(state, 'unknown escape sequence')
        }
        captureStart = captureEnd = state.position
      } else if (is_EOL(ch)) {
        captureSegment(state, captureStart, captureEnd, true)
        writeFoldedLines(state, skipSeparationSpace(state, false, nodeIndent))
        captureStart = captureEnd = state.position
      } else if (
        state.position === state.lineStart &&
        testDocumentSeparator(state)
      ) {
        throwError(
          state,
          'unexpected end of the document within a double quoted scalar'
        )
      } else {
        state.position++
        captureEnd = state.position
      }
    }
    throwError(
      state,
      'unexpected end of the stream within a double quoted scalar'
    )
  }
  function readFlowCollection(state, nodeIndent) {
    let readNext = true,
      _line,
      _lineStart,
      _pos,
      _tag = state.tag,
      _result,
      _anchor = state.anchor,
      following,
      terminator,
      isPair,
      isExplicitPair,
      isMapping,
      overridableKeys = Object.create(null),
      keyNode,
      keyTag,
      valueNode,
      ch
    ch = state.input.charCodeAt(state.position)
    if (ch === 0x5b /* [ */) {
      terminator = 0x5d /* ] */
      isMapping = false
      _result = []
    } else if (ch === 0x7b /* { */) {
      terminator = 0x7d /* } */
      isMapping = true
      _result = {}
    } else {
      return false
    }
    if (state.anchor !== null) {
      state.anchorMap[state.anchor] = _result
    }
    ch = state.input.charCodeAt(++state.position)
    while (ch !== 0) {
      skipSeparationSpace(state, true, nodeIndent)
      ch = state.input.charCodeAt(state.position)
      if (ch === terminator) {
        state.position++
        state.tag = _tag
        state.anchor = _anchor
        state.kind = isMapping ? 'mapping' : 'sequence'
        state.result = _result
        return true
      } else if (!readNext) {
        throwError(state, 'missed comma between flow collection entries')
      } else if (ch === 0x2c /* , */) {
        // "flow collection entries can never be completely empty", as per YAML 1.2, section 7.4
        throwError(state, "expected the node content, but found ','")
      }
      keyTag = keyNode = valueNode = null
      isPair = isExplicitPair = false
      if (ch === 0x3f /* ? */) {
        following = state.input.charCodeAt(state.position + 1)
        if (is_WS_OR_EOL(following)) {
          isPair = isExplicitPair = true
          state.position++
          skipSeparationSpace(state, true, nodeIndent)
        }
      }
      _line = state.line // Save the current line.
      _lineStart = state.lineStart
      _pos = state.position
      composeNode(state, nodeIndent, CONTEXT_FLOW_IN, false, true)
      keyTag = state.tag
      keyNode = state.result
      skipSeparationSpace(state, true, nodeIndent)
      ch = state.input.charCodeAt(state.position)
      if ((isExplicitPair || state.line === _line) && ch === 0x3a /* : */) {
        isPair = true
        ch = state.input.charCodeAt(++state.position)
        skipSeparationSpace(state, true, nodeIndent)
        composeNode(state, nodeIndent, CONTEXT_FLOW_IN, false, true)
        valueNode = state.result
      }
      if (isMapping) {
        storeMappingPair(
          state,
          _result,
          overridableKeys,
          keyTag,
          keyNode,
          valueNode,
          _line,
          _lineStart,
          _pos
        )
      } else if (isPair) {
        _result.push(
          storeMappingPair(
            state,
            null,
            overridableKeys,
            keyTag,
            keyNode,
            valueNode,
            _line,
            _lineStart,
            _pos
          )
        )
      } else {
        _result.push(keyNode)
      }
      skipSeparationSpace(state, true, nodeIndent)
      ch = state.input.charCodeAt(state.position)
      if (ch === 0x2c /* , */) {
        readNext = true
        ch = state.input.charCodeAt(++state.position)
      } else {
        readNext = false
      }
    }
    throwError(state, 'unexpected end of the stream within a flow collection')
  }
  function readBlockScalar(state, nodeIndent) {
    let captureStart,
      folding,
      chomping = CHOMPING_CLIP,
      didReadContent = false,
      detectedIndent = false,
      textIndent = nodeIndent,
      emptyLines = 0,
      atMoreIndented = false,
      tmp,
      ch
    ch = state.input.charCodeAt(state.position)
    if (ch === 0x7c /* | */) {
      folding = false
    } else if (ch === 0x3e /* > */) {
      folding = true
    } else {
      return false
    }
    state.kind = 'scalar'
    state.result = ''
    while (ch !== 0) {
      ch = state.input.charCodeAt(++state.position)
      if (ch === 0x2b /* + */ || ch === 0x2d /* - */) {
        if (CHOMPING_CLIP === chomping) {
          chomping = ch === 0x2b /* + */ ? CHOMPING_KEEP : CHOMPING_STRIP
        } else {
          throwError(state, 'repeat of a chomping mode identifier')
        }
      } else if ((tmp = fromDecimalCode(ch)) >= 0) {
        if (tmp === 0) {
          throwError(
            state,
            'bad explicit indentation width of a block scalar; it cannot be less than one'
          )
        } else if (!detectedIndent) {
          textIndent = nodeIndent + tmp - 1
          detectedIndent = true
        } else {
          throwError(state, 'repeat of an indentation width identifier')
        }
      } else {
        break
      }
    }
    if (is_WHITE_SPACE(ch)) {
      do {
        ch = state.input.charCodeAt(++state.position)
      } while (is_WHITE_SPACE(ch))
      if (ch === 0x23 /* # */) {
        do {
          ch = state.input.charCodeAt(++state.position)
        } while (!is_EOL(ch) && ch !== 0)
      }
    }
    while (ch !== 0) {
      readLineBreak(state)
      state.lineIndent = 0
      ch = state.input.charCodeAt(state.position)
      while (
        (!detectedIndent || state.lineIndent < textIndent) &&
        ch === 0x20 /* Space */
      ) {
        state.lineIndent++
        ch = state.input.charCodeAt(++state.position)
      }
      if (!detectedIndent && state.lineIndent > textIndent) {
        textIndent = state.lineIndent
      }
      if (is_EOL(ch)) {
        emptyLines++
        continue
      }

      // End of the scalar.
      if (state.lineIndent < textIndent) {
        // Perform the chomping.
        if (chomping === CHOMPING_KEEP) {
          state.result += common.repeat(
            '\n',
            didReadContent ? 1 + emptyLines : emptyLines
          )
        } else if (chomping === CHOMPING_CLIP) {
          if (didReadContent) {
            // i.e. only if the scalar is not empty.
            state.result += '\n'
          }
        }

        // Break this `while` cycle and go to the funciton's epilogue.
        break
      }

      // Folded style: use fancy rules to handle line breaks.
      if (folding) {
        // Lines starting with white space characters (more-indented lines) are not folded.
        if (is_WHITE_SPACE(ch)) {
          atMoreIndented = true
          // except for the first content line (cf. Example 8.1)
          state.result += common.repeat(
            '\n',
            didReadContent ? 1 + emptyLines : emptyLines
          )

          // End of more-indented block.
        } else if (atMoreIndented) {
          atMoreIndented = false
          state.result += common.repeat('\n', emptyLines + 1)

          // Just one line break - perceive as the same line.
        } else if (emptyLines === 0) {
          if (didReadContent) {
            // i.e. only if we have already read some scalar content.
            state.result += ' '
          }

          // Several line breaks - perceive as different lines.
        } else {
          state.result += common.repeat('\n', emptyLines)
        }

        // Literal style: just add exact number of line breaks between content lines.
      } else {
        // Keep all line breaks except the header line break.
        state.result += common.repeat(
          '\n',
          didReadContent ? 1 + emptyLines : emptyLines
        )
      }
      didReadContent = true
      detectedIndent = true
      emptyLines = 0
      captureStart = state.position
      while (!is_EOL(ch) && ch !== 0) {
        ch = state.input.charCodeAt(++state.position)
      }
      captureSegment(state, captureStart, state.position, false)
    }
    return true
  }
  function readBlockSequence(state, nodeIndent) {
    let _line,
      _tag = state.tag,
      _anchor = state.anchor,
      _result = [],
      following,
      detected = false,
      ch

    // there is a leading tab before this token, so it can't be a block sequence/mapping;
    // it can still be flow sequence/mapping or a scalar
    if (state.firstTabInLine !== -1) {
      return false
    }
    if (state.anchor !== null) {
      state.anchorMap[state.anchor] = _result
    }
    ch = state.input.charCodeAt(state.position)
    while (ch !== 0) {
      if (state.firstTabInLine !== -1) {
        state.position = state.firstTabInLine
        throwError(state, 'tab characters must not be used in indentation')
      }
      if (ch !== 0x2d /* - */) {
        break
      }
      following = state.input.charCodeAt(state.position + 1)
      if (!is_WS_OR_EOL(following)) {
        break
      }
      detected = true
      state.position++
      if (skipSeparationSpace(state, true, -1)) {
        if (state.lineIndent <= nodeIndent) {
          _result.push(null)
          ch = state.input.charCodeAt(state.position)
          continue
        }
      }
      _line = state.line
      composeNode(state, nodeIndent, CONTEXT_BLOCK_IN, false, true)
      _result.push(state.result)
      skipSeparationSpace(state, true, -1)
      ch = state.input.charCodeAt(state.position)
      if ((state.line === _line || state.lineIndent > nodeIndent) && ch !== 0) {
        throwError(state, 'bad indentation of a sequence entry')
      } else if (state.lineIndent < nodeIndent) {
        break
      }
    }
    if (detected) {
      state.tag = _tag
      state.anchor = _anchor
      state.kind = 'sequence'
      state.result = _result
      return true
    }
    return false
  }
  function readBlockMapping(state, nodeIndent, flowIndent) {
    let following,
      allowCompact,
      _line,
      _keyLine,
      _keyLineStart,
      _keyPos,
      _tag = state.tag,
      _anchor = state.anchor,
      _result = {},
      overridableKeys = Object.create(null),
      keyTag = null,
      keyNode = null,
      valueNode = null,
      atExplicitKey = false,
      detected = false,
      ch

    // there is a leading tab before this token, so it can't be a block sequence/mapping;
    // it can still be flow sequence/mapping or a scalar
    if (state.firstTabInLine !== -1) {
      return false
    }
    if (state.anchor !== null) {
      state.anchorMap[state.anchor] = _result
    }
    ch = state.input.charCodeAt(state.position)
    while (ch !== 0) {
      if (!atExplicitKey && state.firstTabInLine !== -1) {
        state.position = state.firstTabInLine
        throwError(state, 'tab characters must not be used in indentation')
      }
      following = state.input.charCodeAt(state.position + 1)
      _line = state.line // Save the current line.

      //
      // Explicit notation case. There are two separate blocks:
      // first for the key (denoted by "?") and second for the value (denoted by ":")
      //
      if (
        (ch === 0x3f /* ? */ || ch === 0x3a) /* : */ &&
        is_WS_OR_EOL(following)
      ) {
        if (ch === 0x3f /* ? */) {
          if (atExplicitKey) {
            storeMappingPair(
              state,
              _result,
              overridableKeys,
              keyTag,
              keyNode,
              null,
              _keyLine,
              _keyLineStart,
              _keyPos
            )
            keyTag = keyNode = valueNode = null
          }
          detected = true
          atExplicitKey = true
          allowCompact = true
        } else if (atExplicitKey) {
          // i.e. 0x3A/* : */ === character after the explicit key.
          atExplicitKey = false
          allowCompact = true
        } else {
          throwError(
            state,
            'incomplete explicit mapping pair; a key node is missed; or followed by a non-tabulated empty line'
          )
        }
        state.position += 1
        ch = following

        //
        // Implicit notation case. Flow-style node as the key first, then ":", and the value.
        //
      } else {
        _keyLine = state.line
        _keyLineStart = state.lineStart
        _keyPos = state.position
        if (!composeNode(state, flowIndent, CONTEXT_FLOW_OUT, false, true)) {
          // Neither implicit nor explicit notation.
          // Reading is done. Go to the epilogue.
          break
        }
        if (state.line === _line) {
          ch = state.input.charCodeAt(state.position)
          while (is_WHITE_SPACE(ch)) {
            ch = state.input.charCodeAt(++state.position)
          }
          if (ch === 0x3a /* : */) {
            ch = state.input.charCodeAt(++state.position)
            if (!is_WS_OR_EOL(ch)) {
              throwError(
                state,
                'a whitespace character is expected after the key-value separator within a block mapping'
              )
            }
            if (atExplicitKey) {
              storeMappingPair(
                state,
                _result,
                overridableKeys,
                keyTag,
                keyNode,
                null,
                _keyLine,
                _keyLineStart,
                _keyPos
              )
              keyTag = keyNode = valueNode = null
            }
            detected = true
            atExplicitKey = false
            allowCompact = false
            keyTag = state.tag
            keyNode = state.result
          } else if (detected) {
            throwError(
              state,
              'can not read an implicit mapping pair; a colon is missed'
            )
          } else {
            state.tag = _tag
            state.anchor = _anchor
            return true // Keep the result of `composeNode`.
          }
        } else if (detected) {
          throwError(
            state,
            'can not read a block mapping entry; a multiline key may not be an implicit key'
          )
        } else {
          state.tag = _tag
          state.anchor = _anchor
          return true // Keep the result of `composeNode`.
        }
      }

      //
      // Common reading code for both explicit and implicit notations.
      //
      if (state.line === _line || state.lineIndent > nodeIndent) {
        if (atExplicitKey) {
          _keyLine = state.line
          _keyLineStart = state.lineStart
          _keyPos = state.position
        }
        if (
          composeNode(state, nodeIndent, CONTEXT_BLOCK_OUT, true, allowCompact)
        ) {
          if (atExplicitKey) {
            keyNode = state.result
          } else {
            valueNode = state.result
          }
        }
        if (!atExplicitKey) {
          storeMappingPair(
            state,
            _result,
            overridableKeys,
            keyTag,
            keyNode,
            valueNode,
            _keyLine,
            _keyLineStart,
            _keyPos
          )
          keyTag = keyNode = valueNode = null
        }
        skipSeparationSpace(state, true, -1)
        ch = state.input.charCodeAt(state.position)
      }
      if ((state.line === _line || state.lineIndent > nodeIndent) && ch !== 0) {
        throwError(state, 'bad indentation of a mapping entry')
      } else if (state.lineIndent < nodeIndent) {
        break
      }
    }

    //
    // Epilogue.
    //

    // Special case: last mapping's node contains only the key in explicit notation.
    if (atExplicitKey) {
      storeMappingPair(
        state,
        _result,
        overridableKeys,
        keyTag,
        keyNode,
        null,
        _keyLine,
        _keyLineStart,
        _keyPos
      )
    }

    // Expose the resulting mapping.
    if (detected) {
      state.tag = _tag
      state.anchor = _anchor
      state.kind = 'mapping'
      state.result = _result
    }
    return detected
  }
  function readTagProperty(state) {
    let _position,
      isVerbatim = false,
      isNamed = false,
      tagHandle,
      tagName,
      ch
    ch = state.input.charCodeAt(state.position)
    if (ch !== 0x21 /* ! */) {
      return false
    }
    if (state.tag !== null) {
      throwError(state, 'duplication of a tag property')
    }
    ch = state.input.charCodeAt(++state.position)
    if (ch === 0x3c /* < */) {
      isVerbatim = true
      ch = state.input.charCodeAt(++state.position)
    } else if (ch === 0x21 /* ! */) {
      isNamed = true
      tagHandle = '!!'
      ch = state.input.charCodeAt(++state.position)
    } else {
      tagHandle = '!'
    }
    _position = state.position
    if (isVerbatim) {
      do {
        ch = state.input.charCodeAt(++state.position)
      } while (ch !== 0 && ch !== 0x3e /* > */)
      if (state.position < state.length) {
        tagName = state.input.slice(_position, state.position)
        ch = state.input.charCodeAt(++state.position)
      } else {
        throwError(state, 'unexpected end of the stream within a verbatim tag')
      }
    } else {
      while (ch !== 0 && !is_WS_OR_EOL(ch)) {
        if (ch === 0x21 /* ! */) {
          if (!isNamed) {
            tagHandle = state.input.slice(_position - 1, state.position + 1)
            if (!PATTERN_TAG_HANDLE.test(tagHandle)) {
              throwError(
                state,
                'named tag handle cannot contain such characters'
              )
            }
            isNamed = true
            _position = state.position + 1
          } else {
            throwError(state, 'tag suffix cannot contain exclamation marks')
          }
        }
        ch = state.input.charCodeAt(++state.position)
      }
      tagName = state.input.slice(_position, state.position)
      if (PATTERN_FLOW_INDICATORS.test(tagName)) {
        throwError(state, 'tag suffix cannot contain flow indicator characters')
      }
    }
    if (tagName && !PATTERN_TAG_URI.test(tagName)) {
      throwError(state, 'tag name cannot contain such characters: ' + tagName)
    }
    try {
      tagName = decodeURIComponent(tagName)
    } catch (err) {
      throwError(state, 'tag name is malformed: ' + tagName)
    }
    if (isVerbatim) {
      state.tag = tagName
    } else if (_hasOwnProperty.call(state.tagMap, tagHandle)) {
      state.tag = state.tagMap[tagHandle] + tagName
    } else if (tagHandle === '!') {
      state.tag = '!' + tagName
    } else if (tagHandle === '!!') {
      state.tag = 'tag:yaml.org,2002:' + tagName
    } else {
      throwError(state, 'undeclared tag handle "' + tagHandle + '"')
    }
    return true
  }
  function readAnchorProperty(state) {
    let _position, ch
    ch = state.input.charCodeAt(state.position)
    if (ch !== 0x26 /* & */) {
      return false
    }
    if (state.anchor !== null) {
      throwError(state, 'duplication of an anchor property')
    }
    ch = state.input.charCodeAt(++state.position)
    _position = state.position
    while (ch !== 0 && !is_WS_OR_EOL(ch) && !is_FLOW_INDICATOR(ch)) {
      ch = state.input.charCodeAt(++state.position)
    }
    if (state.position === _position) {
      throwError(
        state,
        'name of an anchor node must contain at least one character'
      )
    }
    state.anchor = state.input.slice(_position, state.position)
    return true
  }
  function readAlias(state) {
    let _position, alias, ch
    ch = state.input.charCodeAt(state.position)
    if (ch !== 0x2a /* * */) {
      return false
    }
    ch = state.input.charCodeAt(++state.position)
    _position = state.position
    while (ch !== 0 && !is_WS_OR_EOL(ch) && !is_FLOW_INDICATOR(ch)) {
      ch = state.input.charCodeAt(++state.position)
    }
    if (state.position === _position) {
      throwError(
        state,
        'name of an alias node must contain at least one character'
      )
    }
    alias = state.input.slice(_position, state.position)
    if (!_hasOwnProperty.call(state.anchorMap, alias)) {
      throwError(state, 'unidentified alias "' + alias + '"')
    }
    state.result = state.anchorMap[alias]
    skipSeparationSpace(state, true, -1)
    return true
  }
  function composeNode(
    state,
    parentIndent,
    nodeContext,
    allowToSeek,
    allowCompact
  ) {
    let allowBlockStyles,
      allowBlockScalars,
      allowBlockCollections,
      indentStatus = 1,
      // 1: this>parent, 0: this=parent, -1: this<parent
      atNewLine = false,
      hasContent = false,
      typeIndex,
      typeQuantity,
      typeList,
      type,
      flowIndent,
      blockIndent
    if (state.listener !== null) {
      state.listener('open', state)
    }
    state.tag = null
    state.anchor = null
    state.kind = null
    state.result = null
    allowBlockStyles =
      allowBlockScalars =
      allowBlockCollections =
        CONTEXT_BLOCK_OUT === nodeContext || CONTEXT_BLOCK_IN === nodeContext
    if (allowToSeek) {
      if (skipSeparationSpace(state, true, -1)) {
        atNewLine = true
        if (state.lineIndent > parentIndent) {
          indentStatus = 1
        } else if (state.lineIndent === parentIndent) {
          indentStatus = 0
        } else if (state.lineIndent < parentIndent) {
          indentStatus = -1
        }
      }
    }
    if (indentStatus === 1) {
      while (readTagProperty(state) || readAnchorProperty(state)) {
        if (skipSeparationSpace(state, true, -1)) {
          atNewLine = true
          allowBlockCollections = allowBlockStyles
          if (state.lineIndent > parentIndent) {
            indentStatus = 1
          } else if (state.lineIndent === parentIndent) {
            indentStatus = 0
          } else if (state.lineIndent < parentIndent) {
            indentStatus = -1
          }
        } else {
          allowBlockCollections = false
        }
      }
    }
    if (allowBlockCollections) {
      allowBlockCollections = atNewLine || allowCompact
    }
    if (indentStatus === 1 || CONTEXT_BLOCK_OUT === nodeContext) {
      if (CONTEXT_FLOW_IN === nodeContext || CONTEXT_FLOW_OUT === nodeContext) {
        flowIndent = parentIndent
      } else {
        flowIndent = parentIndent + 1
      }
      blockIndent = state.position - state.lineStart
      if (indentStatus === 1) {
        if (
          (allowBlockCollections &&
            (readBlockSequence(state, blockIndent) ||
              readBlockMapping(state, blockIndent, flowIndent))) ||
          readFlowCollection(state, flowIndent)
        ) {
          hasContent = true
        } else {
          if (
            (allowBlockScalars && readBlockScalar(state, flowIndent)) ||
            readSingleQuotedScalar(state, flowIndent) ||
            readDoubleQuotedScalar(state, flowIndent)
          ) {
            hasContent = true
          } else if (readAlias(state)) {
            hasContent = true
            if (state.tag !== null || state.anchor !== null) {
              throwError(state, 'alias node should not have any properties')
            }
          } else if (
            readPlainScalar(state, flowIndent, CONTEXT_FLOW_IN === nodeContext)
          ) {
            hasContent = true
            if (state.tag === null) {
              state.tag = '?'
            }
          }
          if (state.anchor !== null) {
            state.anchorMap[state.anchor] = state.result
          }
        }
      } else if (indentStatus === 0) {
        // Special case: block sequences are allowed to have same indentation level as the parent.
        // http://www.yaml.org/spec/1.2/spec.html#id2799784
        hasContent =
          allowBlockCollections && readBlockSequence(state, blockIndent)
      }
    }
    if (state.tag === null) {
      if (state.anchor !== null) {
        state.anchorMap[state.anchor] = state.result
      }
    } else if (state.tag === '?') {
      // Implicit resolving is not allowed for non-scalar types, and '?'
      // non-specific tag is only automatically assigned to plain scalars.
      //
      // We only need to check kind conformity in case user explicitly assigns '?'
      // tag, for example like this: "!<?> [0]"
      //
      if (state.result !== null && state.kind !== 'scalar') {
        throwError(
          state,
          'unacceptable node kind for !<?> tag; it should be "scalar", not "' +
            state.kind +
            '"'
        )
      }
      for (
        typeIndex = 0, typeQuantity = state.implicitTypes.length;
        typeIndex < typeQuantity;
        typeIndex += 1
      ) {
        type = state.implicitTypes[typeIndex]
        if (type.resolve(state.result)) {
          // `state.result` updated in resolver if matched
          state.result = type.construct(state.result)
          state.tag = type.tag
          if (state.anchor !== null) {
            state.anchorMap[state.anchor] = state.result
          }
          break
        }
      }
    } else if (state.tag !== '!') {
      if (
        _hasOwnProperty.call(state.typeMap[state.kind || 'fallback'], state.tag)
      ) {
        type = state.typeMap[state.kind || 'fallback'][state.tag]
      } else {
        // looking for multi type
        type = null
        typeList = state.typeMap.multi[state.kind || 'fallback']
        for (
          typeIndex = 0, typeQuantity = typeList.length;
          typeIndex < typeQuantity;
          typeIndex += 1
        ) {
          if (
            state.tag.slice(0, typeList[typeIndex].tag.length) ===
            typeList[typeIndex].tag
          ) {
            type = typeList[typeIndex]
            break
          }
        }
      }
      if (!type) {
        throwError(state, 'unknown tag !<' + state.tag + '>')
      }
      if (state.result !== null && type.kind !== state.kind) {
        throwError(
          state,
          'unacceptable node kind for !<' +
            state.tag +
            '> tag; it should be "' +
            type.kind +
            '", not "' +
            state.kind +
            '"'
        )
      }
      if (!type.resolve(state.result, state.tag)) {
        // `state.result` updated in resolver if matched
        throwError(
          state,
          'cannot resolve a node with !<' + state.tag + '> explicit tag'
        )
      } else {
        state.result = type.construct(state.result, state.tag)
        if (state.anchor !== null) {
          state.anchorMap[state.anchor] = state.result
        }
      }
    }
    if (state.listener !== null) {
      state.listener('close', state)
    }
    return state.tag !== null || state.anchor !== null || hasContent
  }
  function readDocument(state) {
    let documentStart = state.position,
      _position,
      directiveName,
      directiveArgs,
      hasDirectives = false,
      ch
    state.version = null
    state.checkLineBreaks = state.legacy
    state.tagMap = Object.create(null)
    state.anchorMap = Object.create(null)
    while ((ch = state.input.charCodeAt(state.position)) !== 0) {
      skipSeparationSpace(state, true, -1)
      ch = state.input.charCodeAt(state.position)
      if (state.lineIndent > 0 || ch !== 0x25 /* % */) {
        break
      }
      hasDirectives = true
      ch = state.input.charCodeAt(++state.position)
      _position = state.position
      while (ch !== 0 && !is_WS_OR_EOL(ch)) {
        ch = state.input.charCodeAt(++state.position)
      }
      directiveName = state.input.slice(_position, state.position)
      directiveArgs = []
      if (directiveName.length < 1) {
        throwError(
          state,
          'directive name must not be less than one character in length'
        )
      }
      while (ch !== 0) {
        while (is_WHITE_SPACE(ch)) {
          ch = state.input.charCodeAt(++state.position)
        }
        if (ch === 0x23 /* # */) {
          do {
            ch = state.input.charCodeAt(++state.position)
          } while (ch !== 0 && !is_EOL(ch))
          break
        }
        if (is_EOL(ch)) {
          break
        }
        _position = state.position
        while (ch !== 0 && !is_WS_OR_EOL(ch)) {
          ch = state.input.charCodeAt(++state.position)
        }
        directiveArgs.push(state.input.slice(_position, state.position))
      }
      if (ch !== 0) {
        readLineBreak(state)
      }
      if (_hasOwnProperty.call(directiveHandlers, directiveName)) {
        directiveHandlers[directiveName](state, directiveName, directiveArgs)
      } else {
        throwWarning(
          state,
          'unknown document directive "' + directiveName + '"'
        )
      }
    }
    skipSeparationSpace(state, true, -1)
    if (
      state.lineIndent === 0 &&
      state.input.charCodeAt(state.position) === 0x2d /* - */ &&
      state.input.charCodeAt(state.position + 1) === 0x2d /* - */ &&
      state.input.charCodeAt(state.position + 2) === 0x2d /* - */
    ) {
      state.position += 3
      skipSeparationSpace(state, true, -1)
    } else if (hasDirectives) {
      throwError(state, 'directives end mark is expected')
    }
    composeNode(state, state.lineIndent - 1, CONTEXT_BLOCK_OUT, false, true)
    skipSeparationSpace(state, true, -1)
    if (
      state.checkLineBreaks &&
      PATTERN_NON_ASCII_LINE_BREAKS.test(
        state.input.slice(documentStart, state.position)
      )
    ) {
      throwWarning(state, 'non-ASCII line breaks are interpreted as content')
    }
    state.documents.push(state.result)
    if (state.position === state.lineStart && testDocumentSeparator(state)) {
      if (state.input.charCodeAt(state.position) === 0x2e /* . */) {
        state.position += 3
        skipSeparationSpace(state, true, -1)
      }
      return
    }
    if (state.position < state.length - 1) {
      throwError(state, 'end of the stream or a document separator is expected')
    } else {
      return
    }
  }
  function loadDocuments(input, options) {
    input = String(input)
    options = options || {}
    if (input.length !== 0) {
      // Add tailing `\n` if not exists
      if (
        input.charCodeAt(input.length - 1) !== 0x0a /* LF */ &&
        input.charCodeAt(input.length - 1) !== 0x0d /* CR */
      ) {
        input += '\n'
      }

      // Strip BOM
      if (input.charCodeAt(0) === 0xfeff) {
        input = input.slice(1)
      }
    }
    const state = new State(input, options)
    const nullpos = input.indexOf('\0')
    if (nullpos !== -1) {
      state.position = nullpos
      throwError(state, 'null byte is not allowed in input')
    }

    // Use 0 as string terminator. That significantly simplifies bounds check.
    state.input += '\0'
    while (state.input.charCodeAt(state.position) === 0x20 /* Space */) {
      state.lineIndent += 1
      state.position += 1
    }
    while (state.position < state.length - 1) {
      readDocument(state)
    }
    return state.documents
  }
  function loadAll(input, iterator, options) {
    if (
      iterator !== null &&
      typeof iterator === 'object' &&
      typeof options === 'undefined'
    ) {
      options = iterator
      iterator = null
    }
    const documents = loadDocuments(input, options)
    if (typeof iterator !== 'function') {
      return documents
    }
    for (let index = 0, length = documents.length; index < length; index += 1) {
      iterator(documents[index])
    }
  }
  function load(input, options) {
    const documents = loadDocuments(input, options)
    if (documents.length === 0) {
      /*eslint-disable no-undefined*/
      return undefined
    } else if (documents.length === 1) {
      return documents[0]
    }
    throw new YAMLException(
      'expected a single document in the stream, but found more'
    )
  }
  loader.loadAll = loadAll
  loader.load = load
  return loader
}

const dumper = {}

let hasRequiredDumper
function requireDumper() {
  if (hasRequiredDumper) {
    return dumper
  }
  hasRequiredDumper = 1

  /*eslint-disable no-use-before-define*/

  const common = requireCommon()
  const YAMLException = requireException()
  const DEFAULT_SCHEMA = require_default()
  const _toString = Object.prototype.toString
  const _hasOwnProperty = Object.prototype.hasOwnProperty
  const CHAR_BOM = 0xfeff
  const CHAR_TAB = 0x09 /* Tab */
  const CHAR_LINE_FEED = 0x0a /* LF */
  const CHAR_CARRIAGE_RETURN = 0x0d /* CR */
  const CHAR_SPACE = 0x20 /* Space */
  const CHAR_EXCLAMATION = 0x21 /* ! */
  const CHAR_DOUBLE_QUOTE = 0x22 /* " */
  const CHAR_SHARP = 0x23 /* # */
  const CHAR_PERCENT = 0x25 /* % */
  const CHAR_AMPERSAND = 0x26 /* & */
  const CHAR_SINGLE_QUOTE = 0x27 /* ' */
  const CHAR_ASTERISK = 0x2a /* * */
  const CHAR_COMMA = 0x2c /* , */
  const CHAR_MINUS = 0x2d /* - */
  const CHAR_COLON = 0x3a /* : */
  const CHAR_EQUALS = 0x3d /* = */
  const CHAR_GREATER_THAN = 0x3e /* > */
  const CHAR_QUESTION = 0x3f /* ? */
  const CHAR_COMMERCIAL_AT = 0x40 /* @ */
  const CHAR_LEFT_SQUARE_BRACKET = 0x5b /* [ */
  const CHAR_RIGHT_SQUARE_BRACKET = 0x5d /* ] */
  const CHAR_GRAVE_ACCENT = 0x60 /* ` */
  const CHAR_LEFT_CURLY_BRACKET = 0x7b /* { */
  const CHAR_VERTICAL_LINE = 0x7c /* | */
  const CHAR_RIGHT_CURLY_BRACKET = 0x7d /* } */

  const ESCAPE_SEQUENCES = {}
  ESCAPE_SEQUENCES[0x00] = '\\0'
  ESCAPE_SEQUENCES[0x07] = '\\a'
  ESCAPE_SEQUENCES[0x08] = '\\b'
  ESCAPE_SEQUENCES[0x09] = '\\t'
  ESCAPE_SEQUENCES[0x0a] = '\\n'
  ESCAPE_SEQUENCES[0x0b] = '\\v'
  ESCAPE_SEQUENCES[0x0c] = '\\f'
  ESCAPE_SEQUENCES[0x0d] = '\\r'
  ESCAPE_SEQUENCES[0x1b] = '\\e'
  ESCAPE_SEQUENCES[0x22] = '\\"'
  ESCAPE_SEQUENCES[0x5c] = '\\\\'
  ESCAPE_SEQUENCES[0x85] = '\\N'
  ESCAPE_SEQUENCES[0xa0] = '\\_'
  ESCAPE_SEQUENCES[0x2028] = '\\L'
  ESCAPE_SEQUENCES[0x2029] = '\\P'
  const DEPRECATED_BOOLEANS_SYNTAX = [
    'y',
    'Y',
    'yes',
    'Yes',
    'YES',
    'on',
    'On',
    'ON',
    'n',
    'N',
    'no',
    'No',
    'NO',
    'off',
    'Off',
    'OFF'
  ]
  const DEPRECATED_BASE60_SYNTAX = /^[-+]?[0-9_]+(?::[0-9_]+)+(?:\.[0-9_]*)?$/
  const SINGLE_LINE_KEYS = {
    cpu: true,
    engines: true,
    os: true,
    resolution: true,
    libc: true
  }
  function compileStyleMap(schema, map) {
    let result, keys, index, length, tag, style, type
    if (map === null) {
      return {}
    }
    result = {}
    keys = Object.keys(map)
    for (index = 0, length = keys.length; index < length; index += 1) {
      tag = keys[index]
      style = String(map[tag])
      if (tag.slice(0, 2) === '!!') {
        tag = 'tag:yaml.org,2002:' + tag.slice(2)
      }
      type = schema.compiledTypeMap['fallback'][tag]
      if (type && _hasOwnProperty.call(type.styleAliases, style)) {
        style = type.styleAliases[style]
      }
      result[tag] = style
    }
    return result
  }
  function encodeHex(character) {
    let string, handle, length
    string = character.toString(16).toUpperCase()
    if (character <= 0xff) {
      handle = 'x'
      length = 2
    } else if (character <= 0xffff) {
      handle = 'u'
      length = 4
    } else if (character <= 0xffffffff) {
      handle = 'U'
      length = 8
    } else {
      throw new YAMLException(
        'code point within a string may not be greater than 0xFFFFFFFF'
      )
    }
    return '\\' + handle + common.repeat('0', length - string.length) + string
  }
  const QUOTING_TYPE_SINGLE = 1,
    QUOTING_TYPE_DOUBLE = 2
  function State(options) {
    this.blankLines = options['blankLines'] || false
    this.schema = options['schema'] || DEFAULT_SCHEMA
    this.indent = Math.max(1, options['indent'] || 2)
    this.noArrayIndent = options['noArrayIndent'] || false
    this.skipInvalid = options['skipInvalid'] || false
    this.flowLevel = common.isNothing(options['flowLevel'])
      ? -1
      : options['flowLevel']
    this.styleMap = compileStyleMap(this.schema, options['styles'] || null)
    this.sortKeys = options['sortKeys'] || false
    this.lineWidth = options['lineWidth'] || 80
    this.noRefs = options['noRefs'] || false
    this.noCompatMode = options['noCompatMode'] || false
    this.condenseFlow = options['condenseFlow'] || false
    this.quotingType =
      options['quotingType'] === '"' ? QUOTING_TYPE_DOUBLE : QUOTING_TYPE_SINGLE
    this.forceQuotes = options['forceQuotes'] || false
    this.replacer =
      typeof options['replacer'] === 'function' ? options['replacer'] : null
    this.implicitTypes = this.schema.compiledImplicit
    this.explicitTypes = this.schema.compiledExplicit
    this.tag = null
    this.result = ''
    this.duplicates = []
    this.usedDuplicates = null
  }

  // Indents every line in a string. Empty lines (\n only) are not indented.
  function indentString(string, spaces) {
    let ind = common.repeat(' ', spaces),
      position = 0,
      next = -1,
      result = '',
      line,
      length = string.length
    while (position < length) {
      next = string.indexOf('\n', position)
      if (next === -1) {
        line = string.slice(position)
        position = length
      } else {
        line = string.slice(position, next + 1)
        position = next + 1
      }
      if (line.length && line !== '\n') {
        result += ind
      }
      result += line
    }
    return result
  }
  function generateNextLine(state, level, doubleLine) {
    return (
      '\n' + (doubleLine ? '\n' : '') + common.repeat(' ', state.indent * level)
    )
  }
  function testImplicitResolving(state, str) {
    let index, length, type
    for (
      index = 0, length = state.implicitTypes.length;
      index < length;
      index += 1
    ) {
      type = state.implicitTypes[index]
      if (type.resolve(str)) {
        return true
      }
    }
    return false
  }

  // [33] s-white ::= s-space | s-tab
  function isWhitespace(c) {
    return c === CHAR_SPACE || c === CHAR_TAB
  }

  // Returns true if the character can be printed without escaping.
  // From YAML 1.2: "any allowed characters known to be non-printable
  // should also be escaped. [However,] This isn’t mandatory"
  // Derived from nb-char - \t - #x85 - #xA0 - #x2028 - #x2029.
  function isPrintable(c) {
    return (
      (0x00020 <= c && c <= 0x00007e) ||
      (0x000a1 <= c && c <= 0x00d7ff && c !== 0x2028 && c !== 0x2029) ||
      (0x0e000 <= c && c <= 0x00fffd && c !== CHAR_BOM) ||
      (0x10000 <= c && c <= 0x10ffff)
    )
  }

  // [34] ns-char ::= nb-char - s-white
  // [27] nb-char ::= c-printable - b-char - c-byte-order-mark
  // [26] b-char  ::= b-line-feed | b-carriage-return
  // Including s-white (for some reason, examples doesn't match specs in this aspect)
  // ns-char ::= c-printable - b-line-feed - b-carriage-return - c-byte-order-mark
  function isNsCharOrWhitespace(c) {
    return (
      isPrintable(c) &&
      c !== CHAR_BOM &&
      // - b-char
      c !== CHAR_CARRIAGE_RETURN &&
      c !== CHAR_LINE_FEED
    )
  }

  // [127]  ns-plain-safe(c) ::= c = flow-out  ⇒ ns-plain-safe-out
  //                             c = flow-in   ⇒ ns-plain-safe-in
  //                             c = block-key ⇒ ns-plain-safe-out
  //                             c = flow-key  ⇒ ns-plain-safe-in
  // [128] ns-plain-safe-out ::= ns-char
  // [129]  ns-plain-safe-in ::= ns-char - c-flow-indicator
  // [130]  ns-plain-char(c) ::=  ( ns-plain-safe(c) - “:” - “#” )
  //                            | ( /* An ns-char preceding */ “#” )
  //                            | ( “:” /* Followed by an ns-plain-safe(c) */ )
  function isPlainSafe(c, prev, inblock) {
    const cIsNsCharOrWhitespace = isNsCharOrWhitespace(c)
    const cIsNsChar = cIsNsCharOrWhitespace && !isWhitespace(c)
    return (
      // ns-plain-safe
      ((inblock
        ? // c = flow-in
          cIsNsCharOrWhitespace
        : cIsNsCharOrWhitespace &&
          // - c-flow-indicator
          c !== CHAR_COMMA &&
          c !== CHAR_LEFT_SQUARE_BRACKET &&
          c !== CHAR_RIGHT_SQUARE_BRACKET &&
          c !== CHAR_LEFT_CURLY_BRACKET &&
          c !== CHAR_RIGHT_CURLY_BRACKET) &&

      // ns-plain-char
        c !== CHAR_SHARP && // false on '#'
        !(prev === CHAR_COLON && !cIsNsChar)) || // false on ': '
      (isNsCharOrWhitespace(prev) && !isWhitespace(prev) && c === CHAR_SHARP) || // change to true on '[^ ]#'
      (prev === CHAR_COLON && cIsNsChar)
    ) // change to true on ':[^ ]'
  }

  // Simplified test for values allowed as the first character in plain style.
  function isPlainSafeFirst(c) {
    // Uses a subset of ns-char - c-indicator
    // where ns-char = nb-char - s-white.
    // No support of ( ( “?” | “:” | “-” ) /* Followed by an ns-plain-safe(c)) */ ) part
    return (
      isPrintable(c) &&
      c !== CHAR_BOM &&
      !isWhitespace(c) && // - s-white
      // - (c-indicator ::=
      // “-” | “?” | “:” | “,” | “[” | “]” | “{” | “}”
      c !== CHAR_MINUS &&
      c !== CHAR_QUESTION &&
      c !== CHAR_COLON &&
      c !== CHAR_COMMA &&
      c !== CHAR_LEFT_SQUARE_BRACKET &&
      c !== CHAR_RIGHT_SQUARE_BRACKET &&
      c !== CHAR_LEFT_CURLY_BRACKET &&
      c !== CHAR_RIGHT_CURLY_BRACKET &&
      // | “#” | “&” | “*” | “!” | “|” | “=” | “>” | “'” | “"”
      c !== CHAR_SHARP &&
      c !== CHAR_AMPERSAND &&
      c !== CHAR_ASTERISK &&
      c !== CHAR_EXCLAMATION &&
      c !== CHAR_VERTICAL_LINE &&
      c !== CHAR_EQUALS &&
      c !== CHAR_GREATER_THAN &&
      c !== CHAR_SINGLE_QUOTE &&
      c !== CHAR_DOUBLE_QUOTE &&
      // | “%” | “@” | “`”)
      c !== CHAR_PERCENT &&
      c !== CHAR_COMMERCIAL_AT &&
      c !== CHAR_GRAVE_ACCENT
    )
  }

  // Simplified test for values allowed as the last character in plain style.
  function isPlainSafeLast(c) {
    // just not whitespace or colon, it will be checked to be plain character later
    return !isWhitespace(c) && c !== CHAR_COLON
  }

  // Same as 'string'.codePointAt(pos), but works in older browsers.
  function codePointAt(string, pos) {
    let first = string.charCodeAt(pos),
      second
    if (first >= 0xd800 && first <= 0xdbff && pos + 1 < string.length) {
      second = string.charCodeAt(pos + 1)
      if (second >= 0xdc00 && second <= 0xdfff) {
        // https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae
        return (first - 0xd800) * 0x400 + second - 0xdc00 + 0x10000
      }
    }
    return first
  }

  // Determines whether block indentation indicator is required.
  function needIndentIndicator(string) {
    const leadingSpaceRe = /^\n* /
    return leadingSpaceRe.test(string)
  }
  const STYLE_PLAIN = 1,
    STYLE_SINGLE = 2,
    STYLE_LITERAL = 3,
    STYLE_FOLDED = 4,
    STYLE_DOUBLE = 5

  // Determines which scalar styles are possible and returns the preferred style.
  // lineWidth = -1 => no limit.
  // Pre-conditions: str.length > 0.
  // Post-conditions:
  //    STYLE_PLAIN or STYLE_SINGLE => no \n are in the string.
  //    STYLE_LITERAL => no lines are suitable for folding (or lineWidth is -1).
  //    STYLE_FOLDED => a line > lineWidth and can be folded (and lineWidth != -1).
  function chooseScalarStyle(
    string,
    singleLineOnly,
    indentPerLevel,
    lineWidth,
    testAmbiguousType,
    quotingType,
    forceQuotes,
    inblock
  ) {
    let i
    let char = 0
    let prevChar = null
    let hasLineBreak = false
    let hasFoldableLine = false // only checked if shouldTrackWidth
    const shouldTrackWidth = lineWidth !== -1
    let previousLineBreak = -1 // count the first line correctly
    let plain =
      isPlainSafeFirst(codePointAt(string, 0)) &&
      isPlainSafeLast(codePointAt(string, string.length - 1))
    if (singleLineOnly || forceQuotes) {
      // Case: no block styles.
      // Check for disallowed characters to rule out plain and single.
      for (i = 0; i < string.length; char >= 0x10000 ? (i += 2) : i++) {
        char = codePointAt(string, i)
        if (!isPrintable(char)) {
          return STYLE_DOUBLE
        }
        plain = plain && isPlainSafe(char, prevChar, inblock)
        prevChar = char
      }
    } else {
      // Case: block styles permitted.
      for (i = 0; i < string.length; char >= 0x10000 ? (i += 2) : i++) {
        char = codePointAt(string, i)
        if (char === CHAR_LINE_FEED) {
          hasLineBreak = true
          // Check if any line can be folded.
          if (shouldTrackWidth) {
            hasFoldableLine =
              hasFoldableLine ||
              // Foldable line = too long, and not more-indented.
              (i - previousLineBreak - 1 > lineWidth &&
                string[previousLineBreak + 1] !== ' ')
            previousLineBreak = i
          }
        } else if (!isPrintable(char)) {
          return STYLE_DOUBLE
        }
        plain = plain && isPlainSafe(char, prevChar, inblock)
        prevChar = char
      }
      // in case the end is missing a \n
      hasFoldableLine =
        hasFoldableLine ||
        (shouldTrackWidth &&
          i - previousLineBreak - 1 > lineWidth &&
          string[previousLineBreak + 1] !== ' ')
    }
    // Although every style can represent \n without escaping, prefer block styles
    // for multiline, since they're more readable and they don't add empty lines.
    // Also prefer folding a super-long line.
    if (!hasLineBreak && !hasFoldableLine) {
      // Strings interpretable as another type have to be quoted;
      // e.g. the string 'true' vs. the boolean true.
      if (plain && !forceQuotes && !testAmbiguousType(string)) {
        return STYLE_PLAIN
      }
      return quotingType === QUOTING_TYPE_DOUBLE ? STYLE_DOUBLE : STYLE_SINGLE
    }
    // Edge case: block indentation indicator can only have one digit.
    if (indentPerLevel > 9 && needIndentIndicator(string)) {
      return STYLE_DOUBLE
    }
    // At this point we know block styles are valid.
    // Prefer literal style unless we want to fold.
    if (!forceQuotes) {
      return hasFoldableLine ? STYLE_FOLDED : STYLE_LITERAL
    }
    return quotingType === QUOTING_TYPE_DOUBLE ? STYLE_DOUBLE : STYLE_SINGLE
  }

  // Note: line breaking/folding is implemented for only the folded style.
  // NB. We drop the last trailing newline (if any) of a returned block scalar
  //  since the dumper adds its own newline. This always works:
  //    • No ending newline => unaffected; already using strip "-" chomping.
  //    • Ending newline    => removed then restored.
  //  Importantly, this keeps the "+" chomp indicator from gaining an extra line.
  function writeScalar(state, string, level, iskey, inblock, singleLO) {
    state.dump = (function () {
      if (string.length === 0) {
        return state.quotingType === QUOTING_TYPE_DOUBLE ? '""' : "''"
      }
      if (!state.noCompatMode) {
        if (
          DEPRECATED_BOOLEANS_SYNTAX.indexOf(string) !== -1 ||
          DEPRECATED_BASE60_SYNTAX.test(string)
        ) {
          return state.quotingType === QUOTING_TYPE_DOUBLE
            ? '"' + string + '"'
            : "'" + string + "'"
        }
      }
      const indent = state.indent * Math.max(1, level) // no 0-indent scalars
      // As indentation gets deeper, let the width decrease monotonically
      // to the lower bound min(state.lineWidth, 40).
      // Note that this implies
      //  state.lineWidth ≤ 40 + state.indent: width is fixed at the lower bound.
      //  state.lineWidth > 40 + state.indent: width decreases until the lower bound.
      // This behaves better than a constant minimum width which disallows narrower options,
      // or an indent threshold which causes the width to suddenly increase.
      const lineWidth =
        state.lineWidth === -1
          ? -1
          : Math.max(Math.min(state.lineWidth, 40), state.lineWidth - indent)

      // Without knowing if keys are implicit/explicit, assume implicit for safety.
      const singleLineOnly =
        iskey ||
        singleLO ||
        // No block styles in flow mode.
        (state.flowLevel > -1 && level >= state.flowLevel)
      function testAmbiguity(string) {
        return testImplicitResolving(state, string)
      }
      switch (
        chooseScalarStyle(
          string,
          singleLineOnly,
          state.indent,
          lineWidth,
          testAmbiguity,
          state.quotingType,
          state.forceQuotes && !iskey,
          inblock
        )
      ) {
        case STYLE_PLAIN:
          return string
        case STYLE_SINGLE:
          return "'" + string.replace(/'/g, "''") + "'"
        case STYLE_LITERAL:
          return (
            '|' +
            blockHeader(string, state.indent) +
            dropEndingNewline(indentString(string, indent))
          )
        case STYLE_FOLDED:
          return (
            '>' +
            blockHeader(string, state.indent) +
            dropEndingNewline(
              indentString(foldString(string, lineWidth), indent)
            )
          )
        case STYLE_DOUBLE:
          return '"' + escapeString(string) + '"'
        default:
          throw new YAMLException('impossible error: invalid scalar style')
      }
    })()
  }

  // Pre-conditions: string is valid for a block scalar, 1 <= indentPerLevel <= 9.
  function blockHeader(string, indentPerLevel) {
    const indentIndicator = needIndentIndicator(string)
      ? String(indentPerLevel)
      : ''

    // note the special case: the string '\n' counts as a "trailing" empty line.
    const clip = string[string.length - 1] === '\n'
    const keep = clip && (string[string.length - 2] === '\n' || string === '\n')
    const chomp = keep ? '+' : clip ? '' : '-'
    return indentIndicator + chomp + '\n'
  }

  // (See the note for writeScalar.)
  function dropEndingNewline(string) {
    return string[string.length - 1] === '\n' ? string.slice(0, -1) : string
  }

  // Note: a long line without a suitable break point will exceed the width limit.
  // Pre-conditions: every char in str isPrintable, str.length > 0, width > 0.
  function foldString(string, width) {
    // In folded style, $k$ consecutive newlines output as $k+1$ newlines—
    // unless they're before or after a more-indented line, or at the very
    // beginning or end, in which case $k$ maps to $k$.
    // Therefore, parse each chunk as newline(s) followed by a content line.
    const lineRe = /(\n+)([^\n]*)/g

    // first line (possibly an empty line)
    let result = (function () {
      let nextLF = string.indexOf('\n')
      nextLF = nextLF !== -1 ? nextLF : string.length
      lineRe.lastIndex = nextLF
      return foldLine(string.slice(0, nextLF), width)
    })()
    // If we haven't reached the first content line yet, don't add an extra \n.
    let prevMoreIndented = string[0] === '\n' || string[0] === ' '
    let moreIndented

    // rest of the lines
    let match
    while ((match = lineRe.exec(string))) {
      const prefix = match[1],
        line = match[2]
      moreIndented = line[0] === ' '
      result +=
        prefix +
        (!prevMoreIndented && !moreIndented && line !== '' ? '\n' : '') +
        foldLine(line, width)
      prevMoreIndented = moreIndented
    }
    return result
  }

  // Greedy line breaking.
  // Picks the longest line under the limit each time,
  // otherwise settles for the shortest line over the limit.
  // NB. More-indented lines *cannot* be folded, as that would add an extra \n.
  function foldLine(line, width) {
    if (line === '' || line[0] === ' ') {
      return line
    }

    // Since a more-indented line adds a \n, breaks can't be followed by a space.
    const breakRe = / [^ ]/g // note: the match index will always be <= length-2.
    let match
    // start is an inclusive index. end, curr, and next are exclusive.
    let start = 0,
      end,
      curr = 0,
      next = 0
    let result = ''

    // Invariants: 0 <= start <= length-1.
    //   0 <= curr <= next <= max(0, length-2). curr - start <= width.
    // Inside the loop:
    //   A match implies length >= 2, so curr and next are <= length-2.
    while ((match = breakRe.exec(line))) {
      next = match.index
      // maintain invariant: curr - start <= width
      if (next - start > width) {
        end = curr > start ? curr : next // derive end <= length-2
        result += '\n' + line.slice(start, end)
        // skip the space that was output as \n
        start = end + 1 // derive start <= length-1
      }
      curr = next
    }

    // By the invariants, start <= length-1, so there is something left over.
    // It is either the whole string or a part starting from non-whitespace.
    result += '\n'
    // Insert a break if the remainder is too long and there is a break available.
    if (line.length - start > width && curr > start) {
      result += line.slice(start, curr) + '\n' + line.slice(curr + 1)
    } else {
      result += line.slice(start)
    }
    return result.slice(1) // drop extra \n joiner
  }

  // Escapes a double-quoted string.
  function escapeString(string) {
    let result = ''
    let char = 0
    let escapeSeq
    for (let i = 0; i < string.length; char >= 0x10000 ? (i += 2) : i++) {
      char = codePointAt(string, i)
      escapeSeq = ESCAPE_SEQUENCES[char]
      if (!escapeSeq && isPrintable(char)) {
        result += string[i]
        if (char >= 0x10000) {
          result += string[i + 1]
        }
      } else {
        result += escapeSeq || encodeHex(char)
      }
    }
    return result
  }
  function writeFlowSequence(state, level, object) {
    let _result = '',
      _tag = state.tag,
      index,
      length,
      value
    for (index = 0, length = object.length; index < length; index += 1) {
      value = object[index]
      if (state.replacer) {
        value = state.replacer.call(object, String(index), value)
      }

      // Write only valid elements, put null instead of invalid elements.
      if (
        writeNode(state, level, value, false, false) ||
        (typeof value === 'undefined' &&
          writeNode(state, level, null, false, false))
      ) {
        if (_result !== '') {
          _result += ',' + (!state.condenseFlow ? ' ' : '')
        }
        _result += state.dump
      }
    }
    state.tag = _tag
    state.dump = '[' + _result + ']'
  }
  function writeBlockSequence(state, level, object, compact) {
    let _result = '',
      _tag = state.tag,
      index,
      length,
      value
    for (index = 0, length = object.length; index < length; index += 1) {
      value = object[index]
      if (state.replacer) {
        value = state.replacer.call(object, String(index), value)
      }

      // Write only valid elements, put null instead of invalid elements.
      if (
        writeNode(state, level + 1, value, true, true, false, true) ||
        (typeof value === 'undefined' &&
          writeNode(state, level + 1, null, true, true, false, true))
      ) {
        if (!compact || _result !== '') {
          _result += generateNextLine(state, level)
        }
        if (state.dump && CHAR_LINE_FEED === state.dump.charCodeAt(0)) {
          _result += '-'
        } else {
          _result += '- '
        }
        _result += state.dump
      }
    }
    state.tag = _tag
    state.dump = _result || '[]' // Empty sequence if no valid values.
  }
  function writeFlowMapping(state, level, object, singleLineOnly) {
    let _result = '',
      _tag = state.tag,
      objectKeyList = Object.keys(object),
      index,
      length,
      objectKey,
      objectValue,
      pairBuffer
    for (index = 0, length = objectKeyList.length; index < length; index += 1) {
      pairBuffer = ''
      if (_result !== '') {
        pairBuffer += ', '
      }
      if (state.condenseFlow) {
        pairBuffer += '"'
      }
      objectKey = objectKeyList[index]
      objectValue = object[objectKey]
      if (state.replacer) {
        objectValue = state.replacer.call(object, objectKey, objectValue)
      }
      if (!writeNode(state, level, objectKey, false, false, singleLineOnly)) {
        continue // Skip this pair because of invalid key;
      }
      if (state.dump.length > 1024) {
        pairBuffer += '? '
      }
      pairBuffer +=
        state.dump +
        (state.condenseFlow ? '"' : '') +
        ':' +
        (state.condenseFlow ? '' : ' ')
      if (!writeNode(state, level, objectValue, false, false, singleLineOnly)) {
        continue // Skip this pair because of invalid value.
      }
      pairBuffer += state.dump

      // Both key and value are valid.
      _result += pairBuffer
    }
    state.tag = _tag
    state.dump = '{' + _result + '}'
  }
  function writeBlockMapping(state, level, object, compact, doubleLine) {
    let _result = '',
      _tag = state.tag,
      objectKeyList = Object.keys(object),
      index,
      length,
      objectKey,
      objectValue,
      explicitPair,
      pairBuffer

    // Allow sorting keys so that the output file is deterministic
    if (state.sortKeys === true) {
      // Default sorting
      objectKeyList.sort()
    } else if (typeof state.sortKeys === 'function') {
      // Custom sort function
      objectKeyList.sort(state.sortKeys)
    } else if (state.sortKeys) {
      // Something is wrong
      throw new YAMLException('sortKeys must be a boolean or a function')
    }
    for (index = 0, length = objectKeyList.length; index < length; index += 1) {
      pairBuffer = ''
      if (!compact || _result !== '') {
        pairBuffer += generateNextLine(state, level, doubleLine)
      }
      objectKey = objectKeyList[index]
      objectValue = object[objectKey]
      if (state.replacer) {
        objectValue = state.replacer.call(object, objectKey, objectValue)
      }
      if (!writeNode(state, level + 1, objectKey, true, true, true)) {
        continue // Skip this pair because of invalid key.
      }
      explicitPair =
        (state.tag !== null && state.tag !== '?') ||
        (state.dump && state.dump.length > 1024)
      if (explicitPair) {
        if (state.dump && CHAR_LINE_FEED === state.dump.charCodeAt(0)) {
          pairBuffer += '?'
        } else {
          pairBuffer += '? '
        }
      }
      pairBuffer += state.dump
      if (explicitPair) {
        pairBuffer += generateNextLine(state, level)
      }
      if (
        !writeNode(
          state,
          level + 1,
          objectValue,
          true,
          explicitPair,
          null,
          null,
          objectKey
        )
      ) {
        continue // Skip this pair because of invalid value.
      }
      if (state.dump && CHAR_LINE_FEED === state.dump.charCodeAt(0)) {
        pairBuffer += ':'
      } else {
        pairBuffer += ': '
      }
      pairBuffer += state.dump

      // Both key and value are valid.
      _result += pairBuffer
    }
    state.tag = _tag
    state.dump = _result || '{}' // Empty mapping if no valid pairs.
  }
  function detectType(state, object, explicit) {
    let _result, typeList, index, length, type, style
    typeList = explicit ? state.explicitTypes : state.implicitTypes
    for (index = 0, length = typeList.length; index < length; index += 1) {
      type = typeList[index]
      if (
        (type.instanceOf || type.predicate) &&
        (!type.instanceOf ||
          (typeof object === 'object' && object instanceof type.instanceOf)) &&
        (!type.predicate || type.predicate(object))
      ) {
        if (explicit) {
          if (type.multi && type.representName) {
            state.tag = type.representName(object)
          } else {
            state.tag = type.tag
          }
        } else {
          state.tag = '?'
        }
        if (type.represent) {
          style = state.styleMap[type.tag] || type.defaultStyle
          if (_toString.call(type.represent) === '[object Function]') {
            _result = type.represent(object, style)
          } else if (_hasOwnProperty.call(type.represent, style)) {
            _result = type.represent[style](object, style)
          } else {
            throw new YAMLException(
              '!<' +
                type.tag +
                '> tag resolver accepts not "' +
                style +
                '" style'
            )
          }
          state.dump = _result
        }
        return true
      }
    }
    return false
  }

  // Serializes `object` and writes it to global `result`.
  // Returns true on success, or false on invalid object.
  //
  function writeNode(
    state,
    level,
    object,
    block,
    compact,
    iskey,
    isblockseq,
    objectKey,
    singleLineOnly
  ) {
    state.tag = null
    state.dump = object
    if (!detectType(state, object, false)) {
      detectType(state, object, true)
    }
    const type = _toString.call(state.dump)
    const inblock = block
    let tagStr
    if (block) {
      block = state.flowLevel < 0 || state.flowLevel > level
    }
    let objectOrArray = type === '[object Object]' || type === '[object Array]',
      duplicateIndex,
      duplicate
    if (objectOrArray) {
      duplicateIndex = state.duplicates.indexOf(object)
      duplicate = duplicateIndex !== -1
    }
    if (
      (state.tag !== null && state.tag !== '?') ||
      duplicate ||
      (state.indent !== 2 && level > 0)
    ) {
      compact = false
    }
    if (duplicate && state.usedDuplicates[duplicateIndex]) {
      state.dump = '*ref_' + duplicateIndex
    } else {
      if (objectOrArray && duplicate && !state.usedDuplicates[duplicateIndex]) {
        state.usedDuplicates[duplicateIndex] = true
      }
      if (type === '[object Object]') {
        singleLineOnly = SINGLE_LINE_KEYS[objectKey]
        if (block && Object.keys(state.dump).length !== 0 && !singleLineOnly) {
          const doubleLine = state.blankLines
            ? objectKey === 'packages' ||
              objectKey === 'importers' ||
              objectKey === 'snapshots' ||
              level === 0
            : false
          writeBlockMapping(state, level, state.dump, compact, doubleLine)
          if (duplicate) {
            state.dump = '&ref_' + duplicateIndex + state.dump
          }
        } else {
          writeFlowMapping(state, level, state.dump, singleLineOnly)
          if (duplicate) {
            state.dump = '&ref_' + duplicateIndex + ' ' + state.dump
          }
        }
      } else if (type === '[object Array]') {
        singleLineOnly = SINGLE_LINE_KEYS[objectKey]
        if (block && state.dump.length !== 0 && !singleLineOnly) {
          if (state.noArrayIndent && !isblockseq && level > 0) {
            writeBlockSequence(state, level - 1, state.dump, compact)
          } else {
            writeBlockSequence(state, level, state.dump, compact)
          }
          if (duplicate) {
            state.dump = '&ref_' + duplicateIndex + state.dump
          }
        } else {
          writeFlowSequence(state, level, state.dump)
          if (duplicate) {
            state.dump = '&ref_' + duplicateIndex + ' ' + state.dump
          }
        }
      } else if (type === '[object String]') {
        if (state.tag !== '?') {
          writeScalar(state, state.dump, level, iskey, inblock, singleLineOnly)
        }
      } else if (type === '[object Undefined]') {
        return false
      } else {
        if (state.skipInvalid) {
          return false
        }
        throw new YAMLException(
          'unacceptable kind of an object to dump ' + type
        )
      }
      if (state.tag !== null && state.tag !== '?') {
        // Need to encode all characters except those allowed by the spec:
        //
        // [35] ns-dec-digit    ::=  [#x30-#x39] /* 0-9 */
        // [36] ns-hex-digit    ::=  ns-dec-digit
        //                         | [#x41-#x46] /* A-F */ | [#x61-#x66] /* a-f */
        // [37] ns-ascii-letter ::=  [#x41-#x5A] /* A-Z */ | [#x61-#x7A] /* a-z */
        // [38] ns-word-char    ::=  ns-dec-digit | ns-ascii-letter | “-”
        // [39] ns-uri-char     ::=  “%” ns-hex-digit ns-hex-digit | ns-word-char | “#”
        //                         | “;” | “/” | “?” | “:” | “@” | “&” | “=” | “+” | “$” | “,”
        //                         | “_” | “.” | “!” | “~” | “*” | “'” | “(” | “)” | “[” | “]”
        //
        // Also need to encode '!' because it has special meaning (end of tag prefix).
        //
        tagStr = encodeURI(
          state.tag[0] === '!' ? state.tag.slice(1) : state.tag
        ).replace(/!/g, '%21')
        if (state.tag[0] === '!') {
          tagStr = '!' + tagStr
        } else if (tagStr.slice(0, 18) === 'tag:yaml.org,2002:') {
          tagStr = '!!' + tagStr.slice(18)
        } else {
          tagStr = '!<' + tagStr + '>'
        }
        state.dump = tagStr + ' ' + state.dump
      }
    }
    return true
  }
  function getDuplicateReferences(object, state) {
    let objects = [],
      duplicatesIndexes = [],
      index,
      length
    inspectNode(object, objects, duplicatesIndexes)
    for (
      index = 0, length = duplicatesIndexes.length;
      index < length;
      index += 1
    ) {
      state.duplicates.push(objects[duplicatesIndexes[index]])
    }
    state.usedDuplicates = new Array(length)
  }
  function inspectNode(object, objects, duplicatesIndexes) {
    let objectKeyList, index, length
    if (object !== null && typeof object === 'object') {
      index = objects.indexOf(object)
      if (index !== -1) {
        if (duplicatesIndexes.indexOf(index) === -1) {
          duplicatesIndexes.push(index)
        }
      } else {
        objects.push(object)
        if (Array.isArray(object)) {
          for (index = 0, length = object.length; index < length; index += 1) {
            inspectNode(object[index], objects, duplicatesIndexes)
          }
        } else {
          objectKeyList = Object.keys(object)
          for (
            index = 0, length = objectKeyList.length;
            index < length;
            index += 1
          ) {
            inspectNode(
              object[objectKeyList[index]],
              objects,
              duplicatesIndexes
            )
          }
        }
      }
    }
  }
  function dump(input, options) {
    options = options || {}
    const state = new State(options)
    if (!state.noRefs) {
      getDuplicateReferences(input, state)
    }
    let value = input
    if (state.replacer) {
      value = state.replacer.call(
        {
          '': value
        },
        '',
        value
      )
    }
    if (writeNode(state, 0, value, true, true)) {
      return state.dump + '\n'
    }
    return ''
  }
  dumper.dump = dump
  return dumper
}

let hasRequiredJsYaml
function requireJsYaml() {
  if (hasRequiredJsYaml) {
    return jsYaml
  }
  hasRequiredJsYaml = 1
  const loader = requireLoader()
  const dumper = requireDumper()
  function renamed(from, to) {
    return function () {
      throw new Error(
        'Function yaml.' +
          from +
          ' is removed in js-yaml 4. ' +
          'Use yaml.' +
          to +
          ' instead, which is now safe by default.'
      )
    }
  }
  jsYaml.Type = requireType$1()
  jsYaml.Schema = requireSchema()
  jsYaml.FAILSAFE_SCHEMA = requireFailsafe()
  jsYaml.JSON_SCHEMA = requireJson()
  jsYaml.CORE_SCHEMA = requireCore$1()
  jsYaml.DEFAULT_SCHEMA = require_default()
  jsYaml.load = loader.load
  jsYaml.loadAll = loader.loadAll
  jsYaml.dump = dumper.dump
  jsYaml.YAMLException = requireException()

  // Removed functions from JS-YAML 3.0.x
  jsYaml.safeLoad = renamed('safeLoad', 'load')
  jsYaml.safeLoadAll = renamed('safeLoadAll', 'loadAll')
  jsYaml.safeDump = renamed('safeDump', 'dump')
  return jsYaml
}

let _isPlaceholder_1
let hasRequired_isPlaceholder
function require_isPlaceholder() {
  if (hasRequired_isPlaceholder) {
    return _isPlaceholder_1
  }
  hasRequired_isPlaceholder = 1
  function _isPlaceholder(a) {
    return (
      a != null &&
      typeof a === 'object' &&
      a['@@functional/placeholder'] === true
    )
  }
  _isPlaceholder_1 = _isPlaceholder
  return _isPlaceholder_1
}

let _curry1_1
let hasRequired_curry1
function require_curry1() {
  if (hasRequired_curry1) {
    return _curry1_1
  }
  hasRequired_curry1 = 1
  const _isPlaceholder = /*#__PURE__*/ /*@__PURE__*/ require_isPlaceholder()
  /**
   * Optimized internal one-arity curry function.
   *
   * @private
   * @category Function
   * @param {Function} fn The function to curry.
   * @return {Function} The curried function.
   */

  function _curry1(fn) {
    return function f1(a) {
      if (arguments.length === 0 || _isPlaceholder(a)) {
        return f1
      } else {
        return fn.apply(this, arguments)
      }
    }
  }
  _curry1_1 = _curry1
  return _curry1_1
}

let _has_1
let hasRequired_has
function require_has() {
  if (hasRequired_has) {
    return _has_1
  }
  hasRequired_has = 1
  function _has(prop, obj) {
    return Object.prototype.hasOwnProperty.call(obj, prop)
  }
  _has_1 = _has
  return _has_1
}

let _isArguments_1
let hasRequired_isArguments
function require_isArguments() {
  if (hasRequired_isArguments) {
    return _isArguments_1
  }
  hasRequired_isArguments = 1
  const _has = /*#__PURE__*/ /*@__PURE__*/ require_has()
  const toString = Object.prototype.toString
  const _isArguments =
    /*#__PURE__*/
    (function () {
      return toString.call(arguments) === '[object Arguments]'
        ? function _isArguments(x) {
            return toString.call(x) === '[object Arguments]'
          }
        : function _isArguments(x) {
            return _has('callee', x)
          }
    })()
  _isArguments_1 = _isArguments
  return _isArguments_1
}

/**
 * Tests whether or not an object is an array.
 *
 * @private
 * @param {*} val The object to test.
 * @return {Boolean} `true` if `val` is an array, `false` otherwise.
 * @example
 *
 *      _isArray([]); //=> true
 *      _isArray(null); //=> false
 *      _isArray({}); //=> false
 */
let _isArray
let hasRequired_isArray
function require_isArray() {
  if (hasRequired_isArray) {
    return _isArray
  }
  hasRequired_isArray = 1
  _isArray =
    Array.isArray ||
    function _isArray(val) {
      return (
        val != null &&
        val.length >= 0 &&
        Object.prototype.toString.call(val) === '[object Array]'
      )
    }
  return _isArray
}

let _isObject_1
let hasRequired_isObject
function require_isObject() {
  if (hasRequired_isObject) {
    return _isObject_1
  }
  hasRequired_isObject = 1
  function _isObject(x) {
    return Object.prototype.toString.call(x) === '[object Object]'
  }
  _isObject_1 = _isObject
  return _isObject_1
}

let _isString_1
let hasRequired_isString
function require_isString() {
  if (hasRequired_isString) {
    return _isString_1
  }
  hasRequired_isString = 1
  function _isString(x) {
    return Object.prototype.toString.call(x) === '[object String]'
  }
  _isString_1 = _isString
  return _isString_1
}

/**
 * Tests whether or not an object is a typed array.
 *
 * @private
 * @param {*} val The object to test.
 * @return {Boolean} `true` if `val` is a typed array, `false` otherwise.
 * @example
 *
 *      _isTypedArray(new Uint8Array([])); //=> true
 *      _isTypedArray(new Float32Array([])); //=> true
 *      _isTypedArray([]); //=> false
 *      _isTypedArray(null); //=> false
 *      _isTypedArray({}); //=> false
 */
let _isTypedArray_1
let hasRequired_isTypedArray
function require_isTypedArray() {
  if (hasRequired_isTypedArray) {
    return _isTypedArray_1
  }
  hasRequired_isTypedArray = 1
  function _isTypedArray(val) {
    const type = Object.prototype.toString.call(val)
    return (
      type === '[object Uint8ClampedArray]' ||
      type === '[object Int8Array]' ||
      type === '[object Uint8Array]' ||
      type === '[object Int16Array]' ||
      type === '[object Uint16Array]' ||
      type === '[object Int32Array]' ||
      type === '[object Uint32Array]' ||
      type === '[object Float32Array]' ||
      type === '[object Float64Array]' ||
      type === '[object BigInt64Array]' ||
      type === '[object BigUint64Array]'
    )
  }
  _isTypedArray_1 = _isTypedArray
  return _isTypedArray_1
}

let empty_1
let hasRequiredEmpty
function requireEmpty() {
  if (hasRequiredEmpty) {
    return empty_1
  }
  hasRequiredEmpty = 1
  const _curry1 = /*#__PURE__*/ /*@__PURE__*/ require_curry1()
  const _isArguments = /*#__PURE__*/ /*@__PURE__*/ require_isArguments()
  const _isArray = /*#__PURE__*/ /*@__PURE__*/ require_isArray()
  const _isObject = /*#__PURE__*/ /*@__PURE__*/ require_isObject()
  const _isString = /*#__PURE__*/ /*@__PURE__*/ require_isString()
  const _isTypedArray = /*#__PURE__*/ /*@__PURE__*/ require_isTypedArray()
  /**
   * Returns the empty value of its argument's type. Ramda defines the empty
   * value of Array (`[]`), Object (`{}`), String (`''`),
   * TypedArray (`Uint8Array []`, `Float32Array []`, etc), and Arguments. Other
   * types are supported if they define `<Type>.empty`,
   * `<Type>.prototype.empty` or implement the
   * [FantasyLand Monoid spec](https://github.com/fantasyland/fantasy-land#monoid).
   *
   * Dispatches to the `empty` method of the first argument, if present.
   *
   * @func
   * @memberOf R
   * @since v0.3.0
   * @category Function
   * @sig a -> a
   * @param {*} x
   * @return {*}
   * @example
   *
   *      R.empty(Just(42));               //=> Nothing()
   *      R.empty([1, 2, 3]);              //=> []
   *      R.empty('unicorns');             //=> ''
   *      R.empty({x: 1, y: 2});           //=> {}
   *      R.empty(Uint8Array.from('123')); //=> Uint8Array []
   */

  const empty =
    /*#__PURE__*/
    _curry1(function empty(x) {
      return x != null && typeof x['fantasy-land/empty'] === 'function'
        ? x['fantasy-land/empty']()
        : x != null &&
            x.constructor != null &&
            typeof x.constructor['fantasy-land/empty'] === 'function'
          ? x.constructor['fantasy-land/empty']()
          : x != null && typeof x.empty === 'function'
            ? x.empty()
            : x != null &&
                x.constructor != null &&
                typeof x.constructor.empty === 'function'
              ? x.constructor.empty()
              : _isArray(x)
                ? []
                : _isString(x)
                  ? ''
                  : _isObject(x)
                    ? {}
                    : _isArguments(x)
                      ? (function () {
                          return arguments
                        })()
                      : _isTypedArray(x)
                        ? x.constructor.from('')
                        : void 0 // else
    })
  empty_1 = empty
  return empty_1
}

let _curry2_1
let hasRequired_curry2
function require_curry2() {
  if (hasRequired_curry2) {
    return _curry2_1
  }
  hasRequired_curry2 = 1
  const _curry1 = /*#__PURE__*/ /*@__PURE__*/ require_curry1()
  const _isPlaceholder = /*#__PURE__*/ /*@__PURE__*/ require_isPlaceholder()
  /**
   * Optimized internal two-arity curry function.
   *
   * @private
   * @category Function
   * @param {Function} fn The function to curry.
   * @return {Function} The curried function.
   */

  function _curry2(fn) {
    return function f2(a, b) {
      switch (arguments.length) {
        case 0:
          return f2
        case 1:
          return _isPlaceholder(a)
            ? f2
            : _curry1(function (_b) {
                return fn(a, _b)
              })
        default:
          return _isPlaceholder(a) && _isPlaceholder(b)
            ? f2
            : _isPlaceholder(a)
              ? _curry1(function (_a) {
                  return fn(_a, b)
                })
              : _isPlaceholder(b)
                ? _curry1(function (_b) {
                    return fn(a, _b)
                  })
                : fn(a, b)
      }
    }
  }
  _curry2_1 = _curry2
  return _curry2_1
}

let _arrayFromIterator_1
let hasRequired_arrayFromIterator
function require_arrayFromIterator() {
  if (hasRequired_arrayFromIterator) {
    return _arrayFromIterator_1
  }
  hasRequired_arrayFromIterator = 1
  function _arrayFromIterator(iter) {
    const list = []
    let next
    while (!(next = iter.next()).done) {
      list.push(next.value)
    }
    return list
  }
  _arrayFromIterator_1 = _arrayFromIterator
  return _arrayFromIterator_1
}

let _includesWith_1
let hasRequired_includesWith
function require_includesWith() {
  if (hasRequired_includesWith) {
    return _includesWith_1
  }
  hasRequired_includesWith = 1
  function _includesWith(pred, x, list) {
    let idx = 0
    const len = list.length
    while (idx < len) {
      if (pred(x, list[idx])) {
        return true
      }
      idx += 1
    }
    return false
  }
  _includesWith_1 = _includesWith
  return _includesWith_1
}

let _functionName_1
let hasRequired_functionName
function require_functionName() {
  if (hasRequired_functionName) {
    return _functionName_1
  }
  hasRequired_functionName = 1
  function _functionName(f) {
    // String(x => x) evaluates to "x => x", so the pattern may not match.
    const match = String(f).match(/^function (\w*)/)
    return match == null ? '' : match[1]
  }
  _functionName_1 = _functionName
  return _functionName_1
}

let _objectIs_1
let hasRequired_objectIs
function require_objectIs() {
  if (hasRequired_objectIs) {
    return _objectIs_1
  }
  hasRequired_objectIs = 1
  // Based on https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is
  function _objectIs(a, b) {
    // SameValue algorithm
    if (a === b) {
      // Steps 1-5, 7-10
      // Steps 6.b-6.e: +0 != -0
      return a !== 0 || 1 / a === 1 / b
    } else {
      // Step 6.a: NaN == NaN
      return a !== a && b !== b
    }
  }
  _objectIs_1 = typeof Object.is === 'function' ? Object.is : _objectIs
  return _objectIs_1
}

let keys_1
let hasRequiredKeys
function requireKeys() {
  if (hasRequiredKeys) {
    return keys_1
  }
  hasRequiredKeys = 1
  const _curry1 = /*#__PURE__*/ /*@__PURE__*/ require_curry1()
  const _has = /*#__PURE__*/ /*@__PURE__*/ require_has()
  const _isArguments = /*#__PURE__*/ /*@__PURE__*/ require_isArguments() // cover IE < 9 keys issues

  const hasEnumBug = !(
    /*#__PURE__*/
    {
      toString: null
    }.propertyIsEnumerable('toString')
  )
  const nonEnumerableProps = [
    'constructor',
    'valueOf',
    'isPrototypeOf',
    'toString',
    'propertyIsEnumerable',
    'hasOwnProperty',
    'toLocaleString'
  ] // Safari bug

  const hasArgsEnumBug =
    /*#__PURE__*/
    (function () {
      return arguments.propertyIsEnumerable('length')
    })()
  const contains = function contains(list, item) {
    let idx = 0
    while (idx < list.length) {
      if (list[idx] === item) {
        return true
      }
      idx += 1
    }
    return false
  }
  /**
   * Returns a list containing the names of all the enumerable own properties of
   * the supplied object.
   * Note that the order of the output array is not guaranteed to be consistent
   * across different JS platforms.
   *
   * @func
   * @memberOf R
   * @since v0.1.0
   * @category Object
   * @sig {k: v} -> [k]
   * @param {Object} obj The object to extract properties from
   * @return {Array} An array of the object's own properties.
   * @see R.keysIn, R.values, R.toPairs
   * @example
   *
   *      R.keys({a: 1, b: 2, c: 3}); //=> ['a', 'b', 'c']
   */

  const keys =
    typeof Object.keys === 'function' && !hasArgsEnumBug
      ? /*#__PURE__*/
        _curry1(function keys(obj) {
          return Object(obj) !== obj ? [] : Object.keys(obj)
        })
      : /*#__PURE__*/
        _curry1(function keys(obj) {
          if (Object(obj) !== obj) {
            return []
          }
          let prop, nIdx
          const ks = []
          const checkArgsLength = hasArgsEnumBug && _isArguments(obj)
          for (prop in obj) {
            if (_has(prop, obj) && (!checkArgsLength || prop !== 'length')) {
              ks[ks.length] = prop
            }
          }
          if (hasEnumBug) {
            nIdx = nonEnumerableProps.length - 1
            while (nIdx >= 0) {
              prop = nonEnumerableProps[nIdx]
              if (_has(prop, obj) && !contains(ks, prop)) {
                ks[ks.length] = prop
              }
              nIdx -= 1
            }
          }
          return ks
        })
  keys_1 = keys
  return keys_1
}

let type_1
let hasRequiredType
function requireType() {
  if (hasRequiredType) {
    return type_1
  }
  hasRequiredType = 1
  const _curry1 = /*#__PURE__*/ /*@__PURE__*/ require_curry1()
  /**
   * Gives a single-word string description of the (native) type of a value,
   * returning such answers as 'Object', 'Number', 'Array', or 'Null'. Does not
   * attempt to distinguish user Object types any further, reporting them all as
   * 'Object'.
   *
   * @func
   * @memberOf R
   * @since v0.8.0
   * @category Type
   * @sig (* -> {*}) -> String
   * @param {*} val The value to test
   * @return {String}
   * @example
   *
   *      R.type({}); //=> "Object"
   *      R.type(1); //=> "Number"
   *      R.type(false); //=> "Boolean"
   *      R.type('s'); //=> "String"
   *      R.type(null); //=> "Null"
   *      R.type([]); //=> "Array"
   *      R.type(/[A-z]/); //=> "RegExp"
   *      R.type(() => {}); //=> "Function"
   *      R.type(undefined); //=> "Undefined"
   */

  const type =
    /*#__PURE__*/
    _curry1(function type(val) {
      return val === null
        ? 'Null'
        : val === undefined
          ? 'Undefined'
          : Object.prototype.toString.call(val).slice(8, -1)
    })
  type_1 = type
  return type_1
}

let _equals_1
let hasRequired_equals
function require_equals() {
  if (hasRequired_equals) {
    return _equals_1
  }
  hasRequired_equals = 1
  const _arrayFromIterator =
    /*#__PURE__*/
    /*@__PURE__*/ require_arrayFromIterator()
  const _includesWith = /*#__PURE__*/ /*@__PURE__*/ require_includesWith()
  const _functionName = /*#__PURE__*/ /*@__PURE__*/ require_functionName()
  const _has = /*#__PURE__*/ /*@__PURE__*/ require_has()
  const _objectIs = /*#__PURE__*/ /*@__PURE__*/ require_objectIs()
  const keys = /*#__PURE__*/ /*@__PURE__*/ requireKeys()
  const type = /*#__PURE__*/ /*@__PURE__*/ requireType()
  /**
   * private _uniqContentEquals function.
   * That function is checking equality of 2 iterator contents with 2 assumptions
   * - iterators lengths are the same
   * - iterators values are unique
   *
   * false-positive result will be returned for comparison of, e.g.
   * - [1,2,3] and [1,2,3,4]
   * - [1,1,1] and [1,2,3]
   * */

  function _uniqContentEquals(aIterator, bIterator, stackA, stackB) {
    const a = _arrayFromIterator(aIterator)
    const b = _arrayFromIterator(bIterator)
    function eq(_a, _b) {
      return _equals(_a, _b, stackA.slice(), stackB.slice())
    } // if *a* array contains any element that is not included in *b*

    return !_includesWith(
      function (b, aItem) {
        return !_includesWith(eq, aItem, b)
      },
      b,
      a
    )
  }
  function _equals(a, b, stackA, stackB) {
    if (_objectIs(a, b)) {
      return true
    }
    const typeA = type(a)
    if (typeA !== type(b)) {
      return false
    }
    if (
      typeof a['fantasy-land/equals'] === 'function' ||
      typeof b['fantasy-land/equals'] === 'function'
    ) {
      return (
        typeof a['fantasy-land/equals'] === 'function' &&
        a['fantasy-land/equals'](b) &&
        typeof b['fantasy-land/equals'] === 'function' &&
        b['fantasy-land/equals'](a)
      )
    }
    if (typeof a.equals === 'function' || typeof b.equals === 'function') {
      return (
        typeof a.equals === 'function' &&
        a.equals(b) &&
        typeof b.equals === 'function' &&
        b.equals(a)
      )
    }
    switch (typeA) {
      case 'Arguments':
      case 'Array':
      case 'Object':
        if (
          typeof a.constructor === 'function' &&
          _functionName(a.constructor) === 'Promise'
        ) {
          return a === b
        }
        break
      case 'Boolean':
      case 'Number':
      case 'String':
        if (!(typeof a === typeof b && _objectIs(a.valueOf(), b.valueOf()))) {
          return false
        }
        break
      case 'Date':
        if (!_objectIs(a.valueOf(), b.valueOf())) {
          return false
        }
        break
      case 'Error':
        return a.name === b.name && a.message === b.message
      case 'RegExp':
        if (
          !(
            a.source === b.source &&
            a.global === b.global &&
            a.ignoreCase === b.ignoreCase &&
            a.multiline === b.multiline &&
            a.sticky === b.sticky &&
            a.unicode === b.unicode
          )
        ) {
          return false
        }
        break
    }
    let idx = stackA.length - 1
    while (idx >= 0) {
      if (stackA[idx] === a) {
        return stackB[idx] === b
      }
      idx -= 1
    }
    switch (typeA) {
      case 'Map':
        if (a.size !== b.size) {
          return false
        }
        return _uniqContentEquals(
          a.entries(),
          b.entries(),
          stackA.concat([a]),
          stackB.concat([b])
        )
      case 'Set':
        if (a.size !== b.size) {
          return false
        }
        return _uniqContentEquals(
          a.values(),
          b.values(),
          stackA.concat([a]),
          stackB.concat([b])
        )
      case 'Arguments':
      case 'Array':
      case 'Object':
      case 'Boolean':
      case 'Number':
      case 'String':
      case 'Date':
      case 'Error':
      case 'RegExp':
      case 'Int8Array':
      case 'Uint8Array':
      case 'Uint8ClampedArray':
      case 'Int16Array':
      case 'Uint16Array':
      case 'Int32Array':
      case 'Uint32Array':
      case 'Float32Array':
      case 'Float64Array':
      case 'ArrayBuffer':
        break
      default:
        // Values of other types are only equal if identical.
        return false
    }
    const keysA = keys(a)
    if (keysA.length !== keys(b).length) {
      return false
    }
    const extendedStackA = stackA.concat([a])
    const extendedStackB = stackB.concat([b])
    idx = keysA.length - 1
    while (idx >= 0) {
      const key = keysA[idx]
      if (
        !(
          _has(key, b) &&
          _equals(b[key], a[key], extendedStackA, extendedStackB)
        )
      ) {
        return false
      }
      idx -= 1
    }
    return true
  }
  _equals_1 = _equals
  return _equals_1
}

let equals_1
let hasRequiredEquals
function requireEquals() {
  if (hasRequiredEquals) {
    return equals_1
  }
  hasRequiredEquals = 1
  const _curry2 = /*#__PURE__*/ /*@__PURE__*/ require_curry2()
  const _equals = /*#__PURE__*/ /*@__PURE__*/ require_equals()
  /**
   * Returns `true` if its arguments are equivalent, `false` otherwise. Handles
   * cyclical data structures.
   *
   * Dispatches symmetrically to the `equals` methods of both arguments, if
   * present.
   *
   * @func
   * @memberOf R
   * @since v0.15.0
   * @category Relation
   * @sig a -> b -> Boolean
   * @param {*} a
   * @param {*} b
   * @return {Boolean}
   * @example
   *
   *      R.equals(1, 1); //=> true
   *      R.equals(1, '1'); //=> false
   *      R.equals([1, 2, 3], [1, 2, 3]); //=> true
   *
   *      const a = {}; a.v = a;
   *      const b = {}; b.v = b;
   *      R.equals(a, b); //=> true
   */

  const equals =
    /*#__PURE__*/
    _curry2(function equals(a, b) {
      return _equals(a, b, [], [])
    })
  equals_1 = equals
  return equals_1
}

let isEmpty_1
let hasRequiredIsEmpty
function requireIsEmpty() {
  if (hasRequiredIsEmpty) {
    return isEmpty_1
  }
  hasRequiredIsEmpty = 1
  const _curry1 = /*#__PURE__*/ /*@__PURE__*/ require_curry1()
  const empty = /*#__PURE__*/ /*@__PURE__*/ requireEmpty()
  const equals = /*#__PURE__*/ /*@__PURE__*/ requireEquals()
  /**
   * Returns `true` if the given value is its type's empty value; `false`
   * otherwise.
   *
   * @func
   * @memberOf R
   * @since v0.1.0
   * @category Logic
   * @sig a -> Boolean
   * @param {*} x
   * @return {Boolean}
   * @see R.empty
   * @example
   *
   *      R.isEmpty([1, 2, 3]);           //=> false
   *      R.isEmpty([]);                  //=> true
   *      R.isEmpty('');                  //=> true
   *      R.isEmpty(null);                //=> false
   *      R.isEmpty({});                  //=> true
   *      R.isEmpty({length: 0});         //=> false
   *      R.isEmpty(Uint8Array.from('')); //=> true
   */

  const isEmpty =
    /*#__PURE__*/
    _curry1(function isEmpty(x) {
      return x != null && equals(x, empty(x))
    })
  isEmpty_1 = isEmpty
  return isEmpty_1
}

const lib$8 = { exports: {} }

const imurmurhash = { exports: {} }

/**
 * @preserve
 * JS Implementation of incremental MurmurHash3 (r150) (as of May 10, 2013)
 *
 * @author <a href="mailto:jensyt@gmail.com">Jens Taylor</a>
 * @see http://github.com/homebrewing/brauhaus-diff
 * @author <a href="mailto:gary.court@gmail.com">Gary Court</a>
 * @see http://github.com/garycourt/murmurhash-js
 * @author <a href="mailto:aappleby@gmail.com">Austin Appleby</a>
 * @see http://sites.google.com/site/murmurhash/
 */
let hasRequiredImurmurhash
function requireImurmurhash() {
  if (hasRequiredImurmurhash) {
    return imurmurhash.exports
  }
  hasRequiredImurmurhash = 1
  ;(function (module) {
    ;(function () {
      let cache

      // Call this function without `new` to use the cached object (good for
      // single-threaded environments), or with `new` to create a new object.
      //
      // @param {string} key A UTF-16 or ASCII string
      // @param {number} seed An optional positive integer
      // @return {object} A MurmurHash3 object for incremental hashing
      function MurmurHash3(key, seed) {
        const m = this instanceof MurmurHash3 ? this : cache
        m.reset(seed)
        if (typeof key === 'string' && key.length > 0) {
          m.hash(key)
        }
        if (m !== this) {
          return m
        }
      }

      // Incrementally add a string to this hash
      //
      // @param {string} key A UTF-16 or ASCII string
      // @return {object} this
      MurmurHash3.prototype.hash = function (key) {
        let h1, k1, i, top, len
        len = key.length
        this.len += len
        k1 = this.k1
        i = 0
        switch (this.rem) {
          case 0:
            k1 ^= len > i ? key.charCodeAt(i++) & 0xffff : 0
          case 1:
            k1 ^= len > i ? (key.charCodeAt(i++) & 0xffff) << 8 : 0
          case 2:
            k1 ^= len > i ? (key.charCodeAt(i++) & 0xffff) << 16 : 0
          case 3:
            k1 ^= len > i ? (key.charCodeAt(i) & 0xff) << 24 : 0
            k1 ^= len > i ? (key.charCodeAt(i++) & 0xff00) >> 8 : 0
        }
        this.rem = (len + this.rem) & 3 // & 3 is same as % 4
        len -= this.rem
        if (len > 0) {
          h1 = this.h1
          while (1) {
            k1 = (k1 * 0x2d51 + (k1 & 0xffff) * 0xcc9e0000) & 0xffffffff
            k1 = (k1 << 15) | (k1 >>> 17)
            k1 = (k1 * 0x3593 + (k1 & 0xffff) * 0x1b870000) & 0xffffffff
            h1 ^= k1
            h1 = (h1 << 13) | (h1 >>> 19)
            h1 = (h1 * 5 + 0xe6546b64) & 0xffffffff
            if (i >= len) {
              break
            }
            k1 =
              (key.charCodeAt(i++) & 0xffff) ^
              ((key.charCodeAt(i++) & 0xffff) << 8) ^
              ((key.charCodeAt(i++) & 0xffff) << 16)
            top = key.charCodeAt(i++)
            k1 ^= ((top & 0xff) << 24) ^ ((top & 0xff00) >> 8)
          }
          k1 = 0
          switch (this.rem) {
            case 3:
              k1 ^= (key.charCodeAt(i + 2) & 0xffff) << 16
            case 2:
              k1 ^= (key.charCodeAt(i + 1) & 0xffff) << 8
            case 1:
              k1 ^= key.charCodeAt(i) & 0xffff
          }
          this.h1 = h1
        }
        this.k1 = k1
        return this
      }

      // Get the result of this hash
      //
      // @return {number} The 32-bit hash
      MurmurHash3.prototype.result = function () {
        let k1, h1
        k1 = this.k1
        h1 = this.h1
        if (k1 > 0) {
          k1 = (k1 * 0x2d51 + (k1 & 0xffff) * 0xcc9e0000) & 0xffffffff
          k1 = (k1 << 15) | (k1 >>> 17)
          k1 = (k1 * 0x3593 + (k1 & 0xffff) * 0x1b870000) & 0xffffffff
          h1 ^= k1
        }
        h1 ^= this.len
        h1 ^= h1 >>> 16
        h1 = (h1 * 0xca6b + (h1 & 0xffff) * 0x85eb0000) & 0xffffffff
        h1 ^= h1 >>> 13
        h1 = (h1 * 0xae35 + (h1 & 0xffff) * 0xc2b20000) & 0xffffffff
        h1 ^= h1 >>> 16
        return h1 >>> 0
      }

      // Reset the hash object for reuse
      //
      // @param {number} seed An optional positive integer
      MurmurHash3.prototype.reset = function (seed) {
        this.h1 = typeof seed === 'number' ? seed : 0
        this.rem = this.k1 = this.len = 0
        return this
      }

      // A cached object to use. This can be safely used if you're in a single-
      // threaded environment, otherwise you need to create new hashes to use.
      cache = new MurmurHash3()
      {
        module.exports = MurmurHash3
      }
    })()
  })(imurmurhash)
  return imurmurhash.exports
}

const cjs = {}

const signals$2 = {}

let hasRequiredSignals$2
function requireSignals$2() {
  if (hasRequiredSignals$2) {
    return signals$2
  }
  hasRequiredSignals$2 = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.signals = void 0
    /**
     * This is not the set of all possible signals.
     *
     * It IS, however, the set of all signals that trigger
     * an exit on either Linux or BSD systems.  Linux is a
     * superset of the signal names supported on BSD, and
     * the unknown signals just fail to register, so we can
     * catch that easily enough.
     *
     * Windows signals are a different set, since there are
     * signals that terminate Windows processes, but don't
     * terminate (or don't even exist) on Posix systems.
     *
     * Don't bother with SIGKILL.  It's uncatchable, which
     * means that we can't fire any callbacks anyway.
     *
     * If a user does happen to register a handler on a non-
     * fatal signal like SIGWINCH or something, and then
     * exit, it'll end up firing `process.emit('exit')`, so
     * the handler will be fired anyway.
     *
     * SIGBUS, SIGFPE, SIGSEGV and SIGILL, when not raised
     * artificially, inherently leave the process in a
     * state from which it is not safe to try and enter JS
     * listeners.
     */
    exports.signals = []
    exports.signals.push('SIGHUP', 'SIGINT', 'SIGTERM')
    if (process.platform !== 'win32') {
      exports.signals.push(
        'SIGALRM',
        'SIGABRT',
        'SIGVTALRM',
        'SIGXCPU',
        'SIGXFSZ',
        'SIGUSR2',
        'SIGTRAP',
        'SIGSYS',
        'SIGQUIT',
        'SIGIOT'
        // should detect profiler and enable/disable accordingly.
        // see #21
        // 'SIGPROF'
      )
    }
    if (process.platform === 'linux') {
      exports.signals.push('SIGIO', 'SIGPOLL', 'SIGPWR', 'SIGSTKFLT')
    }
  })(signals$2)
  return signals$2
}

let hasRequiredCjs
function requireCjs() {
  if (hasRequiredCjs) {
    return cjs
  }
  hasRequiredCjs = 1
  ;(function (exports) {
    let _a
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.unload = exports.load = exports.onExit = exports.signals = void 0
    // Note: since nyc uses this module to output coverage, any lines
    // that are in the direct sync flow of nyc's outputCoverage are
    // ignored, since we can never get coverage for them.
    // grab a reference to node's real process object right away
    const signals_js_1 = requireSignals$2()
    Object.defineProperty(exports, 'signals', {
      enumerable: true,
      get: function () {
        return signals_js_1.signals
      }
    })
    const processOk = process =>
      !!process &&
      typeof process === 'object' &&
      typeof process.removeListener === 'function' &&
      typeof process.emit === 'function' &&
      typeof process.reallyExit === 'function' &&
      typeof process.listeners === 'function' &&
      typeof process.kill === 'function' &&
      typeof process.pid === 'number' &&
      typeof process.on === 'function'
    const kExitEmitter = Symbol.for('signal-exit emitter')
    const global = globalThis
    const ObjectDefineProperty = Object.defineProperty.bind(Object)
    // teeny special purpose ee
    class Emitter {
      emitted = {
        afterExit: false,
        exit: false
      }
      listeners = {
        afterExit: [],
        exit: []
      }
      count = 0
      id = Math.random()
      constructor() {
        if (global[kExitEmitter]) {
          return global[kExitEmitter]
        }
        ObjectDefineProperty(global, kExitEmitter, {
          value: this,
          writable: false,
          enumerable: false,
          configurable: false
        })
      }
      on(ev, fn) {
        this.listeners[ev].push(fn)
      }
      removeListener(ev, fn) {
        const list = this.listeners[ev]
        const i = list.indexOf(fn)
        /* c8 ignore start */
        if (i === -1) {
          return
        }
        /* c8 ignore stop */
        if (i === 0 && list.length === 1) {
          list.length = 0
        } else {
          list.splice(i, 1)
        }
      }
      emit(ev, code, signal) {
        if (this.emitted[ev]) {
          return false
        }
        this.emitted[ev] = true
        let ret = false
        for (const fn of this.listeners[ev]) {
          ret = fn(code, signal) === true || ret
        }
        if (ev === 'exit') {
          ret = this.emit('afterExit', code, signal) || ret
        }
        return ret
      }
    }
    class SignalExitBase {}
    const signalExitWrap = handler => {
      return {
        onExit(cb, opts) {
          return handler.onExit(cb, opts)
        },
        load() {
          return handler.load()
        },
        unload() {
          return handler.unload()
        }
      }
    }
    class SignalExitFallback extends SignalExitBase {
      onExit() {
        return () => {}
      }
      load() {}
      unload() {}
    }
    class SignalExit extends SignalExitBase {
      // "SIGHUP" throws an `ENOSYS` error on Windows,
      // so use a supported signal instead
      /* c8 ignore start */
      #hupSig = process.platform === 'win32' ? 'SIGINT' : 'SIGHUP'
      /* c8 ignore stop */
      #emitter = new Emitter()
      #process
      #originalProcessEmit
      #originalProcessReallyExit
      #sigListeners = {}
      #loaded = false
      constructor(process) {
        super()
        this.#process = process
        // { <signal>: <listener fn>, ... }
        this.#sigListeners = {}
        for (const sig of signals_js_1.signals) {
          this.#sigListeners[sig] = () => {
            // If there are no other listeners, an exit is coming!
            // Simplest way: remove us and then re-send the signal.
            // We know that this will kill the process, so we can
            // safely emit now.
            const listeners = this.#process.listeners(sig)
            let { count } = this.#emitter
            // This is a workaround for the fact that signal-exit v3 and signal
            // exit v4 are not aware of each other, and each will attempt to let
            // the other handle it, so neither of them do. To correct this, we
            // detect if we're the only handler *except* for previous versions
            // of signal-exit, and increment by the count of listeners it has
            // created.
            /* c8 ignore start */
            const p = process
            if (
              typeof p.__signal_exit_emitter__ === 'object' &&
              typeof p.__signal_exit_emitter__.count === 'number'
            ) {
              count += p.__signal_exit_emitter__.count
            }
            /* c8 ignore stop */
            if (listeners.length === count) {
              this.unload()
              const ret = this.#emitter.emit('exit', null, sig)
              /* c8 ignore start */
              const s = sig === 'SIGHUP' ? this.#hupSig : sig
              if (!ret) {
                process.kill(process.pid, s)
              }
              /* c8 ignore stop */
            }
          }
        }
        this.#originalProcessReallyExit = process.reallyExit
        this.#originalProcessEmit = process.emit
      }
      onExit(cb, opts) {
        /* c8 ignore start */
        if (!processOk(this.#process)) {
          return () => {}
        }
        /* c8 ignore stop */
        if (this.#loaded === false) {
          this.load()
        }
        const ev = opts?.alwaysLast ? 'afterExit' : 'exit'
        this.#emitter.on(ev, cb)
        return () => {
          this.#emitter.removeListener(ev, cb)
          if (
            this.#emitter.listeners['exit'].length === 0 &&
            this.#emitter.listeners['afterExit'].length === 0
          ) {
            this.unload()
          }
        }
      }
      load() {
        if (this.#loaded) {
          return
        }
        this.#loaded = true
        // This is the number of onSignalExit's that are in play.
        // It's important so that we can count the correct number of
        // listeners on signals, and don't wait for the other one to
        // handle it instead of us.
        this.#emitter.count += 1
        for (const sig of signals_js_1.signals) {
          try {
            const fn = this.#sigListeners[sig]
            if (fn) {
              this.#process.on(sig, fn)
            }
          } catch (_) {}
        }
        this.#process.emit = (ev, ...a) => {
          return this.#processEmit(ev, ...a)
        }
        this.#process.reallyExit = code => {
          return this.#processReallyExit(code)
        }
      }
      unload() {
        if (!this.#loaded) {
          return
        }
        this.#loaded = false
        signals_js_1.signals.forEach(sig => {
          const listener = this.#sigListeners[sig]
          /* c8 ignore start */
          if (!listener) {
            throw new Error('Listener not defined for signal: ' + sig)
          }
          /* c8 ignore stop */
          try {
            this.#process.removeListener(sig, listener)
            /* c8 ignore start */
          } catch (_) {}
          /* c8 ignore stop */
        })
        this.#process.emit = this.#originalProcessEmit
        this.#process.reallyExit = this.#originalProcessReallyExit
        this.#emitter.count -= 1
      }
      #processReallyExit(code) {
        /* c8 ignore start */
        if (!processOk(this.#process)) {
          return 0
        }
        this.#process.exitCode = code || 0
        /* c8 ignore stop */
        this.#emitter.emit('exit', this.#process.exitCode, null)
        return this.#originalProcessReallyExit.call(
          this.#process,
          this.#process.exitCode
        )
      }
      #processEmit(ev, ...args) {
        const og = this.#originalProcessEmit
        if (ev === 'exit' && processOk(this.#process)) {
          if (typeof args[0] === 'number') {
            this.#process.exitCode = args[0]
            /* c8 ignore start */
          }
          /* c8 ignore start */
          const ret = og.call(this.#process, ev, ...args)
          /* c8 ignore start */
          this.#emitter.emit('exit', this.#process.exitCode, null)
          /* c8 ignore stop */
          return ret
        } else {
          return og.call(this.#process, ev, ...args)
        }
      }
    }
    const process = globalThis.process
    // wrap so that we call the method on the actual handler, without
    // exporting it directly.
    ;(_a = signalExitWrap(
      processOk(process) ? new SignalExit(process) : new SignalExitFallback()
    )),
      /**
       * Called when the process is exiting, whether via signal, explicit
       * exit, or running out of stuff to do.
       *
       * If the global process object is not suitable for instrumentation,
       * then this will be a no-op.
       *
       * Returns a function that may be used to unload signal-exit.
       */
      (exports.onExit = _a.onExit),
      /**
       * Load the listeners.  Likely you never need to call this, unless
       * doing a rather deep integration with signal-exit functionality.
       * Mostly exposed for the benefit of testing.
       *
       * @internal
       */
      (exports.load = _a.load),
      /**
       * Unload the listeners.  Likely you never need to call this, unless
       * doing a rather deep integration with signal-exit functionality.
       * Mostly exposed for the benefit of testing.
       *
       * @internal
       */
      (exports.unload = _a.unload)
  })(cjs)
  return cjs
}

let hasRequiredLib$9
function requireLib$9() {
  if (hasRequiredLib$9) {
    return lib$8.exports
  }
  hasRequiredLib$9 = 1
  lib$8.exports = writeFile
  lib$8.exports.sync = writeFileSync
  lib$8.exports._getTmpname = getTmpname // for testing
  lib$8.exports._cleanupOnExit = cleanupOnExit
  const fs = require$$0$6
  const MurmurHash3 = requireImurmurhash()
  const { onExit } = requireCjs()
  const path = require$$0$5
  const { promisify } = require$$0$4
  const activeFiles = {}

  // if we run inside of a worker_thread, `process.pid` is not unique
  /* istanbul ignore next */
  const threadId = (function getId() {
    try {
      const workerThreads = require('node:worker_threads')

      /// if we are in main thread, this is set to `0`
      return workerThreads.threadId
    } catch (e) {
      // worker_threads are not available, fallback to 0
      return 0
    }
  })()
  let invocations = 0
  function getTmpname(filename) {
    return (
      filename +
      '.' +
      MurmurHash3(__filename)
        .hash(String(process.pid))
        .hash(String(threadId))
        .hash(String(++invocations))
        .result()
    )
  }
  function cleanupOnExit(tmpfile) {
    return () => {
      try {
        fs.unlinkSync(typeof tmpfile === 'function' ? tmpfile() : tmpfile)
      } catch {
        // ignore errors
      }
    }
  }
  function serializeActiveFile(absoluteName) {
    return new Promise(resolve => {
      // make a queue if it doesn't already exist
      if (!activeFiles[absoluteName]) {
        activeFiles[absoluteName] = []
      }
      activeFiles[absoluteName].push(resolve) // add this job to the queue
      if (activeFiles[absoluteName].length === 1) {
        resolve()
      } // kick off the first one
    })
  }

  // https://github.com/isaacs/node-graceful-fs/blob/master/polyfills.js#L315-L342
  function isChownErrOk(err) {
    if (err.code === 'ENOSYS') {
      return true
    }
    const nonroot = !process.getuid || process.getuid() !== 0
    if (nonroot) {
      if (err.code === 'EINVAL' || err.code === 'EPERM') {
        return true
      }
    }
    return false
  }
  async function writeFileAsync(filename, data, options = {}) {
    if (typeof options === 'string') {
      options = {
        encoding: options
      }
    }
    let fd
    let tmpfile
    /* istanbul ignore next -- The closure only gets called when onExit triggers */
    const removeOnExitHandler = onExit(cleanupOnExit(() => tmpfile))
    const absoluteName = path.resolve(filename)
    try {
      await serializeActiveFile(absoluteName)
      const truename = await promisify(fs.realpath)(filename).catch(
        () => filename
      )
      tmpfile = getTmpname(truename)
      if (!options.mode || !options.chown) {
        // Either mode or chown is not explicitly set
        // Default behavior is to copy it from original file
        const stats = await promisify(fs.stat)(truename).catch(() => {})
        if (stats) {
          if (options.mode == null) {
            options.mode = stats.mode
          }
          if (options.chown == null && process.getuid) {
            options.chown = {
              uid: stats.uid,
              gid: stats.gid
            }
          }
        }
      }
      fd = await promisify(fs.open)(tmpfile, 'w', options.mode)
      if (options.tmpfileCreated) {
        await options.tmpfileCreated(tmpfile)
      }
      if (ArrayBuffer.isView(data)) {
        await promisify(fs.write)(fd, data, 0, data.length, 0)
      } else if (data != null) {
        await promisify(fs.write)(
          fd,
          String(data),
          0,
          String(options.encoding || 'utf8')
        )
      }
      if (options.fsync !== false) {
        await promisify(fs.fsync)(fd)
      }
      await promisify(fs.close)(fd)
      fd = null
      if (options.chown) {
        await promisify(fs.chown)(
          tmpfile,
          options.chown.uid,
          options.chown.gid
        ).catch(err => {
          if (!isChownErrOk(err)) {
            throw err
          }
        })
      }
      if (options.mode) {
        await promisify(fs.chmod)(tmpfile, options.mode).catch(err => {
          if (!isChownErrOk(err)) {
            throw err
          }
        })
      }
      await promisify(fs.rename)(tmpfile, truename)
    } finally {
      if (fd) {
        await promisify(fs.close)(fd).catch(/* istanbul ignore next */ () => {})
      }
      removeOnExitHandler()
      await promisify(fs.unlink)(tmpfile).catch(() => {})
      activeFiles[absoluteName].shift() // remove the element added by serializeSameFile
      if (activeFiles[absoluteName].length > 0) {
        activeFiles[absoluteName][0]() // start next job if one is pending
      } else {
        delete activeFiles[absoluteName]
      }
    }
  }
  async function writeFile(filename, data, options, callback) {
    if (options instanceof Function) {
      callback = options
      options = {}
    }
    const promise = writeFileAsync(filename, data, options)
    if (callback) {
      try {
        const result = await promise
        return callback(result)
      } catch (err) {
        return callback(err)
      }
    }
    return promise
  }
  function writeFileSync(filename, data, options) {
    if (typeof options === 'string') {
      options = {
        encoding: options
      }
    } else if (!options) {
      options = {}
    }
    try {
      filename = fs.realpathSync(filename)
    } catch (ex) {
      // it's ok, it'll happen on a not yet existing file
    }
    const tmpfile = getTmpname(filename)
    if (!options.mode || !options.chown) {
      // Either mode or chown is not explicitly set
      // Default behavior is to copy it from original file
      try {
        const stats = fs.statSync(filename)
        options = Object.assign({}, options)
        if (!options.mode) {
          options.mode = stats.mode
        }
        if (!options.chown && process.getuid) {
          options.chown = {
            uid: stats.uid,
            gid: stats.gid
          }
        }
      } catch (ex) {
        // ignore stat errors
      }
    }
    let fd
    const cleanup = cleanupOnExit(tmpfile)
    const removeOnExitHandler = onExit(cleanup)
    let threw = true
    try {
      fd = fs.openSync(tmpfile, 'w', options.mode || 0o666)
      if (options.tmpfileCreated) {
        options.tmpfileCreated(tmpfile)
      }
      if (ArrayBuffer.isView(data)) {
        fs.writeSync(fd, data, 0, data.length, 0)
      } else if (data != null) {
        fs.writeSync(fd, String(data), 0, String(options.encoding || 'utf8'))
      }
      if (options.fsync !== false) {
        fs.fsyncSync(fd)
      }
      fs.closeSync(fd)
      fd = null
      if (options.chown) {
        try {
          fs.chownSync(tmpfile, options.chown.uid, options.chown.gid)
        } catch (err) {
          if (!isChownErrOk(err)) {
            throw err
          }
        }
      }
      if (options.mode) {
        try {
          fs.chmodSync(tmpfile, options.mode)
        } catch (err) {
          if (!isChownErrOk(err)) {
            throw err
          }
        }
      }
      fs.renameSync(tmpfile, filename)
      threw = false
    } finally {
      if (fd) {
        try {
          fs.closeSync(fd)
        } catch (ex) {
          // ignore close errors at this stage, error may have closed fd already.
        }
      }
      removeOnExitHandler()
      if (threw) {
        cleanup()
      }
    }
  }
  return lib$8.exports
}

const logger$1 = {}

const lib$7 = {}

const logger = {}

let fastSafeStringify
let hasRequiredFastSafeStringify
function requireFastSafeStringify() {
  if (hasRequiredFastSafeStringify) {
    return fastSafeStringify
  }
  hasRequiredFastSafeStringify = 1
  fastSafeStringify = stringify
  stringify.default = stringify
  stringify.stable = deterministicStringify
  stringify.stableStringify = deterministicStringify
  const LIMIT_REPLACE_NODE = '[...]'
  const CIRCULAR_REPLACE_NODE = '[Circular]'
  const arr = []
  const replacerStack = []
  function defaultOptions() {
    return {
      depthLimit: Number.MAX_SAFE_INTEGER,
      edgesLimit: Number.MAX_SAFE_INTEGER
    }
  }

  // Regular stringify
  function stringify(obj, replacer, spacer, options) {
    if (typeof options === 'undefined') {
      options = defaultOptions()
    }
    decirc(obj, '', 0, [], undefined, 0, options)
    let res
    try {
      if (replacerStack.length === 0) {
        res = JSON.stringify(obj, replacer, spacer)
      } else {
        res = JSON.stringify(obj, replaceGetterValues(replacer), spacer)
      }
    } catch (_) {
      return JSON.stringify(
        '[unable to serialize, circular reference is too complex to analyze]'
      )
    } finally {
      while (arr.length !== 0) {
        const part = arr.pop()
        if (part.length === 4) {
          Object.defineProperty(part[0], part[1], part[3])
        } else {
          part[0][part[1]] = part[2]
        }
      }
    }
    return res
  }
  function setReplace(replace, val, k, parent) {
    const propertyDescriptor = Object.getOwnPropertyDescriptor(parent, k)
    if (propertyDescriptor.get !== undefined) {
      if (propertyDescriptor.configurable) {
        Object.defineProperty(parent, k, {
          value: replace
        })
        arr.push([parent, k, val, propertyDescriptor])
      } else {
        replacerStack.push([val, k, replace])
      }
    } else {
      parent[k] = replace
      arr.push([parent, k, val])
    }
  }
  function decirc(val, k, edgeIndex, stack, parent, depth, options) {
    depth += 1
    let i
    if (typeof val === 'object' && val !== null) {
      for (i = 0; i < stack.length; i++) {
        if (stack[i] === val) {
          setReplace(CIRCULAR_REPLACE_NODE, val, k, parent)
          return
        }
      }
      if (
        typeof options.depthLimit !== 'undefined' &&
        depth > options.depthLimit
      ) {
        setReplace(LIMIT_REPLACE_NODE, val, k, parent)
        return
      }
      if (
        typeof options.edgesLimit !== 'undefined' &&
        edgeIndex + 1 > options.edgesLimit
      ) {
        setReplace(LIMIT_REPLACE_NODE, val, k, parent)
        return
      }
      stack.push(val)
      // Optimize for Arrays. Big arrays could kill the performance otherwise!
      if (Array.isArray(val)) {
        for (i = 0; i < val.length; i++) {
          decirc(val[i], i, i, stack, val, depth, options)
        }
      } else {
        const keys = Object.keys(val)
        for (i = 0; i < keys.length; i++) {
          const key = keys[i]
          decirc(val[key], key, i, stack, val, depth, options)
        }
      }
      stack.pop()
    }
  }

  // Stable-stringify
  function compareFunction(a, b) {
    if (a < b) {
      return -1
    }
    if (a > b) {
      return 1
    }
    return 0
  }
  function deterministicStringify(obj, replacer, spacer, options) {
    if (typeof options === 'undefined') {
      options = defaultOptions()
    }
    const tmp =
      deterministicDecirc(obj, '', 0, [], undefined, 0, options) || obj
    let res
    try {
      if (replacerStack.length === 0) {
        res = JSON.stringify(tmp, replacer, spacer)
      } else {
        res = JSON.stringify(tmp, replaceGetterValues(replacer), spacer)
      }
    } catch (_) {
      return JSON.stringify(
        '[unable to serialize, circular reference is too complex to analyze]'
      )
    } finally {
      // Ensure that we restore the object as it was.
      while (arr.length !== 0) {
        const part = arr.pop()
        if (part.length === 4) {
          Object.defineProperty(part[0], part[1], part[3])
        } else {
          part[0][part[1]] = part[2]
        }
      }
    }
    return res
  }
  function deterministicDecirc(
    val,
    k,
    edgeIndex,
    stack,
    parent,
    depth,
    options
  ) {
    depth += 1
    let i
    if (typeof val === 'object' && val !== null) {
      for (i = 0; i < stack.length; i++) {
        if (stack[i] === val) {
          setReplace(CIRCULAR_REPLACE_NODE, val, k, parent)
          return
        }
      }
      try {
        if (typeof val.toJSON === 'function') {
          return
        }
      } catch (_) {
        return
      }
      if (
        typeof options.depthLimit !== 'undefined' &&
        depth > options.depthLimit
      ) {
        setReplace(LIMIT_REPLACE_NODE, val, k, parent)
        return
      }
      if (
        typeof options.edgesLimit !== 'undefined' &&
        edgeIndex + 1 > options.edgesLimit
      ) {
        setReplace(LIMIT_REPLACE_NODE, val, k, parent)
        return
      }
      stack.push(val)
      // Optimize for Arrays. Big arrays could kill the performance otherwise!
      if (Array.isArray(val)) {
        for (i = 0; i < val.length; i++) {
          deterministicDecirc(val[i], i, i, stack, val, depth, options)
        }
      } else {
        // Create a temporary object in the required way
        const tmp = {}
        const keys = Object.keys(val).sort(compareFunction)
        for (i = 0; i < keys.length; i++) {
          const key = keys[i]
          deterministicDecirc(val[key], key, i, stack, val, depth, options)
          tmp[key] = val[key]
        }
        if (typeof parent !== 'undefined') {
          arr.push([parent, k, val])
          parent[k] = tmp
        } else {
          return tmp
        }
      }
      stack.pop()
    }
  }

  // wraps replacer function to handle values we couldn't replace
  // and mark them as replaced value
  function replaceGetterValues(replacer) {
    replacer =
      typeof replacer !== 'undefined'
        ? replacer
        : function (k, v) {
            return v
          }
    return function (key, val) {
      if (replacerStack.length > 0) {
        for (let i = 0; i < replacerStack.length; i++) {
          const part = replacerStack[i]
          if (part[1] === key && part[0] === val) {
            val = part[2]
            replacerStack.splice(i, 1)
            break
          }
        }
      }
      return replacer.call(this, key, val)
    }
  }
  return fastSafeStringify
}

let individual
let hasRequiredIndividual
function requireIndividual() {
  if (hasRequiredIndividual) {
    return individual
  }
  hasRequiredIndividual = 1

  /*global window, global*/

  const root =
    typeof window !== 'undefined'
      ? window
      : typeof global !== 'undefined'
        ? global
        : {}
  individual = Individual
  function Individual(key, value) {
    if (key in root) {
      return root[key]
    }
    root[key] = value
    return value
  }
  return individual
}

let format_1
let hasRequiredFormat
function requireFormat() {
  if (hasRequiredFormat) {
    return format_1
  }
  hasRequiredFormat = 1
  // consider this a warning about getting obsessive about optimization

  const utilformat = require$$0$4.format
  function format(
    a1,
    a2,
    a3,
    a4,
    a5,
    a6,
    a7,
    a8,
    a9,
    a10,
    a11,
    a12,
    a13,
    a14,
    a15,
    a16
  ) {
    if (a16 !== undefined) {
      return utilformat(
        a1,
        a2,
        a3,
        a4,
        a5,
        a6,
        a7,
        a8,
        a9,
        a10,
        a11,
        a12,
        a13,
        a14,
        a15,
        a16
      )
    }
    if (a15 !== undefined) {
      return utilformat(
        a1,
        a2,
        a3,
        a4,
        a5,
        a6,
        a7,
        a8,
        a9,
        a10,
        a11,
        a12,
        a13,
        a14,
        a15
      )
    }
    if (a14 !== undefined) {
      return utilformat(
        a1,
        a2,
        a3,
        a4,
        a5,
        a6,
        a7,
        a8,
        a9,
        a10,
        a11,
        a12,
        a13,
        a14
      )
    }
    if (a13 !== undefined) {
      return utilformat(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13)
    }
    if (a12 !== undefined) {
      return utilformat(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12)
    }
    if (a11 !== undefined) {
      return utilformat(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11)
    }
    if (a10 !== undefined) {
      return utilformat(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10)
    }
    if (a9 !== undefined) {
      return utilformat(a1, a2, a3, a4, a5, a6, a7, a8, a9)
    }
    if (a8 !== undefined) {
      return utilformat(a1, a2, a3, a4, a5, a6, a7, a8)
    }
    if (a7 !== undefined) {
      return utilformat(a1, a2, a3, a4, a5, a6, a7)
    }
    if (a6 !== undefined) {
      return utilformat(a1, a2, a3, a4, a5, a6)
    }
    if (a5 !== undefined) {
      return utilformat(a1, a2, a3, a4, a5)
    }
    if (a4 !== undefined) {
      return utilformat(a1, a2, a3, a4)
    }
    if (a3 !== undefined) {
      return utilformat(a1, a2, a3)
    }
    if (a2 !== undefined) {
      return utilformat(a1, a2)
    }
    return a1
  }
  format_1 = format
  return format_1
}

let bole_1
let hasRequiredBole
function requireBole() {
  if (hasRequiredBole) {
    return bole_1
  }
  hasRequiredBole = 1
  const _stringify = requireFastSafeStringify()
  const individual = requireIndividual()('$$bole', {
    fastTime: false
  }) // singleton
  const format = requireFormat()
  const levels = 'debug info warn error'.split(' ')
  const os = require$$0$c
  const pid = process.pid
  let hasObjMode = false
  const scache = []

  // Ref: https://github.com/rvagg/bole/issues/20
  let hostname
  try {
    hostname = os.hostname()
  } catch (e) {
    hostname =
      os.version().indexOf('Windows 7 ') === 0 ? 'windows7' : 'hostname-unknown'
  }
  const hostnameSt = _stringify(hostname)
  for (const level of levels) {
    // prepare a common part of the stringified output
    scache[level] =
      ',"hostname":' + hostnameSt + ',"pid":' + pid + ',"level":"' + level

    if (!Array.isArray(individual[level])) {
      individual[level] = []
    }
  }
  function stackToString(e) {
    let s = e.stack
    let ce
    if (typeof e.cause === 'function' && (ce = e.cause())) {
      s += '\nCaused by: ' + stackToString(ce)
    }
    return s
  }
  function errorToOut(err, out) {
    out.err = {
      name: err.name,
      message: err.message,
      code: err.code,
      // perhaps
      stack: stackToString(err)
    }
  }
  function requestToOut(req, out) {
    out.req = {
      method: req.method,
      url: req.url,
      headers: req.headers,
      remoteAddress: req.connection.remoteAddress,
      remotePort: req.connection.remotePort
    }
  }
  function objectToOut(obj, out) {
    for (const k in obj) {
      if (
        Object.prototype.hasOwnProperty.call(obj, k) &&
        obj[k] !== undefined
      ) {
        out[k] = obj[k]
      }
    }
  }
  function objectMode(stream) {
    return stream._writableState && stream._writableState.objectMode === true
  }
  function stringify(level, name, message, obj) {
    let s =
      '{"time":' +
      (individual.fastTime
        ? Date.now()
        : '"' + new Date().toISOString() + '"') +
      scache[level] +
      '","name":' +
      name +
      (message !== undefined ? ',"message":' + _stringify(message) : '')
    for (const k in obj) {
      s += ',' + _stringify(k) + ':' + _stringify(obj[k])
    }
    s += '}'

    return s
  }
  function extend(level, name, message, obj) {
    const newObj = {
      time: individual.fastTime ? Date.now() : new Date().toISOString(),
      hostname,
      pid,
      level,
      name
    }
    if (message !== undefined) {
      obj.message = message
    }
    for (const k in obj) {
      newObj[k] = obj[k]
    }
    return newObj
  }
  function levelLogger(level, name) {
    const outputs = individual[level]
    const nameSt = _stringify(name)
    return function namedLevelLogger(
      inp,
      a2,
      a3,
      a4,
      a5,
      a6,
      a7,
      a8,
      a9,
      a10,
      a11,
      a12,
      a13,
      a14,
      a15,
      a16
    ) {
      if (outputs.length === 0) {
        return
      }
      const out = {}
      let objectOut
      let i = 0
      const l = outputs.length
      let stringified
      let message
      if (typeof inp === 'string' || inp == null) {
        if (
          !(message = format(
            inp,
            a2,
            a3,
            a4,
            a5,
            a6,
            a7,
            a8,
            a9,
            a10,
            a11,
            a12,
            a13,
            a14,
            a15,
            a16
          ))
        ) {
          message = undefined
        }
      } else {
        if (inp instanceof Error) {
          if (typeof a2 === 'object') {
            objectToOut(a2, out)
            errorToOut(inp, out)
            if (
              !(message = format(
                a3,
                a4,
                a5,
                a6,
                a7,
                a8,
                a9,
                a10,
                a11,
                a12,
                a13,
                a14,
                a15,
                a16
              ))
            ) {
              message = undefined
            }
          } else {
            errorToOut(inp, out)
            if (
              !(message = format(
                a2,
                a3,
                a4,
                a5,
                a6,
                a7,
                a8,
                a9,
                a10,
                a11,
                a12,
                a13,
                a14,
                a15,
                a16
              ))
            ) {
              message = undefined
            }
          }
        } else {
          if (
            !(message = format(
              a2,
              a3,
              a4,
              a5,
              a6,
              a7,
              a8,
              a9,
              a10,
              a11,
              a12,
              a13,
              a14,
              a15,
              a16
            ))
          ) {
            message = undefined
          }
        }
        if (typeof inp === 'boolean') {
          message = String(inp)
        } else if (typeof inp === 'object' && !(inp instanceof Error)) {
          if (inp.method && inp.url && inp.headers && inp.socket) {
            requestToOut(inp, out)
          } else {
            objectToOut(inp, out)
          }
        }
      }
      if (l === 1 && !hasObjMode) {
        // fast, standard case
        outputs[0].write(
          Buffer.from(stringify(level, nameSt, message, out) + '\n')
        )
        return
      }
      for (; i < l; i++) {
        if (objectMode(outputs[i])) {
          if (objectOut === undefined) {
            // lazy object completion
            objectOut = extend(level, name, message, out)
          }
          outputs[i].write(objectOut)
        } else {
          if (stringified === undefined) {
            // lazy stringify
            stringified = Buffer.from(
              stringify(level, nameSt, message, out) + '\n'
            )
          }
          outputs[i].write(stringified)
        }
      }
    }
  }
  function bole(name) {
    function boleLogger(subname) {
      return bole(name + ':' + subname)
    }
    function makeLogger(p, level) {
      p[level] = levelLogger(level, name)
      return p
    }
    return levels.reduce(makeLogger, boleLogger)
  }
  bole.output = function output(opt) {
    let b = false
    if (Array.isArray(opt)) {
      opt.forEach(bole.output)
      return bole
    }
    if (typeof opt.level !== 'string') {
      throw new TypeError('Must provide a "level" option')
    }
    for (const level of levels) {
      if (!b && level === opt.level) {
        b = true
      }
      if (b) {
        if (opt.stream && objectMode(opt.stream)) {
          hasObjMode = true
        }
        individual[level].push(opt.stream)
      }
    }
    return bole
  }
  bole.reset = function reset() {
    for (const level of levels) {
      individual[level].splice(0, individual[level].length)
    }
    individual.fastTime = false
    return bole
  }
  bole.setFastTime = function setFastTime(b) {
    if (!arguments.length) {
      individual.fastTime = true
    } else {
      individual.fastTime = b
    }
    return bole
  }
  bole_1 = bole
  return bole_1
}

let hasRequiredLogger$1
function requireLogger$1() {
  if (hasRequiredLogger$1) {
    return logger
  }
  hasRequiredLogger$1 = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(logger, '__esModule', {
    value: true
  })
  logger.logger = void 0
  logger.globalWarn = globalWarn
  logger.globalInfo = globalInfo
  const bole_1 = __importDefault(requireBole())
  bole_1.default.setFastTime()
  logger.logger = (0, bole_1.default)('pnpm')
  const globalLogger = (0, bole_1.default)('pnpm:global')
  function globalWarn(message) {
    globalLogger.warn(message)
  }
  function globalInfo(message) {
    globalLogger.info(message)
  }
  return logger
}

const streamParser = {}

const ndjson = {}

const through2 = { exports: {} }

const readable$1 = { exports: {} }

let stream$2
let hasRequiredStream$2
function requireStream$2() {
  if (hasRequiredStream$2) {
    return stream$2
  }
  hasRequiredStream$2 = 1
  stream$2 = require$$0$g
  return stream$2
}

let buffer_list$1
let hasRequiredBuffer_list$1
function requireBuffer_list$1() {
  if (hasRequiredBuffer_list$1) {
    return buffer_list$1
  }
  hasRequiredBuffer_list$1 = 1
  function ownKeys(object, enumerableOnly) {
    const keys = Object.keys(object)
    if (Object.getOwnPropertySymbols) {
      let symbols = Object.getOwnPropertySymbols(object)
      enumerableOnly &&
        (symbols = symbols.filter(function (sym) {
          return Object.getOwnPropertyDescriptor(object, sym).enumerable
        })),
        keys.push.apply(keys, symbols)
    }
    return keys
  }
  function _objectSpread(target) {
    for (let i = 1; i < arguments.length; i++) {
      const source = null != arguments[i] ? arguments[i] : {}
      i % 2
        ? ownKeys(Object(source), true).forEach(function (key) {
            _defineProperty(target, key, source[key])
          })
        : Object.getOwnPropertyDescriptors
          ? Object.defineProperties(
              target,
              Object.getOwnPropertyDescriptors(source)
            )
          : ownKeys(Object(source)).forEach(function (key) {
              Object.defineProperty(
                target,
                key,
                Object.getOwnPropertyDescriptor(source, key)
              )
            })
    }
    return target
  }
  function _defineProperty(obj, key, value) {
    key = _toPropertyKey(key)
    if (key in obj) {
      Object.defineProperty(obj, key, {
        value: value,
        enumerable: true,
        configurable: true,
        writable: true
      })
    } else {
      obj[key] = value
    }
    return obj
  }
  function _classCallCheck(instance, Constructor) {
    if (!(instance instanceof Constructor)) {
      throw new TypeError('Cannot call a class as a function')
    }
  }
  function _defineProperties(target, props) {
    for (let i = 0; i < props.length; i++) {
      const descriptor = props[i]
      descriptor.enumerable = descriptor.enumerable || false
      descriptor.configurable = true
      if ('value' in descriptor) {
        descriptor.writable = true
      }
      Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor)
    }
  }
  function _createClass(Constructor, protoProps, staticProps) {
    if (protoProps) {
      _defineProperties(Constructor.prototype, protoProps)
    }
    Object.defineProperty(Constructor, 'prototype', {
      writable: false
    })
    return Constructor
  }
  function _toPropertyKey(arg) {
    const key = _toPrimitive(arg, 'string')
    return typeof key === 'symbol' ? key : String(key)
  }
  function _toPrimitive(input, hint) {
    if (typeof input !== 'object' || input === null) {
      return input
    }
    const prim = input[Symbol.toPrimitive]
    if (prim !== undefined) {
      const res = prim.call(input, hint)
      if (typeof res !== 'object') {
        return res
      }
      throw new TypeError('@@toPrimitive must return a primitive value.')
    }
    return String(input)
  }
  const _require = require$$2$4,
    Buffer = _require.Buffer
  const _require2 = require$$0$4,
    inspect = _require2.inspect
  const custom = (inspect && inspect.custom) || 'inspect'
  function copyBuffer(src, target, offset) {
    Buffer.prototype.copy.call(src, target, offset)
  }
  buffer_list$1 = /*#__PURE__*/ (function () {
    function BufferList() {
      _classCallCheck(this, BufferList)
      this.head = null
      this.tail = null
      this.length = 0
    }
    _createClass(BufferList, [
      {
        key: 'push',
        value: function push(v) {
          const entry = {
            data: v,
            next: null
          }
          if (this.length > 0) {
            this.tail.next = entry
          } else {
            this.head = entry
          }
          this.tail = entry
          ++this.length
        }
      },
      {
        key: 'unshift',
        value: function unshift(v) {
          const entry = {
            data: v,
            next: this.head
          }
          if (this.length === 0) {
            this.tail = entry
          }
          this.head = entry
          ++this.length
        }
      },
      {
        key: 'shift',
        value: function shift() {
          if (this.length === 0) {
            return
          }
          const ret = this.head.data
          if (this.length === 1) {
            this.head = this.tail = null
          } else {
            this.head = this.head.next
          }
          --this.length
          return ret
        }
      },
      {
        key: 'clear',
        value: function clear() {
          this.head = this.tail = null
          this.length = 0
        }
      },
      {
        key: 'join',
        value: function join(s) {
          if (this.length === 0) {
            return ''
          }
          let p = this.head
          let ret = '' + p.data
          while ((p = p.next)) {
            ret += s + p.data
          }
          return ret
        }
      },
      {
        key: 'concat',
        value: function concat(n) {
          if (this.length === 0) {
            return Buffer.alloc(0)
          }
          const ret = Buffer.allocUnsafe(n >>> 0)
          let p = this.head
          let i = 0
          while (p) {
            copyBuffer(p.data, ret, i)
            i += p.data.length
            p = p.next
          }
          return ret
        }

        // Consumes a specified amount of bytes or characters from the buffered data.
      },
      {
        key: 'consume',
        value: function consume(n, hasStrings) {
          let ret
          if (n < this.head.data.length) {
            // `slice` is the same for buffers and strings.
            ret = this.head.data.slice(0, n)
            this.head.data = this.head.data.slice(n)
          } else if (n === this.head.data.length) {
            // First chunk is a perfect match.
            ret = this.shift()
          } else {
            // Result spans more than one buffer.
            ret = hasStrings ? this._getString(n) : this._getBuffer(n)
          }
          return ret
        }
      },
      {
        key: 'first',
        value: function first() {
          return this.head.data
        }

        // Consumes a specified amount of characters from the buffered data.
      },
      {
        key: '_getString',
        value: function _getString(n) {
          let p = this.head
          let c = 1
          let ret = p.data
          n -= ret.length
          while ((p = p.next)) {
            const str = p.data
            const nb = n > str.length ? str.length : n
            if (nb === str.length) {
              ret += str
            } else {
              ret += str.slice(0, n)
            }
            n -= nb
            if (n === 0) {
              if (nb === str.length) {
                ++c
                if (p.next) {
                  this.head = p.next
                } else {
                  this.head = this.tail = null
                }
              } else {
                this.head = p
                p.data = str.slice(nb)
              }
              break
            }
            ++c
          }
          this.length -= c
          return ret
        }

        // Consumes a specified amount of bytes from the buffered data.
      },
      {
        key: '_getBuffer',
        value: function _getBuffer(n) {
          const ret = Buffer.allocUnsafe(n)
          let p = this.head
          let c = 1
          p.data.copy(ret)
          n -= p.data.length
          while ((p = p.next)) {
            const buf = p.data
            const nb = n > buf.length ? buf.length : n
            buf.copy(ret, ret.length - n, 0, nb)
            n -= nb
            if (n === 0) {
              if (nb === buf.length) {
                ++c
                if (p.next) {
                  this.head = p.next
                } else {
                  this.head = this.tail = null
                }
              } else {
                this.head = p
                p.data = buf.slice(nb)
              }
              break
            }
            ++c
          }
          this.length -= c
          return ret
        }

        // Make sure the linked list only shows the minimal necessary information.
      },
      {
        key: custom,
        value: function value(_, options) {
          return inspect(
            this,
            _objectSpread(
              _objectSpread({}, options),
              {},
              {
                // Only inspect one level.
                depth: 0,
                // It should not recurse.
                customInspect: false
              }
            )
          )
        }
      }
    ])
    return BufferList
  })()
  return buffer_list$1
}

let destroy_1$1
let hasRequiredDestroy$1
function requireDestroy$1() {
  if (hasRequiredDestroy$1) {
    return destroy_1$1
  }
  hasRequiredDestroy$1 = 1

  // undocumented cb() API, needed for core, not for public API
  function destroy(err, cb) {
    const _this = this
    const readableDestroyed =
      this._readableState && this._readableState.destroyed
    const writableDestroyed =
      this._writableState && this._writableState.destroyed
    if (readableDestroyed || writableDestroyed) {
      if (cb) {
        cb(err)
      } else if (err) {
        if (!this._writableState) {
          process.nextTick(emitErrorNT, this, err)
        } else if (!this._writableState.errorEmitted) {
          this._writableState.errorEmitted = true
          process.nextTick(emitErrorNT, this, err)
        }
      }
      return this
    }

    // we set destroyed to true before firing error callbacks in order
    // to make it re-entrance safe in case destroy() is called within callbacks

    if (this._readableState) {
      this._readableState.destroyed = true
    }

    // if this is a duplex stream mark the writable part as destroyed as well
    if (this._writableState) {
      this._writableState.destroyed = true
    }
    this._destroy(err || null, function (err) {
      if (!cb && err) {
        if (!_this._writableState) {
          process.nextTick(emitErrorAndCloseNT, _this, err)
        } else if (!_this._writableState.errorEmitted) {
          _this._writableState.errorEmitted = true
          process.nextTick(emitErrorAndCloseNT, _this, err)
        } else {
          process.nextTick(emitCloseNT, _this)
        }
      } else if (cb) {
        process.nextTick(emitCloseNT, _this)
        cb(err)
      } else {
        process.nextTick(emitCloseNT, _this)
      }
    })
    return this
  }
  function emitErrorAndCloseNT(self, err) {
    emitErrorNT(self, err)
    emitCloseNT(self)
  }
  function emitCloseNT(self) {
    if (self._writableState && !self._writableState.emitClose) {
      return
    }
    if (self._readableState && !self._readableState.emitClose) {
      return
    }
    self.emit('close')
  }
  function undestroy() {
    if (this._readableState) {
      this._readableState.destroyed = false
      this._readableState.reading = false
      this._readableState.ended = false
      this._readableState.endEmitted = false
    }
    if (this._writableState) {
      this._writableState.destroyed = false
      this._writableState.ended = false
      this._writableState.ending = false
      this._writableState.finalCalled = false
      this._writableState.prefinished = false
      this._writableState.finished = false
      this._writableState.errorEmitted = false
    }
  }
  function emitErrorNT(self, err) {
    self.emit('error', err)
  }
  function errorOrDestroy(stream, err) {
    // We have tests that rely on errors being emitted
    // in the same tick, so changing this is semver major.
    // For now when you opt-in to autoDestroy we allow
    // the error to be emitted nextTick. In a future
    // semver major update we should change the default to this.

    const rState = stream._readableState
    const wState = stream._writableState
    if ((rState && rState.autoDestroy) || (wState && wState.autoDestroy)) {
      stream.destroy(err)
    } else {
      stream.emit('error', err)
    }
  }
  destroy_1$1 = {
    destroy: destroy,
    undestroy: undestroy,
    errorOrDestroy: errorOrDestroy
  }
  return destroy_1$1
}

const errors$2 = {}

let hasRequiredErrors$2
function requireErrors$2() {
  if (hasRequiredErrors$2) {
    return errors$2
  }
  hasRequiredErrors$2 = 1
  const codes = {}
  function createErrorType(code, message, Base) {
    if (!Base) {
      Base = Error
    }
    function getMessage(arg1, arg2, arg3) {
      if (typeof message === 'string') {
        return message
      } else {
        return message(arg1, arg2, arg3)
      }
    }
    class NodeError extends Base {
      constructor(arg1, arg2, arg3) {
        super(getMessage(arg1, arg2, arg3))
      }
    }
    NodeError.prototype.name = Base.name
    NodeError.prototype.code = code
    codes[code] = NodeError
  }

  // https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js
  function oneOf(expected, thing) {
    if (Array.isArray(expected)) {
      const len = expected.length
      expected = expected.map(i => String(i))
      if (len > 2) {
        return (
          `one of ${thing} ${expected.slice(0, len - 1).join(', ')}, or ` +
          expected[len - 1]
        )
      } else if (len === 2) {
        return `one of ${thing} ${expected[0]} or ${expected[1]}`
      } else {
        return `of ${thing} ${expected[0]}`
      }
    } else {
      return `of ${thing} ${String(expected)}`
    }
  }

  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith
  function startsWith(str, search, pos) {
    return str.substr(0, search.length) === search
  }

  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith
  function endsWith(str, search, this_len) {
    if (this_len === undefined || this_len > str.length) {
      this_len = str.length
    }
    return str.substring(this_len - search.length, this_len) === search
  }

  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes
  function includes(str, search, start) {
    if (typeof start !== 'number') {
      start = 0
    }
    if (start + search.length > str.length) {
      return false
    } else {
      return str.indexOf(search, start) !== -1
    }
  }
  createErrorType(
    'ERR_INVALID_OPT_VALUE',
    function (name, value) {
      return 'The value "' + value + '" is invalid for option "' + name + '"'
    },
    TypeError
  )
  createErrorType(
    'ERR_INVALID_ARG_TYPE',
    function (name, expected, actual) {
      // determiner: 'must be' or 'must not be'
      let determiner
      if (typeof expected === 'string' && startsWith(expected, 'not ')) {
        determiner = 'must not be'
        expected = expected.replace(/^not /, '')
      } else {
        determiner = 'must be'
      }
      let msg
      if (endsWith(name, ' argument')) {
        // For cases like 'first argument'
        msg = `The ${name} ${determiner} ${oneOf(expected, 'type')}`
      } else {
        const type = includes(name, '.') ? 'property' : 'argument'
        msg = `The "${name}" ${type} ${determiner} ${oneOf(expected, 'type')}`
      }
      msg += `. Received type ${typeof actual}`
      return msg
    },
    TypeError
  )
  createErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF')
  createErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {
    return 'The ' + name + ' method is not implemented'
  })
  createErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close')
  createErrorType('ERR_STREAM_DESTROYED', function (name) {
    return 'Cannot call ' + name + ' after a stream was destroyed'
  })
  createErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times')
  createErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable')
  createErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end')
  createErrorType(
    'ERR_STREAM_NULL_VALUES',
    'May not write null values to stream',
    TypeError
  )
  createErrorType(
    'ERR_UNKNOWN_ENCODING',
    function (arg) {
      return 'Unknown encoding: ' + arg
    },
    TypeError
  )
  createErrorType(
    'ERR_STREAM_UNSHIFT_AFTER_END_EVENT',
    'stream.unshift() after end event'
  )
  errors$2.codes = codes
  return errors$2
}

let state$1
let hasRequiredState$1
function requireState$1() {
  if (hasRequiredState$1) {
    return state$1
  }
  hasRequiredState$1 = 1
  const ERR_INVALID_OPT_VALUE = requireErrors$2().codes.ERR_INVALID_OPT_VALUE
  function highWaterMarkFrom(options, isDuplex, duplexKey) {
    return options.highWaterMark != null
      ? options.highWaterMark
      : isDuplex
        ? options[duplexKey]
        : null
  }
  function getHighWaterMark(state, options, duplexKey, isDuplex) {
    const hwm = highWaterMarkFrom(options, isDuplex, duplexKey)
    if (hwm != null) {
      if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {
        const name = isDuplex ? duplexKey : 'highWaterMark'
        throw new ERR_INVALID_OPT_VALUE(name, hwm)
      }
      return Math.floor(hwm)
    }

    // Default value
    return state.objectMode ? 16 : 16 * 1024
  }
  state$1 = {
    getHighWaterMark: getHighWaterMark
  }
  return state$1
}

const inherits = { exports: {} }

const inherits_browser = { exports: {} }

let hasRequiredInherits_browser
function requireInherits_browser() {
  if (hasRequiredInherits_browser) {
    return inherits_browser.exports
  }
  hasRequiredInherits_browser = 1
  if (typeof Object.create === 'function') {
    // implementation from standard node.js 'util' module
    inherits_browser.exports = function inherits(ctor, superCtor) {
      if (superCtor) {
        ctor.super_ = superCtor
        ctor.prototype = Object.create(superCtor.prototype, {
          constructor: {
            value: ctor,
            enumerable: false,
            writable: true,
            configurable: true
          }
        })
      }
    }
  } else {
    // old school shim for old browsers
    inherits_browser.exports = function inherits(ctor, superCtor) {
      if (superCtor) {
        ctor.super_ = superCtor
        const TempCtor = function () {}
        TempCtor.prototype = superCtor.prototype
        ctor.prototype = new TempCtor()
        ctor.prototype.constructor = ctor
      }
    }
  }
  return inherits_browser.exports
}

let hasRequiredInherits
function requireInherits() {
  if (hasRequiredInherits) {
    return inherits.exports
  }
  hasRequiredInherits = 1
  try {
    const util = require('node:util')
    /* istanbul ignore next */
    if (typeof util.inherits !== 'function') {
      throw ''
    }
    inherits.exports = util.inherits
  } catch (e) {
    /* istanbul ignore next */
    inherits.exports = requireInherits_browser()
  }
  return inherits.exports
}

let node$1
let hasRequiredNode$1
function requireNode$1() {
  if (hasRequiredNode$1) {
    return node$1
  }
  hasRequiredNode$1 = 1
  /**
   * For Node.js, simply re-export the core `util.deprecate` function.
   */

  node$1 = require$$0$4.deprecate
  return node$1
}

let _stream_writable$1
let hasRequired_stream_writable$1
function require_stream_writable$1() {
  if (hasRequired_stream_writable$1) {
    return _stream_writable$1
  }
  hasRequired_stream_writable$1 = 1
  _stream_writable$1 = Writable

  // It seems a linked list but it is not
  // there will be only 2 of these for each stream
  function CorkedRequest(state) {
    const _this = this
    this.next = null
    this.entry = null
    this.finish = function () {
      onCorkedFinish(_this, state)
    }
  }
  /* </replacement> */

  /*<replacement>*/
  let Duplex
  /*</replacement>*/

  Writable.WritableState = WritableState

  /*<replacement>*/
  const internalUtil = {
    deprecate: requireNode$1()
  }
  /*</replacement>*/

  /*<replacement>*/
  const Stream = requireStream$2()
  /*</replacement>*/

  const Buffer = require$$2$4.Buffer
  const OurUint8Array =
    (typeof global !== 'undefined'
      ? global
      : typeof window !== 'undefined'
        ? window
        : typeof self !== 'undefined'
          ? self
          : {}
    ).Uint8Array || function () {}
  function _uint8ArrayToBuffer(chunk) {
    return Buffer.from(chunk)
  }
  function _isUint8Array(obj) {
    return Buffer.isBuffer(obj) || obj instanceof OurUint8Array
  }
  const destroyImpl = requireDestroy$1()
  const _require = requireState$1(),
    getHighWaterMark = _require.getHighWaterMark
  const _require$codes = requireErrors$2().codes,
    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,
    ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,
    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,
    ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,
    ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,
    ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING
  const errorOrDestroy = destroyImpl.errorOrDestroy
  requireInherits()(Writable, Stream)
  function nop() {}
  function WritableState(options, stream, isDuplex) {
    Duplex = Duplex || require_stream_duplex$1()
    options = options || {}

    // Duplex streams are both readable and writable, but share
    // the same options object.
    // However, some cases require setting options to different
    // values for the readable and the writable sides of the duplex stream,
    // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.
    if (typeof isDuplex !== 'boolean') {
      isDuplex = stream instanceof Duplex
    }

    // object stream flag to indicate whether or not this stream
    // contains buffers or objects.
    this.objectMode = !!options.objectMode
    if (isDuplex) {
      this.objectMode = this.objectMode || !!options.writableObjectMode
    }

    // the point at which write() starts returning false
    // Note: 0 is a valid value, means that we always return false if
    // the entire buffer is not flushed immediately on write()
    this.highWaterMark = getHighWaterMark(
      this,
      options,
      'writableHighWaterMark',
      isDuplex
    )

    // if _final has been called
    this.finalCalled = false

    // drain event flag.
    this.needDrain = false
    // at the start of calling end()
    this.ending = false
    // when end() has been called, and returned
    this.ended = false
    // when 'finish' is emitted
    this.finished = false

    // has it been destroyed
    this.destroyed = false

    // should we decode strings into buffers before passing to _write?
    // this is here so that some node-core streams can optimize string
    // handling at a lower level.
    const noDecode = options.decodeStrings === false
    this.decodeStrings = !noDecode

    // Crypto is kind of old and crusty.  Historically, its default string
    // encoding is 'binary' so we have to make this configurable.
    // Everything else in the universe uses 'utf8', though.
    this.defaultEncoding = options.defaultEncoding || 'utf8'

    // not an actual buffer we keep track of, but a measurement
    // of how much we're waiting to get pushed to some underlying
    // socket or file.
    this.length = 0

    // a flag to see when we're in the middle of a write.
    this.writing = false

    // when true all writes will be buffered until .uncork() call
    this.corked = 0

    // a flag to be able to tell if the onwrite cb is called immediately,
    // or on a later tick.  We set this to true at first, because any
    // actions that shouldn't happen until "later" should generally also
    // not happen before the first write call.
    this.sync = true

    // a flag to know if we're processing previously buffered items, which
    // may call the _write() callback in the same tick, so that we don't
    // end up in an overlapped onwrite situation.
    this.bufferProcessing = false

    // the callback that's passed to _write(chunk,cb)
    this.onwrite = function (er) {
      onwrite(stream, er)
    }

    // the callback that the user supplies to write(chunk,encoding,cb)
    this.writecb = null

    // the amount that is being written when _write is called.
    this.writelen = 0
    this.bufferedRequest = null
    this.lastBufferedRequest = null

    // number of pending user-supplied write callbacks
    // this must be 0 before 'finish' can be emitted
    this.pendingcb = 0

    // emit prefinish if the only thing we're waiting for is _write cbs
    // This is relevant for synchronous Transform streams
    this.prefinished = false

    // True if the error was already emitted and should not be thrown again
    this.errorEmitted = false

    // Should close be emitted on destroy. Defaults to true.
    this.emitClose = options.emitClose !== false

    // Should .destroy() be called after 'finish' (and potentially 'end')
    this.autoDestroy = !!options.autoDestroy

    // count buffered requests
    this.bufferedRequestCount = 0

    // allocate the first CorkedRequest, there is always
    // one allocated and free to use, and we maintain at most two
    this.corkedRequestsFree = new CorkedRequest(this)
  }
  WritableState.prototype.getBuffer = function getBuffer() {
    let current = this.bufferedRequest
    const out = []
    while (current) {
      out.push(current)
      current = current.next
    }
    return out
  }
  ;(function () {
    try {
      Object.defineProperty(WritableState.prototype, 'buffer', {
        get: internalUtil.deprecate(
          function writableStateBufferGetter() {
            return this.getBuffer()
          },
          '_writableState.buffer is deprecated. Use _writableState.getBuffer ' +
            'instead.',
          'DEP0003'
        )
      })
    } catch (_) {}
  })()

  // Test _writableState for inheritance to account for Duplex streams,
  // whose prototype chain only points to Readable.
  let realHasInstance
  if (
    typeof Symbol === 'function' &&
    Symbol.hasInstance &&
    typeof Function.prototype[Symbol.hasInstance] === 'function'
  ) {
    realHasInstance = Function.prototype[Symbol.hasInstance]
    Object.defineProperty(Writable, Symbol.hasInstance, {
      value: function value(object) {
        if (realHasInstance.call(this, object)) {
          return true
        }
        if (this !== Writable) {
          return false
        }
        return object && object._writableState instanceof WritableState
      }
    })
  } else {
    realHasInstance = function realHasInstance(object) {
      return object instanceof this
    }
  }
  function Writable(options) {
    Duplex = Duplex || require_stream_duplex$1()

    // Writable ctor is applied to Duplexes, too.
    // `realHasInstance` is necessary because using plain `instanceof`
    // would return false, as no `_writableState` property is attached.

    // Trying to use the custom `instanceof` for Writable here will also break the
    // Node.js LazyTransform implementation, which has a non-trivial getter for
    // `_writableState` that would lead to infinite recursion.

    // Checking for a Stream.Duplex instance is faster here instead of inside
    // the WritableState constructor, at least with V8 6.5
    const isDuplex = this instanceof Duplex
    if (!isDuplex && !realHasInstance.call(Writable, this)) {
      return new Writable(options)
    }
    this._writableState = new WritableState(options, this, isDuplex)

    // legacy.
    this.writable = true
    if (options) {
      if (typeof options.write === 'function') {
        this._write = options.write
      }
      if (typeof options.writev === 'function') {
        this._writev = options.writev
      }
      if (typeof options.destroy === 'function') {
        this._destroy = options.destroy
      }
      if (typeof options.final === 'function') {
        this._final = options.final
      }
    }
    Stream.call(this)
  }

  // Otherwise people can pipe Writable streams, which is just wrong.
  Writable.prototype.pipe = function () {
    errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE())
  }
  function writeAfterEnd(stream, cb) {
    const er = new ERR_STREAM_WRITE_AFTER_END()
    // TODO: defer error events consistently everywhere, not just the cb
    errorOrDestroy(stream, er)
    process.nextTick(cb, er)
  }

  // Checks that a user-supplied chunk is valid, especially for the particular
  // mode the stream is in. Currently this means that `null` is never accepted
  // and undefined/non-string values are only allowed in object mode.
  function validChunk(stream, state, chunk, cb) {
    let er
    if (chunk === null) {
      er = new ERR_STREAM_NULL_VALUES()
    } else if (typeof chunk !== 'string' && !state.objectMode) {
      er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk)
    }
    if (er) {
      errorOrDestroy(stream, er)
      process.nextTick(cb, er)
      return false
    }
    return true
  }
  Writable.prototype.write = function (chunk, encoding, cb) {
    const state = this._writableState
    let ret = false
    const isBuf = !state.objectMode && _isUint8Array(chunk)
    if (isBuf && !Buffer.isBuffer(chunk)) {
      chunk = _uint8ArrayToBuffer(chunk)
    }
    if (typeof encoding === 'function') {
      cb = encoding
      encoding = null
    }
    if (isBuf) {
      encoding = 'buffer'
    } else if (!encoding) {
      encoding = state.defaultEncoding
    }
    if (typeof cb !== 'function') {
      cb = nop
    }
    if (state.ending) {
      writeAfterEnd(this, cb)
    } else if (isBuf || validChunk(this, state, chunk, cb)) {
      state.pendingcb++
      ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb)
    }
    return ret
  }
  Writable.prototype.cork = function () {
    this._writableState.corked++
  }
  Writable.prototype.uncork = function () {
    const state = this._writableState
    if (state.corked) {
      state.corked--
      if (
        !state.writing &&
        !state.corked &&
        !state.bufferProcessing &&
        state.bufferedRequest
      ) {
        clearBuffer(this, state)
      }
    }
  }
  Writable.prototype.setDefaultEncoding = function setDefaultEncoding(
    encoding
  ) {
    // node::ParseEncoding() requires lower case.
    if (typeof encoding === 'string') {
      encoding = encoding.toLowerCase()
    }
    if (
      !(
        [
          'hex',
          'utf8',
          'utf-8',
          'ascii',
          'binary',
          'base64',
          'ucs2',
          'ucs-2',
          'utf16le',
          'utf-16le',
          'raw'
        ].indexOf((encoding + '').toLowerCase()) > -1
      )
    ) {
      throw new ERR_UNKNOWN_ENCODING(encoding)
    }
    this._writableState.defaultEncoding = encoding
    return this
  }
  Object.defineProperty(Writable.prototype, 'writableBuffer', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState && this._writableState.getBuffer()
    }
  })
  function decodeChunk(state, chunk, encoding) {
    if (
      !state.objectMode &&
      state.decodeStrings !== false &&
      typeof chunk === 'string'
    ) {
      chunk = Buffer.from(chunk, encoding)
    }
    return chunk
  }
  Object.defineProperty(Writable.prototype, 'writableHighWaterMark', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState.highWaterMark
    }
  })

  // if we're already writing something, then just put this
  // in the queue, and wait our turn.  Otherwise, call _write
  // If we return false, then we need a drain event, so set that flag.
  function writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {
    if (!isBuf) {
      const newChunk = decodeChunk(state, chunk, encoding)
      if (chunk !== newChunk) {
        isBuf = true
        encoding = 'buffer'
        chunk = newChunk
      }
    }
    const len = state.objectMode ? 1 : chunk.length
    state.length += len
    const ret = state.length < state.highWaterMark
    // we must ensure that previous needDrain will not be reset to false.
    if (!ret) {
      state.needDrain = true
    }
    if (state.writing || state.corked) {
      const last = state.lastBufferedRequest
      state.lastBufferedRequest = {
        chunk: chunk,
        encoding: encoding,
        isBuf: isBuf,
        callback: cb,
        next: null
      }
      if (last) {
        last.next = state.lastBufferedRequest
      } else {
        state.bufferedRequest = state.lastBufferedRequest
      }
      state.bufferedRequestCount += 1
    } else {
      doWrite(stream, state, false, len, chunk, encoding, cb)
    }
    return ret
  }
  function doWrite(stream, state, writev, len, chunk, encoding, cb) {
    state.writelen = len
    state.writecb = cb
    state.writing = true
    state.sync = true
    if (state.destroyed) {
      state.onwrite(new ERR_STREAM_DESTROYED('write'))
    } else if (writev) {
      stream._writev(chunk, state.onwrite)
    } else {
      stream._write(chunk, encoding, state.onwrite)
    }
    state.sync = false
  }
  function onwriteError(stream, state, sync, er, cb) {
    --state.pendingcb
    if (sync) {
      // defer the callback if we are being called synchronously
      // to avoid piling up things on the stack
      process.nextTick(cb, er)
      // this can emit finish, and it will always happen
      // after error
      process.nextTick(finishMaybe, stream, state)
      stream._writableState.errorEmitted = true
      errorOrDestroy(stream, er)
    } else {
      // the caller expect this to happen before if
      // it is async
      cb(er)
      stream._writableState.errorEmitted = true
      errorOrDestroy(stream, er)
      // this can emit finish, but finish must
      // always follow error
      finishMaybe(stream, state)
    }
  }
  function onwriteStateUpdate(state) {
    state.writing = false
    state.writecb = null
    state.length -= state.writelen
    state.writelen = 0
  }
  function onwrite(stream, er) {
    const state = stream._writableState
    const sync = state.sync
    const cb = state.writecb
    if (typeof cb !== 'function') {
      throw new ERR_MULTIPLE_CALLBACK()
    }
    onwriteStateUpdate(state)
    if (er) {
      onwriteError(stream, state, sync, er, cb)
    } else {
      // Check if we're actually ready to finish, but don't emit yet
      const finished = needFinish(state) || stream.destroyed
      if (
        !finished &&
        !state.corked &&
        !state.bufferProcessing &&
        state.bufferedRequest
      ) {
        clearBuffer(stream, state)
      }
      if (sync) {
        process.nextTick(afterWrite, stream, state, finished, cb)
      } else {
        afterWrite(stream, state, finished, cb)
      }
    }
  }
  function afterWrite(stream, state, finished, cb) {
    if (!finished) {
      onwriteDrain(stream, state)
    }
    state.pendingcb--
    cb()
    finishMaybe(stream, state)
  }

  // Must force callback to be called on nextTick, so that we don't
  // emit 'drain' before the write() consumer gets the 'false' return
  // value, and has a chance to attach a 'drain' listener.
  function onwriteDrain(stream, state) {
    if (state.length === 0 && state.needDrain) {
      state.needDrain = false
      stream.emit('drain')
    }
  }

  // if there's something in the buffer waiting, then process it
  function clearBuffer(stream, state) {
    state.bufferProcessing = true
    let entry = state.bufferedRequest
    if (stream._writev && entry && entry.next) {
      // Fast case, write everything using _writev()
      const l = state.bufferedRequestCount
      const buffer = new Array(l)
      const holder = state.corkedRequestsFree
      holder.entry = entry
      let count = 0
      let allBuffers = true
      while (entry) {
        buffer[count] = entry
        if (!entry.isBuf) {
          allBuffers = false
        }
        entry = entry.next
        count += 1
      }
      buffer.allBuffers = allBuffers
      doWrite(stream, state, true, state.length, buffer, '', holder.finish)

      // doWrite is almost always async, defer these to save a bit of time
      // as the hot path ends with doWrite
      state.pendingcb++
      state.lastBufferedRequest = null
      if (holder.next) {
        state.corkedRequestsFree = holder.next
        holder.next = null
      } else {
        state.corkedRequestsFree = new CorkedRequest(state)
      }
      state.bufferedRequestCount = 0
    } else {
      // Slow case, write chunks one-by-one
      while (entry) {
        const chunk = entry.chunk
        const encoding = entry.encoding
        const cb = entry.callback
        const len = state.objectMode ? 1 : chunk.length
        doWrite(stream, state, false, len, chunk, encoding, cb)
        entry = entry.next
        state.bufferedRequestCount--
        // if we didn't call the onwrite immediately, then
        // it means that we need to wait until it does.
        // also, that means that the chunk and cb are currently
        // being processed, so move the buffer counter past them.
        if (state.writing) {
          break
        }
      }
      if (entry === null) {
        state.lastBufferedRequest = null
      }
    }
    state.bufferedRequest = entry
    state.bufferProcessing = false
  }
  Writable.prototype._write = function (chunk, encoding, cb) {
    cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'))
  }
  Writable.prototype._writev = null
  Writable.prototype.end = function (chunk, encoding, cb) {
    const state = this._writableState
    if (typeof chunk === 'function') {
      cb = chunk
      chunk = null
      encoding = null
    } else if (typeof encoding === 'function') {
      cb = encoding
      encoding = null
    }
    if (chunk !== null && chunk !== undefined) {
      this.write(chunk, encoding)
    }

    // .end() fully uncorks
    if (state.corked) {
      state.corked = 1
      this.uncork()
    }

    // ignore unnecessary end() calls.
    if (!state.ending) {
      endWritable(this, state, cb)
    }
    return this
  }
  Object.defineProperty(Writable.prototype, 'writableLength', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState.length
    }
  })
  function needFinish(state) {
    return (
      state.ending &&
      state.length === 0 &&
      state.bufferedRequest === null &&
      !state.finished &&
      !state.writing
    )
  }
  function callFinal(stream, state) {
    stream._final(function (err) {
      state.pendingcb--
      if (err) {
        errorOrDestroy(stream, err)
      }
      state.prefinished = true
      stream.emit('prefinish')
      finishMaybe(stream, state)
    })
  }
  function prefinish(stream, state) {
    if (!state.prefinished && !state.finalCalled) {
      if (typeof stream._final === 'function' && !state.destroyed) {
        state.pendingcb++
        state.finalCalled = true
        process.nextTick(callFinal, stream, state)
      } else {
        state.prefinished = true
        stream.emit('prefinish')
      }
    }
  }
  function finishMaybe(stream, state) {
    const need = needFinish(state)
    if (need) {
      prefinish(stream, state)
      if (state.pendingcb === 0) {
        state.finished = true
        stream.emit('finish')
        if (state.autoDestroy) {
          // In case of duplex streams we need a way to detect
          // if the readable side is ready for autoDestroy as well
          const rState = stream._readableState
          if (!rState || (rState.autoDestroy && rState.endEmitted)) {
            stream.destroy()
          }
        }
      }
    }
    return need
  }
  function endWritable(stream, state, cb) {
    state.ending = true
    finishMaybe(stream, state)
    if (cb) {
      if (state.finished) {
        process.nextTick(cb)
      } else {
        stream.once('finish', cb)
      }
    }
    state.ended = true
    stream.writable = false
  }
  function onCorkedFinish(corkReq, state, err) {
    let entry = corkReq.entry
    corkReq.entry = null
    while (entry) {
      const cb = entry.callback
      state.pendingcb--
      cb(err)
      entry = entry.next
    }

    // reuse the free corkReq.
    state.corkedRequestsFree.next = corkReq
  }
  Object.defineProperty(Writable.prototype, 'destroyed', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      if (this._writableState === undefined) {
        return false
      }
      return this._writableState.destroyed
    },
    set: function set(value) {
      // we ignore the value if the stream
      // has not been initialized yet
      if (!this._writableState) {
        return
      }

      // backward compatibility, the user is explicitly
      // managing destroyed
      this._writableState.destroyed = value
    }
  })
  Writable.prototype.destroy = destroyImpl.destroy
  Writable.prototype._undestroy = destroyImpl.undestroy
  Writable.prototype._destroy = function (err, cb) {
    cb(err)
  }
  return _stream_writable$1
}

let _stream_duplex$1
let hasRequired_stream_duplex$1
function require_stream_duplex$1() {
  if (hasRequired_stream_duplex$1) {
    return _stream_duplex$1
  }
  hasRequired_stream_duplex$1 = 1

  /*<replacement>*/
  const objectKeys =
    Object.keys ||
    function (obj) {
      const keys = []
      for (const key in obj) {
        keys.push(key)
      }
      return keys
    }
  /*</replacement>*/

  _stream_duplex$1 = Duplex
  const Readable = require_stream_readable$1()
  const Writable = require_stream_writable$1()
  requireInherits()(Duplex, Readable)
  {
    // Allow the keys array to be GC'ed.
    const keys = objectKeys(Writable.prototype)
    for (let v = 0; v < keys.length; v++) {
      const method = keys[v]
      if (!Duplex.prototype[method]) {
        Duplex.prototype[method] = Writable.prototype[method]
      }
    }
  }
  function Duplex(options) {
    if (!(this instanceof Duplex)) {
      return new Duplex(options)
    }
    Readable.call(this, options)
    Writable.call(this, options)
    this.allowHalfOpen = true
    if (options) {
      if (options.readable === false) {
        this.readable = false
      }
      if (options.writable === false) {
        this.writable = false
      }
      if (options.allowHalfOpen === false) {
        this.allowHalfOpen = false
        this.once('end', onend)
      }
    }
  }
  Object.defineProperty(Duplex.prototype, 'writableHighWaterMark', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState.highWaterMark
    }
  })
  Object.defineProperty(Duplex.prototype, 'writableBuffer', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState && this._writableState.getBuffer()
    }
  })
  Object.defineProperty(Duplex.prototype, 'writableLength', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState.length
    }
  })

  // the no-half-open enforcer
  function onend() {
    // If the writable side ended, then we're ok.
    if (this._writableState.ended) {
      return
    }

    // no more data can be written.
    // But allow more writes to happen in this tick.
    process.nextTick(onEndNT, this)
  }
  function onEndNT(self) {
    self.end()
  }
  Object.defineProperty(Duplex.prototype, 'destroyed', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      if (
        this._readableState === undefined ||
        this._writableState === undefined
      ) {
        return false
      }
      return this._readableState.destroyed && this._writableState.destroyed
    },
    set: function set(value) {
      // we ignore the value if the stream
      // has not been initialized yet
      if (
        this._readableState === undefined ||
        this._writableState === undefined
      ) {
        return
      }

      // backward compatibility, the user is explicitly
      // managing destroyed
      this._readableState.destroyed = value
      this._writableState.destroyed = value
    }
  })
  return _stream_duplex$1
}

const string_decoder$1 = {}

let safeBuffer
let hasRequiredSafeBuffer
function requireSafeBuffer() {
  if (hasRequiredSafeBuffer) {
    return safeBuffer
  }
  hasRequiredSafeBuffer = 1

  // Use non-'node:' prefixed require to avoid Webpack errors.
  // eslint-disable-next-line n/prefer-node-protocol
  const { Buffer: UnsafeBuffer } = require$$2$4
  const SafeBuffer = Object.defineProperties(function SafeBuffer(
    arg,
    encodingOrOffset,
    length
  ) {
    return UnsafeBuffer.from(arg, encodingOrOffset, length)
  }, Object.getOwnPropertyDescriptors(UnsafeBuffer))
  safeBuffer = {
    Buffer: SafeBuffer
  }
  return safeBuffer
}

let hasRequiredString_decoder$1
function requireString_decoder$1() {
  if (hasRequiredString_decoder$1) {
    return string_decoder$1
  }
  hasRequiredString_decoder$1 = 1

  /*<replacement>*/

  const Buffer = /*@__PURE__*/ requireSafeBuffer().Buffer
  /*</replacement>*/

  const isEncoding =
    Buffer.isEncoding ||
    function (encoding) {
      encoding = '' + encoding
      switch (encoding && encoding.toLowerCase()) {
        case 'hex':
        case 'utf8':
        case 'utf-8':
        case 'ascii':
        case 'binary':
        case 'base64':
        case 'ucs2':
        case 'ucs-2':
        case 'utf16le':
        case 'utf-16le':
        case 'raw':
          return true
        default:
          return false
      }
    }
  function _normalizeEncoding(enc) {
    if (!enc) {
      return 'utf8'
    }
    let retried
    while (true) {
      switch (enc) {
        case 'utf8':
        case 'utf-8':
          return 'utf8'
        case 'ucs2':
        case 'ucs-2':
        case 'utf16le':
        case 'utf-16le':
          return 'utf16le'
        case 'latin1':
        case 'binary':
          return 'latin1'
        case 'base64':
        case 'ascii':
        case 'hex':
          return enc
        default:
          if (retried) {
            return
          } // undefined
          enc = ('' + enc).toLowerCase()
          retried = true
      }
    }
  }

  // Do not cache `Buffer.isEncoding` when checking encoding names as some
  // modules monkey-patch it to support additional encodings
  function normalizeEncoding(enc) {
    const nenc = _normalizeEncoding(enc)
    if (
      typeof nenc !== 'string' &&
      (Buffer.isEncoding === isEncoding || !isEncoding(enc))
    ) {
      throw new Error('Unknown encoding: ' + enc)
    }
    return nenc || enc
  }

  // StringDecoder provides an interface for efficiently splitting a series of
  // buffers into a series of JS strings without breaking apart multi-byte
  // characters.
  string_decoder$1.StringDecoder = StringDecoder
  function StringDecoder(encoding) {
    this.encoding = normalizeEncoding(encoding)
    let nb
    switch (this.encoding) {
      case 'utf16le':
        this.text = utf16Text
        this.end = utf16End
        nb = 4
        break
      case 'utf8':
        this.fillLast = utf8FillLast
        nb = 4
        break
      case 'base64':
        this.text = base64Text
        this.end = base64End
        nb = 3
        break
      default:
        this.write = simpleWrite
        this.end = simpleEnd
        return
    }
    this.lastNeed = 0
    this.lastTotal = 0
    this.lastChar = Buffer.allocUnsafe(nb)
  }
  StringDecoder.prototype.write = function (buf) {
    if (buf.length === 0) {
      return ''
    }
    let r
    let i
    if (this.lastNeed) {
      r = this.fillLast(buf)
      if (r === undefined) {
        return ''
      }
      i = this.lastNeed
      this.lastNeed = 0
    } else {
      i = 0
    }
    if (i < buf.length) {
      return r ? r + this.text(buf, i) : this.text(buf, i)
    }
    return r || ''
  }
  StringDecoder.prototype.end = utf8End

  // Returns only complete characters in a Buffer
  StringDecoder.prototype.text = utf8Text

  // Attempts to complete a partial non-UTF-8 character using bytes from a Buffer
  StringDecoder.prototype.fillLast = function (buf) {
    if (this.lastNeed <= buf.length) {
      buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed)
      return this.lastChar.toString(this.encoding, 0, this.lastTotal)
    }
    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length)
    this.lastNeed -= buf.length
  }

  // Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a
  // continuation byte. If an invalid byte is detected, -2 is returned.
  function utf8CheckByte(byte) {
    if (byte <= 0x7f) {
      return 0
    } else if (byte >> 5 === 0x06) {
      return 2
    } else if (byte >> 4 === 0x0e) {
      return 3
    } else if (byte >> 3 === 0x1e) {
      return 4
    }
    return byte >> 6 === 0x02 ? -1 : -2
  }

  // Checks at most 3 bytes at the end of a Buffer in order to detect an
  // incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)
  // needed to complete the UTF-8 character (if applicable) are returned.
  function utf8CheckIncomplete(self, buf, i) {
    let j = buf.length - 1
    if (j < i) {
      return 0
    }
    let nb = utf8CheckByte(buf[j])
    if (nb >= 0) {
      if (nb > 0) {
        self.lastNeed = nb - 1
      }
      return nb
    }
    if (--j < i || nb === -2) {
      return 0
    }
    nb = utf8CheckByte(buf[j])
    if (nb >= 0) {
      if (nb > 0) {
        self.lastNeed = nb - 2
      }
      return nb
    }
    if (--j < i || nb === -2) {
      return 0
    }
    nb = utf8CheckByte(buf[j])
    if (nb >= 0) {
      if (nb > 0) {
        if (nb === 2) {
          nb = 0
        } else {
          self.lastNeed = nb - 3
        }
      }
      return nb
    }
    return 0
  }

  // Validates as many continuation bytes for a multi-byte UTF-8 character as
  // needed or are available. If we see a non-continuation byte where we expect
  // one, we "replace" the validated continuation bytes we've seen so far with
  // a single UTF-8 replacement character ('\ufffd'), to match v8's UTF-8 decoding
  // behavior. The continuation byte check is included three times in the case
  // where all of the continuation bytes for a character exist in the same buffer.
  // It is also done this way as a slight performance increase instead of using a
  // loop.
  function utf8CheckExtraBytes(self, buf, p) {
    if ((buf[0] & 0xc0) !== 0x80) {
      self.lastNeed = 0
      return '\ufffd'
    }
    if (self.lastNeed > 1 && buf.length > 1) {
      if ((buf[1] & 0xc0) !== 0x80) {
        self.lastNeed = 1
        return '\ufffd'
      }
      if (self.lastNeed > 2 && buf.length > 2) {
        if ((buf[2] & 0xc0) !== 0x80) {
          self.lastNeed = 2
          return '\ufffd'
        }
      }
    }
  }

  // Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.
  function utf8FillLast(buf) {
    const p = this.lastTotal - this.lastNeed
    const r = utf8CheckExtraBytes(this, buf)
    if (r !== undefined) {
      return r
    }
    if (this.lastNeed <= buf.length) {
      buf.copy(this.lastChar, p, 0, this.lastNeed)
      return this.lastChar.toString(this.encoding, 0, this.lastTotal)
    }
    buf.copy(this.lastChar, p, 0, buf.length)
    this.lastNeed -= buf.length
  }

  // Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a
  // partial character, the character's bytes are buffered until the required
  // number of bytes are available.
  function utf8Text(buf, i) {
    const total = utf8CheckIncomplete(this, buf, i)
    if (!this.lastNeed) {
      return buf.toString('utf8', i)
    }
    this.lastTotal = total
    const end = buf.length - (total - this.lastNeed)
    buf.copy(this.lastChar, 0, end)
    return buf.toString('utf8', i, end)
  }

  // For UTF-8, a replacement character is added when ending on a partial
  // character.
  function utf8End(buf) {
    const r = buf && buf.length ? this.write(buf) : ''
    if (this.lastNeed) {
      return r + '\ufffd'
    }
    return r
  }

  // UTF-16LE typically needs two bytes per character, but even if we have an even
  // number of bytes available, we need to check if we end on a leading/high
  // surrogate. In that case, we need to wait for the next two bytes in order to
  // decode the last character properly.
  function utf16Text(buf, i) {
    if ((buf.length - i) % 2 === 0) {
      const r = buf.toString('utf16le', i)
      if (r) {
        const c = r.charCodeAt(r.length - 1)
        if (c >= 0xd800 && c <= 0xdbff) {
          this.lastNeed = 2
          this.lastTotal = 4
          this.lastChar[0] = buf[buf.length - 2]
          this.lastChar[1] = buf[buf.length - 1]
          return r.slice(0, -1)
        }
      }
      return r
    }
    this.lastNeed = 1
    this.lastTotal = 2
    this.lastChar[0] = buf[buf.length - 1]
    return buf.toString('utf16le', i, buf.length - 1)
  }

  // For UTF-16LE we do not explicitly append special replacement characters if we
  // end on a partial character, we simply let v8 handle that.
  function utf16End(buf) {
    const r = buf && buf.length ? this.write(buf) : ''
    if (this.lastNeed) {
      const end = this.lastTotal - this.lastNeed
      return r + this.lastChar.toString('utf16le', 0, end)
    }
    return r
  }
  function base64Text(buf, i) {
    const n = (buf.length - i) % 3
    if (n === 0) {
      return buf.toString('base64', i)
    }
    this.lastNeed = 3 - n
    this.lastTotal = 3
    if (n === 1) {
      this.lastChar[0] = buf[buf.length - 1]
    } else {
      this.lastChar[0] = buf[buf.length - 2]
      this.lastChar[1] = buf[buf.length - 1]
    }
    return buf.toString('base64', i, buf.length - n)
  }
  function base64End(buf) {
    const r = buf && buf.length ? this.write(buf) : ''
    if (this.lastNeed) {
      return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed)
    }
    return r
  }

  // Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)
  function simpleWrite(buf) {
    return buf.toString(this.encoding)
  }
  function simpleEnd(buf) {
    return buf && buf.length ? this.write(buf) : ''
  }
  return string_decoder$1
}

let endOfStream$1
let hasRequiredEndOfStream$1
function requireEndOfStream$1() {
  if (hasRequiredEndOfStream$1) {
    return endOfStream$1
  }
  hasRequiredEndOfStream$1 = 1
  const ERR_STREAM_PREMATURE_CLOSE =
    requireErrors$2().codes.ERR_STREAM_PREMATURE_CLOSE
  function once(callback) {
    let called = false
    return function () {
      if (called) {
        return
      }
      called = true
      for (
        let _len = arguments.length, args = new Array(_len), _key = 0;
        _key < _len;
        _key++
      ) {
        args[_key] = arguments[_key]
      }
      callback.apply(this, args)
    }
  }
  function noop() {}
  function isRequest(stream) {
    return stream.setHeader && typeof stream.abort === 'function'
  }
  function eos(stream, opts, callback) {
    if (typeof opts === 'function') {
      return eos(stream, null, opts)
    }
    if (!opts) {
      opts = {}
    }
    callback = once(callback || noop)
    let readable = opts.readable || (opts.readable !== false && stream.readable)
    let writable = opts.writable || (opts.writable !== false && stream.writable)
    const onlegacyfinish = function onlegacyfinish() {
      if (!stream.writable) {
        onfinish()
      }
    }
    let writableEnded = stream._writableState && stream._writableState.finished
    const onfinish = function onfinish() {
      writable = false
      writableEnded = true
      if (!readable) {
        callback.call(stream)
      }
    }
    let readableEnded =
      stream._readableState && stream._readableState.endEmitted
    const onend = function onend() {
      readable = false
      readableEnded = true
      if (!writable) {
        callback.call(stream)
      }
    }
    const onerror = function onerror(err) {
      callback.call(stream, err)
    }
    const onclose = function onclose() {
      let err
      if (readable && !readableEnded) {
        if (!stream._readableState || !stream._readableState.ended) {
          err = new ERR_STREAM_PREMATURE_CLOSE()
        }
        return callback.call(stream, err)
      }
      if (writable && !writableEnded) {
        if (!stream._writableState || !stream._writableState.ended) {
          err = new ERR_STREAM_PREMATURE_CLOSE()
        }
        return callback.call(stream, err)
      }
    }
    const onrequest = function onrequest() {
      stream.req.on('finish', onfinish)
    }
    if (isRequest(stream)) {
      stream.on('complete', onfinish)
      stream.on('abort', onclose)
      if (stream.req) {
        onrequest()
      } else {
        stream.on('request', onrequest)
      }
    } else if (writable && !stream._writableState) {
      // legacy streams
      stream.on('end', onlegacyfinish)
      stream.on('close', onlegacyfinish)
    }
    stream.on('end', onend)
    stream.on('finish', onfinish)
    if (opts.error !== false) {
      stream.on('error', onerror)
    }
    stream.on('close', onclose)
    return function () {
      stream.removeListener('complete', onfinish)
      stream.removeListener('abort', onclose)
      stream.removeListener('request', onrequest)
      if (stream.req) {
        stream.req.removeListener('finish', onfinish)
      }
      stream.removeListener('end', onlegacyfinish)
      stream.removeListener('close', onlegacyfinish)
      stream.removeListener('finish', onfinish)
      stream.removeListener('end', onend)
      stream.removeListener('error', onerror)
      stream.removeListener('close', onclose)
    }
  }
  endOfStream$1 = eos
  return endOfStream$1
}

let async_iterator$1
let hasRequiredAsync_iterator$1
function requireAsync_iterator$1() {
  if (hasRequiredAsync_iterator$1) {
    return async_iterator$1
  }
  hasRequiredAsync_iterator$1 = 1
  let _Object$setPrototypeO
  function _defineProperty(obj, key, value) {
    key = _toPropertyKey(key)
    if (key in obj) {
      Object.defineProperty(obj, key, {
        value: value,
        enumerable: true,
        configurable: true,
        writable: true
      })
    } else {
      obj[key] = value
    }
    return obj
  }
  function _toPropertyKey(arg) {
    const key = _toPrimitive(arg, 'string')
    return typeof key === 'symbol' ? key : String(key)
  }
  function _toPrimitive(input, hint) {
    if (typeof input !== 'object' || input === null) {
      return input
    }
    const prim = input[Symbol.toPrimitive]
    if (prim !== undefined) {
      const res = prim.call(input, hint)
      if (typeof res !== 'object') {
        return res
      }
      throw new TypeError('@@toPrimitive must return a primitive value.')
    }
    return (hint === 'string' ? String : Number)(input)
  }
  const finished = requireEndOfStream$1()
  const kLastResolve = Symbol('lastResolve')
  const kLastReject = Symbol('lastReject')
  const kError = Symbol('error')
  const kEnded = Symbol('ended')
  const kLastPromise = Symbol('lastPromise')
  const kHandlePromise = Symbol('handlePromise')
  const kStream = Symbol('stream')
  function createIterResult(value, done) {
    return {
      value: value,
      done: done
    }
  }
  function readAndResolve(iter) {
    const resolve = iter[kLastResolve]
    if (resolve !== null) {
      const data = iter[kStream].read()
      // we defer if data is null
      // we can be expecting either 'end' or
      // 'error'
      if (data !== null) {
        iter[kLastPromise] = null
        iter[kLastResolve] = null
        iter[kLastReject] = null
        resolve(createIterResult(data, false))
      }
    }
  }
  function onReadable(iter) {
    // we wait for the next tick, because it might
    // emit an error with process.nextTick
    process.nextTick(readAndResolve, iter)
  }
  function wrapForNext(lastPromise, iter) {
    return function (resolve, reject) {
      lastPromise.then(function () {
        if (iter[kEnded]) {
          resolve(createIterResult(undefined, true))
          return
        }
        iter[kHandlePromise](resolve, reject)
      }, reject)
    }
  }
  const AsyncIteratorPrototype = Object.getPrototypeOf(function () {})
  const ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf(
    ((_Object$setPrototypeO = {
      get stream() {
        return this[kStream]
      },
      next: function next() {
        const _this = this
        // if we have detected an error in the meanwhile
        // reject straight away
        const error = this[kError]
        if (error !== null) {
          return Promise.reject(error)
        }
        if (this[kEnded]) {
          return Promise.resolve(createIterResult(undefined, true))
        }
        if (this[kStream].destroyed) {
          // We need to defer via nextTick because if .destroy(err) is
          // called, the error will be emitted via nextTick, and
          // we cannot guarantee that there is no error lingering around
          // waiting to be emitted.
          return new Promise(function (resolve, reject) {
            process.nextTick(function () {
              if (_this[kError]) {
                reject(_this[kError])
              } else {
                resolve(createIterResult(undefined, true))
              }
            })
          })
        }

        // if we have multiple next() calls
        // we will wait for the previous Promise to finish
        // this logic is optimized to support for await loops,
        // where next() is only called once at a time
        const lastPromise = this[kLastPromise]
        let promise
        if (lastPromise) {
          promise = new Promise(wrapForNext(lastPromise, this))
        } else {
          // fast path needed to support multiple this.push()
          // without triggering the next() queue
          const data = this[kStream].read()
          if (data !== null) {
            return Promise.resolve(createIterResult(data, false))
          }
          promise = new Promise(this[kHandlePromise])
        }
        this[kLastPromise] = promise
        return promise
      }
    }),
    _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {
      return this
    }),
    _defineProperty(_Object$setPrototypeO, 'return', function _return() {
      const _this2 = this
      // destroy(err, cb) is a private API
      // we can guarantee we have that here, because we control the
      // Readable class this is attached to
      return new Promise(function (resolve, reject) {
        _this2[kStream].destroy(null, function (err) {
          if (err) {
            reject(err)
            return
          }
          resolve(createIterResult(undefined, true))
        })
      })
    }),
    _Object$setPrototypeO),
    AsyncIteratorPrototype
  )
  const createReadableStreamAsyncIterator =
    function createReadableStreamAsyncIterator(stream) {
      let _Object$create
      const iterator = Object.create(
        ReadableStreamAsyncIteratorPrototype,
        ((_Object$create = {}),
        _defineProperty(_Object$create, kStream, {
          value: stream,
          writable: true
        }),
        _defineProperty(_Object$create, kLastResolve, {
          value: null,
          writable: true
        }),
        _defineProperty(_Object$create, kLastReject, {
          value: null,
          writable: true
        }),
        _defineProperty(_Object$create, kError, {
          value: null,
          writable: true
        }),
        _defineProperty(_Object$create, kEnded, {
          value: stream._readableState.endEmitted,
          writable: true
        }),
        _defineProperty(_Object$create, kHandlePromise, {
          value: function value(resolve, reject) {
            const data = iterator[kStream].read()
            if (data) {
              iterator[kLastPromise] = null
              iterator[kLastResolve] = null
              iterator[kLastReject] = null
              resolve(createIterResult(data, false))
            } else {
              iterator[kLastResolve] = resolve
              iterator[kLastReject] = reject
            }
          },
          writable: true
        }),
        _Object$create)
      )
      iterator[kLastPromise] = null
      finished(stream, function (err) {
        if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {
          const reject = iterator[kLastReject]
          // reject if we are waiting for data in the Promise
          // returned by next() and store the error
          if (reject !== null) {
            iterator[kLastPromise] = null
            iterator[kLastResolve] = null
            iterator[kLastReject] = null
            reject(err)
          }
          iterator[kError] = err
          return
        }
        const resolve = iterator[kLastResolve]
        if (resolve !== null) {
          iterator[kLastPromise] = null
          iterator[kLastResolve] = null
          iterator[kLastReject] = null
          resolve(createIterResult(undefined, true))
        }
        iterator[kEnded] = true
      })
      stream.on('readable', onReadable.bind(null, iterator))
      return iterator
    }
  async_iterator$1 = createReadableStreamAsyncIterator
  return async_iterator$1
}

let from_1$1
let hasRequiredFrom$1
function requireFrom$1() {
  if (hasRequiredFrom$1) {
    return from_1$1
  }
  hasRequiredFrom$1 = 1
  function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) {
    try {
      const info = gen[key](arg)
      const value = info.value
    } catch (error) {
      reject(error)
      return
    }
    if (info.done) {
      resolve(value)
    } else {
      Promise.resolve(value).then(_next, _throw)
    }
  }
  function _asyncToGenerator(fn) {
    return function () {
      const self = this,
        args = arguments
      return new Promise(function (resolve, reject) {
        const gen = fn.apply(self, args)
        function _next(value) {
          asyncGeneratorStep(gen, resolve, reject, _next, _throw, 'next', value)
        }
        function _throw(err) {
          asyncGeneratorStep(gen, resolve, reject, _next, _throw, 'throw', err)
        }
        _next(undefined)
      })
    }
  }
  function ownKeys(object, enumerableOnly) {
    const keys = Object.keys(object)
    if (Object.getOwnPropertySymbols) {
      let symbols = Object.getOwnPropertySymbols(object)
      enumerableOnly &&
        (symbols = symbols.filter(function (sym) {
          return Object.getOwnPropertyDescriptor(object, sym).enumerable
        })),
        keys.push.apply(keys, symbols)
    }
    return keys
  }
  function _objectSpread(target) {
    for (let i = 1; i < arguments.length; i++) {
      const source = null != arguments[i] ? arguments[i] : {}
      i % 2
        ? ownKeys(Object(source), true).forEach(function (key) {
            _defineProperty(target, key, source[key])
          })
        : Object.getOwnPropertyDescriptors
          ? Object.defineProperties(
              target,
              Object.getOwnPropertyDescriptors(source)
            )
          : ownKeys(Object(source)).forEach(function (key) {
              Object.defineProperty(
                target,
                key,
                Object.getOwnPropertyDescriptor(source, key)
              )
            })
    }
    return target
  }
  function _defineProperty(obj, key, value) {
    key = _toPropertyKey(key)
    if (key in obj) {
      Object.defineProperty(obj, key, {
        value: value,
        enumerable: true,
        configurable: true,
        writable: true
      })
    } else {
      obj[key] = value
    }
    return obj
  }
  function _toPropertyKey(arg) {
    const key = _toPrimitive(arg, 'string')
    return typeof key === 'symbol' ? key : String(key)
  }
  function _toPrimitive(input, hint) {
    if (typeof input !== 'object' || input === null) {
      return input
    }
    const prim = input[Symbol.toPrimitive]
    if (prim !== undefined) {
      const res = prim.call(input, hint)
      if (typeof res !== 'object') {
        return res
      }
      throw new TypeError('@@toPrimitive must return a primitive value.')
    }
    return (hint === 'string' ? String : Number)(input)
  }
  const ERR_INVALID_ARG_TYPE = requireErrors$2().codes.ERR_INVALID_ARG_TYPE
  function from(Readable, iterable, opts) {
    let iterator
    if (iterable && typeof iterable.next === 'function') {
      iterator = iterable
    } else if (iterable && iterable[Symbol.asyncIterator]) {
      iterator = iterable[Symbol.asyncIterator]()
    } else if (iterable && iterable[Symbol.iterator]) {
      iterator = iterable[Symbol.iterator]()
    } else {
      throw new ERR_INVALID_ARG_TYPE('iterable', ['Iterable'], iterable)
    }
    const readable = new Readable(
      _objectSpread(
        {
          objectMode: true
        },
        opts
      )
    )
    // Reading boolean to protect against _read
    // being called before last iteration completion.
    let reading = false
    readable._read = function () {
      if (!reading) {
        reading = true
        next()
      }
    }
    function next() {
      return _next2.apply(this, arguments)
    }
    function _next2() {
      _next2 = _asyncToGenerator(function* () {
        try {
          const _yield$iterator$next = yield iterator.next(),
            value = _yield$iterator$next.value,
            done = _yield$iterator$next.done
          if (done) {
            readable.push(null)
          } else if (readable.push(yield value)) {
            next()
          } else {
            reading = false
          }
        } catch (err) {
          readable.destroy(err)
        }
      })
      return _next2.apply(this, arguments)
    }
    return readable
  }
  from_1$1 = from
  return from_1$1
}

let _stream_readable$1
let hasRequired_stream_readable$1
function require_stream_readable$1() {
  if (hasRequired_stream_readable$1) {
    return _stream_readable$1
  }
  hasRequired_stream_readable$1 = 1
  _stream_readable$1 = Readable

  /*<replacement>*/
  let Duplex
  /*</replacement>*/

  Readable.ReadableState = ReadableState

  /*<replacement>*/
  require$$0$h.EventEmitter
  const EElistenerCount = function EElistenerCount(emitter, type) {
    return emitter.listeners(type).length
  }
  /*</replacement>*/

  /*<replacement>*/
  const Stream = requireStream$2()
  /*</replacement>*/

  const Buffer = require$$2$4.Buffer
  const OurUint8Array =
    (typeof global !== 'undefined'
      ? global
      : typeof window !== 'undefined'
        ? window
        : typeof self !== 'undefined'
          ? self
          : {}
    ).Uint8Array || function () {}
  function _uint8ArrayToBuffer(chunk) {
    return Buffer.from(chunk)
  }
  function _isUint8Array(obj) {
    return Buffer.isBuffer(obj) || obj instanceof OurUint8Array
  }

  /*<replacement>*/
  const debugUtil = require$$0$4
  let debug
  if (debugUtil && debugUtil.debuglog) {
    debug = debugUtil.debuglog('stream')
  } else {
    debug = function debug() {}
  }
  /*</replacement>*/

  const BufferList = requireBuffer_list$1()
  const destroyImpl = requireDestroy$1()
  const _require = requireState$1(),
    getHighWaterMark = _require.getHighWaterMark
  const _require$codes = requireErrors$2().codes,
    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,
    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_STREAM_UNSHIFT_AFTER_END_EVENT =
      _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT

  // Lazy loaded to improve the startup performance.
  let StringDecoder
  let createReadableStreamAsyncIterator
  let from
  requireInherits()(Readable, Stream)
  const errorOrDestroy = destroyImpl.errorOrDestroy
  const kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume']
  function prependListener(emitter, event, fn) {
    // Sadly this is not cacheable as some libraries bundle their own
    // event emitter implementation with them.
    if (typeof emitter.prependListener === 'function') {
      return emitter.prependListener(event, fn)
    }

    // This is a hack to make sure that our error handler is attached before any
    // userland ones.  NEVER DO THIS. This is here only because this code needs
    // to continue to work with older versions of Node.js that do not include
    // the prependListener() method. The goal is to eventually remove this hack.
    if (!emitter._events || !emitter._events[event]) {
      emitter.on(event, fn)
    } else if (Array.isArray(emitter._events[event])) {
      emitter._events[event].unshift(fn)
    } else {
      emitter._events[event] = [fn, emitter._events[event]]
    }
  }
  function ReadableState(options, stream, isDuplex) {
    Duplex = Duplex || require_stream_duplex$1()
    options = options || {}

    // Duplex streams are both readable and writable, but share
    // the same options object.
    // However, some cases require setting options to different
    // values for the readable and the writable sides of the duplex stream.
    // These options can be provided separately as readableXXX and writableXXX.
    if (typeof isDuplex !== 'boolean') {
      isDuplex = stream instanceof Duplex
    }

    // object stream flag. Used to make read(n) ignore n and to
    // make all the buffer merging and length checks go away
    this.objectMode = !!options.objectMode
    if (isDuplex) {
      this.objectMode = this.objectMode || !!options.readableObjectMode
    }

    // the point at which it stops calling _read() to fill the buffer
    // Note: 0 is a valid value, means "don't call _read preemptively ever"
    this.highWaterMark = getHighWaterMark(
      this,
      options,
      'readableHighWaterMark',
      isDuplex
    )

    // A linked list is used to store data chunks instead of an array because the
    // linked list can remove elements from the beginning faster than
    // array.shift()
    this.buffer = new BufferList()
    this.length = 0
    this.pipes = null
    this.pipesCount = 0
    this.flowing = null
    this.ended = false
    this.endEmitted = false
    this.reading = false

    // a flag to be able to tell if the event 'readable'/'data' is emitted
    // immediately, or on a later tick.  We set this to true at first, because
    // any actions that shouldn't happen until "later" should generally also
    // not happen before the first read call.
    this.sync = true

    // whenever we return null, then we set a flag to say
    // that we're awaiting a 'readable' event emission.
    this.needReadable = false
    this.emittedReadable = false
    this.readableListening = false
    this.resumeScheduled = false
    this.paused = true

    // Should close be emitted on destroy. Defaults to true.
    this.emitClose = options.emitClose !== false

    // Should .destroy() be called after 'end' (and potentially 'finish')
    this.autoDestroy = !!options.autoDestroy

    // has it been destroyed
    this.destroyed = false

    // Crypto is kind of old and crusty.  Historically, its default string
    // encoding is 'binary' so we have to make this configurable.
    // Everything else in the universe uses 'utf8', though.
    this.defaultEncoding = options.defaultEncoding || 'utf8'

    // the number of writers that are awaiting a drain event in .pipe()s
    this.awaitDrain = 0

    // if true, a maybeReadMore has been scheduled
    this.readingMore = false
    this.decoder = null
    this.encoding = null
    if (options.encoding) {
      if (!StringDecoder) {
        StringDecoder = requireString_decoder$1().StringDecoder
      }
      this.decoder = new StringDecoder(options.encoding)
      this.encoding = options.encoding
    }
  }
  function Readable(options) {
    Duplex = Duplex || require_stream_duplex$1()
    if (!(this instanceof Readable)) {
      return new Readable(options)
    }

    // Checking for a Stream.Duplex instance is faster here instead of inside
    // the ReadableState constructor, at least with V8 6.5
    const isDuplex = this instanceof Duplex
    this._readableState = new ReadableState(options, this, isDuplex)

    // legacy
    this.readable = true
    if (options) {
      if (typeof options.read === 'function') {
        this._read = options.read
      }
      if (typeof options.destroy === 'function') {
        this._destroy = options.destroy
      }
    }
    Stream.call(this)
  }
  Object.defineProperty(Readable.prototype, 'destroyed', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      if (this._readableState === undefined) {
        return false
      }
      return this._readableState.destroyed
    },
    set: function set(value) {
      // we ignore the value if the stream
      // has not been initialized yet
      if (!this._readableState) {
        return
      }

      // backward compatibility, the user is explicitly
      // managing destroyed
      this._readableState.destroyed = value
    }
  })
  Readable.prototype.destroy = destroyImpl.destroy
  Readable.prototype._undestroy = destroyImpl.undestroy
  Readable.prototype._destroy = function (err, cb) {
    cb(err)
  }

  // Manually shove something into the read() buffer.
  // This returns true if the highWaterMark has not been hit yet,
  // similar to how Writable.write() returns true if you should
  // write() some more.
  Readable.prototype.push = function (chunk, encoding) {
    const state = this._readableState
    let skipChunkCheck
    if (!state.objectMode) {
      if (typeof chunk === 'string') {
        encoding = encoding || state.defaultEncoding
        if (encoding !== state.encoding) {
          chunk = Buffer.from(chunk, encoding)
          encoding = ''
        }
        skipChunkCheck = true
      }
    } else {
      skipChunkCheck = true
    }
    return readableAddChunk(this, chunk, encoding, false, skipChunkCheck)
  }

  // Unshift should *always* be something directly out of read()
  Readable.prototype.unshift = function (chunk) {
    return readableAddChunk(this, chunk, null, true, false)
  }
  function readableAddChunk(
    stream,
    chunk,
    encoding,
    addToFront,
    skipChunkCheck
  ) {
    debug('readableAddChunk', chunk)
    const state = stream._readableState
    if (chunk === null) {
      state.reading = false
      onEofChunk(stream, state)
    } else {
      let er
      if (!skipChunkCheck) {
        er = chunkInvalid(state, chunk)
      }
      if (er) {
        errorOrDestroy(stream, er)
      } else if (state.objectMode || (chunk && chunk.length > 0)) {
        if (
          typeof chunk !== 'string' &&
          !state.objectMode &&
          Object.getPrototypeOf(chunk) !== Buffer.prototype
        ) {
          chunk = _uint8ArrayToBuffer(chunk)
        }
        if (addToFront) {
          if (state.endEmitted) {
            errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT())
          } else {
            addChunk(stream, state, chunk, true)
          }
        } else if (state.ended) {
          errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF())
        } else if (state.destroyed) {
          return false
        } else {
          state.reading = false
          if (state.decoder && !encoding) {
            chunk = state.decoder.write(chunk)
            if (state.objectMode || chunk.length !== 0) {
              addChunk(stream, state, chunk, false)
            } else {
              maybeReadMore(stream, state)
            }
          } else {
            addChunk(stream, state, chunk, false)
          }
        }
      } else if (!addToFront) {
        state.reading = false
        maybeReadMore(stream, state)
      }
    }

    // We can push more data if we are below the highWaterMark.
    // Also, if we have no data yet, we can stand some more bytes.
    // This is to work around cases where hwm=0, such as the repl.
    return (
      !state.ended && (state.length < state.highWaterMark || state.length === 0)
    )
  }
  function addChunk(stream, state, chunk, addToFront) {
    if (state.flowing && state.length === 0 && !state.sync) {
      state.awaitDrain = 0
      stream.emit('data', chunk)
    } else {
      // update the buffer info.
      state.length += state.objectMode ? 1 : chunk.length
      if (addToFront) {
        state.buffer.unshift(chunk)
      } else {
        state.buffer.push(chunk)
      }
      if (state.needReadable) {
        emitReadable(stream)
      }
    }
    maybeReadMore(stream, state)
  }
  function chunkInvalid(state, chunk) {
    let er
    if (
      !_isUint8Array(chunk) &&
      typeof chunk !== 'string' &&
      chunk !== undefined &&
      !state.objectMode
    ) {
      er = new ERR_INVALID_ARG_TYPE(
        'chunk',
        ['string', 'Buffer', 'Uint8Array'],
        chunk
      )
    }
    return er
  }
  Readable.prototype.isPaused = function () {
    return this._readableState.flowing === false
  }

  // backwards compatibility.
  Readable.prototype.setEncoding = function (enc) {
    if (!StringDecoder) {
      StringDecoder = requireString_decoder$1().StringDecoder
    }
    const decoder = new StringDecoder(enc)
    this._readableState.decoder = decoder
    // If setEncoding(null), decoder.encoding equals utf8
    this._readableState.encoding = this._readableState.decoder.encoding

    // Iterate over current buffer to convert already stored Buffers:
    let p = this._readableState.buffer.head
    let content = ''
    while (p !== null) {
      content += decoder.write(p.data)
      p = p.next
    }
    this._readableState.buffer.clear()
    if (content !== '') {
      this._readableState.buffer.push(content)
    }
    this._readableState.length = content.length
    return this
  }

  // Don't raise the hwm > 1GB
  const MAX_HWM = 0x40000000
  function computeNewHighWaterMark(n) {
    if (n >= MAX_HWM) {
      // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.
      n = MAX_HWM
    } else {
      // Get the next highest power of 2 to prevent increasing hwm excessively in
      // tiny amounts
      n--
      n |= n >>> 1
      n |= n >>> 2
      n |= n >>> 4
      n |= n >>> 8
      n |= n >>> 16
      n++
    }
    return n
  }

  // This function is designed to be inlinable, so please take care when making
  // changes to the function body.
  function howMuchToRead(n, state) {
    if (n <= 0 || (state.length === 0 && state.ended)) {
      return 0
    }
    if (state.objectMode) {
      return 1
    }
    if (n !== n) {
      // Only flow one buffer at a time
      if (state.flowing && state.length) {
        return state.buffer.head.data.length
      } else {
        return state.length
      }
    }
    // If we're asking for more than the current hwm, then raise the hwm.
    if (n > state.highWaterMark) {
      state.highWaterMark = computeNewHighWaterMark(n)
    }
    if (n <= state.length) {
      return n
    }
    // Don't have enough
    if (!state.ended) {
      state.needReadable = true
      return 0
    }
    return state.length
  }

  // you can override either this method, or the async _read(n) below.
  Readable.prototype.read = function (n) {
    debug('read', n)
    n = parseInt(n, 10)
    const state = this._readableState
    const nOrig = n
    if (n !== 0) {
      state.emittedReadable = false
    }

    // if we're doing read(0) to trigger a readable event, but we
    // already have a bunch of data in the buffer, then just trigger
    // the 'readable' event and move on.
    if (
      n === 0 &&
      state.needReadable &&
      ((state.highWaterMark !== 0
        ? state.length >= state.highWaterMark
        : state.length > 0) ||
        state.ended)
    ) {
      debug('read: emitReadable', state.length, state.ended)
      if (state.length === 0 && state.ended) {
        endReadable(this)
      } else {
        emitReadable(this)
      }
      return null
    }
    n = howMuchToRead(n, state)

    // if we've ended, and we're now clear, then finish it up.
    if (n === 0 && state.ended) {
      if (state.length === 0) {
        endReadable(this)
      }
      return null
    }

    // All the actual chunk generation logic needs to be
    // *below* the call to _read.  The reason is that in certain
    // synthetic stream cases, such as passthrough streams, _read
    // may be a completely synchronous operation which may change
    // the state of the read buffer, providing enough data when
    // before there was *not* enough.
    //
    // So, the steps are:
    // 1. Figure out what the state of things will be after we do
    // a read from the buffer.
    //
    // 2. If that resulting state will trigger a _read, then call _read.
    // Note that this may be asynchronous, or synchronous.  Yes, it is
    // deeply ugly to write APIs this way, but that still doesn't mean
    // that the Readable class should behave improperly, as streams are
    // designed to be sync/async agnostic.
    // Take note if the _read call is sync or async (ie, if the read call
    // has returned yet), so that we know whether or not it's safe to emit
    // 'readable' etc.
    //
    // 3. Actually pull the requested chunks out of the buffer and return.

    // if we need a readable event, then we need to do some reading.
    let doRead = state.needReadable
    debug('need readable', doRead)

    // if we currently have less than the highWaterMark, then also read some
    if (state.length === 0 || state.length - n < state.highWaterMark) {
      doRead = true
      debug('length less than watermark', doRead)
    }

    // however, if we've ended, then there's no point, and if we're already
    // reading, then it's unnecessary.
    if (state.ended || state.reading) {
      doRead = false
      debug('reading or ended', doRead)
    } else if (doRead) {
      debug('do read')
      state.reading = true
      state.sync = true
      // if the length is currently zero, then we *need* a readable event.
      if (state.length === 0) {
        state.needReadable = true
      }
      // call internal read method
      this._read(state.highWaterMark)
      state.sync = false
      // If _read pushed data synchronously, then `reading` will be false,
      // and we need to re-evaluate how much data we can return to the user.
      if (!state.reading) {
        n = howMuchToRead(nOrig, state)
      }
    }
    let ret
    if (n > 0) {
      ret = fromList(n, state)
    } else {
      ret = null
    }
    if (ret === null) {
      state.needReadable = state.length <= state.highWaterMark
      n = 0
    } else {
      state.length -= n
      state.awaitDrain = 0
    }
    if (state.length === 0) {
      // If we have nothing in the buffer, then we want to know
      // as soon as we *do* get something into the buffer.
      if (!state.ended) {
        state.needReadable = true
      }

      // If we tried to read() past the EOF, then emit end on the next tick.
      if (nOrig !== n && state.ended) {
        endReadable(this)
      }
    }
    if (ret !== null) {
      this.emit('data', ret)
    }
    return ret
  }
  function onEofChunk(stream, state) {
    debug('onEofChunk')
    if (state.ended) {
      return
    }
    if (state.decoder) {
      const chunk = state.decoder.end()
      if (chunk && chunk.length) {
        state.buffer.push(chunk)
        state.length += state.objectMode ? 1 : chunk.length
      }
    }
    state.ended = true
    if (state.sync) {
      // if we are sync, wait until next tick to emit the data.
      // Otherwise we risk emitting data in the flow()
      // the readable code triggers during a read() call
      emitReadable(stream)
    } else {
      // emit 'readable' now to make sure it gets picked up.
      state.needReadable = false
      if (!state.emittedReadable) {
        state.emittedReadable = true
        emitReadable_(stream)
      }
    }
  }

  // Don't emit readable right away in sync mode, because this can trigger
  // another read() call => stack overflow.  This way, it might trigger
  // a nextTick recursion warning, but that's not so bad.
  function emitReadable(stream) {
    const state = stream._readableState
    debug('emitReadable', state.needReadable, state.emittedReadable)
    state.needReadable = false
    if (!state.emittedReadable) {
      debug('emitReadable', state.flowing)
      state.emittedReadable = true
      process.nextTick(emitReadable_, stream)
    }
  }
  function emitReadable_(stream) {
    const state = stream._readableState
    debug('emitReadable_', state.destroyed, state.length, state.ended)
    if (!state.destroyed && (state.length || state.ended)) {
      stream.emit('readable')
      state.emittedReadable = false
    }

    // The stream needs another readable event if
    // 1. It is not flowing, as the flow mechanism will take
    //    care of it.
    // 2. It is not ended.
    // 3. It is below the highWaterMark, so we can schedule
    //    another readable later.
    state.needReadable =
      !state.flowing && !state.ended && state.length <= state.highWaterMark
    flow(stream)
  }

  // at this point, the user has presumably seen the 'readable' event,
  // and called read() to consume some data.  that may have triggered
  // in turn another _read(n) call, in which case reading = true if
  // it's in progress.
  // However, if we're not ended, or reading, and the length < hwm,
  // then go ahead and try to read some more preemptively.
  function maybeReadMore(stream, state) {
    if (!state.readingMore) {
      state.readingMore = true
      process.nextTick(maybeReadMore_, stream, state)
    }
  }
  function maybeReadMore_(stream, state) {
    // Attempt to read more data if we should.
    //
    // The conditions for reading more data are (one of):
    // - Not enough data buffered (state.length < state.highWaterMark). The loop
    //   is responsible for filling the buffer with enough data if such data
    //   is available. If highWaterMark is 0 and we are not in the flowing mode
    //   we should _not_ attempt to buffer any extra data. We'll get more data
    //   when the stream consumer calls read() instead.
    // - No data in the buffer, and the stream is in flowing mode. In this mode
    //   the loop below is responsible for ensuring read() is called. Failing to
    //   call read here would abort the flow and there's no other mechanism for
    //   continuing the flow if the stream consumer has just subscribed to the
    //   'data' event.
    //
    // In addition to the above conditions to keep reading data, the following
    // conditions prevent the data from being read:
    // - The stream has ended (state.ended).
    // - There is already a pending 'read' operation (state.reading). This is a
    //   case where the the stream has called the implementation defined _read()
    //   method, but they are processing the call asynchronously and have _not_
    //   called push() with new data. In this case we skip performing more
    //   read()s. The execution ends in this method again after the _read() ends
    //   up calling push() with more data.
    while (
      !state.reading &&
      !state.ended &&
      (state.length < state.highWaterMark ||
        (state.flowing && state.length === 0))
    ) {
      const len = state.length
      debug('maybeReadMore read 0')
      stream.read(0)
      if (len === state.length) {
        // didn't get any data, stop spinning.
        break
      }
    }
    state.readingMore = false
  }

  // abstract method.  to be overridden in specific implementation classes.
  // call cb(er, data) where data is <= n in length.
  // for virtual (non-string, non-buffer) streams, "length" is somewhat
  // arbitrary, and perhaps not very meaningful.
  Readable.prototype._read = function (n) {
    errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'))
  }
  Readable.prototype.pipe = function (dest, pipeOpts) {
    const src = this
    const state = this._readableState
    switch (state.pipesCount) {
      case 0:
        state.pipes = dest
        break
      case 1:
        state.pipes = [state.pipes, dest]
        break
      default:
        state.pipes.push(dest)
        break
    }
    state.pipesCount += 1
    debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts)
    const doEnd =
      (!pipeOpts || pipeOpts.end !== false) &&
      dest !== process.stdout &&
      dest !== process.stderr
    const endFn = doEnd ? onend : unpipe
    if (state.endEmitted) {
      process.nextTick(endFn)
    } else {
      src.once('end', endFn)
    }
    dest.on('unpipe', onunpipe)
    function onunpipe(readable, unpipeInfo) {
      debug('onunpipe')
      if (readable === src) {
        if (unpipeInfo && unpipeInfo.hasUnpiped === false) {
          unpipeInfo.hasUnpiped = true
          cleanup()
        }
      }
    }
    function onend() {
      debug('onend')
      dest.end()
    }

    // when the dest drains, it reduces the awaitDrain counter
    // on the source.  This would be more elegant with a .once()
    // handler in flow(), but adding and removing repeatedly is
    // too slow.
    const ondrain = pipeOnDrain(src)
    dest.on('drain', ondrain)
    let cleanedUp = false
    function cleanup() {
      debug('cleanup')
      // cleanup event handlers once the pipe is broken
      dest.removeListener('close', onclose)
      dest.removeListener('finish', onfinish)
      dest.removeListener('drain', ondrain)
      dest.removeListener('error', onerror)
      dest.removeListener('unpipe', onunpipe)
      src.removeListener('end', onend)
      src.removeListener('end', unpipe)
      src.removeListener('data', ondata)
      cleanedUp = true

      // if the reader is waiting for a drain event from this
      // specific writer, then it would cause it to never start
      // flowing again.
      // So, if this is awaiting a drain, then we just call it now.
      // If we don't know, then assume that we are waiting for one.
      if (
        state.awaitDrain &&
        (!dest._writableState || dest._writableState.needDrain)
      ) {
        ondrain()
      }
    }
    src.on('data', ondata)
    function ondata(chunk) {
      debug('ondata')
      const ret = dest.write(chunk)
      debug('dest.write', ret)
      if (ret === false) {
        // If the user unpiped during `dest.write()`, it is possible
        // to get stuck in a permanently paused state if that write
        // also returned false.
        // => Check whether `dest` is still a piping destination.
        if (
          ((state.pipesCount === 1 && state.pipes === dest) ||
            (state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1)) &&
          !cleanedUp
        ) {
          debug('false write response, pause', state.awaitDrain)
          state.awaitDrain++
        }
        src.pause()
      }
    }

    // if the dest has an error, then stop piping into it.
    // however, don't suppress the throwing behavior for this.
    function onerror(er) {
      debug('onerror', er)
      unpipe()
      dest.removeListener('error', onerror)
      if (EElistenerCount(dest, 'error') === 0) {
        errorOrDestroy(dest, er)
      }
    }

    // Make sure our error handler is attached before userland ones.
    prependListener(dest, 'error', onerror)

    // Both close and finish should trigger unpipe, but only once.
    function onclose() {
      dest.removeListener('finish', onfinish)
      unpipe()
    }
    dest.once('close', onclose)
    function onfinish() {
      debug('onfinish')
      dest.removeListener('close', onclose)
      unpipe()
    }
    dest.once('finish', onfinish)
    function unpipe() {
      debug('unpipe')
      src.unpipe(dest)
    }

    // tell the dest that it's being piped to
    dest.emit('pipe', src)

    // start the flow if it hasn't been started already.
    if (!state.flowing) {
      debug('pipe resume')
      src.resume()
    }
    return dest
  }
  function pipeOnDrain(src) {
    return function pipeOnDrainFunctionResult() {
      const state = src._readableState
      debug('pipeOnDrain', state.awaitDrain)
      if (state.awaitDrain) {
        state.awaitDrain--
      }
      if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {
        state.flowing = true
        flow(src)
      }
    }
  }
  Readable.prototype.unpipe = function (dest) {
    const state = this._readableState
    const unpipeInfo = {
      hasUnpiped: false
    }

    // if we're not piping anywhere, then do nothing.
    if (state.pipesCount === 0) {
      return this
    }

    // just one destination.  most common case.
    if (state.pipesCount === 1) {
      // passed in one, but it's not the right one.
      if (dest && dest !== state.pipes) {
        return this
      }
      if (!dest) {
        dest = state.pipes
      }

      // got a match.
      state.pipes = null
      state.pipesCount = 0
      state.flowing = false
      if (dest) {
        dest.emit('unpipe', this, unpipeInfo)
      }
      return this
    }

    // slow case. multiple pipe destinations.

    if (!dest) {
      // remove all.
      const dests = state.pipes
      const len = state.pipesCount
      state.pipes = null
      state.pipesCount = 0
      state.flowing = false
      for (let i = 0; i < len; i++) {
        dests[i].emit('unpipe', this, {
          hasUnpiped: false
        })
      }
      return this
    }

    // try to find the right one.
    const index = indexOf(state.pipes, dest)
    if (index === -1) {
      return this
    }
    state.pipes.splice(index, 1)
    state.pipesCount -= 1
    if (state.pipesCount === 1) {
      state.pipes = state.pipes[0]
    }
    dest.emit('unpipe', this, unpipeInfo)
    return this
  }

  // set up data events if they are asked for
  // Ensure readable listeners eventually get something
  Readable.prototype.on = function (ev, fn) {
    const res = Stream.prototype.on.call(this, ev, fn)
    const state = this._readableState
    if (ev === 'data') {
      // update readableListening so that resume() may be a no-op
      // a few lines down. This is needed to support once('readable').
      state.readableListening = this.listenerCount('readable') > 0

      // Try start flowing on next tick if stream isn't explicitly paused
      if (state.flowing !== false) {
        this.resume()
      }
    } else if (ev === 'readable') {
      if (!state.endEmitted && !state.readableListening) {
        state.readableListening = state.needReadable = true
        state.flowing = false
        state.emittedReadable = false
        debug('on readable', state.length, state.reading)
        if (state.length) {
          emitReadable(this)
        } else if (!state.reading) {
          process.nextTick(nReadingNextTick, this)
        }
      }
    }
    return res
  }
  Readable.prototype.addListener = Readable.prototype.on
  Readable.prototype.removeListener = function (ev, fn) {
    const res = Stream.prototype.removeListener.call(this, ev, fn)
    if (ev === 'readable') {
      // We need to check if there is someone still listening to
      // readable and reset the state. However this needs to happen
      // after readable has been emitted but before I/O (nextTick) to
      // support once('readable', fn) cycles. This means that calling
      // resume within the same tick will have no
      // effect.
      process.nextTick(updateReadableListening, this)
    }
    return res
  }
  Readable.prototype.removeAllListeners = function (ev) {
    const res = Stream.prototype.removeAllListeners.apply(this, arguments)
    if (ev === 'readable' || ev === undefined) {
      // We need to check if there is someone still listening to
      // readable and reset the state. However this needs to happen
      // after readable has been emitted but before I/O (nextTick) to
      // support once('readable', fn) cycles. This means that calling
      // resume within the same tick will have no
      // effect.
      process.nextTick(updateReadableListening, this)
    }
    return res
  }
  function updateReadableListening(self) {
    const state = self._readableState
    state.readableListening = self.listenerCount('readable') > 0
    if (state.resumeScheduled && !state.paused) {
      // flowing needs to be set to true now, otherwise
      // the upcoming resume will not flow.
      state.flowing = true

      // crude way to check if we should resume
    } else if (self.listenerCount('data') > 0) {
      self.resume()
    }
  }
  function nReadingNextTick(self) {
    debug('readable nexttick read 0')
    self.read(0)
  }

  // pause() and resume() are remnants of the legacy readable stream API
  // If the user uses them, then switch into old mode.
  Readable.prototype.resume = function () {
    const state = this._readableState
    if (!state.flowing) {
      debug('resume')
      // we flow only if there is no one listening
      // for readable, but we still have to call
      // resume()
      state.flowing = !state.readableListening
      resume(this, state)
    }
    state.paused = false
    return this
  }
  function resume(stream, state) {
    if (!state.resumeScheduled) {
      state.resumeScheduled = true
      process.nextTick(resume_, stream, state)
    }
  }
  function resume_(stream, state) {
    debug('resume', state.reading)
    if (!state.reading) {
      stream.read(0)
    }
    state.resumeScheduled = false
    stream.emit('resume')
    flow(stream)
    if (state.flowing && !state.reading) {
      stream.read(0)
    }
  }
  Readable.prototype.pause = function () {
    debug('call pause flowing=%j', this._readableState.flowing)
    if (this._readableState.flowing !== false) {
      debug('pause')
      this._readableState.flowing = false
      this.emit('pause')
    }
    this._readableState.paused = true
    return this
  }
  function flow(stream) {
    const state = stream._readableState
    debug('flow', state.flowing)
    while (state.flowing && stream.read() !== null) {}
  }

  // wrap an old-style stream as the async data source.
  // This is *not* part of the readable stream interface.
  // It is an ugly unfortunate mess of history.
  Readable.prototype.wrap = function (stream) {
    const _this = this
    const state = this._readableState
    let paused = false
    stream.on('end', function () {
      debug('wrapped end')
      if (state.decoder && !state.ended) {
        const chunk = state.decoder.end()
        if (chunk && chunk.length) {
          _this.push(chunk)
        }
      }
      _this.push(null)
    })
    stream.on('data', function (chunk) {
      debug('wrapped data')
      if (state.decoder) {
        chunk = state.decoder.write(chunk)
      }

      // don't skip over falsy values in objectMode
      if (state.objectMode && (chunk === null || chunk === undefined)) {
        return
      } else if (!state.objectMode && (!chunk || !chunk.length)) {
        return
      }
      const ret = _this.push(chunk)
      if (!ret) {
        paused = true
        stream.pause()
      }
    })

    // proxy all the other methods.
    // important when wrapping filters and duplexes.
    for (const i in stream) {
      if (this[i] === undefined && typeof stream[i] === 'function') {
        this[i] = (function methodWrap(method) {
          return function methodWrapReturnFunction() {
            return stream[method].apply(stream, arguments)
          }
        })(i)
      }
    }

    // proxy certain important events.
    for (let n = 0; n < kProxyEvents.length; n++) {
      stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]))
    }

    // when we try to consume some more bytes, simply unpause the
    // underlying stream.
    this._read = function (n) {
      debug('wrapped _read', n)
      if (paused) {
        paused = false
        stream.resume()
      }
    }
    return this
  }
  if (typeof Symbol === 'function') {
    Readable.prototype[Symbol.asyncIterator] = function () {
      if (createReadableStreamAsyncIterator === undefined) {
        createReadableStreamAsyncIterator = requireAsync_iterator$1()
      }
      return createReadableStreamAsyncIterator(this)
    }
  }
  Object.defineProperty(Readable.prototype, 'readableHighWaterMark', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._readableState.highWaterMark
    }
  })
  Object.defineProperty(Readable.prototype, 'readableBuffer', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._readableState && this._readableState.buffer
    }
  })
  Object.defineProperty(Readable.prototype, 'readableFlowing', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._readableState.flowing
    },
    set: function set(state) {
      if (this._readableState) {
        this._readableState.flowing = state
      }
    }
  })

  // exposed for testing purposes only.
  Readable._fromList = fromList
  Object.defineProperty(Readable.prototype, 'readableLength', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._readableState.length
    }
  })

  // Pluck off n bytes from an array of buffers.
  // Length is the combined lengths of all the buffers in the list.
  // This function is designed to be inlinable, so please take care when making
  // changes to the function body.
  function fromList(n, state) {
    // nothing buffered
    if (state.length === 0) {
      return null
    }
    let ret
    if (state.objectMode) {
      ret = state.buffer.shift()
    } else if (!n || n >= state.length) {
      // read it all, truncate the list
      if (state.decoder) {
        ret = state.buffer.join('')
      } else if (state.buffer.length === 1) {
        ret = state.buffer.first()
      } else {
        ret = state.buffer.concat(state.length)
      }
      state.buffer.clear()
    } else {
      // read part of list
      ret = state.buffer.consume(n, state.decoder)
    }
    return ret
  }
  function endReadable(stream) {
    const state = stream._readableState
    debug('endReadable', state.endEmitted)
    if (!state.endEmitted) {
      state.ended = true
      process.nextTick(endReadableNT, state, stream)
    }
  }
  function endReadableNT(state, stream) {
    debug('endReadableNT', state.endEmitted, state.length)

    // Check that we didn't get one last unshift.
    if (!state.endEmitted && state.length === 0) {
      state.endEmitted = true
      stream.readable = false
      stream.emit('end')
      if (state.autoDestroy) {
        // In case of duplex streams we need a way to detect
        // if the writable side is ready for autoDestroy as well
        const wState = stream._writableState
        if (!wState || (wState.autoDestroy && wState.finished)) {
          stream.destroy()
        }
      }
    }
  }
  if (typeof Symbol === 'function') {
    Readable.from = function (iterable, opts) {
      if (from === undefined) {
        from = requireFrom$1()
      }
      return from(Readable, iterable, opts)
    }
  }
  function indexOf(xs, x) {
    for (let i = 0, l = xs.length; i < l; i++) {
      if (xs[i] === x) {
        return i
      }
    }
    return -1
  }
  return _stream_readable$1
}

let _stream_transform$1
let hasRequired_stream_transform$1
function require_stream_transform$1() {
  if (hasRequired_stream_transform$1) {
    return _stream_transform$1
  }
  hasRequired_stream_transform$1 = 1
  _stream_transform$1 = Transform
  const _require$codes = requireErrors$2().codes,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,
    ERR_TRANSFORM_ALREADY_TRANSFORMING =
      _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,
    ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0
  const Duplex = require_stream_duplex$1()
  requireInherits()(Transform, Duplex)
  function afterTransform(er, data) {
    const ts = this._transformState
    ts.transforming = false
    const cb = ts.writecb
    if (cb === null) {
      return this.emit('error', new ERR_MULTIPLE_CALLBACK())
    }
    ts.writechunk = null
    ts.writecb = null
    if (data != null) {
      // single equals check for both `null` and `undefined`
      this.push(data)
    }
    cb(er)
    const rs = this._readableState
    rs.reading = false
    if (rs.needReadable || rs.length < rs.highWaterMark) {
      this._read(rs.highWaterMark)
    }
  }
  function Transform(options) {
    if (!(this instanceof Transform)) {
      return new Transform(options)
    }
    Duplex.call(this, options)
    this._transformState = {
      afterTransform: afterTransform.bind(this),
      needTransform: false,
      transforming: false,
      writecb: null,
      writechunk: null,
      writeencoding: null
    }

    // start out asking for a readable event once data is transformed.
    this._readableState.needReadable = true

    // we have implemented the _read method, and done the other things
    // that Readable wants before the first _read call, so unset the
    // sync guard flag.
    this._readableState.sync = false
    if (options) {
      if (typeof options.transform === 'function') {
        this._transform = options.transform
      }
      if (typeof options.flush === 'function') {
        this._flush = options.flush
      }
    }

    // When the writable side finishes, then flush out anything remaining.
    this.on('prefinish', prefinish)
  }
  function prefinish() {
    const _this = this
    if (typeof this._flush === 'function' && !this._readableState.destroyed) {
      this._flush(function (er, data) {
        done(_this, er, data)
      })
    } else {
      done(this, null, null)
    }
  }
  Transform.prototype.push = function (chunk, encoding) {
    this._transformState.needTransform = false
    return Duplex.prototype.push.call(this, chunk, encoding)
  }

  // This is the part where you do stuff!
  // override this function in implementation classes.
  // 'chunk' is an input chunk.
  //
  // Call `push(newChunk)` to pass along transformed output
  // to the readable side.  You may call 'push' zero or more times.
  //
  // Call `cb(err)` when you are done with this chunk.  If you pass
  // an error, then that'll put the hurt on the whole operation.  If you
  // never call cb(), then you'll never get another chunk.
  Transform.prototype._transform = function (chunk, encoding, cb) {
    cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'))
  }
  Transform.prototype._write = function (chunk, encoding, cb) {
    const ts = this._transformState
    ts.writecb = cb
    ts.writechunk = chunk
    ts.writeencoding = encoding
    if (!ts.transforming) {
      const rs = this._readableState
      if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) {
        this._read(rs.highWaterMark)
      }
    }
  }

  // Doesn't matter what the args are here.
  // _transform does all the work.
  // That we got here means that the readable side wants more data.
  Transform.prototype._read = function (n) {
    const ts = this._transformState
    if (ts.writechunk !== null && !ts.transforming) {
      ts.transforming = true
      this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform)
    } else {
      // mark that we need a transform, so that any data that comes in
      // will get processed, now that we've asked for it.
      ts.needTransform = true
    }
  }
  Transform.prototype._destroy = function (err, cb) {
    Duplex.prototype._destroy.call(this, err, function (err2) {
      cb(err2)
    })
  }
  function done(stream, er, data) {
    if (er) {
      return stream.emit('error', er)
    }
    if (data != null) {
      // single equals check for both `null` and `undefined`
      stream.push(data)
    }

    // TODO(BridgeAR): Write a test for these two error cases
    // if there's nothing in the write buffer, then that means
    // that nothing more will ever be provided
    if (stream._writableState.length) {
      throw new ERR_TRANSFORM_WITH_LENGTH_0()
    }
    if (stream._transformState.transforming) {
      throw new ERR_TRANSFORM_ALREADY_TRANSFORMING()
    }
    return stream.push(null)
  }
  return _stream_transform$1
}

let _stream_passthrough$1
let hasRequired_stream_passthrough$1
function require_stream_passthrough$1() {
  if (hasRequired_stream_passthrough$1) {
    return _stream_passthrough$1
  }
  hasRequired_stream_passthrough$1 = 1
  _stream_passthrough$1 = PassThrough
  const Transform = require_stream_transform$1()
  requireInherits()(PassThrough, Transform)
  function PassThrough(options) {
    if (!(this instanceof PassThrough)) {
      return new PassThrough(options)
    }
    Transform.call(this, options)
  }
  PassThrough.prototype._transform = function (chunk, encoding, cb) {
    cb(null, chunk)
  }
  return _stream_passthrough$1
}

let pipeline_1$1
let hasRequiredPipeline$1
function requirePipeline$1() {
  if (hasRequiredPipeline$1) {
    return pipeline_1$1
  }
  hasRequiredPipeline$1 = 1
  let eos
  function once(callback) {
    let called = false
    return function () {
      if (called) {
        return
      }
      called = true
      callback.apply(void 0, arguments)
    }
  }
  const _require$codes = requireErrors$2().codes,
    ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,
    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED
  function noop(err) {
    // Rethrow the error if it exists to avoid swallowing it
    if (err) {
      throw err
    }
  }
  function isRequest(stream) {
    return stream.setHeader && typeof stream.abort === 'function'
  }
  function destroyer(stream, reading, writing, callback) {
    callback = once(callback)
    let closed = false
    stream.on('close', function () {
      closed = true
    })
    if (eos === undefined) {
      eos = requireEndOfStream$1()
    }
    eos(
      stream,
      {
        readable: reading,
        writable: writing
      },
      function (err) {
        if (err) {
          return callback(err)
        }
        closed = true
        callback()
      }
    )
    let destroyed = false
    return function (err) {
      if (closed) {
        return
      }
      if (destroyed) {
        return
      }
      destroyed = true

      // request.destroy just do .end - .abort is what we want
      if (isRequest(stream)) {
        return stream.abort()
      }
      if (typeof stream.destroy === 'function') {
        return stream.destroy()
      }
      callback(err || new ERR_STREAM_DESTROYED('pipe'))
    }
  }
  function call(fn) {
    fn()
  }
  function pipe(from, to) {
    return from.pipe(to)
  }
  function popCallback(streams) {
    if (!streams.length) {
      return noop
    }
    if (typeof streams[streams.length - 1] !== 'function') {
      return noop
    }
    return streams.pop()
  }
  function pipeline() {
    for (
      let _len = arguments.length, streams = new Array(_len), _key = 0;
      _key < _len;
      _key++
    ) {
      streams[_key] = arguments[_key]
    }
    const callback = popCallback(streams)
    if (Array.isArray(streams[0])) {
      streams = streams[0]
    }
    if (streams.length < 2) {
      throw new ERR_MISSING_ARGS('streams')
    }
    let error
    const destroys = streams.map(function (stream, i) {
      const reading = i < streams.length - 1
      const writing = i > 0
      return destroyer(stream, reading, writing, function (err) {
        if (!error) {
          error = err
        }
        if (err) {
          destroys.forEach(call)
        }
        if (reading) {
          return
        }
        destroys.forEach(call)
        callback(error)
      })
    })
    return streams.reduce(pipe)
  }
  pipeline_1$1 = pipeline
  return pipeline_1$1
}

let hasRequiredReadable$1
function requireReadable$1() {
  if (hasRequiredReadable$1) {
    return readable$1.exports
  }
  hasRequiredReadable$1 = 1
  ;(function (module, exports) {
    const Stream = require$$0$g
    if (process.env.READABLE_STREAM === 'disable' && Stream) {
      module.exports = Stream.Readable
      Object.assign(module.exports, Stream)
      module.exports.Stream = Stream
    } else {
      exports = module.exports = require_stream_readable$1()
      exports.Stream = Stream || exports
      exports.Readable = exports
      exports.Writable = require_stream_writable$1()
      exports.Duplex = require_stream_duplex$1()
      exports.Transform = require_stream_transform$1()
      exports.PassThrough = require_stream_passthrough$1()
      exports.finished = requireEndOfStream$1()
      exports.pipeline = requirePipeline$1()
    }
  })(readable$1, readable$1.exports)
  return readable$1.exports
}

let hasRequiredThrough2
function requireThrough2() {
  if (hasRequiredThrough2) {
    return through2.exports
  }
  hasRequiredThrough2 = 1
  const { Transform } = requireReadable$1()
  function inherits(fn, sup) {
    fn.super_ = sup
    fn.prototype = Object.create(sup.prototype, {
      constructor: {
        value: fn,
        enumerable: false,
        writable: true,
        configurable: true
      }
    })
  }

  // create a new export function, used by both the main export and
  // the .ctor export, contains common logic for dealing with arguments
  function through2$1(construct) {
    return (options, transform, flush) => {
      if (typeof options === 'function') {
        flush = transform
        transform = options
        options = {}
      }
      if (typeof transform !== 'function') {
        // noop
        transform = (chunk, enc, cb) => cb(null, chunk)
      }
      if (typeof flush !== 'function') {
        flush = null
      }
      return construct(options, transform, flush)
    }
  }

  // main export, just make me a transform stream!
  const make = through2$1((options, transform, flush) => {
    const t2 = new Transform(options)
    t2._transform = transform
    if (flush) {
      t2._flush = flush
    }
    return t2
  })

  // make me a reusable prototype that I can `new`, or implicitly `new`
  // with a constructor call
  const ctor = through2$1((options, transform, flush) => {
    function Through2(override) {
      if (!(this instanceof Through2)) {
        return new Through2(override)
      }
      this.options = Object.assign({}, options, override)
      Transform.call(this, this.options)
      this._transform = transform
      if (flush) {
        this._flush = flush
      }
    }
    inherits(Through2, Transform)
    return Through2
  })
  const obj = through2$1(function (options, transform, flush) {
    const t2 = new Transform(
      Object.assign(
        {
          objectMode: true,
          highWaterMark: 16
        },
        options
      )
    )
    t2._transform = transform
    if (flush) {
      t2._flush = flush
    }
    return t2
  })
  through2.exports = make
  through2.exports.ctor = ctor
  through2.exports.obj = obj
  return through2.exports
}

const readable = { exports: {} }

let stream$1
let hasRequiredStream$1
function requireStream$1() {
  if (hasRequiredStream$1) {
    return stream$1
  }
  hasRequiredStream$1 = 1
  stream$1 = require$$0$g
  return stream$1
}

let buffer_list
let hasRequiredBuffer_list
function requireBuffer_list() {
  if (hasRequiredBuffer_list) {
    return buffer_list
  }
  hasRequiredBuffer_list = 1
  function ownKeys(object, enumerableOnly) {
    const keys = Object.keys(object)
    if (Object.getOwnPropertySymbols) {
      let symbols = Object.getOwnPropertySymbols(object)
      enumerableOnly &&
        (symbols = symbols.filter(function (sym) {
          return Object.getOwnPropertyDescriptor(object, sym).enumerable
        })),
        keys.push.apply(keys, symbols)
    }
    return keys
  }
  function _objectSpread(target) {
    for (let i = 1; i < arguments.length; i++) {
      const source = null != arguments[i] ? arguments[i] : {}
      i % 2
        ? ownKeys(Object(source), true).forEach(function (key) {
            _defineProperty(target, key, source[key])
          })
        : Object.getOwnPropertyDescriptors
          ? Object.defineProperties(
              target,
              Object.getOwnPropertyDescriptors(source)
            )
          : ownKeys(Object(source)).forEach(function (key) {
              Object.defineProperty(
                target,
                key,
                Object.getOwnPropertyDescriptor(source, key)
              )
            })
    }
    return target
  }
  function _defineProperty(obj, key, value) {
    key = _toPropertyKey(key)
    if (key in obj) {
      Object.defineProperty(obj, key, {
        value: value,
        enumerable: true,
        configurable: true,
        writable: true
      })
    } else {
      obj[key] = value
    }
    return obj
  }
  function _classCallCheck(instance, Constructor) {
    if (!(instance instanceof Constructor)) {
      throw new TypeError('Cannot call a class as a function')
    }
  }
  function _defineProperties(target, props) {
    for (let i = 0; i < props.length; i++) {
      const descriptor = props[i]
      descriptor.enumerable = descriptor.enumerable || false
      descriptor.configurable = true
      if ('value' in descriptor) {
        descriptor.writable = true
      }
      Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor)
    }
  }
  function _createClass(Constructor, protoProps, staticProps) {
    if (protoProps) {
      _defineProperties(Constructor.prototype, protoProps)
    }
    Object.defineProperty(Constructor, 'prototype', {
      writable: false
    })
    return Constructor
  }
  function _toPropertyKey(arg) {
    const key = _toPrimitive(arg, 'string')
    return typeof key === 'symbol' ? key : String(key)
  }
  function _toPrimitive(input, hint) {
    if (typeof input !== 'object' || input === null) {
      return input
    }
    const prim = input[Symbol.toPrimitive]
    if (prim !== undefined) {
      const res = prim.call(input, hint)
      if (typeof res !== 'object') {
        return res
      }
      throw new TypeError('@@toPrimitive must return a primitive value.')
    }
    return String(input)
  }
  const _require = require$$2$4,
    Buffer = _require.Buffer
  const _require2 = require$$0$4,
    inspect = _require2.inspect
  const custom = (inspect && inspect.custom) || 'inspect'
  function copyBuffer(src, target, offset) {
    Buffer.prototype.copy.call(src, target, offset)
  }
  buffer_list = /*#__PURE__*/ (function () {
    function BufferList() {
      _classCallCheck(this, BufferList)
      this.head = null
      this.tail = null
      this.length = 0
    }
    _createClass(BufferList, [
      {
        key: 'push',
        value: function push(v) {
          const entry = {
            data: v,
            next: null
          }
          if (this.length > 0) {
            this.tail.next = entry
          } else {
            this.head = entry
          }
          this.tail = entry
          ++this.length
        }
      },
      {
        key: 'unshift',
        value: function unshift(v) {
          const entry = {
            data: v,
            next: this.head
          }
          if (this.length === 0) {
            this.tail = entry
          }
          this.head = entry
          ++this.length
        }
      },
      {
        key: 'shift',
        value: function shift() {
          if (this.length === 0) {
            return
          }
          const ret = this.head.data
          if (this.length === 1) {
            this.head = this.tail = null
          } else {
            this.head = this.head.next
          }
          --this.length
          return ret
        }
      },
      {
        key: 'clear',
        value: function clear() {
          this.head = this.tail = null
          this.length = 0
        }
      },
      {
        key: 'join',
        value: function join(s) {
          if (this.length === 0) {
            return ''
          }
          let p = this.head
          let ret = '' + p.data
          while ((p = p.next)) {
            ret += s + p.data
          }
          return ret
        }
      },
      {
        key: 'concat',
        value: function concat(n) {
          if (this.length === 0) {
            return Buffer.alloc(0)
          }
          const ret = Buffer.allocUnsafe(n >>> 0)
          let p = this.head
          let i = 0
          while (p) {
            copyBuffer(p.data, ret, i)
            i += p.data.length
            p = p.next
          }
          return ret
        }

        // Consumes a specified amount of bytes or characters from the buffered data.
      },
      {
        key: 'consume',
        value: function consume(n, hasStrings) {
          let ret
          if (n < this.head.data.length) {
            // `slice` is the same for buffers and strings.
            ret = this.head.data.slice(0, n)
            this.head.data = this.head.data.slice(n)
          } else if (n === this.head.data.length) {
            // First chunk is a perfect match.
            ret = this.shift()
          } else {
            // Result spans more than one buffer.
            ret = hasStrings ? this._getString(n) : this._getBuffer(n)
          }
          return ret
        }
      },
      {
        key: 'first',
        value: function first() {
          return this.head.data
        }

        // Consumes a specified amount of characters from the buffered data.
      },
      {
        key: '_getString',
        value: function _getString(n) {
          let p = this.head
          let c = 1
          let ret = p.data
          n -= ret.length
          while ((p = p.next)) {
            const str = p.data
            const nb = n > str.length ? str.length : n
            if (nb === str.length) {
              ret += str
            } else {
              ret += str.slice(0, n)
            }
            n -= nb
            if (n === 0) {
              if (nb === str.length) {
                ++c
                if (p.next) {
                  this.head = p.next
                } else {
                  this.head = this.tail = null
                }
              } else {
                this.head = p
                p.data = str.slice(nb)
              }
              break
            }
            ++c
          }
          this.length -= c
          return ret
        }

        // Consumes a specified amount of bytes from the buffered data.
      },
      {
        key: '_getBuffer',
        value: function _getBuffer(n) {
          const ret = Buffer.allocUnsafe(n)
          let p = this.head
          let c = 1
          p.data.copy(ret)
          n -= p.data.length
          while ((p = p.next)) {
            const buf = p.data
            const nb = n > buf.length ? buf.length : n
            buf.copy(ret, ret.length - n, 0, nb)
            n -= nb
            if (n === 0) {
              if (nb === buf.length) {
                ++c
                if (p.next) {
                  this.head = p.next
                } else {
                  this.head = this.tail = null
                }
              } else {
                this.head = p
                p.data = buf.slice(nb)
              }
              break
            }
            ++c
          }
          this.length -= c
          return ret
        }

        // Make sure the linked list only shows the minimal necessary information.
      },
      {
        key: custom,
        value: function value(_, options) {
          return inspect(
            this,
            _objectSpread(
              _objectSpread({}, options),
              {},
              {
                // Only inspect one level.
                depth: 0,
                // It should not recurse.
                customInspect: false
              }
            )
          )
        }
      }
    ])
    return BufferList
  })()
  return buffer_list
}

let destroy_1
let hasRequiredDestroy
function requireDestroy() {
  if (hasRequiredDestroy) {
    return destroy_1
  }
  hasRequiredDestroy = 1

  // undocumented cb() API, needed for core, not for public API
  function destroy(err, cb) {
    const _this = this
    const readableDestroyed =
      this._readableState && this._readableState.destroyed
    const writableDestroyed =
      this._writableState && this._writableState.destroyed
    if (readableDestroyed || writableDestroyed) {
      if (cb) {
        cb(err)
      } else if (err) {
        if (!this._writableState) {
          process.nextTick(emitErrorNT, this, err)
        } else if (!this._writableState.errorEmitted) {
          this._writableState.errorEmitted = true
          process.nextTick(emitErrorNT, this, err)
        }
      }
      return this
    }

    // we set destroyed to true before firing error callbacks in order
    // to make it re-entrance safe in case destroy() is called within callbacks

    if (this._readableState) {
      this._readableState.destroyed = true
    }

    // if this is a duplex stream mark the writable part as destroyed as well
    if (this._writableState) {
      this._writableState.destroyed = true
    }
    this._destroy(err || null, function (err) {
      if (!cb && err) {
        if (!_this._writableState) {
          process.nextTick(emitErrorAndCloseNT, _this, err)
        } else if (!_this._writableState.errorEmitted) {
          _this._writableState.errorEmitted = true
          process.nextTick(emitErrorAndCloseNT, _this, err)
        } else {
          process.nextTick(emitCloseNT, _this)
        }
      } else if (cb) {
        process.nextTick(emitCloseNT, _this)
        cb(err)
      } else {
        process.nextTick(emitCloseNT, _this)
      }
    })
    return this
  }
  function emitErrorAndCloseNT(self, err) {
    emitErrorNT(self, err)
    emitCloseNT(self)
  }
  function emitCloseNT(self) {
    if (self._writableState && !self._writableState.emitClose) {
      return
    }
    if (self._readableState && !self._readableState.emitClose) {
      return
    }
    self.emit('close')
  }
  function undestroy() {
    if (this._readableState) {
      this._readableState.destroyed = false
      this._readableState.reading = false
      this._readableState.ended = false
      this._readableState.endEmitted = false
    }
    if (this._writableState) {
      this._writableState.destroyed = false
      this._writableState.ended = false
      this._writableState.ending = false
      this._writableState.finalCalled = false
      this._writableState.prefinished = false
      this._writableState.finished = false
      this._writableState.errorEmitted = false
    }
  }
  function emitErrorNT(self, err) {
    self.emit('error', err)
  }
  function errorOrDestroy(stream, err) {
    // We have tests that rely on errors being emitted
    // in the same tick, so changing this is semver major.
    // For now when you opt-in to autoDestroy we allow
    // the error to be emitted nextTick. In a future
    // semver major update we should change the default to this.

    const rState = stream._readableState
    const wState = stream._writableState
    if ((rState && rState.autoDestroy) || (wState && wState.autoDestroy)) {
      stream.destroy(err)
    } else {
      stream.emit('error', err)
    }
  }
  destroy_1 = {
    destroy: destroy,
    undestroy: undestroy,
    errorOrDestroy: errorOrDestroy
  }
  return destroy_1
}

const errors$1 = {}

let hasRequiredErrors$1
function requireErrors$1() {
  if (hasRequiredErrors$1) {
    return errors$1
  }
  hasRequiredErrors$1 = 1
  const codes = {}
  function createErrorType(code, message, Base) {
    if (!Base) {
      Base = Error
    }
    function getMessage(arg1, arg2, arg3) {
      if (typeof message === 'string') {
        return message
      } else {
        return message(arg1, arg2, arg3)
      }
    }
    class NodeError extends Base {
      constructor(arg1, arg2, arg3) {
        super(getMessage(arg1, arg2, arg3))
      }
    }
    NodeError.prototype.name = Base.name
    NodeError.prototype.code = code
    codes[code] = NodeError
  }

  // https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js
  function oneOf(expected, thing) {
    if (Array.isArray(expected)) {
      const len = expected.length
      expected = expected.map(i => String(i))
      if (len > 2) {
        return (
          `one of ${thing} ${expected.slice(0, len - 1).join(', ')}, or ` +
          expected[len - 1]
        )
      } else if (len === 2) {
        return `one of ${thing} ${expected[0]} or ${expected[1]}`
      } else {
        return `of ${thing} ${expected[0]}`
      }
    } else {
      return `of ${thing} ${String(expected)}`
    }
  }

  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith
  function startsWith(str, search, pos) {
    return str.substr(0, search.length) === search
  }

  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith
  function endsWith(str, search, this_len) {
    if (this_len === undefined || this_len > str.length) {
      this_len = str.length
    }
    return str.substring(this_len - search.length, this_len) === search
  }

  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes
  function includes(str, search, start) {
    if (typeof start !== 'number') {
      start = 0
    }
    if (start + search.length > str.length) {
      return false
    } else {
      return str.indexOf(search, start) !== -1
    }
  }
  createErrorType(
    'ERR_INVALID_OPT_VALUE',
    function (name, value) {
      return 'The value "' + value + '" is invalid for option "' + name + '"'
    },
    TypeError
  )
  createErrorType(
    'ERR_INVALID_ARG_TYPE',
    function (name, expected, actual) {
      // determiner: 'must be' or 'must not be'
      let determiner
      if (typeof expected === 'string' && startsWith(expected, 'not ')) {
        determiner = 'must not be'
        expected = expected.replace(/^not /, '')
      } else {
        determiner = 'must be'
      }
      let msg
      if (endsWith(name, ' argument')) {
        // For cases like 'first argument'
        msg = `The ${name} ${determiner} ${oneOf(expected, 'type')}`
      } else {
        const type = includes(name, '.') ? 'property' : 'argument'
        msg = `The "${name}" ${type} ${determiner} ${oneOf(expected, 'type')}`
      }
      msg += `. Received type ${typeof actual}`
      return msg
    },
    TypeError
  )
  createErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF')
  createErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {
    return 'The ' + name + ' method is not implemented'
  })
  createErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close')
  createErrorType('ERR_STREAM_DESTROYED', function (name) {
    return 'Cannot call ' + name + ' after a stream was destroyed'
  })
  createErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times')
  createErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable')
  createErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end')
  createErrorType(
    'ERR_STREAM_NULL_VALUES',
    'May not write null values to stream',
    TypeError
  )
  createErrorType(
    'ERR_UNKNOWN_ENCODING',
    function (arg) {
      return 'Unknown encoding: ' + arg
    },
    TypeError
  )
  createErrorType(
    'ERR_STREAM_UNSHIFT_AFTER_END_EVENT',
    'stream.unshift() after end event'
  )
  errors$1.codes = codes
  return errors$1
}

let state
let hasRequiredState
function requireState() {
  if (hasRequiredState) {
    return state
  }
  hasRequiredState = 1
  const ERR_INVALID_OPT_VALUE = requireErrors$1().codes.ERR_INVALID_OPT_VALUE
  function highWaterMarkFrom(options, isDuplex, duplexKey) {
    return options.highWaterMark != null
      ? options.highWaterMark
      : isDuplex
        ? options[duplexKey]
        : null
  }
  function getHighWaterMark(state, options, duplexKey, isDuplex) {
    const hwm = highWaterMarkFrom(options, isDuplex, duplexKey)
    if (hwm != null) {
      if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {
        const name = isDuplex ? duplexKey : 'highWaterMark'
        throw new ERR_INVALID_OPT_VALUE(name, hwm)
      }
      return Math.floor(hwm)
    }

    // Default value
    return state.objectMode ? 16 : 16 * 1024
  }
  state = {
    getHighWaterMark: getHighWaterMark
  }
  return state
}

let _stream_writable
let hasRequired_stream_writable
function require_stream_writable() {
  if (hasRequired_stream_writable) {
    return _stream_writable
  }
  hasRequired_stream_writable = 1
  _stream_writable = Writable

  // It seems a linked list but it is not
  // there will be only 2 of these for each stream
  function CorkedRequest(state) {
    const _this = this
    this.next = null
    this.entry = null
    this.finish = function () {
      onCorkedFinish(_this, state)
    }
  }
  /* </replacement> */

  /*<replacement>*/
  let Duplex
  /*</replacement>*/

  Writable.WritableState = WritableState

  /*<replacement>*/
  const internalUtil = {
    deprecate: requireNode$1()
  }
  /*</replacement>*/

  /*<replacement>*/
  const Stream = requireStream$1()
  /*</replacement>*/

  const Buffer = require$$2$4.Buffer
  const OurUint8Array =
    (typeof global !== 'undefined'
      ? global
      : typeof window !== 'undefined'
        ? window
        : typeof self !== 'undefined'
          ? self
          : {}
    ).Uint8Array || function () {}
  function _uint8ArrayToBuffer(chunk) {
    return Buffer.from(chunk)
  }
  function _isUint8Array(obj) {
    return Buffer.isBuffer(obj) || obj instanceof OurUint8Array
  }
  const destroyImpl = requireDestroy()
  const _require = requireState(),
    getHighWaterMark = _require.getHighWaterMark
  const _require$codes = requireErrors$1().codes,
    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,
    ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,
    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,
    ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,
    ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,
    ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING
  const errorOrDestroy = destroyImpl.errorOrDestroy
  requireInherits()(Writable, Stream)
  function nop() {}
  function WritableState(options, stream, isDuplex) {
    Duplex = Duplex || require_stream_duplex()
    options = options || {}

    // Duplex streams are both readable and writable, but share
    // the same options object.
    // However, some cases require setting options to different
    // values for the readable and the writable sides of the duplex stream,
    // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.
    if (typeof isDuplex !== 'boolean') {
      isDuplex = stream instanceof Duplex
    }

    // object stream flag to indicate whether or not this stream
    // contains buffers or objects.
    this.objectMode = !!options.objectMode
    if (isDuplex) {
      this.objectMode = this.objectMode || !!options.writableObjectMode
    }

    // the point at which write() starts returning false
    // Note: 0 is a valid value, means that we always return false if
    // the entire buffer is not flushed immediately on write()
    this.highWaterMark = getHighWaterMark(
      this,
      options,
      'writableHighWaterMark',
      isDuplex
    )

    // if _final has been called
    this.finalCalled = false

    // drain event flag.
    this.needDrain = false
    // at the start of calling end()
    this.ending = false
    // when end() has been called, and returned
    this.ended = false
    // when 'finish' is emitted
    this.finished = false

    // has it been destroyed
    this.destroyed = false

    // should we decode strings into buffers before passing to _write?
    // this is here so that some node-core streams can optimize string
    // handling at a lower level.
    const noDecode = options.decodeStrings === false
    this.decodeStrings = !noDecode

    // Crypto is kind of old and crusty.  Historically, its default string
    // encoding is 'binary' so we have to make this configurable.
    // Everything else in the universe uses 'utf8', though.
    this.defaultEncoding = options.defaultEncoding || 'utf8'

    // not an actual buffer we keep track of, but a measurement
    // of how much we're waiting to get pushed to some underlying
    // socket or file.
    this.length = 0

    // a flag to see when we're in the middle of a write.
    this.writing = false

    // when true all writes will be buffered until .uncork() call
    this.corked = 0

    // a flag to be able to tell if the onwrite cb is called immediately,
    // or on a later tick.  We set this to true at first, because any
    // actions that shouldn't happen until "later" should generally also
    // not happen before the first write call.
    this.sync = true

    // a flag to know if we're processing previously buffered items, which
    // may call the _write() callback in the same tick, so that we don't
    // end up in an overlapped onwrite situation.
    this.bufferProcessing = false

    // the callback that's passed to _write(chunk,cb)
    this.onwrite = function (er) {
      onwrite(stream, er)
    }

    // the callback that the user supplies to write(chunk,encoding,cb)
    this.writecb = null

    // the amount that is being written when _write is called.
    this.writelen = 0
    this.bufferedRequest = null
    this.lastBufferedRequest = null

    // number of pending user-supplied write callbacks
    // this must be 0 before 'finish' can be emitted
    this.pendingcb = 0

    // emit prefinish if the only thing we're waiting for is _write cbs
    // This is relevant for synchronous Transform streams
    this.prefinished = false

    // True if the error was already emitted and should not be thrown again
    this.errorEmitted = false

    // Should close be emitted on destroy. Defaults to true.
    this.emitClose = options.emitClose !== false

    // Should .destroy() be called after 'finish' (and potentially 'end')
    this.autoDestroy = !!options.autoDestroy

    // count buffered requests
    this.bufferedRequestCount = 0

    // allocate the first CorkedRequest, there is always
    // one allocated and free to use, and we maintain at most two
    this.corkedRequestsFree = new CorkedRequest(this)
  }
  WritableState.prototype.getBuffer = function getBuffer() {
    let current = this.bufferedRequest
    const out = []
    while (current) {
      out.push(current)
      current = current.next
    }
    return out
  }
  ;(function () {
    try {
      Object.defineProperty(WritableState.prototype, 'buffer', {
        get: internalUtil.deprecate(
          function writableStateBufferGetter() {
            return this.getBuffer()
          },
          '_writableState.buffer is deprecated. Use _writableState.getBuffer ' +
            'instead.',
          'DEP0003'
        )
      })
    } catch (_) {}
  })()

  // Test _writableState for inheritance to account for Duplex streams,
  // whose prototype chain only points to Readable.
  let realHasInstance
  if (
    typeof Symbol === 'function' &&
    Symbol.hasInstance &&
    typeof Function.prototype[Symbol.hasInstance] === 'function'
  ) {
    realHasInstance = Function.prototype[Symbol.hasInstance]
    Object.defineProperty(Writable, Symbol.hasInstance, {
      value: function value(object) {
        if (realHasInstance.call(this, object)) {
          return true
        }
        if (this !== Writable) {
          return false
        }
        return object && object._writableState instanceof WritableState
      }
    })
  } else {
    realHasInstance = function realHasInstance(object) {
      return object instanceof this
    }
  }
  function Writable(options) {
    Duplex = Duplex || require_stream_duplex()

    // Writable ctor is applied to Duplexes, too.
    // `realHasInstance` is necessary because using plain `instanceof`
    // would return false, as no `_writableState` property is attached.

    // Trying to use the custom `instanceof` for Writable here will also break the
    // Node.js LazyTransform implementation, which has a non-trivial getter for
    // `_writableState` that would lead to infinite recursion.

    // Checking for a Stream.Duplex instance is faster here instead of inside
    // the WritableState constructor, at least with V8 6.5
    const isDuplex = this instanceof Duplex
    if (!isDuplex && !realHasInstance.call(Writable, this)) {
      return new Writable(options)
    }
    this._writableState = new WritableState(options, this, isDuplex)

    // legacy.
    this.writable = true
    if (options) {
      if (typeof options.write === 'function') {
        this._write = options.write
      }
      if (typeof options.writev === 'function') {
        this._writev = options.writev
      }
      if (typeof options.destroy === 'function') {
        this._destroy = options.destroy
      }
      if (typeof options.final === 'function') {
        this._final = options.final
      }
    }
    Stream.call(this)
  }

  // Otherwise people can pipe Writable streams, which is just wrong.
  Writable.prototype.pipe = function () {
    errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE())
  }
  function writeAfterEnd(stream, cb) {
    const er = new ERR_STREAM_WRITE_AFTER_END()
    // TODO: defer error events consistently everywhere, not just the cb
    errorOrDestroy(stream, er)
    process.nextTick(cb, er)
  }

  // Checks that a user-supplied chunk is valid, especially for the particular
  // mode the stream is in. Currently this means that `null` is never accepted
  // and undefined/non-string values are only allowed in object mode.
  function validChunk(stream, state, chunk, cb) {
    let er
    if (chunk === null) {
      er = new ERR_STREAM_NULL_VALUES()
    } else if (typeof chunk !== 'string' && !state.objectMode) {
      er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk)
    }
    if (er) {
      errorOrDestroy(stream, er)
      process.nextTick(cb, er)
      return false
    }
    return true
  }
  Writable.prototype.write = function (chunk, encoding, cb) {
    const state = this._writableState
    let ret = false
    const isBuf = !state.objectMode && _isUint8Array(chunk)
    if (isBuf && !Buffer.isBuffer(chunk)) {
      chunk = _uint8ArrayToBuffer(chunk)
    }
    if (typeof encoding === 'function') {
      cb = encoding
      encoding = null
    }
    if (isBuf) {
      encoding = 'buffer'
    } else if (!encoding) {
      encoding = state.defaultEncoding
    }
    if (typeof cb !== 'function') {
      cb = nop
    }
    if (state.ending) {
      writeAfterEnd(this, cb)
    } else if (isBuf || validChunk(this, state, chunk, cb)) {
      state.pendingcb++
      ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb)
    }
    return ret
  }
  Writable.prototype.cork = function () {
    this._writableState.corked++
  }
  Writable.prototype.uncork = function () {
    const state = this._writableState
    if (state.corked) {
      state.corked--
      if (
        !state.writing &&
        !state.corked &&
        !state.bufferProcessing &&
        state.bufferedRequest
      ) {
        clearBuffer(this, state)
      }
    }
  }
  Writable.prototype.setDefaultEncoding = function setDefaultEncoding(
    encoding
  ) {
    // node::ParseEncoding() requires lower case.
    if (typeof encoding === 'string') {
      encoding = encoding.toLowerCase()
    }
    if (
      !(
        [
          'hex',
          'utf8',
          'utf-8',
          'ascii',
          'binary',
          'base64',
          'ucs2',
          'ucs-2',
          'utf16le',
          'utf-16le',
          'raw'
        ].indexOf((encoding + '').toLowerCase()) > -1
      )
    ) {
      throw new ERR_UNKNOWN_ENCODING(encoding)
    }
    this._writableState.defaultEncoding = encoding
    return this
  }
  Object.defineProperty(Writable.prototype, 'writableBuffer', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState && this._writableState.getBuffer()
    }
  })
  function decodeChunk(state, chunk, encoding) {
    if (
      !state.objectMode &&
      state.decodeStrings !== false &&
      typeof chunk === 'string'
    ) {
      chunk = Buffer.from(chunk, encoding)
    }
    return chunk
  }
  Object.defineProperty(Writable.prototype, 'writableHighWaterMark', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState.highWaterMark
    }
  })

  // if we're already writing something, then just put this
  // in the queue, and wait our turn.  Otherwise, call _write
  // If we return false, then we need a drain event, so set that flag.
  function writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {
    if (!isBuf) {
      const newChunk = decodeChunk(state, chunk, encoding)
      if (chunk !== newChunk) {
        isBuf = true
        encoding = 'buffer'
        chunk = newChunk
      }
    }
    const len = state.objectMode ? 1 : chunk.length
    state.length += len
    const ret = state.length < state.highWaterMark
    // we must ensure that previous needDrain will not be reset to false.
    if (!ret) {
      state.needDrain = true
    }
    if (state.writing || state.corked) {
      const last = state.lastBufferedRequest
      state.lastBufferedRequest = {
        chunk: chunk,
        encoding: encoding,
        isBuf: isBuf,
        callback: cb,
        next: null
      }
      if (last) {
        last.next = state.lastBufferedRequest
      } else {
        state.bufferedRequest = state.lastBufferedRequest
      }
      state.bufferedRequestCount += 1
    } else {
      doWrite(stream, state, false, len, chunk, encoding, cb)
    }
    return ret
  }
  function doWrite(stream, state, writev, len, chunk, encoding, cb) {
    state.writelen = len
    state.writecb = cb
    state.writing = true
    state.sync = true
    if (state.destroyed) {
      state.onwrite(new ERR_STREAM_DESTROYED('write'))
    } else if (writev) {
      stream._writev(chunk, state.onwrite)
    } else {
      stream._write(chunk, encoding, state.onwrite)
    }
    state.sync = false
  }
  function onwriteError(stream, state, sync, er, cb) {
    --state.pendingcb
    if (sync) {
      // defer the callback if we are being called synchronously
      // to avoid piling up things on the stack
      process.nextTick(cb, er)
      // this can emit finish, and it will always happen
      // after error
      process.nextTick(finishMaybe, stream, state)
      stream._writableState.errorEmitted = true
      errorOrDestroy(stream, er)
    } else {
      // the caller expect this to happen before if
      // it is async
      cb(er)
      stream._writableState.errorEmitted = true
      errorOrDestroy(stream, er)
      // this can emit finish, but finish must
      // always follow error
      finishMaybe(stream, state)
    }
  }
  function onwriteStateUpdate(state) {
    state.writing = false
    state.writecb = null
    state.length -= state.writelen
    state.writelen = 0
  }
  function onwrite(stream, er) {
    const state = stream._writableState
    const sync = state.sync
    const cb = state.writecb
    if (typeof cb !== 'function') {
      throw new ERR_MULTIPLE_CALLBACK()
    }
    onwriteStateUpdate(state)
    if (er) {
      onwriteError(stream, state, sync, er, cb)
    } else {
      // Check if we're actually ready to finish, but don't emit yet
      const finished = needFinish(state) || stream.destroyed
      if (
        !finished &&
        !state.corked &&
        !state.bufferProcessing &&
        state.bufferedRequest
      ) {
        clearBuffer(stream, state)
      }
      if (sync) {
        process.nextTick(afterWrite, stream, state, finished, cb)
      } else {
        afterWrite(stream, state, finished, cb)
      }
    }
  }
  function afterWrite(stream, state, finished, cb) {
    if (!finished) {
      onwriteDrain(stream, state)
    }
    state.pendingcb--
    cb()
    finishMaybe(stream, state)
  }

  // Must force callback to be called on nextTick, so that we don't
  // emit 'drain' before the write() consumer gets the 'false' return
  // value, and has a chance to attach a 'drain' listener.
  function onwriteDrain(stream, state) {
    if (state.length === 0 && state.needDrain) {
      state.needDrain = false
      stream.emit('drain')
    }
  }

  // if there's something in the buffer waiting, then process it
  function clearBuffer(stream, state) {
    state.bufferProcessing = true
    let entry = state.bufferedRequest
    if (stream._writev && entry && entry.next) {
      // Fast case, write everything using _writev()
      const l = state.bufferedRequestCount
      const buffer = new Array(l)
      const holder = state.corkedRequestsFree
      holder.entry = entry
      let count = 0
      let allBuffers = true
      while (entry) {
        buffer[count] = entry
        if (!entry.isBuf) {
          allBuffers = false
        }
        entry = entry.next
        count += 1
      }
      buffer.allBuffers = allBuffers
      doWrite(stream, state, true, state.length, buffer, '', holder.finish)

      // doWrite is almost always async, defer these to save a bit of time
      // as the hot path ends with doWrite
      state.pendingcb++
      state.lastBufferedRequest = null
      if (holder.next) {
        state.corkedRequestsFree = holder.next
        holder.next = null
      } else {
        state.corkedRequestsFree = new CorkedRequest(state)
      }
      state.bufferedRequestCount = 0
    } else {
      // Slow case, write chunks one-by-one
      while (entry) {
        const chunk = entry.chunk
        const encoding = entry.encoding
        const cb = entry.callback
        const len = state.objectMode ? 1 : chunk.length
        doWrite(stream, state, false, len, chunk, encoding, cb)
        entry = entry.next
        state.bufferedRequestCount--
        // if we didn't call the onwrite immediately, then
        // it means that we need to wait until it does.
        // also, that means that the chunk and cb are currently
        // being processed, so move the buffer counter past them.
        if (state.writing) {
          break
        }
      }
      if (entry === null) {
        state.lastBufferedRequest = null
      }
    }
    state.bufferedRequest = entry
    state.bufferProcessing = false
  }
  Writable.prototype._write = function (chunk, encoding, cb) {
    cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'))
  }
  Writable.prototype._writev = null
  Writable.prototype.end = function (chunk, encoding, cb) {
    const state = this._writableState
    if (typeof chunk === 'function') {
      cb = chunk
      chunk = null
      encoding = null
    } else if (typeof encoding === 'function') {
      cb = encoding
      encoding = null
    }
    if (chunk !== null && chunk !== undefined) {
      this.write(chunk, encoding)
    }

    // .end() fully uncorks
    if (state.corked) {
      state.corked = 1
      this.uncork()
    }

    // ignore unnecessary end() calls.
    if (!state.ending) {
      endWritable(this, state, cb)
    }
    return this
  }
  Object.defineProperty(Writable.prototype, 'writableLength', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState.length
    }
  })
  function needFinish(state) {
    return (
      state.ending &&
      state.length === 0 &&
      state.bufferedRequest === null &&
      !state.finished &&
      !state.writing
    )
  }
  function callFinal(stream, state) {
    stream._final(function (err) {
      state.pendingcb--
      if (err) {
        errorOrDestroy(stream, err)
      }
      state.prefinished = true
      stream.emit('prefinish')
      finishMaybe(stream, state)
    })
  }
  function prefinish(stream, state) {
    if (!state.prefinished && !state.finalCalled) {
      if (typeof stream._final === 'function' && !state.destroyed) {
        state.pendingcb++
        state.finalCalled = true
        process.nextTick(callFinal, stream, state)
      } else {
        state.prefinished = true
        stream.emit('prefinish')
      }
    }
  }
  function finishMaybe(stream, state) {
    const need = needFinish(state)
    if (need) {
      prefinish(stream, state)
      if (state.pendingcb === 0) {
        state.finished = true
        stream.emit('finish')
        if (state.autoDestroy) {
          // In case of duplex streams we need a way to detect
          // if the readable side is ready for autoDestroy as well
          const rState = stream._readableState
          if (!rState || (rState.autoDestroy && rState.endEmitted)) {
            stream.destroy()
          }
        }
      }
    }
    return need
  }
  function endWritable(stream, state, cb) {
    state.ending = true
    finishMaybe(stream, state)
    if (cb) {
      if (state.finished) {
        process.nextTick(cb)
      } else {
        stream.once('finish', cb)
      }
    }
    state.ended = true
    stream.writable = false
  }
  function onCorkedFinish(corkReq, state, err) {
    let entry = corkReq.entry
    corkReq.entry = null
    while (entry) {
      const cb = entry.callback
      state.pendingcb--
      cb(err)
      entry = entry.next
    }

    // reuse the free corkReq.
    state.corkedRequestsFree.next = corkReq
  }
  Object.defineProperty(Writable.prototype, 'destroyed', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      if (this._writableState === undefined) {
        return false
      }
      return this._writableState.destroyed
    },
    set: function set(value) {
      // we ignore the value if the stream
      // has not been initialized yet
      if (!this._writableState) {
        return
      }

      // backward compatibility, the user is explicitly
      // managing destroyed
      this._writableState.destroyed = value
    }
  })
  Writable.prototype.destroy = destroyImpl.destroy
  Writable.prototype._undestroy = destroyImpl.undestroy
  Writable.prototype._destroy = function (err, cb) {
    cb(err)
  }
  return _stream_writable
}

let _stream_duplex
let hasRequired_stream_duplex
function require_stream_duplex() {
  if (hasRequired_stream_duplex) {
    return _stream_duplex
  }
  hasRequired_stream_duplex = 1

  /*<replacement>*/
  const objectKeys =
    Object.keys ||
    function (obj) {
      const keys = []
      for (const key in obj) {
        keys.push(key)
      }
      return keys
    }
  /*</replacement>*/

  _stream_duplex = Duplex
  const Readable = require_stream_readable()
  const Writable = require_stream_writable()
  requireInherits()(Duplex, Readable)
  {
    // Allow the keys array to be GC'ed.
    const keys = objectKeys(Writable.prototype)
    for (let v = 0; v < keys.length; v++) {
      const method = keys[v]
      if (!Duplex.prototype[method]) {
        Duplex.prototype[method] = Writable.prototype[method]
      }
    }
  }
  function Duplex(options) {
    if (!(this instanceof Duplex)) {
      return new Duplex(options)
    }
    Readable.call(this, options)
    Writable.call(this, options)
    this.allowHalfOpen = true
    if (options) {
      if (options.readable === false) {
        this.readable = false
      }
      if (options.writable === false) {
        this.writable = false
      }
      if (options.allowHalfOpen === false) {
        this.allowHalfOpen = false
        this.once('end', onend)
      }
    }
  }
  Object.defineProperty(Duplex.prototype, 'writableHighWaterMark', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState.highWaterMark
    }
  })
  Object.defineProperty(Duplex.prototype, 'writableBuffer', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState && this._writableState.getBuffer()
    }
  })
  Object.defineProperty(Duplex.prototype, 'writableLength', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._writableState.length
    }
  })

  // the no-half-open enforcer
  function onend() {
    // If the writable side ended, then we're ok.
    if (this._writableState.ended) {
      return
    }

    // no more data can be written.
    // But allow more writes to happen in this tick.
    process.nextTick(onEndNT, this)
  }
  function onEndNT(self) {
    self.end()
  }
  Object.defineProperty(Duplex.prototype, 'destroyed', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      if (
        this._readableState === undefined ||
        this._writableState === undefined
      ) {
        return false
      }
      return this._readableState.destroyed && this._writableState.destroyed
    },
    set: function set(value) {
      // we ignore the value if the stream
      // has not been initialized yet
      if (
        this._readableState === undefined ||
        this._writableState === undefined
      ) {
        return
      }

      // backward compatibility, the user is explicitly
      // managing destroyed
      this._readableState.destroyed = value
      this._writableState.destroyed = value
    }
  })
  return _stream_duplex
}

const string_decoder = {}

let hasRequiredString_decoder
function requireString_decoder() {
  if (hasRequiredString_decoder) {
    return string_decoder
  }
  hasRequiredString_decoder = 1

  /*<replacement>*/

  const Buffer = /*@__PURE__*/ requireSafeBuffer().Buffer
  /*</replacement>*/

  const isEncoding =
    Buffer.isEncoding ||
    function (encoding) {
      encoding = '' + encoding
      switch (encoding && encoding.toLowerCase()) {
        case 'hex':
        case 'utf8':
        case 'utf-8':
        case 'ascii':
        case 'binary':
        case 'base64':
        case 'ucs2':
        case 'ucs-2':
        case 'utf16le':
        case 'utf-16le':
        case 'raw':
          return true
        default:
          return false
      }
    }
  function _normalizeEncoding(enc) {
    if (!enc) {
      return 'utf8'
    }
    let retried
    while (true) {
      switch (enc) {
        case 'utf8':
        case 'utf-8':
          return 'utf8'
        case 'ucs2':
        case 'ucs-2':
        case 'utf16le':
        case 'utf-16le':
          return 'utf16le'
        case 'latin1':
        case 'binary':
          return 'latin1'
        case 'base64':
        case 'ascii':
        case 'hex':
          return enc
        default:
          if (retried) {
            return
          } // undefined
          enc = ('' + enc).toLowerCase()
          retried = true
      }
    }
  }

  // Do not cache `Buffer.isEncoding` when checking encoding names as some
  // modules monkey-patch it to support additional encodings
  function normalizeEncoding(enc) {
    const nenc = _normalizeEncoding(enc)
    if (
      typeof nenc !== 'string' &&
      (Buffer.isEncoding === isEncoding || !isEncoding(enc))
    ) {
      throw new Error('Unknown encoding: ' + enc)
    }
    return nenc || enc
  }

  // StringDecoder provides an interface for efficiently splitting a series of
  // buffers into a series of JS strings without breaking apart multi-byte
  // characters.
  string_decoder.StringDecoder = StringDecoder
  function StringDecoder(encoding) {
    this.encoding = normalizeEncoding(encoding)
    let nb
    switch (this.encoding) {
      case 'utf16le':
        this.text = utf16Text
        this.end = utf16End
        nb = 4
        break
      case 'utf8':
        this.fillLast = utf8FillLast
        nb = 4
        break
      case 'base64':
        this.text = base64Text
        this.end = base64End
        nb = 3
        break
      default:
        this.write = simpleWrite
        this.end = simpleEnd
        return
    }
    this.lastNeed = 0
    this.lastTotal = 0
    this.lastChar = Buffer.allocUnsafe(nb)
  }
  StringDecoder.prototype.write = function (buf) {
    if (buf.length === 0) {
      return ''
    }
    let r
    let i
    if (this.lastNeed) {
      r = this.fillLast(buf)
      if (r === undefined) {
        return ''
      }
      i = this.lastNeed
      this.lastNeed = 0
    } else {
      i = 0
    }
    if (i < buf.length) {
      return r ? r + this.text(buf, i) : this.text(buf, i)
    }
    return r || ''
  }
  StringDecoder.prototype.end = utf8End

  // Returns only complete characters in a Buffer
  StringDecoder.prototype.text = utf8Text

  // Attempts to complete a partial non-UTF-8 character using bytes from a Buffer
  StringDecoder.prototype.fillLast = function (buf) {
    if (this.lastNeed <= buf.length) {
      buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed)
      return this.lastChar.toString(this.encoding, 0, this.lastTotal)
    }
    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length)
    this.lastNeed -= buf.length
  }

  // Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a
  // continuation byte. If an invalid byte is detected, -2 is returned.
  function utf8CheckByte(byte) {
    if (byte <= 0x7f) {
      return 0
    } else if (byte >> 5 === 0x06) {
      return 2
    } else if (byte >> 4 === 0x0e) {
      return 3
    } else if (byte >> 3 === 0x1e) {
      return 4
    }
    return byte >> 6 === 0x02 ? -1 : -2
  }

  // Checks at most 3 bytes at the end of a Buffer in order to detect an
  // incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)
  // needed to complete the UTF-8 character (if applicable) are returned.
  function utf8CheckIncomplete(self, buf, i) {
    let j = buf.length - 1
    if (j < i) {
      return 0
    }
    let nb = utf8CheckByte(buf[j])
    if (nb >= 0) {
      if (nb > 0) {
        self.lastNeed = nb - 1
      }
      return nb
    }
    if (--j < i || nb === -2) {
      return 0
    }
    nb = utf8CheckByte(buf[j])
    if (nb >= 0) {
      if (nb > 0) {
        self.lastNeed = nb - 2
      }
      return nb
    }
    if (--j < i || nb === -2) {
      return 0
    }
    nb = utf8CheckByte(buf[j])
    if (nb >= 0) {
      if (nb > 0) {
        if (nb === 2) {
          nb = 0
        } else {
          self.lastNeed = nb - 3
        }
      }
      return nb
    }
    return 0
  }

  // Validates as many continuation bytes for a multi-byte UTF-8 character as
  // needed or are available. If we see a non-continuation byte where we expect
  // one, we "replace" the validated continuation bytes we've seen so far with
  // a single UTF-8 replacement character ('\ufffd'), to match v8's UTF-8 decoding
  // behavior. The continuation byte check is included three times in the case
  // where all of the continuation bytes for a character exist in the same buffer.
  // It is also done this way as a slight performance increase instead of using a
  // loop.
  function utf8CheckExtraBytes(self, buf, p) {
    if ((buf[0] & 0xc0) !== 0x80) {
      self.lastNeed = 0
      return '\ufffd'
    }
    if (self.lastNeed > 1 && buf.length > 1) {
      if ((buf[1] & 0xc0) !== 0x80) {
        self.lastNeed = 1
        return '\ufffd'
      }
      if (self.lastNeed > 2 && buf.length > 2) {
        if ((buf[2] & 0xc0) !== 0x80) {
          self.lastNeed = 2
          return '\ufffd'
        }
      }
    }
  }

  // Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.
  function utf8FillLast(buf) {
    const p = this.lastTotal - this.lastNeed
    const r = utf8CheckExtraBytes(this, buf)
    if (r !== undefined) {
      return r
    }
    if (this.lastNeed <= buf.length) {
      buf.copy(this.lastChar, p, 0, this.lastNeed)
      return this.lastChar.toString(this.encoding, 0, this.lastTotal)
    }
    buf.copy(this.lastChar, p, 0, buf.length)
    this.lastNeed -= buf.length
  }

  // Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a
  // partial character, the character's bytes are buffered until the required
  // number of bytes are available.
  function utf8Text(buf, i) {
    const total = utf8CheckIncomplete(this, buf, i)
    if (!this.lastNeed) {
      return buf.toString('utf8', i)
    }
    this.lastTotal = total
    const end = buf.length - (total - this.lastNeed)
    buf.copy(this.lastChar, 0, end)
    return buf.toString('utf8', i, end)
  }

  // For UTF-8, a replacement character is added when ending on a partial
  // character.
  function utf8End(buf) {
    const r = buf && buf.length ? this.write(buf) : ''
    if (this.lastNeed) {
      return r + '\ufffd'
    }
    return r
  }

  // UTF-16LE typically needs two bytes per character, but even if we have an even
  // number of bytes available, we need to check if we end on a leading/high
  // surrogate. In that case, we need to wait for the next two bytes in order to
  // decode the last character properly.
  function utf16Text(buf, i) {
    if ((buf.length - i) % 2 === 0) {
      const r = buf.toString('utf16le', i)
      if (r) {
        const c = r.charCodeAt(r.length - 1)
        if (c >= 0xd800 && c <= 0xdbff) {
          this.lastNeed = 2
          this.lastTotal = 4
          this.lastChar[0] = buf[buf.length - 2]
          this.lastChar[1] = buf[buf.length - 1]
          return r.slice(0, -1)
        }
      }
      return r
    }
    this.lastNeed = 1
    this.lastTotal = 2
    this.lastChar[0] = buf[buf.length - 1]
    return buf.toString('utf16le', i, buf.length - 1)
  }

  // For UTF-16LE we do not explicitly append special replacement characters if we
  // end on a partial character, we simply let v8 handle that.
  function utf16End(buf) {
    const r = buf && buf.length ? this.write(buf) : ''
    if (this.lastNeed) {
      const end = this.lastTotal - this.lastNeed
      return r + this.lastChar.toString('utf16le', 0, end)
    }
    return r
  }
  function base64Text(buf, i) {
    const n = (buf.length - i) % 3
    if (n === 0) {
      return buf.toString('base64', i)
    }
    this.lastNeed = 3 - n
    this.lastTotal = 3
    if (n === 1) {
      this.lastChar[0] = buf[buf.length - 1]
    } else {
      this.lastChar[0] = buf[buf.length - 2]
      this.lastChar[1] = buf[buf.length - 1]
    }
    return buf.toString('base64', i, buf.length - n)
  }
  function base64End(buf) {
    const r = buf && buf.length ? this.write(buf) : ''
    if (this.lastNeed) {
      return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed)
    }
    return r
  }

  // Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)
  function simpleWrite(buf) {
    return buf.toString(this.encoding)
  }
  function simpleEnd(buf) {
    return buf && buf.length ? this.write(buf) : ''
  }
  return string_decoder
}

let endOfStream
let hasRequiredEndOfStream
function requireEndOfStream() {
  if (hasRequiredEndOfStream) {
    return endOfStream
  }
  hasRequiredEndOfStream = 1
  const ERR_STREAM_PREMATURE_CLOSE =
    requireErrors$1().codes.ERR_STREAM_PREMATURE_CLOSE
  function once(callback) {
    let called = false
    return function () {
      if (called) {
        return
      }
      called = true
      for (
        let _len = arguments.length, args = new Array(_len), _key = 0;
        _key < _len;
        _key++
      ) {
        args[_key] = arguments[_key]
      }
      callback.apply(this, args)
    }
  }
  function noop() {}
  function isRequest(stream) {
    return stream.setHeader && typeof stream.abort === 'function'
  }
  function eos(stream, opts, callback) {
    if (typeof opts === 'function') {
      return eos(stream, null, opts)
    }
    if (!opts) {
      opts = {}
    }
    callback = once(callback || noop)
    let readable = opts.readable || (opts.readable !== false && stream.readable)
    let writable = opts.writable || (opts.writable !== false && stream.writable)
    const onlegacyfinish = function onlegacyfinish() {
      if (!stream.writable) {
        onfinish()
      }
    }
    let writableEnded = stream._writableState && stream._writableState.finished
    const onfinish = function onfinish() {
      writable = false
      writableEnded = true
      if (!readable) {
        callback.call(stream)
      }
    }
    let readableEnded =
      stream._readableState && stream._readableState.endEmitted
    const onend = function onend() {
      readable = false
      readableEnded = true
      if (!writable) {
        callback.call(stream)
      }
    }
    const onerror = function onerror(err) {
      callback.call(stream, err)
    }
    const onclose = function onclose() {
      let err
      if (readable && !readableEnded) {
        if (!stream._readableState || !stream._readableState.ended) {
          err = new ERR_STREAM_PREMATURE_CLOSE()
        }
        return callback.call(stream, err)
      }
      if (writable && !writableEnded) {
        if (!stream._writableState || !stream._writableState.ended) {
          err = new ERR_STREAM_PREMATURE_CLOSE()
        }
        return callback.call(stream, err)
      }
    }
    const onrequest = function onrequest() {
      stream.req.on('finish', onfinish)
    }
    if (isRequest(stream)) {
      stream.on('complete', onfinish)
      stream.on('abort', onclose)
      if (stream.req) {
        onrequest()
      } else {
        stream.on('request', onrequest)
      }
    } else if (writable && !stream._writableState) {
      // legacy streams
      stream.on('end', onlegacyfinish)
      stream.on('close', onlegacyfinish)
    }
    stream.on('end', onend)
    stream.on('finish', onfinish)
    if (opts.error !== false) {
      stream.on('error', onerror)
    }
    stream.on('close', onclose)
    return function () {
      stream.removeListener('complete', onfinish)
      stream.removeListener('abort', onclose)
      stream.removeListener('request', onrequest)
      if (stream.req) {
        stream.req.removeListener('finish', onfinish)
      }
      stream.removeListener('end', onlegacyfinish)
      stream.removeListener('close', onlegacyfinish)
      stream.removeListener('finish', onfinish)
      stream.removeListener('end', onend)
      stream.removeListener('error', onerror)
      stream.removeListener('close', onclose)
    }
  }
  endOfStream = eos
  return endOfStream
}

let async_iterator
let hasRequiredAsync_iterator
function requireAsync_iterator() {
  if (hasRequiredAsync_iterator) {
    return async_iterator
  }
  hasRequiredAsync_iterator = 1
  let _Object$setPrototypeO
  function _defineProperty(obj, key, value) {
    key = _toPropertyKey(key)
    if (key in obj) {
      Object.defineProperty(obj, key, {
        value: value,
        enumerable: true,
        configurable: true,
        writable: true
      })
    } else {
      obj[key] = value
    }
    return obj
  }
  function _toPropertyKey(arg) {
    const key = _toPrimitive(arg, 'string')
    return typeof key === 'symbol' ? key : String(key)
  }
  function _toPrimitive(input, hint) {
    if (typeof input !== 'object' || input === null) {
      return input
    }
    const prim = input[Symbol.toPrimitive]
    if (prim !== undefined) {
      const res = prim.call(input, hint)
      if (typeof res !== 'object') {
        return res
      }
      throw new TypeError('@@toPrimitive must return a primitive value.')
    }
    return (hint === 'string' ? String : Number)(input)
  }
  const finished = requireEndOfStream()
  const kLastResolve = Symbol('lastResolve')
  const kLastReject = Symbol('lastReject')
  const kError = Symbol('error')
  const kEnded = Symbol('ended')
  const kLastPromise = Symbol('lastPromise')
  const kHandlePromise = Symbol('handlePromise')
  const kStream = Symbol('stream')
  function createIterResult(value, done) {
    return {
      value: value,
      done: done
    }
  }
  function readAndResolve(iter) {
    const resolve = iter[kLastResolve]
    if (resolve !== null) {
      const data = iter[kStream].read()
      // we defer if data is null
      // we can be expecting either 'end' or
      // 'error'
      if (data !== null) {
        iter[kLastPromise] = null
        iter[kLastResolve] = null
        iter[kLastReject] = null
        resolve(createIterResult(data, false))
      }
    }
  }
  function onReadable(iter) {
    // we wait for the next tick, because it might
    // emit an error with process.nextTick
    process.nextTick(readAndResolve, iter)
  }
  function wrapForNext(lastPromise, iter) {
    return function (resolve, reject) {
      lastPromise.then(function () {
        if (iter[kEnded]) {
          resolve(createIterResult(undefined, true))
          return
        }
        iter[kHandlePromise](resolve, reject)
      }, reject)
    }
  }
  const AsyncIteratorPrototype = Object.getPrototypeOf(function () {})
  const ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf(
    ((_Object$setPrototypeO = {
      get stream() {
        return this[kStream]
      },
      next: function next() {
        const _this = this
        // if we have detected an error in the meanwhile
        // reject straight away
        const error = this[kError]
        if (error !== null) {
          return Promise.reject(error)
        }
        if (this[kEnded]) {
          return Promise.resolve(createIterResult(undefined, true))
        }
        if (this[kStream].destroyed) {
          // We need to defer via nextTick because if .destroy(err) is
          // called, the error will be emitted via nextTick, and
          // we cannot guarantee that there is no error lingering around
          // waiting to be emitted.
          return new Promise(function (resolve, reject) {
            process.nextTick(function () {
              if (_this[kError]) {
                reject(_this[kError])
              } else {
                resolve(createIterResult(undefined, true))
              }
            })
          })
        }

        // if we have multiple next() calls
        // we will wait for the previous Promise to finish
        // this logic is optimized to support for await loops,
        // where next() is only called once at a time
        const lastPromise = this[kLastPromise]
        let promise
        if (lastPromise) {
          promise = new Promise(wrapForNext(lastPromise, this))
        } else {
          // fast path needed to support multiple this.push()
          // without triggering the next() queue
          const data = this[kStream].read()
          if (data !== null) {
            return Promise.resolve(createIterResult(data, false))
          }
          promise = new Promise(this[kHandlePromise])
        }
        this[kLastPromise] = promise
        return promise
      }
    }),
    _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {
      return this
    }),
    _defineProperty(_Object$setPrototypeO, 'return', function _return() {
      const _this2 = this
      // destroy(err, cb) is a private API
      // we can guarantee we have that here, because we control the
      // Readable class this is attached to
      return new Promise(function (resolve, reject) {
        _this2[kStream].destroy(null, function (err) {
          if (err) {
            reject(err)
            return
          }
          resolve(createIterResult(undefined, true))
        })
      })
    }),
    _Object$setPrototypeO),
    AsyncIteratorPrototype
  )
  const createReadableStreamAsyncIterator =
    function createReadableStreamAsyncIterator(stream) {
      let _Object$create
      const iterator = Object.create(
        ReadableStreamAsyncIteratorPrototype,
        ((_Object$create = {}),
        _defineProperty(_Object$create, kStream, {
          value: stream,
          writable: true
        }),
        _defineProperty(_Object$create, kLastResolve, {
          value: null,
          writable: true
        }),
        _defineProperty(_Object$create, kLastReject, {
          value: null,
          writable: true
        }),
        _defineProperty(_Object$create, kError, {
          value: null,
          writable: true
        }),
        _defineProperty(_Object$create, kEnded, {
          value: stream._readableState.endEmitted,
          writable: true
        }),
        _defineProperty(_Object$create, kHandlePromise, {
          value: function value(resolve, reject) {
            const data = iterator[kStream].read()
            if (data) {
              iterator[kLastPromise] = null
              iterator[kLastResolve] = null
              iterator[kLastReject] = null
              resolve(createIterResult(data, false))
            } else {
              iterator[kLastResolve] = resolve
              iterator[kLastReject] = reject
            }
          },
          writable: true
        }),
        _Object$create)
      )
      iterator[kLastPromise] = null
      finished(stream, function (err) {
        if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {
          const reject = iterator[kLastReject]
          // reject if we are waiting for data in the Promise
          // returned by next() and store the error
          if (reject !== null) {
            iterator[kLastPromise] = null
            iterator[kLastResolve] = null
            iterator[kLastReject] = null
            reject(err)
          }
          iterator[kError] = err
          return
        }
        const resolve = iterator[kLastResolve]
        if (resolve !== null) {
          iterator[kLastPromise] = null
          iterator[kLastResolve] = null
          iterator[kLastReject] = null
          resolve(createIterResult(undefined, true))
        }
        iterator[kEnded] = true
      })
      stream.on('readable', onReadable.bind(null, iterator))
      return iterator
    }
  async_iterator = createReadableStreamAsyncIterator
  return async_iterator
}

let from_1
let hasRequiredFrom
function requireFrom() {
  if (hasRequiredFrom) {
    return from_1
  }
  hasRequiredFrom = 1
  function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) {
    try {
      const info = gen[key](arg)
      const value = info.value
    } catch (error) {
      reject(error)
      return
    }
    if (info.done) {
      resolve(value)
    } else {
      Promise.resolve(value).then(_next, _throw)
    }
  }
  function _asyncToGenerator(fn) {
    return function () {
      const self = this,
        args = arguments
      return new Promise(function (resolve, reject) {
        const gen = fn.apply(self, args)
        function _next(value) {
          asyncGeneratorStep(gen, resolve, reject, _next, _throw, 'next', value)
        }
        function _throw(err) {
          asyncGeneratorStep(gen, resolve, reject, _next, _throw, 'throw', err)
        }
        _next(undefined)
      })
    }
  }
  function ownKeys(object, enumerableOnly) {
    const keys = Object.keys(object)
    if (Object.getOwnPropertySymbols) {
      let symbols = Object.getOwnPropertySymbols(object)
      enumerableOnly &&
        (symbols = symbols.filter(function (sym) {
          return Object.getOwnPropertyDescriptor(object, sym).enumerable
        })),
        keys.push.apply(keys, symbols)
    }
    return keys
  }
  function _objectSpread(target) {
    for (let i = 1; i < arguments.length; i++) {
      const source = null != arguments[i] ? arguments[i] : {}
      i % 2
        ? ownKeys(Object(source), true).forEach(function (key) {
            _defineProperty(target, key, source[key])
          })
        : Object.getOwnPropertyDescriptors
          ? Object.defineProperties(
              target,
              Object.getOwnPropertyDescriptors(source)
            )
          : ownKeys(Object(source)).forEach(function (key) {
              Object.defineProperty(
                target,
                key,
                Object.getOwnPropertyDescriptor(source, key)
              )
            })
    }
    return target
  }
  function _defineProperty(obj, key, value) {
    key = _toPropertyKey(key)
    if (key in obj) {
      Object.defineProperty(obj, key, {
        value: value,
        enumerable: true,
        configurable: true,
        writable: true
      })
    } else {
      obj[key] = value
    }
    return obj
  }
  function _toPropertyKey(arg) {
    const key = _toPrimitive(arg, 'string')
    return typeof key === 'symbol' ? key : String(key)
  }
  function _toPrimitive(input, hint) {
    if (typeof input !== 'object' || input === null) {
      return input
    }
    const prim = input[Symbol.toPrimitive]
    if (prim !== undefined) {
      const res = prim.call(input, hint)
      if (typeof res !== 'object') {
        return res
      }
      throw new TypeError('@@toPrimitive must return a primitive value.')
    }
    return (hint === 'string' ? String : Number)(input)
  }
  const ERR_INVALID_ARG_TYPE = requireErrors$1().codes.ERR_INVALID_ARG_TYPE
  function from(Readable, iterable, opts) {
    let iterator
    if (iterable && typeof iterable.next === 'function') {
      iterator = iterable
    } else if (iterable && iterable[Symbol.asyncIterator]) {
      iterator = iterable[Symbol.asyncIterator]()
    } else if (iterable && iterable[Symbol.iterator]) {
      iterator = iterable[Symbol.iterator]()
    } else {
      throw new ERR_INVALID_ARG_TYPE('iterable', ['Iterable'], iterable)
    }
    const readable = new Readable(
      _objectSpread(
        {
          objectMode: true
        },
        opts
      )
    )
    // Reading boolean to protect against _read
    // being called before last iteration completion.
    let reading = false
    readable._read = function () {
      if (!reading) {
        reading = true
        next()
      }
    }
    function next() {
      return _next2.apply(this, arguments)
    }
    function _next2() {
      _next2 = _asyncToGenerator(function* () {
        try {
          const _yield$iterator$next = yield iterator.next(),
            value = _yield$iterator$next.value,
            done = _yield$iterator$next.done
          if (done) {
            readable.push(null)
          } else if (readable.push(yield value)) {
            next()
          } else {
            reading = false
          }
        } catch (err) {
          readable.destroy(err)
        }
      })
      return _next2.apply(this, arguments)
    }
    return readable
  }
  from_1 = from
  return from_1
}

let _stream_readable
let hasRequired_stream_readable
function require_stream_readable() {
  if (hasRequired_stream_readable) {
    return _stream_readable
  }
  hasRequired_stream_readable = 1
  _stream_readable = Readable

  /*<replacement>*/
  let Duplex
  /*</replacement>*/

  Readable.ReadableState = ReadableState

  /*<replacement>*/
  require$$0$h.EventEmitter
  const EElistenerCount = function EElistenerCount(emitter, type) {
    return emitter.listeners(type).length
  }
  /*</replacement>*/

  /*<replacement>*/
  const Stream = requireStream$1()
  /*</replacement>*/

  const Buffer = require$$2$4.Buffer
  const OurUint8Array =
    (typeof global !== 'undefined'
      ? global
      : typeof window !== 'undefined'
        ? window
        : typeof self !== 'undefined'
          ? self
          : {}
    ).Uint8Array || function () {}
  function _uint8ArrayToBuffer(chunk) {
    return Buffer.from(chunk)
  }
  function _isUint8Array(obj) {
    return Buffer.isBuffer(obj) || obj instanceof OurUint8Array
  }

  /*<replacement>*/
  const debugUtil = require$$0$4
  let debug
  if (debugUtil && debugUtil.debuglog) {
    debug = debugUtil.debuglog('stream')
  } else {
    debug = function debug() {}
  }
  /*</replacement>*/

  const BufferList = requireBuffer_list()
  const destroyImpl = requireDestroy()
  const _require = requireState(),
    getHighWaterMark = _require.getHighWaterMark
  const _require$codes = requireErrors$1().codes,
    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,
    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_STREAM_UNSHIFT_AFTER_END_EVENT =
      _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT

  // Lazy loaded to improve the startup performance.
  let StringDecoder
  let createReadableStreamAsyncIterator
  let from
  requireInherits()(Readable, Stream)
  const errorOrDestroy = destroyImpl.errorOrDestroy
  const kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume']
  function prependListener(emitter, event, fn) {
    // Sadly this is not cacheable as some libraries bundle their own
    // event emitter implementation with them.
    if (typeof emitter.prependListener === 'function') {
      return emitter.prependListener(event, fn)
    }

    // This is a hack to make sure that our error handler is attached before any
    // userland ones.  NEVER DO THIS. This is here only because this code needs
    // to continue to work with older versions of Node.js that do not include
    // the prependListener() method. The goal is to eventually remove this hack.
    if (!emitter._events || !emitter._events[event]) {
      emitter.on(event, fn)
    } else if (Array.isArray(emitter._events[event])) {
      emitter._events[event].unshift(fn)
    } else {
      emitter._events[event] = [fn, emitter._events[event]]
    }
  }
  function ReadableState(options, stream, isDuplex) {
    Duplex = Duplex || require_stream_duplex()
    options = options || {}

    // Duplex streams are both readable and writable, but share
    // the same options object.
    // However, some cases require setting options to different
    // values for the readable and the writable sides of the duplex stream.
    // These options can be provided separately as readableXXX and writableXXX.
    if (typeof isDuplex !== 'boolean') {
      isDuplex = stream instanceof Duplex
    }

    // object stream flag. Used to make read(n) ignore n and to
    // make all the buffer merging and length checks go away
    this.objectMode = !!options.objectMode
    if (isDuplex) {
      this.objectMode = this.objectMode || !!options.readableObjectMode
    }

    // the point at which it stops calling _read() to fill the buffer
    // Note: 0 is a valid value, means "don't call _read preemptively ever"
    this.highWaterMark = getHighWaterMark(
      this,
      options,
      'readableHighWaterMark',
      isDuplex
    )

    // A linked list is used to store data chunks instead of an array because the
    // linked list can remove elements from the beginning faster than
    // array.shift()
    this.buffer = new BufferList()
    this.length = 0
    this.pipes = null
    this.pipesCount = 0
    this.flowing = null
    this.ended = false
    this.endEmitted = false
    this.reading = false

    // a flag to be able to tell if the event 'readable'/'data' is emitted
    // immediately, or on a later tick.  We set this to true at first, because
    // any actions that shouldn't happen until "later" should generally also
    // not happen before the first read call.
    this.sync = true

    // whenever we return null, then we set a flag to say
    // that we're awaiting a 'readable' event emission.
    this.needReadable = false
    this.emittedReadable = false
    this.readableListening = false
    this.resumeScheduled = false
    this.paused = true

    // Should close be emitted on destroy. Defaults to true.
    this.emitClose = options.emitClose !== false

    // Should .destroy() be called after 'end' (and potentially 'finish')
    this.autoDestroy = !!options.autoDestroy

    // has it been destroyed
    this.destroyed = false

    // Crypto is kind of old and crusty.  Historically, its default string
    // encoding is 'binary' so we have to make this configurable.
    // Everything else in the universe uses 'utf8', though.
    this.defaultEncoding = options.defaultEncoding || 'utf8'

    // the number of writers that are awaiting a drain event in .pipe()s
    this.awaitDrain = 0

    // if true, a maybeReadMore has been scheduled
    this.readingMore = false
    this.decoder = null
    this.encoding = null
    if (options.encoding) {
      if (!StringDecoder) {
        StringDecoder = requireString_decoder().StringDecoder
      }
      this.decoder = new StringDecoder(options.encoding)
      this.encoding = options.encoding
    }
  }
  function Readable(options) {
    Duplex = Duplex || require_stream_duplex()
    if (!(this instanceof Readable)) {
      return new Readable(options)
    }

    // Checking for a Stream.Duplex instance is faster here instead of inside
    // the ReadableState constructor, at least with V8 6.5
    const isDuplex = this instanceof Duplex
    this._readableState = new ReadableState(options, this, isDuplex)

    // legacy
    this.readable = true
    if (options) {
      if (typeof options.read === 'function') {
        this._read = options.read
      }
      if (typeof options.destroy === 'function') {
        this._destroy = options.destroy
      }
    }
    Stream.call(this)
  }
  Object.defineProperty(Readable.prototype, 'destroyed', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      if (this._readableState === undefined) {
        return false
      }
      return this._readableState.destroyed
    },
    set: function set(value) {
      // we ignore the value if the stream
      // has not been initialized yet
      if (!this._readableState) {
        return
      }

      // backward compatibility, the user is explicitly
      // managing destroyed
      this._readableState.destroyed = value
    }
  })
  Readable.prototype.destroy = destroyImpl.destroy
  Readable.prototype._undestroy = destroyImpl.undestroy
  Readable.prototype._destroy = function (err, cb) {
    cb(err)
  }

  // Manually shove something into the read() buffer.
  // This returns true if the highWaterMark has not been hit yet,
  // similar to how Writable.write() returns true if you should
  // write() some more.
  Readable.prototype.push = function (chunk, encoding) {
    const state = this._readableState
    let skipChunkCheck
    if (!state.objectMode) {
      if (typeof chunk === 'string') {
        encoding = encoding || state.defaultEncoding
        if (encoding !== state.encoding) {
          chunk = Buffer.from(chunk, encoding)
          encoding = ''
        }
        skipChunkCheck = true
      }
    } else {
      skipChunkCheck = true
    }
    return readableAddChunk(this, chunk, encoding, false, skipChunkCheck)
  }

  // Unshift should *always* be something directly out of read()
  Readable.prototype.unshift = function (chunk) {
    return readableAddChunk(this, chunk, null, true, false)
  }
  function readableAddChunk(
    stream,
    chunk,
    encoding,
    addToFront,
    skipChunkCheck
  ) {
    debug('readableAddChunk', chunk)
    const state = stream._readableState
    if (chunk === null) {
      state.reading = false
      onEofChunk(stream, state)
    } else {
      let er
      if (!skipChunkCheck) {
        er = chunkInvalid(state, chunk)
      }
      if (er) {
        errorOrDestroy(stream, er)
      } else if (state.objectMode || (chunk && chunk.length > 0)) {
        if (
          typeof chunk !== 'string' &&
          !state.objectMode &&
          Object.getPrototypeOf(chunk) !== Buffer.prototype
        ) {
          chunk = _uint8ArrayToBuffer(chunk)
        }
        if (addToFront) {
          if (state.endEmitted) {
            errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT())
          } else {
            addChunk(stream, state, chunk, true)
          }
        } else if (state.ended) {
          errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF())
        } else if (state.destroyed) {
          return false
        } else {
          state.reading = false
          if (state.decoder && !encoding) {
            chunk = state.decoder.write(chunk)
            if (state.objectMode || chunk.length !== 0) {
              addChunk(stream, state, chunk, false)
            } else {
              maybeReadMore(stream, state)
            }
          } else {
            addChunk(stream, state, chunk, false)
          }
        }
      } else if (!addToFront) {
        state.reading = false
        maybeReadMore(stream, state)
      }
    }

    // We can push more data if we are below the highWaterMark.
    // Also, if we have no data yet, we can stand some more bytes.
    // This is to work around cases where hwm=0, such as the repl.
    return (
      !state.ended && (state.length < state.highWaterMark || state.length === 0)
    )
  }
  function addChunk(stream, state, chunk, addToFront) {
    if (state.flowing && state.length === 0 && !state.sync) {
      state.awaitDrain = 0
      stream.emit('data', chunk)
    } else {
      // update the buffer info.
      state.length += state.objectMode ? 1 : chunk.length
      if (addToFront) {
        state.buffer.unshift(chunk)
      } else {
        state.buffer.push(chunk)
      }
      if (state.needReadable) {
        emitReadable(stream)
      }
    }
    maybeReadMore(stream, state)
  }
  function chunkInvalid(state, chunk) {
    let er
    if (
      !_isUint8Array(chunk) &&
      typeof chunk !== 'string' &&
      chunk !== undefined &&
      !state.objectMode
    ) {
      er = new ERR_INVALID_ARG_TYPE(
        'chunk',
        ['string', 'Buffer', 'Uint8Array'],
        chunk
      )
    }
    return er
  }
  Readable.prototype.isPaused = function () {
    return this._readableState.flowing === false
  }

  // backwards compatibility.
  Readable.prototype.setEncoding = function (enc) {
    if (!StringDecoder) {
      StringDecoder = requireString_decoder().StringDecoder
    }
    const decoder = new StringDecoder(enc)
    this._readableState.decoder = decoder
    // If setEncoding(null), decoder.encoding equals utf8
    this._readableState.encoding = this._readableState.decoder.encoding

    // Iterate over current buffer to convert already stored Buffers:
    let p = this._readableState.buffer.head
    let content = ''
    while (p !== null) {
      content += decoder.write(p.data)
      p = p.next
    }
    this._readableState.buffer.clear()
    if (content !== '') {
      this._readableState.buffer.push(content)
    }
    this._readableState.length = content.length
    return this
  }

  // Don't raise the hwm > 1GB
  const MAX_HWM = 0x40000000
  function computeNewHighWaterMark(n) {
    if (n >= MAX_HWM) {
      // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.
      n = MAX_HWM
    } else {
      // Get the next highest power of 2 to prevent increasing hwm excessively in
      // tiny amounts
      n--
      n |= n >>> 1
      n |= n >>> 2
      n |= n >>> 4
      n |= n >>> 8
      n |= n >>> 16
      n++
    }
    return n
  }

  // This function is designed to be inlinable, so please take care when making
  // changes to the function body.
  function howMuchToRead(n, state) {
    if (n <= 0 || (state.length === 0 && state.ended)) {
      return 0
    }
    if (state.objectMode) {
      return 1
    }
    if (n !== n) {
      // Only flow one buffer at a time
      if (state.flowing && state.length) {
        return state.buffer.head.data.length
      } else {
        return state.length
      }
    }
    // If we're asking for more than the current hwm, then raise the hwm.
    if (n > state.highWaterMark) {
      state.highWaterMark = computeNewHighWaterMark(n)
    }
    if (n <= state.length) {
      return n
    }
    // Don't have enough
    if (!state.ended) {
      state.needReadable = true
      return 0
    }
    return state.length
  }

  // you can override either this method, or the async _read(n) below.
  Readable.prototype.read = function (n) {
    debug('read', n)
    n = parseInt(n, 10)
    const state = this._readableState
    const nOrig = n
    if (n !== 0) {
      state.emittedReadable = false
    }

    // if we're doing read(0) to trigger a readable event, but we
    // already have a bunch of data in the buffer, then just trigger
    // the 'readable' event and move on.
    if (
      n === 0 &&
      state.needReadable &&
      ((state.highWaterMark !== 0
        ? state.length >= state.highWaterMark
        : state.length > 0) ||
        state.ended)
    ) {
      debug('read: emitReadable', state.length, state.ended)
      if (state.length === 0 && state.ended) {
        endReadable(this)
      } else {
        emitReadable(this)
      }
      return null
    }
    n = howMuchToRead(n, state)

    // if we've ended, and we're now clear, then finish it up.
    if (n === 0 && state.ended) {
      if (state.length === 0) {
        endReadable(this)
      }
      return null
    }

    // All the actual chunk generation logic needs to be
    // *below* the call to _read.  The reason is that in certain
    // synthetic stream cases, such as passthrough streams, _read
    // may be a completely synchronous operation which may change
    // the state of the read buffer, providing enough data when
    // before there was *not* enough.
    //
    // So, the steps are:
    // 1. Figure out what the state of things will be after we do
    // a read from the buffer.
    //
    // 2. If that resulting state will trigger a _read, then call _read.
    // Note that this may be asynchronous, or synchronous.  Yes, it is
    // deeply ugly to write APIs this way, but that still doesn't mean
    // that the Readable class should behave improperly, as streams are
    // designed to be sync/async agnostic.
    // Take note if the _read call is sync or async (ie, if the read call
    // has returned yet), so that we know whether or not it's safe to emit
    // 'readable' etc.
    //
    // 3. Actually pull the requested chunks out of the buffer and return.

    // if we need a readable event, then we need to do some reading.
    let doRead = state.needReadable
    debug('need readable', doRead)

    // if we currently have less than the highWaterMark, then also read some
    if (state.length === 0 || state.length - n < state.highWaterMark) {
      doRead = true
      debug('length less than watermark', doRead)
    }

    // however, if we've ended, then there's no point, and if we're already
    // reading, then it's unnecessary.
    if (state.ended || state.reading) {
      doRead = false
      debug('reading or ended', doRead)
    } else if (doRead) {
      debug('do read')
      state.reading = true
      state.sync = true
      // if the length is currently zero, then we *need* a readable event.
      if (state.length === 0) {
        state.needReadable = true
      }
      // call internal read method
      this._read(state.highWaterMark)
      state.sync = false
      // If _read pushed data synchronously, then `reading` will be false,
      // and we need to re-evaluate how much data we can return to the user.
      if (!state.reading) {
        n = howMuchToRead(nOrig, state)
      }
    }
    let ret
    if (n > 0) {
      ret = fromList(n, state)
    } else {
      ret = null
    }
    if (ret === null) {
      state.needReadable = state.length <= state.highWaterMark
      n = 0
    } else {
      state.length -= n
      state.awaitDrain = 0
    }
    if (state.length === 0) {
      // If we have nothing in the buffer, then we want to know
      // as soon as we *do* get something into the buffer.
      if (!state.ended) {
        state.needReadable = true
      }

      // If we tried to read() past the EOF, then emit end on the next tick.
      if (nOrig !== n && state.ended) {
        endReadable(this)
      }
    }
    if (ret !== null) {
      this.emit('data', ret)
    }
    return ret
  }
  function onEofChunk(stream, state) {
    debug('onEofChunk')
    if (state.ended) {
      return
    }
    if (state.decoder) {
      const chunk = state.decoder.end()
      if (chunk && chunk.length) {
        state.buffer.push(chunk)
        state.length += state.objectMode ? 1 : chunk.length
      }
    }
    state.ended = true
    if (state.sync) {
      // if we are sync, wait until next tick to emit the data.
      // Otherwise we risk emitting data in the flow()
      // the readable code triggers during a read() call
      emitReadable(stream)
    } else {
      // emit 'readable' now to make sure it gets picked up.
      state.needReadable = false
      if (!state.emittedReadable) {
        state.emittedReadable = true
        emitReadable_(stream)
      }
    }
  }

  // Don't emit readable right away in sync mode, because this can trigger
  // another read() call => stack overflow.  This way, it might trigger
  // a nextTick recursion warning, but that's not so bad.
  function emitReadable(stream) {
    const state = stream._readableState
    debug('emitReadable', state.needReadable, state.emittedReadable)
    state.needReadable = false
    if (!state.emittedReadable) {
      debug('emitReadable', state.flowing)
      state.emittedReadable = true
      process.nextTick(emitReadable_, stream)
    }
  }
  function emitReadable_(stream) {
    const state = stream._readableState
    debug('emitReadable_', state.destroyed, state.length, state.ended)
    if (!state.destroyed && (state.length || state.ended)) {
      stream.emit('readable')
      state.emittedReadable = false
    }

    // The stream needs another readable event if
    // 1. It is not flowing, as the flow mechanism will take
    //    care of it.
    // 2. It is not ended.
    // 3. It is below the highWaterMark, so we can schedule
    //    another readable later.
    state.needReadable =
      !state.flowing && !state.ended && state.length <= state.highWaterMark
    flow(stream)
  }

  // at this point, the user has presumably seen the 'readable' event,
  // and called read() to consume some data.  that may have triggered
  // in turn another _read(n) call, in which case reading = true if
  // it's in progress.
  // However, if we're not ended, or reading, and the length < hwm,
  // then go ahead and try to read some more preemptively.
  function maybeReadMore(stream, state) {
    if (!state.readingMore) {
      state.readingMore = true
      process.nextTick(maybeReadMore_, stream, state)
    }
  }
  function maybeReadMore_(stream, state) {
    // Attempt to read more data if we should.
    //
    // The conditions for reading more data are (one of):
    // - Not enough data buffered (state.length < state.highWaterMark). The loop
    //   is responsible for filling the buffer with enough data if such data
    //   is available. If highWaterMark is 0 and we are not in the flowing mode
    //   we should _not_ attempt to buffer any extra data. We'll get more data
    //   when the stream consumer calls read() instead.
    // - No data in the buffer, and the stream is in flowing mode. In this mode
    //   the loop below is responsible for ensuring read() is called. Failing to
    //   call read here would abort the flow and there's no other mechanism for
    //   continuing the flow if the stream consumer has just subscribed to the
    //   'data' event.
    //
    // In addition to the above conditions to keep reading data, the following
    // conditions prevent the data from being read:
    // - The stream has ended (state.ended).
    // - There is already a pending 'read' operation (state.reading). This is a
    //   case where the the stream has called the implementation defined _read()
    //   method, but they are processing the call asynchronously and have _not_
    //   called push() with new data. In this case we skip performing more
    //   read()s. The execution ends in this method again after the _read() ends
    //   up calling push() with more data.
    while (
      !state.reading &&
      !state.ended &&
      (state.length < state.highWaterMark ||
        (state.flowing && state.length === 0))
    ) {
      const len = state.length
      debug('maybeReadMore read 0')
      stream.read(0)
      if (len === state.length) {
        // didn't get any data, stop spinning.
        break
      }
    }
    state.readingMore = false
  }

  // abstract method.  to be overridden in specific implementation classes.
  // call cb(er, data) where data is <= n in length.
  // for virtual (non-string, non-buffer) streams, "length" is somewhat
  // arbitrary, and perhaps not very meaningful.
  Readable.prototype._read = function (n) {
    errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'))
  }
  Readable.prototype.pipe = function (dest, pipeOpts) {
    const src = this
    const state = this._readableState
    switch (state.pipesCount) {
      case 0:
        state.pipes = dest
        break
      case 1:
        state.pipes = [state.pipes, dest]
        break
      default:
        state.pipes.push(dest)
        break
    }
    state.pipesCount += 1
    debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts)
    const doEnd =
      (!pipeOpts || pipeOpts.end !== false) &&
      dest !== process.stdout &&
      dest !== process.stderr
    const endFn = doEnd ? onend : unpipe
    if (state.endEmitted) {
      process.nextTick(endFn)
    } else {
      src.once('end', endFn)
    }
    dest.on('unpipe', onunpipe)
    function onunpipe(readable, unpipeInfo) {
      debug('onunpipe')
      if (readable === src) {
        if (unpipeInfo && unpipeInfo.hasUnpiped === false) {
          unpipeInfo.hasUnpiped = true
          cleanup()
        }
      }
    }
    function onend() {
      debug('onend')
      dest.end()
    }

    // when the dest drains, it reduces the awaitDrain counter
    // on the source.  This would be more elegant with a .once()
    // handler in flow(), but adding and removing repeatedly is
    // too slow.
    const ondrain = pipeOnDrain(src)
    dest.on('drain', ondrain)
    let cleanedUp = false
    function cleanup() {
      debug('cleanup')
      // cleanup event handlers once the pipe is broken
      dest.removeListener('close', onclose)
      dest.removeListener('finish', onfinish)
      dest.removeListener('drain', ondrain)
      dest.removeListener('error', onerror)
      dest.removeListener('unpipe', onunpipe)
      src.removeListener('end', onend)
      src.removeListener('end', unpipe)
      src.removeListener('data', ondata)
      cleanedUp = true

      // if the reader is waiting for a drain event from this
      // specific writer, then it would cause it to never start
      // flowing again.
      // So, if this is awaiting a drain, then we just call it now.
      // If we don't know, then assume that we are waiting for one.
      if (
        state.awaitDrain &&
        (!dest._writableState || dest._writableState.needDrain)
      ) {
        ondrain()
      }
    }
    src.on('data', ondata)
    function ondata(chunk) {
      debug('ondata')
      const ret = dest.write(chunk)
      debug('dest.write', ret)
      if (ret === false) {
        // If the user unpiped during `dest.write()`, it is possible
        // to get stuck in a permanently paused state if that write
        // also returned false.
        // => Check whether `dest` is still a piping destination.
        if (
          ((state.pipesCount === 1 && state.pipes === dest) ||
            (state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1)) &&
          !cleanedUp
        ) {
          debug('false write response, pause', state.awaitDrain)
          state.awaitDrain++
        }
        src.pause()
      }
    }

    // if the dest has an error, then stop piping into it.
    // however, don't suppress the throwing behavior for this.
    function onerror(er) {
      debug('onerror', er)
      unpipe()
      dest.removeListener('error', onerror)
      if (EElistenerCount(dest, 'error') === 0) {
        errorOrDestroy(dest, er)
      }
    }

    // Make sure our error handler is attached before userland ones.
    prependListener(dest, 'error', onerror)

    // Both close and finish should trigger unpipe, but only once.
    function onclose() {
      dest.removeListener('finish', onfinish)
      unpipe()
    }
    dest.once('close', onclose)
    function onfinish() {
      debug('onfinish')
      dest.removeListener('close', onclose)
      unpipe()
    }
    dest.once('finish', onfinish)
    function unpipe() {
      debug('unpipe')
      src.unpipe(dest)
    }

    // tell the dest that it's being piped to
    dest.emit('pipe', src)

    // start the flow if it hasn't been started already.
    if (!state.flowing) {
      debug('pipe resume')
      src.resume()
    }
    return dest
  }
  function pipeOnDrain(src) {
    return function pipeOnDrainFunctionResult() {
      const state = src._readableState
      debug('pipeOnDrain', state.awaitDrain)
      if (state.awaitDrain) {
        state.awaitDrain--
      }
      if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {
        state.flowing = true
        flow(src)
      }
    }
  }
  Readable.prototype.unpipe = function (dest) {
    const state = this._readableState
    const unpipeInfo = {
      hasUnpiped: false
    }

    // if we're not piping anywhere, then do nothing.
    if (state.pipesCount === 0) {
      return this
    }

    // just one destination.  most common case.
    if (state.pipesCount === 1) {
      // passed in one, but it's not the right one.
      if (dest && dest !== state.pipes) {
        return this
      }
      if (!dest) {
        dest = state.pipes
      }

      // got a match.
      state.pipes = null
      state.pipesCount = 0
      state.flowing = false
      if (dest) {
        dest.emit('unpipe', this, unpipeInfo)
      }
      return this
    }

    // slow case. multiple pipe destinations.

    if (!dest) {
      // remove all.
      const dests = state.pipes
      const len = state.pipesCount
      state.pipes = null
      state.pipesCount = 0
      state.flowing = false
      for (let i = 0; i < len; i++) {
        dests[i].emit('unpipe', this, {
          hasUnpiped: false
        })
      }
      return this
    }

    // try to find the right one.
    const index = indexOf(state.pipes, dest)
    if (index === -1) {
      return this
    }
    state.pipes.splice(index, 1)
    state.pipesCount -= 1
    if (state.pipesCount === 1) {
      state.pipes = state.pipes[0]
    }
    dest.emit('unpipe', this, unpipeInfo)
    return this
  }

  // set up data events if they are asked for
  // Ensure readable listeners eventually get something
  Readable.prototype.on = function (ev, fn) {
    const res = Stream.prototype.on.call(this, ev, fn)
    const state = this._readableState
    if (ev === 'data') {
      // update readableListening so that resume() may be a no-op
      // a few lines down. This is needed to support once('readable').
      state.readableListening = this.listenerCount('readable') > 0

      // Try start flowing on next tick if stream isn't explicitly paused
      if (state.flowing !== false) {
        this.resume()
      }
    } else if (ev === 'readable') {
      if (!state.endEmitted && !state.readableListening) {
        state.readableListening = state.needReadable = true
        state.flowing = false
        state.emittedReadable = false
        debug('on readable', state.length, state.reading)
        if (state.length) {
          emitReadable(this)
        } else if (!state.reading) {
          process.nextTick(nReadingNextTick, this)
        }
      }
    }
    return res
  }
  Readable.prototype.addListener = Readable.prototype.on
  Readable.prototype.removeListener = function (ev, fn) {
    const res = Stream.prototype.removeListener.call(this, ev, fn)
    if (ev === 'readable') {
      // We need to check if there is someone still listening to
      // readable and reset the state. However this needs to happen
      // after readable has been emitted but before I/O (nextTick) to
      // support once('readable', fn) cycles. This means that calling
      // resume within the same tick will have no
      // effect.
      process.nextTick(updateReadableListening, this)
    }
    return res
  }
  Readable.prototype.removeAllListeners = function (ev) {
    const res = Stream.prototype.removeAllListeners.apply(this, arguments)
    if (ev === 'readable' || ev === undefined) {
      // We need to check if there is someone still listening to
      // readable and reset the state. However this needs to happen
      // after readable has been emitted but before I/O (nextTick) to
      // support once('readable', fn) cycles. This means that calling
      // resume within the same tick will have no
      // effect.
      process.nextTick(updateReadableListening, this)
    }
    return res
  }
  function updateReadableListening(self) {
    const state = self._readableState
    state.readableListening = self.listenerCount('readable') > 0
    if (state.resumeScheduled && !state.paused) {
      // flowing needs to be set to true now, otherwise
      // the upcoming resume will not flow.
      state.flowing = true

      // crude way to check if we should resume
    } else if (self.listenerCount('data') > 0) {
      self.resume()
    }
  }
  function nReadingNextTick(self) {
    debug('readable nexttick read 0')
    self.read(0)
  }

  // pause() and resume() are remnants of the legacy readable stream API
  // If the user uses them, then switch into old mode.
  Readable.prototype.resume = function () {
    const state = this._readableState
    if (!state.flowing) {
      debug('resume')
      // we flow only if there is no one listening
      // for readable, but we still have to call
      // resume()
      state.flowing = !state.readableListening
      resume(this, state)
    }
    state.paused = false
    return this
  }
  function resume(stream, state) {
    if (!state.resumeScheduled) {
      state.resumeScheduled = true
      process.nextTick(resume_, stream, state)
    }
  }
  function resume_(stream, state) {
    debug('resume', state.reading)
    if (!state.reading) {
      stream.read(0)
    }
    state.resumeScheduled = false
    stream.emit('resume')
    flow(stream)
    if (state.flowing && !state.reading) {
      stream.read(0)
    }
  }
  Readable.prototype.pause = function () {
    debug('call pause flowing=%j', this._readableState.flowing)
    if (this._readableState.flowing !== false) {
      debug('pause')
      this._readableState.flowing = false
      this.emit('pause')
    }
    this._readableState.paused = true
    return this
  }
  function flow(stream) {
    const state = stream._readableState
    debug('flow', state.flowing)
    while (state.flowing && stream.read() !== null) {}
  }

  // wrap an old-style stream as the async data source.
  // This is *not* part of the readable stream interface.
  // It is an ugly unfortunate mess of history.
  Readable.prototype.wrap = function (stream) {
    const _this = this
    const state = this._readableState
    let paused = false
    stream.on('end', function () {
      debug('wrapped end')
      if (state.decoder && !state.ended) {
        const chunk = state.decoder.end()
        if (chunk && chunk.length) {
          _this.push(chunk)
        }
      }
      _this.push(null)
    })
    stream.on('data', function (chunk) {
      debug('wrapped data')
      if (state.decoder) {
        chunk = state.decoder.write(chunk)
      }

      // don't skip over falsy values in objectMode
      if (state.objectMode && (chunk === null || chunk === undefined)) {
        return
      } else if (!state.objectMode && (!chunk || !chunk.length)) {
        return
      }
      const ret = _this.push(chunk)
      if (!ret) {
        paused = true
        stream.pause()
      }
    })

    // proxy all the other methods.
    // important when wrapping filters and duplexes.
    for (const i in stream) {
      if (this[i] === undefined && typeof stream[i] === 'function') {
        this[i] = (function methodWrap(method) {
          return function methodWrapReturnFunction() {
            return stream[method].apply(stream, arguments)
          }
        })(i)
      }
    }

    // proxy certain important events.
    for (let n = 0; n < kProxyEvents.length; n++) {
      stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]))
    }

    // when we try to consume some more bytes, simply unpause the
    // underlying stream.
    this._read = function (n) {
      debug('wrapped _read', n)
      if (paused) {
        paused = false
        stream.resume()
      }
    }
    return this
  }
  if (typeof Symbol === 'function') {
    Readable.prototype[Symbol.asyncIterator] = function () {
      if (createReadableStreamAsyncIterator === undefined) {
        createReadableStreamAsyncIterator = requireAsync_iterator()
      }
      return createReadableStreamAsyncIterator(this)
    }
  }
  Object.defineProperty(Readable.prototype, 'readableHighWaterMark', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._readableState.highWaterMark
    }
  })
  Object.defineProperty(Readable.prototype, 'readableBuffer', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._readableState && this._readableState.buffer
    }
  })
  Object.defineProperty(Readable.prototype, 'readableFlowing', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._readableState.flowing
    },
    set: function set(state) {
      if (this._readableState) {
        this._readableState.flowing = state
      }
    }
  })

  // exposed for testing purposes only.
  Readable._fromList = fromList
  Object.defineProperty(Readable.prototype, 'readableLength', {
    // making it explicit this property is not enumerable
    // because otherwise some prototype manipulation in
    // userland will fail
    enumerable: false,
    get: function get() {
      return this._readableState.length
    }
  })

  // Pluck off n bytes from an array of buffers.
  // Length is the combined lengths of all the buffers in the list.
  // This function is designed to be inlinable, so please take care when making
  // changes to the function body.
  function fromList(n, state) {
    // nothing buffered
    if (state.length === 0) {
      return null
    }
    let ret
    if (state.objectMode) {
      ret = state.buffer.shift()
    } else if (!n || n >= state.length) {
      // read it all, truncate the list
      if (state.decoder) {
        ret = state.buffer.join('')
      } else if (state.buffer.length === 1) {
        ret = state.buffer.first()
      } else {
        ret = state.buffer.concat(state.length)
      }
      state.buffer.clear()
    } else {
      // read part of list
      ret = state.buffer.consume(n, state.decoder)
    }
    return ret
  }
  function endReadable(stream) {
    const state = stream._readableState
    debug('endReadable', state.endEmitted)
    if (!state.endEmitted) {
      state.ended = true
      process.nextTick(endReadableNT, state, stream)
    }
  }
  function endReadableNT(state, stream) {
    debug('endReadableNT', state.endEmitted, state.length)

    // Check that we didn't get one last unshift.
    if (!state.endEmitted && state.length === 0) {
      state.endEmitted = true
      stream.readable = false
      stream.emit('end')
      if (state.autoDestroy) {
        // In case of duplex streams we need a way to detect
        // if the writable side is ready for autoDestroy as well
        const wState = stream._writableState
        if (!wState || (wState.autoDestroy && wState.finished)) {
          stream.destroy()
        }
      }
    }
  }
  if (typeof Symbol === 'function') {
    Readable.from = function (iterable, opts) {
      if (from === undefined) {
        from = requireFrom()
      }
      return from(Readable, iterable, opts)
    }
  }
  function indexOf(xs, x) {
    for (let i = 0, l = xs.length; i < l; i++) {
      if (xs[i] === x) {
        return i
      }
    }
    return -1
  }
  return _stream_readable
}

let _stream_transform
let hasRequired_stream_transform
function require_stream_transform() {
  if (hasRequired_stream_transform) {
    return _stream_transform
  }
  hasRequired_stream_transform = 1
  _stream_transform = Transform
  const _require$codes = requireErrors$1().codes,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,
    ERR_TRANSFORM_ALREADY_TRANSFORMING =
      _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,
    ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0
  const Duplex = require_stream_duplex()
  requireInherits()(Transform, Duplex)
  function afterTransform(er, data) {
    const ts = this._transformState
    ts.transforming = false
    const cb = ts.writecb
    if (cb === null) {
      return this.emit('error', new ERR_MULTIPLE_CALLBACK())
    }
    ts.writechunk = null
    ts.writecb = null
    if (data != null) {
      // single equals check for both `null` and `undefined`
      this.push(data)
    }
    cb(er)
    const rs = this._readableState
    rs.reading = false
    if (rs.needReadable || rs.length < rs.highWaterMark) {
      this._read(rs.highWaterMark)
    }
  }
  function Transform(options) {
    if (!(this instanceof Transform)) {
      return new Transform(options)
    }
    Duplex.call(this, options)
    this._transformState = {
      afterTransform: afterTransform.bind(this),
      needTransform: false,
      transforming: false,
      writecb: null,
      writechunk: null,
      writeencoding: null
    }

    // start out asking for a readable event once data is transformed.
    this._readableState.needReadable = true

    // we have implemented the _read method, and done the other things
    // that Readable wants before the first _read call, so unset the
    // sync guard flag.
    this._readableState.sync = false
    if (options) {
      if (typeof options.transform === 'function') {
        this._transform = options.transform
      }
      if (typeof options.flush === 'function') {
        this._flush = options.flush
      }
    }

    // When the writable side finishes, then flush out anything remaining.
    this.on('prefinish', prefinish)
  }
  function prefinish() {
    const _this = this
    if (typeof this._flush === 'function' && !this._readableState.destroyed) {
      this._flush(function (er, data) {
        done(_this, er, data)
      })
    } else {
      done(this, null, null)
    }
  }
  Transform.prototype.push = function (chunk, encoding) {
    this._transformState.needTransform = false
    return Duplex.prototype.push.call(this, chunk, encoding)
  }

  // This is the part where you do stuff!
  // override this function in implementation classes.
  // 'chunk' is an input chunk.
  //
  // Call `push(newChunk)` to pass along transformed output
  // to the readable side.  You may call 'push' zero or more times.
  //
  // Call `cb(err)` when you are done with this chunk.  If you pass
  // an error, then that'll put the hurt on the whole operation.  If you
  // never call cb(), then you'll never get another chunk.
  Transform.prototype._transform = function (chunk, encoding, cb) {
    cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'))
  }
  Transform.prototype._write = function (chunk, encoding, cb) {
    const ts = this._transformState
    ts.writecb = cb
    ts.writechunk = chunk
    ts.writeencoding = encoding
    if (!ts.transforming) {
      const rs = this._readableState
      if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) {
        this._read(rs.highWaterMark)
      }
    }
  }

  // Doesn't matter what the args are here.
  // _transform does all the work.
  // That we got here means that the readable side wants more data.
  Transform.prototype._read = function (n) {
    const ts = this._transformState
    if (ts.writechunk !== null && !ts.transforming) {
      ts.transforming = true
      this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform)
    } else {
      // mark that we need a transform, so that any data that comes in
      // will get processed, now that we've asked for it.
      ts.needTransform = true
    }
  }
  Transform.prototype._destroy = function (err, cb) {
    Duplex.prototype._destroy.call(this, err, function (err2) {
      cb(err2)
    })
  }
  function done(stream, er, data) {
    if (er) {
      return stream.emit('error', er)
    }
    if (data != null) {
      // single equals check for both `null` and `undefined`
      stream.push(data)
    }

    // TODO(BridgeAR): Write a test for these two error cases
    // if there's nothing in the write buffer, then that means
    // that nothing more will ever be provided
    if (stream._writableState.length) {
      throw new ERR_TRANSFORM_WITH_LENGTH_0()
    }
    if (stream._transformState.transforming) {
      throw new ERR_TRANSFORM_ALREADY_TRANSFORMING()
    }
    return stream.push(null)
  }
  return _stream_transform
}

let _stream_passthrough
let hasRequired_stream_passthrough
function require_stream_passthrough() {
  if (hasRequired_stream_passthrough) {
    return _stream_passthrough
  }
  hasRequired_stream_passthrough = 1
  _stream_passthrough = PassThrough
  const Transform = require_stream_transform()
  requireInherits()(PassThrough, Transform)
  function PassThrough(options) {
    if (!(this instanceof PassThrough)) {
      return new PassThrough(options)
    }
    Transform.call(this, options)
  }
  PassThrough.prototype._transform = function (chunk, encoding, cb) {
    cb(null, chunk)
  }
  return _stream_passthrough
}

let pipeline_1
let hasRequiredPipeline
function requirePipeline() {
  if (hasRequiredPipeline) {
    return pipeline_1
  }
  hasRequiredPipeline = 1
  let eos
  function once(callback) {
    let called = false
    return function () {
      if (called) {
        return
      }
      called = true
      callback.apply(void 0, arguments)
    }
  }
  const _require$codes = requireErrors$1().codes,
    ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,
    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED
  function noop(err) {
    // Rethrow the error if it exists to avoid swallowing it
    if (err) {
      throw err
    }
  }
  function isRequest(stream) {
    return stream.setHeader && typeof stream.abort === 'function'
  }
  function destroyer(stream, reading, writing, callback) {
    callback = once(callback)
    let closed = false
    stream.on('close', function () {
      closed = true
    })
    if (eos === undefined) {
      eos = requireEndOfStream()
    }
    eos(
      stream,
      {
        readable: reading,
        writable: writing
      },
      function (err) {
        if (err) {
          return callback(err)
        }
        closed = true
        callback()
      }
    )
    let destroyed = false
    return function (err) {
      if (closed) {
        return
      }
      if (destroyed) {
        return
      }
      destroyed = true

      // request.destroy just do .end - .abort is what we want
      if (isRequest(stream)) {
        return stream.abort()
      }
      if (typeof stream.destroy === 'function') {
        return stream.destroy()
      }
      callback(err || new ERR_STREAM_DESTROYED('pipe'))
    }
  }
  function call(fn) {
    fn()
  }
  function pipe(from, to) {
    return from.pipe(to)
  }
  function popCallback(streams) {
    if (!streams.length) {
      return noop
    }
    if (typeof streams[streams.length - 1] !== 'function') {
      return noop
    }
    return streams.pop()
  }
  function pipeline() {
    for (
      let _len = arguments.length, streams = new Array(_len), _key = 0;
      _key < _len;
      _key++
    ) {
      streams[_key] = arguments[_key]
    }
    const callback = popCallback(streams)
    if (Array.isArray(streams[0])) {
      streams = streams[0]
    }
    if (streams.length < 2) {
      throw new ERR_MISSING_ARGS('streams')
    }
    let error
    const destroys = streams.map(function (stream, i) {
      const reading = i < streams.length - 1
      const writing = i > 0
      return destroyer(stream, reading, writing, function (err) {
        if (!error) {
          error = err
        }
        if (err) {
          destroys.forEach(call)
        }
        if (reading) {
          return
        }
        destroys.forEach(call)
        callback(error)
      })
    })
    return streams.reduce(pipe)
  }
  pipeline_1 = pipeline
  return pipeline_1
}

let hasRequiredReadable
function requireReadable() {
  if (hasRequiredReadable) {
    return readable.exports
  }
  hasRequiredReadable = 1
  ;(function (module, exports) {
    const Stream = require$$0$g
    if (process.env.READABLE_STREAM === 'disable' && Stream) {
      module.exports = Stream.Readable
      Object.assign(module.exports, Stream)
      module.exports.Stream = Stream
    } else {
      exports = module.exports = require_stream_readable()
      exports.Stream = Stream || exports
      exports.Readable = exports
      exports.Writable = require_stream_writable()
      exports.Duplex = require_stream_duplex()
      exports.Transform = require_stream_transform()
      exports.PassThrough = require_stream_passthrough()
      exports.finished = requireEndOfStream()
      exports.pipeline = requirePipeline()
    }
  })(readable, readable.exports)
  return readable.exports
}

/*
Copyright (c) 2014-2018, Matteo Collina <hello@matteocollina.com>

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
*/
let split2
let hasRequiredSplit2
function requireSplit2() {
  if (hasRequiredSplit2) {
    return split2
  }
  hasRequiredSplit2 = 1
  const { Transform } = requireReadable()
  const { StringDecoder } = require$$1$a
  const kLast = Symbol('last')
  const kDecoder = Symbol('decoder')
  function transform(chunk, enc, cb) {
    let list
    if (this.overflow) {
      // Line buffer is full. Skip to start of next line.
      const buf = this[kDecoder].write(chunk)
      list = buf.split(this.matcher)
      if (list.length === 1) {
        return cb()
      } // Line ending not found. Discard entire chunk.

      // Line ending found. Discard trailing fragment of previous line and reset overflow state.
      list.shift()
      this.overflow = false
    } else {
      this[kLast] += this[kDecoder].write(chunk)
      list = this[kLast].split(this.matcher)
    }
    this[kLast] = list.pop()
    for (let i = 0; i < list.length; i++) {
      try {
        push(this, this.mapper(list[i]))
      } catch (error) {
        return cb(error)
      }
    }
    this.overflow = this[kLast].length > this.maxLength
    if (this.overflow && !this.skipOverflow) {
      return cb(new Error('maximum buffer reached'))
    }
    cb()
  }
  function flush(cb) {
    // forward any gibberish left in there
    this[kLast] += this[kDecoder].end()
    if (this[kLast]) {
      try {
        push(this, this.mapper(this[kLast]))
      } catch (error) {
        return cb(error)
      }
    }
    cb()
  }
  function push(self, val) {
    if (val !== undefined) {
      self.push(val)
    }
  }
  function noop(incoming) {
    return incoming
  }
  function split(matcher, mapper, options) {
    // Set defaults for any arguments not supplied.
    matcher = matcher || /\r?\n/
    mapper = mapper || noop
    options = options || {}

    // Test arguments explicitly.
    switch (arguments.length) {
      case 1:
        // If mapper is only argument.
        if (typeof matcher === 'function') {
          mapper = matcher
          matcher = /\r?\n/
          // If options is only argument.
        } else if (
          typeof matcher === 'object' &&
          !(matcher instanceof RegExp)
        ) {
          options = matcher
          matcher = /\r?\n/
        }
        break
      case 2:
        // If mapper and options are arguments.
        if (typeof matcher === 'function') {
          options = mapper
          mapper = matcher
          matcher = /\r?\n/
          // If matcher and options are arguments.
        } else if (typeof mapper === 'object') {
          options = mapper
          mapper = noop
        }
    }
    options = Object.assign({}, options)
    options.transform = transform
    options.flush = flush
    options.readableObjectMode = true
    const stream = new Transform(options)
    stream[kLast] = ''
    stream[kDecoder] = new StringDecoder('utf8')
    stream.matcher = matcher
    stream.mapper = mapper
    stream.maxLength = options.maxLength
    stream.skipOverflow = options.skipOverflow
    stream.overflow = false
    return stream
  }
  split2 = split
  return split2
}

const stringify = { exports: {} }

let hasRequiredStringify
function requireStringify() {
  if (hasRequiredStringify) {
    return stringify.exports
  }
  hasRequiredStringify = 1
  ;(function (module, exports) {
    exports = module.exports = stringify
    exports.getSerialize = serializer
    function stringify(obj, replacer, spaces, cycleReplacer) {
      return JSON.stringify(obj, serializer(replacer, cycleReplacer), spaces)
    }
    function serializer(replacer, cycleReplacer) {
      const stack = [],
        keys = []
      if (cycleReplacer == null) {
        cycleReplacer = function (key, value) {
          if (stack[0] === value) return '[Circular ~]'
          return (
            '[Circular ~.' + keys.slice(0, stack.indexOf(value)).join('.') + ']'
          )
        }
      }
      return function (key, value) {
        if (stack.length > 0) {
          const thisPos = stack.indexOf(this)
          ~thisPos ? stack.splice(thisPos + 1) : stack.push(this)
          ~thisPos ? keys.splice(thisPos, Infinity, key) : keys.push(key)
          if (~stack.indexOf(value)) {
            value = cycleReplacer.call(this, key, value)
          }
        } else {
          stack.push(value)
        }
        return replacer == null ? value : replacer.call(this, key, value)
      }
    }
  })(stringify, stringify.exports)
  return stringify.exports
}

let hasRequiredNdjson
function requireNdjson() {
  if (hasRequiredNdjson) {
    return ndjson
  }
  hasRequiredNdjson = 1
  const through = requireThrough2()
  const split = requireSplit2()
  const { EOL } = require$$0$c
  const stringify = requireStringify()
  ndjson.stringify = opts =>
    through.obj(opts, (obj, _, cb) => {
      cb(null, stringify(obj) + EOL)
    })
  ndjson.parse = opts => {
    opts = opts || {}
    opts.strict = opts.strict !== false
    function parseRow(row) {
      try {
        if (row) {
          return JSON.parse(row)
        }
      } catch (e) {
        if (opts.strict) {
          this.emit(
            'error',
            new Error('Could not parse row ' + row.slice(0, 50) + '...')
          )
        }
      }
    }
    return split(parseRow, opts)
  }
  return ndjson
}

let hasRequiredStreamParser
function requireStreamParser() {
  if (hasRequiredStreamParser) {
    return streamParser
  }
  hasRequiredStreamParser = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(streamParser, '__esModule', {
    value: true
  })
  streamParser.streamParser = void 0
  streamParser.createStreamParser = createStreamParser
  const bole_1 = __importDefault(requireBole())
  const ndjson_1 = __importDefault(requireNdjson())
  streamParser.streamParser = createStreamParser()
  function createStreamParser() {
    const sp = ndjson_1.default.parse()
    bole_1.default.output([
      {
        level: 'debug',
        stream: sp
      }
    ])
    return sp
  }
  return streamParser
}

const writeToConsole = {}

let hasRequiredWriteToConsole
function requireWriteToConsole() {
  if (hasRequiredWriteToConsole) {
    return writeToConsole
  }
  hasRequiredWriteToConsole = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(writeToConsole, '__esModule', {
    value: true
  })
  writeToConsole.writeToConsole = writeToConsole$1
  const bole_1 = __importDefault(requireBole())
  function writeToConsole$1() {
    bole_1.default.output([
      {
        level: 'debug',
        stream: process.stdout
      }
    ])
  }
  return writeToConsole
}

let hasRequiredLib$8
function requireLib$8() {
  if (hasRequiredLib$8) {
    return lib$7
  }
  hasRequiredLib$8 = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.writeToConsole =
      exports.streamParser =
      exports.createStreamParser =
      exports.globalWarn =
      exports.globalInfo =
      exports.logger =
        void 0
    const logger_1 = requireLogger$1()
    Object.defineProperty(exports, 'logger', {
      enumerable: true,
      get: function () {
        return logger_1.logger
      }
    })
    Object.defineProperty(exports, 'globalInfo', {
      enumerable: true,
      get: function () {
        return logger_1.globalInfo
      }
    })
    Object.defineProperty(exports, 'globalWarn', {
      enumerable: true,
      get: function () {
        return logger_1.globalWarn
      }
    })
    const streamParser_1 = requireStreamParser()
    Object.defineProperty(exports, 'createStreamParser', {
      enumerable: true,
      get: function () {
        return streamParser_1.createStreamParser
      }
    })
    Object.defineProperty(exports, 'streamParser', {
      enumerable: true,
      get: function () {
        return streamParser_1.streamParser
      }
    })
    const writeToConsole_1 = requireWriteToConsole()
    Object.defineProperty(exports, 'writeToConsole', {
      enumerable: true,
      get: function () {
        return writeToConsole_1.writeToConsole
      }
    })
  })(lib$7)
  return lib$7
}

let hasRequiredLogger
function requireLogger() {
  if (hasRequiredLogger) {
    return logger$1
  }
  hasRequiredLogger = 1
  Object.defineProperty(logger$1, '__esModule', {
    value: true
  })
  logger$1.lockfileLogger = void 0
  const logger_1 = requireLib$8()
  logger$1.lockfileLogger = (0, logger_1.logger)('lockfile')
  return logger$1
}

const sortLockfileKeys = {}

const lib$6 = {}

const dist = {}

const lexComparator = {}

let hasRequiredLexComparator
function requireLexComparator() {
  if (hasRequiredLexComparator) {
    return lexComparator
  }
  hasRequiredLexComparator = 1
  Object.defineProperty(lexComparator, '__esModule', {
    value: true
  })
  lexComparator.lexCompare = void 0
  function lexCompare(a, b) {
    return a > b ? 1 : a < b ? -1 : 0
  }
  lexComparator.lexCompare = lexCompare
  return lexComparator
}

let hasRequiredDist
function requireDist() {
  if (hasRequiredDist) {
    return dist
  }
  hasRequiredDist = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.lexCompare = void 0
    const lex_comparator_1 = requireLexComparator()
    Object.defineProperty(exports, 'lexCompare', {
      enumerable: true,
      get: function () {
        return lex_comparator_1.lexCompare
      }
    })
  })(dist)
  return dist
}

let isPlainObj
let hasRequiredIsPlainObj
function requireIsPlainObj() {
  if (hasRequiredIsPlainObj) {
    return isPlainObj
  }
  hasRequiredIsPlainObj = 1
  isPlainObj = value => {
    if (Object.prototype.toString.call(value) !== '[object Object]') {
      return false
    }
    const prototype = Object.getPrototypeOf(value)
    return prototype === null || prototype === Object.prototype
  }
  return isPlainObj
}

let sortKeys
let hasRequiredSortKeys
function requireSortKeys() {
  if (hasRequiredSortKeys) {
    return sortKeys
  }
  hasRequiredSortKeys = 1
  const isPlainObject = requireIsPlainObj()
  sortKeys = (object, options = {}) => {
    if (!isPlainObject(object) && !Array.isArray(object)) {
      throw new TypeError('Expected a plain object or array')
    }
    const { deep } = options
    const seenInput = []
    const seenOutput = []
    const deepSortArray = array => {
      const seenIndex = seenInput.indexOf(array)
      if (seenIndex !== -1) {
        return seenOutput[seenIndex]
      }
      const result = []
      seenInput.push(array)
      seenOutput.push(result)
      result.push(
        ...array.map(item => {
          if (Array.isArray(item)) {
            return deepSortArray(item)
          }
          if (isPlainObject(item)) {
            return sortKeys(item)
          }
          return item
        })
      )
      return result
    }
    const sortKeys = object => {
      const seenIndex = seenInput.indexOf(object)
      if (seenIndex !== -1) {
        return seenOutput[seenIndex]
      }
      const result = {}
      const keys = Object.keys(object).sort(options.compare)
      seenInput.push(object)
      seenOutput.push(result)
      for (const key of keys) {
        const value = object[key]
        let newValue
        if (deep && Array.isArray(value)) {
          newValue = deepSortArray(value)
        } else {
          newValue = deep && isPlainObject(value) ? sortKeys(value) : value
        }
        Object.defineProperty(result, key, {
          ...Object.getOwnPropertyDescriptor(object, key),
          value: newValue
        })
      }
      return result
    }
    if (Array.isArray(object)) {
      return deep ? deepSortArray(object) : object.slice()
    }
    return sortKeys(object)
  }
  return sortKeys
}

let hasRequiredLib$7
function requireLib$7() {
  if (hasRequiredLib$7) {
    return lib$6
  }
  hasRequiredLib$7 = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(lib$6, '__esModule', {
    value: true
  })
  lib$6.sortDirectKeys = sortDirectKeys
  lib$6.sortDeepKeys = sortDeepKeys
  lib$6.sortKeysByPriority = sortKeysByPriority
  const util_lex_comparator_1 = requireDist()
  const sort_keys_1 = __importDefault(requireSortKeys())
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  function sortDirectKeys(obj) {
    return (0, sort_keys_1.default)(obj, {
      compare: util_lex_comparator_1.lexCompare,
      deep: false
    })
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  function sortDeepKeys(obj) {
    return (0, sort_keys_1.default)(obj, {
      compare: util_lex_comparator_1.lexCompare,
      deep: true
    })
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  function sortKeysByPriority(opts, obj) {
    const compare = compareWithPriority.bind(null, opts.priority)
    return (0, sort_keys_1.default)(obj, {
      compare,
      deep: opts.deep
    })
  }
  function compareWithPriority(priority, left, right) {
    const leftPriority = priority[left]
    const rightPriority = priority[right]
    if (leftPriority != null && rightPriority != null) {
      return leftPriority - rightPriority
    }
    if (leftPriority != null) {
      return -1
    }
    if (rightPriority != null) {
      return 1
    }
    return (0, util_lex_comparator_1.lexCompare)(left, right)
  }
  return lib$6
}

let hasRequiredSortLockfileKeys
function requireSortLockfileKeys() {
  if (hasRequiredSortLockfileKeys) {
    return sortLockfileKeys
  }
  hasRequiredSortLockfileKeys = 1
  Object.defineProperty(sortLockfileKeys, '__esModule', {
    value: true
  })
  sortLockfileKeys.sortLockfileKeys = sortLockfileKeys$1
  const object_key_sorting_1 = requireLib$7()
  const ORDERED_KEYS = {
    resolution: 1,
    id: 2,
    name: 3,
    version: 4,
    engines: 5,
    cpu: 6,
    os: 7,
    libc: 8,
    deprecated: 9,
    hasBin: 10,
    prepare: 11,
    requiresBuild: 12,
    bundleDependencies: 13,
    peerDependencies: 14,
    peerDependenciesMeta: 15,
    dependencies: 16,
    optionalDependencies: 17,
    transitivePeerDependencies: 18,
    dev: 19,
    optional: 20
  }
  const ROOT_KEYS = [
    'lockfileVersion',
    'settings',
    'catalogs',
    'overrides',
    'packageExtensionsChecksum',
    'pnpmfileChecksum',
    'patchedDependencies',
    'importers',
    'packages'
  ]
  const ROOT_KEYS_ORDER = Object.fromEntries(
    ROOT_KEYS.map((key, index) => [key, index])
  )
  function sortLockfileKeys$1(lockfile) {
    if (lockfile.importers != null) {
      lockfile.importers = (0, object_key_sorting_1.sortDirectKeys)(
        lockfile.importers
      )
      for (const [importerId, importer] of Object.entries(lockfile.importers)) {
        lockfile.importers[importerId] = (0,
        object_key_sorting_1.sortKeysByPriority)(
          {
            priority: ROOT_KEYS_ORDER,
            deep: true
          },
          importer
        )
      }
    }
    if (lockfile.packages != null) {
      lockfile.packages = (0, object_key_sorting_1.sortDirectKeys)(
        lockfile.packages
      )
      for (const [pkgId, pkg] of Object.entries(lockfile.packages)) {
        lockfile.packages[pkgId] = (0, object_key_sorting_1.sortKeysByPriority)(
          {
            priority: ORDERED_KEYS,
            deep: true
          },
          pkg
        )
      }
    }
    if (lockfile.snapshots != null) {
      lockfile.snapshots = (0, object_key_sorting_1.sortDirectKeys)(
        lockfile.snapshots
      )
      for (const [pkgId, pkg] of Object.entries(lockfile.snapshots)) {
        lockfile.snapshots[pkgId] = (0,
        object_key_sorting_1.sortKeysByPriority)(
          {
            priority: ORDERED_KEYS,
            deep: true
          },
          pkg
        )
      }
    }
    if (lockfile.catalogs != null) {
      lockfile.catalogs = (0, object_key_sorting_1.sortDirectKeys)(
        lockfile.catalogs
      )
      for (const [catalogName, catalog] of Object.entries(lockfile.catalogs)) {
        lockfile.catalogs[catalogName] = (0, object_key_sorting_1.sortDeepKeys)(
          catalog
        )
      }
    }
    for (const key of ['time', 'patchedDependencies']) {
      if (!lockfile[key]) {
        continue
      }
      lockfile[key] = (0, object_key_sorting_1.sortDirectKeys)(lockfile[key]) // eslint-disable-line @typescript-eslint/no-explicit-any
    }
    return (0, object_key_sorting_1.sortKeysByPriority)(
      {
        priority: ROOT_KEYS_ORDER
      },
      lockfile
    )
  }
  return sortLockfileKeys
}

const lockfileName = {}

const lib$5 = {}

const lib$4 = {}

let windows
let hasRequiredWindows
function requireWindows() {
  if (hasRequiredWindows) {
    return windows
  }
  hasRequiredWindows = 1
  windows = isexe
  isexe.sync = sync
  const fs = require$$0$6
  function checkPathExt(path, options) {
    let pathext =
      options.pathExt !== undefined ? options.pathExt : process.env.PATHEXT
    if (!pathext) {
      return true
    }
    pathext = pathext.split(';')
    if (pathext.indexOf('') !== -1) {
      return true
    }
    for (let i = 0; i < pathext.length; i++) {
      const p = pathext[i].toLowerCase()
      if (p && path.substr(-p.length).toLowerCase() === p) {
        return true
      }
    }
    return false
  }
  function checkStat(stat, path, options) {
    if (!stat.isSymbolicLink() && !stat.isFile()) {
      return false
    }
    return checkPathExt(path, options)
  }
  function isexe(path, options, cb) {
    fs.stat(path, function (er, stat) {
      cb(er, er ? false : checkStat(stat, path, options))
    })
  }
  function sync(path, options) {
    return checkStat(fs.statSync(path), path, options)
  }
  return windows
}

let mode
let hasRequiredMode
function requireMode() {
  if (hasRequiredMode) {
    return mode
  }
  hasRequiredMode = 1
  mode = isexe
  isexe.sync = sync
  const fs = require$$0$6
  function isexe(path, options, cb) {
    fs.stat(path, function (er, stat) {
      cb(er, er ? false : checkStat(stat, options))
    })
  }
  function sync(path, options) {
    return checkStat(fs.statSync(path), options)
  }
  function checkStat(stat, options) {
    return stat.isFile() && checkMode(stat, options)
  }
  function checkMode(stat, options) {
    const mod = stat.mode
    const uid = stat.uid
    const gid = stat.gid
    const myUid =
      options.uid !== undefined
        ? options.uid
        : process.getuid && process.getuid()
    const myGid =
      options.gid !== undefined
        ? options.gid
        : process.getgid && process.getgid()
    const u = parseInt('100', 8)
    const g = parseInt('010', 8)
    const o = parseInt('001', 8)
    const ug = u | g
    const ret =
      mod & o ||
      (mod & g && gid === myGid) ||
      (mod & u && uid === myUid) ||
      (mod & ug && myUid === 0)
    return ret
  }
  return mode
}

let isexe_1
let hasRequiredIsexe
function requireIsexe() {
  if (hasRequiredIsexe) {
    return isexe_1
  }
  hasRequiredIsexe = 1
  let core
  if (process.platform === 'win32' || global.TESTING_WINDOWS) {
    core = requireWindows()
  } else {
    core = requireMode()
  }
  isexe_1 = isexe
  isexe.sync = sync
  function isexe(path, options, cb) {
    if (typeof options === 'function') {
      cb = options
      options = {}
    }
    if (!cb) {
      if (typeof Promise !== 'function') {
        throw new TypeError('callback not provided')
      }
      return new Promise(function (resolve, reject) {
        isexe(path, options || {}, function (er, is) {
          if (er) {
            reject(er)
          } else {
            resolve(is)
          }
        })
      })
    }
    core(path, options || {}, function (er, is) {
      // ignore EACCES because that just means we aren't allowed to run it
      if (er) {
        if (er.code === 'EACCES' || (options && options.ignoreErrors)) {
          er = null
          is = false
        }
      }
      cb(er, is)
    })
  }
  function sync(path, options) {
    // my kingdom for a filtered catch
    try {
      return core.sync(path, options || {})
    } catch (er) {
      if ((options && options.ignoreErrors) || er.code === 'EACCES') {
        return false
      } else {
        throw er
      }
    }
  }
  return isexe_1
}

let which_1$1
let hasRequiredWhich$1
function requireWhich$1() {
  if (hasRequiredWhich$1) {
    return which_1$1
  }
  hasRequiredWhich$1 = 1
  const isWindows =
    process.platform === 'win32' ||
    process.env.OSTYPE === 'cygwin' ||
    process.env.OSTYPE === 'msys'
  const path = require$$0$5
  const COLON = isWindows ? ';' : ':'
  const isexe = requireIsexe()
  const getNotFoundError = cmd =>
    Object.assign(new Error(`not found: ${cmd}`), {
      code: 'ENOENT'
    })
  const getPathInfo = (cmd, opt) => {
    const colon = opt.colon || COLON

    // If it has a slash, then we don't bother searching the pathenv.
    // just check the file itself, and that's it.
    const pathEnv =
      cmd.match(/\//) || (isWindows && cmd.match(/\\/))
        ? ['']
        : (
            opt.path ||
            process.env.PATH ||
            /* istanbul ignore next: very unusual */ ''
          ).split(colon)
    const pathExtExe = isWindows
      ? opt.pathExt || process.env.PATHEXT || '.EXE;.CMD;.BAT;.COM'
      : ''
    const pathExt = isWindows ? pathExtExe.split(colon) : ['']
    if (isWindows) {
      if (cmd.indexOf('.') !== -1 && pathExt[0] !== '') {
        pathExt.unshift('')
      }
    }
    return {
      pathEnv,
      pathExt,
      pathExtExe
    }
  }
  const which = (cmd, opt, cb) => {
    if (typeof opt === 'function') {
      cb = opt
      opt = {}
    }
    if (!opt) {
      opt = {}
    }
    const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)
    const found = []
    const step = i =>
      new Promise((resolve, reject) => {
        if (i === pathEnv.length) {
          return opt.all && found.length
            ? resolve(found)
            : reject(getNotFoundError(cmd))
        }
        const ppRaw = pathEnv[i]
        const pathPart = /^".*"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw
        const pCmd = path.join(pathPart, cmd)
        const p =
          !pathPart && /^\.[\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd : pCmd
        resolve(subStep(p, i, 0))
      })
    const subStep = (p, i, ii) =>
      new Promise((resolve, reject) => {
        if (ii === pathExt.length) {
          return resolve(step(i + 1))
        }
        const ext = pathExt[ii]
        isexe(
          p + ext,
          {
            pathExt: pathExtExe
          },
          (er, is) => {
            if (!er && is) {
              if (opt.all) {
                found.push(p + ext)
              } else {
                return resolve(p + ext)
              }
            }
            return resolve(subStep(p, i, ii + 1))
          }
        )
      })
    return cb ? step(0).then(res => cb(null, res), cb) : step(0)
  }
  const whichSync = (cmd, opt) => {
    opt = opt || {}
    const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)
    const found = []
    for (let i = 0; i < pathEnv.length; i++) {
      const ppRaw = pathEnv[i]
      const pathPart = /^".*"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw
      const pCmd = path.join(pathPart, cmd)
      const p =
        !pathPart && /^\.[\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd : pCmd
      for (let j = 0; j < pathExt.length; j++) {
        const cur = p + pathExt[j]
        try {
          const is = isexe.sync(cur, {
            pathExt: pathExtExe
          })
          if (is) {
            if (opt.all) {
              found.push(cur)
            } else {
              return cur
            }
          }
        } catch (ex) {}
      }
    }
    if (opt.all && found.length) {
      return found
    }
    if (opt.nothrow) {
      return null
    }
    throw getNotFoundError(cmd)
  }
  which_1$1 = which
  which.sync = whichSync
  return which_1$1
}

const execa = { exports: {} }

const crossSpawn = { exports: {} }

let which_1
let hasRequiredWhich
function requireWhich() {
  if (hasRequiredWhich) {
    return which_1
  }
  hasRequiredWhich = 1
  const isWindows =
    process.platform === 'win32' ||
    process.env.OSTYPE === 'cygwin' ||
    process.env.OSTYPE === 'msys'
  const path = require$$0$5
  const COLON = isWindows ? ';' : ':'
  const isexe = requireIsexe()
  const getNotFoundError = cmd =>
    Object.assign(new Error(`not found: ${cmd}`), {
      code: 'ENOENT'
    })
  const getPathInfo = (cmd, opt) => {
    const colon = opt.colon || COLON

    // If it has a slash, then we don't bother searching the pathenv.
    // just check the file itself, and that's it.
    const pathEnv =
      cmd.match(/\//) || (isWindows && cmd.match(/\\/))
        ? ['']
        : [
            // windows always checks the cwd first
            ...(isWindows ? [process.cwd()] : []),
            ...(
              opt.path ||
              process.env.PATH ||
              /* istanbul ignore next: very unusual */ ''
            ).split(colon)
          ]
    const pathExtExe = isWindows
      ? opt.pathExt || process.env.PATHEXT || '.EXE;.CMD;.BAT;.COM'
      : ''
    const pathExt = isWindows ? pathExtExe.split(colon) : ['']
    if (isWindows) {
      if (cmd.indexOf('.') !== -1 && pathExt[0] !== '') {
        pathExt.unshift('')
      }
    }
    return {
      pathEnv,
      pathExt,
      pathExtExe
    }
  }
  const which = (cmd, opt, cb) => {
    if (typeof opt === 'function') {
      cb = opt
      opt = {}
    }
    if (!opt) {
      opt = {}
    }
    const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)
    const found = []
    const step = i =>
      new Promise((resolve, reject) => {
        if (i === pathEnv.length) {
          return opt.all && found.length
            ? resolve(found)
            : reject(getNotFoundError(cmd))
        }
        const ppRaw = pathEnv[i]
        const pathPart = /^".*"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw
        const pCmd = path.join(pathPart, cmd)
        const p =
          !pathPart && /^\.[\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd : pCmd
        resolve(subStep(p, i, 0))
      })
    const subStep = (p, i, ii) =>
      new Promise((resolve, reject) => {
        if (ii === pathExt.length) {
          return resolve(step(i + 1))
        }
        const ext = pathExt[ii]
        isexe(
          p + ext,
          {
            pathExt: pathExtExe
          },
          (er, is) => {
            if (!er && is) {
              if (opt.all) {
                found.push(p + ext)
              } else {
                return resolve(p + ext)
              }
            }
            return resolve(subStep(p, i, ii + 1))
          }
        )
      })
    return cb ? step(0).then(res => cb(null, res), cb) : step(0)
  }
  const whichSync = (cmd, opt) => {
    opt = opt || {}
    const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)
    const found = []
    for (let i = 0; i < pathEnv.length; i++) {
      const ppRaw = pathEnv[i]
      const pathPart = /^".*"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw
      const pCmd = path.join(pathPart, cmd)
      const p =
        !pathPart && /^\.[\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd : pCmd
      for (let j = 0; j < pathExt.length; j++) {
        const cur = p + pathExt[j]
        try {
          const is = isexe.sync(cur, {
            pathExt: pathExtExe
          })
          if (is) {
            if (opt.all) {
              found.push(cur)
            } else {
              return cur
            }
          }
        } catch (ex) {}
      }
    }
    if (opt.all && found.length) {
      return found
    }
    if (opt.nothrow) {
      return null
    }
    throw getNotFoundError(cmd)
  }
  which_1 = which
  which.sync = whichSync
  return which_1
}

const pathKey = { exports: {} }

let hasRequiredPathKey
function requirePathKey() {
  if (hasRequiredPathKey) {
    return pathKey.exports
  }
  hasRequiredPathKey = 1
  const pathKey$1 = (options = {}) => {
    const environment = options.env || process.env
    const platform = options.platform || process.platform
    if (platform !== 'win32') {
      return 'PATH'
    }
    return (
      Object.keys(environment)
        .reverse()
        .find(key => key.toUpperCase() === 'PATH') || 'Path'
    )
  }
  pathKey.exports = pathKey$1
  // TODO: Remove this for the next major release
  pathKey.exports.default = pathKey$1
  return pathKey.exports
}

let resolveCommand_1
let hasRequiredResolveCommand
function requireResolveCommand() {
  if (hasRequiredResolveCommand) {
    return resolveCommand_1
  }
  hasRequiredResolveCommand = 1
  const path = require$$0$5
  const which = requireWhich()
  const getPathKey = requirePathKey()
  function resolveCommandAttempt(parsed, withoutPathExt) {
    const env = parsed.options.env || process.env
    const cwd = process.cwd()
    const hasCustomCwd = parsed.options.cwd != null
    // Worker threads do not have process.chdir()
    const shouldSwitchCwd =
      hasCustomCwd && process.chdir !== undefined && !process.chdir.disabled

    // If a custom `cwd` was specified, we need to change the process cwd
    // because `which` will do stat calls but does not support a custom cwd
    if (shouldSwitchCwd) {
      try {
        process.chdir(parsed.options.cwd)
      } catch (err) {
        /* Empty */
      }
    }
    let resolved
    try {
      resolved = which.sync(parsed.command, {
        path: env[
          getPathKey({
            env
          })
        ],
        pathExt: withoutPathExt ? path.delimiter : undefined
      })
    } catch (e) {
      /* Empty */
    } finally {
      if (shouldSwitchCwd) {
        process.chdir(cwd)
      }
    }

    // If we successfully resolved, ensure that an absolute path is returned
    // Note that when a custom `cwd` was used, we need to resolve to an absolute path based on it
    if (resolved) {
      resolved = path.resolve(hasCustomCwd ? parsed.options.cwd : '', resolved)
    }
    return resolved
  }
  function resolveCommand(parsed) {
    return resolveCommandAttempt(parsed) || resolveCommandAttempt(parsed, true)
  }
  resolveCommand_1 = resolveCommand
  return resolveCommand_1
}

const _escape = {}

let hasRequired_escape
function require_escape() {
  if (hasRequired_escape) {
    return _escape
  }
  hasRequired_escape = 1

  // See http://www.robvanderwoude.com/escapechars.php
  const metaCharsRegExp = /([()\][%!^"`<>&|;, *?])/g
  function escapeCommand(arg) {
    // Escape meta chars
    arg = arg.replace(metaCharsRegExp, '^$1')
    return arg
  }
  function escapeArgument(arg, doubleEscapeMetaChars) {
    // Convert to string
    arg = `${arg}`

    // Algorithm below is based on https://qntm.org/cmd
    // It's slightly altered to disable JS backtracking to avoid hanging on specially crafted input
    // Please see https://github.com/moxystudio/node-cross-spawn/pull/160 for more information

    // Sequence of backslashes followed by a double quote:
    // double up all the backslashes and escape the double quote
    arg = arg.replace(/(?=(\\+?)?)\1"/g, '$1$1\\"')

    // Sequence of backslashes followed by the end of the string
    // (which will become a double quote later):
    // double up all the backslashes
    arg = arg.replace(/(?=(\\+?)?)\1$/, '$1$1')

    // All other backslashes occur literally

    // Quote the whole thing:
    arg = `"${arg}"`

    // Escape meta chars
    arg = arg.replace(metaCharsRegExp, '^$1')

    // Double escape meta chars if necessary
    if (doubleEscapeMetaChars) {
      arg = arg.replace(metaCharsRegExp, '^$1')
    }
    return arg
  }
  _escape.command = escapeCommand
  _escape.argument = escapeArgument
  return _escape
}

let shebangRegex
let hasRequiredShebangRegex
function requireShebangRegex() {
  if (hasRequiredShebangRegex) {
    return shebangRegex
  }
  hasRequiredShebangRegex = 1
  shebangRegex = /^#!(.*)/
  return shebangRegex
}

let shebangCommand
let hasRequiredShebangCommand
function requireShebangCommand() {
  if (hasRequiredShebangCommand) {
    return shebangCommand
  }
  hasRequiredShebangCommand = 1
  const shebangRegex = requireShebangRegex()
  shebangCommand = (string = '') => {
    const match = string.match(shebangRegex)
    if (!match) {
      return null
    }
    const [path, argument] = match[0].replace(/#! ?/, '').split(' ')
    const binary = path.split('/').pop()
    if (binary === 'env') {
      return argument
    }
    return argument ? `${binary} ${argument}` : binary
  }
  return shebangCommand
}

let readShebang_1
let hasRequiredReadShebang
function requireReadShebang() {
  if (hasRequiredReadShebang) {
    return readShebang_1
  }
  hasRequiredReadShebang = 1
  const fs = require$$0$6
  const shebangCommand = requireShebangCommand()
  function readShebang(command) {
    // Read the first 150 bytes from the file
    const size = 150
    const buffer = Buffer.alloc(size)
    let fd
    try {
      fd = fs.openSync(command, 'r')
      fs.readSync(fd, buffer, 0, size, 0)
      fs.closeSync(fd)
    } catch (e) {
      /* Empty */
    }

    // Attempt to extract shebang (null is returned if not a shebang)
    return shebangCommand(buffer.toString())
  }
  readShebang_1 = readShebang
  return readShebang_1
}

let parse_1
let hasRequiredParse$1
function requireParse$1() {
  if (hasRequiredParse$1) {
    return parse_1
  }
  hasRequiredParse$1 = 1
  const path = require$$0$5
  const resolveCommand = requireResolveCommand()
  const escape = require_escape()
  const readShebang = requireReadShebang()
  const isWin = process.platform === 'win32'
  const isExecutableRegExp = /\.(?:com|exe)$/i
  const isCmdShimRegExp = /node_modules[\\/].bin[\\/][^\\/]+\.cmd$/i
  function detectShebang(parsed) {
    parsed.file = resolveCommand(parsed)
    const shebang = parsed.file && readShebang(parsed.file)
    if (shebang) {
      parsed.args.unshift(parsed.file)
      parsed.command = shebang
      return resolveCommand(parsed)
    }
    return parsed.file
  }
  function parseNonShell(parsed) {
    if (!isWin) {
      return parsed
    }

    // Detect & add support for shebangs
    const commandFile = detectShebang(parsed)

    // We don't need a shell if the command filename is an executable
    const needsShell = !isExecutableRegExp.test(commandFile)

    // If a shell is required, use cmd.exe and take care of escaping everything correctly
    // Note that `forceShell` is an hidden option used only in tests
    if (parsed.options.forceShell || needsShell) {
      // Need to double escape meta chars if the command is a cmd-shim located in `node_modules/.bin/`
      // The cmd-shim simply calls execute the package bin file with NodeJS, proxying any argument
      // Because the escape of metachars with ^ gets interpreted when the cmd.exe is first called,
      // we need to double escape them
      const needsDoubleEscapeMetaChars = isCmdShimRegExp.test(commandFile)

      // Normalize posix paths into OS compatible paths (e.g.: foo/bar -> foo\bar)
      // This is necessary otherwise it will always fail with ENOENT in those cases
      parsed.command = path.normalize(parsed.command)

      // Escape command & arguments
      parsed.command = escape.command(parsed.command)
      parsed.args = parsed.args.map(arg =>
        escape.argument(arg, needsDoubleEscapeMetaChars)
      )
      const shellCommand = [parsed.command].concat(parsed.args).join(' ')
      parsed.args = ['/d', '/s', '/c', `"${shellCommand}"`]
      parsed.command = process.env.comspec || 'cmd.exe'
      parsed.options.windowsVerbatimArguments = true // Tell node's spawn that the arguments are already escaped
    }
    return parsed
  }
  function parse(command, args, options) {
    // Normalize arguments, similar to nodejs
    if (args && !Array.isArray(args)) {
      options = args
      args = null
    }
    args = args ? args.slice(0) : [] // Clone array to avoid changing the original
    options = Object.assign({}, options) // Clone object to avoid changing the original

    // Build our parsed object
    const parsed = {
      command,
      args,
      options,
      file: undefined,
      original: {
        command,
        args
      }
    }

    // Delegate further parsing to shell or non-shell
    return options.shell ? parsed : parseNonShell(parsed)
  }
  parse_1 = parse
  return parse_1
}

let enoent
let hasRequiredEnoent
function requireEnoent() {
  if (hasRequiredEnoent) {
    return enoent
  }
  hasRequiredEnoent = 1
  const isWin = process.platform === 'win32'
  function notFoundError(original, syscall) {
    return Object.assign(new Error(`${syscall} ${original.command} ENOENT`), {
      code: 'ENOENT',
      errno: 'ENOENT',
      syscall: `${syscall} ${original.command}`,
      path: original.command,
      spawnargs: original.args
    })
  }
  function hookChildProcess(cp, parsed) {
    if (!isWin) {
      return
    }
    const originalEmit = cp.emit
    cp.emit = function (name, arg1) {
      // If emitting "exit" event and exit code is 1, we need to check if
      // the command exists and emit an "error" instead
      // See https://github.com/IndigoUnited/node-cross-spawn/issues/16
      if (name === 'exit') {
        const err = verifyENOENT(arg1, parsed)
        if (err) {
          return originalEmit.call(cp, 'error', err)
        }
      }
      return originalEmit.apply(cp, arguments) // eslint-disable-line prefer-rest-params
    }
  }
  function verifyENOENT(status, parsed) {
    if (isWin && status === 1 && !parsed.file) {
      return notFoundError(parsed.original, 'spawn')
    }
    return null
  }
  function verifyENOENTSync(status, parsed) {
    if (isWin && status === 1 && !parsed.file) {
      return notFoundError(parsed.original, 'spawnSync')
    }
    return null
  }
  enoent = {
    hookChildProcess,
    verifyENOENT,
    verifyENOENTSync,
    notFoundError
  }
  return enoent
}

let hasRequiredCrossSpawn
function requireCrossSpawn() {
  if (hasRequiredCrossSpawn) {
    return crossSpawn.exports
  }
  hasRequiredCrossSpawn = 1
  const cp = require$$0$i
  const parse = requireParse$1()
  const enoent = requireEnoent()
  function spawn(command, args, options) {
    // Parse the arguments
    const parsed = parse(command, args, options)

    // Spawn the child process
    const spawned = cp.spawn(parsed.command, parsed.args, parsed.options)

    // Hook into child process "exit" event to emit an error if the command
    // does not exists, see: https://github.com/IndigoUnited/node-cross-spawn/issues/16
    enoent.hookChildProcess(spawned, parsed)
    return spawned
  }
  function spawnSync(command, args, options) {
    // Parse the arguments
    const parsed = parse(command, args, options)

    // Spawn the child process
    const result = cp.spawnSync(parsed.command, parsed.args, parsed.options)

    // Analyze if the command does not exist, see: https://github.com/IndigoUnited/node-cross-spawn/issues/16
    result.error =
      result.error || enoent.verifyENOENTSync(result.status, parsed)
    return result
  }
  crossSpawn.exports = spawn
  crossSpawn.exports.spawn = spawn
  crossSpawn.exports.sync = spawnSync
  crossSpawn.exports._parse = parse
  crossSpawn.exports._enoent = enoent
  return crossSpawn.exports
}

let stripFinalNewline
let hasRequiredStripFinalNewline
function requireStripFinalNewline() {
  if (hasRequiredStripFinalNewline) {
    return stripFinalNewline
  }
  hasRequiredStripFinalNewline = 1
  stripFinalNewline = input => {
    const LF = typeof input === 'string' ? '\n' : '\n'.charCodeAt()
    const CR = typeof input === 'string' ? '\r' : '\r'.charCodeAt()
    if (input[input.length - 1] === LF) {
      input = input.slice(0, input.length - 1)
    }
    if (input[input.length - 1] === CR) {
      input = input.slice(0, input.length - 1)
    }
    return input
  }
  return stripFinalNewline
}

const npmRunPath = { exports: {} }

npmRunPath.exports
let hasRequiredNpmRunPath
function requireNpmRunPath() {
  if (hasRequiredNpmRunPath) {
    return npmRunPath.exports
  }
  hasRequiredNpmRunPath = 1
  ;(function (module) {
    const path = require$$0$5
    const pathKey = requirePathKey()
    const npmRunPath = options => {
      options = {
        cwd: process.cwd(),
        path: process.env[pathKey()],
        execPath: process.execPath,
        ...options
      }
      let previous
      let cwdPath = path.resolve(options.cwd)
      const result = []
      while (previous !== cwdPath) {
        result.push(path.join(cwdPath, 'node_modules/.bin'))
        previous = cwdPath
        cwdPath = path.resolve(cwdPath, '..')
      }

      // Ensure the running `node` binary is used
      const execPathDir = path.resolve(options.cwd, options.execPath, '..')
      result.push(execPathDir)
      return result.concat(options.path).join(path.delimiter)
    }
    module.exports = npmRunPath
    // TODO: Remove this for the next major release
    module.exports.default = npmRunPath
    module.exports.env = options => {
      options = {
        env: process.env,
        ...options
      }
      const env = {
        ...options.env
      }
      const path = pathKey({
        env
      })
      options.path = env[path]
      env[path] = module.exports(options)
      return env
    }
  })(npmRunPath)
  return npmRunPath.exports
}

const onetime = { exports: {} }

const mimicFn = { exports: {} }

let hasRequiredMimicFn
function requireMimicFn() {
  if (hasRequiredMimicFn) {
    return mimicFn.exports
  }
  hasRequiredMimicFn = 1
  const mimicFn$1 = (to, from) => {
    for (const prop of Reflect.ownKeys(from)) {
      Object.defineProperty(
        to,
        prop,
        Object.getOwnPropertyDescriptor(from, prop)
      )
    }
    return to
  }
  mimicFn.exports = mimicFn$1
  // TODO: Remove this for the next major release
  mimicFn.exports.default = mimicFn$1
  return mimicFn.exports
}

let hasRequiredOnetime
function requireOnetime() {
  if (hasRequiredOnetime) {
    return onetime.exports
  }
  hasRequiredOnetime = 1
  const mimicFn = requireMimicFn()
  const calledFunctions = new WeakMap()
  const onetime$1 = (function_, options = {}) => {
    if (typeof function_ !== 'function') {
      throw new TypeError('Expected a function')
    }
    let returnValue
    let callCount = 0
    const functionName =
      function_.displayName || function_.name || '<anonymous>'
    const onetime = function (...arguments_) {
      calledFunctions.set(onetime, ++callCount)
      if (callCount === 1) {
        returnValue = function_.apply(this, arguments_)
        function_ = null
      } else if (options.throw === true) {
        throw new Error(`Function \`${functionName}\` can only be called once`)
      }
      return returnValue
    }
    mimicFn(onetime, function_)
    calledFunctions.set(onetime, callCount)
    return onetime
  }
  onetime.exports = onetime$1
  // TODO: Remove this for the next major release
  onetime.exports.default = onetime$1
  onetime.exports.callCount = function_ => {
    if (!calledFunctions.has(function_)) {
      throw new Error(
        `The given function \`${function_.name}\` is not wrapped by the \`onetime\` package`
      )
    }
    return calledFunctions.get(function_)
  }
  return onetime.exports
}

const main = {}

const signals$1 = {}

const core = {}

let hasRequiredCore
function requireCore() {
  if (hasRequiredCore) {
    return core
  }
  hasRequiredCore = 1
  Object.defineProperty(core, '__esModule', {
    value: true
  })
  core.SIGNALS = void 0
  const SIGNALS = [
    {
      name: 'SIGHUP',
      number: 1,
      action: 'terminate',
      description: 'Terminal closed',
      standard: 'posix'
    },
    {
      name: 'SIGINT',
      number: 2,
      action: 'terminate',
      description: 'User interruption with CTRL-C',
      standard: 'ansi'
    },
    {
      name: 'SIGQUIT',
      number: 3,
      action: 'core',
      description: 'User interruption with CTRL-\\',
      standard: 'posix'
    },
    {
      name: 'SIGILL',
      number: 4,
      action: 'core',
      description: 'Invalid machine instruction',
      standard: 'ansi'
    },
    {
      name: 'SIGTRAP',
      number: 5,
      action: 'core',
      description: 'Debugger breakpoint',
      standard: 'posix'
    },
    {
      name: 'SIGABRT',
      number: 6,
      action: 'core',
      description: 'Aborted',
      standard: 'ansi'
    },
    {
      name: 'SIGIOT',
      number: 6,
      action: 'core',
      description: 'Aborted',
      standard: 'bsd'
    },
    {
      name: 'SIGBUS',
      number: 7,
      action: 'core',
      description:
        'Bus error due to misaligned, non-existing address or paging error',
      standard: 'bsd'
    },
    {
      name: 'SIGEMT',
      number: 7,
      action: 'terminate',
      description: 'Command should be emulated but is not implemented',
      standard: 'other'
    },
    {
      name: 'SIGFPE',
      number: 8,
      action: 'core',
      description: 'Floating point arithmetic error',
      standard: 'ansi'
    },
    {
      name: 'SIGKILL',
      number: 9,
      action: 'terminate',
      description: 'Forced termination',
      standard: 'posix',
      forced: true
    },
    {
      name: 'SIGUSR1',
      number: 10,
      action: 'terminate',
      description: 'Application-specific signal',
      standard: 'posix'
    },
    {
      name: 'SIGSEGV',
      number: 11,
      action: 'core',
      description: 'Segmentation fault',
      standard: 'ansi'
    },
    {
      name: 'SIGUSR2',
      number: 12,
      action: 'terminate',
      description: 'Application-specific signal',
      standard: 'posix'
    },
    {
      name: 'SIGPIPE',
      number: 13,
      action: 'terminate',
      description: 'Broken pipe or socket',
      standard: 'posix'
    },
    {
      name: 'SIGALRM',
      number: 14,
      action: 'terminate',
      description: 'Timeout or timer',
      standard: 'posix'
    },
    {
      name: 'SIGTERM',
      number: 15,
      action: 'terminate',
      description: 'Termination',
      standard: 'ansi'
    },
    {
      name: 'SIGSTKFLT',
      number: 16,
      action: 'terminate',
      description: 'Stack is empty or overflowed',
      standard: 'other'
    },
    {
      name: 'SIGCHLD',
      number: 17,
      action: 'ignore',
      description: 'Child process terminated, paused or unpaused',
      standard: 'posix'
    },
    {
      name: 'SIGCLD',
      number: 17,
      action: 'ignore',
      description: 'Child process terminated, paused or unpaused',
      standard: 'other'
    },
    {
      name: 'SIGCONT',
      number: 18,
      action: 'unpause',
      description: 'Unpaused',
      standard: 'posix',
      forced: true
    },
    {
      name: 'SIGSTOP',
      number: 19,
      action: 'pause',
      description: 'Paused',
      standard: 'posix',
      forced: true
    },
    {
      name: 'SIGTSTP',
      number: 20,
      action: 'pause',
      description: 'Paused using CTRL-Z or "suspend"',
      standard: 'posix'
    },
    {
      name: 'SIGTTIN',
      number: 21,
      action: 'pause',
      description: 'Background process cannot read terminal input',
      standard: 'posix'
    },
    {
      name: 'SIGBREAK',
      number: 21,
      action: 'terminate',
      description: 'User interruption with CTRL-BREAK',
      standard: 'other'
    },
    {
      name: 'SIGTTOU',
      number: 22,
      action: 'pause',
      description: 'Background process cannot write to terminal output',
      standard: 'posix'
    },
    {
      name: 'SIGURG',
      number: 23,
      action: 'ignore',
      description: 'Socket received out-of-band data',
      standard: 'bsd'
    },
    {
      name: 'SIGXCPU',
      number: 24,
      action: 'core',
      description: 'Process timed out',
      standard: 'bsd'
    },
    {
      name: 'SIGXFSZ',
      number: 25,
      action: 'core',
      description: 'File too big',
      standard: 'bsd'
    },
    {
      name: 'SIGVTALRM',
      number: 26,
      action: 'terminate',
      description: 'Timeout or timer',
      standard: 'bsd'
    },
    {
      name: 'SIGPROF',
      number: 27,
      action: 'terminate',
      description: 'Timeout or timer',
      standard: 'bsd'
    },
    {
      name: 'SIGWINCH',
      number: 28,
      action: 'ignore',
      description: 'Terminal window size changed',
      standard: 'bsd'
    },
    {
      name: 'SIGIO',
      number: 29,
      action: 'terminate',
      description: 'I/O is available',
      standard: 'other'
    },
    {
      name: 'SIGPOLL',
      number: 29,
      action: 'terminate',
      description: 'Watched event',
      standard: 'other'
    },
    {
      name: 'SIGINFO',
      number: 29,
      action: 'ignore',
      description: 'Request for process information',
      standard: 'other'
    },
    {
      name: 'SIGPWR',
      number: 30,
      action: 'terminate',
      description: 'Device running out of power',
      standard: 'systemv'
    },
    {
      name: 'SIGSYS',
      number: 31,
      action: 'core',
      description: 'Invalid system call',
      standard: 'other'
    },
    {
      name: 'SIGUNUSED',
      number: 31,
      action: 'terminate',
      description: 'Invalid system call',
      standard: 'other'
    }
  ]
  core.SIGNALS = SIGNALS
  return core
}

const realtime = {}

let hasRequiredRealtime
function requireRealtime() {
  if (hasRequiredRealtime) {
    return realtime
  }
  hasRequiredRealtime = 1
  Object.defineProperty(realtime, '__esModule', {
    value: true
  })
  realtime.SIGRTMAX = realtime.getRealtimeSignals = void 0
  const getRealtimeSignals = function () {
    const length = SIGRTMAX - SIGRTMIN + 1
    return Array.from(
      {
        length
      },
      getRealtimeSignal
    )
  }
  realtime.getRealtimeSignals = getRealtimeSignals
  const getRealtimeSignal = function (value, index) {
    return {
      name: `SIGRT${index + 1}`,
      number: SIGRTMIN + index,
      action: 'terminate',
      description: 'Application-specific signal (realtime)',
      standard: 'posix'
    }
  }
  const SIGRTMIN = 34
  const SIGRTMAX = 64
  realtime.SIGRTMAX = SIGRTMAX
  return realtime
}

let hasRequiredSignals$1
function requireSignals$1() {
  if (hasRequiredSignals$1) {
    return signals$1
  }
  hasRequiredSignals$1 = 1
  Object.defineProperty(signals$1, '__esModule', {
    value: true
  })
  signals$1.getSignals = void 0
  const _os = require$$0$c
  const _core = requireCore()
  const _realtime = requireRealtime()
  const getSignals = function () {
    const realtimeSignals = (0, _realtime.getRealtimeSignals)()
    const signals = [..._core.SIGNALS, ...realtimeSignals].map(normalizeSignal)
    return signals
  }
  signals$1.getSignals = getSignals
  const normalizeSignal = function ({
    name,
    number: defaultNumber,
    description,
    action,
    forced = false,
    standard
  }) {
    const {
      signals: { [name]: constantSignal }
    } = _os.constants
    const supported = constantSignal !== undefined
    const number = supported ? constantSignal : defaultNumber
    return {
      name,
      number,
      description,
      supported,
      action,
      forced,
      standard
    }
  }
  return signals$1
}

let hasRequiredMain
function requireMain() {
  if (hasRequiredMain) {
    return main
  }
  hasRequiredMain = 1
  Object.defineProperty(main, '__esModule', {
    value: true
  })
  main.signalsByNumber = main.signalsByName = void 0
  const _os = require$$0$c
  const _signals = requireSignals$1()
  const _realtime = requireRealtime()
  const getSignalsByName = function () {
    const signals = (0, _signals.getSignals)()
    return signals.reduce(getSignalByName, {})
  }
  const getSignalByName = function (
    signalByNameMemo,
    { name, number, description, supported, action, forced, standard }
  ) {
    return {
      ...signalByNameMemo,
      [name]: {
        name,
        number,
        description,
        supported,
        action,
        forced,
        standard
      }
    }
  }
  const signalsByName = getSignalsByName()
  main.signalsByName = signalsByName
  const getSignalsByNumber = function () {
    const signals = (0, _signals.getSignals)()
    const length = _realtime.SIGRTMAX + 1
    const signalsA = Array.from(
      {
        length
      },
      (value, number) => getSignalByNumber(number, signals)
    )
    return Object.assign({}, ...signalsA)
  }
  const getSignalByNumber = function (number, signals) {
    const signal = findSignalByNumber(number, signals)
    if (signal === undefined) {
      return {}
    }
    const { name, description, supported, action, forced, standard } = signal
    return {
      [number]: {
        name,
        number,
        description,
        supported,
        action,
        forced,
        standard
      }
    }
  }
  const findSignalByNumber = function (number, signals) {
    const signal = signals.find(
      ({ name }) => _os.constants.signals[name] === number
    )
    if (signal !== undefined) {
      return signal
    }
    return signals.find(signalA => signalA.number === number)
  }
  const signalsByNumber = getSignalsByNumber()
  main.signalsByNumber = signalsByNumber
  return main
}

let error$1
let hasRequiredError$1
function requireError$1() {
  if (hasRequiredError$1) {
    return error$1
  }
  hasRequiredError$1 = 1
  const { signalsByName } = requireMain()
  const getErrorPrefix = ({
    timedOut,
    timeout,
    errorCode,
    signal,
    signalDescription,
    exitCode,
    isCanceled
  }) => {
    if (timedOut) {
      return `timed out after ${timeout} milliseconds`
    }
    if (isCanceled) {
      return 'was canceled'
    }
    if (errorCode !== undefined) {
      return `failed with ${errorCode}`
    }
    if (signal !== undefined) {
      return `was killed with ${signal} (${signalDescription})`
    }
    if (exitCode !== undefined) {
      return `failed with exit code ${exitCode}`
    }
    return 'failed'
  }
  const makeError = ({
    stdout,
    stderr,
    all,
    error,
    signal,
    exitCode,
    command,
    escapedCommand,
    timedOut,
    isCanceled,
    killed,
    parsed: {
      options: { timeout }
    }
  }) => {
    // `signal` and `exitCode` emitted on `spawned.on('exit')` event can be `null`.
    // We normalize them to `undefined`
    exitCode = exitCode === null ? undefined : exitCode
    signal = signal === null ? undefined : signal
    const signalDescription =
      signal === undefined ? undefined : signalsByName[signal].description
    const errorCode = error && error.code
    const prefix = getErrorPrefix({
      timedOut,
      timeout,
      errorCode,
      signal,
      signalDescription,
      exitCode,
      isCanceled
    })
    const execaMessage = `Command ${prefix}: ${command}`
    const isError = Object.prototype.toString.call(error) === '[object Error]'
    const shortMessage = isError
      ? `${execaMessage}\n${error.message}`
      : execaMessage
    const message = [shortMessage, stderr, stdout].filter(Boolean).join('\n')
    if (isError) {
      error.originalMessage = error.message
      error.message = message
    } else {
      error = new Error(message)
    }
    error.shortMessage = shortMessage
    error.command = command
    error.escapedCommand = escapedCommand
    error.exitCode = exitCode
    error.signal = signal
    error.signalDescription = signalDescription
    error.stdout = stdout
    error.stderr = stderr
    if (all !== undefined) {
      error.all = all
    }
    if ('bufferedData' in error) {
      delete error.bufferedData
    }
    error.failed = true
    error.timedOut = Boolean(timedOut)
    error.isCanceled = isCanceled
    error.killed = killed && !timedOut
    return error
  }
  error$1 = makeError
  return error$1
}

const stdio = { exports: {} }

let hasRequiredStdio
function requireStdio() {
  if (hasRequiredStdio) {
    return stdio.exports
  }
  hasRequiredStdio = 1
  const aliases = ['stdin', 'stdout', 'stderr']
  const hasAlias = options =>
    aliases.some(alias => options[alias] !== undefined)
  const normalizeStdio = options => {
    if (!options) {
      return
    }
    const { stdio } = options
    if (stdio === undefined) {
      return aliases.map(alias => options[alias])
    }
    if (hasAlias(options)) {
      throw new Error(
        `It's not possible to provide \`stdio\` in combination with one of ${aliases.map(alias => `\`${alias}\``).join(', ')}`
      )
    }
    if (typeof stdio === 'string') {
      return stdio
    }
    if (!Array.isArray(stdio)) {
      throw new TypeError(
        `Expected \`stdio\` to be of type \`string\` or \`Array\`, got \`${typeof stdio}\``
      )
    }
    const length = Math.max(stdio.length, aliases.length)
    return Array.from(
      {
        length
      },
      (value, index) => stdio[index]
    )
  }
  stdio.exports = normalizeStdio

  // `ipc` is pushed unless it is already present
  stdio.exports.node = options => {
    const stdio = normalizeStdio(options)
    if (stdio === 'ipc') {
      return 'ipc'
    }
    if (stdio === undefined || typeof stdio === 'string') {
      return [stdio, stdio, stdio, 'ipc']
    }
    if (stdio.includes('ipc')) {
      return stdio
    }
    return [...stdio, 'ipc']
  }
  return stdio.exports
}

const signalExit = { exports: {} }

const signals = { exports: {} }

let hasRequiredSignals
function requireSignals() {
  if (hasRequiredSignals) {
    return signals.exports
  }
  hasRequiredSignals = 1
  ;(function (module) {
    // This is not the set of all possible signals.
    //
    // It IS, however, the set of all signals that trigger
    // an exit on either Linux or BSD systems.  Linux is a
    // superset of the signal names supported on BSD, and
    // the unknown signals just fail to register, so we can
    // catch that easily enough.
    //
    // Don't bother with SIGKILL.  It's uncatchable, which
    // means that we can't fire any callbacks anyway.
    //
    // If a user does happen to register a handler on a non-
    // fatal signal like SIGWINCH or something, and then
    // exit, it'll end up firing `process.emit('exit')`, so
    // the handler will be fired anyway.
    //
    // SIGBUS, SIGFPE, SIGSEGV and SIGILL, when not raised
    // artificially, inherently leave the process in a
    // state from which it is not safe to try and enter JS
    // listeners.
    module.exports = ['SIGABRT', 'SIGALRM', 'SIGHUP', 'SIGINT', 'SIGTERM']
    if (process.platform !== 'win32') {
      module.exports.push(
        'SIGVTALRM',
        'SIGXCPU',
        'SIGXFSZ',
        'SIGUSR2',
        'SIGTRAP',
        'SIGSYS',
        'SIGQUIT',
        'SIGIOT'
        // should detect profiler and enable/disable accordingly.
        // see #21
        // 'SIGPROF'
      )
    }
    if (process.platform === 'linux') {
      module.exports.push(
        'SIGIO',
        'SIGPOLL',
        'SIGPWR',
        'SIGSTKFLT',
        'SIGUNUSED'
      )
    }
  })(signals)
  return signals.exports
}

let hasRequiredSignalExit
function requireSignalExit() {
  if (hasRequiredSignalExit) {
    return signalExit.exports
  }
  hasRequiredSignalExit = 1
  // Note: since nyc uses this module to output coverage, any lines
  // that are in the direct sync flow of nyc's outputCoverage are
  // ignored, since we can never get coverage for them.
  // grab a reference to node's real process object right away
  const process = global.process
  const processOk = function (process) {
    return (
      process &&
      typeof process === 'object' &&
      typeof process.removeListener === 'function' &&
      typeof process.emit === 'function' &&
      typeof process.reallyExit === 'function' &&
      typeof process.listeners === 'function' &&
      typeof process.kill === 'function' &&
      typeof process.pid === 'number' &&
      typeof process.on === 'function'
    )
  }

  // some kind of non-node environment, just no-op
  /* istanbul ignore if */
  if (!processOk(process)) {
    signalExit.exports = function () {
      return function () {}
    }
  } else {
    const assert = require$$5$1
    let signals = requireSignals()
    const isWin = /^win/i.test(process.platform)
    let EE = require$$0$h
    /* istanbul ignore if */
    if (typeof EE !== 'function') {
      EE = EE.EventEmitter
    }
    let emitter
    if (process.__signal_exit_emitter__) {
      emitter = process.__signal_exit_emitter__
    } else {
      emitter = process.__signal_exit_emitter__ = new EE()
      emitter.count = 0
      emitter.emitted = {}
    }

    // Because this emitter is a global, we have to check to see if a
    // previous version of this library failed to enable infinite listeners.
    // I know what you're about to say.  But literally everything about
    // signal-exit is a compromise with evil.  Get used to it.
    if (!emitter.infinite) {
      emitter.setMaxListeners(Infinity)
      emitter.infinite = true
    }
    signalExit.exports = function (cb, opts) {
      /* istanbul ignore if */
      if (!processOk(global.process)) {
        return function () {}
      }
      assert.equal(
        typeof cb,
        'function',
        'a callback must be provided for exit handler'
      )
      if (loaded === false) {
        load()
      }
      let ev = 'exit'
      if (opts && opts.alwaysLast) {
        ev = 'afterexit'
      }
      const remove = function () {
        emitter.removeListener(ev, cb)
        if (
          emitter.listeners('exit').length === 0 &&
          emitter.listeners('afterexit').length === 0
        ) {
          unload()
        }
      }
      emitter.on(ev, cb)
      return remove
    }
    const unload = function unload() {
      if (!loaded || !processOk(global.process)) {
        return
      }
      loaded = false
      signals.forEach(function (sig) {
        try {
          process.removeListener(sig, sigListeners[sig])
        } catch (er) {}
      })
      process.emit = originalProcessEmit
      process.reallyExit = originalProcessReallyExit
      emitter.count -= 1
    }
    signalExit.exports.unload = unload
    const emit = function emit(event, code, signal) {
      /* istanbul ignore if */
      if (emitter.emitted[event]) {
        return
      }
      emitter.emitted[event] = true
      emitter.emit(event, code, signal)
    }

    // { <signal>: <listener fn>, ... }
    const sigListeners = {}
    signals.forEach(function (sig) {
      sigListeners[sig] = function listener() {
        /* istanbul ignore if */
        if (!processOk(global.process)) {
          return
        }
        // If there are no other listeners, an exit is coming!
        // Simplest way: remove us and then re-send the signal.
        // We know that this will kill the process, so we can
        // safely emit now.
        const listeners = process.listeners(sig)
        if (listeners.length === emitter.count) {
          unload()
          emit('exit', null, sig)
          /* istanbul ignore next */
          emit('afterexit', null, sig)
          /* istanbul ignore next */
          if (isWin && sig === 'SIGHUP') {
            // "SIGHUP" throws an `ENOSYS` error on Windows,
            // so use a supported signal instead
            sig = 'SIGINT'
          }
          /* istanbul ignore next */
          process.kill(process.pid, sig)
        }
      }
    })
    signalExit.exports.signals = function () {
      return signals
    }
    let loaded = false
    const load = function load() {
      if (loaded || !processOk(global.process)) {
        return
      }
      loaded = true

      // This is the number of onSignalExit's that are in play.
      // It's important so that we can count the correct number of
      // listeners on signals, and don't wait for the other one to
      // handle it instead of us.
      emitter.count += 1
      signals = signals.filter(function (sig) {
        try {
          process.on(sig, sigListeners[sig])
          return true
        } catch (er) {
          return false
        }
      })
      process.emit = processEmit
      process.reallyExit = processReallyExit
    }
    signalExit.exports.load = load
    const originalProcessReallyExit = process.reallyExit
    const processReallyExit = function processReallyExit(code) {
      /* istanbul ignore if */
      if (!processOk(global.process)) {
        return
      }
      process.exitCode = code || /* istanbul ignore next */ 0
      emit('exit', process.exitCode, null)
      /* istanbul ignore next */
      emit('afterexit', process.exitCode, null)
      /* istanbul ignore next */
      originalProcessReallyExit.call(process, process.exitCode)
    }
    const originalProcessEmit = process.emit
    const processEmit = function processEmit(ev, arg) {
      if (ev === 'exit' && processOk(global.process)) {
        /* istanbul ignore else */
        if (arg !== undefined) {
          process.exitCode = arg
        }
        const ret = originalProcessEmit.apply(this, arguments)
        /* istanbul ignore next */
        emit('exit', process.exitCode, null)
        /* istanbul ignore next */
        emit('afterexit', process.exitCode, null)
        /* istanbul ignore next */
        return ret
      } else {
        return originalProcessEmit.apply(this, arguments)
      }
    }
  }
  return signalExit.exports
}

let kill
let hasRequiredKill
function requireKill() {
  if (hasRequiredKill) {
    return kill
  }
  hasRequiredKill = 1
  const os = require$$0$c
  const onExit = requireSignalExit()
  const DEFAULT_FORCE_KILL_TIMEOUT = 1000 * 5

  // Monkey-patches `childProcess.kill()` to add `forceKillAfterTimeout` behavior
  const spawnedKill = (kill, signal = 'SIGTERM', options = {}) => {
    const killResult = kill(signal)
    setKillTimeout(kill, signal, options, killResult)
    return killResult
  }
  const setKillTimeout = (kill, signal, options, killResult) => {
    if (!shouldForceKill(signal, options, killResult)) {
      return
    }
    const timeout = getForceKillAfterTimeout(options)
    const t = setTimeout(() => {
      kill('SIGKILL')
    }, timeout)

    // Guarded because there's no `.unref()` when `execa` is used in the renderer
    // process in Electron. This cannot be tested since we don't run tests in
    // Electron.
    // istanbul ignore else
    if (t.unref) {
      t.unref()
    }
  }
  const shouldForceKill = (signal, { forceKillAfterTimeout }, killResult) => {
    return isSigterm(signal) && forceKillAfterTimeout !== false && killResult
  }
  const isSigterm = signal => {
    return (
      signal === os.constants.signals.SIGTERM ||
      (typeof signal === 'string' && signal.toUpperCase() === 'SIGTERM')
    )
  }
  const getForceKillAfterTimeout = ({ forceKillAfterTimeout = true }) => {
    if (forceKillAfterTimeout === true) {
      return DEFAULT_FORCE_KILL_TIMEOUT
    }
    if (!Number.isFinite(forceKillAfterTimeout) || forceKillAfterTimeout < 0) {
      throw new TypeError(
        `Expected the \`forceKillAfterTimeout\` option to be a non-negative integer, got \`${forceKillAfterTimeout}\` (${typeof forceKillAfterTimeout})`
      )
    }
    return forceKillAfterTimeout
  }

  // `childProcess.cancel()`
  const spawnedCancel = (spawned, context) => {
    const killResult = spawned.kill()
    if (killResult) {
      context.isCanceled = true
    }
  }
  const timeoutKill = (spawned, signal, reject) => {
    spawned.kill(signal)
    reject(
      Object.assign(new Error('Timed out'), {
        timedOut: true,
        signal
      })
    )
  }

  // `timeout` option handling
  const setupTimeout = (
    spawned,
    { timeout, killSignal = 'SIGTERM' },
    spawnedPromise
  ) => {
    if (timeout === 0 || timeout === undefined) {
      return spawnedPromise
    }
    let timeoutId
    const timeoutPromise = new Promise((resolve, reject) => {
      timeoutId = setTimeout(() => {
        timeoutKill(spawned, killSignal, reject)
      }, timeout)
    })
    const safeSpawnedPromise = spawnedPromise.finally(() => {
      clearTimeout(timeoutId)
    })
    return Promise.race([timeoutPromise, safeSpawnedPromise])
  }
  const validateTimeout = ({ timeout }) => {
    if (timeout !== undefined && (!Number.isFinite(timeout) || timeout < 0)) {
      throw new TypeError(
        `Expected the \`timeout\` option to be a non-negative integer, got \`${timeout}\` (${typeof timeout})`
      )
    }
  }

  // `cleanup` option handling
  const setExitHandler = async (
    spawned,
    { cleanup, detached },
    timedPromise
  ) => {
    if (!cleanup || detached) {
      return timedPromise
    }
    const removeExitHandler = onExit(() => {
      spawned.kill()
    })
    return timedPromise.finally(() => {
      removeExitHandler()
    })
  }
  kill = {
    spawnedKill,
    spawnedCancel,
    setupTimeout,
    validateTimeout,
    setExitHandler
  }
  return kill
}

let isStream_1
let hasRequiredIsStream
function requireIsStream() {
  if (hasRequiredIsStream) {
    return isStream_1
  }
  hasRequiredIsStream = 1
  const isStream = stream =>
    stream !== null &&
    typeof stream === 'object' &&
    typeof stream.pipe === 'function'
  isStream.writable = stream =>
    isStream(stream) &&
    stream.writable !== false &&
    typeof stream._write === 'function' &&
    typeof stream._writableState === 'object'
  isStream.readable = stream =>
    isStream(stream) &&
    stream.readable !== false &&
    typeof stream._read === 'function' &&
    typeof stream._readableState === 'object'
  isStream.duplex = stream =>
    isStream.writable(stream) && isStream.readable(stream)
  isStream.transform = stream =>
    isStream.duplex(stream) && typeof stream._transform === 'function'
  isStream_1 = isStream
  return isStream_1
}

const getStream = { exports: {} }

let bufferStream
let hasRequiredBufferStream
function requireBufferStream() {
  if (hasRequiredBufferStream) {
    return bufferStream
  }
  hasRequiredBufferStream = 1
  const { PassThrough: PassThroughStream } = require$$0$g
  bufferStream = options => {
    options = {
      ...options
    }
    const { array } = options
    let { encoding } = options
    const isBuffer = encoding === 'buffer'
    let objectMode = false
    if (array) {
      objectMode = !(encoding || isBuffer)
    } else {
      encoding = encoding || 'utf8'
    }
    if (isBuffer) {
      encoding = null
    }
    const stream = new PassThroughStream({
      objectMode
    })
    if (encoding) {
      stream.setEncoding(encoding)
    }
    let length = 0
    const chunks = []
    stream.on('data', chunk => {
      chunks.push(chunk)
      if (objectMode) {
        length = chunks.length
      } else {
        length += chunk.length
      }
    })
    stream.getBufferedValue = () => {
      if (array) {
        return chunks
      }
      return isBuffer ? Buffer.concat(chunks, length) : chunks.join('')
    }
    stream.getBufferedLength = () => length
    return stream
  }
  return bufferStream
}

let hasRequiredGetStream
function requireGetStream() {
  if (hasRequiredGetStream) {
    return getStream.exports
  }
  hasRequiredGetStream = 1
  const { constants: BufferConstants } = require$$2$4
  const stream = require$$0$g
  const { promisify } = require$$0$4
  const bufferStream = requireBufferStream()
  const streamPipelinePromisified = promisify(stream.pipeline)
  class MaxBufferError extends Error {
    constructor() {
      super('maxBuffer exceeded')
      this.name = 'MaxBufferError'
    }
  }
  async function getStream$1(inputStream, options) {
    if (!inputStream) {
      throw new Error('Expected a stream')
    }
    options = {
      maxBuffer: Infinity,
      ...options
    }
    const { maxBuffer } = options
    const stream = bufferStream(options)
    await new Promise((resolve, reject) => {
      const rejectPromise = error => {
        // Don't retrieve an oversized buffer.
        if (error && stream.getBufferedLength() <= BufferConstants.MAX_LENGTH) {
          error.bufferedData = stream.getBufferedValue()
        }
        reject(error)
      }
      ;(async () => {
        try {
          await streamPipelinePromisified(inputStream, stream)
          resolve()
        } catch (error) {
          rejectPromise(error)
        }
      })()
      stream.on('data', () => {
        if (stream.getBufferedLength() > maxBuffer) {
          rejectPromise(new MaxBufferError())
        }
      })
    })
    return stream.getBufferedValue()
  }
  getStream.exports = getStream$1
  getStream.exports.buffer = (stream, options) =>
    getStream$1(stream, {
      ...options,
      encoding: 'buffer'
    })
  getStream.exports.array = (stream, options) =>
    getStream$1(stream, {
      ...options,
      array: true
    })
  getStream.exports.MaxBufferError = MaxBufferError
  return getStream.exports
}

let mergeStream
let hasRequiredMergeStream
function requireMergeStream() {
  if (hasRequiredMergeStream) {
    return mergeStream
  }
  hasRequiredMergeStream = 1
  const { PassThrough } = require$$0$g
  mergeStream = function /*streams...*/ () {
    let sources = []
    const output = new PassThrough({
      objectMode: true
    })
    output.setMaxListeners(0)
    output.add = add
    output.isEmpty = isEmpty
    output.on('unpipe', remove)
    Array.prototype.slice.call(arguments).forEach(add)
    return output
    function add(source) {
      if (Array.isArray(source)) {
        source.forEach(add)
        return this
      }
      sources.push(source)
      source.once('end', remove.bind(null, source))
      source.once('error', output.emit.bind(output, 'error'))
      source.pipe(output, {
        end: false
      })
      return this
    }
    function isEmpty() {
      return sources.length == 0
    }
    function remove(source) {
      sources = sources.filter(function (it) {
        return it !== source
      })
      if (!sources.length && output.readable) {
        output.end()
      }
    }
  }
  return mergeStream
}

let stream
let hasRequiredStream
function requireStream() {
  if (hasRequiredStream) {
    return stream
  }
  hasRequiredStream = 1
  const isStream = requireIsStream()
  const getStream = requireGetStream()
  const mergeStream = requireMergeStream()

  // `input` option
  const handleInput = (spawned, input) => {
    // Checking for stdin is workaround for https://github.com/nodejs/node/issues/26852
    // @todo remove `|| spawned.stdin === undefined` once we drop support for Node.js <=12.2.0
    if (input === undefined || spawned.stdin === undefined) {
      return
    }
    if (isStream(input)) {
      input.pipe(spawned.stdin)
    } else {
      spawned.stdin.end(input)
    }
  }

  // `all` interleaves `stdout` and `stderr`
  const makeAllStream = (spawned, { all }) => {
    if (!all || (!spawned.stdout && !spawned.stderr)) {
      return
    }
    const mixed = mergeStream()
    if (spawned.stdout) {
      mixed.add(spawned.stdout)
    }
    if (spawned.stderr) {
      mixed.add(spawned.stderr)
    }
    return mixed
  }

  // On failure, `result.stdout|stderr|all` should contain the currently buffered stream
  const getBufferedData = async (stream, streamPromise) => {
    if (!stream) {
      return
    }
    stream.destroy()
    try {
      return await streamPromise
    } catch (error) {
      return error.bufferedData
    }
  }
  const getStreamPromise = (stream, { encoding, buffer, maxBuffer }) => {
    if (!stream || !buffer) {
      return
    }
    if (encoding) {
      return getStream(stream, {
        encoding,
        maxBuffer
      })
    }
    return getStream.buffer(stream, {
      maxBuffer
    })
  }

  // Retrieve result of child process: exit code, signal, error, streams (stdout/stderr/all)
  const getSpawnedResult = async (
    { stdout, stderr, all },
    { encoding, buffer, maxBuffer },
    processDone
  ) => {
    const stdoutPromise = getStreamPromise(stdout, {
      encoding,
      buffer,
      maxBuffer
    })
    const stderrPromise = getStreamPromise(stderr, {
      encoding,
      buffer,
      maxBuffer
    })
    const allPromise = getStreamPromise(all, {
      encoding,
      buffer,
      maxBuffer: maxBuffer * 2
    })
    try {
      return await Promise.all([
        processDone,
        stdoutPromise,
        stderrPromise,
        allPromise
      ])
    } catch (error) {
      return Promise.all([
        {
          error,
          signal: error.signal,
          timedOut: error.timedOut
        },
        getBufferedData(stdout, stdoutPromise),
        getBufferedData(stderr, stderrPromise),
        getBufferedData(all, allPromise)
      ])
    }
  }
  const validateInputSync = ({ input }) => {
    if (isStream(input)) {
      throw new TypeError('The `input` option cannot be a stream in sync mode')
    }
  }
  stream = {
    handleInput,
    makeAllStream,
    getSpawnedResult,
    validateInputSync
  }
  return stream
}

let promise
let hasRequiredPromise
function requirePromise() {
  if (hasRequiredPromise) {
    return promise
  }
  hasRequiredPromise = 1
  const nativePromisePrototype = (async () => {})().constructor.prototype
  const descriptors = ['then', 'catch', 'finally'].map(property => [
    property,
    Reflect.getOwnPropertyDescriptor(nativePromisePrototype, property)
  ])

  // The return value is a mixin of `childProcess` and `Promise`
  const mergePromise = (spawned, promise) => {
    for (const [property, descriptor] of descriptors) {
      // Starting the main `promise` is deferred to avoid consuming streams
      const value =
        typeof promise === 'function'
          ? (...args) => Reflect.apply(descriptor.value, promise(), args)
          : descriptor.value.bind(promise)
      Reflect.defineProperty(spawned, property, {
        ...descriptor,
        value
      })
    }
    return spawned
  }

  // Use promises instead of `child_process` events
  const getSpawnedPromise = spawned => {
    return new Promise((resolve, reject) => {
      spawned.on('exit', (exitCode, signal) => {
        resolve({
          exitCode,
          signal
        })
      })
      spawned.on('error', error => {
        reject(error)
      })
      if (spawned.stdin) {
        spawned.stdin.on('error', error => {
          reject(error)
        })
      }
    })
  }
  promise = {
    mergePromise,
    getSpawnedPromise
  }
  return promise
}

let command
let hasRequiredCommand
function requireCommand() {
  if (hasRequiredCommand) {
    return command
  }
  hasRequiredCommand = 1
  const normalizeArgs = (file, args = []) => {
    if (!Array.isArray(args)) {
      return [file]
    }
    return [file, ...args]
  }
  const NO_ESCAPE_REGEXP = /^[\w.-]+$/
  const DOUBLE_QUOTES_REGEXP = /"/g
  const escapeArg = arg => {
    if (typeof arg !== 'string' || NO_ESCAPE_REGEXP.test(arg)) {
      return arg
    }
    return `"${arg.replace(DOUBLE_QUOTES_REGEXP, '\\"')}"`
  }
  const joinCommand = (file, args) => {
    return normalizeArgs(file, args).join(' ')
  }
  const getEscapedCommand = (file, args) => {
    return normalizeArgs(file, args)
      .map(arg => escapeArg(arg))
      .join(' ')
  }
  const SPACES_REGEXP = / +/g

  // Handle `execa.command()`
  const parseCommand = command => {
    const tokens = []
    for (const token of command.trim().split(SPACES_REGEXP)) {
      // Allow spaces to be escaped by a backslash if not meant as a delimiter
      const previousToken = tokens[tokens.length - 1]
      if (previousToken && previousToken.endsWith('\\')) {
        // Merge previous token with current one
        tokens[tokens.length - 1] = `${previousToken.slice(0, -1)} ${token}`
      } else {
        tokens.push(token)
      }
    }
    return tokens
  }
  command = {
    joinCommand,
    getEscapedCommand,
    parseCommand
  }
  return command
}

let hasRequiredExeca
function requireExeca() {
  if (hasRequiredExeca) {
    return execa.exports
  }
  hasRequiredExeca = 1
  const path = require$$0$5
  const childProcess = require$$0$i
  const crossSpawn = requireCrossSpawn()
  const stripFinalNewline = requireStripFinalNewline()
  const npmRunPath = requireNpmRunPath()
  const onetime = requireOnetime()
  const makeError = requireError$1()
  const normalizeStdio = requireStdio()
  const {
    spawnedKill,
    spawnedCancel,
    setupTimeout,
    validateTimeout,
    setExitHandler
  } = requireKill()
  const { handleInput, getSpawnedResult, makeAllStream, validateInputSync } =
    requireStream()
  const { mergePromise, getSpawnedPromise } = requirePromise()
  const { joinCommand, parseCommand, getEscapedCommand } = requireCommand()
  const DEFAULT_MAX_BUFFER = 1000 * 1000 * 100
  const getEnv = ({
    env: envOption,
    extendEnv,
    preferLocal,
    localDir,
    execPath
  }) => {
    const env = extendEnv
      ? {
          ...process.env,
          ...envOption
        }
      : envOption
    if (preferLocal) {
      return npmRunPath.env({
        env,
        cwd: localDir,
        execPath
      })
    }
    return env
  }
  const handleArguments = (file, args, options = {}) => {
    const parsed = crossSpawn._parse(file, args, options)
    file = parsed.command
    args = parsed.args
    options = parsed.options
    options = {
      maxBuffer: DEFAULT_MAX_BUFFER,
      buffer: true,
      stripFinalNewline: true,
      extendEnv: true,
      preferLocal: false,
      localDir: options.cwd || process.cwd(),
      execPath: process.execPath,
      encoding: 'utf8',
      reject: true,
      cleanup: true,
      all: false,
      windowsHide: true,
      ...options
    }
    options.env = getEnv(options)
    options.stdio = normalizeStdio(options)
    if (process.platform === 'win32' && path.basename(file, '.exe') === 'cmd') {
      // #116
      args.unshift('/q')
    }
    return {
      file,
      args,
      options,
      parsed
    }
  }
  const handleOutput = (options, value, error) => {
    if (typeof value !== 'string' && !Buffer.isBuffer(value)) {
      // When `execa.sync()` errors, we normalize it to '' to mimic `execa()`
      return error === undefined ? undefined : ''
    }
    if (options.stripFinalNewline) {
      return stripFinalNewline(value)
    }
    return value
  }
  const execa$1 = (file, args, options) => {
    const parsed = handleArguments(file, args, options)
    const command = joinCommand(file, args)
    const escapedCommand = getEscapedCommand(file, args)
    validateTimeout(parsed.options)
    let spawned
    try {
      spawned = childProcess.spawn(parsed.file, parsed.args, parsed.options)
    } catch (error) {
      // Ensure the returned error is always both a promise and a child process
      const dummySpawned = new childProcess.ChildProcess()
      const errorPromise = Promise.reject(
        makeError({
          error,
          stdout: '',
          stderr: '',
          all: '',
          command,
          escapedCommand,
          parsed,
          timedOut: false,
          isCanceled: false,
          killed: false
        })
      )
      return mergePromise(dummySpawned, errorPromise)
    }
    const spawnedPromise = getSpawnedPromise(spawned)
    const timedPromise = setupTimeout(spawned, parsed.options, spawnedPromise)
    const processDone = setExitHandler(spawned, parsed.options, timedPromise)
    const context = {
      isCanceled: false
    }
    spawned.kill = spawnedKill.bind(null, spawned.kill.bind(spawned))
    spawned.cancel = spawnedCancel.bind(null, spawned, context)
    const handlePromise = async () => {
      const [
        { error, exitCode, signal, timedOut },
        stdoutResult,
        stderrResult,
        allResult
      ] = await getSpawnedResult(spawned, parsed.options, processDone)
      const stdout = handleOutput(parsed.options, stdoutResult)
      const stderr = handleOutput(parsed.options, stderrResult)
      const all = handleOutput(parsed.options, allResult)
      if (error || exitCode !== 0 || signal !== null) {
        const returnedError = makeError({
          error,
          exitCode,
          signal,
          stdout,
          stderr,
          all,
          command,
          escapedCommand,
          parsed,
          timedOut,
          isCanceled: context.isCanceled,
          killed: spawned.killed
        })
        if (!parsed.options.reject) {
          return returnedError
        }
        throw returnedError
      }
      return {
        command,
        escapedCommand,
        exitCode: 0,
        stdout,
        stderr,
        all,
        failed: false,
        timedOut: false,
        isCanceled: false,
        killed: false
      }
    }
    const handlePromiseOnce = onetime(handlePromise)
    handleInput(spawned, parsed.options.input)
    spawned.all = makeAllStream(spawned, parsed.options)
    return mergePromise(spawned, handlePromiseOnce)
  }
  execa.exports = execa$1
  execa.exports.sync = (file, args, options) => {
    const parsed = handleArguments(file, args, options)
    const command = joinCommand(file, args)
    const escapedCommand = getEscapedCommand(file, args)
    validateInputSync(parsed.options)
    let result
    try {
      result = childProcess.spawnSync(parsed.file, parsed.args, parsed.options)
    } catch (error) {
      throw makeError({
        error,
        stdout: '',
        stderr: '',
        all: '',
        command,
        escapedCommand,
        parsed,
        timedOut: false,
        isCanceled: false,
        killed: false
      })
    }
    const stdout = handleOutput(parsed.options, result.stdout, result.error)
    const stderr = handleOutput(parsed.options, result.stderr, result.error)
    if (result.error || result.status !== 0 || result.signal !== null) {
      const error = makeError({
        stdout,
        stderr,
        error: result.error,
        signal: result.signal,
        exitCode: result.status,
        command,
        escapedCommand,
        parsed,
        timedOut: result.error && result.error.code === 'ETIMEDOUT',
        isCanceled: false,
        killed: result.signal !== null
      })
      if (!parsed.options.reject) {
        return error
      }
      throw error
    }
    return {
      command,
      escapedCommand,
      exitCode: 0,
      stdout,
      stderr,
      failed: false,
      timedOut: false,
      isCanceled: false,
      killed: false
    }
  }
  execa.exports.command = (command, options) => {
    const [file, ...args] = parseCommand(command)
    return execa$1(file, args, options)
  }
  execa.exports.commandSync = (command, options) => {
    const [file, ...args] = parseCommand(command)
    return execa$1.sync(file, args, options)
  }
  execa.exports.node = (scriptPath, args, options = {}) => {
    if (args && !Array.isArray(args) && typeof args === 'object') {
      options = args
      args = []
    }
    const stdio = normalizeStdio.node(options)
    const defaultExecArgv = process.execArgv.filter(
      arg => !arg.startsWith('--inspect')
    )
    const { nodePath = process.execPath, nodeOptions = defaultExecArgv } =
      options
    return execa$1(
      nodePath,
      [...nodeOptions, scriptPath, ...(Array.isArray(args) ? args : [])],
      {
        ...options,
        stdin: undefined,
        stdout: undefined,
        stderr: undefined,
        stdio,
        shell: false
      }
    )
  }
  return execa.exports
}

let pathName
let hasRequiredPathName
function requirePathName() {
  if (hasRequiredPathName) {
    return pathName
  }
  hasRequiredPathName = 1
  let PATH
  // windows calls it's path 'Path' usually, but this is not guaranteed.
  if (process.platform === 'win32') {
    PATH = 'Path'
    Object.keys(process.env).forEach(e => {
      if (e.match(/^PATH$/i)) {
        PATH = e
      }
    })
  } else {
    PATH = 'PATH'
  }
  pathName = PATH
  return pathName
}

let hasRequiredLib$6
function requireLib$6() {
  if (hasRequiredLib$6) {
    return lib$4
  }
  hasRequiredLib$6 = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(lib$4, '__esModule', {
    value: true
  })
  lib$4.sync = void 0
  const which_1 = __importDefault(requireWhich$1())
  const execa_1 = __importDefault(requireExeca())
  const path_name_1 = __importDefault(requirePathName())
  const pathCache = new Map()
  function sync(file, args, options) {
    let _a
    try {
      which_1.default.sync(file, {
        path:
          (_a =
            options === null || options === void 0 ? void 0 : options.cwd) !==
            null && _a !== void 0
            ? _a
            : process.cwd
      })
    } catch (err) {
      // If the command is not found in the current directory, there is no need to resolve the command to full location
      // as there is no danger of binary planting attack on Windows
      if (err.code === 'ENOENT') {
        return execa_1.default.sync(file, args, options)
      }
    }
    const fileAbsolutePath = getCommandAbsolutePathSync(file, options)
    return execa_1.default.sync(fileAbsolutePath, args, options)
  }
  lib$4.sync = sync
  function getCommandAbsolutePathSync(file, options) {
    let _a, _b
    if (file.includes('\\') || file.includes('/')) {
      return file
    }
    const path =
      (_b =
        (_a = options === null || options === void 0 ? void 0 : options.env) ===
          null || _a === void 0
          ? void 0
          : _a[path_name_1.default]) !== null && _b !== void 0
        ? _b
        : process.env[path_name_1.default]
    const key = JSON.stringify([path, file])
    let fileAbsolutePath = pathCache.get(key)
    if (fileAbsolutePath == null) {
      fileAbsolutePath = which_1.default.sync(file, {
        path
      })
      pathCache.set(key, fileAbsolutePath)
    }
    if (fileAbsolutePath == null) {
      throw new Error(`Couldn't find ${file}`)
    }
    return fileAbsolutePath
  }
  function default_1(file, args, options) {
    let _a
    try {
      which_1.default.sync(file, {
        path:
          (_a =
            options === null || options === void 0 ? void 0 : options.cwd) !==
            null && _a !== void 0
            ? _a
            : process.cwd
      })
    } catch (err) {
      // If the command is not found in the current directory, there is no need to resolve the command to full location
      // as there is no danger of binary planting attack on Windows
      if (err.code === 'ENOENT') {
        return (0, execa_1.default)(file, args, options)
      }
    }
    const fileAbsolutePath = getCommandAbsolutePathSync(file, options)
    return (0, execa_1.default)(fileAbsolutePath, args, options)
  }
  lib$4.default = default_1
  return lib$4
}

let hasRequiredLib$5
function requireLib$5() {
  if (hasRequiredLib$5) {
    return lib$5
  }
  hasRequiredLib$5 = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(lib$5, '__esModule', {
    value: true
  })
  lib$5.isGitRepo = isGitRepo
  lib$5.getCurrentBranch = getCurrentBranch
  lib$5.isWorkingTreeClean = isWorkingTreeClean
  lib$5.isRemoteHistoryClean = isRemoteHistoryClean
  const execa_1 = __importDefault(requireLib$6())
  // git checks logic is from https://github.com/sindresorhus/np/blob/master/source/git-tasks.js
  async function isGitRepo() {
    try {
      await (0, execa_1.default)('git', ['rev-parse', '--git-dir'])
    } catch {
      return false
    }
    return true
  }
  async function getCurrentBranch() {
    try {
      const { stdout } = await (0, execa_1.default)('git', [
        'symbolic-ref',
        '--short',
        'HEAD'
      ])
      return stdout
    } catch {
      // Command will fail with code 1 if the HEAD is detached.
      return null
    }
  }
  async function isWorkingTreeClean() {
    try {
      const { stdout: status } = await (0, execa_1.default)('git', [
        'status',
        '--porcelain'
      ])
      if (status !== '') {
        return false
      }
      return true
    } catch {
      return false
    }
  }
  async function isRemoteHistoryClean() {
    let history
    try {
      // Gracefully handle no remote set up.
      const { stdout } = await (0, execa_1.default)('git', [
        'rev-list',
        '--count',
        '--left-only',
        '@{u}...HEAD'
      ])
      history = stdout
    } catch {
      history = null
    }
    if (history && history !== '0') {
      return false
    }
    return true
  }
  return lib$5
}

let hasRequiredLockfileName
function requireLockfileName() {
  if (hasRequiredLockfileName) {
    return lockfileName
  }
  hasRequiredLockfileName = 1
  Object.defineProperty(lockfileName, '__esModule', {
    value: true
  })
  lockfileName.getWantedLockfileName = getWantedLockfileName
  const constants_1 = requireLib$a()
  const git_utils_1 = requireLib$5()
  async function getWantedLockfileName(
    opts = {
      useGitBranchLockfile: false,
      mergeGitBranchLockfiles: false
    }
  ) {
    if (opts.useGitBranchLockfile && !opts.mergeGitBranchLockfiles) {
      const currentBranchName = await (0, git_utils_1.getCurrentBranch)()
      if (currentBranchName) {
        return constants_1.WANTED_LOCKFILE.replace(
          '.yaml',
          `.${stringifyBranchName(currentBranchName)}.yaml`
        )
      }
    }
    return constants_1.WANTED_LOCKFILE
  }
  /**
   * 1. Git branch name may contains slashes, which is not allowed in filenames
   * 2. Filesystem may be case-insensitive, so we need to convert branch name to lowercase
   */
  function stringifyBranchName(branchName = '') {
    return branchName.replace(/[^\w.-]/g, '!').toLowerCase()
  }
  return lockfileName
}

const lockfileFormatConverters = {}

const lib$3 = {}

const env = {}

let hasRequiredEnv
function requireEnv() {
  if (hasRequiredEnv) {
    return env
  }
  hasRequiredEnv = 1
  Object.defineProperty(env, '__esModule', {
    value: true
  })
  return env
}

const misc = {}

let hasRequiredMisc
function requireMisc() {
  if (hasRequiredMisc) {
    return misc
  }
  hasRequiredMisc = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.DEPENDENCIES_OR_PEER_FIELDS = exports.DEPENDENCIES_FIELDS = void 0
    // NOTE: The order in this array is important.
    exports.DEPENDENCIES_FIELDS = [
      'optionalDependencies',
      'dependencies',
      'devDependencies'
    ]
    exports.DEPENDENCIES_OR_PEER_FIELDS = [
      ...exports.DEPENDENCIES_FIELDS,
      'peerDependencies'
    ]
  })(misc)
  return misc
}

const options = {}

let hasRequiredOptions
function requireOptions() {
  if (hasRequiredOptions) {
    return options
  }
  hasRequiredOptions = 1
  Object.defineProperty(options, '__esModule', {
    value: true
  })
  return options
}

const _package = {}

let hasRequired_package
function require_package() {
  if (hasRequired_package) {
    return _package
  }
  hasRequired_package = 1
  Object.defineProperty(_package, '__esModule', {
    value: true
  })
  return _package
}

const peerDependencyIssues = {}

let hasRequiredPeerDependencyIssues
function requirePeerDependencyIssues() {
  if (hasRequiredPeerDependencyIssues) {
    return peerDependencyIssues
  }
  hasRequiredPeerDependencyIssues = 1
  Object.defineProperty(peerDependencyIssues, '__esModule', {
    value: true
  })
  return peerDependencyIssues
}

const project = {}

let hasRequiredProject
function requireProject() {
  if (hasRequiredProject) {
    return project
  }
  hasRequiredProject = 1
  Object.defineProperty(project, '__esModule', {
    value: true
  })
  return project
}

let hasRequiredLib$4
function requireLib$4() {
  if (hasRequiredLib$4) {
    return lib$3
  }
  hasRequiredLib$4 = 1
  ;(function (exports) {
    const __createBinding =
      (this && this.__createBinding) ||
      (Object.create
        ? function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            let desc = Object.getOwnPropertyDescriptor(m, k)
            if (
              !desc ||
              ('get' in desc
                ? !m.__esModule
                : desc.writable || desc.configurable)
            ) {
              desc = {
                enumerable: true,
                get: function () {
                  return m[k]
                }
              }
            }
            Object.defineProperty(o, k2, desc)
          }
        : function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            o[k2] = m[k]
          })
    const __exportStar =
      (this && this.__exportStar) ||
      function (m, exports) {
        for (const p in m) {
          if (
            p !== 'default' &&
            !Object.prototype.hasOwnProperty.call(exports, p)
          )
            __createBinding(exports, m, p)
        }
      }
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    __exportStar(requireEnv(), exports)
    __exportStar(requireMisc(), exports)
    __exportStar(requireOptions(), exports)
    __exportStar(require_package(), exports)
    __exportStar(requirePeerDependencyIssues(), exports)
    __exportStar(requireProject(), exports)
  })(lib$3)
  return lib$3
}

let _isTransformer_1
let hasRequired_isTransformer
function require_isTransformer() {
  if (hasRequired_isTransformer) {
    return _isTransformer_1
  }
  hasRequired_isTransformer = 1
  function _isTransformer(obj) {
    return obj != null && typeof obj['@@transducer/step'] === 'function'
  }
  _isTransformer_1 = _isTransformer
  return _isTransformer_1
}

let _dispatchable_1
let hasRequired_dispatchable
function require_dispatchable() {
  if (hasRequired_dispatchable) {
    return _dispatchable_1
  }
  hasRequired_dispatchable = 1
  const _isArray = /*#__PURE__*/ /*@__PURE__*/ require_isArray()
  const _isTransformer = /*#__PURE__*/ /*@__PURE__*/ require_isTransformer()
  /**
   * Returns a function that dispatches with different strategies based on the
   * object in list position (last argument). If it is an array, executes [fn].
   * Otherwise, if it has a function with one of the given method names, it will
   * execute that function (functor case). Otherwise, if it is a transformer,
   * uses transducer created by [transducerCreator] to return a new transformer
   * (transducer case).
   * Otherwise, it will default to executing [fn].
   *
   * @private
   * @param {Array} methodNames properties to check for a custom implementation
   * @param {Function} transducerCreator transducer factory if object is transformer
   * @param {Function} fn default ramda implementation
   * @return {Function} A function that dispatches on object in list position
   */

  function _dispatchable(methodNames, transducerCreator, fn) {
    return function () {
      if (arguments.length === 0) {
        return fn()
      }
      const obj = arguments[arguments.length - 1]
      if (!_isArray(obj)) {
        let idx = 0
        while (idx < methodNames.length) {
          if (typeof obj[methodNames[idx]] === 'function') {
            return obj[methodNames[idx]].apply(
              obj,
              Array.prototype.slice.call(arguments, 0, -1)
            )
          }
          idx += 1
        }
        if (_isTransformer(obj)) {
          const transducer = transducerCreator.apply(
            null,
            Array.prototype.slice.call(arguments, 0, -1)
          )
          return transducer(obj)
        }
      }
      return fn.apply(this, arguments)
    }
  }
  _dispatchable_1 = _dispatchable
  return _dispatchable_1
}

let _map_1
let hasRequired_map
function require_map() {
  if (hasRequired_map) {
    return _map_1
  }
  hasRequired_map = 1
  function _map(fn, functor) {
    let idx = 0
    const len = functor.length
    const result = Array(len)
    while (idx < len) {
      result[idx] = fn(functor[idx])
      idx += 1
    }
    return result
  }
  _map_1 = _map
  return _map_1
}

let _isArrayLike_1
let hasRequired_isArrayLike
function require_isArrayLike() {
  if (hasRequired_isArrayLike) {
    return _isArrayLike_1
  }
  hasRequired_isArrayLike = 1
  const _curry1 = /*#__PURE__*/ /*@__PURE__*/ require_curry1()
  const _isArray = /*#__PURE__*/ /*@__PURE__*/ require_isArray()
  const _isString = /*#__PURE__*/ /*@__PURE__*/ require_isString()
  /**
   * Tests whether or not an object is similar to an array.
   *
   * @private
   * @category Type
   * @category List
   * @sig * -> Boolean
   * @param {*} x The object to test.
   * @return {Boolean} `true` if `x` has a numeric length property and extreme indices defined; `false` otherwise.
   * @example
   *
   *      _isArrayLike([]); //=> true
   *      _isArrayLike(true); //=> false
   *      _isArrayLike({}); //=> false
   *      _isArrayLike({length: 10}); //=> false
   *      _isArrayLike({0: 'zero', 9: 'nine', length: 10}); //=> true
   *      _isArrayLike({nodeType: 1, length: 1}) // => false
   */

  const _isArrayLike =
    /*#__PURE__*/
    _curry1(function isArrayLike(x) {
      if (_isArray(x)) {
        return true
      }
      if (!x) {
        return false
      }
      if (typeof x !== 'object') {
        return false
      }
      if (_isString(x)) {
        return false
      }
      if (x.length === 0) {
        return true
      }
      if (x.length > 0) {
        return x.hasOwnProperty(0) && x.hasOwnProperty(x.length - 1)
      }
      return false
    })
  _isArrayLike_1 = _isArrayLike
  return _isArrayLike_1
}

let _xwrap_1
let hasRequired_xwrap
function require_xwrap() {
  if (hasRequired_xwrap) {
    return _xwrap_1
  }
  hasRequired_xwrap = 1
  const XWrap =
    /*#__PURE__*/
    (function () {
      function XWrap(fn) {
        this.f = fn
      }
      XWrap.prototype['@@transducer/init'] = function () {
        throw new Error('init not implemented on XWrap')
      }
      XWrap.prototype['@@transducer/result'] = function (acc) {
        return acc
      }
      XWrap.prototype['@@transducer/step'] = function (acc, x) {
        return this.f(acc, x)
      }
      return XWrap
    })()
  function _xwrap(fn) {
    return new XWrap(fn)
  }
  _xwrap_1 = _xwrap
  return _xwrap_1
}

let _arity_1
let hasRequired_arity
function require_arity() {
  if (hasRequired_arity) {
    return _arity_1
  }
  hasRequired_arity = 1
  function _arity(n, fn) {
    /* eslint-disable no-unused-vars */
    switch (n) {
      case 0:
        return function () {
          return fn.apply(this, arguments)
        }
      case 1:
        return function (a0) {
          return fn.apply(this, arguments)
        }
      case 2:
        return function (a0, a1) {
          return fn.apply(this, arguments)
        }
      case 3:
        return function (a0, a1, a2) {
          return fn.apply(this, arguments)
        }
      case 4:
        return function (a0, a1, a2, a3) {
          return fn.apply(this, arguments)
        }
      case 5:
        return function (a0, a1, a2, a3, a4) {
          return fn.apply(this, arguments)
        }
      case 6:
        return function (a0, a1, a2, a3, a4, a5) {
          return fn.apply(this, arguments)
        }
      case 7:
        return function (a0, a1, a2, a3, a4, a5, a6) {
          return fn.apply(this, arguments)
        }
      case 8:
        return function (a0, a1, a2, a3, a4, a5, a6, a7) {
          return fn.apply(this, arguments)
        }
      case 9:
        return function (a0, a1, a2, a3, a4, a5, a6, a7, a8) {
          return fn.apply(this, arguments)
        }
      case 10:
        return function (a0, a1, a2, a3, a4, a5, a6, a7, a8, a9) {
          return fn.apply(this, arguments)
        }
      default:
        throw new Error(
          'First argument to _arity must be a non-negative integer no greater than ten'
        )
    }
  }
  _arity_1 = _arity
  return _arity_1
}

let bind_1
let hasRequiredBind
function requireBind() {
  if (hasRequiredBind) {
    return bind_1
  }
  hasRequiredBind = 1
  const _arity = /*#__PURE__*/ /*@__PURE__*/ require_arity()
  const _curry2 = /*#__PURE__*/ /*@__PURE__*/ require_curry2()
  /**
   * Creates a function that is bound to a context.
   * Note: `R.bind` does not provide the additional argument-binding capabilities of
   * [Function.prototype.bind](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/bind).
   *
   * @func
   * @memberOf R
   * @since v0.6.0
   * @category Function
   * @category Object
   * @sig (* -> *) -> {*} -> (* -> *)
   * @param {Function} fn The function to bind to context
   * @param {Object} thisObj The context to bind `fn` to
   * @return {Function} A function that will execute in the context of `thisObj`.
   * @see R.partial
   * @example
   *
   *      const log = R.bind(console.log, console);
   *      R.pipe(R.assoc('a', 2), R.tap(log), R.assoc('a', 3))({a: 1}); //=> {a: 3}
   *      // logs {a: 2}
   * @symb R.bind(f, o)(a, b) = f.call(o, a, b)
   */

  const bind =
    /*#__PURE__*/
    _curry2(function bind(fn, thisObj) {
      return _arity(fn.length, function () {
        return fn.apply(thisObj, arguments)
      })
    })
  bind_1 = bind
  return bind_1
}

let _reduce_1
let hasRequired_reduce
function require_reduce() {
  if (hasRequired_reduce) {
    return _reduce_1
  }
  hasRequired_reduce = 1
  const _isArrayLike = /*#__PURE__*/ /*@__PURE__*/ require_isArrayLike()
  const _xwrap = /*#__PURE__*/ /*@__PURE__*/ require_xwrap()
  const bind = /*#__PURE__*/ /*@__PURE__*/ requireBind()
  function _arrayReduce(xf, acc, list) {
    let idx = 0
    const len = list.length
    while (idx < len) {
      acc = xf['@@transducer/step'](acc, list[idx])
      if (acc && acc['@@transducer/reduced']) {
        acc = acc['@@transducer/value']
        break
      }
      idx += 1
    }
    return xf['@@transducer/result'](acc)
  }
  function _iterableReduce(xf, acc, iter) {
    let step = iter.next()
    while (!step.done) {
      acc = xf['@@transducer/step'](acc, step.value)
      if (acc && acc['@@transducer/reduced']) {
        acc = acc['@@transducer/value']
        break
      }
      step = iter.next()
    }
    return xf['@@transducer/result'](acc)
  }
  function _methodReduce(xf, acc, obj, methodName) {
    return xf['@@transducer/result'](
      obj[methodName](bind(xf['@@transducer/step'], xf), acc)
    )
  }
  const symIterator =
    typeof Symbol !== 'undefined' ? Symbol.iterator : '@@iterator'
  function _reduce(fn, acc, list) {
    if (typeof fn === 'function') {
      fn = _xwrap(fn)
    }
    if (_isArrayLike(list)) {
      return _arrayReduce(fn, acc, list)
    }
    if (typeof list['fantasy-land/reduce'] === 'function') {
      return _methodReduce(fn, acc, list, 'fantasy-land/reduce')
    }
    if (list[symIterator] != null) {
      return _iterableReduce(fn, acc, list[symIterator]())
    }
    if (typeof list.next === 'function') {
      return _iterableReduce(fn, acc, list)
    }
    if (typeof list.reduce === 'function') {
      return _methodReduce(fn, acc, list, 'reduce')
    }
    throw new TypeError('reduce: list must be array or iterable')
  }
  _reduce_1 = _reduce
  return _reduce_1
}

let _xfBase
let hasRequired_xfBase
function require_xfBase() {
  if (hasRequired_xfBase) {
    return _xfBase
  }
  hasRequired_xfBase = 1
  _xfBase = {
    init: function () {
      return this.xf['@@transducer/init']()
    },
    result: function (result) {
      return this.xf['@@transducer/result'](result)
    }
  }
  return _xfBase
}

let _xmap_1
let hasRequired_xmap
function require_xmap() {
  if (hasRequired_xmap) {
    return _xmap_1
  }
  hasRequired_xmap = 1
  const _curry2 = /*#__PURE__*/ /*@__PURE__*/ require_curry2()
  const _xfBase = /*#__PURE__*/ /*@__PURE__*/ require_xfBase()
  const XMap =
    /*#__PURE__*/
    (function () {
      function XMap(f, xf) {
        this.xf = xf
        this.f = f
      }
      XMap.prototype['@@transducer/init'] = _xfBase.init
      XMap.prototype['@@transducer/result'] = _xfBase.result
      XMap.prototype['@@transducer/step'] = function (result, input) {
        return this.xf['@@transducer/step'](result, this.f(input))
      }
      return XMap
    })()
  const _xmap =
    /*#__PURE__*/
    _curry2(function _xmap(f, xf) {
      return new XMap(f, xf)
    })
  _xmap_1 = _xmap
  return _xmap_1
}

let _curryN_1
let hasRequired_curryN
function require_curryN() {
  if (hasRequired_curryN) {
    return _curryN_1
  }
  hasRequired_curryN = 1
  const _arity = /*#__PURE__*/ /*@__PURE__*/ require_arity()
  const _isPlaceholder = /*#__PURE__*/ /*@__PURE__*/ require_isPlaceholder()
  /**
   * Internal curryN function.
   *
   * @private
   * @category Function
   * @param {Number} length The arity of the curried function.
   * @param {Array} received An array of arguments received thus far.
   * @param {Function} fn The function to curry.
   * @return {Function} The curried function.
   */

  function _curryN(length, received, fn) {
    return function () {
      const combined = []
      let argsIdx = 0
      let left = length
      let combinedIdx = 0
      while (combinedIdx < received.length || argsIdx < arguments.length) {
        let result
        if (
          combinedIdx < received.length &&
          (!_isPlaceholder(received[combinedIdx]) ||
            argsIdx >= arguments.length)
        ) {
          result = received[combinedIdx]
        } else {
          result = arguments[argsIdx]
          argsIdx += 1
        }
        combined[combinedIdx] = result
        if (!_isPlaceholder(result)) {
          left -= 1
        }
        combinedIdx += 1
      }
      return left <= 0
        ? fn.apply(this, combined)
        : _arity(left, _curryN(length, combined, fn))
    }
  }
  _curryN_1 = _curryN
  return _curryN_1
}

let curryN_1
let hasRequiredCurryN
function requireCurryN() {
  if (hasRequiredCurryN) {
    return curryN_1
  }
  hasRequiredCurryN = 1
  const _arity = /*#__PURE__*/ /*@__PURE__*/ require_arity()
  const _curry1 = /*#__PURE__*/ /*@__PURE__*/ require_curry1()
  const _curry2 = /*#__PURE__*/ /*@__PURE__*/ require_curry2()
  const _curryN = /*#__PURE__*/ /*@__PURE__*/ require_curryN()
  /**
   * Returns a curried equivalent of the provided function, with the specified
   * arity. The curried function has two unusual capabilities. First, its
   * arguments needn't be provided one at a time. If `g` is `R.curryN(3, f)`, the
   * following are equivalent:
   *
   *   - `g(1)(2)(3)`
   *   - `g(1)(2, 3)`
   *   - `g(1, 2)(3)`
   *   - `g(1, 2, 3)`
   *
   * Secondly, the special placeholder value [`R.__`](#__) may be used to specify
   * "gaps", allowing partial application of any combination of arguments,
   * regardless of their positions. If `g` is as above and `_` is [`R.__`](#__),
   * the following are equivalent:
   *
   *   - `g(1, 2, 3)`
   *   - `g(_, 2, 3)(1)`
   *   - `g(_, _, 3)(1)(2)`
   *   - `g(_, _, 3)(1, 2)`
   *   - `g(_, 2)(1)(3)`
   *   - `g(_, 2)(1, 3)`
   *   - `g(_, 2)(_, 3)(1)`
   *
   * @func
   * @memberOf R
   * @since v0.5.0
   * @category Function
   * @sig Number -> (* -> a) -> (* -> a)
   * @param {Number} length The arity for the returned function.
   * @param {Function} fn The function to curry.
   * @return {Function} A new, curried function.
   * @see R.curry
   * @example
   *
   *      const sumArgs = (...args) => R.sum(args);
   *
   *      const curriedAddFourNumbers = R.curryN(4, sumArgs);
   *      const f = curriedAddFourNumbers(1, 2);
   *      const g = f(3);
   *      g(4); //=> 10
   */

  const curryN =
    /*#__PURE__*/
    _curry2(function curryN(length, fn) {
      if (length === 1) {
        return _curry1(fn)
      }
      return _arity(length, _curryN(length, [], fn))
    })
  curryN_1 = curryN
  return curryN_1
}

let map_1
let hasRequiredMap
function requireMap() {
  if (hasRequiredMap) {
    return map_1
  }
  hasRequiredMap = 1
  const _curry2 = /*#__PURE__*/ /*@__PURE__*/ require_curry2()
  const _dispatchable = /*#__PURE__*/ /*@__PURE__*/ require_dispatchable()
  const _map = /*#__PURE__*/ /*@__PURE__*/ require_map()
  const _reduce = /*#__PURE__*/ /*@__PURE__*/ require_reduce()
  const _xmap = /*#__PURE__*/ /*@__PURE__*/ require_xmap()
  const curryN = /*#__PURE__*/ /*@__PURE__*/ requireCurryN()
  const keys = /*#__PURE__*/ /*@__PURE__*/ requireKeys()
  /**
   * Takes a function and
   * a [functor](https://github.com/fantasyland/fantasy-land#functor),
   * applies the function to each of the functor's values, and returns
   * a functor of the same shape.
   *
   * Ramda provides suitable `map` implementations for `Array` and `Object`,
   * so this function may be applied to `[1, 2, 3]` or `{x: 1, y: 2, z: 3}`.
   *
   * Dispatches to the `map` method of the second argument, if present.
   *
   * Acts as a transducer if a transformer is given in list position.
   *
   * Also treats functions as functors and will compose them together.
   *
   * @func
   * @memberOf R
   * @since v0.1.0
   * @category List
   * @sig Functor f => (a -> b) -> f a -> f b
   * @param {Function} fn The function to be called on every element of the input `list`.
   * @param {Array} list The list to be iterated over.
   * @return {Array} The new list.
   * @see R.transduce, R.addIndex, R.pluck, R.project
   * @example
   *
   *      const double = x => x * 2;
   *
   *      R.map(double, [1, 2, 3]); //=> [2, 4, 6]
   *
   *      R.map(double, {x: 1, y: 2, z: 3}); //=> {x: 2, y: 4, z: 6}
   * @symb R.map(f, [a, b]) = [f(a), f(b)]
   * @symb R.map(f, { x: a, y: b }) = { x: f(a), y: f(b) }
   * @symb R.map(f, functor_o) = functor_o.map(f)
   */

  const map =
    /*#__PURE__*/
    _curry2(
      /*#__PURE__*/
      _dispatchable(
        ['fantasy-land/map', 'map'],
        _xmap,
        function map(fn, functor) {
          switch (Object.prototype.toString.call(functor)) {
            case '[object Function]':
              return curryN(functor.length, function () {
                return fn.call(this, functor.apply(this, arguments))
              })
            case '[object Object]':
              return _reduce(
                function (acc, key) {
                  acc[key] = fn(functor[key])
                  return acc
                },
                {},
                keys(functor)
              )
            default:
              return _map(fn, functor)
          }
        }
      )
    )
  map_1 = map
  return map_1
}

let omit_1
let hasRequiredOmit
function requireOmit() {
  if (hasRequiredOmit) {
    return omit_1
  }
  hasRequiredOmit = 1
  const _curry2 = /*#__PURE__*/ /*@__PURE__*/ require_curry2()
  /**
   * Returns a partial copy of an object omitting the keys specified.
   *
   * @func
   * @memberOf R
   * @since v0.1.0
   * @category Object
   * @sig [String] -> {String: *} -> {String: *}
   * @param {Array} names an array of String property names to omit from the new object
   * @param {Object} obj The object to copy from
   * @return {Object} A new object with properties from `names` not on it.
   * @see R.pick
   * @example
   *
   *      R.omit(['a', 'd'], {a: 1, b: 2, c: 3, d: 4}); //=> {b: 2, c: 3}
   */

  const omit =
    /*#__PURE__*/
    _curry2(function omit(names, obj) {
      const result = {}
      const index = {}
      let idx = 0
      const len = names.length
      while (idx < len) {
        index[names[idx]] = 1
        idx += 1
      }
      for (const prop in obj) {
        if (!index.hasOwnProperty(prop)) {
          result[prop] = obj[prop]
        }
      }
      return result
    })
  omit_1 = omit
  return omit_1
}

let pickBy_1
let hasRequiredPickBy
function requirePickBy() {
  if (hasRequiredPickBy) {
    return pickBy_1
  }
  hasRequiredPickBy = 1
  const _curry2 = /*#__PURE__*/ /*@__PURE__*/ require_curry2()
  /**
   * Returns a partial copy of an object containing only the keys that satisfy
   * the supplied predicate.
   *
   * @func
   * @memberOf R
   * @since v0.8.0
   * @category Object
   * @sig ((v, k) -> Boolean) -> {k: v} -> {k: v}
   * @param {Function} pred A predicate to determine whether or not a key
   *        should be included on the output object.
   * @param {Object} obj The object to copy from
   * @return {Object} A new object with only properties that satisfy `pred`
   *         on it.
   * @see R.pick, R.filter
   * @example
   *
   *      const isUpperCase = (val, key) => key.toUpperCase() === key;
   *      R.pickBy(isUpperCase, {a: 1, b: 2, A: 3, B: 4}); //=> {A: 3, B: 4}
   */

  const pickBy =
    /*#__PURE__*/
    _curry2(function pickBy(test, obj) {
      const result = {}
      for (const prop in obj) {
        if (test(obj[prop], prop, obj)) {
          result[prop] = obj[prop]
        }
      }
      return result
    })
  pickBy_1 = pickBy
  return pickBy_1
}

let pick_1
let hasRequiredPick
function requirePick() {
  if (hasRequiredPick) {
    return pick_1
  }
  hasRequiredPick = 1
  const _curry2 = /*#__PURE__*/ /*@__PURE__*/ require_curry2()
  /**
   * Returns a partial copy of an object containing only the keys specified. If
   * the key does not exist, the property is ignored.
   *
   * @func
   * @memberOf R
   * @since v0.1.0
   * @category Object
   * @sig [k] -> {k: v} -> {k: v}
   * @param {Array} names an array of String property names to copy onto a new object
   * @param {Object} obj The object to copy from
   * @return {Object} A new object with only properties from `names` on it.
   * @see R.omit, R.props
   * @example
   *
   *      R.pick(['a', 'd'], {a: 1, b: 2, c: 3, d: 4}); //=> {a: 1, d: 4}
   *      R.pick(['a', 'e', 'f'], {a: 1, b: 2, c: 3, d: 4}); //=> {a: 1}
   */

  const pick =
    /*#__PURE__*/
    _curry2(function pick(names, obj) {
      const result = {}
      let idx = 0
      while (idx < names.length) {
        if (names[idx] in obj) {
          result[names[idx]] = obj[names[idx]]
        }
        idx += 1
      }
      return result
    })
  pick_1 = pick
  return pick_1
}

let hasRequiredLockfileFormatConverters
function requireLockfileFormatConverters() {
  if (hasRequiredLockfileFormatConverters) {
    return lockfileFormatConverters
  }
  hasRequiredLockfileFormatConverters = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(lockfileFormatConverters, '__esModule', {
    value: true
  })
  lockfileFormatConverters.convertToLockfileFile = convertToLockfileFile
  lockfileFormatConverters.convertToLockfileObject = convertToLockfileObject
  const dependency_path_1 = requireLib$c()
  const types_1 = requireLib$4()
  const isEmpty_1 = __importDefault(/*@__PURE__*/ requireIsEmpty())
  const map_1 = __importDefault(/*@__PURE__*/ requireMap())
  const omit_1 = __importDefault(/*@__PURE__*/ requireOmit())
  const pickBy_1 = __importDefault(/*@__PURE__*/ requirePickBy())
  const pick_1 = __importDefault(/*@__PURE__*/ requirePick())
  const constants_1 = requireLib$a()
  function convertToLockfileFile(lockfile) {
    const packages = {}
    const snapshots = {}
    for (const [depPath, pkg] of Object.entries(lockfile.packages ?? {})) {
      snapshots[depPath] = (0, pick_1.default)(
        [
          'dependencies',
          'optionalDependencies',
          'transitivePeerDependencies',
          'optional',
          'id'
        ],
        pkg
      )
      const pkgId = (0, dependency_path_1.removeSuffix)(depPath)
      if (!packages[pkgId]) {
        packages[pkgId] = (0, pick_1.default)(
          [
            'bundledDependencies',
            'cpu',
            'deprecated',
            'engines',
            'hasBin',
            'libc',
            'name',
            'os',
            'peerDependencies',
            'peerDependenciesMeta',
            'resolution',
            'version'
          ],
          pkg
        )
      }
    }
    const newLockfile = {
      ...lockfile,
      snapshots,
      packages,
      lockfileVersion: constants_1.LOCKFILE_VERSION,
      importers: mapValues(
        lockfile.importers,
        convertProjectSnapshotToInlineSpecifiersFormat
      )
    }
    if (newLockfile.settings?.peersSuffixMaxLength === 1000) {
      newLockfile.settings = (0, omit_1.default)(
        ['peersSuffixMaxLength'],
        newLockfile.settings
      )
    }
    if (newLockfile.settings?.injectWorkspacePackages === false) {
      delete newLockfile.settings.injectWorkspacePackages
    }
    return normalizeLockfile(newLockfile)
  }
  function normalizeLockfile(lockfile) {
    const lockfileToSave = {
      ...lockfile,
      importers: (0, map_1.default)(importer => {
        const normalizedImporter = {}
        if (
          importer.dependenciesMeta != null &&
          !(0, isEmpty_1.default)(importer.dependenciesMeta)
        ) {
          normalizedImporter.dependenciesMeta = importer.dependenciesMeta
        }
        for (const depType of types_1.DEPENDENCIES_FIELDS) {
          if (!(0, isEmpty_1.default)(importer[depType] ?? {})) {
            normalizedImporter[depType] = importer[depType]
          }
        }
        if (importer.publishDirectory) {
          normalizedImporter.publishDirectory = importer.publishDirectory
        }
        return normalizedImporter
      }, lockfile.importers ?? {})
    }
    if (
      (0, isEmpty_1.default)(lockfileToSave.packages) ||
      lockfileToSave.packages == null
    ) {
      delete lockfileToSave.packages
    }
    if (
      (0, isEmpty_1.default)(lockfileToSave.snapshots) ||
      lockfileToSave.snapshots == null
    ) {
      delete lockfileToSave.snapshots
    }
    if (lockfileToSave.time) {
      lockfileToSave.time = pruneTimeInLockfile(
        lockfileToSave.time,
        lockfile.importers ?? {}
      )
    }
    if (
      lockfileToSave.catalogs != null &&
      (0, isEmpty_1.default)(lockfileToSave.catalogs)
    ) {
      delete lockfileToSave.catalogs
    }
    if (
      lockfileToSave.overrides != null &&
      (0, isEmpty_1.default)(lockfileToSave.overrides)
    ) {
      delete lockfileToSave.overrides
    }
    if (
      lockfileToSave.patchedDependencies != null &&
      (0, isEmpty_1.default)(lockfileToSave.patchedDependencies)
    ) {
      delete lockfileToSave.patchedDependencies
    }
    if (!lockfileToSave.packageExtensionsChecksum) {
      delete lockfileToSave.packageExtensionsChecksum
    }
    if (!lockfileToSave.ignoredOptionalDependencies?.length) {
      delete lockfileToSave.ignoredOptionalDependencies
    }
    if (!lockfileToSave.pnpmfileChecksum) {
      delete lockfileToSave.pnpmfileChecksum
    }
    return lockfileToSave
  }
  function pruneTimeInLockfile(time, importers) {
    const rootDepPaths = new Set()
    for (const importer of Object.values(importers)) {
      for (const depType of types_1.DEPENDENCIES_FIELDS) {
        for (const [depName, ref] of Object.entries(importer[depType] ?? {})) {
          const suffixStart = ref.version.indexOf('(')
          const refWithoutPeerSuffix =
            suffixStart === -1 ? ref.version : ref.version.slice(0, suffixStart)
          const depPath = refToRelative(refWithoutPeerSuffix, depName)
          if (!depPath) {
            continue
          }
          rootDepPaths.add(depPath)
        }
      }
    }
    return (0, pickBy_1.default)(
      (_, depPath) => rootDepPaths.has(depPath),
      time
    )
  }
  function refToRelative(reference, pkgName) {
    if (reference.startsWith('link:')) {
      return null
    }
    if (reference.startsWith('file:')) {
      return reference
    }
    if (
      !reference.includes('/') ||
      !reference.replace(/(?:\([^)]+\))+$/, '').includes('/')
    ) {
      return `/${pkgName}@${reference}`
    }
    return reference
  }
  function convertToLockfileObject(lockfile) {
    const { importers, ...rest } = lockfile
    const packages = {}
    for (const [depPath, pkg] of Object.entries(lockfile.snapshots ?? {})) {
      const pkgId = (0, dependency_path_1.removeSuffix)(depPath)
      packages[depPath] = Object.assign(pkg, lockfile.packages?.[pkgId])
    }
    return {
      ...(0, omit_1.default)(['snapshots'], rest),
      packages,
      importers: mapValues(importers ?? {}, revertProjectSnapshot)
    }
  }
  function convertProjectSnapshotToInlineSpecifiersFormat(projectSnapshot) {
    const { specifiers, ...rest } = projectSnapshot
    if (specifiers == null) {
      return projectSnapshot
    }
    const convertBlock = block =>
      block != null
        ? convertResolvedDependenciesToInlineSpecifiersFormat(block, {
            specifiers
          })
        : block
    return {
      ...rest,
      dependencies: convertBlock(projectSnapshot.dependencies ?? {}),
      optionalDependencies: convertBlock(
        projectSnapshot.optionalDependencies ?? {}
      ),
      devDependencies: convertBlock(projectSnapshot.devDependencies ?? {})
    }
  }
  function convertResolvedDependenciesToInlineSpecifiersFormat(
    resolvedDependencies,
    { specifiers }
  ) {
    return mapValues(resolvedDependencies, (version, depName) => ({
      specifier: specifiers[depName],
      version
    }))
  }
  function revertProjectSnapshot(from) {
    const specifiers = {}
    function moveSpecifiers(from) {
      const resolvedDependencies = {}
      for (const [depName, { specifier, version }] of Object.entries(from)) {
        const existingValue = specifiers[depName]
        if (existingValue != null && existingValue !== specifier) {
          throw new Error(
            `Project snapshot lists the same dependency more than once with conflicting versions: ${depName}`
          )
        }
        specifiers[depName] = specifier
        resolvedDependencies[depName] = version
      }
      return resolvedDependencies
    }
    const dependencies =
      from.dependencies == null
        ? from.dependencies
        : moveSpecifiers(from.dependencies)
    const devDependencies =
      from.devDependencies == null
        ? from.devDependencies
        : moveSpecifiers(from.devDependencies)
    const optionalDependencies =
      from.optionalDependencies == null
        ? from.optionalDependencies
        : moveSpecifiers(from.optionalDependencies)
    return {
      ...from,
      specifiers,
      dependencies,
      devDependencies,
      optionalDependencies
    }
  }
  function mapValues(obj, mapper) {
    const result = {}
    for (const [key, value] of Object.entries(obj)) {
      result[key] = mapper(value, key)
    }
    return result
  }
  return lockfileFormatConverters
}

let hasRequiredWrite
function requireWrite() {
  if (hasRequiredWrite) {
    return write
  }
  hasRequiredWrite = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(write, '__esModule', {
    value: true
  })
  write.writeWantedLockfile = writeWantedLockfile
  write.writeCurrentLockfile = writeCurrentLockfile
  write.writeLockfileFile = writeLockfileFile
  write.isEmptyLockfile = isEmptyLockfile
  write.writeLockfiles = writeLockfiles
  const fs_1 = require$$0$6
  const path_1 = __importDefault(require$$0$5)
  const constants_1 = requireLib$a()
  const rimraf_1 = __importDefault(requireRimraf())
  const js_yaml_1 = __importDefault(requireJsYaml())
  const isEmpty_1 = __importDefault(/*@__PURE__*/ requireIsEmpty())
  const write_file_atomic_1 = __importDefault(requireLib$9())
  const logger_1 = requireLogger()
  const sortLockfileKeys_1 = requireSortLockfileKeys()
  const lockfileName_1 = requireLockfileName()
  const lockfileFormatConverters_1 = requireLockfileFormatConverters()
  async function writeFileAtomic(filename, data) {
    return new Promise((resolve, reject) => {
      ;(0, write_file_atomic_1.default)(filename, data, {}, err => {
        err != null ? reject(err) : resolve()
      })
    })
  }
  const LOCKFILE_YAML_FORMAT = {
    blankLines: true,
    lineWidth: -1,
    // This is setting line width to never wrap
    noCompatMode: true,
    noRefs: true,
    sortKeys: false
  }
  async function writeWantedLockfile(pkgPath, wantedLockfile, opts) {
    const wantedLockfileName = await (0, lockfileName_1.getWantedLockfileName)(
      opts
    )
    return writeLockfile(wantedLockfileName, pkgPath, wantedLockfile)
  }
  async function writeCurrentLockfile(virtualStoreDir, currentLockfile) {
    // empty lockfile is not saved
    if (isEmptyLockfile(currentLockfile)) {
      await (0, rimraf_1.default)(
        path_1.default.join(virtualStoreDir, 'lock.yaml')
      )
      return
    }
    await fs_1.promises.mkdir(virtualStoreDir, {
      recursive: true
    })
    return writeLockfile('lock.yaml', virtualStoreDir, currentLockfile)
  }
  async function writeLockfile(lockfileFilename, pkgPath, wantedLockfile) {
    const lockfilePath = path_1.default.join(pkgPath, lockfileFilename)
    const lockfileToStringify = (0,
    lockfileFormatConverters_1.convertToLockfileFile)(wantedLockfile)
    return writeLockfileFile(lockfilePath, lockfileToStringify)
  }
  function writeLockfileFile(lockfilePath, wantedLockfile) {
    const yamlDoc = yamlStringify(wantedLockfile)
    return writeFileAtomic(lockfilePath, yamlDoc)
  }
  function yamlStringify(lockfile) {
    const sortedLockfile = (0, sortLockfileKeys_1.sortLockfileKeys)(lockfile)
    return js_yaml_1.default.dump(sortedLockfile, LOCKFILE_YAML_FORMAT)
  }
  function isEmptyLockfile(lockfile) {
    return Object.values(lockfile.importers).every(
      importer =>
        (0, isEmpty_1.default)(importer.specifiers ?? {}) &&
        (0, isEmpty_1.default)(importer.dependencies ?? {})
    )
  }
  async function writeLockfiles(opts) {
    const wantedLockfileName = await (0, lockfileName_1.getWantedLockfileName)(
      opts
    )
    const wantedLockfilePath = path_1.default.join(
      opts.wantedLockfileDir,
      wantedLockfileName
    )
    const currentLockfilePath = path_1.default.join(
      opts.currentLockfileDir,
      'lock.yaml'
    )
    const wantedLockfileToStringify = (0,
    lockfileFormatConverters_1.convertToLockfileFile)(opts.wantedLockfile)
    const yamlDoc = yamlStringify(wantedLockfileToStringify)
    // in most cases the `pnpm-lock.yaml` and `node_modules/.pnpm-lock.yaml` are equal
    // in those cases the YAML document can be stringified only once for both files
    // which is more efficient
    if (opts.wantedLockfile === opts.currentLockfile) {
      await Promise.all([
        writeFileAtomic(wantedLockfilePath, yamlDoc),
        (async () => {
          if (isEmptyLockfile(opts.wantedLockfile)) {
            await (0, rimraf_1.default)(currentLockfilePath)
          } else {
            await fs_1.promises.mkdir(
              path_1.default.dirname(currentLockfilePath),
              {
                recursive: true
              }
            )
            await writeFileAtomic(currentLockfilePath, yamlDoc)
          }
        })()
      ])
      return
    }
    logger_1.lockfileLogger.debug({
      message: `\`${constants_1.WANTED_LOCKFILE}\` differs from \`${path_1.default.relative(opts.wantedLockfileDir, currentLockfilePath)}\``,
      prefix: opts.wantedLockfileDir
    })
    const currentLockfileToStringify = (0,
    lockfileFormatConverters_1.convertToLockfileFile)(opts.currentLockfile)
    const currentYamlDoc = yamlStringify(currentLockfileToStringify)
    await Promise.all([
      writeFileAtomic(wantedLockfilePath, yamlDoc),
      (async () => {
        if (isEmptyLockfile(opts.wantedLockfile)) {
          await (0, rimraf_1.default)(currentLockfilePath)
        } else {
          await fs_1.promises.mkdir(
            path_1.default.dirname(currentLockfilePath),
            {
              recursive: true
            }
          )
          await writeFileAtomic(currentLockfilePath, currentYamlDoc)
        }
      })()
    ])
  }
  return write
}

const existsWantedLockfile = {}

let hasRequiredExistsWantedLockfile
function requireExistsWantedLockfile() {
  if (hasRequiredExistsWantedLockfile) {
    return existsWantedLockfile
  }
  hasRequiredExistsWantedLockfile = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(existsWantedLockfile, '__esModule', {
    value: true
  })
  existsWantedLockfile.existsNonEmptyWantedLockfile =
    existsNonEmptyWantedLockfile
  const fs_1 = __importDefault(require$$0$6)
  const path_1 = __importDefault(require$$0$5)
  const lockfileName_1 = requireLockfileName()
  async function existsNonEmptyWantedLockfile(
    pkgPath,
    opts = {
      useGitBranchLockfile: false,
      mergeGitBranchLockfiles: false
    }
  ) {
    const wantedLockfile = await (0, lockfileName_1.getWantedLockfileName)(opts)
    return new Promise((resolve, reject) => {
      fs_1.default.access(path_1.default.join(pkgPath, wantedLockfile), err => {
        if (err == null) {
          resolve(true)
          return
        }
        if (err.code === 'ENOENT') {
          resolve(false)
          return
        }
        reject(err)
      })
    })
  }
  return existsWantedLockfile
}

const getLockfileImporterId = {}

/*!
 * normalize-path <https://github.com/jonschlinkert/normalize-path>
 *
 * Copyright (c) 2014-2018, Jon Schlinkert.
 * Released under the MIT License.
 */
let normalizePath
let hasRequiredNormalizePath
function requireNormalizePath() {
  if (hasRequiredNormalizePath) {
    return normalizePath
  }
  hasRequiredNormalizePath = 1
  normalizePath = function (path, stripTrailing) {
    if (typeof path !== 'string') {
      throw new TypeError('expected path to be a string')
    }
    if (path === '\\' || path === '/') {
      return '/'
    }
    const len = path.length
    if (len <= 1) {
      return path
    }

    // ensure that win32 namespaces has two leading slashes, so that the path is
    // handled properly by the win32 version of path.parse() after being normalized
    // https://msdn.microsoft.com/library/windows/desktop/aa365247(v=vs.85).aspx#namespaces
    let prefix = ''
    if (len > 4 && path[3] === '\\') {
      const ch = path[2]
      if ((ch === '?' || ch === '.') && path.slice(0, 2) === '\\\\') {
        path = path.slice(2)
        prefix = '//'
      }
    }
    const segs = path.split(/[/\\]+/)
    if (stripTrailing !== false && segs[segs.length - 1] === '') {
      segs.pop()
    }
    return prefix + segs.join('/')
  }
  return normalizePath
}

let hasRequiredGetLockfileImporterId
function requireGetLockfileImporterId() {
  if (hasRequiredGetLockfileImporterId) {
    return getLockfileImporterId
  }
  hasRequiredGetLockfileImporterId = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(getLockfileImporterId, '__esModule', {
    value: true
  })
  getLockfileImporterId.getLockfileImporterId = getLockfileImporterId$1
  const path_1 = __importDefault(require$$0$5)
  const normalize_path_1 = __importDefault(requireNormalizePath())
  function getLockfileImporterId$1(lockfileDir, prefix) {
    return (
      (0, normalize_path_1.default)(
        path_1.default.relative(lockfileDir, prefix)
      ) || '.'
    )
  }
  return getLockfileImporterId
}

const lib$2 = {}

const lockfileFileTypes = {}

let hasRequiredLockfileFileTypes
function requireLockfileFileTypes() {
  if (hasRequiredLockfileFileTypes) {
    return lockfileFileTypes
  }
  hasRequiredLockfileFileTypes = 1
  Object.defineProperty(lockfileFileTypes, '__esModule', {
    value: true
  })
  return lockfileFileTypes
}

let hasRequiredLib$3
function requireLib$3() {
  if (hasRequiredLib$3) {
    return lib$2
  }
  hasRequiredLib$3 = 1
  ;(function (exports) {
    const __createBinding =
      (this && this.__createBinding) ||
      (Object.create
        ? function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            let desc = Object.getOwnPropertyDescriptor(m, k)
            if (
              !desc ||
              ('get' in desc
                ? !m.__esModule
                : desc.writable || desc.configurable)
            ) {
              desc = {
                enumerable: true,
                get: function () {
                  return m[k]
                }
              }
            }
            Object.defineProperty(o, k2, desc)
          }
        : function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            o[k2] = m[k]
          })
    const __exportStar =
      (this && this.__exportStar) ||
      function (m, exports) {
        for (const p in m) {
          if (
            p !== 'default' &&
            !Object.prototype.hasOwnProperty.call(exports, p)
          )
            __createBinding(exports, m, p)
        }
      }
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    __exportStar(requireLockfileFileTypes(), exports)
  })(lib$2)
  return lib$2
}

const read = {}

const lib$1 = {}

let hasRequiredLib$2
function requireLib$2() {
  if (hasRequiredLib$2) {
    return lib$1
  }
  hasRequiredLib$2 = 1
  Object.defineProperty(lib$1, '__esModule', {
    value: true
  })
  lib$1.LockfileMissingDependencyError =
    lib$1.FetchError =
    lib$1.PnpmError =
      void 0
  const constants_1 = requireLib$a()
  class PnpmError extends Error {
    constructor(code, message, opts) {
      super(message)
      this.code = code.startsWith('ERR_PNPM_') ? code : `ERR_PNPM_${code}`
      this.hint = opts?.hint
      this.attempts = opts?.attempts
    }
  }
  lib$1.PnpmError = PnpmError
  class FetchError extends PnpmError {
    constructor(request, response, hint) {
      const _request = {
        url: request.url
      }
      if (request.authHeaderValue) {
        _request.authHeaderValue = hideAuthInformation(request.authHeaderValue)
      }
      const message = `GET ${request.url}: ${response.statusText} - ${response.status}`
      // NOTE: For security reasons, some registries respond with 404 on authentication errors as well.
      // So we print authorization info on 404 errors as well.
      if (
        response.status === 401 ||
        response.status === 403 ||
        response.status === 404
      ) {
        hint = hint ? `${hint}\n\n` : ''
        if (_request.authHeaderValue) {
          hint += `An authorization header was used: ${_request.authHeaderValue}`
        } else {
          hint += 'No authorization header was set for the request.'
        }
      }
      super(`FETCH_${response.status}`, message, {
        hint
      })
      this.request = _request
      this.response = response
    }
  }
  lib$1.FetchError = FetchError
  function hideAuthInformation(authHeaderValue) {
    const [authType, token] = authHeaderValue.split(' ')
    if (token == null) {
      return '[hidden]'
    }
    if (token.length < 20) {
      return `${authType} [hidden]`
    }
    return `${authType} ${token.substring(0, 4)}[hidden]`
  }
  class LockfileMissingDependencyError extends PnpmError {
    constructor(depPath) {
      const message = `Broken lockfile: no entry for '${depPath}' in ${constants_1.WANTED_LOCKFILE}`
      super('LOCKFILE_MISSING_DEPENDENCY', message, {
        hint:
          'This issue is probably caused by a badly resolved merge conflict.\n' +
          "To fix the lockfile, run 'pnpm install --no-frozen-lockfile'."
      })
    }
  }
  lib$1.LockfileMissingDependencyError = LockfileMissingDependencyError
  return lib$1
}

const lib = {}

let comverToSemver
let hasRequiredComverToSemver
function requireComverToSemver() {
  if (hasRequiredComverToSemver) {
    return comverToSemver
  }
  hasRequiredComverToSemver = 1
  comverToSemver = function comverToSemver(comver) {
    if (!comver.includes('.')) {
      return `${comver}.0.0`
    }
    return `${comver}.0`
  }
  return comverToSemver
}

let hasRequiredLib$1
function requireLib$1() {
  if (hasRequiredLib$1) {
    return lib
  }
  hasRequiredLib$1 = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(lib, '__esModule', {
    value: true
  })
  lib.mergeLockfileChanges = mergeLockfileChanges
  const comver_to_semver_1 = __importDefault(requireComverToSemver())
  const semver_1 = __importDefault(requireSemver())
  function mergeLockfileChanges(ours, theirs) {
    const newLockfile = {
      importers: {},
      lockfileVersion: semver_1.default.gt(
        (0, comver_to_semver_1.default)(theirs.lockfileVersion.toString()),
        (0, comver_to_semver_1.default)(ours.lockfileVersion.toString())
      )
        ? theirs.lockfileVersion
        : ours.lockfileVersion
    }
    const pnpmfileChecksum = ours.pnpmfileChecksum ?? theirs.pnpmfileChecksum // Install should automatically detect change later
    if (pnpmfileChecksum) {
      newLockfile.pnpmfileChecksum = pnpmfileChecksum
    }
    const ignoredOptionalDependencies = [
      ...new Set([
        ...(ours.ignoredOptionalDependencies ?? []),
        ...(theirs.ignoredOptionalDependencies ?? [])
      ])
    ]
    if (ignoredOptionalDependencies.length) {
      newLockfile.ignoredOptionalDependencies = ignoredOptionalDependencies
    }
    for (const importerId of Array.from(
      new Set([
        ...Object.keys(ours.importers),
        ...Object.keys(theirs.importers)
      ])
    )) {
      newLockfile.importers[importerId] = {
        specifiers: {}
      }
      for (const key of [
        'dependencies',
        'devDependencies',
        'optionalDependencies'
      ]) {
        newLockfile.importers[importerId][key] = mergeDict(
          ours.importers[importerId]?.[key] ?? {},
          theirs.importers[importerId]?.[key] ?? {},
          mergeVersions
        )
        if (
          Object.keys(newLockfile.importers[importerId][key] ?? {}).length === 0
        ) {
          delete newLockfile.importers[importerId][key]
        }
      }
      newLockfile.importers[importerId].specifiers = mergeDict(
        ours.importers[importerId]?.specifiers ?? {},
        theirs.importers[importerId]?.specifiers ?? {},
        takeChangedValue
      )
    }
    const packages = {}
    for (const depPath of Array.from(
      new Set([
        ...Object.keys(ours.packages ?? {}),
        ...Object.keys(theirs.packages ?? {})
      ])
    )) {
      const ourPkg = ours.packages?.[depPath]
      const theirPkg = theirs.packages?.[depPath]
      const pkg = {
        ...ourPkg,
        ...theirPkg
      }
      for (const key of ['dependencies', 'optionalDependencies']) {
        pkg[key] = mergeDict(
          ourPkg?.[key] ?? {},
          theirPkg?.[key] ?? {},
          mergeVersions
        )
        if (Object.keys(pkg[key] ?? {}).length === 0) {
          delete pkg[key]
        }
      }
      packages[depPath] = pkg
    }
    newLockfile.packages = packages
    return newLockfile
  }
  function mergeDict(ourDict, theirDict, valueMerger) {
    const newDict = {}
    for (const key of Object.keys(ourDict).concat(Object.keys(theirDict))) {
      const changedValue = valueMerger(ourDict[key], theirDict[key])
      if (changedValue) {
        newDict[key] = changedValue
      }
    }
    return newDict
  }
  function takeChangedValue(ourValue, theirValue) {
    if (ourValue === theirValue || theirValue == null) {
      return ourValue
    }
    return theirValue
  }
  function mergeVersions(ourValue, theirValue) {
    if (ourValue === theirValue || !theirValue) {
      return ourValue
    }
    if (!ourValue) {
      return theirValue
    }
    const [ourVersion] = ourValue.split('(')
    const [theirVersion] = theirValue.split('(')
    if (semver_1.default.gt(ourVersion, theirVersion)) {
      return ourValue
    }
    return theirValue
  }
  return lib
}

let stripBom
let hasRequiredStripBom
function requireStripBom() {
  if (hasRequiredStripBom) {
    return stripBom
  }
  hasRequiredStripBom = 1
  stripBom = string => {
    if (typeof string !== 'string') {
      throw new TypeError(`Expected a string, got ${typeof string}`)
    }

    // Catches EFBBBF (UTF-8 BOM) because the buffer-to-string
    // conversion translates it to FEFF (UTF-16 BOM)
    if (string.charCodeAt(0) === 0xfeff) {
      return string.slice(1)
    }
    return string
  }
  return stripBom
}

const errors = {}

const LockfileBreakingChangeError = {}

let hasRequiredLockfileBreakingChangeError
function requireLockfileBreakingChangeError() {
  if (hasRequiredLockfileBreakingChangeError) {
    return LockfileBreakingChangeError
  }
  hasRequiredLockfileBreakingChangeError = 1
  Object.defineProperty(LockfileBreakingChangeError, '__esModule', {
    value: true
  })
  LockfileBreakingChangeError.LockfileBreakingChangeError = void 0
  const error_1 = requireLib$2()
  let LockfileBreakingChangeError$1 = class LockfileBreakingChangeError extends error_1.PnpmError {
    constructor(filename) {
      super(
        'LOCKFILE_BREAKING_CHANGE',
        `Lockfile ${filename} not compatible with current pnpm`
      )
      this.filename = filename
    }
  }
  LockfileBreakingChangeError.LockfileBreakingChangeError =
    LockfileBreakingChangeError$1
  return LockfileBreakingChangeError
}

let hasRequiredErrors
function requireErrors() {
  if (hasRequiredErrors) {
    return errors
  }
  hasRequiredErrors = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.LockfileBreakingChangeError = void 0
    const LockfileBreakingChangeError_1 = requireLockfileBreakingChangeError()
    Object.defineProperty(exports, 'LockfileBreakingChangeError', {
      enumerable: true,
      get: function () {
        return LockfileBreakingChangeError_1.LockfileBreakingChangeError
      }
    })
  })(errors)
  return errors
}

const gitMergeFile = {}

let hasRequiredGitMergeFile
function requireGitMergeFile() {
  if (hasRequiredGitMergeFile) {
    return gitMergeFile
  }
  hasRequiredGitMergeFile = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(gitMergeFile, '__esModule', {
    value: true
  })
  gitMergeFile.autofixMergeConflicts = autofixMergeConflicts
  gitMergeFile.isDiff = isDiff
  const lockfile_merger_1 = requireLib$1()
  const js_yaml_1 = __importDefault(requireJsYaml())
  const lockfileFormatConverters_1 = requireLockfileFormatConverters()
  const MERGE_CONFLICT_PARENT = '|||||||'
  const MERGE_CONFLICT_END = '>>>>>>>'
  const MERGE_CONFLICT_THEIRS = '======='
  const MERGE_CONFLICT_OURS = '<<<<<<<'
  function autofixMergeConflicts(fileContent) {
    const { ours, theirs } = parseMergeFile(fileContent)
    return (0, lockfile_merger_1.mergeLockfileChanges)(
      (0, lockfileFormatConverters_1.convertToLockfileObject)(
        js_yaml_1.default.load(ours)
      ),
      (0, lockfileFormatConverters_1.convertToLockfileObject)(
        js_yaml_1.default.load(theirs)
      )
    )
  }
  function parseMergeFile(fileContent) {
    const lines = fileContent.split(/[\n\r]+/)
    let state = 'top'
    const ours = []
    const theirs = []
    while (lines.length > 0) {
      const line = lines.shift()
      if (line.startsWith(MERGE_CONFLICT_PARENT)) {
        state = 'parent'
        continue
      }
      if (line.startsWith(MERGE_CONFLICT_OURS)) {
        state = 'ours'
        continue
      }
      if (line === MERGE_CONFLICT_THEIRS) {
        state = 'theirs'
        continue
      }
      if (line.startsWith(MERGE_CONFLICT_END)) {
        state = 'top'
        continue
      }
      if (state === 'top' || state === 'ours') {
        ours.push(line)
      }
      if (state === 'top' || state === 'theirs') {
        theirs.push(line)
      }
    }
    return {
      ours: ours.join('\n'),
      theirs: theirs.join('\n')
    }
  }
  function isDiff(fileContent) {
    return (
      fileContent.includes(MERGE_CONFLICT_OURS) &&
      fileContent.includes(MERGE_CONFLICT_THEIRS) &&
      fileContent.includes(MERGE_CONFLICT_END)
    )
  }
  return gitMergeFile
}

const gitBranchLockfile = {}

let hasRequiredGitBranchLockfile
function requireGitBranchLockfile() {
  if (hasRequiredGitBranchLockfile) {
    return gitBranchLockfile
  }
  hasRequiredGitBranchLockfile = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(gitBranchLockfile, '__esModule', {
    value: true
  })
  gitBranchLockfile.getGitBranchLockfileNames = getGitBranchLockfileNames
  gitBranchLockfile.cleanGitBranchLockfiles = cleanGitBranchLockfiles
  const fs_1 = require$$0$6
  const path_1 = __importDefault(require$$0$5)
  async function getGitBranchLockfileNames(lockfileDir) {
    const files = await fs_1.promises.readdir(lockfileDir)
    // eslint-disable-next-line regexp/no-useless-non-capturing-group
    const gitBranchLockfileNames = files.filter(file =>
      file.match(/^pnpm-lock.(?:.*).yaml$/)
    )
    return gitBranchLockfileNames
  }
  async function cleanGitBranchLockfiles(lockfileDir) {
    const gitBranchLockfiles = await getGitBranchLockfileNames(lockfileDir)
    await Promise.all(
      gitBranchLockfiles.map(async file => {
        const filepath = path_1.default.join(lockfileDir, file)
        await fs_1.promises.unlink(filepath)
      })
    )
  }
  return gitBranchLockfile
}

let hasRequiredRead
function requireRead() {
  if (hasRequiredRead) {
    return read
  }
  hasRequiredRead = 1
  const __importDefault =
    (this && this.__importDefault) ||
    function (mod) {
      return mod && mod.__esModule
        ? mod
        : {
            default: mod
          }
    }
  Object.defineProperty(read, '__esModule', {
    value: true
  })
  read.readCurrentLockfile = readCurrentLockfile
  read.readWantedLockfileAndAutofixConflicts =
    readWantedLockfileAndAutofixConflicts
  read.readWantedLockfile = readWantedLockfile
  read.createLockfileObject = createLockfileObject
  const fs_1 = require$$0$6
  const path_1 = __importDefault(require$$0$5)
  const util_1 = __importDefault(require$$0$4)
  const constants_1 = requireLib$a()
  const error_1 = requireLib$2()
  const lockfile_merger_1 = requireLib$1()
  const comver_to_semver_1 = __importDefault(requireComverToSemver())
  const js_yaml_1 = __importDefault(requireJsYaml())
  const semver_1 = __importDefault(requireSemver())
  const strip_bom_1 = __importDefault(requireStripBom())
  const errors_1 = requireErrors()
  const gitMergeFile_1 = requireGitMergeFile()
  const logger_1 = requireLogger()
  const lockfileName_1 = requireLockfileName()
  const gitBranchLockfile_1 = requireGitBranchLockfile()
  const lockfileFormatConverters_1 = requireLockfileFormatConverters()
  async function readCurrentLockfile(virtualStoreDir, opts) {
    const lockfilePath = path_1.default.join(virtualStoreDir, 'lock.yaml')
    return (await _read(lockfilePath, virtualStoreDir, opts)).lockfile
  }
  async function readWantedLockfileAndAutofixConflicts(pkgPath, opts) {
    return _readWantedLockfile(pkgPath, {
      ...opts,
      autofixMergeConflicts: true
    })
  }
  async function readWantedLockfile(pkgPath, opts) {
    return (await _readWantedLockfile(pkgPath, opts)).lockfile
  }
  async function _read(
    lockfilePath,
    prefix,
    // only for logging
    opts
  ) {
    let lockfileRawContent
    try {
      lockfileRawContent = (0, strip_bom_1.default)(
        await fs_1.promises.readFile(lockfilePath, 'utf8')
      )
    } catch (err) {
      if (
        !(
          util_1.default.types.isNativeError(err) &&
          'code' in err &&
          err.code === 'ENOENT'
        )
      ) {
        throw err
      }
      return {
        lockfile: null,
        hadConflicts: false
      }
    }
    let lockfile
    let hadConflicts
    try {
      lockfile = (0, lockfileFormatConverters_1.convertToLockfileObject)(
        js_yaml_1.default.load(lockfileRawContent)
      ) // eslint-disable-line
      hadConflicts = false
    } catch (err) {
      if (
        !opts.autofixMergeConflicts ||
        !(0, gitMergeFile_1.isDiff)(lockfileRawContent)
      ) {
        throw new error_1.PnpmError(
          'BROKEN_LOCKFILE',
          `The lockfile at "${lockfilePath}" is broken: ${err.message}`
        )
      }
      hadConflicts = true
      lockfile = (0, gitMergeFile_1.autofixMergeConflicts)(lockfileRawContent)
      logger_1.lockfileLogger.info({
        message: `Merge conflict detected in ${constants_1.WANTED_LOCKFILE} and successfully merged`,
        prefix
      })
    }
    if (lockfile) {
      const lockfileSemver = (0, comver_to_semver_1.default)(
        (lockfile.lockfileVersion ?? 0).toString()
      )
      if (
        !opts.wantedVersions ||
        opts.wantedVersions.length === 0 ||
        opts.wantedVersions.some(wantedVersion => {
          if (
            semver_1.default.major(lockfileSemver) !==
            semver_1.default.major(
              (0, comver_to_semver_1.default)(wantedVersion)
            )
          ) {
            return false
          }
          if (
            lockfile.lockfileVersion !== '6.1' &&
            semver_1.default.gt(
              lockfileSemver,
              (0, comver_to_semver_1.default)(wantedVersion)
            )
          ) {
            logger_1.lockfileLogger.warn({
              message:
                `Your ${constants_1.WANTED_LOCKFILE} was generated by a newer version of pnpm. ` +
                `It is a compatible version but it might get downgraded to version ${wantedVersion}`,
              prefix
            })
          }
          return true
        })
      ) {
        return {
          lockfile,
          hadConflicts
        }
      }
    }
    if (opts.ignoreIncompatible) {
      logger_1.lockfileLogger.warn({
        message: `Ignoring not compatible lockfile at ${lockfilePath}`,
        prefix
      })
      return {
        lockfile: null,
        hadConflicts: false
      }
    }
    throw new errors_1.LockfileBreakingChangeError(lockfilePath)
  }
  function createLockfileObject(importerIds, opts) {
    const importers = {}
    for (const importerId of importerIds) {
      importers[importerId] = {
        dependencies: {},
        specifiers: {}
      }
    }
    return {
      importers,
      lockfileVersion: opts.lockfileVersion || constants_1.LOCKFILE_VERSION,
      settings: {
        autoInstallPeers: opts.autoInstallPeers,
        excludeLinksFromLockfile: opts.excludeLinksFromLockfile,
        peersSuffixMaxLength: opts.peersSuffixMaxLength
      }
    }
  }
  async function _readWantedLockfile(pkgPath, opts) {
    const lockfileNames = [constants_1.WANTED_LOCKFILE]
    if (opts.useGitBranchLockfile) {
      const gitBranchLockfileName = await (0,
      lockfileName_1.getWantedLockfileName)(opts)
      if (gitBranchLockfileName !== constants_1.WANTED_LOCKFILE) {
        lockfileNames.unshift(gitBranchLockfileName)
      }
    }
    let result = {
      lockfile: null,
      hadConflicts: false
    }
    /* eslint-disable no-await-in-loop */
    for (const lockfileName of lockfileNames) {
      result = await _read(
        path_1.default.join(pkgPath, lockfileName),
        pkgPath,
        {
          ...opts,
          autofixMergeConflicts: true
        }
      )
      if (result.lockfile) {
        if (opts.mergeGitBranchLockfiles) {
          result.lockfile = await _mergeGitBranchLockfiles(
            result.lockfile,
            pkgPath,
            pkgPath,
            opts
          )
        }
        break
      }
    }
    /* eslint-enable no-await-in-loop */
    return result
  }
  async function _mergeGitBranchLockfiles(lockfile, lockfileDir, prefix, opts) {
    if (!lockfile) {
      return lockfile
    }
    const gitBranchLockfiles = (
      await _readGitBranchLockfiles(lockfileDir, prefix, opts)
    ).map(({ lockfile }) => lockfile)
    let mergedLockfile = lockfile
    for (const gitBranchLockfile of gitBranchLockfiles) {
      if (!gitBranchLockfile) {
        continue
      }
      mergedLockfile = (0, lockfile_merger_1.mergeLockfileChanges)(
        mergedLockfile,
        gitBranchLockfile
      )
    }
    return mergedLockfile
  }
  async function _readGitBranchLockfiles(lockfileDir, prefix, opts) {
    const files = await (0, gitBranchLockfile_1.getGitBranchLockfileNames)(
      lockfileDir
    )
    return Promise.all(
      files.map(file =>
        _read(path_1.default.join(lockfileDir, file), prefix, opts)
      )
    )
  }
  return read
}

let hasRequiredLib
function requireLib() {
  if (hasRequiredLib) {
    return lib$a
  }
  hasRequiredLib = 1
  ;(function (exports) {
    const __createBinding =
      (this && this.__createBinding) ||
      (Object.create
        ? function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            let desc = Object.getOwnPropertyDescriptor(m, k)
            if (
              !desc ||
              ('get' in desc
                ? !m.__esModule
                : desc.writable || desc.configurable)
            ) {
              desc = {
                enumerable: true,
                get: function () {
                  return m[k]
                }
              }
            }
            Object.defineProperty(o, k2, desc)
          }
        : function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            o[k2] = m[k]
          })
    const __exportStar =
      (this && this.__exportStar) ||
      function (m, exports) {
        for (const p in m) {
          if (
            p !== 'default' &&
            !Object.prototype.hasOwnProperty.call(exports, p)
          )
            __createBinding(exports, m, p)
        }
      }
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.convertToLockfileFile =
      exports.cleanGitBranchLockfiles =
      exports.getLockfileImporterId =
      exports.existsNonEmptyWantedLockfile =
      exports.writeLockfileFile =
      exports.writeWantedLockfile =
      exports.writeCurrentLockfile =
      exports.writeLockfiles =
      exports.isEmptyLockfile =
        void 0
    const write_1 = requireWrite()
    Object.defineProperty(exports, 'isEmptyLockfile', {
      enumerable: true,
      get: function () {
        return write_1.isEmptyLockfile
      }
    })
    Object.defineProperty(exports, 'writeLockfiles', {
      enumerable: true,
      get: function () {
        return write_1.writeLockfiles
      }
    })
    Object.defineProperty(exports, 'writeCurrentLockfile', {
      enumerable: true,
      get: function () {
        return write_1.writeCurrentLockfile
      }
    })
    Object.defineProperty(exports, 'writeWantedLockfile', {
      enumerable: true,
      get: function () {
        return write_1.writeWantedLockfile
      }
    })
    Object.defineProperty(exports, 'writeLockfileFile', {
      enumerable: true,
      get: function () {
        return write_1.writeLockfileFile
      }
    })
    const existsWantedLockfile_1 = requireExistsWantedLockfile()
    Object.defineProperty(exports, 'existsNonEmptyWantedLockfile', {
      enumerable: true,
      get: function () {
        return existsWantedLockfile_1.existsNonEmptyWantedLockfile
      }
    })
    const getLockfileImporterId_1 = requireGetLockfileImporterId()
    Object.defineProperty(exports, 'getLockfileImporterId', {
      enumerable: true,
      get: function () {
        return getLockfileImporterId_1.getLockfileImporterId
      }
    })
    __exportStar(requireLib$3(), exports)
    __exportStar(requireRead(), exports)
    const gitBranchLockfile_1 = requireGitBranchLockfile()
    Object.defineProperty(exports, 'cleanGitBranchLockfiles', {
      enumerable: true,
      get: function () {
        return gitBranchLockfile_1.cleanGitBranchLockfiles
      }
    })
    const lockfileFormatConverters_1 = requireLockfileFormatConverters()
    Object.defineProperty(exports, 'convertToLockfileFile', {
      enumerable: true,
      get: function () {
        return lockfileFormatConverters_1.convertToLockfileFile
      }
    })
  })(lib$a)
  return lib$a
}

const libExports = requireLib()

const require$$0 = [
  {
    name: 'nodejs',
    version: '0.2.0',
    date: '2011-08-26',
    lts: false,
    security: false,
    v8: '2.3.8.0'
  },
  {
    name: 'nodejs',
    version: '0.3.0',
    date: '2011-08-26',
    lts: false,
    security: false,
    v8: '2.5.1.0'
  },
  {
    name: 'nodejs',
    version: '0.4.0',
    date: '2011-08-26',
    lts: false,
    security: false,
    v8: '3.1.2.0'
  },
  {
    name: 'nodejs',
    version: '0.5.0',
    date: '2011-08-26',
    lts: false,
    security: false,
    v8: '3.1.8.25'
  },
  {
    name: 'nodejs',
    version: '0.6.0',
    date: '2011-11-04',
    lts: false,
    security: false,
    v8: '3.6.6.6'
  },
  {
    name: 'nodejs',
    version: '0.7.0',
    date: '2012-01-17',
    lts: false,
    security: false,
    v8: '3.8.6.0'
  },
  {
    name: 'nodejs',
    version: '0.8.0',
    date: '2012-06-22',
    lts: false,
    security: false,
    v8: '3.11.10.10'
  },
  {
    name: 'nodejs',
    version: '0.9.0',
    date: '2012-07-20',
    lts: false,
    security: false,
    v8: '3.11.10.15'
  },
  {
    name: 'nodejs',
    version: '0.10.0',
    date: '2013-03-11',
    lts: false,
    security: false,
    v8: '3.14.5.8'
  },
  {
    name: 'nodejs',
    version: '0.11.0',
    date: '2013-03-28',
    lts: false,
    security: false,
    v8: '3.17.13.0'
  },
  {
    name: 'nodejs',
    version: '0.12.0',
    date: '2015-02-06',
    lts: false,
    security: false,
    v8: '3.28.73.0'
  },
  {
    name: 'nodejs',
    version: '4.0.0',
    date: '2015-09-08',
    lts: false,
    security: false,
    v8: '4.5.103.30'
  },
  {
    name: 'nodejs',
    version: '4.1.0',
    date: '2015-09-17',
    lts: false,
    security: false,
    v8: '4.5.103.33'
  },
  {
    name: 'nodejs',
    version: '4.2.0',
    date: '2015-10-12',
    lts: 'Argon',
    security: false,
    v8: '4.5.103.35'
  },
  {
    name: 'nodejs',
    version: '4.3.0',
    date: '2016-02-09',
    lts: 'Argon',
    security: false,
    v8: '4.5.103.35'
  },
  {
    name: 'nodejs',
    version: '4.4.0',
    date: '2016-03-08',
    lts: 'Argon',
    security: false,
    v8: '4.5.103.35'
  },
  {
    name: 'nodejs',
    version: '4.5.0',
    date: '2016-08-16',
    lts: 'Argon',
    security: false,
    v8: '4.5.103.37'
  },
  {
    name: 'nodejs',
    version: '4.6.0',
    date: '2016-09-27',
    lts: 'Argon',
    security: true,
    v8: '4.5.103.37'
  },
  {
    name: 'nodejs',
    version: '4.7.0',
    date: '2016-12-06',
    lts: 'Argon',
    security: false,
    v8: '4.5.103.43'
  },
  {
    name: 'nodejs',
    version: '4.8.0',
    date: '2017-02-21',
    lts: 'Argon',
    security: false,
    v8: '4.5.103.45'
  },
  {
    name: 'nodejs',
    version: '4.9.0',
    date: '2018-03-28',
    lts: 'Argon',
    security: true,
    v8: '4.5.103.53'
  },
  {
    name: 'nodejs',
    version: '5.0.0',
    date: '2015-10-29',
    lts: false,
    security: false,
    v8: '4.6.85.28'
  },
  {
    name: 'nodejs',
    version: '5.1.0',
    date: '2015-11-17',
    lts: false,
    security: false,
    v8: '4.6.85.31'
  },
  {
    name: 'nodejs',
    version: '5.2.0',
    date: '2015-12-09',
    lts: false,
    security: false,
    v8: '4.6.85.31'
  },
  {
    name: 'nodejs',
    version: '5.3.0',
    date: '2015-12-15',
    lts: false,
    security: false,
    v8: '4.6.85.31'
  },
  {
    name: 'nodejs',
    version: '5.4.0',
    date: '2016-01-06',
    lts: false,
    security: false,
    v8: '4.6.85.31'
  },
  {
    name: 'nodejs',
    version: '5.5.0',
    date: '2016-01-21',
    lts: false,
    security: false,
    v8: '4.6.85.31'
  },
  {
    name: 'nodejs',
    version: '5.6.0',
    date: '2016-02-09',
    lts: false,
    security: false,
    v8: '4.6.85.31'
  },
  {
    name: 'nodejs',
    version: '5.7.0',
    date: '2016-02-23',
    lts: false,
    security: false,
    v8: '4.6.85.31'
  },
  {
    name: 'nodejs',
    version: '5.8.0',
    date: '2016-03-09',
    lts: false,
    security: false,
    v8: '4.6.85.31'
  },
  {
    name: 'nodejs',
    version: '5.9.0',
    date: '2016-03-16',
    lts: false,
    security: false,
    v8: '4.6.85.31'
  },
  {
    name: 'nodejs',
    version: '5.10.0',
    date: '2016-04-01',
    lts: false,
    security: false,
    v8: '4.6.85.31'
  },
  {
    name: 'nodejs',
    version: '5.11.0',
    date: '2016-04-21',
    lts: false,
    security: false,
    v8: '4.6.85.31'
  },
  {
    name: 'nodejs',
    version: '5.12.0',
    date: '2016-06-23',
    lts: false,
    security: false,
    v8: '4.6.85.32'
  },
  {
    name: 'nodejs',
    version: '6.0.0',
    date: '2016-04-26',
    lts: false,
    security: false,
    v8: '5.0.71.35'
  },
  {
    name: 'nodejs',
    version: '6.1.0',
    date: '2016-05-05',
    lts: false,
    security: false,
    v8: '5.0.71.35'
  },
  {
    name: 'nodejs',
    version: '6.2.0',
    date: '2016-05-17',
    lts: false,
    security: false,
    v8: '5.0.71.47'
  },
  {
    name: 'nodejs',
    version: '6.3.0',
    date: '2016-07-06',
    lts: false,
    security: false,
    v8: '5.0.71.52'
  },
  {
    name: 'nodejs',
    version: '6.4.0',
    date: '2016-08-12',
    lts: false,
    security: false,
    v8: '5.0.71.60'
  },
  {
    name: 'nodejs',
    version: '6.5.0',
    date: '2016-08-26',
    lts: false,
    security: false,
    v8: '5.1.281.81'
  },
  {
    name: 'nodejs',
    version: '6.6.0',
    date: '2016-09-14',
    lts: false,
    security: false,
    v8: '5.1.281.83'
  },
  {
    name: 'nodejs',
    version: '6.7.0',
    date: '2016-09-27',
    lts: false,
    security: true,
    v8: '5.1.281.83'
  },
  {
    name: 'nodejs',
    version: '6.8.0',
    date: '2016-10-12',
    lts: false,
    security: false,
    v8: '5.1.281.84'
  },
  {
    name: 'nodejs',
    version: '6.9.0',
    date: '2016-10-18',
    lts: 'Boron',
    security: false,
    v8: '5.1.281.84'
  },
  {
    name: 'nodejs',
    version: '6.10.0',
    date: '2017-02-21',
    lts: 'Boron',
    security: false,
    v8: '5.1.281.93'
  },
  {
    name: 'nodejs',
    version: '6.11.0',
    date: '2017-06-06',
    lts: 'Boron',
    security: false,
    v8: '5.1.281.102'
  },
  {
    name: 'nodejs',
    version: '6.12.0',
    date: '2017-11-06',
    lts: 'Boron',
    security: false,
    v8: '5.1.281.108'
  },
  {
    name: 'nodejs',
    version: '6.13.0',
    date: '2018-02-10',
    lts: 'Boron',
    security: false,
    v8: '5.1.281.111'
  },
  {
    name: 'nodejs',
    version: '6.14.0',
    date: '2018-03-28',
    lts: 'Boron',
    security: true,
    v8: '5.1.281.111'
  },
  {
    name: 'nodejs',
    version: '6.15.0',
    date: '2018-11-27',
    lts: 'Boron',
    security: true,
    v8: '5.1.281.111'
  },
  {
    name: 'nodejs',
    version: '6.16.0',
    date: '2018-12-26',
    lts: 'Boron',
    security: false,
    v8: '5.1.281.111'
  },
  {
    name: 'nodejs',
    version: '6.17.0',
    date: '2019-02-28',
    lts: 'Boron',
    security: true,
    v8: '5.1.281.111'
  },
  {
    name: 'nodejs',
    version: '7.0.0',
    date: '2016-10-25',
    lts: false,
    security: false,
    v8: '5.4.500.36'
  },
  {
    name: 'nodejs',
    version: '7.1.0',
    date: '2016-11-08',
    lts: false,
    security: false,
    v8: '5.4.500.36'
  },
  {
    name: 'nodejs',
    version: '7.2.0',
    date: '2016-11-22',
    lts: false,
    security: false,
    v8: '5.4.500.43'
  },
  {
    name: 'nodejs',
    version: '7.3.0',
    date: '2016-12-20',
    lts: false,
    security: false,
    v8: '5.4.500.45'
  },
  {
    name: 'nodejs',
    version: '7.4.0',
    date: '2017-01-04',
    lts: false,
    security: false,
    v8: '5.4.500.45'
  },
  {
    name: 'nodejs',
    version: '7.5.0',
    date: '2017-01-31',
    lts: false,
    security: false,
    v8: '5.4.500.48'
  },
  {
    name: 'nodejs',
    version: '7.6.0',
    date: '2017-02-21',
    lts: false,
    security: false,
    v8: '5.5.372.40'
  },
  {
    name: 'nodejs',
    version: '7.7.0',
    date: '2017-02-28',
    lts: false,
    security: false,
    v8: '5.5.372.41'
  },
  {
    name: 'nodejs',
    version: '7.8.0',
    date: '2017-03-29',
    lts: false,
    security: false,
    v8: '5.5.372.43'
  },
  {
    name: 'nodejs',
    version: '7.9.0',
    date: '2017-04-11',
    lts: false,
    security: false,
    v8: '5.5.372.43'
  },
  {
    name: 'nodejs',
    version: '7.10.0',
    date: '2017-05-02',
    lts: false,
    security: false,
    v8: '5.5.372.43'
  },
  {
    name: 'nodejs',
    version: '8.0.0',
    date: '2017-05-30',
    lts: false,
    security: false,
    v8: '5.8.283.41'
  },
  {
    name: 'nodejs',
    version: '8.1.0',
    date: '2017-06-08',
    lts: false,
    security: false,
    v8: '5.8.283.41'
  },
  {
    name: 'nodejs',
    version: '8.2.0',
    date: '2017-07-19',
    lts: false,
    security: false,
    v8: '5.8.283.41'
  },
  {
    name: 'nodejs',
    version: '8.3.0',
    date: '2017-08-08',
    lts: false,
    security: false,
    v8: '6.0.286.52'
  },
  {
    name: 'nodejs',
    version: '8.4.0',
    date: '2017-08-15',
    lts: false,
    security: false,
    v8: '6.0.286.52'
  },
  {
    name: 'nodejs',
    version: '8.5.0',
    date: '2017-09-12',
    lts: false,
    security: false,
    v8: '6.0.287.53'
  },
  {
    name: 'nodejs',
    version: '8.6.0',
    date: '2017-09-26',
    lts: false,
    security: false,
    v8: '6.0.287.53'
  },
  {
    name: 'nodejs',
    version: '8.7.0',
    date: '2017-10-11',
    lts: false,
    security: false,
    v8: '6.1.534.42'
  },
  {
    name: 'nodejs',
    version: '8.8.0',
    date: '2017-10-24',
    lts: false,
    security: false,
    v8: '6.1.534.42'
  },
  {
    name: 'nodejs',
    version: '8.9.0',
    date: '2017-10-31',
    lts: 'Carbon',
    security: false,
    v8: '6.1.534.46'
  },
  {
    name: 'nodejs',
    version: '8.10.0',
    date: '2018-03-06',
    lts: 'Carbon',
    security: false,
    v8: '6.2.414.50'
  },
  {
    name: 'nodejs',
    version: '8.11.0',
    date: '2018-03-28',
    lts: 'Carbon',
    security: true,
    v8: '6.2.414.50'
  },
  {
    name: 'nodejs',
    version: '8.12.0',
    date: '2018-09-10',
    lts: 'Carbon',
    security: false,
    v8: '6.2.414.66'
  },
  {
    name: 'nodejs',
    version: '8.13.0',
    date: '2018-11-20',
    lts: 'Carbon',
    security: false,
    v8: '6.2.414.72'
  },
  {
    name: 'nodejs',
    version: '8.14.0',
    date: '2018-11-27',
    lts: 'Carbon',
    security: true,
    v8: '6.2.414.72'
  },
  {
    name: 'nodejs',
    version: '8.15.0',
    date: '2018-12-26',
    lts: 'Carbon',
    security: false,
    v8: '6.2.414.75'
  },
  {
    name: 'nodejs',
    version: '8.16.0',
    date: '2019-04-16',
    lts: 'Carbon',
    security: false,
    v8: '6.2.414.77'
  },
  {
    name: 'nodejs',
    version: '8.17.0',
    date: '2019-12-17',
    lts: 'Carbon',
    security: true,
    v8: '6.2.414.78'
  },
  {
    name: 'nodejs',
    version: '9.0.0',
    date: '2017-10-31',
    lts: false,
    security: false,
    v8: '6.2.414.32'
  },
  {
    name: 'nodejs',
    version: '9.1.0',
    date: '2017-11-07',
    lts: false,
    security: false,
    v8: '6.2.414.32'
  },
  {
    name: 'nodejs',
    version: '9.2.0',
    date: '2017-11-14',
    lts: false,
    security: false,
    v8: '6.2.414.44'
  },
  {
    name: 'nodejs',
    version: '9.3.0',
    date: '2017-12-12',
    lts: false,
    security: false,
    v8: '6.2.414.46'
  },
  {
    name: 'nodejs',
    version: '9.4.0',
    date: '2018-01-10',
    lts: false,
    security: false,
    v8: '6.2.414.46'
  },
  {
    name: 'nodejs',
    version: '9.5.0',
    date: '2018-01-31',
    lts: false,
    security: false,
    v8: '6.2.414.46'
  },
  {
    name: 'nodejs',
    version: '9.6.0',
    date: '2018-02-21',
    lts: false,
    security: false,
    v8: '6.2.414.46'
  },
  {
    name: 'nodejs',
    version: '9.7.0',
    date: '2018-03-01',
    lts: false,
    security: false,
    v8: '6.2.414.46'
  },
  {
    name: 'nodejs',
    version: '9.8.0',
    date: '2018-03-07',
    lts: false,
    security: false,
    v8: '6.2.414.46'
  },
  {
    name: 'nodejs',
    version: '9.9.0',
    date: '2018-03-21',
    lts: false,
    security: false,
    v8: '6.2.414.46'
  },
  {
    name: 'nodejs',
    version: '9.10.0',
    date: '2018-03-28',
    lts: false,
    security: true,
    v8: '6.2.414.46'
  },
  {
    name: 'nodejs',
    version: '9.11.0',
    date: '2018-04-04',
    lts: false,
    security: false,
    v8: '6.2.414.46'
  },
  {
    name: 'nodejs',
    version: '10.0.0',
    date: '2018-04-24',
    lts: false,
    security: false,
    v8: '6.6.346.24'
  },
  {
    name: 'nodejs',
    version: '10.1.0',
    date: '2018-05-08',
    lts: false,
    security: false,
    v8: '6.6.346.27'
  },
  {
    name: 'nodejs',
    version: '10.2.0',
    date: '2018-05-23',
    lts: false,
    security: false,
    v8: '6.6.346.32'
  },
  {
    name: 'nodejs',
    version: '10.3.0',
    date: '2018-05-29',
    lts: false,
    security: false,
    v8: '6.6.346.32'
  },
  {
    name: 'nodejs',
    version: '10.4.0',
    date: '2018-06-06',
    lts: false,
    security: false,
    v8: '6.7.288.43'
  },
  {
    name: 'nodejs',
    version: '10.5.0',
    date: '2018-06-20',
    lts: false,
    security: false,
    v8: '6.7.288.46'
  },
  {
    name: 'nodejs',
    version: '10.6.0',
    date: '2018-07-04',
    lts: false,
    security: false,
    v8: '6.7.288.46'
  },
  {
    name: 'nodejs',
    version: '10.7.0',
    date: '2018-07-18',
    lts: false,
    security: false,
    v8: '6.7.288.49'
  },
  {
    name: 'nodejs',
    version: '10.8.0',
    date: '2018-08-01',
    lts: false,
    security: false,
    v8: '6.7.288.49'
  },
  {
    name: 'nodejs',
    version: '10.9.0',
    date: '2018-08-15',
    lts: false,
    security: false,
    v8: '6.8.275.24'
  },
  {
    name: 'nodejs',
    version: '10.10.0',
    date: '2018-09-06',
    lts: false,
    security: false,
    v8: '6.8.275.30'
  },
  {
    name: 'nodejs',
    version: '10.11.0',
    date: '2018-09-19',
    lts: false,
    security: false,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.12.0',
    date: '2018-10-10',
    lts: false,
    security: false,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.13.0',
    date: '2018-10-30',
    lts: 'Dubnium',
    security: false,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.14.0',
    date: '2018-11-27',
    lts: 'Dubnium',
    security: true,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.15.0',
    date: '2018-12-26',
    lts: 'Dubnium',
    security: false,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.16.0',
    date: '2019-05-28',
    lts: 'Dubnium',
    security: false,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.17.0',
    date: '2019-10-22',
    lts: 'Dubnium',
    security: false,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.18.0',
    date: '2019-12-17',
    lts: 'Dubnium',
    security: true,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.19.0',
    date: '2020-02-05',
    lts: 'Dubnium',
    security: true,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.20.0',
    date: '2020-03-26',
    lts: 'Dubnium',
    security: false,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.21.0',
    date: '2020-06-02',
    lts: 'Dubnium',
    security: true,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.22.0',
    date: '2020-07-21',
    lts: 'Dubnium',
    security: false,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.23.0',
    date: '2020-10-27',
    lts: 'Dubnium',
    security: false,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '10.24.0',
    date: '2021-02-23',
    lts: 'Dubnium',
    security: true,
    v8: '6.8.275.32'
  },
  {
    name: 'nodejs',
    version: '11.0.0',
    date: '2018-10-23',
    lts: false,
    security: false,
    v8: '7.0.276.28'
  },
  {
    name: 'nodejs',
    version: '11.1.0',
    date: '2018-10-30',
    lts: false,
    security: false,
    v8: '7.0.276.32'
  },
  {
    name: 'nodejs',
    version: '11.2.0',
    date: '2018-11-15',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.3.0',
    date: '2018-11-27',
    lts: false,
    security: true,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.4.0',
    date: '2018-12-07',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.5.0',
    date: '2018-12-18',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.6.0',
    date: '2018-12-26',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.7.0',
    date: '2019-01-17',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.8.0',
    date: '2019-01-24',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.9.0',
    date: '2019-01-30',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.10.0',
    date: '2019-02-14',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.11.0',
    date: '2019-03-05',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.12.0',
    date: '2019-03-14',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.13.0',
    date: '2019-03-28',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.14.0',
    date: '2019-04-10',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '11.15.0',
    date: '2019-04-30',
    lts: false,
    security: false,
    v8: '7.0.276.38'
  },
  {
    name: 'nodejs',
    version: '12.0.0',
    date: '2019-04-23',
    lts: false,
    security: false,
    v8: '7.4.288.21'
  },
  {
    name: 'nodejs',
    version: '12.1.0',
    date: '2019-04-29',
    lts: false,
    security: false,
    v8: '7.4.288.21'
  },
  {
    name: 'nodejs',
    version: '12.2.0',
    date: '2019-05-07',
    lts: false,
    security: false,
    v8: '7.4.288.21'
  },
  {
    name: 'nodejs',
    version: '12.3.0',
    date: '2019-05-21',
    lts: false,
    security: false,
    v8: '7.4.288.27'
  },
  {
    name: 'nodejs',
    version: '12.4.0',
    date: '2019-06-04',
    lts: false,
    security: false,
    v8: '7.4.288.27'
  },
  {
    name: 'nodejs',
    version: '12.5.0',
    date: '2019-06-26',
    lts: false,
    security: false,
    v8: '7.5.288.22'
  },
  {
    name: 'nodejs',
    version: '12.6.0',
    date: '2019-07-03',
    lts: false,
    security: false,
    v8: '7.5.288.22'
  },
  {
    name: 'nodejs',
    version: '12.7.0',
    date: '2019-07-23',
    lts: false,
    security: false,
    v8: '7.5.288.22'
  },
  {
    name: 'nodejs',
    version: '12.8.0',
    date: '2019-08-06',
    lts: false,
    security: false,
    v8: '7.5.288.22'
  },
  {
    name: 'nodejs',
    version: '12.9.0',
    date: '2019-08-20',
    lts: false,
    security: false,
    v8: '7.6.303.29'
  },
  {
    name: 'nodejs',
    version: '12.10.0',
    date: '2019-09-04',
    lts: false,
    security: false,
    v8: '7.6.303.29'
  },
  {
    name: 'nodejs',
    version: '12.11.0',
    date: '2019-09-25',
    lts: false,
    security: false,
    v8: '7.7.299.11'
  },
  {
    name: 'nodejs',
    version: '12.12.0',
    date: '2019-10-11',
    lts: false,
    security: false,
    v8: '7.7.299.13'
  },
  {
    name: 'nodejs',
    version: '12.13.0',
    date: '2019-10-21',
    lts: 'Erbium',
    security: false,
    v8: '7.7.299.13'
  },
  {
    name: 'nodejs',
    version: '12.14.0',
    date: '2019-12-17',
    lts: 'Erbium',
    security: true,
    v8: '7.7.299.13'
  },
  {
    name: 'nodejs',
    version: '12.15.0',
    date: '2020-02-05',
    lts: 'Erbium',
    security: true,
    v8: '7.7.299.13'
  },
  {
    name: 'nodejs',
    version: '12.16.0',
    date: '2020-02-11',
    lts: 'Erbium',
    security: false,
    v8: '7.8.279.23'
  },
  {
    name: 'nodejs',
    version: '12.17.0',
    date: '2020-05-26',
    lts: 'Erbium',
    security: false,
    v8: '7.8.279.23'
  },
  {
    name: 'nodejs',
    version: '12.18.0',
    date: '2020-06-02',
    lts: 'Erbium',
    security: true,
    v8: '7.8.279.23'
  },
  {
    name: 'nodejs',
    version: '12.19.0',
    date: '2020-10-06',
    lts: 'Erbium',
    security: false,
    v8: '7.8.279.23'
  },
  {
    name: 'nodejs',
    version: '12.20.0',
    date: '2020-11-24',
    lts: 'Erbium',
    security: false,
    v8: '7.8.279.23'
  },
  {
    name: 'nodejs',
    version: '12.21.0',
    date: '2021-02-23',
    lts: 'Erbium',
    security: true,
    v8: '7.8.279.23'
  },
  {
    name: 'nodejs',
    version: '12.22.0',
    date: '2021-03-30',
    lts: 'Erbium',
    security: false,
    v8: '7.8.279.23'
  },
  {
    name: 'nodejs',
    version: '13.0.0',
    date: '2019-10-22',
    lts: false,
    security: false,
    v8: '7.8.279.17'
  },
  {
    name: 'nodejs',
    version: '13.1.0',
    date: '2019-11-05',
    lts: false,
    security: false,
    v8: '7.8.279.17'
  },
  {
    name: 'nodejs',
    version: '13.2.0',
    date: '2019-11-21',
    lts: false,
    security: false,
    v8: '7.9.317.23'
  },
  {
    name: 'nodejs',
    version: '13.3.0',
    date: '2019-12-03',
    lts: false,
    security: false,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '13.4.0',
    date: '2019-12-17',
    lts: false,
    security: true,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '13.5.0',
    date: '2019-12-18',
    lts: false,
    security: false,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '13.6.0',
    date: '2020-01-07',
    lts: false,
    security: false,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '13.7.0',
    date: '2020-01-21',
    lts: false,
    security: false,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '13.8.0',
    date: '2020-02-05',
    lts: false,
    security: true,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '13.9.0',
    date: '2020-02-18',
    lts: false,
    security: false,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '13.10.0',
    date: '2020-03-04',
    lts: false,
    security: false,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '13.11.0',
    date: '2020-03-12',
    lts: false,
    security: false,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '13.12.0',
    date: '2020-03-26',
    lts: false,
    security: false,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '13.13.0',
    date: '2020-04-14',
    lts: false,
    security: false,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '13.14.0',
    date: '2020-04-29',
    lts: false,
    security: false,
    v8: '7.9.317.25'
  },
  {
    name: 'nodejs',
    version: '14.0.0',
    date: '2020-04-21',
    lts: false,
    security: false,
    v8: '8.1.307.30'
  },
  {
    name: 'nodejs',
    version: '14.1.0',
    date: '2020-04-29',
    lts: false,
    security: false,
    v8: '8.1.307.31'
  },
  {
    name: 'nodejs',
    version: '14.2.0',
    date: '2020-05-05',
    lts: false,
    security: false,
    v8: '8.1.307.31'
  },
  {
    name: 'nodejs',
    version: '14.3.0',
    date: '2020-05-19',
    lts: false,
    security: false,
    v8: '8.1.307.31'
  },
  {
    name: 'nodejs',
    version: '14.4.0',
    date: '2020-06-02',
    lts: false,
    security: true,
    v8: '8.1.307.31'
  },
  {
    name: 'nodejs',
    version: '14.5.0',
    date: '2020-06-30',
    lts: false,
    security: false,
    v8: '8.3.110.9'
  },
  {
    name: 'nodejs',
    version: '14.6.0',
    date: '2020-07-20',
    lts: false,
    security: false,
    v8: '8.4.371.19'
  },
  {
    name: 'nodejs',
    version: '14.7.0',
    date: '2020-07-29',
    lts: false,
    security: false,
    v8: '8.4.371.19'
  },
  {
    name: 'nodejs',
    version: '14.8.0',
    date: '2020-08-11',
    lts: false,
    security: false,
    v8: '8.4.371.19'
  },
  {
    name: 'nodejs',
    version: '14.9.0',
    date: '2020-08-27',
    lts: false,
    security: false,
    v8: '8.4.371.19'
  },
  {
    name: 'nodejs',
    version: '14.10.0',
    date: '2020-09-08',
    lts: false,
    security: false,
    v8: '8.4.371.19'
  },
  {
    name: 'nodejs',
    version: '14.11.0',
    date: '2020-09-15',
    lts: false,
    security: true,
    v8: '8.4.371.19'
  },
  {
    name: 'nodejs',
    version: '14.12.0',
    date: '2020-09-22',
    lts: false,
    security: false,
    v8: '8.4.371.19'
  },
  {
    name: 'nodejs',
    version: '14.13.0',
    date: '2020-09-29',
    lts: false,
    security: false,
    v8: '8.4.371.19'
  },
  {
    name: 'nodejs',
    version: '14.14.0',
    date: '2020-10-15',
    lts: false,
    security: false,
    v8: '8.4.371.19'
  },
  {
    name: 'nodejs',
    version: '14.15.0',
    date: '2020-10-27',
    lts: 'Fermium',
    security: false,
    v8: '8.4.371.19'
  },
  {
    name: 'nodejs',
    version: '14.16.0',
    date: '2021-02-23',
    lts: 'Fermium',
    security: true,
    v8: '8.4.371.19'
  },
  {
    name: 'nodejs',
    version: '14.17.0',
    date: '2021-05-11',
    lts: 'Fermium',
    security: false,
    v8: '8.4.371.23'
  },
  {
    name: 'nodejs',
    version: '14.18.0',
    date: '2021-09-28',
    lts: 'Fermium',
    security: false,
    v8: '8.4.371.23'
  },
  {
    name: 'nodejs',
    version: '14.19.0',
    date: '2022-02-01',
    lts: 'Fermium',
    security: false,
    v8: '8.4.371.23'
  },
  {
    name: 'nodejs',
    version: '14.20.0',
    date: '2022-07-07',
    lts: 'Fermium',
    security: true,
    v8: '8.4.371.23'
  },
  {
    name: 'nodejs',
    version: '14.21.0',
    date: '2022-11-01',
    lts: 'Fermium',
    security: false,
    v8: '8.4.371.23'
  },
  {
    name: 'nodejs',
    version: '15.0.0',
    date: '2020-10-20',
    lts: false,
    security: false,
    v8: '8.6.395.16'
  },
  {
    name: 'nodejs',
    version: '15.1.0',
    date: '2020-11-04',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.2.0',
    date: '2020-11-10',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.3.0',
    date: '2020-11-24',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.4.0',
    date: '2020-12-09',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.5.0',
    date: '2020-12-22',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.6.0',
    date: '2021-01-14',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.7.0',
    date: '2021-01-25',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.8.0',
    date: '2021-02-02',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.9.0',
    date: '2021-02-18',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.10.0',
    date: '2021-02-23',
    lts: false,
    security: true,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.11.0',
    date: '2021-03-03',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.12.0',
    date: '2021-03-17',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.13.0',
    date: '2021-03-31',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '15.14.0',
    date: '2021-04-06',
    lts: false,
    security: false,
    v8: '8.6.395.17'
  },
  {
    name: 'nodejs',
    version: '16.0.0',
    date: '2021-04-20',
    lts: false,
    security: false,
    v8: '9.0.257.17'
  },
  {
    name: 'nodejs',
    version: '16.1.0',
    date: '2021-05-04',
    lts: false,
    security: false,
    v8: '9.0.257.24'
  },
  {
    name: 'nodejs',
    version: '16.2.0',
    date: '2021-05-19',
    lts: false,
    security: false,
    v8: '9.0.257.25'
  },
  {
    name: 'nodejs',
    version: '16.3.0',
    date: '2021-06-03',
    lts: false,
    security: false,
    v8: '9.0.257.25'
  },
  {
    name: 'nodejs',
    version: '16.4.0',
    date: '2021-06-23',
    lts: false,
    security: false,
    v8: '9.1.269.36'
  },
  {
    name: 'nodejs',
    version: '16.5.0',
    date: '2021-07-14',
    lts: false,
    security: false,
    v8: '9.1.269.38'
  },
  {
    name: 'nodejs',
    version: '16.6.0',
    date: '2021-07-29',
    lts: false,
    security: true,
    v8: '9.2.230.21'
  },
  {
    name: 'nodejs',
    version: '16.7.0',
    date: '2021-08-18',
    lts: false,
    security: false,
    v8: '9.2.230.21'
  },
  {
    name: 'nodejs',
    version: '16.8.0',
    date: '2021-08-25',
    lts: false,
    security: false,
    v8: '9.2.230.21'
  },
  {
    name: 'nodejs',
    version: '16.9.0',
    date: '2021-09-07',
    lts: false,
    security: false,
    v8: '9.3.345.16'
  },
  {
    name: 'nodejs',
    version: '16.10.0',
    date: '2021-09-22',
    lts: false,
    security: false,
    v8: '9.3.345.19'
  },
  {
    name: 'nodejs',
    version: '16.11.0',
    date: '2021-10-08',
    lts: false,
    security: false,
    v8: '9.4.146.19'
  },
  {
    name: 'nodejs',
    version: '16.12.0',
    date: '2021-10-20',
    lts: false,
    security: false,
    v8: '9.4.146.19'
  },
  {
    name: 'nodejs',
    version: '16.13.0',
    date: '2021-10-26',
    lts: 'Gallium',
    security: false,
    v8: '9.4.146.19'
  },
  {
    name: 'nodejs',
    version: '16.14.0',
    date: '2022-02-08',
    lts: 'Gallium',
    security: false,
    v8: '9.4.146.24'
  },
  {
    name: 'nodejs',
    version: '16.15.0',
    date: '2022-04-26',
    lts: 'Gallium',
    security: false,
    v8: '9.4.146.24'
  },
  {
    name: 'nodejs',
    version: '16.16.0',
    date: '2022-07-07',
    lts: 'Gallium',
    security: true,
    v8: '9.4.146.24'
  },
  {
    name: 'nodejs',
    version: '16.17.0',
    date: '2022-08-16',
    lts: 'Gallium',
    security: false,
    v8: '9.4.146.26'
  },
  {
    name: 'nodejs',
    version: '16.18.0',
    date: '2022-10-12',
    lts: 'Gallium',
    security: false,
    v8: '9.4.146.26'
  },
  {
    name: 'nodejs',
    version: '16.19.0',
    date: '2022-12-13',
    lts: 'Gallium',
    security: false,
    v8: '9.4.146.26'
  },
  {
    name: 'nodejs',
    version: '16.20.0',
    date: '2023-03-28',
    lts: 'Gallium',
    security: false,
    v8: '9.4.146.26'
  },
  {
    name: 'nodejs',
    version: '17.0.0',
    date: '2021-10-19',
    lts: false,
    security: false,
    v8: '9.5.172.21'
  },
  {
    name: 'nodejs',
    version: '17.1.0',
    date: '2021-11-09',
    lts: false,
    security: false,
    v8: '9.5.172.25'
  },
  {
    name: 'nodejs',
    version: '17.2.0',
    date: '2021-11-30',
    lts: false,
    security: false,
    v8: '9.6.180.14'
  },
  {
    name: 'nodejs',
    version: '17.3.0',
    date: '2021-12-17',
    lts: false,
    security: false,
    v8: '9.6.180.15'
  },
  {
    name: 'nodejs',
    version: '17.4.0',
    date: '2022-01-18',
    lts: false,
    security: false,
    v8: '9.6.180.15'
  },
  {
    name: 'nodejs',
    version: '17.5.0',
    date: '2022-02-10',
    lts: false,
    security: false,
    v8: '9.6.180.15'
  },
  {
    name: 'nodejs',
    version: '17.6.0',
    date: '2022-02-22',
    lts: false,
    security: false,
    v8: '9.6.180.15'
  },
  {
    name: 'nodejs',
    version: '17.7.0',
    date: '2022-03-09',
    lts: false,
    security: false,
    v8: '9.6.180.15'
  },
  {
    name: 'nodejs',
    version: '17.8.0',
    date: '2022-03-22',
    lts: false,
    security: false,
    v8: '9.6.180.15'
  },
  {
    name: 'nodejs',
    version: '17.9.0',
    date: '2022-04-07',
    lts: false,
    security: false,
    v8: '9.6.180.15'
  },
  {
    name: 'nodejs',
    version: '18.0.0',
    date: '2022-04-18',
    lts: false,
    security: false,
    v8: '10.1.124.8'
  },
  {
    name: 'nodejs',
    version: '18.1.0',
    date: '2022-05-03',
    lts: false,
    security: false,
    v8: '10.1.124.8'
  },
  {
    name: 'nodejs',
    version: '18.2.0',
    date: '2022-05-17',
    lts: false,
    security: false,
    v8: '10.1.124.8'
  },
  {
    name: 'nodejs',
    version: '18.3.0',
    date: '2022-06-02',
    lts: false,
    security: false,
    v8: '10.2.154.4'
  },
  {
    name: 'nodejs',
    version: '18.4.0',
    date: '2022-06-16',
    lts: false,
    security: false,
    v8: '10.2.154.4'
  },
  {
    name: 'nodejs',
    version: '18.5.0',
    date: '2022-07-06',
    lts: false,
    security: true,
    v8: '10.2.154.4'
  },
  {
    name: 'nodejs',
    version: '18.6.0',
    date: '2022-07-13',
    lts: false,
    security: false,
    v8: '10.2.154.13'
  },
  {
    name: 'nodejs',
    version: '18.7.0',
    date: '2022-07-26',
    lts: false,
    security: false,
    v8: '10.2.154.13'
  },
  {
    name: 'nodejs',
    version: '18.8.0',
    date: '2022-08-24',
    lts: false,
    security: false,
    v8: '10.2.154.13'
  },
  {
    name: 'nodejs',
    version: '18.9.0',
    date: '2022-09-07',
    lts: false,
    security: false,
    v8: '10.2.154.15'
  },
  {
    name: 'nodejs',
    version: '18.10.0',
    date: '2022-09-28',
    lts: false,
    security: false,
    v8: '10.2.154.15'
  },
  {
    name: 'nodejs',
    version: '18.11.0',
    date: '2022-10-13',
    lts: false,
    security: false,
    v8: '10.2.154.15'
  },
  {
    name: 'nodejs',
    version: '18.12.0',
    date: '2022-10-25',
    lts: 'Hydrogen',
    security: false,
    v8: '10.2.154.15'
  },
  {
    name: 'nodejs',
    version: '18.13.0',
    date: '2023-01-05',
    lts: 'Hydrogen',
    security: false,
    v8: '10.2.154.23'
  },
  {
    name: 'nodejs',
    version: '18.14.0',
    date: '2023-02-01',
    lts: 'Hydrogen',
    security: false,
    v8: '10.2.154.23'
  },
  {
    name: 'nodejs',
    version: '18.15.0',
    date: '2023-03-05',
    lts: 'Hydrogen',
    security: false,
    v8: '10.2.154.26'
  },
  {
    name: 'nodejs',
    version: '18.16.0',
    date: '2023-04-12',
    lts: 'Hydrogen',
    security: false,
    v8: '10.2.154.26'
  },
  {
    name: 'nodejs',
    version: '18.17.0',
    date: '2023-07-18',
    lts: 'Hydrogen',
    security: false,
    v8: '10.2.154.26'
  },
  {
    name: 'nodejs',
    version: '18.18.0',
    date: '2023-09-18',
    lts: 'Hydrogen',
    security: false,
    v8: '10.2.154.26'
  },
  {
    name: 'nodejs',
    version: '18.19.0',
    date: '2023-11-29',
    lts: 'Hydrogen',
    security: false,
    v8: '10.2.154.26'
  },
  {
    name: 'nodejs',
    version: '18.20.0',
    date: '2024-03-26',
    lts: 'Hydrogen',
    security: false,
    v8: '10.2.154.26'
  },
  {
    name: 'nodejs',
    version: '19.0.0',
    date: '2022-10-17',
    lts: false,
    security: false,
    v8: '10.7.193.13'
  },
  {
    name: 'nodejs',
    version: '19.1.0',
    date: '2022-11-14',
    lts: false,
    security: false,
    v8: '10.7.193.20'
  },
  {
    name: 'nodejs',
    version: '19.2.0',
    date: '2022-11-29',
    lts: false,
    security: false,
    v8: '10.8.168.20'
  },
  {
    name: 'nodejs',
    version: '19.3.0',
    date: '2022-12-14',
    lts: false,
    security: false,
    v8: '10.8.168.21'
  },
  {
    name: 'nodejs',
    version: '19.4.0',
    date: '2023-01-05',
    lts: false,
    security: false,
    v8: '10.8.168.25'
  },
  {
    name: 'nodejs',
    version: '19.5.0',
    date: '2023-01-24',
    lts: false,
    security: false,
    v8: '10.8.168.25'
  },
  {
    name: 'nodejs',
    version: '19.6.0',
    date: '2023-02-01',
    lts: false,
    security: false,
    v8: '10.8.168.25'
  },
  {
    name: 'nodejs',
    version: '19.7.0',
    date: '2023-02-21',
    lts: false,
    security: false,
    v8: '10.8.168.25'
  },
  {
    name: 'nodejs',
    version: '19.8.0',
    date: '2023-03-14',
    lts: false,
    security: false,
    v8: '10.8.168.25'
  },
  {
    name: 'nodejs',
    version: '19.9.0',
    date: '2023-04-10',
    lts: false,
    security: false,
    v8: '10.8.168.25'
  },
  {
    name: 'nodejs',
    version: '20.0.0',
    date: '2023-04-17',
    lts: false,
    security: false,
    v8: '11.3.244.4'
  },
  {
    name: 'nodejs',
    version: '20.1.0',
    date: '2023-05-03',
    lts: false,
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.2.0',
    date: '2023-05-16',
    lts: false,
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.3.0',
    date: '2023-06-08',
    lts: false,
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.4.0',
    date: '2023-07-04',
    lts: false,
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.5.0',
    date: '2023-07-19',
    lts: false,
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.6.0',
    date: '2023-08-23',
    lts: false,
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.7.0',
    date: '2023-09-18',
    lts: false,
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.8.0',
    date: '2023-09-28',
    lts: false,
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.9.0',
    date: '2023-10-24',
    lts: 'Iron',
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.10.0',
    date: '2023-11-22',
    lts: 'Iron',
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.11.0',
    date: '2024-01-09',
    lts: 'Iron',
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.12.0',
    date: '2024-03-26',
    lts: 'Iron',
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.13.0',
    date: '2024-05-07',
    lts: 'Iron',
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.14.0',
    date: '2024-05-28',
    lts: 'Iron',
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.15.0',
    date: '2024-06-20',
    lts: 'Iron',
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.16.0',
    date: '2024-07-24',
    lts: 'Iron',
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.17.0',
    date: '2024-08-21',
    lts: 'Iron',
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '20.18.0',
    date: '2024-10-03',
    lts: 'Iron',
    security: false,
    v8: '11.3.244.8'
  },
  {
    name: 'nodejs',
    version: '21.0.0',
    date: '2023-10-17',
    lts: false,
    security: false,
    v8: '11.8.172.13'
  },
  {
    name: 'nodejs',
    version: '21.1.0',
    date: '2023-10-24',
    lts: false,
    security: false,
    v8: '11.8.172.15'
  },
  {
    name: 'nodejs',
    version: '21.2.0',
    date: '2023-11-14',
    lts: false,
    security: false,
    v8: '11.8.172.17'
  },
  {
    name: 'nodejs',
    version: '21.3.0',
    date: '2023-11-30',
    lts: false,
    security: false,
    v8: '11.8.172.17'
  },
  {
    name: 'nodejs',
    version: '21.4.0',
    date: '2023-12-05',
    lts: false,
    security: false,
    v8: '11.8.172.17'
  },
  {
    name: 'nodejs',
    version: '21.5.0',
    date: '2023-12-19',
    lts: false,
    security: false,
    v8: '11.8.172.17'
  },
  {
    name: 'nodejs',
    version: '21.6.0',
    date: '2024-01-14',
    lts: false,
    security: false,
    v8: '11.8.172.17'
  },
  {
    name: 'nodejs',
    version: '21.7.0',
    date: '2024-03-06',
    lts: false,
    security: false,
    v8: '11.8.172.17'
  },
  {
    name: 'nodejs',
    version: '22.0.0',
    date: '2024-04-24',
    lts: false,
    security: false,
    v8: '12.4.254.14'
  },
  {
    name: 'nodejs',
    version: '22.1.0',
    date: '2024-05-02',
    lts: false,
    security: false,
    v8: '12.4.254.14'
  },
  {
    name: 'nodejs',
    version: '22.2.0',
    date: '2024-05-15',
    lts: false,
    security: false,
    v8: '12.4.254.14'
  },
  {
    name: 'nodejs',
    version: '22.3.0',
    date: '2024-06-11',
    lts: false,
    security: false,
    v8: '12.4.254.20'
  },
  {
    name: 'nodejs',
    version: '22.4.0',
    date: '2024-07-02',
    lts: false,
    security: false,
    v8: '12.4.254.21'
  },
  {
    name: 'nodejs',
    version: '22.5.0',
    date: '2024-07-17',
    lts: false,
    security: false,
    v8: '12.4.254.21'
  },
  {
    name: 'nodejs',
    version: '22.6.0',
    date: '2024-08-06',
    lts: false,
    security: false,
    v8: '12.4.254.21'
  },
  {
    name: 'nodejs',
    version: '22.7.0',
    date: '2024-08-21',
    lts: false,
    security: false,
    v8: '12.4.254.21'
  },
  {
    name: 'nodejs',
    version: '22.8.0',
    date: '2024-09-03',
    lts: false,
    security: false,
    v8: '12.4.254.21'
  },
  {
    name: 'nodejs',
    version: '22.9.0',
    date: '2024-09-17',
    lts: false,
    security: false,
    v8: '12.4.254.21'
  },
  {
    name: 'nodejs',
    version: '22.10.0',
    date: '2024-10-16',
    lts: false,
    security: false,
    v8: '12.4.254.21'
  },
  {
    name: 'nodejs',
    version: '22.11.0',
    date: '2024-10-29',
    lts: 'Jod',
    security: false,
    v8: '12.4.254.21'
  },
  {
    name: 'nodejs',
    version: '22.12.0',
    date: '2024-12-02',
    lts: 'Jod',
    security: false,
    v8: '12.4.254.21'
  },
  {
    name: 'nodejs',
    version: '23.0.0',
    date: '2024-10-16',
    lts: false,
    security: false,
    v8: '12.9.202.26'
  },
  {
    name: 'nodejs',
    version: '23.1.0',
    date: '2024-10-24',
    lts: false,
    security: false,
    v8: '12.9.202.28'
  },
  {
    name: 'nodejs',
    version: '23.2.0',
    date: '2024-11-11',
    lts: false,
    security: false,
    v8: '12.9.202.28'
  },
  {
    name: 'nodejs',
    version: '23.3.0',
    date: '2024-11-20',
    lts: false,
    security: false,
    v8: '12.9.202.28'
  }
]

const agents$1 = {}

const browsers$1 = {}

let browsers
let hasRequiredBrowsers$1
function requireBrowsers$1() {
  if (hasRequiredBrowsers$1) {
    return browsers
  }
  hasRequiredBrowsers$1 = 1
  browsers = {
    A: 'ie',
    B: 'edge',
    C: 'firefox',
    D: 'chrome',
    E: 'safari',
    F: 'opera',
    G: 'ios_saf',
    H: 'op_mini',
    I: 'android',
    J: 'bb',
    K: 'op_mob',
    L: 'and_chr',
    M: 'and_ff',
    N: 'ie_mob',
    O: 'and_uc',
    P: 'samsung',
    Q: 'and_qq',
    R: 'baidu',
    S: 'kaios'
  }
  return browsers
}

let hasRequiredBrowsers
function requireBrowsers() {
  if (hasRequiredBrowsers) {
    return browsers$1
  }
  hasRequiredBrowsers = 1
  browsers$1.browsers = requireBrowsers$1()
  return browsers$1
}

const browserVersions$1 = {}

let browserVersions
let hasRequiredBrowserVersions$1
function requireBrowserVersions$1() {
  if (hasRequiredBrowserVersions$1) {
    return browserVersions
  }
  hasRequiredBrowserVersions$1 = 1
  browserVersions = {
    0: '117',
    1: '20',
    2: '21',
    3: '22',
    4: '23',
    5: '24',
    6: '25',
    7: '26',
    8: '27',
    9: '118',
    A: '10',
    B: '11',
    C: '12',
    D: '7',
    E: '8',
    F: '9',
    G: '15',
    H: '80',
    I: '135',
    J: '4',
    K: '6',
    L: '13',
    M: '14',
    N: '16',
    O: '17',
    P: '18',
    Q: '79',
    R: '81',
    S: '83',
    T: '84',
    U: '85',
    V: '86',
    W: '87',
    X: '88',
    Y: '89',
    Z: '90',
    a: '91',
    b: '92',
    c: '93',
    d: '94',
    e: '95',
    f: '96',
    g: '97',
    h: '98',
    i: '99',
    j: '100',
    k: '101',
    l: '102',
    m: '103',
    n: '104',
    o: '105',
    p: '106',
    q: '107',
    r: '108',
    s: '109',
    t: '110',
    u: '111',
    v: '112',
    w: '113',
    x: '114',
    y: '115',
    z: '116',
    AB: '119',
    BB: '120',
    CB: '121',
    DB: '122',
    EB: '123',
    FB: '124',
    GB: '125',
    HB: '126',
    IB: '127',
    JB: '128',
    KB: '129',
    LB: '130',
    MB: '131',
    NB: '132',
    OB: '133',
    PB: '134',
    QB: '136',
    RB: '5',
    SB: '19',
    TB: '28',
    UB: '29',
    VB: '30',
    WB: '31',
    XB: '32',
    YB: '33',
    ZB: '34',
    aB: '35',
    bB: '36',
    cB: '37',
    dB: '38',
    eB: '39',
    fB: '40',
    gB: '41',
    hB: '42',
    iB: '43',
    jB: '44',
    kB: '45',
    lB: '46',
    mB: '47',
    nB: '48',
    oB: '49',
    pB: '50',
    qB: '51',
    rB: '52',
    sB: '53',
    tB: '54',
    uB: '55',
    vB: '56',
    wB: '57',
    xB: '58',
    yB: '60',
    zB: '62',
    '0B': '63',
    '1B': '64',
    '2B': '65',
    '3B': '66',
    '4B': '67',
    '5B': '68',
    '6B': '69',
    '7B': '70',
    '8B': '71',
    '9B': '72',
    AC: '73',
    BC: '74',
    CC: '75',
    DC: '76',
    EC: '77',
    FC: '78',
    GC: '137',
    HC: '11.1',
    IC: '12.1',
    JC: '15.5',
    KC: '16.0',
    LC: '17.0',
    MC: '18.0',
    NC: '3',
    OC: '59',
    PC: '61',
    QC: '82',
    RC: '138',
    SC: '139',
    TC: '3.2',
    UC: '10.1',
    VC: '15.2-15.3',
    WC: '15.4',
    XC: '16.1',
    YC: '16.2',
    ZC: '16.3',
    aC: '16.4',
    bC: '16.5',
    cC: '17.1',
    dC: '17.2',
    eC: '17.3',
    fC: '17.4',
    gC: '17.5',
    hC: '18.1',
    iC: '18.2',
    jC: '18.3',
    kC: '18.4',
    lC: '18.5',
    mC: '11.5',
    nC: '4.2-4.3',
    oC: '5.5',
    pC: '2',
    qC: '140',
    rC: '141',
    sC: '3.5',
    tC: '3.6',
    uC: '3.1',
    vC: '5.1',
    wC: '6.1',
    xC: '7.1',
    yC: '9.1',
    zC: '13.1',
    '0C': '14.1',
    '1C': '15.1',
    '2C': '15.6',
    '3C': '16.6',
    '4C': '17.6',
    '5C': 'TP',
    '6C': '9.5-9.6',
    '7C': '10.0-10.1',
    '8C': '10.5',
    '9C': '10.6',
    AD: '11.6',
    BD: '4.0-4.1',
    CD: '5.0-5.1',
    DD: '6.0-6.1',
    ED: '7.0-7.1',
    FD: '8.1-8.4',
    GD: '9.0-9.2',
    HD: '9.3',
    ID: '10.0-10.2',
    JD: '10.3',
    KD: '11.0-11.2',
    LD: '11.3-11.4',
    MD: '12.0-12.1',
    ND: '12.2-12.5',
    OD: '13.0-13.1',
    PD: '13.2',
    QD: '13.3',
    RD: '13.4-13.7',
    SD: '14.0-14.4',
    TD: '14.5-14.8',
    UD: '15.0-15.1',
    VD: '15.6-15.8',
    WD: '16.6-16.7',
    XD: '17.6-17.7',
    YD: 'all',
    ZD: '2.1',
    aD: '2.2',
    bD: '2.3',
    cD: '4.1',
    dD: '4.4',
    eD: '4.4.3-4.4.4',
    fD: '5.0-5.4',
    gD: '6.2-6.4',
    hD: '7.2-7.4',
    iD: '8.2',
    jD: '9.2',
    kD: '11.1-11.2',
    lD: '12.0',
    mD: '13.0',
    nD: '14.0',
    oD: '15.0',
    pD: '19.0',
    qD: '14.9',
    rD: '13.52',
    sD: '2.5',
    tD: '3.0-3.1'
  }
  return browserVersions
}

let hasRequiredBrowserVersions
function requireBrowserVersions() {
  if (hasRequiredBrowserVersions) {
    return browserVersions$1
  }
  hasRequiredBrowserVersions = 1
  browserVersions$1.browserVersions = requireBrowserVersions$1()
  return browserVersions$1
}

let agents
let hasRequiredAgents$1
function requireAgents$1() {
  if (hasRequiredAgents$1) {
    return agents
  }
  hasRequiredAgents$1 = 1
  agents = {
    A: {
      A: {
        K: 0,
        D: 0,
        E: 0,
        F: 0.0324821,
        A: 0,
        B: 0.438508,
        oC: 0
      },
      B: 'ms',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'oC',
        'K',
        'D',
        'E',
        'F',
        'A',
        'B',
        '',
        '',
        ''
      ],
      E: 'IE',
      F: {
        oC: 962323200,
        K: 998870400,
        D: 1161129600,
        E: 1237420800,
        F: 1300060800,
        A: 1346716800,
        B: 1381968000
      }
    },
    B: {
      A: {
        0: 0.003623,
        9: 0.003623,
        C: 0,
        L: 0,
        M: 0,
        G: 0,
        N: 0,
        O: 0,
        P: 0.097821,
        Q: 0,
        H: 0,
        R: 0,
        S: 0,
        T: 0,
        U: 0,
        V: 0,
        W: 0,
        X: 0,
        Y: 0,
        Z: 0,
        a: 0,
        b: 0.010869,
        c: 0,
        d: 0,
        e: 0,
        f: 0,
        g: 0,
        h: 0,
        i: 0,
        j: 0,
        k: 0,
        l: 0,
        m: 0,
        n: 0,
        o: 0,
        p: 0,
        q: 0,
        r: 0.003623,
        s: 0.047099,
        t: 0,
        u: 0,
        v: 0,
        w: 0.007246,
        x: 0.014492,
        y: 0.007246,
        z: 0,
        AB: 0.003623,
        BB: 0.03623,
        CB: 0.007246,
        DB: 0.014492,
        EB: 0.007246,
        FB: 0.007246,
        GB: 0.007246,
        HB: 0.021738,
        IB: 0.014492,
        JB: 0.014492,
        KB: 0.014492,
        LB: 0.025361,
        MB: 0.065214,
        NB: 0.079706,
        OB: 1.34051,
        PB: 3.0252,
        I: 0,
        QB: 0
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'C',
        'L',
        'M',
        'G',
        'N',
        'O',
        'P',
        'Q',
        'H',
        'R',
        'S',
        'T',
        'U',
        'V',
        'W',
        'X',
        'Y',
        'Z',
        'a',
        'b',
        'c',
        'd',
        'e',
        'f',
        'g',
        'h',
        'i',
        'j',
        'k',
        'l',
        'm',
        'n',
        'o',
        'p',
        'q',
        'r',
        's',
        't',
        'u',
        'v',
        'w',
        'x',
        'y',
        'z',
        '0',
        '9',
        'AB',
        'BB',
        'CB',
        'DB',
        'EB',
        'FB',
        'GB',
        'HB',
        'IB',
        'JB',
        'KB',
        'LB',
        'MB',
        'NB',
        'OB',
        'PB',
        'I',
        'QB',
        '',
        ''
      ],
      E: 'Edge',
      F: {
        0: 1694649600,
        9: 1697155200,
        C: 1438128000,
        L: 1447286400,
        M: 1470096000,
        G: 1491868800,
        N: 1508198400,
        O: 1525046400,
        P: 1542067200,
        Q: 1579046400,
        H: 1581033600,
        R: 1586736000,
        S: 1590019200,
        T: 1594857600,
        U: 1598486400,
        V: 1602201600,
        W: 1605830400,
        X: 1611360000,
        Y: 1614816000,
        Z: 1618358400,
        a: 1622073600,
        b: 1626912000,
        c: 1630627200,
        d: 1632441600,
        e: 1634774400,
        f: 1637539200,
        g: 1641427200,
        h: 1643932800,
        i: 1646265600,
        j: 1649635200,
        k: 1651190400,
        l: 1653955200,
        m: 1655942400,
        n: 1659657600,
        o: 1661990400,
        p: 1664755200,
        q: 1666915200,
        r: 1670198400,
        s: 1673481600,
        t: 1675900800,
        u: 1678665600,
        v: 1680825600,
        w: 1683158400,
        x: 1685664000,
        y: 1689897600,
        z: 1692576000,
        AB: 1698969600,
        BB: 1701993600,
        CB: 1706227200,
        DB: 1708732800,
        EB: 1711152000,
        FB: 1713398400,
        GB: 1715990400,
        HB: 1718841600,
        IB: 1721865600,
        JB: 1724371200,
        KB: 1726704000,
        LB: 1729123200,
        MB: 1731542400,
        NB: 1737417600,
        OB: 1740614400,
        PB: 1741219200,
        I: 1743984000,
        QB: null
      },
      D: {
        C: 'ms',
        L: 'ms',
        M: 'ms',
        G: 'ms',
        N: 'ms',
        O: 'ms',
        P: 'ms'
      }
    },
    C: {
      A: {
        0: 0,
        1: 0,
        2: 0,
        3: 0,
        4: 0,
        5: 0,
        6: 0,
        7: 0,
        8: 0,
        9: 0.094198,
        pC: 0.007246,
        NC: 0,
        J: 0,
        RB: 0,
        K: 0,
        D: 0,
        E: 0,
        F: 0,
        A: 0,
        B: 0.025361,
        C: 0,
        L: 0,
        M: 0,
        G: 0,
        N: 0,
        O: 0,
        P: 0,
        SB: 0,
        TB: 0,
        UB: 0,
        VB: 0,
        WB: 0,
        XB: 0,
        YB: 0,
        ZB: 0,
        aB: 0,
        bB: 0,
        cB: 0,
        dB: 0,
        eB: 0,
        fB: 0,
        gB: 0,
        hB: 0,
        iB: 0,
        jB: 0.003623,
        kB: 0,
        lB: 0,
        mB: 0,
        nB: 0,
        oB: 0,
        pB: 0,
        qB: 0,
        rB: 0.028984,
        sB: 0.014492,
        tB: 0,
        uB: 0.007246,
        vB: 0.007246,
        wB: 0,
        xB: 0,
        OC: 0.007246,
        yB: 0,
        PC: 0,
        zB: 0,
        '0B': 0,
        '1B': 0,
        '2B': 0,
        '3B': 0,
        '4B': 0,
        '5B': 0,
        '6B': 0,
        '7B': 0,
        '8B': 0,
        '9B': 0.003623,
        AC: 0,
        BC: 0,
        CC: 0,
        DC: 0,
        EC: 0,
        FC: 0.010869,
        Q: 0,
        H: 0,
        R: 0,
        QC: 0,
        S: 0,
        T: 0,
        U: 0,
        V: 0,
        W: 0,
        X: 0.007246,
        Y: 0,
        Z: 0,
        a: 0,
        b: 0,
        c: 0,
        d: 0.003623,
        e: 0,
        f: 0,
        g: 0,
        h: 0,
        i: 0,
        j: 0,
        k: 0,
        l: 0,
        m: 0,
        n: 0,
        o: 0,
        p: 0,
        q: 0,
        r: 0,
        s: 0.003623,
        t: 0,
        u: 0,
        v: 0,
        w: 0.003623,
        x: 0,
        y: 0.213757,
        z: 0,
        AB: 0,
        BB: 0.003623,
        CB: 0,
        DB: 0,
        EB: 0,
        FB: 0,
        GB: 0.014492,
        HB: 0,
        IB: 0.007246,
        JB: 0.083329,
        KB: 0,
        LB: 0,
        MB: 0.003623,
        NB: 0.007246,
        OB: 0.018115,
        PB: 0.025361,
        I: 0.347808,
        QB: 1.11951,
        GC: 0.007246,
        RC: 0,
        SC: 0,
        qC: 0,
        rC: 0,
        sC: 0,
        tC: 0
      },
      B: 'moz',
      C: [
        'pC',
        'NC',
        'sC',
        'tC',
        'J',
        'RB',
        'K',
        'D',
        'E',
        'F',
        'A',
        'B',
        'C',
        'L',
        'M',
        'G',
        'N',
        'O',
        'P',
        'SB',
        '1',
        '2',
        '3',
        '4',
        '5',
        '6',
        '7',
        '8',
        'TB',
        'UB',
        'VB',
        'WB',
        'XB',
        'YB',
        'ZB',
        'aB',
        'bB',
        'cB',
        'dB',
        'eB',
        'fB',
        'gB',
        'hB',
        'iB',
        'jB',
        'kB',
        'lB',
        'mB',
        'nB',
        'oB',
        'pB',
        'qB',
        'rB',
        'sB',
        'tB',
        'uB',
        'vB',
        'wB',
        'xB',
        'OC',
        'yB',
        'PC',
        'zB',
        '0B',
        '1B',
        '2B',
        '3B',
        '4B',
        '5B',
        '6B',
        '7B',
        '8B',
        '9B',
        'AC',
        'BC',
        'CC',
        'DC',
        'EC',
        'FC',
        'Q',
        'H',
        'R',
        'QC',
        'S',
        'T',
        'U',
        'V',
        'W',
        'X',
        'Y',
        'Z',
        'a',
        'b',
        'c',
        'd',
        'e',
        'f',
        'g',
        'h',
        'i',
        'j',
        'k',
        'l',
        'm',
        'n',
        'o',
        'p',
        'q',
        'r',
        's',
        't',
        'u',
        'v',
        'w',
        'x',
        'y',
        'z',
        '0',
        '9',
        'AB',
        'BB',
        'CB',
        'DB',
        'EB',
        'FB',
        'GB',
        'HB',
        'IB',
        'JB',
        'KB',
        'LB',
        'MB',
        'NB',
        'OB',
        'PB',
        'I',
        'QB',
        'GC',
        'RC',
        'SC',
        'qC',
        'rC'
      ],
      E: 'Firefox',
      F: {
        0: 1693267200,
        1: 1361232000,
        2: 1364860800,
        3: 1368489600,
        4: 1372118400,
        5: 1375747200,
        6: 1379376000,
        7: 1386633600,
        8: 1391472000,
        9: 1695686400,
        pC: 1161648000,
        NC: 1213660800,
        sC: 1246320000,
        tC: 1264032000,
        J: 1300752000,
        RB: 1308614400,
        K: 1313452800,
        D: 1317081600,
        E: 1317081600,
        F: 1320710400,
        A: 1324339200,
        B: 1327968000,
        C: 1331596800,
        L: 1335225600,
        M: 1338854400,
        G: 1342483200,
        N: 1346112000,
        O: 1349740800,
        P: 1353628800,
        SB: 1357603200,
        TB: 1395100800,
        UB: 1398729600,
        VB: 1402358400,
        WB: 1405987200,
        XB: 1409616000,
        YB: 1413244800,
        ZB: 1417392000,
        aB: 1421107200,
        bB: 1424736000,
        cB: 1428278400,
        dB: 1431475200,
        eB: 1435881600,
        fB: 1439251200,
        gB: 1442880000,
        hB: 1446508800,
        iB: 1450137600,
        jB: 1453852800,
        kB: 1457395200,
        lB: 1461628800,
        mB: 1465257600,
        nB: 1470096000,
        oB: 1474329600,
        pB: 1479168000,
        qB: 1485216000,
        rB: 1488844800,
        sB: 1492560000,
        tB: 1497312000,
        uB: 1502150400,
        vB: 1506556800,
        wB: 1510617600,
        xB: 1516665600,
        OC: 1520985600,
        yB: 1525824000,
        PC: 1529971200,
        zB: 1536105600,
        '0B': 1540252800,
        '1B': 1544486400,
        '2B': 1548720000,
        '3B': 1552953600,
        '4B': 1558396800,
        '5B': 1562630400,
        '6B': 1567468800,
        '7B': 1571788800,
        '8B': 1575331200,
        '9B': 1578355200,
        AC: 1581379200,
        BC: 1583798400,
        CC: 1586304000,
        DC: 1588636800,
        EC: 1591056000,
        FC: 1593475200,
        Q: 1595894400,
        H: 1598313600,
        R: 1600732800,
        QC: 1603152000,
        S: 1605571200,
        T: 1607990400,
        U: 1611619200,
        V: 1614038400,
        W: 1616457600,
        X: 1618790400,
        Y: 1622505600,
        Z: 1626134400,
        a: 1628553600,
        b: 1630972800,
        c: 1633392000,
        d: 1635811200,
        e: 1638835200,
        f: 1641859200,
        g: 1644364800,
        h: 1646697600,
        i: 1649116800,
        j: 1651536000,
        k: 1653955200,
        l: 1656374400,
        m: 1658793600,
        n: 1661212800,
        o: 1663632000,
        p: 1666051200,
        q: 1668470400,
        r: 1670889600,
        s: 1673913600,
        t: 1676332800,
        u: 1678752000,
        v: 1681171200,
        w: 1683590400,
        x: 1686009600,
        y: 1688428800,
        z: 1690848000,
        AB: 1698105600,
        BB: 1700524800,
        CB: 1702944000,
        DB: 1705968000,
        EB: 1708387200,
        FB: 1710806400,
        GB: 1713225600,
        HB: 1715644800,
        IB: 1718064000,
        JB: 1720483200,
        KB: 1722902400,
        LB: 1725321600,
        MB: 1727740800,
        NB: 1730160000,
        OB: 1732579200,
        PB: 1736208000,
        I: 1738627200,
        QB: 1741046400,
        GC: 1743465600,
        RC: 1745884800,
        SC: null,
        qC: null,
        rC: null
      }
    },
    D: {
      A: {
        0: 0.094198,
        1: 0,
        2: 0,
        3: 0,
        4: 0,
        5: 0,
        6: 0,
        7: 0,
        8: 0,
        9: 0.057968,
        J: 0,
        RB: 0,
        K: 0,
        D: 0,
        E: 0,
        F: 0,
        A: 0,
        B: 0,
        C: 0,
        L: 0,
        M: 0,
        G: 0,
        N: 0,
        O: 0,
        P: 0,
        SB: 0,
        TB: 0,
        UB: 0,
        VB: 0,
        WB: 0,
        XB: 0,
        YB: 0,
        ZB: 0,
        aB: 0,
        bB: 0,
        cB: 0,
        dB: 0.003623,
        eB: 0.007246,
        fB: 0.003623,
        gB: 0.007246,
        hB: 0.007246,
        iB: 0.007246,
        jB: 0.007246,
        kB: 0.007246,
        lB: 0.003623,
        mB: 0.007246,
        nB: 0.018115,
        oB: 0.018115,
        pB: 0.007246,
        qB: 0.007246,
        rB: 0.010869,
        sB: 0.007246,
        tB: 0.007246,
        uB: 0.007246,
        vB: 0.014492,
        wB: 0.007246,
        xB: 0.010869,
        OC: 0.007246,
        yB: 0.007246,
        PC: 0,
        zB: 0,
        '0B': 0,
        '1B': 0,
        '2B': 0,
        '3B': 0.021738,
        '4B': 0,
        '5B': 0,
        '6B': 0.010869,
        '7B': 0.010869,
        '8B': 0,
        '9B': 0,
        AC: 0.007246,
        BC: 0.003623,
        CC: 0.007246,
        DC: 0.003623,
        EC: 0.014492,
        FC: 0.010869,
        Q: 0.068837,
        H: 0.010869,
        R: 0.014492,
        S: 0.028984,
        T: 0.003623,
        U: 0.010869,
        V: 0.014492,
        W: 0.057968,
        X: 0.014492,
        Y: 0.003623,
        Z: 0.007246,
        a: 0.03623,
        b: 0.010869,
        c: 0.014492,
        d: 0.028984,
        e: 0.007246,
        f: 0.007246,
        g: 0.018115,
        h: 0.03623,
        i: 0.010869,
        j: 0.028984,
        k: 0.014492,
        l: 0.014492,
        m: 0.076083,
        n: 0.050722,
        o: 0.010869,
        p: 0.021738,
        q: 0.025361,
        r: 0.039853,
        s: 0.912996,
        t: 0.018115,
        u: 0.03623,
        v: 0.03623,
        w: 0.10869,
        x: 0.054345,
        y: 0.032607,
        z: 0.101444,
        AB: 0.03623,
        BB: 0.086952,
        CB: 0.094198,
        DB: 0.076083,
        EB: 0.086952,
        FB: 0.123182,
        GB: 0.344185,
        HB: 0.152166,
        IB: 0.101444,
        JB: 0.130428,
        KB: 0.101444,
        LB: 0.152166,
        MB: 1.17747,
        NB: 0.815175,
        OB: 5.89462,
        PB: 9.91615,
        I: 0.021738,
        QB: 0.014492,
        GC: 0,
        RC: 0,
        SC: 0
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'J',
        'RB',
        'K',
        'D',
        'E',
        'F',
        'A',
        'B',
        'C',
        'L',
        'M',
        'G',
        'N',
        'O',
        'P',
        'SB',
        '1',
        '2',
        '3',
        '4',
        '5',
        '6',
        '7',
        '8',
        'TB',
        'UB',
        'VB',
        'WB',
        'XB',
        'YB',
        'ZB',
        'aB',
        'bB',
        'cB',
        'dB',
        'eB',
        'fB',
        'gB',
        'hB',
        'iB',
        'jB',
        'kB',
        'lB',
        'mB',
        'nB',
        'oB',
        'pB',
        'qB',
        'rB',
        'sB',
        'tB',
        'uB',
        'vB',
        'wB',
        'xB',
        'OC',
        'yB',
        'PC',
        'zB',
        '0B',
        '1B',
        '2B',
        '3B',
        '4B',
        '5B',
        '6B',
        '7B',
        '8B',
        '9B',
        'AC',
        'BC',
        'CC',
        'DC',
        'EC',
        'FC',
        'Q',
        'H',
        'R',
        'S',
        'T',
        'U',
        'V',
        'W',
        'X',
        'Y',
        'Z',
        'a',
        'b',
        'c',
        'd',
        'e',
        'f',
        'g',
        'h',
        'i',
        'j',
        'k',
        'l',
        'm',
        'n',
        'o',
        'p',
        'q',
        'r',
        's',
        't',
        'u',
        'v',
        'w',
        'x',
        'y',
        'z',
        '0',
        '9',
        'AB',
        'BB',
        'CB',
        'DB',
        'EB',
        'FB',
        'GB',
        'HB',
        'IB',
        'JB',
        'KB',
        'LB',
        'MB',
        'NB',
        'OB',
        'PB',
        'I',
        'QB',
        'GC',
        'RC',
        'SC'
      ],
      E: 'Chrome',
      F: {
        0: 1694476800,
        1: 1337040000,
        2: 1340668800,
        3: 1343692800,
        4: 1348531200,
        5: 1352246400,
        6: 1357862400,
        7: 1361404800,
        8: 1364428800,
        9: 1696896000,
        J: 1264377600,
        RB: 1274745600,
        K: 1283385600,
        D: 1287619200,
        E: 1291248000,
        F: 1296777600,
        A: 1299542400,
        B: 1303862400,
        C: 1307404800,
        L: 1312243200,
        M: 1316131200,
        G: 1316131200,
        N: 1319500800,
        O: 1323734400,
        P: 1328659200,
        SB: 1332892800,
        TB: 1369094400,
        UB: 1374105600,
        VB: 1376956800,
        WB: 1384214400,
        XB: 1389657600,
        YB: 1392940800,
        ZB: 1397001600,
        aB: 1400544000,
        bB: 1405468800,
        cB: 1409011200,
        dB: 1412640000,
        eB: 1416268800,
        fB: 1421798400,
        gB: 1425513600,
        hB: 1429401600,
        iB: 1432080000,
        jB: 1437523200,
        kB: 1441152000,
        lB: 1444780800,
        mB: 1449014400,
        nB: 1453248000,
        oB: 1456963200,
        pB: 1460592000,
        qB: 1464134400,
        rB: 1469059200,
        sB: 1472601600,
        tB: 1476230400,
        uB: 1480550400,
        vB: 1485302400,
        wB: 1489017600,
        xB: 1492560000,
        OC: 1496707200,
        yB: 1500940800,
        PC: 1504569600,
        zB: 1508198400,
        '0B': 1512518400,
        '1B': 1516752000,
        '2B': 1520294400,
        '3B': 1523923200,
        '4B': 1527552000,
        '5B': 1532390400,
        '6B': 1536019200,
        '7B': 1539648000,
        '8B': 1543968000,
        '9B': 1548720000,
        AC: 1552348800,
        BC: 1555977600,
        CC: 1559606400,
        DC: 1564444800,
        EC: 1568073600,
        FC: 1571702400,
        Q: 1575936000,
        H: 1580860800,
        R: 1586304000,
        S: 1589846400,
        T: 1594684800,
        U: 1598313600,
        V: 1601942400,
        W: 1605571200,
        X: 1611014400,
        Y: 1614556800,
        Z: 1618272000,
        a: 1621987200,
        b: 1626739200,
        c: 1630368000,
        d: 1632268800,
        e: 1634601600,
        f: 1637020800,
        g: 1641340800,
        h: 1643673600,
        i: 1646092800,
        j: 1648512000,
        k: 1650931200,
        l: 1653350400,
        m: 1655769600,
        n: 1659398400,
        o: 1661817600,
        p: 1664236800,
        q: 1666656000,
        r: 1669680000,
        s: 1673308800,
        t: 1675728000,
        u: 1678147200,
        v: 1680566400,
        w: 1682985600,
        x: 1685404800,
        y: 1689724800,
        z: 1692057600,
        AB: 1698710400,
        BB: 1701993600,
        CB: 1705968000,
        DB: 1708387200,
        EB: 1710806400,
        FB: 1713225600,
        GB: 1715644800,
        HB: 1718064000,
        IB: 1721174400,
        JB: 1724112000,
        KB: 1726531200,
        LB: 1728950400,
        MB: 1731369600,
        NB: 1736812800,
        OB: 1738627200,
        PB: 1741046400,
        I: 1743465600,
        QB: 1745884800,
        GC: null,
        RC: null,
        SC: null
      }
    },
    E: {
      A: {
        J: 0,
        RB: 0,
        K: 0,
        D: 0,
        E: 0,
        F: 0,
        A: 0,
        B: 0,
        C: 0,
        L: 0,
        M: 0.014492,
        G: 0.003623,
        uC: 0,
        TC: 0,
        vC: 0,
        wC: 0,
        xC: 0,
        yC: 0,
        UC: 0,
        HC: 0.007246,
        IC: 0.007246,
        zC: 0.032607,
        '0C': 0.043476,
        '1C': 0.014492,
        VC: 0.003623,
        WC: 0.010869,
        JC: 0.014492,
        '2C': 0.148543,
        KC: 0.032607,
        XC: 0.021738,
        YC: 0.018115,
        ZC: 0.039853,
        aC: 0.014492,
        bC: 0.025361,
        '3C': 0.199265,
        LC: 0.010869,
        cC: 0.123182,
        dC: 0.018115,
        eC: 0.021738,
        fC: 0.050722,
        gC: 0.086952,
        '4C': 0.264479,
        MC: 0.03623,
        hC: 0.115936,
        iC: 0.057968,
        jC: 1.4021,
        kC: 0.018115,
        lC: 0,
        '5C': 0
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'uC',
        'TC',
        'J',
        'RB',
        'vC',
        'K',
        'wC',
        'D',
        'xC',
        'E',
        'F',
        'yC',
        'A',
        'UC',
        'B',
        'HC',
        'C',
        'IC',
        'L',
        'zC',
        'M',
        '0C',
        'G',
        '1C',
        'VC',
        'WC',
        'JC',
        '2C',
        'KC',
        'XC',
        'YC',
        'ZC',
        'aC',
        'bC',
        '3C',
        'LC',
        'cC',
        'dC',
        'eC',
        'fC',
        'gC',
        '4C',
        'MC',
        'hC',
        'iC',
        'jC',
        'kC',
        'lC',
        '5C',
        ''
      ],
      E: 'Safari',
      F: {
        uC: 1205798400,
        TC: 1226534400,
        J: 1244419200,
        RB: 1275868800,
        vC: 1311120000,
        K: 1343174400,
        wC: 1382400000,
        D: 1382400000,
        xC: 1410998400,
        E: 1413417600,
        F: 1443657600,
        yC: 1458518400,
        A: 1474329600,
        UC: 1490572800,
        B: 1505779200,
        HC: 1522281600,
        C: 1537142400,
        IC: 1553472000,
        L: 1568851200,
        zC: 1585008000,
        M: 1600214400,
        '0C': 1619395200,
        G: 1632096000,
        '1C': 1635292800,
        VC: 1639353600,
        WC: 1647216000,
        JC: 1652745600,
        '2C': 1658275200,
        KC: 1662940800,
        XC: 1666569600,
        YC: 1670889600,
        ZC: 1674432000,
        aC: 1679875200,
        bC: 1684368000,
        '3C': 1690156800,
        LC: 1695686400,
        cC: 1698192000,
        dC: 1702252800,
        eC: 1705881600,
        fC: 1709596800,
        gC: 1715558400,
        '4C': 1722211200,
        MC: 1726444800,
        hC: 1730073600,
        iC: 1733875200,
        jC: 1737936000,
        kC: 1743379200,
        lC: null,
        '5C': null
      }
    },
    F: {
      A: {
        0: 0.684747,
        1: 0,
        2: 0,
        3: 0,
        4: 0,
        5: 0,
        6: 0,
        7: 0,
        8: 0,
        F: 0,
        B: 0,
        C: 0,
        G: 0,
        N: 0,
        O: 0,
        P: 0,
        SB: 0,
        TB: 0,
        UB: 0,
        VB: 0,
        WB: 0,
        XB: 0,
        YB: 0,
        ZB: 0,
        aB: 0,
        bB: 0,
        cB: 0,
        dB: 0,
        eB: 0,
        fB: 0.003623,
        gB: 0,
        hB: 0,
        iB: 0,
        jB: 0,
        kB: 0,
        lB: 0.010869,
        mB: 0,
        nB: 0,
        oB: 0,
        pB: 0,
        qB: 0,
        rB: 0,
        sB: 0,
        tB: 0,
        uB: 0,
        vB: 0,
        wB: 0,
        xB: 0,
        yB: 0,
        zB: 0,
        '0B': 0,
        '1B': 0,
        '2B': 0,
        '3B': 0,
        '4B': 0,
        '5B': 0,
        '6B': 0,
        '7B': 0,
        '8B': 0,
        '9B': 0,
        AC: 0,
        BC: 0,
        CC: 0,
        DC: 0,
        EC: 0,
        FC: 0,
        Q: 0,
        H: 0,
        R: 0,
        QC: 0,
        S: 0,
        T: 0,
        U: 0,
        V: 0,
        W: 0.025361,
        X: 0.007246,
        Y: 0,
        Z: 0,
        a: 0,
        b: 0,
        c: 0,
        d: 0,
        e: 0.032607,
        f: 0,
        g: 0,
        h: 0,
        i: 0,
        j: 0,
        k: 0,
        l: 0.018115,
        m: 0,
        n: 0,
        o: 0,
        p: 0,
        q: 0,
        r: 0,
        s: 0,
        t: 0,
        u: 0,
        v: 0,
        w: 0,
        x: 0.003623,
        y: 0,
        z: 0.202888,
        '6C': 0,
        '7C': 0,
        '8C': 0,
        '9C': 0,
        HC: 0,
        mC: 0,
        AD: 0,
        IC: 0
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'F',
        '6C',
        '7C',
        '8C',
        '9C',
        'B',
        'HC',
        'mC',
        'AD',
        'C',
        'IC',
        'G',
        'N',
        'O',
        'P',
        'SB',
        '1',
        '2',
        '3',
        '4',
        '5',
        '6',
        '7',
        '8',
        'TB',
        'UB',
        'VB',
        'WB',
        'XB',
        'YB',
        'ZB',
        'aB',
        'bB',
        'cB',
        'dB',
        'eB',
        'fB',
        'gB',
        'hB',
        'iB',
        'jB',
        'kB',
        'lB',
        'mB',
        'nB',
        'oB',
        'pB',
        'qB',
        'rB',
        'sB',
        'tB',
        'uB',
        'vB',
        'wB',
        'xB',
        'yB',
        'zB',
        '0B',
        '1B',
        '2B',
        '3B',
        '4B',
        '5B',
        '6B',
        '7B',
        '8B',
        '9B',
        'AC',
        'BC',
        'CC',
        'DC',
        'EC',
        'FC',
        'Q',
        'H',
        'R',
        'QC',
        'S',
        'T',
        'U',
        'V',
        'W',
        'X',
        'Y',
        'Z',
        'a',
        'b',
        'c',
        'd',
        'e',
        'f',
        'g',
        'h',
        'i',
        'j',
        'k',
        'l',
        'm',
        'n',
        'o',
        'p',
        'q',
        'r',
        's',
        't',
        'u',
        'v',
        'w',
        'x',
        'y',
        'z',
        '0',
        '',
        '',
        ''
      ],
      E: 'Opera',
      F: {
        0: 1739404800,
        1: 1393891200,
        2: 1399334400,
        3: 1401753600,
        4: 1405987200,
        5: 1409616000,
        6: 1413331200,
        7: 1417132800,
        8: 1422316800,
        F: 1150761600,
        '6C': 1223424000,
        '7C': 1251763200,
        '8C': 1267488000,
        '9C': 1277942400,
        B: 1292457600,
        HC: 1302566400,
        mC: 1309219200,
        AD: 1323129600,
        C: 1323129600,
        IC: 1352073600,
        G: 1372723200,
        N: 1377561600,
        O: 1381104000,
        P: 1386288000,
        SB: 1390867200,
        TB: 1425945600,
        UB: 1430179200,
        VB: 1433808000,
        WB: 1438646400,
        XB: 1442448000,
        YB: 1445904000,
        ZB: 1449100800,
        aB: 1454371200,
        bB: 1457308800,
        cB: 1462320000,
        dB: 1465344000,
        eB: 1470096000,
        fB: 1474329600,
        gB: 1477267200,
        hB: 1481587200,
        iB: 1486425600,
        jB: 1490054400,
        kB: 1494374400,
        lB: 1498003200,
        mB: 1502236800,
        nB: 1506470400,
        oB: 1510099200,
        pB: 1515024000,
        qB: 1517961600,
        rB: 1521676800,
        sB: 1525910400,
        tB: 1530144000,
        uB: 1534982400,
        vB: 1537833600,
        wB: 1543363200,
        xB: 1548201600,
        yB: 1554768000,
        zB: 1561593600,
        '0B': 1566259200,
        '1B': 1570406400,
        '2B': 1573689600,
        '3B': 1578441600,
        '4B': 1583971200,
        '5B': 1587513600,
        '6B': 1592956800,
        '7B': 1595894400,
        '8B': 1600128000,
        '9B': 1603238400,
        AC: 1613520000,
        BC: 1612224000,
        CC: 1616544000,
        DC: 1619568000,
        EC: 1623715200,
        FC: 1627948800,
        Q: 1631577600,
        H: 1633392000,
        R: 1635984000,
        QC: 1638403200,
        S: 1642550400,
        T: 1644969600,
        U: 1647993600,
        V: 1650412800,
        W: 1652745600,
        X: 1654646400,
        Y: 1657152000,
        Z: 1660780800,
        a: 1663113600,
        b: 1668816000,
        c: 1668643200,
        d: 1671062400,
        e: 1675209600,
        f: 1677024000,
        g: 1679529600,
        h: 1681948800,
        i: 1684195200,
        j: 1687219200,
        k: 1690329600,
        l: 1692748800,
        m: 1696204800,
        n: 1699920000,
        o: 1699920000,
        p: 1702944000,
        q: 1707264000,
        r: 1710115200,
        s: 1711497600,
        t: 1716336000,
        u: 1719273600,
        v: 1721088000,
        w: 1724284800,
        x: 1727222400,
        y: 1732665600,
        z: 1736294400
      },
      D: {
        F: 'o',
        B: 'o',
        C: 'o',
        '6C': 'o',
        '7C': 'o',
        '8C': 'o',
        '9C': 'o',
        HC: 'o',
        mC: 'o',
        AD: 'o',
        IC: 'o'
      }
    },
    G: {
      A: {
        E: 0,
        TC: 0,
        BD: 0,
        nC: 0.00289898,
        CD: 0,
        DD: 0.00869695,
        ED: 0.00724746,
        FD: 0,
        GD: 0.00434848,
        HD: 0.0202929,
        ID: 0.00144949,
        JD: 0.0333383,
        KD: 0.153646,
        LD: 0.0101464,
        MD: 0.00579797,
        ND: 0.14205,
        OD: 0.00289898,
        PD: 0.00579797,
        QD: 0.00579797,
        RD: 0.0202929,
        SD: 0.124656,
        TD: 0.0608787,
        UD: 0.0333383,
        VC: 0.0333383,
        WC: 0.0405858,
        JC: 0.0463837,
        VD: 0.568201,
        KC: 0.0797221,
        XC: 0.165242,
        YC: 0.08552,
        ZC: 0.150747,
        aC: 0.0333383,
        bC: 0.0623282,
        WD: 0.672564,
        LC: 0.0405858,
        cC: 0.0724746,
        dC: 0.0550807,
        eC: 0.0768231,
        fC: 0.153646,
        gC: 0.340631,
        XD: 0.988554,
        MC: 0.276853,
        hC: 0.905933,
        iC: 0.405858,
        jC: 8.46503,
        kC: 0.126106,
        lC: 0
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'TC',
        'BD',
        'nC',
        'CD',
        'DD',
        'ED',
        'E',
        'FD',
        'GD',
        'HD',
        'ID',
        'JD',
        'KD',
        'LD',
        'MD',
        'ND',
        'OD',
        'PD',
        'QD',
        'RD',
        'SD',
        'TD',
        'UD',
        'VC',
        'WC',
        'JC',
        'VD',
        'KC',
        'XC',
        'YC',
        'ZC',
        'aC',
        'bC',
        'WD',
        'LC',
        'cC',
        'dC',
        'eC',
        'fC',
        'gC',
        'XD',
        'MC',
        'hC',
        'iC',
        'jC',
        'kC',
        'lC',
        '',
        ''
      ],
      E: 'Safari on iOS',
      F: {
        TC: 1270252800,
        BD: 1283904000,
        nC: 1299628800,
        CD: 1331078400,
        DD: 1359331200,
        ED: 1394409600,
        E: 1410912000,
        FD: 1413763200,
        GD: 1442361600,
        HD: 1458518400,
        ID: 1473724800,
        JD: 1490572800,
        KD: 1505779200,
        LD: 1522281600,
        MD: 1537142400,
        ND: 1553472000,
        OD: 1568851200,
        PD: 1572220800,
        QD: 1580169600,
        RD: 1585008000,
        SD: 1600214400,
        TD: 1619395200,
        UD: 1632096000,
        VC: 1639353600,
        WC: 1647216000,
        JC: 1652659200,
        VD: 1658275200,
        KC: 1662940800,
        XC: 1666569600,
        YC: 1670889600,
        ZC: 1674432000,
        aC: 1679875200,
        bC: 1684368000,
        WD: 1690156800,
        LC: 1694995200,
        cC: 1698192000,
        dC: 1702252800,
        eC: 1705881600,
        fC: 1709596800,
        gC: 1715558400,
        XD: 1722211200,
        MC: 1726444800,
        hC: 1730073600,
        iC: 1733875200,
        jC: 1737936000,
        kC: 1743379200,
        lC: null
      }
    },
    H: {
      A: {
        YD: 0.05
      },
      B: 'o',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'YD',
        '',
        '',
        ''
      ],
      E: 'Opera Mini',
      F: {
        YD: 1426464000
      }
    },
    I: {
      A: {
        NC: 0,
        J: 0,
        I: 0.871727,
        ZD: 0,
        aD: 0,
        bD: 0,
        cD: 0,
        nC: 0.000262095,
        dD: 0,
        eD: 0.000961014
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'ZD',
        'aD',
        'bD',
        'NC',
        'J',
        'cD',
        'nC',
        'dD',
        'eD',
        'I',
        '',
        '',
        ''
      ],
      E: 'Android Browser',
      F: {
        ZD: 1256515200,
        aD: 1274313600,
        bD: 1291593600,
        NC: 1298332800,
        J: 1318896000,
        cD: 1341792000,
        nC: 1374624000,
        dD: 1386547200,
        eD: 1401667200,
        I: 1743379200
      }
    },
    J: {
      A: {
        D: 0,
        A: 0
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'D',
        'A',
        '',
        '',
        ''
      ],
      E: 'Blackberry Browser',
      F: {
        D: 1325376000,
        A: 1359504000
      }
    },
    K: {
      A: {
        A: 0,
        B: 0,
        C: 0,
        H: 1.04047,
        HC: 0,
        mC: 0,
        IC: 0
      },
      B: 'o',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'A',
        'B',
        'HC',
        'mC',
        'C',
        'IC',
        'H',
        '',
        '',
        ''
      ],
      E: 'Opera Mobile',
      F: {
        A: 1287100800,
        B: 1300752000,
        HC: 1314835200,
        mC: 1318291200,
        C: 1330300800,
        IC: 1349740800,
        H: 1709769600
      },
      D: {
        H: 'webkit'
      }
    },
    L: {
      A: {
        I: 44.6783
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'I',
        '',
        '',
        ''
      ],
      E: 'Chrome for Android',
      F: {
        I: 1743379200
      }
    },
    M: {
      A: {
        GC: 0.350735
      },
      B: 'moz',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'GC',
        '',
        '',
        ''
      ],
      E: 'Firefox for Android',
      F: {
        GC: 1743465600
      }
    },
    N: {
      A: {
        A: 0,
        B: 0
      },
      B: 'ms',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'A',
        'B',
        '',
        '',
        ''
      ],
      E: 'IE Mobile',
      F: {
        A: 1340150400,
        B: 1353456000
      }
    },
    O: {
      A: {
        JC: 0.848141
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'JC',
        '',
        '',
        ''
      ],
      E: 'UC Browser for Android',
      F: {
        JC: 1710115200
      },
      D: {
        JC: 'webkit'
      }
    },
    P: {
      A: {
        1: 0,
        2: 0.0219344,
        3: 0.0219344,
        4: 0.0329016,
        5: 0.0438688,
        6: 0.0438688,
        7: 0.0877377,
        8: 1.96313,
        J: 0.0329016,
        fD: 0,
        gD: 0,
        hD: 0.0109672,
        iD: 0,
        jD: 0,
        UC: 0,
        kD: 0,
        lD: 0,
        mD: 0,
        nD: 0,
        oD: 0,
        KC: 0,
        LC: 0.0109672,
        MC: 0,
        pD: 0
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'J',
        'fD',
        'gD',
        'hD',
        'iD',
        'jD',
        'UC',
        'kD',
        'lD',
        'mD',
        'nD',
        'oD',
        'KC',
        'LC',
        'MC',
        'pD',
        '1',
        '2',
        '3',
        '4',
        '5',
        '6',
        '7',
        '8',
        '',
        '',
        ''
      ],
      E: 'Samsung Internet',
      F: {
        1: 1677369600,
        2: 1684454400,
        3: 1689292800,
        4: 1697587200,
        5: 1711497600,
        6: 1715126400,
        7: 1717718400,
        8: 1725667200,
        J: 1461024000,
        fD: 1481846400,
        gD: 1509408000,
        hD: 1528329600,
        iD: 1546128000,
        jD: 1554163200,
        UC: 1567900800,
        kD: 1582588800,
        lD: 1593475200,
        mD: 1605657600,
        nD: 1618531200,
        oD: 1629072000,
        KC: 1640736000,
        LC: 1651708800,
        MC: 1659657600,
        pD: 1667260800
      }
    },
    Q: {
      A: {
        qD: 0.229572
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'qD',
        '',
        '',
        ''
      ],
      E: 'QQ Browser',
      F: {
        qD: 1710288000
      }
    },
    R: {
      A: {
        rD: 0
      },
      B: 'webkit',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'rD',
        '',
        '',
        ''
      ],
      E: 'Baidu Browser',
      F: {
        rD: 1710201600
      }
    },
    S: {
      A: {
        sD: 0.012754,
        tD: 0
      },
      B: 'moz',
      C: [
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        '',
        'sD',
        'tD',
        '',
        '',
        ''
      ],
      E: 'KaiOS Browser',
      F: {
        sD: 1527811200,
        tD: 1631664000
      }
    }
  }
  return agents
}

let hasRequiredAgents
function requireAgents() {
  if (hasRequiredAgents) {
    return agents$1
  }
  hasRequiredAgents = 1
  const browsers = requireBrowsers().browsers
  const versions = requireBrowserVersions().browserVersions
  const agentsData = requireAgents$1()
  function unpackBrowserVersions(versionsData) {
    return Object.keys(versionsData).reduce((usage, version) => {
      usage[versions[version]] = versionsData[version]
      return usage
    }, {})
  }
  agents$1.agents = Object.keys(agentsData).reduce((map, key) => {
    let versionsData = agentsData[key]
    map[browsers[key]] = Object.keys(versionsData).reduce((data, entry) => {
      if (entry === 'A') {
        data.usage_global = unpackBrowserVersions(versionsData[entry])
      } else if (entry === 'C') {
        data.versions = versionsData[entry].reduce((list, version) => {
          if (version === '') {
            list.push(null)
          } else {
            list.push(versions[version])
          }
          return list
        }, [])
      } else if (entry === 'D') {
        data.prefix_exceptions = unpackBrowserVersions(versionsData[entry])
      } else if (entry === 'E') {
        data.browser = versionsData[entry]
      } else if (entry === 'F') {
        data.release_date = Object.keys(versionsData[entry]).reduce(
          (map2, key2) => {
            map2[versions[key2]] = versionsData[entry][key2]
            return map2
          },
          {}
        )
      } else {
        // entry is B
        data.prefix = versionsData[entry]
      }
      return data
    }, {})
    return map
  }, {})
  return agents$1
}

let versions
let hasRequiredVersions
function requireVersions() {
  if (hasRequiredVersions) {
    return versions
  }
  hasRequiredVersions = 1
  versions = {
    '0.20': '39',
    0.21: '41',
    0.22: '41',
    0.23: '41',
    0.24: '41',
    0.25: '42',
    0.26: '42',
    0.27: '43',
    0.28: '43',
    0.29: '43',
    '0.30': '44',
    0.31: '45',
    0.32: '45',
    0.33: '45',
    0.34: '45',
    0.35: '45',
    0.36: '47',
    0.37: '49',
    '1.0': '49',
    1.1: '50',
    1.2: '51',
    1.3: '52',
    1.4: '53',
    1.5: '54',
    1.6: '56',
    1.7: '58',
    1.8: '59',
    '2.0': '61',
    2.1: '61',
    '3.0': '66',
    3.1: '66',
    '4.0': '69',
    4.1: '69',
    4.2: '69',
    '5.0': '73',
    '6.0': '76',
    6.1: '76',
    '7.0': '78',
    7.1: '78',
    7.2: '78',
    7.3: '78',
    '8.0': '80',
    8.1: '80',
    8.2: '80',
    8.3: '80',
    8.4: '80',
    8.5: '80',
    '9.0': '83',
    9.1: '83',
    9.2: '83',
    9.3: '83',
    9.4: '83',
    '10.0': '85',
    10.1: '85',
    10.2: '85',
    10.3: '85',
    10.4: '85',
    '11.0': '87',
    11.1: '87',
    11.2: '87',
    11.3: '87',
    11.4: '87',
    11.5: '87',
    '12.0': '89',
    12.1: '89',
    12.2: '89',
    '13.0': '91',
    13.1: '91',
    13.2: '91',
    13.3: '91',
    13.4: '91',
    13.5: '91',
    13.6: '91',
    '14.0': '93',
    14.1: '93',
    14.2: '93',
    '15.0': '94',
    15.1: '94',
    15.2: '94',
    15.3: '94',
    15.4: '94',
    15.5: '94',
    '16.0': '96',
    16.1: '96',
    16.2: '96',
    '17.0': '98',
    17.1: '98',
    17.2: '98',
    17.3: '98',
    17.4: '98',
    '18.0': '100',
    18.1: '100',
    18.2: '100',
    18.3: '100',
    '19.0': '102',
    19.1: '102',
    '20.0': '104',
    20.1: '104',
    20.2: '104',
    20.3: '104',
    '21.0': '106',
    21.1: '106',
    21.2: '106',
    21.3: '106',
    21.4: '106',
    '22.0': '108',
    22.1: '108',
    22.2: '108',
    22.3: '108',
    '23.0': '110',
    23.1: '110',
    23.2: '110',
    23.3: '110',
    '24.0': '112',
    24.1: '112',
    24.2: '112',
    24.3: '112',
    24.4: '112',
    24.5: '112',
    24.6: '112',
    24.7: '112',
    24.8: '112',
    '25.0': '114',
    25.1: '114',
    25.2: '114',
    25.3: '114',
    25.4: '114',
    25.5: '114',
    25.6: '114',
    25.7: '114',
    25.8: '114',
    25.9: '114',
    '26.0': '116',
    26.1: '116',
    26.2: '116',
    26.3: '116',
    26.4: '116',
    26.5: '116',
    26.6: '116',
    '27.0': '118',
    27.1: '118',
    27.2: '118',
    27.3: '118',
    '28.0': '120',
    28.1: '120',
    28.2: '120',
    28.3: '120',
    '29.0': '122',
    29.1: '122',
    29.2: '122',
    29.3: '122',
    29.4: '122',
    '30.0': '124',
    30.1: '124',
    30.2: '124',
    30.3: '124',
    30.4: '124',
    30.5: '124',
    '31.0': '126',
    31.1: '126',
    31.2: '126',
    31.3: '126',
    31.4: '126',
    31.5: '126',
    31.6: '126',
    31.7: '126',
    '32.0': '128',
    32.1: '128',
    32.2: '128',
    32.3: '128',
    '33.0': '130',
    33.1: '130',
    33.2: '130',
    33.3: '130',
    33.4: '130',
    '34.0': '132',
    34.1: '132',
    34.2: '132',
    34.3: '132',
    34.4: '132',
    34.5: '132',
    '35.0': '134',
    35.1: '134',
    35.2: '134',
    '36.0': '136',
    36.1: '136',
    '37.0': '138'
  }
  return versions
}

const v4 = {
  start: '2015-09-08',
  lts: '2015-10-12',
  maintenance: '2017-04-01',
  end: '2018-04-30',
  codename: 'Argon'
}
const v5 = {
  start: '2015-10-29',
  maintenance: '2016-04-30',
  end: '2016-06-30'
}
const v6 = {
  start: '2016-04-26',
  lts: '2016-10-18',
  maintenance: '2018-04-30',
  end: '2019-04-30',
  codename: 'Boron'
}
const v7 = {
  start: '2016-10-25',
  maintenance: '2017-04-30',
  end: '2017-06-30'
}
const v8 = {
  start: '2017-05-30',
  lts: '2017-10-31',
  maintenance: '2019-01-01',
  end: '2019-12-31',
  codename: 'Carbon'
}
const v9 = {
  start: '2017-10-01',
  maintenance: '2018-04-01',
  end: '2018-06-30'
}
const v10 = {
  start: '2018-04-24',
  lts: '2018-10-30',
  maintenance: '2020-05-19',
  end: '2021-04-30',
  codename: 'Dubnium'
}
const v11 = {
  start: '2018-10-23',
  maintenance: '2019-04-22',
  end: '2019-06-01'
}
const v12 = {
  start: '2019-04-23',
  lts: '2019-10-21',
  maintenance: '2020-11-30',
  end: '2022-04-30',
  codename: 'Erbium'
}
const v13 = {
  start: '2019-10-22',
  maintenance: '2020-04-01',
  end: '2020-06-01'
}
const v14 = {
  start: '2020-04-21',
  lts: '2020-10-27',
  maintenance: '2021-10-19',
  end: '2023-04-30',
  codename: 'Fermium'
}
const v15 = {
  start: '2020-10-20',
  maintenance: '2021-04-01',
  end: '2021-06-01'
}
const v16 = {
  start: '2021-04-20',
  lts: '2021-10-26',
  maintenance: '2022-10-18',
  end: '2023-09-11',
  codename: 'Gallium'
}
const v17 = {
  start: '2021-10-19',
  maintenance: '2022-04-01',
  end: '2022-06-01'
}
const v18 = {
  start: '2022-04-19',
  lts: '2022-10-25',
  maintenance: '2023-10-18',
  end: '2025-04-30',
  codename: 'Hydrogen'
}
const v19 = {
  start: '2022-10-18',
  maintenance: '2023-04-01',
  end: '2023-06-01'
}
const v20 = {
  start: '2023-04-18',
  lts: '2023-10-24',
  maintenance: '2024-10-22',
  end: '2026-04-30',
  codename: 'Iron'
}
const v21 = {
  start: '2023-10-17',
  maintenance: '2024-04-01',
  end: '2024-06-01'
}
const v22 = {
  start: '2024-04-24',
  lts: '2024-10-29',
  maintenance: '2025-10-21',
  end: '2027-04-30',
  codename: 'Jod'
}
const v23 = {
  start: '2024-10-16',
  maintenance: '2025-04-01',
  end: '2025-06-01'
}
const v24 = {
  start: '2025-04-22',
  lts: '2025-10-28',
  maintenance: '2026-10-20',
  end: '2028-04-30',
  codename: ''
}
const require$$3 = {
  'v0.8': {
    start: '2012-06-25',
    end: '2014-07-31'
  },
  'v0.10': {
    start: '2013-03-11',
    end: '2016-10-31'
  },
  'v0.12': {
    start: '2015-02-06',
    end: '2016-12-31'
  },
  v4: v4,
  v5: v5,
  v6: v6,
  v7: v7,
  v8: v8,
  v9: v9,
  v10: v10,
  v11: v11,
  v12: v12,
  v13: v13,
  v14: v14,
  v15: v15,
  v16: v16,
  v17: v17,
  v18: v18,
  v19: v19,
  v20: v20,
  v21: v21,
  v22: v22,
  v23: v23,
  v24: v24
}

let error
let hasRequiredError
function requireError() {
  if (hasRequiredError) {
    return error
  }
  hasRequiredError = 1
  function BrowserslistError(message) {
    this.name = 'BrowserslistError'
    this.message = message
    this.browserslist = true
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, BrowserslistError)
    }
  }
  BrowserslistError.prototype = Error.prototype
  error = BrowserslistError
  return error
}

const node = { exports: {} }

const feature = { exports: {} }

let statuses
let hasRequiredStatuses
function requireStatuses() {
  if (hasRequiredStatuses) {
    return statuses
  }
  hasRequiredStatuses = 1
  statuses = {
    1: 'ls',
    // WHATWG Living Standard
    2: 'rec',
    // W3C Recommendation
    3: 'pr',
    // W3C Proposed Recommendation
    4: 'cr',
    // W3C Candidate Recommendation
    5: 'wd',
    // W3C Working Draft
    6: 'other',
    // Non-W3C, but reputable
    7: 'unoff' // Unofficial, Editor's Draft or W3C "Note"
  }
  return statuses
}

let supported
let hasRequiredSupported
function requireSupported() {
  if (hasRequiredSupported) {
    return supported
  }
  hasRequiredSupported = 1
  supported = {
    y: 1 << 0,
    n: 1 << 1,
    a: 1 << 2,
    p: 1 << 3,
    u: 1 << 4,
    x: 1 << 5,
    d: 1 << 6
  }
  return supported
}

let hasRequiredFeature
function requireFeature() {
  if (hasRequiredFeature) {
    return feature.exports
  }
  hasRequiredFeature = 1
  const statuses = requireStatuses()
  const supported = requireSupported()
  const browsers = requireBrowsers().browsers
  const versions = requireBrowserVersions().browserVersions
  const MATH2LOG = Math.log(2)
  function unpackSupport(cipher) {
    // bit flags
    let stats = Object.keys(supported).reduce((list, support) => {
      if (cipher & supported[support]) {
        list.push(support)
      }
      return list
    }, [])

    // notes
    let notes = cipher >> 7
    let notesArray = []
    while (notes) {
      let note = Math.floor(Math.log(notes) / MATH2LOG) + 1
      notesArray.unshift(`#${note}`)
      notes -= Math.pow(2, note - 1)
    }
    return stats.concat(notesArray).join(' ')
  }
  function unpackFeature(packed) {
    let unpacked = {
      status: statuses[packed.B],
      title: packed.C,
      shown: packed.D
    }
    unpacked.stats = Object.keys(packed.A).reduce((browserStats, key) => {
      let browser = packed.A[key]
      browserStats[browsers[key]] = Object.keys(browser).reduce(
        (stats, support) => {
          let packedVersions = browser[support].split(' ')
          let unpacked2 = unpackSupport(support)
          packedVersions.forEach(v => (stats[versions[v]] = unpacked2))
          return stats
        },
        {}
      )
      return browserStats
    }, {})
    return unpacked
  }
  feature.exports = unpackFeature
  feature.exports.default = unpackFeature
  return feature.exports
}

const region = { exports: {} }

let hasRequiredRegion
function requireRegion() {
  if (hasRequiredRegion) {
    return region.exports
  }
  hasRequiredRegion = 1
  const browsers = requireBrowsers().browsers
  function unpackRegion(packed) {
    return Object.keys(packed).reduce((list, browser) => {
      let data = packed[browser]
      list[browsers[browser]] = Object.keys(data).reduce((memo, key) => {
        let stats = data[key]
        if (key === '_') {
          stats.split(' ').forEach(version => (memo[version] = null))
        } else {
          memo[key] = stats
        }
        return memo
      }, {})
      return list
    }, {})
  }
  region.exports = unpackRegion
  region.exports.default = unpackRegion
  return region.exports
}

let hasRequiredNode
function requireNode() {
  if (hasRequiredNode) {
    return node.exports
  }
  hasRequiredNode = 1
  ;(function (module) {
    const feature = requireFeature().default
    const region = requireRegion().default
    const fs = require$$0$6
    const path = require$$0$5
    const BrowserslistError = requireError()
    const IS_SECTION = /^\s*\[(.+)]\s*$/
    const CONFIG_PATTERN = /^browserslist-config-/
    const SCOPED_CONFIG__PATTERN =
      /@[^/]+(?:\/[^/]+)?\/browserslist-config(?:-|$|\/)/
    const FORMAT =
      'Browserslist config should be a string or an array ' +
      'of strings with browser queries'
    let dataTimeChecked = false
    let statCache = {}
    let configPathCache = {}
    let parseConfigCache = {}
    function checkExtend(name) {
      const use = ' Use `dangerousExtend` option to disable.'
      if (!CONFIG_PATTERN.test(name) && !SCOPED_CONFIG__PATTERN.test(name)) {
        throw new BrowserslistError(
          'Browserslist config needs `browserslist-config-` prefix. ' + use
        )
      }
      if (name.replace(/^@[^/]+\//, '').indexOf('.') !== -1) {
        throw new BrowserslistError(
          '`.` not allowed in Browserslist config name. ' + use
        )
      }
      if (name.indexOf('node_modules') !== -1) {
        throw new BrowserslistError(
          '`node_modules` not allowed in Browserslist config.' + use
        )
      }
    }
    function isFile(file) {
      return fs.existsSync(file) && fs.statSync(file).isFile()
    }
    function isDirectory(dir) {
      return fs.existsSync(dir) && fs.statSync(dir).isDirectory()
    }
    function eachParent(file, callback, cache) {
      let loc = path.resolve(file)
      const pathsForCacheResult = []
      let result
      do {
        if (!pathInRoot(loc)) {
          break
        }
        if (cache && loc in cache) {
          result = cache[loc]
          break
        }
        pathsForCacheResult.push(loc)
        if (!isDirectory(loc)) {
          continue
        }
        const locResult = callback(loc)
        if (typeof locResult !== 'undefined') {
          result = locResult
          break
        }
      } while (loc !== (loc = path.dirname(loc)))
      if (cache && !process.env.BROWSERSLIST_DISABLE_CACHE) {
        pathsForCacheResult.forEach(function (cachePath) {
          cache[cachePath] = result
        })
      }
      return result
    }
    function pathInRoot(p) {
      if (!process.env.BROWSERSLIST_ROOT_PATH) {
        return true
      }
      const rootPath = path.resolve(process.env.BROWSERSLIST_ROOT_PATH)
      if (path.relative(rootPath, p).substring(0, 2) === '..') {
        return false
      }
      return true
    }
    function check(section) {
      if (Array.isArray(section)) {
        for (let i = 0; i < section.length; i++) {
          if (typeof section[i] !== 'string') {
            throw new BrowserslistError(FORMAT)
          }
        }
      } else if (typeof section !== 'string') {
        throw new BrowserslistError(FORMAT)
      }
    }
    function pickEnv(config, opts) {
      if (typeof config !== 'object') {
        return config
      }
      let name
      if (typeof opts.env === 'string') {
        name = opts.env
      } else if (process.env.BROWSERSLIST_ENV) {
        name = process.env.BROWSERSLIST_ENV
      } else if (process.env.NODE_ENV) {
        name = process.env.NODE_ENV
      } else {
        name = 'production'
      }
      if (opts.throwOnMissing) {
        if (name && name !== 'defaults' && !config[name]) {
          throw new BrowserslistError(
            'Missing config for Browserslist environment `' + name + '`'
          )
        }
      }
      return config[name] || config.defaults
    }
    function parsePackage(file) {
      const text = fs
        .readFileSync(file)
        .toString()
        .replace(/^\uFEFF/m, '')
      let list
      if (text.indexOf('"browserslist"') >= 0) {
        list = JSON.parse(text).browserslist
      } else if (text.indexOf('"browserlist"') >= 0) {
        const config = JSON.parse(text)
        if (config.browserlist && !config.browserslist) {
          throw new BrowserslistError(
            '`browserlist` key instead of `browserslist` in ' + file
          )
        }
      }
      if (Array.isArray(list) || typeof list === 'string') {
        list = {
          defaults: list
        }
      }
      for (const i in list) {
        check(list[i])
      }
      return list
    }
    function parsePackageOrReadConfig(file) {
      if (file in parseConfigCache) {
        return parseConfigCache[file]
      }
      const isPackage = path.basename(file) === 'package.json'
      const result = isPackage
        ? parsePackage(file)
        : module.exports.readConfig(file)
      if (!process.env.BROWSERSLIST_DISABLE_CACHE) {
        parseConfigCache[file] = result
      }
      return result
    }
    function latestReleaseTime(agents) {
      let latest = 0
      for (const name in agents) {
        const dates = agents[name].releaseDate || {}
        for (const key in dates) {
          if (latest < dates[key]) {
            latest = dates[key]
          }
        }
      }
      return latest * 1000
    }
    function getMonthsPassed(date) {
      const now = new Date()
      const past = new Date(date)
      const years = now.getFullYear() - past.getFullYear()
      const months = now.getMonth() - past.getMonth()
      return years * 12 + months
    }
    function normalizeStats(data, stats) {
      if (!data) {
        data = {}
      }
      if (stats && 'dataByBrowser' in stats) {
        stats = stats.dataByBrowser
      }
      if (typeof stats !== 'object') {
        return undefined
      }
      const normalized = {}
      for (const i in stats) {
        const versions = Object.keys(stats[i])
        if (versions.length === 1 && data[i] && data[i].versions.length === 1) {
          const normal = data[i].versions[0]
          normalized[i] = {}
          normalized[i][normal] = stats[i][versions[0]]
        } else {
          normalized[i] = stats[i]
        }
      }
      return normalized
    }
    function normalizeUsageData(usageData, data) {
      for (const browser in usageData) {
        const browserUsage = usageData[browser]
        // https://github.com/browserslist/browserslist/issues/431#issuecomment-565230615
        // caniuse-db returns { 0: "percentage" } for `and_*` regional stats
        if ('0' in browserUsage) {
          const versions = data[browser].versions
          browserUsage[versions[versions.length - 1]] = browserUsage[0]
          delete browserUsage[0]
        }
      }
    }
    module.exports = {
      loadQueries: function loadQueries(ctx, name) {
        if (
          !ctx.dangerousExtend &&
          !process.env.BROWSERSLIST_DANGEROUS_EXTEND
        ) {
          checkExtend(name)
        }
        let queries = require(
          require.resolve(name, {
            paths: ['.', ctx.path]
          })
        )
        if (
          typeof queries === 'object' &&
          queries !== null &&
          queries.__esModule
        ) {
          queries = queries.default
        }
        if (queries) {
          if (Array.isArray(queries)) {
            return queries
          } else if (typeof queries === 'object') {
            if (!queries.defaults) {
              queries.defaults = []
            }
            return pickEnv(queries, ctx)
          }
        }
        throw new BrowserslistError(
          '`' +
            name +
            '` config exports not an array of queries' +
            ' or an object of envs'
        )
      },
      loadStat: function loadStat(ctx, name, data) {
        if (
          !ctx.dangerousExtend &&
          !process.env.BROWSERSLIST_DANGEROUS_EXTEND
        ) {
          checkExtend(name)
        }
        const stats = require(
          require.resolve(path.join(name, 'browserslist-stats.json'), {
            paths: ['.']
          })
        )
        return normalizeStats(data, stats)
      },
      getStat: function getStat(opts, data) {
        let stats
        if (opts.stats) {
          stats = opts.stats
        } else if (process.env.BROWSERSLIST_STATS) {
          stats = process.env.BROWSERSLIST_STATS
        } else if (opts.path && path.resolve && fs.existsSync) {
          stats = eachParent(
            opts.path,
            function (dir) {
              const file = path.join(dir, 'browserslist-stats.json')
              return isFile(file) ? file : undefined
            },
            statCache
          )
        }
        if (typeof stats === 'string') {
          try {
            stats = JSON.parse(fs.readFileSync(stats))
          } catch (e) {
            throw new BrowserslistError("Can't read " + stats)
          }
        }
        return normalizeStats(data, stats)
      },
      loadConfig: function loadConfig(opts) {
        if (process.env.BROWSERSLIST) {
          return process.env.BROWSERSLIST
        } else if (opts.config || process.env.BROWSERSLIST_CONFIG) {
          const file = opts.config || process.env.BROWSERSLIST_CONFIG
          return pickEnv(parsePackageOrReadConfig(file), opts)
        } else if (opts.path) {
          return pickEnv(module.exports.findConfig(opts.path), opts)
        } else {
          return undefined
        }
      },
      loadCountry: function loadCountry(usage, country, data) {
        const code = country.replace(/[^\w-]/g, '')
        if (!usage[code]) {
          let compressed
          try {
            compressed = require('caniuse-lite/data/regions/' + code + '.js')
          } catch (e) {
            throw new BrowserslistError('Unknown region name `' + code + '`.')
          }
          const usageData = region(compressed)
          normalizeUsageData(usageData, data)
          usage[country] = {}
          for (const i in usageData) {
            for (const j in usageData[i]) {
              usage[country][i + ' ' + j] = usageData[i][j]
            }
          }
        }
      },
      loadFeature: function loadFeature(features, name) {
        name = name.replace(/[^\w-]/g, '')
        if (features[name]) {
          return
        }
        let compressed
        try {
          compressed = require('caniuse-lite/data/features/' + name + '.js')
        } catch (e) {
          throw new BrowserslistError('Unknown feature name `' + name + '`.')
        }
        const stats = feature(compressed).stats
        features[name] = {}
        for (const i in stats) {
          features[name][i] = {}
          for (const j in stats[i]) {
            features[name][i][j] = stats[i][j]
          }
        }
      },
      parseConfig: function parseConfig(string) {
        const result = {
          defaults: []
        }
        let sections = ['defaults']
        string
          .toString()
          .replace(/#[^\n]*/g, '')
          .split(/\n|,/)
          .map(function (line) {
            return line.trim()
          })
          .filter(function (line) {
            return line !== ''
          })
          .forEach(function (line) {
            if (IS_SECTION.test(line)) {
              sections = line.match(IS_SECTION)[1].trim().split(' ')
              sections.forEach(function (section) {
                if (result[section]) {
                  throw new BrowserslistError(
                    'Duplicate section ' + section + ' in Browserslist config'
                  )
                }
                result[section] = []
              })
            } else {
              sections.forEach(function (section) {
                result[section].push(line)
              })
            }
          })
        return result
      },
      readConfig: function readConfig(file) {
        if (!isFile(file)) {
          throw new BrowserslistError("Can't read " + file + ' config')
        }
        return module.exports.parseConfig(fs.readFileSync(file))
      },
      findConfigFile: function findConfigFile(from) {
        return eachParent(
          from,
          function (dir) {
            const config = path.join(dir, 'browserslist')
            const pkg = path.join(dir, 'package.json')
            const rc = path.join(dir, '.browserslistrc')
            let pkgBrowserslist
            if (isFile(pkg)) {
              try {
                pkgBrowserslist = parsePackage(pkg)
              } catch (e) {
                if (e.name === 'BrowserslistError') {
                  throw e
                }
                console.warn(
                  '[Browserslist] Could not parse ' + pkg + '. Ignoring it.'
                )
              }
            }
            if (isFile(config) && pkgBrowserslist) {
              throw new BrowserslistError(
                dir +
                  ' contains both browserslist and package.json with browsers'
              )
            } else if (isFile(rc) && pkgBrowserslist) {
              throw new BrowserslistError(
                dir +
                  ' contains both .browserslistrc and package.json with browsers'
              )
            } else if (isFile(config) && isFile(rc)) {
              throw new BrowserslistError(
                dir + ' contains both .browserslistrc and browserslist'
              )
            } else if (isFile(config)) {
              return config
            } else if (isFile(rc)) {
              return rc
            } else if (pkgBrowserslist) {
              return pkg
            }
          },
          configPathCache
        )
      },
      findConfig: function findConfig(from) {
        const configFile = this.findConfigFile(from)
        return configFile ? parsePackageOrReadConfig(configFile) : undefined
      },
      clearCaches: function clearCaches() {
        dataTimeChecked = false
        statCache = {}
        configPathCache = {}
        parseConfigCache = {}
        this.cache = {}
      },
      oldDataWarning: function oldDataWarning(agentsObj) {
        if (dataTimeChecked) {
          return
        }
        dataTimeChecked = true
        if (process.env.BROWSERSLIST_IGNORE_OLD_DATA) {
          return
        }
        const latest = latestReleaseTime(agentsObj)
        const monthsPassed = getMonthsPassed(latest)
        if (latest !== 0 && monthsPassed >= 6) {
          const months =
            monthsPassed + ' ' + (monthsPassed > 1 ? 'months' : 'month')
          console.warn(
            'Browserslist: browsers data (caniuse-lite) is ' +
              months +
              ' old. Please run:\n' +
              '  npx update-browserslist-db@latest\n' +
              '  Why you should do it regularly: ' +
              'https://github.com/browserslist/update-db#readme'
          )
        }
      },
      currentNode: function currentNode() {
        return 'node ' + process.versions.node
      },
      env: process.env
    }
  })(node)
  return node.exports
}

let parse
let hasRequiredParse
function requireParse() {
  if (hasRequiredParse) {
    return parse
  }
  hasRequiredParse = 1
  const AND_REGEXP = /^\s+and\s+(.*)/i
  const OR_REGEXP = /^(?:,\s*|\s+or\s+)(.*)/i
  function flatten(array) {
    if (!Array.isArray(array)) {
      return [array]
    }
    return array.reduce(function (a, b) {
      return a.concat(flatten(b))
    }, [])
  }
  function find(string, predicate) {
    for (let max = string.length, n = 1; n <= max; n++) {
      const parsed = string.substr(-n, n)
      if (predicate(parsed, n, max)) {
        return string.slice(0, -n)
      }
    }
    return ''
  }
  function matchQuery(all, query) {
    const node = {
      query: query
    }
    if (query.indexOf('not ') === 0) {
      node.not = true
      query = query.slice(4)
    }
    for (const name in all) {
      const type = all[name]
      const match = query.match(type.regexp)
      if (match) {
        node.type = name
        for (let i = 0; i < type.matches.length; i++) {
          node[type.matches[i]] = match[i + 1]
        }
        return node
      }
    }
    node.type = 'unknown'
    return node
  }
  function matchBlock(all, string, qs) {
    let node
    return find(string, function (parsed, n, max) {
      if (AND_REGEXP.test(parsed)) {
        node = matchQuery(all, parsed.match(AND_REGEXP)[1])
        node.compose = 'and'
        qs.unshift(node)
        return true
      } else if (OR_REGEXP.test(parsed)) {
        node = matchQuery(all, parsed.match(OR_REGEXP)[1])
        node.compose = 'or'
        qs.unshift(node)
        return true
      } else if (n === max) {
        node = matchQuery(all, parsed.trim())
        node.compose = 'or'
        qs.unshift(node)
        return true
      }
      return false
    })
  }
  parse = function parse(all, queries) {
    if (!Array.isArray(queries)) {
      queries = [queries]
    }
    return flatten(
      queries.map(function (block) {
        const qs = []
        do {
          block = matchBlock(all, block, qs)
        } while (block)
        return qs
      })
    )
  }
  return parse
}

let browserslist_1
let hasRequiredBrowserslist
function requireBrowserslist() {
  if (hasRequiredBrowserslist) {
    return browserslist_1
  }
  hasRequiredBrowserslist = 1
  const jsReleases = require$$0
  const agents = requireAgents().agents
  const e2c = requireVersions()
  const jsEOL = require$$3
  const path = require$$0$5
  const BrowserslistError = requireError()
  const env = requireNode()
  const parseWithoutCache = requireParse() // Will load browser.js in webpack

  const YEAR = 365.259641 * 24 * 60 * 60 * 1000
  const ANDROID_EVERGREEN_FIRST = '37'
  const OP_MOB_BLINK_FIRST = 14

  // Helpers

  function isVersionsMatch(versionA, versionB) {
    return (versionA + '.').indexOf(versionB + '.') === 0
  }
  function isEolReleased(name) {
    const version = name.slice(1)
    return browserslist.nodeVersions.some(function (i) {
      return isVersionsMatch(i, version)
    })
  }
  function normalize(versions) {
    return versions.filter(function (version) {
      return typeof version === 'string'
    })
  }
  function normalizeElectron(version) {
    let versionToUse = version
    if (version.split('.').length === 3) {
      versionToUse = version.split('.').slice(0, -1).join('.')
    }
    return versionToUse
  }
  function nameMapper(name) {
    return function mapName(version) {
      return name + ' ' + version
    }
  }
  function getMajor(version) {
    return parseInt(version.split('.')[0])
  }
  function getMajorVersions(released, number) {
    if (released.length === 0) {
      return []
    }
    const majorVersions = uniq(released.map(getMajor))
    const minimum = majorVersions[majorVersions.length - number]
    if (!minimum) {
      return released
    }
    const selected = []
    for (let i = released.length - 1; i >= 0; i--) {
      if (minimum > getMajor(released[i])) {
        break
      }
      selected.unshift(released[i])
    }
    return selected
  }
  function uniq(array) {
    const filtered = []
    for (let i = 0; i < array.length; i++) {
      if (filtered.indexOf(array[i]) === -1) {
        filtered.push(array[i])
      }
    }
    return filtered
  }
  function fillUsage(result, name, data) {
    for (const i in data) {
      result[name + ' ' + i] = data[i]
    }
  }
  function generateFilter(sign, version) {
    version = parseFloat(version)
    if (sign === '>') {
      return function (v) {
        return parseLatestFloat(v) > version
      }
    } else if (sign === '>=') {
      return function (v) {
        return parseLatestFloat(v) >= version
      }
    } else if (sign === '<') {
      return function (v) {
        return parseFloat(v) < version
      }
    } else {
      return function (v) {
        return parseFloat(v) <= version
      }
    }
    function parseLatestFloat(v) {
      return parseFloat(v.split('-')[1] || v)
    }
  }
  function generateSemverFilter(sign, version) {
    version = version.split('.').map(parseSimpleInt)
    version[1] = version[1] || 0
    version[2] = version[2] || 0
    if (sign === '>') {
      return function (v) {
        v = v.split('.').map(parseSimpleInt)
        return compareSemver(v, version) > 0
      }
    } else if (sign === '>=') {
      return function (v) {
        v = v.split('.').map(parseSimpleInt)
        return compareSemver(v, version) >= 0
      }
    } else if (sign === '<') {
      return function (v) {
        v = v.split('.').map(parseSimpleInt)
        return compareSemver(version, v) > 0
      }
    } else {
      return function (v) {
        v = v.split('.').map(parseSimpleInt)
        return compareSemver(version, v) >= 0
      }
    }
  }
  function parseSimpleInt(x) {
    return parseInt(x)
  }
  function compare(a, b) {
    if (a < b) {
      return -1
    }
    if (a > b) {
      return 1
    }
    return 0
  }
  function compareSemver(a, b) {
    return (
      compare(parseInt(a[0]), parseInt(b[0])) ||
      compare(parseInt(a[1] || '0'), parseInt(b[1] || '0')) ||
      compare(parseInt(a[2] || '0'), parseInt(b[2] || '0'))
    )
  }

  // this follows the npm-like semver behavior
  function semverFilterLoose(operator, range) {
    range = range.split('.').map(parseSimpleInt)
    if (typeof range[1] === 'undefined') {
      range[1] = 'x'
    }
    // ignore any patch version because we only return minor versions
    // range[2] = 'x'
    switch (operator) {
      case '<=':
        return function (version) {
          version = version.split('.').map(parseSimpleInt)
          return compareSemverLoose(version, range) <= 0
        }
      case '>=':
      default:
        return function (version) {
          version = version.split('.').map(parseSimpleInt)
          return compareSemverLoose(version, range) >= 0
        }
    }
  }

  // this follows the npm-like semver behavior
  function compareSemverLoose(version, range) {
    if (version[0] !== range[0]) {
      return version[0] < range[0] ? -1 : 1
    }
    if (range[1] === 'x') {
      return 0
    }
    if (version[1] !== range[1]) {
      return version[1] < range[1] ? -1 : 1
    }
    return 0
  }
  function resolveVersion(data, version) {
    if (data.versions.indexOf(version) !== -1) {
      return version
    } else if (browserslist.versionAliases[data.name][version]) {
      return browserslist.versionAliases[data.name][version]
    } else {
      return false
    }
  }
  function normalizeVersion(data, version) {
    const resolved = resolveVersion(data, version)
    if (resolved) {
      return resolved
    } else if (data.versions.length === 1) {
      return data.versions[0]
    } else {
      return false
    }
  }
  function filterByYear(since, context) {
    since = since / 1000
    return Object.keys(agents).reduce(function (selected, name) {
      const data = byName(name, context)
      if (!data) {
        return selected
      }
      const versions = Object.keys(data.releaseDate).filter(function (v) {
        const date = data.releaseDate[v]
        return date !== null && date >= since
      })
      return selected.concat(versions.map(nameMapper(data.name)))
    }, [])
  }
  function cloneData(data) {
    return {
      name: data.name,
      versions: data.versions,
      released: data.released,
      releaseDate: data.releaseDate
    }
  }
  function byName(name, context) {
    name = name.toLowerCase()
    name = browserslist.aliases[name] || name
    if (context.mobileToDesktop && browserslist.desktopNames[name]) {
      const desktop = browserslist.data[browserslist.desktopNames[name]]
      if (name === 'android') {
        return normalizeAndroidData(cloneData(browserslist.data[name]), desktop)
      } else {
        const cloned = cloneData(desktop)
        cloned.name = name
        return cloned
      }
    }
    return browserslist.data[name]
  }
  function normalizeAndroidVersions(androidVersions, chromeVersions) {
    const iFirstEvergreen = chromeVersions.indexOf(ANDROID_EVERGREEN_FIRST)
    return androidVersions
      .filter(function (version) {
        return /^(?:[2-4]\.|[34]$)/.test(version)
      })
      .concat(chromeVersions.slice(iFirstEvergreen))
  }
  function copyObject(obj) {
    const copy = {}
    for (const key in obj) {
      copy[key] = obj[key]
    }
    return copy
  }
  function normalizeAndroidData(android, chrome) {
    android.released = normalizeAndroidVersions(
      android.released,
      chrome.released
    )
    android.versions = normalizeAndroidVersions(
      android.versions,
      chrome.versions
    )
    android.releaseDate = copyObject(android.releaseDate)
    android.released.forEach(function (v) {
      if (android.releaseDate[v] === undefined) {
        android.releaseDate[v] = chrome.releaseDate[v]
      }
    })
    return android
  }
  function checkName(name, context) {
    const data = byName(name, context)
    if (!data) {
      throw new BrowserslistError('Unknown browser ' + name)
    }
    return data
  }
  function unknownQuery(query) {
    return new BrowserslistError(
      'Unknown browser query `' +
        query +
        '`. ' +
        'Maybe you are using old Browserslist or made typo in query.'
    )
  }

  // Adjusts last X versions queries for some mobile browsers,
  // where caniuse data jumps from a legacy version to the latest
  function filterJumps(list, name, nVersions, context) {
    let jump = 1
    switch (name) {
      case 'android':
        if (context.mobileToDesktop) {
          return list
        }
        const released = browserslist.data.chrome.released
        jump = released.length - released.indexOf(ANDROID_EVERGREEN_FIRST)
        break
      case 'op_mob':
        const latest = browserslist.data.op_mob.released.slice(-1)[0]
        jump = getMajor(latest) - OP_MOB_BLINK_FIRST + 1
        break
      default:
        return list
    }
    if (nVersions <= jump) {
      return list.slice(-1)
    }
    return list.slice(jump - 1 - nVersions)
  }
  function isSupported(flags, withPartial) {
    return (
      typeof flags === 'string' &&
      (flags.indexOf('y') >= 0 || (withPartial && flags.indexOf('a') >= 0))
    )
  }
  function resolve(queries, context) {
    return parseQueries(queries).reduce(function (result, node, index) {
      if (node.not && index === 0) {
        throw new BrowserslistError(
          'Write any browsers query (for instance, `defaults`) ' +
            'before `' +
            node.query +
            '`'
        )
      }
      const type = QUERIES[node.type]
      const array = type.select
        .call(browserslist, context, node)
        .map(function (j) {
          const parts = j.split(' ')
          if (parts[1] === '0') {
            return parts[0] + ' ' + byName(parts[0], context).versions[0]
          } else {
            return j
          }
        })
      if (node.compose === 'and') {
        if (node.not) {
          return result.filter(function (j) {
            return array.indexOf(j) === -1
          })
        } else {
          return result.filter(function (j) {
            return array.indexOf(j) !== -1
          })
        }
      } else {
        if (node.not) {
          const filter = {}
          array.forEach(function (j) {
            filter[j] = true
          })
          return result.filter(function (j) {
            return !filter[j]
          })
        }
        return result.concat(array)
      }
    }, [])
  }
  function prepareOpts(opts) {
    if (typeof opts === 'undefined') {
      opts = {}
    }
    if (typeof opts.path === 'undefined') {
      opts.path = path.resolve ? path.resolve('.') : '.'
    }
    return opts
  }
  function prepareQueries(queries, opts) {
    if (typeof queries === 'undefined' || queries === null) {
      const config = browserslist.loadConfig(opts)
      if (config) {
        queries = config
      } else {
        queries = browserslist.defaults
      }
    }
    return queries
  }
  function checkQueries(queries) {
    if (!(typeof queries === 'string' || Array.isArray(queries))) {
      throw new BrowserslistError(
        'Browser queries must be an array or string. Got ' +
          typeof queries +
          '.'
      )
    }
  }
  const cache = {}
  const parseCache = {}
  function browserslist(queries, opts) {
    opts = prepareOpts(opts)
    queries = prepareQueries(queries, opts)
    checkQueries(queries)
    const needsPath = parseQueries(queries).some(function (node) {
      return QUERIES[node.type].needsPath
    })
    const context = {
      ignoreUnknownVersions: opts.ignoreUnknownVersions,
      dangerousExtend: opts.dangerousExtend,
      mobileToDesktop: opts.mobileToDesktop,
      env: opts.env
    }
    // Removing to avoid using context.path without marking query as needsPath
    if (needsPath) {
      context.path = opts.path
    }
    env.oldDataWarning(browserslist.data)
    const stats = env.getStat(opts, browserslist.data)
    if (stats) {
      context.customUsage = {}
      for (const browser in stats) {
        fillUsage(context.customUsage, browser, stats[browser])
      }
    }
    const cacheKey = JSON.stringify([queries, context])
    if (cache[cacheKey]) {
      return cache[cacheKey]
    }
    const result = uniq(resolve(queries, context)).sort(
      function (name1, name2) {
        name1 = name1.split(' ')
        name2 = name2.split(' ')
        if (name1[0] === name2[0]) {
          // assumptions on caniuse data
          // 1) version ranges never overlaps
          // 2) if version is not a range, it never contains `-`
          const version1 = name1[1].split('-')[0]
          const version2 = name2[1].split('-')[0]
          return compareSemver(version2.split('.'), version1.split('.'))
        } else {
          return compare(name1[0], name2[0])
        }
      }
    )
    if (!env.env.BROWSERSLIST_DISABLE_CACHE) {
      cache[cacheKey] = result
    }
    return result
  }
  function parseQueries(queries) {
    const cacheKey = JSON.stringify(queries)
    if (cacheKey in parseCache) {
      return parseCache[cacheKey]
    }
    const result = parseWithoutCache(QUERIES, queries)
    if (!env.env.BROWSERSLIST_DISABLE_CACHE) {
      parseCache[cacheKey] = result
    }
    return result
  }
  browserslist.parse = function (queries, opts) {
    opts = prepareOpts(opts)
    queries = prepareQueries(queries, opts)
    checkQueries(queries)
    return parseQueries(queries)
  }

  // Will be filled by Can I Use data below
  browserslist.cache = {}
  browserslist.data = {}
  browserslist.usage = {
    global: {},
    custom: null
  }

  // Default browsers query
  browserslist.defaults = [
    '> 0.5%',
    'last 2 versions',
    'Firefox ESR',
    'not dead'
  ]

  // Browser names aliases
  browserslist.aliases = {
    fx: 'firefox',
    ff: 'firefox',
    ios: 'ios_saf',
    explorer: 'ie',
    blackberry: 'bb',
    explorermobile: 'ie_mob',
    operamini: 'op_mini',
    operamobile: 'op_mob',
    chromeandroid: 'and_chr',
    firefoxandroid: 'and_ff',
    ucandroid: 'and_uc',
    qqandroid: 'and_qq'
  }

  // Can I Use only provides a few versions for some browsers (e.g. and_chr).
  // Fallback to a similar browser for unknown versions
  // Note op_mob is not included as its chromium versions are not in sync with Opera desktop
  browserslist.desktopNames = {
    and_chr: 'chrome',
    and_ff: 'firefox',
    ie_mob: 'ie',
    android: 'chrome' // has extra processing logic
  }

  // Aliases to work with joined versions like `ios_saf 7.0-7.1`
  browserslist.versionAliases = {}
  browserslist.clearCaches = env.clearCaches
  browserslist.parseConfig = env.parseConfig
  browserslist.readConfig = env.readConfig
  browserslist.findConfigFile = env.findConfigFile
  browserslist.findConfig = env.findConfig
  browserslist.loadConfig = env.loadConfig
  browserslist.coverage = function (browsers, stats) {
    let data
    if (typeof stats === 'undefined') {
      data = browserslist.usage.global
    } else if (stats === 'my stats') {
      const opts = {}
      opts.path = path.resolve ? path.resolve('.') : '.'
      const customStats = env.getStat(opts)
      if (!customStats) {
        throw new BrowserslistError('Custom usage statistics was not provided')
      }
      data = {}
      for (const browser in customStats) {
        fillUsage(data, browser, customStats[browser])
      }
    } else if (typeof stats === 'string') {
      if (stats.length > 2) {
        stats = stats.toLowerCase()
      } else {
        stats = stats.toUpperCase()
      }
      env.loadCountry(browserslist.usage, stats, browserslist.data)
      data = browserslist.usage[stats]
    } else {
      if ('dataByBrowser' in stats) {
        stats = stats.dataByBrowser
      }
      data = {}
      for (const name in stats) {
        for (const version in stats[name]) {
          data[name + ' ' + version] = stats[name][version]
        }
      }
    }
    return browsers.reduce(function (all, i) {
      let usage = data[i]
      if (usage === undefined) {
        usage = data[i.replace(/ \S+$/, ' 0')]
      }
      return all + (usage || 0)
    }, 0)
  }
  function nodeQuery(context, node) {
    const matched = browserslist.nodeVersions.filter(function (i) {
      return isVersionsMatch(i, node.version)
    })
    if (matched.length === 0) {
      if (context.ignoreUnknownVersions) {
        return []
      } else {
        throw new BrowserslistError(
          'Unknown version ' + node.version + ' of Node.js'
        )
      }
    }
    return ['node ' + matched[matched.length - 1]]
  }
  function sinceQuery(context, node) {
    const year = parseInt(node.year)
    const month = parseInt(node.month || '01') - 1
    const day = parseInt(node.day || '01')
    return filterByYear(Date.UTC(year, month, day, 0, 0, 0), context)
  }
  function coverQuery(context, node) {
    const coverage = parseFloat(node.coverage)
    let usage = browserslist.usage.global
    if (node.place) {
      if (node.place.match(/^my\s+stats$/i)) {
        if (!context.customUsage) {
          throw new BrowserslistError(
            'Custom usage statistics was not provided'
          )
        }
        usage = context.customUsage
      } else {
        let place
        if (node.place.length === 2) {
          place = node.place.toUpperCase()
        } else {
          place = node.place.toLowerCase()
        }
        env.loadCountry(browserslist.usage, place, browserslist.data)
        usage = browserslist.usage[place]
      }
    }
    const versions = Object.keys(usage).sort(function (a, b) {
      return usage[b] - usage[a]
    })
    let coveraged = 0
    const result = []
    let version
    for (let i = 0; i < versions.length; i++) {
      version = versions[i]
      if (usage[version] === 0) {
        break
      }
      coveraged += usage[version]
      result.push(version)
      if (coveraged >= coverage) {
        break
      }
    }
    return result
  }
  const QUERIES = {
    last_major_versions: {
      matches: ['versions'],
      regexp: /^last\s+(\d+)\s+major\s+versions?$/i,
      select: function (context, node) {
        return Object.keys(agents).reduce(function (selected, name) {
          const data = byName(name, context)
          if (!data) {
            return selected
          }
          let list = getMajorVersions(data.released, node.versions)
          list = list.map(nameMapper(data.name))
          list = filterJumps(list, data.name, node.versions, context)
          return selected.concat(list)
        }, [])
      }
    },
    last_versions: {
      matches: ['versions'],
      regexp: /^last\s+(\d+)\s+versions?$/i,
      select: function (context, node) {
        return Object.keys(agents).reduce(function (selected, name) {
          const data = byName(name, context)
          if (!data) {
            return selected
          }
          let list = data.released.slice(-node.versions)
          list = list.map(nameMapper(data.name))
          list = filterJumps(list, data.name, node.versions, context)
          return selected.concat(list)
        }, [])
      }
    },
    last_electron_major_versions: {
      matches: ['versions'],
      regexp: /^last\s+(\d+)\s+electron\s+major\s+versions?$/i,
      select: function (context, node) {
        const validVersions = getMajorVersions(Object.keys(e2c), node.versions)
        return validVersions.map(function (i) {
          return 'chrome ' + e2c[i]
        })
      }
    },
    last_node_major_versions: {
      matches: ['versions'],
      regexp: /^last\s+(\d+)\s+node\s+major\s+versions?$/i,
      select: function (context, node) {
        return getMajorVersions(browserslist.nodeVersions, node.versions).map(
          function (version) {
            return 'node ' + version
          }
        )
      }
    },
    last_browser_major_versions: {
      matches: ['versions', 'browser'],
      regexp: /^last\s+(\d+)\s+(\w+)\s+major\s+versions?$/i,
      select: function (context, node) {
        const data = checkName(node.browser, context)
        const validVersions = getMajorVersions(data.released, node.versions)
        let list = validVersions.map(nameMapper(data.name))
        list = filterJumps(list, data.name, node.versions, context)
        return list
      }
    },
    last_electron_versions: {
      matches: ['versions'],
      regexp: /^last\s+(\d+)\s+electron\s+versions?$/i,
      select: function (context, node) {
        return Object.keys(e2c)
          .slice(-node.versions)
          .map(function (i) {
            return 'chrome ' + e2c[i]
          })
      }
    },
    last_node_versions: {
      matches: ['versions'],
      regexp: /^last\s+(\d+)\s+node\s+versions?$/i,
      select: function (context, node) {
        return browserslist.nodeVersions
          .slice(-node.versions)
          .map(function (version) {
            return 'node ' + version
          })
      }
    },
    last_browser_versions: {
      matches: ['versions', 'browser'],
      regexp: /^last\s+(\d+)\s+(\w+)\s+versions?$/i,
      select: function (context, node) {
        const data = checkName(node.browser, context)
        let list = data.released
          .slice(-node.versions)
          .map(nameMapper(data.name))
        list = filterJumps(list, data.name, node.versions, context)
        return list
      }
    },
    unreleased_versions: {
      matches: [],
      regexp: /^unreleased\s+versions$/i,
      select: function (context) {
        return Object.keys(agents).reduce(function (selected, name) {
          const data = byName(name, context)
          if (!data) {
            return selected
          }
          let list = data.versions.filter(function (v) {
            return data.released.indexOf(v) === -1
          })
          list = list.map(nameMapper(data.name))
          return selected.concat(list)
        }, [])
      }
    },
    unreleased_electron_versions: {
      matches: [],
      regexp: /^unreleased\s+electron\s+versions?$/i,
      select: function () {
        return []
      }
    },
    unreleased_browser_versions: {
      matches: ['browser'],
      regexp: /^unreleased\s+(\w+)\s+versions?$/i,
      select: function (context, node) {
        const data = checkName(node.browser, context)
        return data.versions
          .filter(function (v) {
            return data.released.indexOf(v) === -1
          })
          .map(nameMapper(data.name))
      }
    },
    last_years: {
      matches: ['years'],
      regexp: /^last\s+(\d*.?\d+)\s+years?$/i,
      select: function (context, node) {
        return filterByYear(Date.now() - YEAR * node.years, context)
      }
    },
    since_y: {
      matches: ['year'],
      regexp: /^since (\d+)$/i,
      select: sinceQuery
    },
    since_y_m: {
      matches: ['year', 'month'],
      regexp: /^since (\d+)-(\d+)$/i,
      select: sinceQuery
    },
    since_y_m_d: {
      matches: ['year', 'month', 'day'],
      regexp: /^since (\d+)-(\d+)-(\d+)$/i,
      select: sinceQuery
    },
    popularity: {
      matches: ['sign', 'popularity'],
      regexp: /^(>=?|<=?)\s*(\d+|\d+\.\d+|\.\d+)%$/,
      select: function (context, node) {
        const popularity = parseFloat(node.popularity)
        const usage = browserslist.usage.global
        return Object.keys(usage).reduce(function (result, version) {
          if (node.sign === '>') {
            if (usage[version] > popularity) {
              result.push(version)
            }
          } else if (node.sign === '<') {
            if (usage[version] < popularity) {
              result.push(version)
            }
          } else if (node.sign === '<=') {
            if (usage[version] <= popularity) {
              result.push(version)
            }
          } else if (usage[version] >= popularity) {
            result.push(version)
          }
          return result
        }, [])
      }
    },
    popularity_in_my_stats: {
      matches: ['sign', 'popularity'],
      regexp: /^(>=?|<=?)\s*(\d+|\d+\.\d+|\.\d+)%\s+in\s+my\s+stats$/,
      select: function (context, node) {
        const popularity = parseFloat(node.popularity)
        if (!context.customUsage) {
          throw new BrowserslistError(
            'Custom usage statistics was not provided'
          )
        }
        const usage = context.customUsage
        return Object.keys(usage).reduce(function (result, version) {
          const percentage = usage[version]
          if (percentage == null) {
            return result
          }
          if (node.sign === '>') {
            if (percentage > popularity) {
              result.push(version)
            }
          } else if (node.sign === '<') {
            if (percentage < popularity) {
              result.push(version)
            }
          } else if (node.sign === '<=') {
            if (percentage <= popularity) {
              result.push(version)
            }
          } else if (percentage >= popularity) {
            result.push(version)
          }
          return result
        }, [])
      }
    },
    popularity_in_config_stats: {
      matches: ['sign', 'popularity', 'config'],
      regexp: /^(>=?|<=?)\s*(\d+|\d+\.\d+|\.\d+)%\s+in\s+(\S+)\s+stats$/,
      select: function (context, node) {
        const popularity = parseFloat(node.popularity)
        const stats = env.loadStat(context, node.config, browserslist.data)
        if (stats) {
          context.customUsage = {}
          for (const browser in stats) {
            fillUsage(context.customUsage, browser, stats[browser])
          }
        }
        if (!context.customUsage) {
          throw new BrowserslistError(
            'Custom usage statistics was not provided'
          )
        }
        const usage = context.customUsage
        return Object.keys(usage).reduce(function (result, version) {
          const percentage = usage[version]
          if (percentage == null) {
            return result
          }
          if (node.sign === '>') {
            if (percentage > popularity) {
              result.push(version)
            }
          } else if (node.sign === '<') {
            if (percentage < popularity) {
              result.push(version)
            }
          } else if (node.sign === '<=') {
            if (percentage <= popularity) {
              result.push(version)
            }
          } else if (percentage >= popularity) {
            result.push(version)
          }
          return result
        }, [])
      }
    },
    popularity_in_place: {
      matches: ['sign', 'popularity', 'place'],
      regexp: /^(>=?|<=?)\s*(\d+|\d+\.\d+|\.\d+)%\s+in\s+((alt-)?\w\w)$/,
      select: function (context, node) {
        const popularity = parseFloat(node.popularity)
        let place = node.place
        if (place.length === 2) {
          place = place.toUpperCase()
        } else {
          place = place.toLowerCase()
        }
        env.loadCountry(browserslist.usage, place, browserslist.data)
        const usage = browserslist.usage[place]
        return Object.keys(usage).reduce(function (result, version) {
          const percentage = usage[version]
          if (percentage == null) {
            return result
          }
          if (node.sign === '>') {
            if (percentage > popularity) {
              result.push(version)
            }
          } else if (node.sign === '<') {
            if (percentage < popularity) {
              result.push(version)
            }
          } else if (node.sign === '<=') {
            if (percentage <= popularity) {
              result.push(version)
            }
          } else if (percentage >= popularity) {
            result.push(version)
          }
          return result
        }, [])
      }
    },
    cover: {
      matches: ['coverage'],
      regexp: /^cover\s+(\d+|\d+\.\d+|\.\d+)%$/i,
      select: coverQuery
    },
    cover_in: {
      matches: ['coverage', 'place'],
      regexp:
        /^cover\s+(\d+|\d+\.\d+|\.\d+)%\s+in\s+(my\s+stats|(alt-)?\w\w)$/i,
      select: coverQuery
    },
    supports: {
      matches: ['supportType', 'feature'],
      regexp: /^(?:(fully|partially)\s+)?supports\s+([\w-]+)$/,
      select: function (context, node) {
        env.loadFeature(browserslist.cache, node.feature)
        const withPartial = node.supportType !== 'fully'
        const features = browserslist.cache[node.feature]
        const result = []
        for (const name in features) {
          const data = byName(name, context)
          // Only check desktop when latest released mobile has support
          let iMax = data.released.length - 1
          while (iMax >= 0) {
            if (data.released[iMax] in features[name]) {
              break
            }
            iMax--
          }
          const checkDesktop =
            context.mobileToDesktop &&
            name in browserslist.desktopNames &&
            isSupported(features[name][data.released[iMax]], withPartial)
          data.versions.forEach(function (version) {
            let flags = features[name][version]
            if (flags === undefined && checkDesktop) {
              flags = features[browserslist.desktopNames[name]][version]
            }
            if (isSupported(flags, withPartial)) {
              result.push(name + ' ' + version)
            }
          })
        }
        return result
      }
    },
    electron_range: {
      matches: ['from', 'to'],
      regexp: /^electron\s+([\d.]+)\s*-\s*([\d.]+)$/i,
      select: function (context, node) {
        const fromToUse = normalizeElectron(node.from)
        const toToUse = normalizeElectron(node.to)
        const from = parseFloat(node.from)
        const to = parseFloat(node.to)
        if (!e2c[fromToUse]) {
          throw new BrowserslistError(
            'Unknown version ' + from + ' of electron'
          )
        }
        if (!e2c[toToUse]) {
          throw new BrowserslistError('Unknown version ' + to + ' of electron')
        }
        return Object.keys(e2c)
          .filter(function (i) {
            const parsed = parseFloat(i)
            return parsed >= from && parsed <= to
          })
          .map(function (i) {
            return 'chrome ' + e2c[i]
          })
      }
    },
    node_range: {
      matches: ['from', 'to'],
      regexp: /^node\s+([\d.]+)\s*-\s*([\d.]+)$/i,
      select: function (context, node) {
        return browserslist.nodeVersions
          .filter(semverFilterLoose('>=', node.from))
          .filter(semverFilterLoose('<=', node.to))
          .map(function (v) {
            return 'node ' + v
          })
      }
    },
    browser_range: {
      matches: ['browser', 'from', 'to'],
      regexp: /^(\w+)\s+([\d.]+)\s*-\s*([\d.]+)$/i,
      select: function (context, node) {
        const data = checkName(node.browser, context)
        const from = parseFloat(normalizeVersion(data, node.from) || node.from)
        const to = parseFloat(normalizeVersion(data, node.to) || node.to)
        function filter(v) {
          const parsed = parseFloat(v)
          return parsed >= from && parsed <= to
        }
        return data.released.filter(filter).map(nameMapper(data.name))
      }
    },
    electron_ray: {
      matches: ['sign', 'version'],
      regexp: /^electron\s*(>=?|<=?)\s*([\d.]+)$/i,
      select: function (context, node) {
        const versionToUse = normalizeElectron(node.version)
        return Object.keys(e2c)
          .filter(generateFilter(node.sign, versionToUse))
          .map(function (i) {
            return 'chrome ' + e2c[i]
          })
      }
    },
    node_ray: {
      matches: ['sign', 'version'],
      regexp: /^node\s*(>=?|<=?)\s*([\d.]+)$/i,
      select: function (context, node) {
        return browserslist.nodeVersions
          .filter(generateSemverFilter(node.sign, node.version))
          .map(function (v) {
            return 'node ' + v
          })
      }
    },
    browser_ray: {
      matches: ['browser', 'sign', 'version'],
      regexp: /^(\w+)\s*(>=?|<=?)\s*([\d.]+)$/,
      select: function (context, node) {
        let version = node.version
        const data = checkName(node.browser, context)
        const alias = browserslist.versionAliases[data.name][version]
        if (alias) {
          version = alias
        }
        return data.released
          .filter(generateFilter(node.sign, version))
          .map(function (v) {
            return data.name + ' ' + v
          })
      }
    },
    firefox_esr: {
      matches: [],
      regexp: /^(firefox|ff|fx)\s+esr$/i,
      select: function () {
        return ['firefox 128']
      }
    },
    opera_mini_all: {
      matches: [],
      regexp: /(operamini|op_mini)\s+all/i,
      select: function () {
        return ['op_mini all']
      }
    },
    electron_version: {
      matches: ['version'],
      regexp: /^electron\s+([\d.]+)$/i,
      select: function (context, node) {
        const versionToUse = normalizeElectron(node.version)
        const chrome = e2c[versionToUse]
        if (!chrome) {
          throw new BrowserslistError(
            'Unknown version ' + node.version + ' of electron'
          )
        }
        return ['chrome ' + chrome]
      }
    },
    node_major_version: {
      matches: ['version'],
      regexp: /^node\s+(\d+)$/i,
      select: nodeQuery
    },
    node_minor_version: {
      matches: ['version'],
      regexp: /^node\s+(\d+\.\d+)$/i,
      select: nodeQuery
    },
    node_patch_version: {
      matches: ['version'],
      regexp: /^node\s+(\d+\.\d+\.\d+)$/i,
      select: nodeQuery
    },
    current_node: {
      matches: [],
      regexp: /^current\s+node$/i,
      select: function (context) {
        return [env.currentNode(resolve, context)]
      }
    },
    maintained_node: {
      matches: [],
      regexp: /^maintained\s+node\s+versions$/i,
      select: function (context) {
        const now = Date.now()
        const queries = Object.keys(jsEOL)
          .filter(function (key) {
            return (
              now < Date.parse(jsEOL[key].end) &&
              now > Date.parse(jsEOL[key].start) &&
              isEolReleased(key)
            )
          })
          .map(function (key) {
            return 'node ' + key.slice(1)
          })
        return resolve(queries, context)
      }
    },
    phantomjs_1_9: {
      matches: [],
      regexp: /^phantomjs\s+1.9$/i,
      select: function () {
        return ['safari 5']
      }
    },
    phantomjs_2_1: {
      matches: [],
      regexp: /^phantomjs\s+2.1$/i,
      select: function () {
        return ['safari 6']
      }
    },
    browser_version: {
      matches: ['browser', 'version'],
      regexp: /^(\w+)\s+(tp|[\d.]+)$/i,
      select: function (context, node) {
        let version = node.version
        if (/^tp$/i.test(version)) {
          version = 'TP'
        }
        const data = checkName(node.browser, context)
        let alias = normalizeVersion(data, version)
        if (alias) {
          version = alias
        } else {
          if (version.indexOf('.') === -1) {
            alias = version + '.0'
          } else {
            alias = version.replace(/\.0$/, '')
          }
          alias = normalizeVersion(data, alias)
          if (alias) {
            version = alias
          } else if (context.ignoreUnknownVersions) {
            return []
          } else {
            throw new BrowserslistError(
              'Unknown version ' + version + ' of ' + node.browser
            )
          }
        }
        return [data.name + ' ' + version]
      }
    },
    browserslist_config: {
      matches: [],
      regexp: /^browserslist config$/i,
      needsPath: true,
      select: function (context) {
        return browserslist(undefined, context)
      }
    },
    extends: {
      matches: ['config'],
      regexp: /^extends (.+)$/i,
      needsPath: true,
      select: function (context, node) {
        return resolve(env.loadQueries(context, node.config), context)
      }
    },
    defaults: {
      matches: [],
      regexp: /^defaults$/i,
      select: function (context) {
        return resolve(browserslist.defaults, context)
      }
    },
    dead: {
      matches: [],
      regexp: /^dead$/i,
      select: function (context) {
        const dead = [
          'Baidu >= 0',
          'ie <= 11',
          'ie_mob <= 11',
          'bb <= 10',
          'op_mob <= 12.1',
          'samsung 4'
        ]
        return resolve(dead, context)
      }
    },
    unknown: {
      matches: [],
      regexp: /^(\w+)$/i,
      select: function (context, node) {
        if (byName(node.query, context)) {
          throw new BrowserslistError(
            'Specify versions in Browserslist query for browser ' + node.query
          )
        } else {
          throw unknownQuery(node.query)
        }
      }
    }
  }

  // Get and convert Can I Use data
  ;(function () {
    for (const name in agents) {
      const browser = agents[name]
      browserslist.data[name] = {
        name: name,
        versions: normalize(agents[name].versions),
        released: normalize(agents[name].versions.slice(0, -3)),
        releaseDate: agents[name].release_date
      }
      fillUsage(browserslist.usage.global, name, browser.usage_global)
      browserslist.versionAliases[name] = {}
      for (let i = 0; i < browser.versions.length; i++) {
        const full = browser.versions[i]
        if (!full) {
          continue
        }
        if (full.indexOf('-') !== -1) {
          const interval = full.split('-')
          for (let j = 0; j < interval.length; j++) {
            browserslist.versionAliases[name][interval[j]] = full
          }
        }
      }
    }
    browserslist.nodeVersions = jsReleases.map(function (release) {
      return release.version
    })
  })()
  browserslist_1 = browserslist
  return browserslist_1
}

const browserslistExports = requireBrowserslist()

let hyrious__bun_lockb
let hasRequiredHyrious__bun_lockb

function requireHyrious__bun_lockb() {
  if (hasRequiredHyrious__bun_lockb) {
    return hyrious__bun_lockb
  }
  hasRequiredHyrious__bun_lockb = 1

  let _localeCompare
  function localeCompare(x, y) {
    if (_localeCompare === undefined) {
      // Lazily call new Intl.Collator() because in Node it can take 10-14ms.
      _localeCompare = new Intl.Collator().compare
    }
    return _localeCompare(x, y)
  }

  function assert(truthy, message = 'assert failed') {
    if (truthy) {
      return
    }
    throw new TypeError(message)
  }

  function base64(a) {
    let ret
    if (a.length < 65535) {
      ret = btoa(String.fromCodePoint.apply(String, a))
    } else {
      ret = ''
      for (const value of a) {
        ret += String.fromCodePoint(value)
      }
      ret = btoa(ret)
    }
    return ret
  }

  function eq(a, b) {
    if (a.byteLength !== b.byteLength) {
      return false
    }
    for (let i = a.byteLength - 1; i >= 0; i--) {
      if (a[i] !== b[i]) {
        return false
      }
    }
    return true
  }

  function fmt_hash(a) {
    if (a.byteLength < 32) {
      throw new TypeError('meta_hash too short')
    }
    let hash = ''
    for (let i = 0; i < 32; i += 1) {
      let c = hex(a[i])
      if (i < 8 || (16 <= i && i < 24)) {
        c = c.toUpperCase()
      }
      hash += c
      if (i < 31 && (i + 1) % 8 === 0) {
        hash += '-'
      }
    }
    return hash
  }

  function fmt_integrity(a) {
    if (a.byteLength < 65) {
      throw new TypeError('integrity too short')
    }
    const tag = a[0]
    a = a.subarray(1)
    let out
    if (tag === 1) {
      out = 'sha1-'
    } else if (tag === 2) {
      out = 'sha256-'
    } else if (tag === 3) {
      out = 'sha384-'
    } else if (tag === 4) {
      out = 'sha512-'
    } else {
      return ''
    }
    out += base64(a)
    return out
  }

  function fmt_resolution(a, buffers) {
    if (a.byteLength < 64) {
      throw new TypeError('resolution too short')
    }
    const tag = a[0]
    const view2 = new DataView(a.buffer, a.byteOffset, a.byteLength)
    let pos = 8
    if (tag === 2 /* npm */) {
      pos += 8
      const major = view2.getUint32((pos += 4) - 4, true)
      const minor = view2.getUint32((pos += 4) - 4, true)
      const patch = view2.getUint32((pos += 4) - 4, true)
      pos += 4
      const version_tag = new Uint8Array(
        view2.buffer,
        view2.byteOffset + pos,
        32
      )
      const pre = str(version_tag.subarray(0, 8), buffers)
      const build = str(version_tag.subarray(16, 24), buffers)
      let v = `${major}.${minor}.${patch}`
      if (pre) {
        v += '-' + pre
      }
      if (build) {
        v += '+' + build
      }
      return v
    }
    if (
      tag === 4 /* folder */ ||
      tag === 8 /* local_tarball */ ||
      tag === 80 /* remote_tarball */ ||
      tag === 72 /* workspace */ ||
      tag === 64 /* symlink */ ||
      tag === 100 /* single_file_module */
    ) {
      let v = str(
        new Uint8Array(view2.buffer, view2.byteOffset + pos, 8),
        buffers
      )
      if (tag === 72 /* workspace */) {
        v = `workspace:${v}`
      }
      if (tag === 64 /* symlink */) {
        v = `link:${v}`
      }
      if (tag === 100 /* single_file_module */) {
        v = `module:${v}`
      }
      return v
    }
    if (
      tag === 32 /* git */ ||
      tag === 16 /* github */ ||
      tag === 24 /* gitlab */
    ) {
      let out =
        tag === 32 /* git */
          ? 'git+'
          : tag === 16 /* github */
            ? 'github:'
            : 'gitlab:'
      const owner = str(
        new Uint8Array(view2.buffer, view2.byteOffset + pos, 8),
        buffers
      )
      const repo = str(
        new Uint8Array(view2.buffer, view2.byteOffset + pos + 8, 8),
        buffers
      )
      if (owner) {
        out += owner + '/'
      } else if (is_scp(repo)) {
        out += 'ssh://'
      }
      out += repo
      pos += 16
      const commitish = str(
        new Uint8Array(view2.buffer, view2.byteOffset + pos, 8),
        buffers
      )
      let resolved = str(
        new Uint8Array(view2.buffer, view2.byteOffset + pos + 8, 8),
        buffers
      )
      if (resolved) {
        out += '#'
        let i = -1
        if ((i = resolved.lastIndexOf('-')) >= 0) {
          resolved = resolved.slice(i + 1)
        }
        out += resolved
      } else if (commitish) {
        out += `#${commitish}`
      }
      return out
    }
    return ''
  }

  function fmt_specs(name, specs, version) {
    specs = Array.from(new Set(specs.map(e => e || `^${version}`))).sort()
    let out = ''
    let comma = false
    for (const spec of specs) {
      const item = `${name}@${spec}`
      if (comma) {
        out += ', '
      }
      out += quote(item)
      comma = true
    }
    return `${out}:`
  }

  function fmt_url(a, buffers) {
    if (a.byteLength < 64) {
      throw new TypeError('resolution too short')
    }
    return a[0] === 2 /* npm */
      ? str(new Uint8Array(a.buffer, a.byteOffset + 8, 8), buffers)
      : fmt_resolution(a, buffers)
  }

  function hex(a) {
    return (256 + a).toString(16).slice(1)
  }

  function is_scp(s) {
    if (s.length < 3) {
      return false
    }
    let at = -1
    for (let i = 0, { length } = s; i < length; i += 1) {
      if (s[i] === '@') {
        if (at < 0) {
          at = i
        }
      } else if (s[i] === ':') {
        if (s.slice(i).startsWith('://')) {
          return false
        }
        return at >= 0 ? i > at + 1 : i > 0
      } else if (s[i] === '/') {
        return at >= 0 && i > at + 1
      }
    }
    return false
  }

  function quote(s) {
    return s.startsWith('true') ||
      s.startsWith('false') ||
      /[:\s\n\\",[\]|\t!]/g.test(s) ||
      /^[0-9]/g.test(s) ||
      !/^[a-zA-Z]/g.test(s)
      ? JSON.stringify(s)
      : s
  }

  function slice(data, a, item) {
    const { 0: off, 1: length } = to_u32(a)
    return Array.from({ length }, (_, i) =>
      data.subarray(item * off + item * i, item * off + item * i + item)
    )
  }

  function str(a, buffers) {
    if ((a[7] & 128) === 0) {
      const i = a.indexOf(0)
      if (i >= 0) {
        a = a.subarray(0, i)
      }
      return new TextDecoder().decode(a)
    }
    const [off, len] = to_u32(a)
    return new TextDecoder().decode(
      buffers.string_bytes.subarray(off, off + (len & 2147483647))
    )
  }

  function to_u32(a) {
    if (a.byteOffset % 4 === 0) {
      return new Uint32Array(a.buffer, a.byteOffset, a.byteLength / 4)
    }
    const view2 = new DataView(a.buffer, a.byteOffset, a.byteLength)
    return Uint32Array.from({ length: a.byteLength / 4 }, (_, i) =>
      view2.getUint32(i * 4, true)
    )
  }

  function parse(buf) {
    let pos = 0
    const view =
      buf instanceof ArrayBuffer
        ? new DataView(buf)
        : new DataView(buf.buffer, buf.byteOffset, buf.byteLength)
    const header_bytes = new TextEncoder().encode(
      '#!/usr/bin/env bun\nbun-lockfile-format-v0\n'
    )
    const u32 = () => {
      if (pos + 4 > view.byteLength) {
        throw new TypeError('too short')
      }
      return view.getUint32((pos += 4) - 4, true)
    }
    const u64 = () => {
      if (pos + 8 > view.byteLength) {
        throw new TypeError('too short')
      }
      const a = view.getUint32((pos += 4) - 4, true)
      const b = view.getUint32((pos += 4) - 4, true)
      return a + b * 2 ** 32
    }
    const read = n => {
      if (pos + n > view.byteLength) {
        throw new TypeError('too short')
      }
      return new Uint8Array(view.buffer, view.byteOffset + (pos += n) - n, n)
    }
    const header_buf = read(header_bytes.byteLength)
    assert(eq(header_buf, header_bytes), 'invalid lockfile')
    const format = u32()
    assert(format === 2, 'outdated lockfile version')
    const meta_hash = read(32)
    const end = u64()
    assert(end <= view.byteLength, 'lockfile is missing data')
    const list_len = u64()
    assert(
      list_len < 2 ** 32,
      'lockfile validation failed: list is impossibly long'
    )
    const input_alignment = u64()
    assert(input_alignment === 8)
    const field_count = u64()
    assert(field_count === 8)
    const begin_at = u64()
    const end_at = u64()
    assert(
      begin_at <= end && end_at <= end && begin_at <= end_at,
      'lockfile validation failed: invalid package list range'
    )
    pos = begin_at
    const packages = Object.entries({
      name: 8,
      name_hash: 8,
      resolution: 64,
      dependencies: 8,
      resolutions: 8,
      meta: 88,
      bin: 20,
      scripts: 48
    }).reduce(
      (list, [field, len]) => {
        const data = read(len * list_len)
        list.forEach((a, i) => {
          a[field] = data.subarray(i * len, i * len + len)
        })
        return list
      },
      Array.from({ length: list_len }, () => ({}))
    )
    pos = end_at
    const buffers = [
      'trees',
      'hoisted_dependencies',
      'resolutions',
      // u32[]
      'dependencies',
      // name(8) + name_hash(8) + behavior(1) + tag(1) + literal(8) = 26[]
      'extern_strings',
      'string_bytes'
    ].reduce((a, key) => {
      const start = u64()
      const end2 = u64()
      pos = start
      a[key] = read(end2 - start)
      pos = end2
      return a
    }, {})
    const requested_versions = Array(list_len)
    requested_versions[0] = []
    for (let i = 1; i < list_len; i += 1) {
      let resolutions = to_u32(buffers.resolutions.subarray())
      let dependencies = buffers.dependencies.subarray()
      let k = -1
      const all_requested_versions = []
      while ((k = resolutions.indexOf(i)) >= 0) {
        all_requested_versions.push(dependencies.subarray(k * 26, k * 26 + 26))
        dependencies = dependencies.subarray(k * 26 + 26)
        resolutions = resolutions.subarray(k + 1)
      }
      requested_versions[i] = all_requested_versions
    }
    let ResolutionTag
    ;(ResolutionTag2 => {
      ResolutionTag2[(ResolutionTag2['uninitialized'] = 0)] = 'uninitialized'
      ResolutionTag2[(ResolutionTag2['root'] = 1)] = 'root'
      ResolutionTag2[(ResolutionTag2['npm'] = 2)] = 'npm'
      ResolutionTag2[(ResolutionTag2['folder'] = 4)] = 'folder'
      ResolutionTag2[(ResolutionTag2['local_tarball'] = 8)] = 'local_tarball'
      ResolutionTag2[(ResolutionTag2['github'] = 16)] = 'github'
      ResolutionTag2[(ResolutionTag2['gitlab'] = 24)] = 'gitlab'
      ResolutionTag2[(ResolutionTag2['git'] = 32)] = 'git'
      ResolutionTag2[(ResolutionTag2['symlink'] = 64)] = 'symlink'
      ResolutionTag2[(ResolutionTag2['workspace'] = 72)] = 'workspace'
      ResolutionTag2[(ResolutionTag2['remote_tarball'] = 80)] = 'remote_tarball'
      ResolutionTag2[(ResolutionTag2['single_file_module'] = 100)] =
        'single_file_module'
    })(ResolutionTag || (ResolutionTag = {}))
    const out = [
      '# THIS IS AN AUTOGENERATED FILE. DO NOT EDIT THIS FILE DIRECTLY.',
      '# yarn lockfile v1',
      `# bun ./bun.lockb --hash: ${fmt_hash(meta_hash)}`,
      ''
    ]
    const order = Array.from({ length: list_len }, (_, i) => i)
      .slice(1)
      .sort((a, b) => {
        const pa = packages[a]
        const pb = packages[b]
        return (
          localeCompare(str(pa.name, buffers), str(pb.name, buffers)) ||
          localeCompare(
            fmt_resolution(pa.resolution, buffers),
            fmt_resolution(pb.resolution, buffers)
          )
        )
      })
    for (const i of order) {
      const a = packages[i]
      const name = str(a.name, buffers)
      const resolution = a.resolution
      const meta = a.meta
      const dependencies = slice(buffers.dependencies, a.dependencies, 26)
      const dependency_versions = requested_versions[i]
      const version = fmt_resolution(resolution, buffers)
      const versions = dependency_versions.map(b =>
        str(b.subarray(18, 18 + 8), buffers)
      )
      const url = fmt_url(resolution, buffers)
      const integrity = fmt_integrity(meta.subarray(20, 85))
      out.push('')
      out.push(fmt_specs(name, versions, version))
      out.push(`  version ${JSON.stringify(version)}`)
      out.push(`  resolved ${JSON.stringify(url)}`)
      if (integrity) {
        out.push(`  integrity ${integrity}`)
      }
      if (dependencies.length > 0) {
        let Behavior
        ;(Behavior2 => {
          Behavior2[(Behavior2['_'] = 0)] = '_'
          Behavior2[(Behavior2['normal'] = 2)] = 'normal'
          Behavior2[(Behavior2['optional'] = 4)] = 'optional'
          Behavior2[(Behavior2['dev'] = 8)] = 'dev'
          Behavior2[(Behavior2['peer'] = 16)] = 'peer'
          Behavior2[(Behavior2['workspace'] = 32)] = 'workspace'
        })(Behavior || (Behavior = {}))
        let behavior = 0 /* _ */
        for (const dependency of dependencies) {
          const dep_behavior = dependency[16]
          if (behavior !== dep_behavior) {
            if ((dep_behavior & 4) /* optional */ > 0) {
              out.push('  optionalDependencies:')
            } else if ((dep_behavior & 2) /* normal */ > 0) {
              out.push('  dependencies:')
            } else if ((dep_behavior & 8) /* dev */ > 0) {
              out.push('  devDependencies:')
            } else {
              continue
            }
            behavior = dep_behavior
          }
          const dep_name = str(dependency.subarray(0, 8), buffers)
          const literal = str(dependency.subarray(18, 18 + 8), buffers)
          out.push(`    ${quote(dep_name)} "${literal}"`)
        }
      }
    }
    out.push('')
    return out.join('\n')
  }

  hyrious__bun_lockb = {
    parse
  }
  return hyrious__bun_lockb
}

const hyrious__bun_lockbExports = /*@__PURE__*/ requireHyrious__bun_lockb()

exports.GraphqlResponseError = GraphqlResponseError
exports.HttpsProxyAgent = HttpsProxyAgent
exports.Octokit = Octokit
exports.RequestError = RequestError
exports.browserslistExports = browserslistExports
exports.configExports = configExports
exports.distExports = distExports$2
exports.distExports$1 = distExports$1
exports.distExports$2 = distExports
exports.graphql2 = graphql2
exports.hyrious__bun_lockbExports = hyrious__bun_lockbExports
exports.ignoreExports = ignoreExports
exports.indentStringExports = indentStringExports
exports.isInteractiveExports = isInteractiveExports
exports.libExports = libExports$4
exports.libExports$1 = libExports$3
exports.libExports$2 = libExports$1
exports.libExports$3 = libExports$2
exports.libExports$4 = libExports
exports.meow = meow
exports.messageWithCauses = messageWithCauses
exports.micromatchExports = micromatchExports
exports.npaExports = npaExports
exports.open = open
exports.packageurlJsExports = packageurlJsExports
exports.semverExports = semverExports
exports.srcExports = srcExports
exports.stackWithCauses = stackWithCauses
exports.terminalLinkExports = terminalLinkExports
exports.updater = updater
exports.yargsParser = yargsParser
exports.yoctocolorsCjsExports = yoctocolorsCjsExports
//# debugId=d8009203-2429-47e6-a0c5-d14b77158759
//# sourceMappingURL=vendor.js.map
