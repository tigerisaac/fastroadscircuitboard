#!/usr/bin/env node
'use strict'

const require$$0 = require('node:url')
const vendor = require('./vendor.js')
const debug = require('../external/@socketsecurity/registry/lib/debug')
const logger = require('../external/@socketsecurity/registry/lib/logger')
const utils = require('./utils.js')
const fs = require('node:fs/promises')
const Module = require('node:module')
const constants = require('./constants.js')
const words = require('../external/@socketsecurity/registry/lib/words')
const fs$1 = require('node:fs')
const path = require('node:path')
const shadowBin = require('./shadow-bin.js')
const prompts = require('../external/@socketsecurity/registry/lib/prompts')
const util = require('node:util')
const arrays = require('../external/@socketsecurity/registry/lib/arrays')
const registry = require('../external/@socketsecurity/registry')
const npm = require('../external/@socketsecurity/registry/lib/npm')
const packages = require('../external/@socketsecurity/registry/lib/packages')
const path$1 = require('../external/@socketsecurity/registry/lib/path')
const regexps = require('../external/@socketsecurity/registry/lib/regexps')
const spawn = require('../external/@socketsecurity/registry/lib/spawn')
const fs$2 = require('../external/@socketsecurity/registry/lib/fs')
const shadowNpmInject = require('./shadow-npm-inject.js')
const objects = require('../external/@socketsecurity/registry/lib/objects')
const registryConstants = require('../external/@socketsecurity/registry/lib/constants')
const promises = require('../external/@socketsecurity/registry/lib/promises')

const _documentCurrentScript =
  typeof document !== 'undefined' ? document.currentScript : null
async function fetchOrgAnalyticsData(time) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.getOrgAnalytics(time.toString()),
    'analytics data'
  )
}

async function fetchRepoAnalyticsData(repo, time) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.getRepoAnalytics(repo, time.toString()),
    'analytics data'
  )
}

// Note: Widgets does not seem to actually work as code :'(

const require$4 = Module.createRequire(
  require$$0.pathToFileURL(__filename).href
)
const METRICS = [
  'total_critical_alerts',
  'total_high_alerts',
  'total_medium_alerts',
  'total_low_alerts',
  'total_critical_added',
  'total_medium_added',
  'total_low_added',
  'total_high_added',
  'total_critical_prevented',
  'total_high_prevented',
  'total_medium_prevented',
  'total_low_prevented'
]

// Note: This maps `new Date(date).getMonth()` to English three letters
const Months = [
  'Jan',
  'Feb',
  'Mar',
  'Apr',
  'May',
  'Jun',
  'Jul',
  'Aug',
  'Sep',
  'Oct',
  'Nov',
  'Dec'
]
async function outputAnalytics(
  result,
  { filePath, outputKind, repo, scope, time }
) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result))
      return
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  if (outputKind === 'json') {
    const serialized = utils.serializeResultJson(result)
    if (filePath) {
      try {
        await fs.writeFile(filePath, serialized, 'utf8')
        logger.logger.error(`Data successfully written to ${filePath}`)
      } catch (e) {
        process.exitCode = 1
        logger.logger.log(
          utils.serializeResultJson({
            ok: false,
            message: 'File Write Failure',
            cause: 'There was an error trying to write the json to disk'
          })
        )
      }
    } else {
      logger.logger.log(serialized)
    }
    return
  }
  const fdata =
    scope === 'org' ? formatDataOrg(result.data) : formatDataRepo(result.data)
  if (outputKind === 'markdown') {
    const serialized = renderMarkdown(fdata, time, repo)

    // TODO: do we want to write to file even if there was an error...?
    if (filePath) {
      try {
        await fs.writeFile(filePath, serialized, 'utf8')
        logger.logger.log(`Data successfully written to ${filePath}`)
      } catch (e) {
        logger.logger.error(e)
      }
    } else {
      logger.logger.log(serialized)
    }
  } else {
    displayAnalyticsScreen(fdata)
  }
}
function renderMarkdown(data, days, repoSlug) {
  return (
    `
# Socket Alert Analytics

These are the Socket.dev analytics for the ${repoSlug ? `${repoSlug} repo` : 'org'} of the past ${days} days

${[
  [
    'Total critical alerts',
    utils.mdTableStringNumber('Date', 'Counts', data['total_critical_alerts'])
  ],
  [
    'Total high alerts',
    utils.mdTableStringNumber('Date', 'Counts', data['total_high_alerts'])
  ],
  [
    'Total critical alerts added to the main branch',
    utils.mdTableStringNumber('Date', 'Counts', data['total_critical_added'])
  ],
  [
    'Total high alerts added to the main branch',
    utils.mdTableStringNumber('Date', 'Counts', data['total_high_added'])
  ],
  [
    'Total critical alerts prevented from the main branch',
    utils.mdTableStringNumber(
      'Date',
      'Counts',
      data['total_critical_prevented']
    )
  ],
  [
    'Total high alerts prevented from the main branch',
    utils.mdTableStringNumber('Date', 'Counts', data['total_high_prevented'])
  ],
  [
    'Total medium alerts prevented from the main branch',
    utils.mdTableStringNumber('Date', 'Counts', data['total_medium_prevented'])
  ],
  [
    'Total low alerts prevented from the main branch',
    utils.mdTableStringNumber('Date', 'Counts', data['total_low_prevented'])
  ]
]
  .map(([title, table]) =>
    `
## ${title}

${table}
`.trim()
  )
  .join('\n\n')}

## Top 5 alert types

${utils.mdTableStringNumber('Name', 'Counts', data['top_five_alert_types'])}
`.trim() + '\n'
  )
}
function displayAnalyticsScreen(data) {
  const ScreenWidget = require$4('../external/blessed/lib/widgets/screen.js')
  // Lazily access constants.blessedOptions.
  const screen = new ScreenWidget({
    ...constants.blessedOptions
  })
  const GridLayout = require$4('../external/blessed-contrib/lib/layout/grid.js')
  const grid = new GridLayout({
    rows: 5,
    cols: 4,
    screen
  })
  renderLineCharts(
    grid,
    screen,
    'Total critical alerts',
    [0, 0, 1, 2],
    data['total_critical_alerts']
  )
  renderLineCharts(
    grid,
    screen,
    'Total high alerts',
    [0, 2, 1, 2],
    data['total_high_alerts']
  )
  renderLineCharts(
    grid,
    screen,
    'Total critical alerts added to the main branch',
    [1, 0, 1, 2],
    data['total_critical_added']
  )
  renderLineCharts(
    grid,
    screen,
    'Total high alerts added to the main branch',
    [1, 2, 1, 2],
    data['total_high_added']
  )
  renderLineCharts(
    grid,
    screen,
    'Total critical alerts prevented from the main branch',
    [2, 0, 1, 2],
    data['total_critical_prevented']
  )
  renderLineCharts(
    grid,
    screen,
    'Total high alerts prevented from the main branch',
    [2, 2, 1, 2],
    data['total_high_prevented']
  )
  renderLineCharts(
    grid,
    screen,
    'Total medium alerts prevented from the main branch',
    [3, 0, 1, 2],
    data['total_medium_prevented']
  )
  renderLineCharts(
    grid,
    screen,
    'Total low alerts prevented from the main branch',
    [3, 2, 1, 2],
    data['total_low_prevented']
  )
  const BarChart = require$4(
    '../external/blessed-contrib/lib/widget/charts/bar.js'
  )
  const bar = grid.set(4, 0, 1, 2, BarChart, {
    label: 'Top 5 alert types',
    barWidth: 10,
    barSpacing: 17,
    xOffset: 0,
    maxHeight: 9,
    barBgColor: 'magenta'
  })
  screen.append(bar) //must append before setting data

  bar.setData({
    titles: Object.keys(data.top_five_alert_types),
    data: Object.values(data.top_five_alert_types)
  })
  screen.render()
  // eslint-disable-next-line n/no-process-exit
  screen.key(['escape', 'q', 'C-c'], () => process.exit(0))
}
function formatDataRepo(data) {
  const sortedTopFiveAlerts = {}
  const totalTopAlerts = {}
  const formattedData = {}
  for (const metric of METRICS) {
    formattedData[metric] = {}
  }
  for (const entry of data) {
    const topFiveAlertTypes = entry['top_five_alert_types']
    for (const type of Object.keys(topFiveAlertTypes)) {
      const count = topFiveAlertTypes[type] ?? 0
      if (!totalTopAlerts[type]) {
        totalTopAlerts[type] = count
      } else if (count > (totalTopAlerts[type] ?? 0)) {
        totalTopAlerts[type] = count
      }
    }
  }
  for (const entry of data) {
    for (const metric of METRICS) {
      formattedData[metric][formatDate(entry['created_at'])] = entry[metric]
    }
  }
  const topFiveAlertEntries = Object.entries(totalTopAlerts)
    .sort(([_keya, a], [_keyb, b]) => b - a)
    .slice(0, 5)
  for (const [key, value] of topFiveAlertEntries) {
    sortedTopFiveAlerts[key] = value
  }
  return {
    ...formattedData,
    top_five_alert_types: sortedTopFiveAlerts
  }
}
function formatDataOrg(data) {
  const sortedTopFiveAlerts = {}
  const totalTopAlerts = {}
  const formattedData = {}
  for (const metric of METRICS) {
    formattedData[metric] = {}
  }
  for (const entry of data) {
    const topFiveAlertTypes = entry['top_five_alert_types']
    for (const type of Object.keys(topFiveAlertTypes)) {
      const count = topFiveAlertTypes[type] ?? 0
      if (!totalTopAlerts[type]) {
        totalTopAlerts[type] = count
      } else {
        totalTopAlerts[type] += count
      }
    }
  }
  for (const metric of METRICS) {
    const formatted = formattedData[metric]
    for (const entry of data) {
      const date = formatDate(entry['created_at'])
      if (!formatted[date]) {
        formatted[date] = entry[metric]
      } else {
        formatted[date] += entry[metric]
      }
    }
  }
  const topFiveAlertEntries = Object.entries(totalTopAlerts)
    .sort(([_keya, a], [_keyb, b]) => b - a)
    .slice(0, 5)
  for (const [key, value] of topFiveAlertEntries) {
    sortedTopFiveAlerts[key] = value
  }
  return {
    ...formattedData,
    top_five_alert_types: sortedTopFiveAlerts
  }
}
function formatDate(date) {
  return `${Months[new Date(date).getMonth()]} ${new Date(date).getDate()}`
}
function renderLineCharts(grid, screen, title, coords, data) {
  const LineChart = require$4(
    '../external/blessed-contrib/lib/widget/charts/line.js'
  )
  const line = grid.set(...coords, LineChart, {
    style: {
      line: 'cyan',
      text: 'cyan',
      baseline: 'black'
    },
    xLabelPadding: 0,
    xPadding: 0,
    xOffset: 0,
    wholeNumbersOnly: true,
    legend: {
      width: 1
    },
    label: title
  })
  screen.append(line)
  const lineData = {
    x: Object.keys(data),
    y: Object.values(data)
  }
  line.setData([lineData])
}

async function handleAnalytics({ filePath, outputKind, repo, scope, time }) {
  let result
  if (scope === 'org') {
    result = await fetchOrgAnalyticsData(time)
  } else if (repo) {
    result = await fetchRepoAnalyticsData(repo, time)
  } else {
    result = {
      ok: false,
      message: 'Missing repository name in command'
    }
  }
  if (result.ok && !result.data.length) {
    result = {
      ok: true,
      message: `The analytics data for this ${scope === 'org' ? 'organization' : 'repository'} is not yet available.`,
      data: []
    }
  }
  await outputAnalytics(result, {
    filePath,
    outputKind,
    repo,
    scope,
    time
  })
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$I } = constants
const config$M = {
  commandName: 'analytics',
  description: `Look up analytics data`,
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    file: {
      type: 'string',
      shortFlag: 'f',
      description:
        'Filepath to save output. Only valid with --json/--markdown. Defaults to stdout.'
    },
    repo: {
      type: 'string',
      shortFlag: 'r',
      default: '',
      description: 'Name of the repository. Only valid when scope=repo'
    },
    scope: {
      type: 'string',
      shortFlag: 's',
      default: 'org',
      description:
        "Scope of the analytics data - either 'org' or 'repo', default: org"
    },
    time: {
      type: 'number',
      shortFlag: 't',
      default: 30,
      description: 'Time filter - either 7, 30 or 90, default: 30'
    }
  },
  help: (command, { flags }) =>
    `
    Usage
      $ ${command} ${utils.isTestingV1() ? '[ org | repo <reponame>] [time]' : '--scope=<scope> --time=<time filter>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: report:write

    ${utils.isTestingV1() ? '' : 'Default parameters are set to show the organization-level analytics over the'}
    ${utils.isTestingV1() ? '' : 'last 30 days.'}

    ${utils.isTestingV1() ? 'The scope is either org or repo level, defaults to org.' : ''}

    ${utils.isTestingV1() ? 'When scope is repo, a repo slug must be given as well.' : ''}

    ${utils.isTestingV1() ? 'The time argument must be number 7, 30, or 90 and defaults to 30.' : ''}

    Options
      ${utils.getFlagListOutput(flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? 'org 7' : '--scope=org --time=7'}
      $ ${command} ${utils.isTestingV1() ? 'repo test-repo 30' : '--scope=org --time=30'}
      $ ${command} ${utils.isTestingV1() ? '90' : '--scope=repo --repo=test-repo --time=30'}
  `
      // Drop consecutive empty lines. Temporarily necessary to deal with v1 prep.
      .replace(/\n(?: *\n)+/g, '\n\n')
}
const cmdAnalytics = {
  description: config$M.description,
  hidden: config$M.hidden,
  run: run$M
}
async function run$M(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$M,
    importMeta,
    parentName
  })
  const { file, json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)

  // In v1 mode support:
  // - []        (no args)
  // - ['org']
  // - ['org', '30']
  // - ['repo', 'name']
  // - ['repo', 'name', '30']
  // - ['30']
  // Validate final values in the next step
  let scope = 'org'
  let time = utils.isTestingV1() ? '30' : 30
  let repoName = ''
  if (utils.isTestingV1()) {
    if (cli.input[0] === 'org') {
      if (cli.input[1]) {
        time = cli.input[1]
      }
    } else if (cli.input[0] === 'repo') {
      scope = 'repo'
      if (cli.input[1]) {
        repoName = cli.input[1]
      }
      if (cli.input[2]) {
        time = cli.input[2]
      }
    } else if (cli.input[0]) {
      time = cli.input[0]
    }
  } else {
    if (cli.flags['scope']) {
      scope = String(cli.flags['scope'] || '')
    }
    if (scope === 'repo') {
      repoName = String(cli.flags['repo'] || '')
    }
    if (cli.flags['time']) {
      time = Number(cli.flags['time'] || 30)
    }
  }
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      // In v1 this can't go wrong anymore since the unknown value goes to time
      nook: !utils.isTestingV1(),
      test: scope === 'org' || scope === 'repo',
      message: 'Scope must be "repo" or "org"',
      pass: 'ok',
      fail: 'bad'
    },
    {
      nook: true,
      // Before v1 there were no args, only flags
      test: utils.isTestingV1() || cli.input.length === 0,
      message: 'This command does not accept any arguments (use flags instead)',
      pass: 'ok',
      fail: `bad`
    },
    {
      nook: true,
      test: scope === 'org' || !!repoName,
      message: utils.isTestingV1()
        ? 'When scope=repo, repo name should be the second argument'
        : 'When scope=repo, repo name should be set through --repo',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test:
        scope === 'org' ||
        !utils.isTestingV1() ||
        (repoName !== '7' && repoName !== '30' && repoName !== '90'),
      message: 'When scope is repo, the second arg should be repo, not time',
      pass: 'ok',
      fail: 'missing'
    },
    {
      test: utils.isTestingV1()
        ? time === '7' || time === '30' || time === '90'
        : time === 7 || time === 30 || time === 90,
      message: 'The time filter must either be 7, 30 or 90',
      pass: 'ok',
      fail: utils.isTestingV1()
        ? 'invalid range set, see --help for command arg details.'
        : 'bad'
    },
    {
      nook: true,
      test: !file || !!json || !!markdown,
      message:
        'The `--file` flag is only valid when using `--json` or `--markdown`',
      pass: 'ok',
      fail: 'bad'
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$I)
    return
  }
  return await handleAnalytics({
    scope,
    time:
      time === '90' || time === 90 ? 90 : time === '30' || time === 30 ? 30 : 7,
    repo: repoName,
    outputKind,
    filePath: String(file || '')
  })
}

async function fetchAuditLog({ logType, orgSlug, outputKind, page, perPage }) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.getAuditLogEvents(orgSlug, {
      // I'm not sure this is used at all.
      outputJson: String(outputKind === 'json'),
      // I'm not sure this is used at all.
      outputMarkdown: String(outputKind === 'markdown'),
      orgSlug,
      type: logType,
      page: String(page),
      per_page: String(perPage)
    }),
    `audit log for ${orgSlug}`
  )
}

const { REDACTED } = constants
async function outputAuditLog(
  auditLogs,
  { logType, orgSlug, outputKind, page, perPage }
) {
  if (!auditLogs.ok) {
    process.exitCode = auditLogs.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(
      await outputAsJson(auditLogs, {
        logType,
        orgSlug,
        page,
        perPage
      })
    )
  } else if (outputKind !== 'markdown' && !auditLogs.ok) {
    logger.logger.fail(
      utils.failMsgWithBadge(auditLogs.message, auditLogs.cause)
    )
  } else {
    logger.logger.log(
      await outputAsMarkdown(auditLogs, {
        logType,
        orgSlug,
        page,
        perPage
      })
    )
  }
}
async function outputAsJson(auditLogs, { logType, orgSlug, page, perPage }) {
  if (!auditLogs.ok) {
    return utils.serializeResultJson(auditLogs)
  }
  return utils.serializeResultJson({
    ok: true,
    data: {
      desc: 'Audit logs for given query',
      // Lazily access constants.ENV.VITEST.
      generated: constants.ENV.VITEST ? REDACTED : new Date().toISOString(),
      org: orgSlug,
      logType,
      page,
      nextPage: auditLogs.data.nextPage,
      perPage,
      logs: auditLogs.data.results.map(log => {
        // Note: The subset is pretty arbitrary
        const {
          created_at,
          event_id,
          ip_address,
          type,
          user_agent,
          user_email
        } = log
        return {
          event_id,
          created_at,
          ip_address,
          type,
          user_agent,
          user_email
        }
      })
    }
  })
}
async function outputAsMarkdown(
  auditLogs,
  { logType, orgSlug, page, perPage }
) {
  if (!auditLogs.ok) {
    return `
# Socket Audit Logs

There was a problem fetching the audit logs:

> ${auditLogs.message}
${
  auditLogs.cause
    ? '>\n' +
      (
        auditLogs.cause
          .split('\n')
          .map(s => `> ${s}\n`)
          .join('') ?? ''
      )
    : ''
}
Parameters:

- org: ${orgSlug}
- type filter: ${logType || '(none)'}
- page: ${page}
- per page: ${perPage}
`
  }
  try {
    const table = utils.mdTable(auditLogs.data.results, [
      'event_id',
      'created_at',
      'type',
      'user_email',
      'ip_address',
      'user_agent'
    ])
    return `
# Socket Audit Logs

These are the Socket.dev audit logs as per requested query.
- org: ${orgSlug}
- type filter: ${logType || '(none)'}
- page: ${page}
- next page: ${auditLogs.data.nextPage}
- per page: ${perPage}
- generated: ${constants.ENV.VITEST ? REDACTED : new Date().toISOString()}

${table}
`
  } catch (e) {
    process.exitCode = 1
    logger.logger.fail(
      'There was a problem converting the logs to Markdown, please try the `--json` flag'
    )
    if (debug.isDebug()) {
      debug.debugLog('Error:\n', e)
    }
    // logger.error(e)
    return ''
  }
}

async function handleAuditLog({ logType, orgSlug, outputKind, page, perPage }) {
  const auditLogs = await fetchAuditLog({
    orgSlug,
    outputKind,
    page,
    perPage,
    logType
  })
  await outputAuditLog(auditLogs, {
    logType,
    orgSlug,
    outputKind,
    page,
    perPage
  })
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$H } = constants
const config$L = {
  commandName: 'audit-log',
  description: 'Look up the audit log for an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    },
    type: {
      type: 'string',
      shortFlag: 't',
      default: '',
      description: 'Type of log event'
    },
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Results per page - default is 30'
    },
    page: {
      type: 'number',
      shortFlag: 'p',
      default: 1,
      description: 'Page number - default is 1'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '<repo>' : '<org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: audit-log:list

    This feature requires an Enterprise Plan. To learn more about getting access
    to this feature and many more, please visit https://socket.dev/pricing

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? '' : 'FakeOrg'}
  `
}
const cmdAuditLog = {
  description: config$L.description,
  hidden: config$L.hidden,
  run: run$L
}
async function run$L(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$L,
    importMeta,
    parentName
  })
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag,
    page,
    perPage,
    type
  } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const logType = String(type || '')
  const [orgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !!orgSlug,
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$H)
    return
  }
  await handleAuditLog({
    orgSlug,
    outputKind,
    page: Number(page || 0),
    perPage: Number(perPage || 0),
    logType: logType.charAt(0).toUpperCase() + logType.slice(1)
  })
}

const {
  NPM: NPM$d,
  NPX: NPX$3,
  PACKAGE_LOCK_JSON,
  PNPM: PNPM$8,
  YARN,
  YARN_LOCK
} = constants
const nodejsPlatformTypes = new Set([
  'javascript',
  'js',
  'nodejs',
  NPM$d,
  PNPM$8,
  'ts',
  'tsx',
  'typescript'
])
async function runCycloneDX(yargvWithYes) {
  let cleanupPackageLock = false
  const { yes, ...yargv } = {
    __proto__: null,
    ...yargvWithYes
  }
  const yesArgs = yes ? ['--yes'] : []
  if (
    yargv.type !== YARN &&
    nodejsPlatformTypes.has(yargv.type) &&
    fs$1.existsSync(`./${YARN_LOCK}`)
  ) {
    if (fs$1.existsSync(`./${PACKAGE_LOCK_JSON}`)) {
      yargv.type = NPM$d
    } else {
      // Use synp to create a package-lock.json from the yarn.lock,
      // based on the node_modules folder, for a more accurate SBOM.
      try {
        await shadowBin(NPX$3, [
          ...yesArgs,
          // Lazily access constants.ENV.INLINED_SYNP_VERSION.
          `synp@${constants.ENV.INLINED_SYNP_VERSION}`,
          '--source-file',
          `./${YARN_LOCK}`
        ])
        yargv.type = NPM$d
        cleanupPackageLock = true
      } catch {}
    }
  }
  await shadowBin(NPX$3, [
    ...yesArgs,
    // Lazily access constants.ENV.INLINED_CYCLONEDX_CDXGEN_VERSION.
    `@cyclonedx/cdxgen@${constants.ENV.INLINED_CYCLONEDX_CDXGEN_VERSION}`,
    ...argvToArray(yargv)
  ])
  if (cleanupPackageLock) {
    try {
      await fs$1.promises.rm(`./${PACKAGE_LOCK_JSON}`)
    } catch {}
  }
  const fullOutputPath = path.join(process.cwd(), yargv.output)
  if (fs$1.existsSync(fullOutputPath)) {
    logger.logger.log(
      vendor.yoctocolorsCjsExports.cyanBright(`${yargv.output} created!`)
    )
  }
}
function argvToArray(argv) {
  if (argv['help']) {
    return ['--help']
  }
  const result = []
  for (const { 0: key, 1: value } of Object.entries(argv)) {
    if (key === '_' || key === '--') {
      continue
    }
    if (key === 'babel' || key === 'install-deps' || key === 'validate') {
      // cdxgen documents no-babel, no-install-deps, and no-validate flags so
      // use them when relevant.
      result.push(`--${value ? key : `no-${key}`}`)
    } else if (value === true) {
      result.push(`--${key}`)
    } else if (typeof value === 'string') {
      result.push(`--${key}`, String(value))
    } else if (Array.isArray(value)) {
      result.push(`--${key}`, ...value.map(String))
    }
  }
  if (argv['--']) {
    result.push('--', ...argv['--'])
  }
  return result
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$G } = constants

// TODO: Convert yargs to meow.
const toLower = arg => arg.toLowerCase()
const arrayToLower = arg => arg.map(toLower)

// npx @cyclonedx/cdxgen@11.2.7 --help
//
// Options:
//   -o, --output                 Output file. Default bom.json                                       [default: "bom.json"]
//   -t, --type                   Project type. Please refer to https://cyclonedx.github.io/cdxgen/#/PROJECT_TYPES for supp
//                                orted languages/platforms.                                                        [array]
//       --exclude-type           Project types to exclude. Please refer to https://cyclonedx.github.io/cdxgen/#/PROJECT_TY
//                                PES for supported languages/platforms.
//   -r, --recurse                Recurse mode suitable for mono-repos. Defaults to true. Pass --no-recurse to disable.
//                                                                                                [boolean] [default: true]
//   -p, --print                  Print the SBOM as a table with tree.                                            [boolean]
//   -c, --resolve-class          Resolve class names for packages. jars only for now.                            [boolean]
//       --deep                   Perform deep searches for components. Useful while scanning C/C++ apps, live OS and oci i
//                                mages.                                                                          [boolean]
//       --server-url             Dependency track url. Eg: https://deptrack.cyclonedx.io
//       --skip-dt-tls-check      Skip TLS certificate check when calling Dependency-Track.      [boolean] [default: false]
//       --api-key                Dependency track api key
//       --project-group          Dependency track project group
//       --project-name           Dependency track project name. Default use the directory name
//       --project-version        Dependency track project version                                   [string] [default: ""]
//       --project-id             Dependency track project id. Either provide the id or the project name and version togeth
//                                er                                                                               [string]
//       --parent-project-id      Dependency track parent project id                                               [string]
//       --required-only          Include only the packages with required scope on the SBOM. Would set compositions.aggrega
//                                te to incomplete unless --no-auto-compositions is passed.                       [boolean]
//       --fail-on-error          Fail if any dependency extractor fails.                                         [boolean]
//       --no-babel               Do not use babel to perform usage analysis for JavaScript/TypeScript projects.  [boolean]
//       --generate-key-and-sign  Generate an RSA public/private key pair and then sign the generated SBOM using JSON Web S
//                                ignatures.                                                                      [boolean]
//       --server                 Run cdxgen as a server                                                          [boolean]
//       --server-host            Listen address                                                     [default: "127.0.0.1"]
//       --server-port            Listen port                                                             [default: "9090"]
//       --install-deps           Install dependencies automatically for some projects. Defaults to true but disabled for c
//                                ontainers and oci scans. Use --no-install-deps to disable this feature.
//                                                                                                [boolean] [default: true]
//       --validate               Validate the generated SBOM using json schema. Defaults to true. Pass --no-validate to di
//                                sable.                                                          [boolean] [default: true]
//       --evidence               Generate SBOM with evidence for supported languages.           [boolean] [default: false]
//       --spec-version           CycloneDX Specification version to use. Defaults to 1.6
//                                                                         [number] [choices: 1.4, 1.5, 1.6] [default: 1.6]
//       --filter                 Filter components containing this word in purl or component.properties.value. Multiple va
//                                lues allowed.                                                                     [array]
//       --only                   Include components only containing this word in purl. Useful to generate BOM with first p
//                                arty components alone. Multiple values allowed.                                   [array]
//       --author                 The person(s) who created the BOM. Set this value if you're intending the modify the BOM
//                                and claim authorship.                               [array] [default: "OWASP Foundation"]
//       --profile                BOM profile to use for generation. Default generic.
//   [choices: "appsec", "research", "operational", "threat-modeling", "license-compliance", "generic", "machine-learning",
//                                                        "ml", "deep-learning", "ml-deep", "ml-tiny"] [default: "generic"]
//       --exclude                Additional glob pattern(s) to ignore                                              [array]
//       --include-formulation    Generate formulation section with git metadata and build tools. Defaults to false.
//                                                                                               [boolean] [default: false]
//       --include-crypto         Include crypto libraries as components.                        [boolean] [default: false]
//       --standard               The list of standards which may consist of regulations, industry or organizational-specif
//                                ic standards, maturity models, best practices, or any other requirements which can be eva
//                                luated against or attested to.
//   [array] [choices: "asvs-5.0", "asvs-4.0.3", "bsimm-v13", "masvs-2.0.0", "nist_ssdf-1.1", "pcissc-secure-slc-1.1", "scv
//                                                                                          s-1.0.0", "ssaf-DRAFT-2023-11"]
//       --json-pretty            Pretty-print the generated BOM json.                           [boolean] [default: false]
//       --min-confidence         Minimum confidence needed for the identity of a component from 0 - 1, where 1 is 100% con
//                                fidence.                                                            [number] [default: 0]
//       --technique              Analysis technique to use
//   [array] [choices: "auto", "source-code-analysis", "binary-analysis", "manifest-analysis", "hash-comparison", "instrume
//                                                                                                    ntation", "filename"]
//       --auto-compositions      Automatically set compositions when the BOM was filtered. Defaults to true
//                                                                                                [boolean] [default: true]
//   -h, --help                   Show help                                                                       [boolean]
//   -v, --version                Show version number                                                             [boolean]

// isSecureMode defined at:
// https://github.com/CycloneDX/cdxgen/blob/v11.2.7/lib/helpers/utils.js#L66
// const isSecureMode =
//   ['true', '1'].includes(process.env?.CDXGEN_SECURE_MODE) ||
//   process.env?.NODE_OPTIONS?.includes('--permission')

// Yargs CDXGEN configuration defined at:
// https://github.com/CycloneDX/cdxgen/blob/v11.2.7/bin/cdxgen.js#L64
const yargsConfig = {
  configuration: {
    'camel-case-expansion': false,
    'greedy-arrays': false,
    'parse-numbers': false,
    'populate--': true,
    'short-option-groups': false,
    'strip-aliased': true,
    'unknown-options-as-args': true
  },
  coerce: {
    'exclude-type': arrayToLower,
    'feature-flags': arrayToLower,
    filter: arrayToLower,
    only: arrayToLower,
    profile: toLower,
    standard: arrayToLower,
    technique: arrayToLower,
    type: arrayToLower
  },
  default: {
    //author: ['OWASP Foundation'],
    //'auto-compositions': true,
    //babel: true,
    //banner: false, // hidden
    //'deps-slices-file': 'deps.slices.json', // hidden
    //evidence: false,
    //'exclude-type': [],
    //'export-proto': true, // hidden
    //'fail-on-error': isSecureMode,
    //'feature-flags': [], // hidden
    //'include-crypto': false,
    //'include-formulation': false,
    //'install-deps': !isSecureMode
    //lifecycle: 'build', // hidden
    //'min-confidence': '0',
    //output: 'bom.json',
    //profile: 'generic',
    //'project-version': '',
    //'proto-bin-file': 'bom.cdx', // hidden
    //recurse: true,
    //'skip-dt-tls-check': false,
    //'semantics-slices-file': 'semantics.slices.json',
    //'server-host': '127.0.0.1',
    //'server-port': '9090',
    //'spec-version': '1.6',
    type: ['js']
    //validate: true,
  },
  alias: {
    help: ['h'],
    output: ['o'],
    print: ['p'],
    recurse: ['r'],
    'resolve-class': ['c'],
    type: ['t'],
    version: ['v'],
    yes: ['y']
  },
  array: [
    {
      key: 'author',
      type: 'string'
    },
    {
      key: 'exclude',
      type: 'string'
    },
    {
      key: 'exclude-type',
      type: 'string'
    },
    {
      key: 'feature-flags',
      type: 'string'
    },
    // hidden
    {
      key: 'filter',
      type: 'string'
    },
    {
      key: 'only',
      type: 'string'
    },
    {
      key: 'standard',
      type: 'string'
    },
    {
      key: 'technique',
      type: 'string'
    },
    {
      key: 'type',
      type: 'string'
    }
  ],
  boolean: [
    'auto-compositions',
    'babel',
    'banner',
    // hidden
    'deep',
    'evidence',
    'export-proto',
    // hidden
    'fail-on-error',
    'generate-key-and-sign',
    'help',
    'include-crypto',
    'include-formulation',
    'install-deps',
    'json-pretty',
    'print',
    'recurse',
    'required-only',
    'resolve-class',
    'skip-dt-tls-check',
    'server',
    'validate',
    'version',
    // The --yes flag and -y alias map to the corresponding flag and alias of npx.
    // https://docs.npmjs.com/cli/v7/commands/npx#compatibility-with-older-npx-versions
    'yes'
  ],
  string: [
    'api-key',
    'data-flow-slices-file',
    // hidden
    'deps-slices-file',
    // hidden
    'evinse-output',
    // hidden
    'lifecycle',
    'min-confidence',
    // number
    'openapi-spec-file',
    // hidden
    'output',
    'parent-project-id',
    'profile',
    'project-group',
    'project-name',
    'project-version',
    'project-id',
    'proto-bin-file',
    // hidden
    'reachables-slices-file',
    // hidden
    'semantics-slices-file',
    // hidden
    'server-host',
    'server-port',
    'server-url',
    'spec-version',
    // number
    'usages-slices-file' // hidden
  ]
}
const config$K = {
  commandName: 'cdxgen',
  description: 'Create an SBOM with CycloneDX generator (cdxgen)',
  hidden: false,
  // Stub out flags and help.
  // TODO: Convert yargs to meow.
  flags: {},
  help: () => ''
}
const cmdCdxgen = {
  description: config$K.description,
  hidden: config$K.hidden,
  run: run$K
}
async function run$K(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    allowUnknownFlags: true,
    // Don't let meow take over --help.
    argv: argv.filter(a => !utils.isHelpFlag(a)),
    config: config$K,
    importMeta,
    parentName
  })

  // TODO: Convert yargs to meow.
  const yargv = {
    ...vendor.yargsParser(argv, yargsConfig)
  }
  const unknown = yargv._
  const { length: unknownLength } = unknown
  if (unknownLength) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2
    logger.logger.fail(
      `Unknown ${words.pluralize('argument', unknownLength)}: ${yargv._.join(', ')}`
    )
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$G)
    return
  }

  // Make 'lifecycle' default to 'pre-build', which also sets 'install-deps' to `false`,
  // to avoid arbitrary code execution on the cdxgen scan.
  // https://github.com/CycloneDX/cdxgen/issues/1328
  if (yargv.lifecycle === undefined) {
    yargv.lifecycle = 'pre-build'
    yargv['install-deps'] = false
    logger.logger.info(
      `Socket set cdxgen --lifecycle to "${yargv.lifecycle}" to avoid arbitrary code execution on this scan.\n  Pass "--lifecycle build" to generate a BOM consisting of information obtained during the build process.\n  See cdxgen ${vendor.terminalLinkExports('BOM lifecycles documentation', 'https://cyclonedx.github.io/cdxgen/#/ADVANCED?id=bom-lifecycles')} for more details.`
    )
  }
  if (yargv.output === undefined) {
    yargv.output = 'socket-cdx.json'
  }
  await runCycloneDX(yargv)
}

// Use the config defaultOrg when set, otherwise discover from remote
async function getDefaultOrgSlug() {
  const defaultOrgResult = utils.getConfigValueOrUndef('defaultOrg')
  if (defaultOrgResult) {
    debug.debugLog(`Using default org: ${defaultOrgResult}`)
    return {
      ok: true,
      data: defaultOrgResult
    }
  }
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  const result = await utils.handleApiCall(
    sockSdk.getOrganizations(),
    'list of organizations'
  )
  if (!result.ok) {
    return result
  }
  const orgs = result.data.organizations
  const keys = Object.keys(orgs)
  if (!keys[0]) {
    return {
      ok: false,
      message: 'Failed to establish identity',
      data: `API did not return any organization associated with the current API token. Unable to continue.`
    }
  }
  const slug = (keys[0] in orgs && orgs?.[keys[0]]?.name) ?? undefined
  if (!slug) {
    return {
      ok: false,
      message: 'Failed to establish identity',
      data: `Was unable to determine the default organization for the current API token. Unable to continue.`
    }
  }
  debug.debugLog(`Resolved org to: ${slug}`)
  return {
    ok: true,
    message: 'Retrieved default org from server',
    data: slug
  }
}

async function fetchCreateOrgFullScan(
  packagePaths,
  orgSlug,
  defaultBranch,
  pendingHead,
  tmp,
  cwd,
  { branchName, commitHash, commitMessage, committers, pullRequest, repoName }
) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.createOrgFullScan(
      orgSlug,
      {
        ...(branchName
          ? {
              branch: branchName
            }
          : {}),
        ...(commitHash
          ? {
              commit_hash: commitHash
            }
          : {}),
        ...(commitMessage
          ? {
              commit_message: commitMessage
            }
          : {}),
        ...(committers
          ? {
              committers
            }
          : {}),
        make_default_branch: String(defaultBranch),
        ...(pullRequest
          ? {
              pull_request: String(pullRequest)
            }
          : {}),
        repo: repoName || 'socket-default-repository',
        // mandatory, this is server default for repo
        set_as_pending_head: String(pendingHead),
        tmp: String(tmp)
      },
      packagePaths,
      cwd
    ),
    'to create a scan'
  )
}

async function fetchSupportedScanFileNames() {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.getReportSupportedFiles(),
    'supported scan file types'
  )
}

/**
 * This fetches all the relevant pieces of data to generate a report, given a
 * full scan ID.
 */
async function fetchReportData(orgSlug, scanId, includeLicensePolicy) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  let scanStatus = 'requested..'
  let policyStatus = 'requested..'
  let finishedFetching = false

  // Lazily access constants.spinner.
  const { spinner } = constants
  function updateScan(desc) {
    scanStatus = desc
    updateProgress()
  }
  function updatePolicy(desc) {
    policyStatus = desc
    updateProgress()
  }
  function updateProgress() {
    if (finishedFetching) {
      spinner.stop()
      logger.logger.error(
        `Scan result: ${scanStatus}. Security policy: ${policyStatus}.`
      )
    } else {
      spinner.start(
        `Scan result: ${scanStatus}. Security policy: ${policyStatus}.`
      )
    }
  }
  async function fetchScanResult() {
    const result = await utils.queryApiSafeText(
      `orgs/${orgSlug}/full-scans/${encodeURIComponent(scanId)}${includeLicensePolicy ? '?include_license_details=true' : ''}`
    )
    updateScan(`response received`)
    if (!result.ok) {
      return result
    }
    const jsonsString = result.data

    // This is nd-json; each line is a json object
    const lines = jsonsString.split('\n').filter(Boolean)
    let ok = true
    const data = lines.map(line => {
      try {
        return JSON.parse(line)
      } catch {
        ok = false
        debug.debugLog('ndjson failed to parse the following line:')
        debug.debugLog(line)
        return
      }
    })
    if (ok) {
      updateScan(`success`)
      return {
        ok: true,
        data
      }
    }
    updateScan(`received invalid JSON response`)
    return {
      ok: false,
      message: 'Invalid API response',
      cause:
        'The API responded with at least one line that was not valid JSON. Please report if this persists.'
    }
  }
  async function fetchSecurityPolicy() {
    const result = await utils.handleApiCallNoSpinner(
      sockSdk.getOrgSecurityPolicy(orgSlug),
      'GetOrgSecurityPolicy'
    )
    updatePolicy('received policy')
    return result
  }
  updateProgress()
  const [scan, securityPolicy] = await Promise.all([
    fetchScanResult().catch(e => {
      updateScan(`failure; unknown blocking problem occurred`)
      return {
        ok: false,
        message: 'Unexpected API problem',
        cause: `We encountered an unexpected problem while requesting the Scan from the API: ${e?.message || '(no error message found)'}${e?.cause ? ` (cause: ${e.cause})` : ''}`
      }
    }),
    fetchSecurityPolicy().catch(e => {
      updatePolicy(`failure; unknown blocking problem occurred`)
      return {
        ok: false,
        message: 'Unexpected API problem',
        cause: `We encountered an unexpected problem while requesting the policy from the API: ${e?.message || '(no error message found)'}${e?.cause ? ` (cause: ${e.cause})` : ''}`
      }
    })
  ]).finally(() => {
    finishedFetching = true
    updateProgress()
  })
  if (!scan.ok) {
    return scan
  }
  if (!securityPolicy.ok) {
    return securityPolicy
  }
  if (!Array.isArray(scan.data)) {
    return {
      ok: false,
      message: 'Failed to fetch',
      cause: 'Was unable to fetch scan result, bailing'
    }
  }
  return {
    ok: true,
    data: {
      scan: scan.data,
      securityPolicy: securityPolicy.data
    }
  }
}

// Note: The returned cresult will only be ok:false when the generation
//       failed. It won't reflect the healthy state.
function generateReport(
  scan,
  securityPolicy,
  { fold, orgSlug, reportLevel, scanId, short, spinner }
) {
  const now = Date.now()
  spinner?.start('Generating report...')

  // Create an object that includes:
  //   healthy: boolean
  //   worst violation level;
  //   per eco
  //     per package
  //       per version
  //         per offending file
  //           reported issue -> policy action

  // In the context of a report;
  // - the alert.severity is irrelevant
  // - the securityPolicyDefault is irrelevant
  // - the report defaults to healthy:true with no alerts
  // - the appearance of an alert will trigger the policy action;
  //   - error: healthy will end up as false, add alerts to report
  //   - warn: healthy unchanged, add alerts to report
  //   - monitor/ignore: no action
  //   - defer: unknown (no action)

  // Note: the server will emit alerts for license policy violations but
  //       those are only included if you set the flag when requesting the scan
  //       data. The alerts map to a single security policy key that determines
  //       what to do with any violation, regardless of the concrete license.
  //       That rule is called "License Policy Violation".
  // The license policy part is implicitly handled here. Either they are
  // included and may show up, or they are not and won't show up.

  const violations = new Map()
  let healthy = true
  const securityRules = securityPolicy.securityPolicyRules
  if (securityRules) {
    // Note: reportLevel: error > warn > monitor > ignore > defer
    scan.forEach(artifact => {
      const {
        alerts,
        name: pkgName = '<unknown>',
        type: ecosystem,
        version = '<unknown>'
      } = artifact
      alerts?.forEach(alert => {
        const alertName = alert.type // => policy[type]
        const action = securityRules[alertName]?.action || ''
        switch (action) {
          case 'error': {
            healthy = false
            if (!short) {
              addAlert(
                artifact,
                violations,
                fold,
                ecosystem,
                pkgName,
                version,
                alert,
                action
              )
            }
            break
          }
          case 'warn': {
            if (!short && reportLevel !== 'error') {
              addAlert(
                artifact,
                violations,
                fold,
                ecosystem,
                pkgName,
                version,
                alert,
                action
              )
            }
            break
          }
          case 'monitor': {
            if (!short && reportLevel !== 'warn' && reportLevel !== 'error') {
              addAlert(
                artifact,
                violations,
                fold,
                ecosystem,
                pkgName,
                version,
                alert,
                action
              )
            }
            break
          }
          case 'ignore': {
            if (
              !short &&
              reportLevel !== 'warn' &&
              reportLevel !== 'error' &&
              reportLevel !== 'monitor'
            ) {
              addAlert(
                artifact,
                violations,
                fold,
                ecosystem,
                pkgName,
                version,
                alert,
                action
              )
            }
            break
          }
          case 'defer': {
            // Not sure but ignore for now. Defer to later ;)
            if (!short && reportLevel === 'defer') {
              addAlert(
                artifact,
                violations,
                fold,
                ecosystem,
                pkgName,
                version,
                alert,
                action
              )
            }
            break
          }
        }
      })
    })
  }
  spinner?.successAndStop(`Generated reported in ${Date.now() - now} ms`)
  if (short) {
    return {
      ok: true,
      data: {
        healthy
      }
    }
  }
  const report = {
    healthy,
    orgSlug,
    scanId,
    options: {
      fold,
      reportLevel
    },
    alerts: violations
  }
  if (!healthy) {
    return {
      ok: true,
      message:
        'The report contains at least one alert that violates the policies set by your organization',
      data: report
    }
  }
  return {
    ok: true,
    data: report
  }
}
function createLeaf(art, alert, policyAction) {
  const leaf = {
    type: alert.type,
    policy: policyAction,
    url: utils.getSocketDevPackageOverviewUrlFromPurl(art),
    manifest: art.manifestFiles?.map(obj => obj.file) ?? []
  }
  return leaf
}
function addAlert(
  art,
  violations,
  foldSetting,
  ecosystem,
  pkgName,
  version,
  alert,
  policyAction
) {
  if (!violations.has(ecosystem)) {
    violations.set(ecosystem, new Map())
  }
  const ecomap = violations.get(ecosystem)
  if (foldSetting === 'pkg') {
    const existing = ecomap.get(pkgName)
    if (!existing || isStricterPolicy(existing.policy, policyAction)) {
      ecomap.set(pkgName, createLeaf(art, alert, policyAction))
    }
  } else {
    if (!ecomap.has(pkgName)) {
      ecomap.set(pkgName, new Map())
    }
    const pkgmap = ecomap.get(pkgName)
    if (foldSetting === 'version') {
      const existing = pkgmap.get(version)
      if (!existing || isStricterPolicy(existing.policy, policyAction)) {
        pkgmap.set(version, createLeaf(art, alert, policyAction))
      }
    } else {
      if (!pkgmap.has(version)) {
        pkgmap.set(version, new Map())
      }
      const file = alert.file || '<unknown>'
      const vermap = pkgmap.get(version)
      if (foldSetting === 'file') {
        const existing = vermap.get(file)
        if (!existing || isStricterPolicy(existing.policy, policyAction)) {
          vermap.set(file, createLeaf(art, alert, policyAction))
        }
      } else {
        if (!vermap.has(file)) {
          vermap.set(file, new Map())
        }
        const key = `${alert.type} at ${alert.start}:${alert.end}`
        const filemap = vermap.get(file)
        const existing = filemap.get(key)
        if (!existing || isStricterPolicy(existing.policy, policyAction)) {
          filemap.set(key, createLeaf(art, alert, policyAction))
        }
      }
    }
  }
}
function isStricterPolicy(was, is) {
  // error > warn > monitor > ignore > defer > {unknown}
  if (was === 'error') {
    return false
  }
  if (is === 'error') {
    return true
  }
  if (was === 'warn') {
    return false
  }
  if (is === 'warn') {
    return false
  }
  if (was === 'monitor') {
    return false
  }
  if (is === 'monitor') {
    return false
  }
  if (was === 'ignore') {
    return false
  }
  if (is === 'ignore') {
    return false
  }
  if (was === 'defer') {
    return false
  }
  if (is === 'defer') {
    return false
  }
  // unreachable?
  return false
}

async function outputScanReport(
  result,
  {
    filePath,
    fold,
    includeLicensePolicy,
    orgSlug,
    outputKind,
    reportLevel,
    scanId,
    short
  }
) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result))
      return
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  const scanReport = generateReport(
    result.data.scan,
    result.data.securityPolicy,
    {
      orgSlug,
      scanId,
      fold,
      reportLevel,
      short,
      // Lazily access constants.spinner.
      spinner: constants.spinner
    }
  )
  if (!scanReport.ok) {
    // Note: this means generation failed, it does not reflect the healthy state
    process.exitCode = scanReport.code ?? 1

    // If report generation somehow failed then .data should not be set.
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(scanReport))
      return
    }
    logger.logger.fail(
      utils.failMsgWithBadge(scanReport.message, scanReport.cause)
    )
    return
  }

  // I don't think we emit the default error message with banner for an unhealhty report, do we?
  // if (!scanReport.data.healhty) {
  //   logger.fail(failMsgWithBadge(scanReport.message, scanReport.cause))
  //   return
  // }

  if (
    outputKind === 'json' ||
    (outputKind === 'text' && filePath && filePath.endsWith('.json'))
  ) {
    const json = short
      ? utils.serializeResultJson(scanReport)
      : toJsonReport(scanReport.data, includeLicensePolicy)
    if (filePath && filePath !== '-') {
      logger.logger.log('Writing json report to', filePath)
      return await fs.writeFile(filePath, json)
    }
    logger.logger.log(json)
    return
  }
  if (outputKind === 'markdown' || (filePath && filePath.endsWith('.md'))) {
    const md = short
      ? `healthy = ${scanReport.data.healthy}`
      : toMarkdownReport(
          scanReport.data,
          // not short so must be regular report
          includeLicensePolicy
        )
    if (filePath && filePath !== '-') {
      logger.logger.log('Writing markdown report to', filePath)
      return await fs.writeFile(filePath, md)
    }
    logger.logger.log(md)
    logger.logger.log('')
    return
  }
  if (short) {
    logger.logger.log(scanReport.data.healthy ? 'OK' : 'ERR')
  } else {
    logger.logger.dir(scanReport.data, {
      depth: null
    })
  }
}
function toJsonReport(report, includeLicensePolicy) {
  const obj = utils.mapToObject(report.alerts)
  const newReport = {
    includeLicensePolicy,
    ...report,
    alerts: obj
  }
  return utils.serializeResultJson({
    ok: true,
    data: newReport
  })
}
function toMarkdownReport(report, includeLicensePolicy) {
  const flatData = Array.from(utils.walkNestedMap(report.alerts)).map(
    ({ keys, value }) => {
      const { manifest, policy, type, url } = value
      return {
        'Alert Type': type,
        Package: keys[1] || '<unknown>',
        'Introduced by': keys[2] || '<unknown>',
        url,
        'Manifest file': manifest.join(', '),
        Policy: policy
      }
    }
  )
  const md =
    `
# Scan Policy Report

This report tells you whether the results of a Socket scan results violate the
security${includeLicensePolicy ? ' or license' : ''} policy set by your organization.

## Health status

${report.healthy ? `The scan *PASSES* all requirements set by your security${includeLicensePolicy ? ' and license' : ''} policy.` : 'The scan *VIOLATES* one or more policies set to the "error" level.'}

## Settings

Configuration used to generate this report:

- Organization: ${report.orgSlug}
- Scan ID: ${report.scanId}
- Alert folding: ${report.options.fold === 'none' ? 'none' : `up to ${report.options.fold}`}
- Minimal policy level for alert to be included in report: ${report.options.reportLevel === 'defer' ? 'everything' : report.options.reportLevel}
- Include license alerts: ${includeLicensePolicy ? 'yes' : 'no'}

## Alerts

${report.alerts.size ? `All the alerts from the scan with a policy set to at least "${report.options.reportLevel}".` : `The scan contained no alerts with a policy set to at least "${report.options.reportLevel}".`}

${!report.alerts.size ? '' : utils.mdTable(flatData, ['Policy', 'Alert Type', 'Package', 'Introduced by', 'url', 'Manifest file'])}
  `.trim() + '\n'
  return md
}

async function handleScanReport({
  filePath,
  fold,
  includeLicensePolicy,
  orgSlug,
  outputKind,
  reportLevel,
  scanId,
  short
}) {
  const result = await fetchReportData(orgSlug, scanId, includeLicensePolicy)
  await outputScanReport(result, {
    filePath,
    fold,
    scanId: scanId,
    includeLicensePolicy,
    orgSlug,
    outputKind,
    reportLevel,
    short
  })
}

async function outputCreateNewScan(result, outputKind, interactive) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  if (!result.data.id) {
    logger.logger.fail('Did not receive a scan ID from the API...')
    process.exitCode = 1
  }
  if (outputKind === 'markdown') {
    logger.logger.log('# Create New Scan')
    logger.logger.log('')
    if (result.data.id) {
      logger.logger.log(
        `A [new Scan](${result.data.html_report_url}) was created with ID: ${result.data.id}`
      )
      logger.logger.log('')
    } else {
      logger.logger.log(
        `The server did not return a Scan ID while trying to create a new Scan. This could be an indication something went wrong.`
      )
    }
    logger.logger.log('')
    return
  }
  const link = vendor.yoctocolorsCjsExports.underline(
    vendor.yoctocolorsCjsExports.cyan(`${result.data.html_report_url}`)
  )
  logger.logger.log(`Available at: ${link}`)
  if (
    interactive &&
    (await prompts.confirm({
      message: 'Would you like to open it in your browser?',
      default: false
    }))
  ) {
    await vendor.open(`${result.data.html_report_url}`)
  }
}

async function handleCreateNewScan({
  branchName,
  commitHash,
  commitMessage,
  committers,
  cwd,
  defaultBranch,
  interactive,
  orgSlug,
  outputKind,
  pendingHead,
  pullRequest,
  readOnly,
  repoName,
  report,
  targets,
  tmp
}) {
  const supportedFileNames = await fetchSupportedScanFileNames()
  if (!supportedFileNames.ok) {
    await outputCreateNewScan(supportedFileNames, outputKind, interactive)
    return
  }
  const packagePaths = await utils.getPackageFilesForScan(
    cwd,
    targets,
    supportedFileNames.data
  )
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: packagePaths.length > 0,
    pass: 'ok',
    fail: 'found no eligible files to scan',
    message:
      'TARGET (file/dir) must contain matching / supported file types for a scan'
  })
  if (!wasValidInput) {
    return
  }
  if (readOnly) {
    logger.logger.log('[ReadOnly] Bailing now')
    return
  }
  const data = await fetchCreateOrgFullScan(
    packagePaths,
    orgSlug,
    defaultBranch,
    pendingHead,
    tmp,
    cwd,
    {
      commitHash,
      commitMessage,
      committers,
      pullRequest,
      repoName,
      branchName
    }
  )
  if (data.ok && report) {
    if (data.data?.id) {
      await handleScanReport({
        filePath: '-',
        fold: 'version',
        includeLicensePolicy: true,
        orgSlug,
        outputKind,
        reportLevel: 'error',
        scanId: data.data.id,
        short: false
      })
    } else {
      await outputCreateNewScan(
        {
          ok: false,
          message: 'Missing Scan ID',
          cause: 'Server did not respond with a scan ID',
          data: data.data
        },
        outputKind,
        interactive
      )
    }
  } else {
    await outputCreateNewScan(data, outputKind, interactive)
  }
}

async function handleCI() {
  // ci: {
  //   description: 'Alias for "report create --view --strict"',
  //     argv: ['report', 'create', '--view', '--strict']
  // }
  const result = await getDefaultOrgSlug()
  if (!result.ok) {
    process.exitCode = result.code ?? 1
    // Always assume json mode
    logger.logger.log(utils.serializeResultJson(result))
    return
  }

  // TODO: does it make sense to discover the commit details from local git?
  // TODO: does it makes sense to use custom branch/repo names here? probably socket.yml, right
  await handleCreateNewScan({
    branchName: 'socket-default-branch',
    commitMessage: '',
    commitHash: '',
    committers: '',
    cwd: process.cwd(),
    defaultBranch: false,
    interactive: false,
    orgSlug: result.data,
    outputKind: 'json',
    pendingHead: true,
    // when true, requires branch name set, tmp false
    pullRequest: 0,
    repoName: 'socket-default-repository',
    readOnly: false,
    report: true,
    targets: ['.'],
    tmp: false // don't set when pendingHead is true
  })
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$F } = constants
const config$J = {
  commandName: 'ci',
  description:
    'Create a new scan and report whether it passes your security policy',
  hidden: true,
  flags: {
    ...utils.commonFlags
  },
  help: (parentName, _config) => `
    Usage
      $ ${parentName}

    This command is intended to use in CI runs to allow automated systems to
    accept or reject a current build. When the scan does not pass your security
    policy, the exit code will be non-zero.

    It will use the default org for the set API token.
  `
}
const cmdCI = {
  description: config$J.description,
  hidden: config$J.hidden,
  run: run$J
}
async function run$J(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$J,
    importMeta,
    parentName
  })
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$F)
    return
  }
  await handleCI()
}

async function discoverConfigValue(key) {
  // This will have to be a specific implementation per key because certain
  // keys should request information from particular API endpoints while
  // others should simply return their default value, like endpoint URL.

  if (!utils.supportedConfigKeys.has(key)) {
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: 'Requested key is not a valid config key.'
    }
  }
  if (key === 'apiBaseUrl') {
    // Return the default value
    return {
      ok: false,
      message: 'Auto discover failed',
      cause:
        "If you're unsure about the base endpoint URL then simply unset it."
    }
  }
  if (key === 'apiProxy') {
    // I don't think we can auto-discover this with any order of reliability..?
    return {
      ok: false,
      message: 'Auto discover failed',
      cause:
        'When uncertain, unset this key. Otherwise ask your network administrator'
    }
  }
  if (key === 'apiToken') {
    return {
      ok: false,
      message: 'Auto discover failed',
      cause:
        'You can find/create your API token in your Socket dashboard > settings > API tokens.\nYou should then use `socket login` to login instead of this command.'
    }
  }
  if (key === 'defaultOrg') {
    const hasApiToken = utils.hasDefaultToken()
    if (!hasApiToken) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause: 'No API token set, must have a token to resolve its default org.'
      }
    }
    const org = await getDefaultOrgFromToken()
    if (!org?.length) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause: 'Was unable to determine default org for the current API token.'
      }
    }
    if (Array.isArray(org)) {
      return {
        ok: true,
        data: org,
        message: 'These are the orgs that the current API token can access.'
      }
    }
    return {
      ok: true,
      data: org,
      message: 'This is the org that belongs to the current API token.'
    }
  }
  if (key === 'enforcedOrgs') {
    const hasApiToken = utils.hasDefaultToken()
    if (!hasApiToken) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause: 'No API token set, must have a token to resolve orgs to enforce.'
      }
    }
    const orgs = await getEnforceableOrgsFromToken()
    if (!orgs?.length) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause:
          'Was unable to determine any orgs to enforce for the current API token.'
      }
    }
    return {
      ok: true,
      data: orgs,
      message: 'These are the orgs whose security policy you can enforce.'
    }
  }
  if (key === 'test') {
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: 'congrats, you found the test key'
    }
  }

  // Mostly to please TS, because we're not telling it `key` is keyof LocalConfig
  return {
    ok: false,
    message: 'Auto discover failed',
    cause: 'unreachable?'
  }
}
async function getDefaultOrgFromToken() {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return undefined
  }
  const sockSdk = sockSdkResult.data
  const result = await utils.handleApiCall(
    sockSdk.getOrganizations(),
    'list of organizations'
  )
  if (result.ok) {
    const arr = Array.from(Object.values(result.data.organizations)).map(
      ({ slug }) => slug
    )
    if (arr.length === 0) {
      return undefined
    }
    if (arr.length === 1) {
      return arr[0]
    }
    return arr
  }
  return undefined
}
async function getEnforceableOrgsFromToken() {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return undefined
  }
  const sockSdk = sockSdkResult.data
  const result = await utils.handleApiCall(
    sockSdk.getOrganizations(),
    'list of organizations'
  )
  if (result.ok) {
    const arr = Array.from(Object.values(result.data.organizations)).map(
      ({ slug }) => slug
    )
    if (arr.length === 0) {
      return undefined
    }
    return arr
  }
  return undefined
}

async function outputConfigAuto(key, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`# Auto discover config value`)
    logger.logger.log('')
    logger.logger.log(
      `Attempted to automatically discover the value for config key: "${key}"`
    )
    logger.logger.log('')
    if (result.ok) {
      logger.logger.log(`The discovered value is: "${result.data}"`)
      if (result.message) {
        logger.logger.log('')
        logger.logger.log(result.message)
      }
    }
    logger.logger.log('')
  } else {
    if (result.message) {
      logger.logger.log(result.message)
      logger.logger.log('')
    }
    logger.logger.log(`- ${key}: ${result.data}`)
    logger.logger.log('')
    if (utils.isReadOnlyConfig()) {
      logger.logger.log(
        '(Unable to persist this value because the config is in read-only mode, meaning it was overridden through env or flag.)'
      )
    } else if (key === 'defaultOrg') {
      const proceed = await prompts.select({
        message:
          'Would you like to update the default org in local config to this value?',
        choices: (Array.isArray(result.data) ? result.data : [result.data])
          .map(slug => ({
            name: 'Yes [' + slug + ']',
            value: slug,
            description: `Use "${slug}" as the default organization`
          }))
          .concat({
            name: 'No',
            value: '',
            description: 'Do not use any of these organizations'
          })
      })
      if (proceed) {
        logger.logger.log(`Setting defaultOrg to "${proceed}"...`)
        const updateResult = utils.updateConfigValue('defaultOrg', proceed)
        if (updateResult.ok) {
          logger.logger.log(
            `OK. Updated defaultOrg to "${proceed}".\nYou should no longer need to add the org to commands that normally require it.`
          )
        } else {
          logger.logger.log(
            utils.failMsgWithBadge(updateResult.message, updateResult.cause)
          )
        }
      } else {
        logger.logger.log('OK. No changes made.')
      }
    } else if (key === 'enforcedOrgs') {
      const proceed = await prompts.select({
        message:
          'Would you like to update the enforced orgs in local config to this value?',
        choices: (Array.isArray(result.data) ? result.data : [result.data])
          .map(slug => ({
            name: 'Yes [' + slug + ']',
            value: slug,
            description: `Enforce the security policy of "${slug}" on this machine`
          }))
          .concat({
            name: 'No',
            value: '',
            description: 'Do not use any of these organizations'
          })
      })
      if (proceed) {
        logger.logger.log(`Setting enforcedOrgs key to "${proceed}"...`)
        const updateResult = utils.updateConfigValue('defaultOrg', proceed)
        if (updateResult.ok) {
          logger.logger.log(`OK. Updated enforcedOrgs to "${proceed}".`)
        } else {
          logger.logger.log(
            utils.failMsgWithBadge(updateResult.message, updateResult.cause)
          )
        }
      } else {
        logger.logger.log('OK. No changes made.')
      }
    }
  }
}

async function handleConfigAuto({ key, outputKind }) {
  const result = await discoverConfigValue(key)
  await outputConfigAuto(key, result, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$E } = constants
const config$I = {
  commandName: 'auto',
  description: 'Automatically discover and set the correct value config item',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Attempt to automatically discover the correct value for a certain config key.

    For certain keys it will request the value from server, for others it will
    reset the value to the default. For some keys this has no effect.

    Keys:

${Array.from(utils.supportedConfigKeys.entries())
  .map(([key, desc]) => `     - ${key} -- ${desc}`)
  .join('\n')}

    Examples
      $ ${command} auto defaultOrg
  `
}
const cmdConfigAuto = {
  description: config$I.description,
  hidden: config$I.hidden,
  run: run$I
}
async function run$I(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$I,
    importMeta,
    parentName
  })
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [key = ''] = cli.input
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: utils.supportedConfigKeys.has(key) && key !== 'test',
      message: 'Config key should be the first arg',
      pass: 'ok',
      fail: key ? 'invalid config key' : 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$E)
    return
  }
  await handleConfigAuto({
    key: key,
    outputKind
  })
}

async function outputConfigGet(key, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  const readOnly = utils.isReadOnlyConfig()
  if (outputKind === 'markdown') {
    logger.logger.log(`# Config Value`)
    logger.logger.log('')
    logger.logger.log(`Config key '${key}' has value '${result.data}`)
    if (readOnly) {
      logger.logger.log('')
      logger.logger.log(
        'Note: the config is in read-only mode, meaning at least one key was temporarily\n      overridden from an env var or command flag.'
      )
    }
  } else {
    logger.logger.log(`${key}: ${result.data}`)
    if (readOnly) {
      logger.logger.log('')
      logger.logger.log(
        'Note: the config is in read-only mode, meaning at least one key was temporarily overridden from an env var or command flag.'
      )
    }
  }
}

async function handleConfigGet({ key, outputKind }) {
  const result = utils.getConfigValue(key)
  await outputConfigGet(key, result, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$D } = constants
const config$H = {
  commandName: 'get',
  description: 'Get the value of a local CLI config item',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Keys:

${Array.from(utils.supportedConfigKeys.entries())
  .map(([key, desc]) => `     - ${key} -- ${desc}`)
  .join('\n')}

    Examples
      $ ${command} FakeOrg --repoName=test-repo
  `
}
const cmdConfigGet = {
  description: config$H.description,
  hidden: config$H.hidden,
  run: run$H
}
async function run$H(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$H,
    importMeta,
    parentName
  })
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [key = ''] = cli.input
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: utils.supportedConfigKeys.has(key) || key === 'test',
      message: 'Config key should be the first arg',
      pass: 'ok',
      fail: key ? 'invalid config key' : 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$D)
    return
  }
  await handleConfigGet({
    key: key,
    outputKind
  })
}

async function outputConfigList({ full, outputKind }) {
  const readOnly = utils.isReadOnlyConfig()
  if (outputKind === 'json') {
    let failed = false
    const obj = {}
    for (const key of utils.supportedConfigKeys.keys()) {
      const result = utils.getConfigValue(key)
      let value = result.data
      if (!result.ok) {
        value = `Failed to retrieve: ${result.message}`
        failed = true
      } else if (!full && utils.sensitiveConfigKeys.has(key)) {
        value = '********'
      }
      if (full || value !== undefined) {
        obj[key] = value ?? '<none>'
      }
    }
    if (failed) {
      process.exitCode = 1
    }
    logger.logger.log(
      utils.serializeResultJson(
        failed
          ? {
              ok: false,
              message: 'At least one config key failed to be fetched...',
              data: JSON.stringify({
                full,
                config: obj,
                readOnly
              })
            }
          : {
              ok: true,
              data: {
                full,
                config: obj,
                readOnly
              }
            }
      )
    )
  } else {
    const maxWidth = Array.from(utils.supportedConfigKeys.keys()).reduce(
      (a, b) => Math.max(a, b.length),
      0
    )
    logger.logger.log('# Local CLI Config')
    logger.logger.log('')
    logger.logger.log(`This is the local CLI config (full=${!!full}):`)
    logger.logger.log('')
    for (const key of utils.supportedConfigKeys.keys()) {
      const result = utils.getConfigValue(key)
      if (!result.ok) {
        logger.logger.log(`- ${key}: failed to read: ${result.message}`)
      } else {
        let value = result.data
        if (!full && utils.sensitiveConfigKeys.has(key)) {
          value = '********'
        }
        if (full || value !== undefined) {
          logger.logger.log(
            `- ${key}:${' '.repeat(Math.max(0, maxWidth - key.length + 3))} ${Array.isArray(value) ? value.join(', ') || '<none>' : (value ?? '<none>')}`
          )
        }
      }
    }
    if (readOnly) {
      logger.logger.log('')
      logger.logger.log(
        'Note: the config is in read-only mode, meaning at least one key was temporarily\n      overridden from an env var or command flag.'
      )
    }
  }
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$C } = constants
const config$G = {
  commandName: 'list',
  description: 'Show all local CLI config items and their values',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    full: {
      type: 'boolean',
      default: false,
      description: 'Show full tokens in plaintext (unsafe)'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Keys:

${Array.from(utils.supportedConfigKeys.entries())
  .map(([key, desc]) => `     - ${key} -- ${desc}`)
  .join('\n')}

    Examples
      $ ${command} FakeOrg --repoName=test-repo
  `
}
const cmdConfigList = {
  description: config$G.description,
  hidden: config$G.hidden,
  run: run$G
}
async function run$G(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$G,
    importMeta,
    parentName
  })
  const { full, json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message:
      'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  })
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$C)
    return
  }
  await outputConfigList({
    full: !!full,
    outputKind
  })
}

async function outputConfigSet(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`# Update config`)
    logger.logger.log('')
    logger.logger.log(result.message)
    if (result.data) {
      logger.logger.log('')
      logger.logger.log(result.data)
    }
  } else {
    logger.logger.log(`OK`)
    logger.logger.log(result.message)
    if (result.data) {
      logger.logger.log('')
      logger.logger.log(result.data)
    }
  }
}

async function handleConfigSet({ key, outputKind, value }) {
  const result = utils.updateConfigValue(key, value)
  await outputConfigSet(result, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$B } = constants
const config$F = {
  commandName: 'set',
  description: 'Update the value of a local CLI config item',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <key> <value>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    This is a crude way of updating the local configuration for this CLI tool.

    Note that updating a value here is nothing more than updating a key/value
    store entry. No validation is happening. The server may reject your config.

    Keys:

${Array.from(utils.supportedConfigKeys.entries())
  .map(([key, desc]) => `     - ${key} -- ${desc}`)
  .join('\n')}

    Examples
      $ ${command} apiProxy https://example.com
  `
}
const cmdConfigSet = {
  description: config$F.description,
  hidden: config$F.hidden,
  run: run$F
}
async function run$F(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$F,
    importMeta,
    parentName
  })
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [key = '', ...rest] = cli.input
  const value = rest.join(' ')
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: key === 'test' || utils.supportedConfigKeys.has(key),
      message: 'Config key should be the first arg',
      pass: 'ok',
      fail: key ? 'invalid config key' : 'missing'
    },
    {
      test: !!value,
      // This is a string, empty string is not ok
      message:
        'Key value should be the remaining args (use `unset` to unset a value)',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$B)
    return
  }
  await handleConfigSet({
    key: key,
    outputKind,
    value
  })
}

async function outputConfigUnset(updateResult, outputKind) {
  if (!updateResult.ok) {
    process.exitCode = updateResult.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(updateResult))
    return
  }
  if (!updateResult.ok) {
    logger.logger.fail(
      utils.failMsgWithBadge(updateResult.message, updateResult.cause)
    )
    return
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`# Update config`)
    logger.logger.log('')
    logger.logger.log(updateResult.message)
    if (updateResult.data) {
      logger.logger.log('')
      logger.logger.log(updateResult.data)
    }
  } else {
    logger.logger.log(`OK`)
    logger.logger.log(updateResult.message)
    if (updateResult.data) {
      logger.logger.log('')
      logger.logger.log(updateResult.data)
    }
  }
}

async function handleConfigUnset({ key, outputKind }) {
  const updateResult = utils.updateConfigValue(key, undefined)
  await outputConfigUnset(updateResult, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$A } = constants
const config$E = {
  commandName: 'unset',
  description: 'Clear the value of a local CLI config item',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Keys:

${Array.from(utils.supportedConfigKeys.entries())
  .map(([key, desc]) => `     - ${key} -- ${desc}`)
  .join('\n')}

    Examples
      $ ${command} FakeOrg --repoName=test-repo
  `
}
const cmdConfigUnset = {
  description: config$E.description,
  hidden: config$E.hidden,
  run: run$E
}
async function run$E(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$E,
    importMeta,
    parentName
  })
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [key = ''] = cli.input
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: key === 'test' || utils.supportedConfigKeys.has(key),
      message: 'Config key should be the first arg',
      pass: 'ok',
      fail: key ? 'invalid config key' : 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$A)
    return
  }
  await handleConfigUnset({
    key: key,
    outputKind
  })
}

const description$7 = 'Commands related to the local CLI configuration'
const cmdConfig = {
  description: description$7,
  hidden: true,
  // [beta]
  async run(argv, importMeta, { parentName }) {
    await utils.meowWithSubcommands(
      {
        auto: cmdConfigAuto,
        get: cmdConfigGet,
        list: cmdConfigList,
        set: cmdConfigSet,
        unset: cmdConfigUnset
      },
      {
        argv,
        description: description$7,
        importMeta,
        name: `${parentName} config`
      }
    )
  }
}

async function fetchDependencies({ limit, offset }) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.searchDependencies({
      limit,
      offset
    }),
    'organization dependencies'
  )
}

// @ts-ignore
async function outputDependencies(result, { limit, offset, outputKind }) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  logger.logger.log(
    'Request details: Offset:',
    offset,
    ', limit:',
    limit,
    ', is there more data after this?',
    result.data.end ? 'no' : 'yes'
  )
  const options = {
    columns: [
      {
        field: 'namespace',
        name: vendor.yoctocolorsCjsExports.cyan('Namespace')
      },
      {
        field: 'name',
        name: vendor.yoctocolorsCjsExports.cyan('Name')
      },
      {
        field: 'version',
        name: vendor.yoctocolorsCjsExports.cyan('Version')
      },
      {
        field: 'repository',
        name: vendor.yoctocolorsCjsExports.cyan('Repository')
      },
      {
        field: 'branch',
        name: vendor.yoctocolorsCjsExports.cyan('Branch')
      },
      {
        field: 'type',
        name: vendor.yoctocolorsCjsExports.cyan('Type')
      },
      {
        field: 'direct',
        name: vendor.yoctocolorsCjsExports.cyan('Direct')
      }
    ]
  }
  logger.logger.log(vendor.srcExports(options, result.data.rows))
}

async function handleDependencies({ limit, offset, outputKind }) {
  const result = await fetchDependencies({
    limit,
    offset
  })
  await outputDependencies(result, {
    limit,
    offset,
    outputKind
  })
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$z } = constants
const config$D = {
  commandName: 'dependencies',
  description:
    'Search for any dependency that is being used in your organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    limit: {
      type: 'number',
      shortFlag: 'l',
      default: 50,
      description: 'Maximum number of dependencies returned'
    },
    offset: {
      type: 'number',
      shortFlag: 'o',
      default: 0,
      description: 'Page number'
    },
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      ${command}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: none (does need token with access to target org)

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      ${command} --limit 20 --offset 10
  `
}
const cmdScanCreate$1 = {
  description: config$D.description,
  hidden: config$D.hidden,
  run: run$D
}
async function run$D(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$D,
    importMeta,
    parentName
  })
  const { json, limit, markdown, offset } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$z)
    return
  }
  await handleDependencies({
    limit: Number(limit || 0) || 0,
    offset: Number(offset || 0) || 0,
    outputKind
  })
}

async function fetchDiffScan$1({ after, before, orgSlug }) {
  return await utils.queryApiSafeJson(
    `orgs/${orgSlug}/full-scans/diff?before=${encodeURIComponent(before)}&after=${encodeURIComponent(after)}`,
    'a scan diff'
  )
}

async function outputDiffScan$1(result, { depth, file, outputKind }) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result))
      return
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  const dashboardUrl = result.data.diff_report_url
  const dashboardMessage = dashboardUrl
    ? `\n View this diff scan in the Socket dashboard: ${vendor.yoctocolorsCjsExports.cyan(dashboardUrl)}`
    : ''

  // When forcing json, or dumping to file, serialize to string such that it
  // won't get truncated. The only way to dump the full raw JSON to stdout is
  // to use `--json --file -` (the dash is a standard notation for stdout)
  if (outputKind === 'json' || file) {
    const json = utils.serializeResultJson(result)
    if (file && file !== '-') {
      logger.logger.log(`Writing json to \`${file}\``)
      fs$1.writeFile(file, JSON.stringify(result, null, 2), err => {
        if (err) {
          logger.logger.fail(`Writing to \`${file}\` failed...`)
          logger.logger.error(err)
        } else {
          logger.logger.log(`Data successfully written to \`${file}\``)
        }
        logger.logger.error(dashboardMessage)
      })
    } else {
      // TODO: expose different method for writing to stderr when simply dodging stdout
      logger.logger.error(`\n Diff scan result: \n`)
      logger.logger.log(json)
      logger.logger.error(dashboardMessage)
    }
    return
  }

  // In this case neither the --json nor the --file flag was passed
  // Dump the JSON to CLI and let NodeJS deal with truncation

  logger.logger.log('Diff scan result:')
  logger.logger.log(
    util.inspect(result, {
      showHidden: false,
      depth: depth > 0 ? depth : null,
      colors: true,
      maxArrayLength: null
    })
  )
  logger.logger.log(
    `\n 📝 To display the detailed report in the terminal, use the --json flag \n`
  )
  logger.logger.log(dashboardMessage)
}

async function handleDiffScan$1({
  after,
  before,
  depth,
  file,
  orgSlug,
  outputKind
}) {
  const data = await fetchDiffScan$1({
    after,
    before,
    orgSlug
  })
  await outputDiffScan$1(data, {
    depth,
    file,
    outputKind
  })
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$y } = constants
const config$C = {
  commandName: 'get',
  description: 'Get a diff scan for an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    after: {
      type: 'string',
      shortFlag: 'a',
      default: '',
      description: 'The scan ID of the head scan'
    },
    before: {
      type: 'string',
      shortFlag: 'b',
      default: '',
      description: 'The scan ID of the base scan'
    },
    depth: {
      type: 'number',
      default: 2,
      description:
        'Max depth of JSON to display before truncating, use zero for no limit (without --json/--file)'
    },
    json: {
      type: 'boolean',
      shortFlag: 'j',
      default: false,
      description:
        'Output result as json. This can be big. Use --file to store it to disk without truncation.'
    },
    file: {
      type: 'string',
      shortFlag: 'f',
      default: '',
      description:
        'Path to a local file where the output should be saved. Use `-` to force stdout.'
    }
  },
  help: (command, config) =>
    utils.isTestingV1()
      ? 'This command will be removed in v1'
      : `
    Note: This command is deprecated, to be dropped in the next major bump.
          Please see \`socket scan diff\`

    Usage
      $ ${command} <org slug> --before=<before> --after=<after>

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:list

    This command displays the package changes between two scans. The full output
    can be pretty large depending on the size of your repo and time range. It is
    best stored to disk to be further analyzed by other tools.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeCorp --before=aaa0aa0a-aaaa-0000-0a0a-0000000a00a0 --after=aaa1aa1a-aaaa-1111-1a1a-1111111a11a1
  `
}
const cmdDiffScanGet = {
  description: config$C.description,
  hidden: config$C.hidden,
  run: run$C
}
async function run$C(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$C,
    importMeta,
    parentName
  })
  const { after, before, depth, file, json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const defaultOrgSlugResult = utils.getConfigValueOrUndef('defaultOrg')
  const orgSlug = defaultOrgSlugResult || cli.input[0] || ''
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: !!(before && after),
      message:
        'Specify a before and after scan ID.\nThe args are expecting a full `aaa0aa0a-aaaa-0000-0a0a-0000000a00a0` scan ID.',
      pass: 'ok',
      fail:
        !before && !after
          ? 'missing before and after'
          : !before
            ? 'missing before'
            : 'missing after'
    },
    {
      test: !!orgSlug,
      nook: true,
      message: 'Org name as the first argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  logger.logger.fail(
    'Warning: this command is deprecated in favor of `socket scan diff` and will be removed in the next major bump.'
  )
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$y)
    return
  }
  await handleDiffScan$1({
    before: String(before || ''),
    after: String(after || ''),
    depth: Number(depth),
    orgSlug,
    outputKind,
    file: String(file || '')
  })
}

const description$6 = 'Diff scans related commands'
const cmdDiffScan = {
  description: description$6,
  // Hidden because it was broken all this time (nobody could be using it)
  // and we're not sure if it's useful to anyone in its current state.
  // Until we do, we'll hide this to keep the help tidier.
  // And later, we may simply move this under `scan`, anyways.
  hidden: true,
  async run(argv, importMeta, { parentName }) {
    await utils.meowWithSubcommands(
      {
        get: cmdDiffScanGet
      },
      {
        argv,
        description: description$6,
        importMeta,
        name: parentName + ' diff-scan'
      }
    )
  }
}

function formatBranchName(str) {
  return str
    .replace(/[-_.\\/]+/g, '-')
    .replace(/[^-a-zA-Z0-9]+/g, '')
    .replace(/^-+|-+$/g, '')
}
function getBaseGitBranch() {
  // Lazily access constants.ENV.GITHUB_REF_NAME.
  return (
    constants.ENV.GITHUB_REF_NAME ||
    // GitHub defaults to branch name "main"
    // https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-branches#about-the-default-branch
    'main'
  )
}
function getSocketBranchName(purl, newVersion, workspaceName) {
  const purlObj = vendor.packageurlJsExports.PackageURL.fromString(purl)
  const maybeWorkspaceName = workspaceName
    ? `${formatBranchName(workspaceName)}-`
    : ''
  const maybeNamespace = purlObj.namespace
    ? `${formatBranchName(purlObj.namespace)}-`
    : ''
  const fullName = `${maybeWorkspaceName}${maybeNamespace}${formatBranchName(purlObj.name)}`
  return `socket/${fullName}-${formatBranchName(newVersion)}`
}
function getSocketPrTitlePattern(purl, workspaceName) {
  const purlObj = vendor.packageurlJsExports.PackageURL.fromString(purl)
  const pkgFullName = utils.getPkgFullNameFromPurlObj(purlObj)
  const workspaceDetails = workspaceName
    ? ` in ${regexps.escapeRegExp(workspaceName)}`
    : ''
  return new RegExp(
    `Bump ${regexps.escapeRegExp(pkgFullName)} from ${regexps.escapeRegExp(purlObj.version)} to \\S+${workspaceDetails}`
  )
}
function getSocketPullRequestTitle(purl, newVersion, workspaceName) {
  const purlObj = vendor.packageurlJsExports.PackageURL.fromString(purl)
  const pkgFullName = utils.getPkgFullNameFromPurlObj(purlObj)
  const workspaceDetails = workspaceName ? ` in ${workspaceName}` : ''
  return `Bump ${pkgFullName} from ${purlObj.version} to ${newVersion}${workspaceDetails}`
}
function getSocketPullRequestBody(purl, newVersion, workspaceName) {
  const purlObj = vendor.packageurlJsExports.PackageURL.fromString(purl)
  const pkgFullName = utils.getPkgFullNameFromPurlObj(purlObj)
  const workspaceDetails = workspaceName ? ` in ${workspaceName}` : ''
  return `Bump [${pkgFullName}](${utils.getSocketDevPackageOverviewUrlFromPurl(purlObj)}) from ${purlObj.version} to ${newVersion}${workspaceDetails}.`
}
function getSocketCommitMessage(purl, newVersion, workspaceName) {
  const purlObj = vendor.packageurlJsExports.PackageURL.fromString(purl)
  const pkgFullName = utils.getPkgFullNameFromPurlObj(purlObj)
  const workspaceDetails = workspaceName ? ` in ${workspaceName}` : ''
  return `socket: Bump ${pkgFullName} from ${purlObj.version} to ${newVersion}${workspaceDetails}`
}
async function gitCreateAndPushBranchIfNeeded(
  branch,
  commitMsg,
  cwd = process.cwd()
) {
  if (await gitRemoteBranchExists(branch, cwd)) {
    logger.logger.warn(
      `Branch "${branch}" already exists remotely, skipping push.`
    )
    return true
  }
  const moddedFilepaths = (await gitUnstagedModifiedFiles(cwd)).filter(p => {
    const basename = path.basename(p)
    return (
      basename === 'package.json' ||
      basename === 'package-lock.json' ||
      basename === 'pnpm-lock.yaml'
    )
  })
  if (!moddedFilepaths.length) {
    logger.logger.warn('Nothing to commit, skipping push.')
    return false
  }
  await spawn.spawn('git', ['checkout', '-b', branch], {
    cwd
  })
  await spawn.spawn('git', ['add', ...moddedFilepaths], {
    cwd
  })
  await spawn.spawn('git', ['commit', '-m', commitMsg], {
    cwd
  })
  try {
    await spawn.spawn('git', ['push', '--set-upstream', 'origin', branch], {
      cwd
    })
    return true
  } catch {}
  logger.logger.warn(`Push failed for "${branch}", trying force-push`)
  try {
    await spawn.spawn(
      'git',
      ['push', '--force', '--set-upstream', 'origin', branch],
      {
        cwd
      }
    )
    return true
  } catch {}
  logger.logger.warn(`Force-push failed for "${branch}"`)
  return false
}
async function gitResetAndClean(branch = 'HEAD', cwd = process.cwd()) {
  // Discards tracked changes.
  await gitResetHard(branch, cwd)
  // Deletes all untracked files and directories.
  await gitCleanFdx(cwd)
}
async function gitResetHard(branch = 'HEAD', cwd = process.cwd()) {
  await spawn.spawn('git', ['reset', '--hard', branch], {
    cwd
  })
}
async function gitCleanFdx(cwd = process.cwd()) {
  await spawn.spawn('git', ['clean', '-fdx'], {
    cwd
  })
}
async function gitRemoteBranchExists(branch, cwd = process.cwd()) {
  try {
    const { stdout } = await spawn.spawn(
      'git',
      ['ls-remote', '--heads', 'origin', branch],
      {
        cwd
      }
    )
    return stdout.trim().length > 0
  } catch {
    return false
  }
}
async function gitUnstagedModifiedFiles(cwd = process.cwd()) {
  const { stdout } = await spawn.spawn('git', ['diff', '--name-only'], {
    cwd
  })
  const rawFiles = stdout?.trim().split('\n') ?? []
  return rawFiles.map(relPath => path$1.normalizePath(relPath))
}

let _octokit
function getOctokit() {
  if (_octokit === undefined) {
    _octokit = new vendor.Octokit({
      // Lazily access constants.ENV.SOCKET_SECURITY_GITHUB_PAT.
      auth: constants.ENV.SOCKET_SECURITY_GITHUB_PAT
    })
  }
  return _octokit
}
let _octokitGraphql
function getOctokitGraphql() {
  if (!_octokitGraphql) {
    _octokitGraphql = vendor.graphql2.defaults({
      headers: {
        // Lazily access constants.ENV.SOCKET_SECURITY_GITHUB_PAT.
        authorization: `token ${constants.ENV.SOCKET_SECURITY_GITHUB_PAT}`
      }
    })
  }
  return _octokitGraphql
}
async function cacheFetch(key, fetcher, ttlMs) {
  // Optionally disable cache.
  if (constants.ENV.DISABLE_GITHUB_CACHE) {
    return await fetcher()
  }
  let data = await readCache(key, ttlMs)
  if (!data) {
    data = await fetcher()
    await writeCache(key, data)
  }
  return data
}
async function readCache(
  key,
  // 5 minute in milliseconds time to live (TTL).
  ttlMs = 5 * 60 * 1000
) {
  // Lazily access constants.rootPath.
  const cachePath = path.join(constants.rootPath, '.cache/github')
  const cacheJsonPath = path.join(cachePath, `${key}.json`)
  try {
    const stat = fs$1.statSync(cacheJsonPath)
    const isExpired = Date.now() - stat.mtimeMs > ttlMs
    if (!isExpired) {
      return await fs$2.readJson(cacheJsonPath)
    }
  } catch {}
  return null
}
async function writeCache(key, data) {
  // Lazily access constants.rootPath.
  const cachePath = path.join(constants.rootPath, '.cache/github')
  const cacheJsonPath = path.join(cachePath, `${key}.json`)
  if (!fs$1.existsSync(cachePath)) {
    await fs$1.promises.mkdir(cachePath, {
      recursive: true
    })
  }
  await fs$2.writeJson(cacheJsonPath, data)
}
async function cleanupOpenPrs(owner, repo, purl, newVersion, options) {
  const { workspaceName } = {
    __proto__: null,
    ...options
  }
  const octokit = getOctokit()
  const octokitGraphql = getOctokitGraphql()
  const titlePattern = getSocketPrTitlePattern(purl, workspaceName)
  const prMatches = []
  try {
    // Optimistically fetch only the first 50 open PRs using GraphQL to minimize
    // API quota usage. Fallback to REST if no matching PRs are found.
    const gqlCacheKey = `${repo}-pr-graphql-snapshot`
    const gqlResp = await cacheFetch(gqlCacheKey, () =>
      octokitGraphql(
        `
          query($owner: String!, $repo: String!) {
            repository(owner: $owner, name: $repo) {
              pullRequests(first: 50, states: OPEN, orderBy: {field: CREATED_AT, direction: DESC}) {
                nodes {
                  number
                  title
                  mergeStateStatus
                  headRefName
                  baseRefName
                }
              }
            }
          }
          `,
        {
          owner,
          repo
        }
      )
    )
    const nodes = gqlResp?.repository?.pullRequests?.nodes
    if (nodes) {
      for (let i = 0, { length } = nodes; i < length; i += 1) {
        const node = nodes[i]
        if (titlePattern.test(node.title)) {
          prMatches.push({
            apiType: 'graphql',
            cacheKey: gqlCacheKey,
            data: gqlResp,
            entry: node,
            index: i,
            parent: nodes,
            props: node
          })
        }
      }
    }
  } catch {}

  // Fallback to REST if GraphQL found no matching PRs.
  let allOpenPrs
  if (!prMatches.length) {
    const cacheKey = `${repo}-open-prs`
    try {
      allOpenPrs = await cacheFetch(
        cacheKey,
        async () =>
          await octokit.paginate(octokit.pulls.list, {
            owner,
            repo,
            state: 'open',
            per_page: 100
          })
      )
    } catch {}
    if (allOpenPrs) {
      for (let i = 0, { length } = allOpenPrs; i < length; i += 1) {
        const pr = allOpenPrs[i]
        if (titlePattern.test(pr.title)) {
          prMatches.push({
            apiType: 'rest',
            cacheKey,
            data: allOpenPrs,
            entry: pr,
            index: i,
            parent: allOpenPrs,
            props: {
              baseRefName: pr.base.ref,
              headRefName: pr.head.ref,
              // Upper cased mergeable_state is equivalent to mergeStateStatus.
              // https://docs.github.com/en/rest/pulls/pulls?apiVersion=2022-11-28#get-a-pull-request
              mergeStateStatus:
                pr.mergeable_state?.toUpperCase?.() ?? 'UNKNOWN',
              number: pr.number,
              title: pr.title
            }
          })
        }
      }
    }
  }
  if (!prMatches.length) {
    return
  }
  const cachesToSave = new Map()
  await Promise.allSettled(
    prMatches.map(async match => {
      const { props } = match
      const versionText = /(?<= to )\S+/.exec(props.title)?.[0]
      const { number: prNumber } = props
      const prVersion = vendor.semverExports.coerce(versionText)
      // Close older PRs.
      if (prVersion && vendor.semverExports.lt(prVersion, newVersion)) {
        try {
          await octokit.pulls.update({
            owner,
            repo,
            pull_number: prNumber,
            state: 'closed'
          })
          logger.logger.info(
            `Closed PR #${prNumber} for older version ${prVersion}`
          )
          // Remove entry from parent object.
          match.parent.splice(match.index, 1)
          // Mark cache to be saved.
          cachesToSave.set(match.cacheKey, match.data)
        } catch (e) {
          logger.logger.warn(`Failed to close PR #${prNumber}: ${e.message}`)
          return
        }
      }
      // Update stale PRs.
      // https://docs.github.com/en/graphql/reference/enums#mergestatestatus
      if (props.mergeStateStatus === 'BEHIND') {
        try {
          await octokit.repos.merge({
            owner,
            repo,
            base: props.headRefName,
            head: props.baseRefName
          })
          logger.logger.info(`Updated stale PR #${prNumber}`)
          // Update entry entry.
          if (match.apiType === 'graphql') {
            match.entry.mergeStateStatus = 'CLEAN'
          } else if (match.apiType === 'rest') {
            match.entry.mergeable_state = 'clean'
          }
          // Mark cache to be saved.
          cachesToSave.set(match.cacheKey, match.data)
        } catch (e) {
          const message = e?.message ?? 'Unknown error'
          logger.logger.warn(`Failed to update PR #${prNumber}: ${message}`)
        }
      }
    })
  )
  if (cachesToSave.size) {
    await Promise.allSettled(
      [...cachesToSave].map(({ 0: key, 1: data }) => writeCache(key, data))
    )
  }
}
async function enablePrAutoMerge({ node_id: prId, number: prNumber }) {
  const octokitGraphql = getOctokitGraphql()
  let error
  try {
    const response = await octokitGraphql(
      `
      mutation EnableAutoMerge($pullRequestId: ID!) {
        enablePullRequestAutoMerge(input: {
          pullRequestId: $pullRequestId,
          mergeMethod: SQUASH
        }) {
          pullRequest {
            number
          }
        }
      }`,
      {
        pullRequestId: prId
      }
    )
    const respPrNumber =
      response?.enablePullRequestAutoMerge?.pullRequest?.number
    if (respPrNumber) {
      logger.logger.info(`Auto-merge enabled for PR #${respPrNumber}`)
      return true
    }
  } catch (e) {
    error = e
  }
  let message = `Failed to enable auto-merge for PR #${prNumber}`
  if (error instanceof vendor.GraphqlResponseError && error.errors) {
    const details = error.errors
      .map(({ message }) => ` - ${message.trim()}`)
      .join('\n')
    message += `:\n${details}`
  }
  logger.logger.error(message)
  return false
}
function getGitHubEnvRepoInfo() {
  // Lazily access constants.ENV.GITHUB_REPOSITORY.
  const ownerSlashRepo = constants.ENV.GITHUB_REPOSITORY
  const slashIndex = ownerSlashRepo.indexOf('/')
  if (slashIndex === -1) {
    throw new Error('Missing GITHUB_REPOSITORY environment variable')
  }
  return {
    owner: ownerSlashRepo.slice(0, slashIndex),
    repo: ownerSlashRepo.slice(slashIndex + 1)
  }
}
async function openPr(owner, repo, branch, purl, newVersion, options) {
  const {
    baseBranch = 'main',
    cwd = process.cwd(),
    workspaceName
  } = {
    __proto__: null,
    ...options
  }
  // Lazily access constants.ENV.GITHUB_ACTIONS.
  if (constants.ENV.GITHUB_ACTIONS) {
    // Lazily access constants.ENV.SOCKET_SECURITY_GITHUB_PAT.
    const pat = constants.ENV.SOCKET_SECURITY_GITHUB_PAT
    if (!pat) {
      throw new Error('Missing SOCKET_SECURITY_GITHUB_PAT environment variable')
    }
    const url = `https://x-access-token:${pat}@github.com/${owner}/${repo}`
    await spawn.spawn('git', ['remote', 'set-url', 'origin', url], {
      cwd
    })
    const octokit = getOctokit()
    try {
      return await octokit.pulls.create({
        owner,
        repo,
        title: getSocketPullRequestTitle(purl, newVersion, workspaceName),
        head: branch,
        base: baseBranch,
        body: getSocketPullRequestBody(purl, newVersion, workspaceName)
      })
    } catch (e) {
      let message = `Failed to open pull request`
      if (e instanceof vendor.RequestError) {
        const restErrors = e.response?.data?.['errors']
        if (Array.isArray(restErrors)) {
          const details = restErrors
            .map(
              restErr =>
                `- ${restErr.message?.trim() ?? `${restErr.resource}.${restErr.field} (${restErr.code})`}`
            )
            .join('\n')
          message += `:\n${details}`
        }
      }
      logger.logger.error(message)
      return null
    }
  }
  throw new Error('Missing GITHUB_ACTIONS environment variable')
}
async function prExistForBranch(owner, repo, branch) {
  const octokit = getOctokit()
  try {
    const { data: prs } = await octokit.pulls.list({
      owner,
      repo,
      head: `${owner}:${branch}`,
      state: 'open',
      per_page: 1
    })
    return prs.length > 0
  } catch {}
  return false
}

const CMD_NAME$1 = 'socket fix'
function getAlertMapOptions(options = {}) {
  return {
    __proto__: null,
    consolidate: true,
    nothrow: true,
    ...options,
    include: {
      __proto__: null,
      existing: true,
      unfixable: false,
      upgradable: false,
      ...options?.include
    }
  }
}
function normalizeFixOptions(options_) {
  const options = {
    __proto__: null,
    ...options_
  }
  if (typeof options.autopilot !== 'boolean') {
    options.autopilot = false
  }
  if (typeof options.autoMerge !== 'boolean') {
    options.autoMerge = !!options.autopilot
  }
  if (typeof options.cwd !== 'string') {
    options.cwd = process.cwd()
  }
  const limit =
    typeof options.limit === 'number'
      ? options.limit
      : parseInt(`${options.limit || ''}`, 10)
  options.limit = Number.isNaN(limit) ? Infinity : limit
  options.purls = Array.isArray(options.purls)
    ? options.purls.flatMap(p => p.split(/, */))
    : []
  if (typeof options.rangeStyle !== 'string') {
    options.rangeStyle = 'preserve'
  }
  if (typeof options.test !== 'boolean') {
    options.test = !!options.autopilot || !!options.testScript
  }
  if (typeof options.testScript !== 'string') {
    options.testScript = 'test'
  }
  return options
}

const { DRY_RUN_NOT_SAVING: DRY_RUN_NOT_SAVING$1, NPM: NPM$c } = constants
async function install$1(idealTree, options) {
  const { cwd = process.cwd() } = {
    __proto__: null,
    ...options
  }
  const arb = new shadowNpmInject.Arborist({
    path: cwd
  })
  arb.idealTree = idealTree
  await arb.reify()
}
async function npmFix(
  pkgEnvDetails,
  { autoMerge, cwd, dryRun, limit, purls, rangeStyle, test, testScript }
) {
  if (dryRun) {
    logger.logger.log(DRY_RUN_NOT_SAVING$1)
    return
  }
  // Lazily access constants.spinner.
  const { spinner } = constants
  spinner?.start()
  const { pkgPath: rootPath } = pkgEnvDetails
  const arb = new shadowNpmInject.SafeArborist({
    path: rootPath,
    ...shadowNpmInject.SAFE_ARBORIST_REIFY_OPTIONS_OVERRIDES
  })
  // Calling arb.reify() creates the arb.diff object and nulls-out arb.idealTree.
  await arb.reify()
  const alertsMap = purls.length
    ? await utils.getAlertsMapFromPurls(
        purls,
        getAlertMapOptions({
          limit
        })
      )
    : await shadowNpmInject.getAlertsMapFromArborist(
        arb,
        getAlertMapOptions({
          limit
        })
      )
  const infoByPkg = utils.getCveInfoByAlertsMap(alertsMap, {
    limit
  })
  if (!infoByPkg) {
    spinner?.stop()
    logger.logger.info('No fixable vulnerabilities found.')
    return
  }

  // Lazily access constants.ENV.CI.
  const isCi = constants.ENV.CI
  const baseBranch = isCi ? getBaseGitBranch() : ''
  const workspacePkgJsonPaths = await utils.globWorkspace(
    pkgEnvDetails.agent,
    rootPath
  )
  const pkgJsonPaths = [
    ...workspacePkgJsonPaths,
    // Process the workspace root last since it will add an override to package.json.
    pkgEnvDetails.editablePkgJson.filename
  ]
  let count = 0
  infoByPkgLoop: for (const { 0: name, 1: infos } of infoByPkg) {
    debug.debugLog(`Processing vulnerable package: ${name}`)
    if (registry.getManifestData(NPM$c, name)) {
      spinner?.info(`Socket Optimize package for ${name} exists, skipping`)
      continue
    }
    if (!infos.length) {
      debug.debugLog(`No vuln info found for ${name}`)
      continue
    }
    // eslint-disable-next-line no-await-in-loop
    const packument = await packages.fetchPackagePackument(name)
    if (!packument) {
      debug.debugLog(`No packument found for ${name}`)
      continue
    }
    const availableVersions = Object.keys(packument.versions)
    const fixedSpecs = new Set()
    for (const pkgJsonPath of pkgJsonPaths) {
      const pkgPath = path.dirname(pkgJsonPath)
      const isWorkspaceRoot =
        pkgJsonPath === pkgEnvDetails.editablePkgJson.filename
      const workspaceName = isWorkspaceRoot
        ? 'root'
        : path.relative(rootPath, pkgPath)
      debug.debugLog(`Checking workspace: ${workspaceName}`)
      arb.idealTree = null
      // eslint-disable-next-line no-await-in-loop
      await arb.buildIdealTree()
      const oldVersions = arrays.arrayUnique(
        shadowNpmInject
          .findPackageNodes(arb.idealTree, name)
          .map(n => n.target?.version ?? n.version)
          .filter(Boolean)
      )
      if (!oldVersions.length) {
        debug.debugLog(`Lockfile entries not found for ${name}`)
        continue
      }

      // Always re-read the editable package.json to avoid stale mutations
      // across iterations.
      // eslint-disable-next-line no-await-in-loop
      const editablePkgJson = await packages.readPackageJson(pkgJsonPath, {
        editable: true
      })
      for (const oldVersion of oldVersions) {
        const oldId = `${name}@${oldVersion}`
        const oldPurl = utils.idToPurl(oldId)
        const node = shadowNpmInject.findPackageNode(
          arb.idealTree,
          name,
          oldVersion
        )
        if (!node) {
          debug.debugLog(`Arborist node not found, skipping ${oldId}`)
          continue
        }
        for (const {
          firstPatchedVersionIdentifier,
          vulnerableVersionRange
        } of infos) {
          const newVersion = shadowNpmInject.findBestPatchVersion(
            node,
            availableVersions,
            vulnerableVersionRange
          )
          const newVersionPackument = newVersion
            ? packument.versions[newVersion]
            : undefined
          if (!(newVersion && newVersionPackument)) {
            debug.debugLog(
              `No suitable update. ${oldId} needs >=${firstPatchedVersionIdentifier}, skipping`
            )
            continue
          }
          const newVersionRange = utils.applyRange(
            oldVersion,
            newVersion,
            rangeStyle
          )
          const newId = `${name}@${newVersionRange}`
          const newSpecKey = `${workspaceName}:${newId}`
          if (fixedSpecs.has(newSpecKey)) {
            debug.debugLog(
              `Already fixed ${newId} in ${workspaceName}, skipping`
            )
            continue
          }
          const revertData = {
            ...(editablePkgJson.content.dependencies && {
              dependencies: {
                ...editablePkgJson.content.dependencies
              }
            }),
            ...(editablePkgJson.content.optionalDependencies && {
              optionalDependencies: {
                ...editablePkgJson.content.optionalDependencies
              }
            }),
            ...(editablePkgJson.content.peerDependencies && {
              peerDependencies: {
                ...editablePkgJson.content.peerDependencies
              }
            })
          }
          shadowNpmInject.updateNode(node, newVersion, newVersionPackument)
          shadowNpmInject.updatePackageJsonFromNode(
            editablePkgJson,
            arb.idealTree,
            node,
            newVersion,
            rangeStyle
          )
          // eslint-disable-next-line no-await-in-loop
          if (
            !(await editablePkgJson.save({
              ignoreWhitespace: true
            }))
          ) {
            debug.debugLog(
              `Nothing changed for ${workspaceName}, skipping install`
            )
            // Reset things just in case.
            if (isCi) {
              // eslint-disable-next-line no-await-in-loop
              await gitResetAndClean(baseBranch, cwd)
            }
            continue
          }
          spinner?.info(`Installing ${newId} in ${workspaceName}`)
          let error
          let errored = false
          try {
            // eslint-disable-next-line no-await-in-loop
            await install$1(arb.idealTree, {
              cwd
            })
            if (test) {
              spinner?.info(`Testing ${newId} in ${workspaceName}`)
              // eslint-disable-next-line no-await-in-loop
              await npm.runScript(testScript, [], {
                spinner,
                stdio: 'ignore'
              })
            }
            fixedSpecs.add(newSpecKey)
            spinner?.successAndStop(`Fixed ${name} in ${workspaceName}`)
            spinner?.start()
          } catch (e) {
            errored = true
            error = e
          }
          if (!errored && isCi) {
            const branch = getSocketBranchName(
              oldPurl,
              newVersion,
              workspaceName
            )
            try {
              const { owner, repo } = getGitHubEnvRepoInfo()
              if (
                // eslint-disable-next-line no-await-in-loop
                (await prExistForBranch(owner, repo, branch)) ||
                // eslint-disable-next-line no-await-in-loop
                !(await gitCreateAndPushBranchIfNeeded(
                  branch,
                  getSocketCommitMessage(oldPurl, newVersion, workspaceName),
                  cwd
                ))
              ) {
                continue
              }
              // eslint-disable-next-line no-await-in-loop
              await cleanupOpenPrs(owner, repo, oldPurl, newVersion, {
                workspaceName
              })
              // eslint-disable-next-line no-await-in-loop
              const prResponse = await openPr(
                owner,
                repo,
                branch,
                oldPurl,
                newVersion,
                {
                  baseBranch,
                  cwd,
                  workspaceName
                }
              )
              if (prResponse) {
                const { data } = prResponse
                spinner?.info(`Opened PR #${data.number}.`)
                if (autoMerge) {
                  // eslint-disable-next-line no-await-in-loop
                  await enablePrAutoMerge(data)
                }
              }
            } catch (e) {
              error = e
              errored = true
            }
          }
          if (isCi) {
            // eslint-disable-next-line no-await-in-loop
            await gitResetAndClean(baseBranch, cwd)
            // eslint-disable-next-line no-await-in-loop
            await install$1(arb.idealTree, {
              cwd
            })
          }
          if (errored) {
            if (!isCi) {
              editablePkgJson.update(revertData)
              // eslint-disable-next-line no-await-in-loop
              await Promise.all([
                utils.removeNodeModules(cwd),
                editablePkgJson.save({
                  ignoreWhitespace: true
                })
              ])
              // eslint-disable-next-line no-await-in-loop
              await install$1(arb.idealTree, {
                cwd
              })
            }
            spinner?.failAndStop(
              `Update failed for ${oldId} in ${workspaceName}`,
              error
            )
          }
          if (++count >= limit) {
            break infoByPkgLoop
          }
        }
      }
    }
  }
  spinner?.stop()
}

const {
  DRY_RUN_NOT_SAVING,
  NPM: NPM$b,
  OVERRIDES: OVERRIDES$2,
  PNPM: PNPM$7
} = constants
async function getActualTree(cwd = process.cwd()) {
  const arb = new shadowNpmInject.SafeArborist({
    path: cwd,
    ...shadowNpmInject.SAFE_ARBORIST_REIFY_OPTIONS_OVERRIDES
  })
  return await arb.loadActual()
}
async function install(pkgEnvDetails, options) {
  const { args, cwd, spinner } = {
    __proto__: null,
    ...options
  }
  await utils.runAgentInstall(pkgEnvDetails, {
    args: [...(args ?? []), '--no-frozen-lockfile'],
    spinner,
    stdio: debug.isDebug() ? 'inherit' : 'ignore'
  })
  return await getActualTree(cwd)
}
async function readLockfile(pkgPath) {
  return await vendor.libExports$4.readWantedLockfile(pkgPath, {
    ignoreIncompatible: false
  })
}
async function pnpmFix(
  pkgEnvDetails,
  { autoMerge, cwd, dryRun, limit, purls, rangeStyle, test, testScript }
) {
  if (dryRun) {
    logger.logger.log(DRY_RUN_NOT_SAVING)
    return
  }
  // Lazily access constants.spinner.
  const { spinner } = constants
  const { pkgPath: rootPath } = pkgEnvDetails
  spinner?.start()
  let lockfile = await readLockfile(rootPath)

  // If pnpm-lock.yaml does NOT exist then install with pnpm to create it.
  if (!lockfile) {
    await install(pkgEnvDetails, {
      cwd,
      spinner
    })
    lockfile = await readLockfile(rootPath)
  }
  // Update pnpm-lock.yaml if its version is older than what the installed pnpm
  // produces.
  if (
    lockfile &&
    pkgEnvDetails.agentVersion.major >= 10 &&
    utils.parsePnpmLockfileVersion(lockfile.lockfileVersion).major <= 6
  ) {
    await install(pkgEnvDetails, {
      args: ['--lockfile-only'],
      cwd,
      spinner
    })
    lockfile = await readLockfile(rootPath)
  }
  // Exit early if pnpm-lock.yaml is not found.
  if (!lockfile) {
    spinner?.stop()
    logger.logger.error('Required pnpm-lock.yaml not found.')
    return
  }
  const alertsMap = purls.length
    ? await utils.getAlertsMapFromPurls(
        purls,
        getAlertMapOptions({
          limit
        })
      )
    : await utils.getAlertsMapFromPnpmLockfile(
        lockfile,
        getAlertMapOptions({
          limit
        })
      )
  const infoByPkg = utils.getCveInfoByAlertsMap(alertsMap, {
    limit
  })
  if (!infoByPkg) {
    spinner?.stop()
    logger.logger.info('No fixable vulnerabilities found.')
    return
  }

  // Lazily access constants.ENV.CI.
  const isCi = constants.ENV.CI
  const baseBranch = isCi ? getBaseGitBranch() : ''
  const workspacePkgJsonPaths = await utils.globWorkspace(
    pkgEnvDetails.agent,
    rootPath
  )
  const pkgJsonPaths = [
    ...workspacePkgJsonPaths,
    // Process the workspace root last since it will add an override to package.json.
    pkgEnvDetails.editablePkgJson.filename
  ]
  let count = 0
  infoByPkgLoop: for (const { 0: name, 1: infos } of infoByPkg) {
    debug.debugLog(`Processing vulnerable package: ${name}`)
    if (registry.getManifestData(NPM$b, name)) {
      spinner?.info(`Socket Optimize package for ${name} exists, skipping`)
      continue
    }
    if (!infos.length) {
      debug.debugLog(`No vuln info found for ${name}`)
      continue
    }
    // eslint-disable-next-line no-await-in-loop
    const packument = await packages.fetchPackagePackument(name)
    if (!packument) {
      debug.debugLog(`No packument found for ${name}`)
      continue
    }
    const availableVersions = Object.keys(packument.versions)
    const fixedSpecs = new Set()
    for (const pkgJsonPath of pkgJsonPaths) {
      const pkgPath = path.dirname(pkgJsonPath)
      const isWorkspaceRoot =
        pkgJsonPath === pkgEnvDetails.editablePkgJson.filename
      const workspaceName = isWorkspaceRoot
        ? 'root'
        : path.relative(rootPath, pkgPath)
      debug.debugLog(`Checking workspace: ${workspaceName}`)

      // eslint-disable-next-line no-await-in-loop
      let actualTree = await getActualTree(cwd)
      const oldVersions = arrays.arrayUnique(
        shadowNpmInject
          .findPackageNodes(actualTree, name)
          .map(n => n.target?.version ?? n.version)
          .filter(Boolean)
      )
      if (!oldVersions.length) {
        debug.debugLog(`Lockfile entries not found for ${name}`)
        continue
      }

      // Always re-read the editable package.json to avoid stale mutations
      // across iterations.
      // eslint-disable-next-line no-await-in-loop
      const editablePkgJson = await packages.readPackageJson(pkgJsonPath, {
        editable: true
      })
      // Get current overrides for revert logic
      const oldPnpmSection = editablePkgJson.content[PNPM$7]
      const oldOverrides = oldPnpmSection?.[OVERRIDES$2]
      for (const oldVersion of oldVersions) {
        const oldId = `${name}@${oldVersion}`
        const oldPurl = utils.idToPurl(oldId)
        const node = shadowNpmInject.findPackageNode(
          actualTree,
          name,
          oldVersion
        )
        if (!node) {
          debug.debugLog(`Arborist node not found, skipping ${oldId}`)
          continue
        }
        for (const {
          firstPatchedVersionIdentifier,
          vulnerableVersionRange
        } of infos) {
          const newVersion = shadowNpmInject.findBestPatchVersion(
            node,
            availableVersions,
            vulnerableVersionRange
          )
          const newVersionPackument = newVersion
            ? packument.versions[newVersion]
            : undefined
          if (!(newVersion && newVersionPackument)) {
            debug.debugLog(
              `No suitable update. ${oldId} needs >=${firstPatchedVersionIdentifier}, skipping`
            )
            continue
          }
          const overrideKey = `${name}@${vulnerableVersionRange}`
          const newVersionRange = utils.applyRange(
            oldOverrides?.[overrideKey] ?? oldVersion,
            newVersion,
            rangeStyle
          )
          const newId = `${name}@${newVersionRange}`
          const newSpecKey = `${workspaceName}:${newId}`
          if (fixedSpecs.has(newSpecKey)) {
            debug.debugLog(
              `Already fixed ${newId} in ${workspaceName}, skipping`
            )
            continue
          }
          const updateData = isWorkspaceRoot
            ? {
                [PNPM$7]: {
                  ...oldPnpmSection,
                  [OVERRIDES$2]: {
                    ...oldOverrides,
                    [overrideKey]: newVersionRange
                  }
                }
              }
            : undefined
          const revertData = {
            ...(isWorkspaceRoot
              ? {
                  [PNPM$7]: {
                    ...oldPnpmSection,
                    [OVERRIDES$2]:
                      oldOverrides && Object.keys(oldOverrides).length > 1
                        ? {
                            ...oldOverrides,
                            [overrideKey]: undefined
                          }
                        : undefined
                  }
                }
              : {}),
            ...(editablePkgJson.content.dependencies && {
              dependencies: {
                ...editablePkgJson.content.dependencies
              }
            }),
            ...(editablePkgJson.content.optionalDependencies && {
              optionalDependencies: {
                ...editablePkgJson.content.optionalDependencies
              }
            }),
            ...(editablePkgJson.content.peerDependencies && {
              peerDependencies: {
                ...editablePkgJson.content.peerDependencies
              }
            })
          }
          if (updateData) {
            editablePkgJson.update(updateData)
          }
          shadowNpmInject.updatePackageJsonFromNode(
            editablePkgJson,
            actualTree,
            node,
            newVersion,
            rangeStyle
          )
          // eslint-disable-next-line no-await-in-loop
          if (
            !(await editablePkgJson.save({
              ignoreWhitespace: true
            }))
          ) {
            debug.debugLog(
              `Nothing changed for ${workspaceName}, skipping install`
            )
            // Reset things just in case.
            if (isCi) {
              // eslint-disable-next-line no-await-in-loop
              await gitResetAndClean(baseBranch, cwd)
            }
            continue
          }
          spinner?.info(`Installing ${newId} in ${workspaceName}`)
          let error
          let errored = false
          try {
            // eslint-disable-next-line no-await-in-loop
            actualTree = await install(pkgEnvDetails, {
              cwd,
              spinner
            })
            if (test) {
              spinner?.info(`Testing ${newId} in ${workspaceName}`)
              // eslint-disable-next-line no-await-in-loop
              await npm.runScript(testScript, [], {
                spinner,
                stdio: 'ignore'
              })
            }
            fixedSpecs.add(newSpecKey)
            spinner?.successAndStop(`Fixed ${name} in ${workspaceName}`)
            spinner?.start()
          } catch (e) {
            error = e
            errored = true
          }
          if (!errored && isCi) {
            const branch = getSocketBranchName(
              oldPurl,
              newVersion,
              workspaceName
            )
            try {
              const { owner, repo } = getGitHubEnvRepoInfo()
              if (
                // eslint-disable-next-line no-await-in-loop
                (await prExistForBranch(owner, repo, branch)) ||
                // eslint-disable-next-line no-await-in-loop
                !(await gitCreateAndPushBranchIfNeeded(
                  branch,
                  getSocketCommitMessage(oldPurl, newVersion, workspaceName),
                  cwd
                ))
              ) {
                continue
              }
              // eslint-disable-next-line no-await-in-loop
              await cleanupOpenPrs(owner, repo, oldPurl, newVersion, {
                workspaceName
              })
              // eslint-disable-next-line no-await-in-loop
              const prResponse = await openPr(
                owner,
                repo,
                branch,
                oldPurl,
                newVersion,
                {
                  baseBranch,
                  cwd,
                  workspaceName
                }
              )
              if (prResponse) {
                const { data } = prResponse
                spinner?.info(`Opened PR #${data.number}.`)
                if (autoMerge) {
                  // eslint-disable-next-line no-await-in-loop
                  await enablePrAutoMerge(data)
                }
              }
            } catch (e) {
              error = e
              errored = true
            }
          }
          if (isCi) {
            // eslint-disable-next-line no-await-in-loop
            await gitResetAndClean(baseBranch, cwd)
            // eslint-disable-next-line no-await-in-loop
            actualTree = await install(pkgEnvDetails, {
              cwd,
              spinner
            })
          }
          if (errored) {
            if (!isCi) {
              editablePkgJson.update(revertData)
              // eslint-disable-next-line no-await-in-loop
              await Promise.all([
                utils.removeNodeModules(cwd),
                editablePkgJson.save({
                  ignoreWhitespace: true
                })
              ])
              // eslint-disable-next-line no-await-in-loop
              actualTree = await install(pkgEnvDetails, {
                cwd,
                spinner
              })
            }
            spinner?.failAndStop(
              `Update failed for ${oldId} in ${workspaceName}`,
              error
            )
          }
          if (++count >= limit) {
            break infoByPkgLoop
          }
        }
      }
    }
  }
  spinner?.stop()
}

const { NPM: NPM$a, PNPM: PNPM$6 } = constants
async function runFix(options_) {
  const options = normalizeFixOptions(options_)
  const pkgEnvDetails = await utils.detectAndValidatePackageEnvironment(
    options.cwd,
    {
      cmdName: CMD_NAME$1,
      logger: logger.logger
    }
  )
  if (!pkgEnvDetails) {
    return
  }
  logger.logger.info(`Fixing packages for ${pkgEnvDetails.agent}`)
  const { agent } = pkgEnvDetails
  if (agent === NPM$a) {
    await npmFix(pkgEnvDetails, options)
  } else if (agent === PNPM$6) {
    await pnpmFix(pkgEnvDetails, options)
  }
}

const config$B = {
  commandName: 'fix',
  description: 'Update dependencies with "fixable" Socket alerts',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    autoMerge: {
      type: 'boolean',
      default: false,
      description: `Enable auto-merge for pull requests that Socket opens.\n                        See ${vendor.terminalLinkExports('GitHub documentation', 'https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/configuring-pull-request-merges/managing-auto-merge-for-pull-requests-in-your-repository')} for managing auto-merge for pull requests in your repository.`
    },
    autopilot: {
      type: 'boolean',
      default: false,
      description: `Shorthand for --autoMerge --test`
    },
    limit: {
      type: 'number',
      default: Infinity,
      description: 'The number of fixes to attempt at a time'
    },
    purl: {
      type: 'string',
      default: [],
      description: `Provide a list of ${vendor.terminalLinkExports('package URLs', 'https://github.com/package-url/purl-spec?tab=readme-ov-file#purl')} (PURLs) to fix, as either a comma separated value or as multiple flags,\n                        instead of querying the Socket API`,
      isMultiple: true,
      shortFlag: 'p'
    },
    rangeStyle: {
      type: 'string',
      default: 'preserve',
      description: `
                        Define how updated dependency versions should be written in package.json.
                        Available styles:
                          * caret - Use ^ range for compatible updates (e.g. ^1.2.3)
                          * gt - Use > to allow any newer version (e.g. >1.2.3)
                          * gte - Use >= to allow any newer version (e.g. >=1.2.3)
                          * lt - Use < to allow only lower versions (e.g. <1.2.3)
                          * lte - Use <= to allow only lower versions (e.g. <=1.2.3)
                          * pin - Use the exact version (e.g. 1.2.3)
                          * preserve - Retain the existing version range style as-is
                          * tilde - Use ~ range for patch/minor updates (e.g. ~1.2.3)
      `.trim()
    },
    test: {
      type: 'boolean',
      default: false,
      description: 'Verify the fix by running unit tests'
    },
    testScript: {
      type: 'string',
      default: 'test',
      description: 'The test script to run for each fix attempt'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}

    Options
      ${utils.getFlagListOutput(config.flags, 6)}
  `
}
const cmdFix = {
  description: config$B.description,
  hidden: config$B.hidden,
  run: run$B
}
async function run$B(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$B,
    importMeta,
    parentName
  })
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown) // TODO: impl json/md further

  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: utils.RangeStyles.includes(cli.flags['rangeStyle']),
    message: `Expecting range style of ${arrays.joinOr(utils.RangeStyles)}`,
    pass: 'ok',
    fail: 'missing'
  })
  if (!wasValidInput) {
    return
  }
  await runFix({
    autoMerge: Boolean(cli.flags['autoMerge']),
    autopilot: Boolean(cli.flags['autopilot']),
    limit: Number(cli.flags['limit']),
    dryRun: Boolean(cli.flags['dryRun']),
    purls: Array.isArray(cli.flags['purl']) ? cli.flags['purl'] : [],
    rangeStyle: cli.flags['rangeStyle'] ?? undefined,
    test: Boolean(cli.flags['test']),
    testScript: cli.flags['testScript']
  })
}

async function fetchPackageInfo(pkgName, pkgVersion, includeAllIssues) {
  const sockSdkResult = await utils.setupSdk(utils.getPublicToken())
  if (!sockSdkResult.ok) {
    throw new Error('Was unable to setup sdk. Run `socket login` first.')
  }
  const sockSdk = sockSdkResult.data
  const result = await utils.handleApiCall(
    sockSdk.getIssuesByNPMPackage(pkgName, pkgVersion),
    'package issues'
  )
  const scoreResult = await utils.handleApiCall(
    sockSdk.getScoreByNPMPackage(pkgName, pkgVersion),
    'package score'
  )
  if (!result.ok) {
    utils.handleUnsuccessfulApiResponse(
      'getIssuesByNPMPackage',
      result.message,
      result.cause ?? '',
      result.data?.code ?? 0
    )
  }
  if (!scoreResult.ok) {
    utils.handleUnsuccessfulApiResponse(
      'getScoreByNPMPackage',
      scoreResult.message,
      scoreResult.cause ?? '',
      scoreResult.data?.code ?? 0
    )
  }
  const severityCount = utils.getSeverityCount(
    result.data,
    includeAllIssues ? undefined : 'high'
  )
  return {
    data: result.data,
    severityCount,
    score: scoreResult.data
  }
}

const { NPM: NPM$9 } = registryConstants
function formatScore$1(score) {
  if (score > 80) {
    return vendor.yoctocolorsCjsExports.green(`${score}`)
  } else if (score < 80 && score > 60) {
    return vendor.yoctocolorsCjsExports.yellow(`${score}`)
  }
  return vendor.yoctocolorsCjsExports.red(`${score}`)
}
function outputPackageIssuesDetails(packageData, outputMarkdown) {
  const issueDetails = packageData.filter(
    d =>
      d.value?.severity === utils.ALERT_SEVERITY.critical ||
      d.value?.severity === utils.ALERT_SEVERITY.high
  )
  const uniqueIssueDetails = issueDetails.reduce((acc, issue) => {
    const { type } = issue
    if (type) {
      const details = acc.get(type)
      if (details) {
        details.count += 1
      } else {
        acc.set(type, {
          label: issue.value?.label ?? '',
          count: 1
        })
      }
    }
    return acc
  }, new Map())
  const format = new utils.ColorOrMarkdown(outputMarkdown)
  for (const [type, details] of uniqueIssueDetails.entries()) {
    const issueWithLink = format.hyperlink(
      details.label,
      utils.getSocketDevAlertUrl(type),
      {
        fallbackToUrl: true
      }
    )
    if (details.count === 1) {
      logger.logger.log(`- ${issueWithLink}`)
    } else {
      logger.logger.log(`- ${issueWithLink}: ${details.count}`)
    }
  }
}
function outputPackageInfo(
  { data, score, severityCount },
  { commandName, outputKind, pkgName, pkgVersion }
) {
  if (outputKind === 'json') {
    logger.logger.log(JSON.stringify(data, undefined, 2))
    return
  }
  if (outputKind === 'markdown') {
    logger.logger.log(
      `
# Package report for ${pkgName}

Package report card:
    `.trim()
    )
  } else {
    logger.logger.log(`Package report card for ${pkgName}:`)
  }
  const scoreResult = {
    'Supply Chain Risk': Math.floor(score.supplyChainRisk.score * 100),
    Maintenance: Math.floor(score.maintenance.score * 100),
    Quality: Math.floor(score.quality.score * 100),
    Vulnerabilities: Math.floor(score.vulnerability.score * 100),
    License: Math.floor(score.license.score * 100)
  }
  logger.logger.log('\n')
  Object.entries(scoreResult).map(score =>
    logger.logger.log(`- ${score[0]}: ${formatScore$1(score[1])}`)
  )
  logger.logger.log('\n')
  if (objects.hasKeys(severityCount)) {
    if (outputKind === 'markdown') {
      logger.logger.log('# Issues\n')
    }
    logger.logger.log(
      `Package has these issues: ${utils.formatSeverityCount(severityCount)}\n`
    )
    outputPackageIssuesDetails(data, outputKind === 'markdown')
  } else {
    logger.logger.log('Package has no issues')
  }
  const format = new utils.ColorOrMarkdown(outputKind === 'markdown')
  const url = utils.getSocketDevPackageOverviewUrl(NPM$9, pkgName, pkgVersion)
  logger.logger.log('\n')
  if (pkgVersion === 'latest') {
    logger.logger.log(
      `Detailed info on socket.dev: ${format.hyperlink(`${pkgName}`, url, {
        fallbackToUrl: true
      })}`
    )
  } else {
    logger.logger.log(
      `Detailed info on socket.dev: ${format.hyperlink(
        `${pkgName} v${pkgVersion}`,
        url,
        {
          fallbackToUrl: true
        }
      )}`
    )
  }
  if (outputKind !== 'markdown') {
    logger.logger.log(
      vendor.yoctocolorsCjsExports.dim(
        `\nOr rerun ${vendor.yoctocolorsCjsExports.italic(commandName)} using the ${vendor.yoctocolorsCjsExports.italic('--json')} flag to get full JSON output`
      )
    )
  } else {
    logger.logger.log('')
  }
}

async function handlePackageInfo({
  commandName,
  includeAllIssues,
  outputKind,
  pkgName,
  pkgVersion,
  strict
}) {
  const packageData = await fetchPackageInfo(
    pkgName,
    pkgVersion,
    includeAllIssues
  )
  if (packageData) {
    outputPackageInfo(packageData, {
      commandName,
      outputKind,
      pkgName,
      pkgVersion
    })
    if (strict && objects.hasKeys(packageData.severityCount)) {
      // Let NodeJS exit gracefully but with exit(1)
      process.exitCode = 1
    }
  }
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$x } = constants
const config$A = {
  commandName: 'info',
  description: 'Look up info regarding a package',
  hidden: true,
  // Deprecated
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    ...utils.validationFlags
  },
  help: (command, config) =>
    utils.isTestingV1()
      ? 'This command will be removed in v1'
      : `
    Usage
      $ ${command} <name>

    Note: this command will be deprecated in favor of \`socket package score\` soon

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} webtorrent
      $ ${command} webtorrent@1.9.1
  `
}
const cmdInfo = {
  description: config$A.description,
  hidden: config$A.hidden,
  run: run$A
}
async function run$A(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$A,
    importMeta,
    parentName
  })
  const { all, json, markdown, strict } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [rawPkgName = ''] = cli.input
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: !!rawPkgName,
      message: 'Expecting a package name',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: cli.input.length === 1,
      message: 'Can only accept one package at a time',
      pass: 'ok',
      fail: 'got ' + cli.input.length
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    }
  )
  if (!wasValidInput) {
    return
  }
  const versionSeparator = rawPkgName.lastIndexOf('@')
  const pkgName =
    versionSeparator < 1 ? rawPkgName : rawPkgName.slice(0, versionSeparator)
  const pkgVersion =
    versionSeparator < 1 ? 'latest' : rawPkgName.slice(versionSeparator + 1)
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$x)
    return
  }
  await handlePackageInfo({
    commandName: `${parentName} ${config$A.commandName}`,
    includeAllIssues: Boolean(all),
    outputKind,
    pkgName,
    pkgVersion,
    strict: Boolean(strict)
  })
}

function applyLogin(apiToken, enforcedOrgs, apiBaseUrl, apiProxy) {
  utils.updateConfigValue('enforcedOrgs', enforcedOrgs)
  utils.updateConfigValue('apiToken', apiToken)
  utils.updateConfigValue('apiBaseUrl', apiBaseUrl)
  utils.updateConfigValue('apiProxy', apiProxy)
}

const { SOCKET_PUBLIC_API_TOKEN } = constants
async function attemptLogin(apiBaseUrl, apiProxy) {
  apiBaseUrl ??= utils.getConfigValueOrUndef('apiBaseUrl') ?? undefined
  apiProxy ??= utils.getConfigValueOrUndef('apiProxy') ?? undefined
  const apiToken =
    (await prompts.password({
      message: `Enter your ${vendor.terminalLinkExports('Socket.dev API key', 'https://docs.socket.dev/docs/api-keys')} (leave blank for a public key)`
    })) || SOCKET_PUBLIC_API_TOKEN
  const sdk = await utils.setupSdk(apiToken, apiBaseUrl, apiProxy)
  if (!sdk.ok) {
    process.exitCode = 1
    logger.logger.fail(utils.failMsgWithBadge(sdk.message, sdk.cause))
    return
  }
  const result = await utils.handleApiCall(
    sdk.data.getOrganizations(),
    'token verification'
  )
  if (!result.ok) {
    process.exitCode = 1
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  logger.logger.success('API key verified')
  const orgs = result.data
  const enforcedChoices = Object.values(orgs.organizations)
    .filter(org => org?.plan === 'enterprise')
    .map(org => ({
      name: org.name ?? 'undefined',
      value: org.id
    }))
  let enforcedOrgs = []
  if (enforcedChoices.length > 1) {
    const id = await prompts.select({
      message:
        "Which organization's policies should Socket enforce system-wide?",
      choices: enforcedChoices.concat({
        name: 'None',
        value: '',
        description: 'Pick "None" if this is a personal device'
      })
    })
    if (id) {
      enforcedOrgs = [id]
    }
  } else if (enforcedChoices.length) {
    if (
      await prompts.confirm({
        message: `Should Socket enforce ${enforcedChoices[0]?.name}'s security policies system-wide?`,
        default: true
      })
    ) {
      const existing = enforcedChoices[0]
      if (existing) {
        enforcedOrgs = [existing.value]
      }
    }
  }
  const previousPersistedToken = utils.getConfigValueOrUndef('apiToken')
  try {
    applyLogin(apiToken, enforcedOrgs, apiBaseUrl, apiProxy)
    logger.logger.success(
      `API credentials ${previousPersistedToken === apiToken ? 'refreshed' : previousPersistedToken ? 'updated' : 'set'}`
    )
    if (utils.isReadOnlyConfig()) {
      logger.logger.log('')
      logger.logger.warn(
        'Note: config is in read-only mode, at least one key was overridden through flag/env, so the login was not persisted!'
      )
    }
  } catch {
    process.exitCode = 1
    logger.logger.fail(`API login failed`)
  }
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$w } = constants
const config$z = {
  commandName: 'login',
  description: 'Socket API login',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    apiBaseUrl: {
      type: 'string',
      description: 'API server to connect to for login'
    },
    apiProxy: {
      type: 'string',
      description: 'Proxy to use when making connection to API server'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}

    API Token Requirements
      - Quota: 1 unit

    Logs into the Socket API by prompting for an API key

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}
      $ ${command} --api-proxy=http://localhost:1234
  `
}
const cmdLogin = {
  description: config$z.description,
  hidden: config$z.hidden,
  run: run$z
}
async function run$z(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$z,
    importMeta,
    parentName
  })
  const apiBaseUrl = cli.flags['apiBaseUrl']
  const apiProxy = cli.flags['apiProxy']
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$w)
    return
  }
  if (!vendor.isInteractiveExports()) {
    throw new utils.InputError(
      'Cannot prompt for credentials in a non-interactive shell'
    )
  }
  await attemptLogin(apiBaseUrl, apiProxy)
}

function applyLogout() {
  utils.updateConfigValue('apiToken', null)
  utils.updateConfigValue('apiBaseUrl', null)
  utils.updateConfigValue('apiProxy', null)
  utils.updateConfigValue('enforcedOrgs', null)
}

function attemptLogout() {
  try {
    applyLogout()
    logger.logger.success('Successfully logged out')
    if (utils.isReadOnlyConfig()) {
      logger.logger.log('')
      logger.logger.warn(
        'Note: config is in read-only mode, at least one key was overridden through flag/env, so the logout was not persisted!'
      )
    }
  } catch {
    logger.logger.fail('Failed to complete logout steps')
  }
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$v } = constants
const config$y = {
  commandName: 'logout',
  description: 'Socket API logout',
  hidden: false,
  flags: {
    ...utils.commonFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}

    Logs out of the Socket API and clears all Socket credentials from disk
  `
}
const cmdLogout = {
  description: config$y.description,
  hidden: config$y.hidden,
  run: run$y
}
async function run$y(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$y,
    importMeta,
    parentName
  })
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$v)
    return
  }
  attemptLogout()
}

async function convertCondaToRequirements(target, cwd, verbose) {
  let contents
  if (target === '-') {
    if (verbose) {
      logger.logger.error(`[VERBOSE] reading input from stdin`)
    }
    const buf = []
    contents = await new Promise((resolve, reject) => {
      process.stdin.on('data', chunk => {
        const input = chunk.toString()
        buf.push(input)
      })
      process.stdin.on('end', () => {
        resolve(buf.join(''))
      })
      process.stdin.on('error', e => {
        if (verbose) {
          logger.logger.error('Unexpected error while reading from stdin:', e)
        }
        reject(e)
      })
      process.stdin.on('close', () => {
        if (buf.length === 0) {
          if (verbose) {
            logger.logger.error('stdin closed explicitly without data received')
          }
          reject(new Error('No data received from stdin'))
        } else {
          if (verbose) {
            logger.logger.error(
              'warning: stdin closed explicitly with some data received'
            )
          }
          resolve(buf.join(''))
        }
      })
    })
    if (!contents) {
      return {
        ok: false,
        message: 'Manifest Generation Failed',
        cause: 'No data received from stdin'
      }
    }
  } else {
    const f = path.resolve(cwd, target)
    if (verbose) {
      logger.logger.error(`[VERBOSE] target file: ${f}`)
    }
    if (!fs$1.existsSync(f)) {
      return {
        ok: false,
        message: 'Manifest Generation Failed',
        cause: `Input file not found at ${f}`
      }
    }
    contents = fs$1.readFileSync(target, 'utf8')
    if (!contents) {
      return {
        ok: false,
        message: 'Manifest Generation Failed',
        cause: 'File is empty'
      }
    }
  }
  return {
    ok: true,
    data: {
      contents,
      pip: convertCondaToRequirementsFromInput(contents)
    }
  }
}

// Just extract the first pip block, if one exists at all.
function convertCondaToRequirementsFromInput(input) {
  const keeping = []
  let collecting = false
  let delim = '-'
  let indent = ''
  input.split('\n').some(line => {
    if (!line) {
      // Ignore empty lines
      return
    }
    if (collecting) {
      if (line.startsWith('#')) {
        // Ignore comment lines (keep?)
        return
      }
      if (line.startsWith(delim)) {
        // In this case we have a line with the same indentation as the
        // `- pip:` line, so we have reached the end of the pip block.
        return true // the end
      } else {
        if (!indent) {
          // Store the indentation of the block
          if (line.trim().startsWith('-')) {
            indent = line.split('-')[0] + '-'
            if (indent.length <= delim.length) {
              // The first line after the `pip:` line does not indent further
              // than that so the block is empty?
              return true
            }
          }
        }
        if (line.startsWith(indent)) {
          keeping.push(line.slice(indent.length).trim())
        } else {
          // Unexpected input. bail.
          return true
        }
      }
    } else {
      // Note: the line may end with a line comment so don't === it.
      if (line.trim().startsWith('- pip:')) {
        delim = line.split('-')[0] + '-'
        collecting = true
      }
    }
  })
  return keeping.join('\n')
}

async function outputRequirements(result, outputKind, out) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result))
      return
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  if (outputKind === 'json') {
    const json = utils.serializeResultJson(result)
    if (out === '-') {
      logger.logger.log(json)
    } else {
      fs$1.writeFileSync(out, json, 'utf8')
    }
    return
  }
  if (outputKind === 'markdown') {
    const arr = []
    arr.push('# Converted Conda file')
    arr.push('')
    arr.push(
      'This is the Conda `environment.yml` file converted to python `requirements.txt`:'
    )
    arr.push('')
    arr.push('```file=requirements.txt')
    arr.push(result.data.pip)
    arr.push('```')
    arr.push('')
    const md = arr.join('\n')
    if (out === '-') {
      logger.logger.log(md)
    } else {
      fs$1.writeFileSync(out, md, 'utf8')
    }
    return
  }
  if (out === '-') {
    logger.logger.log(result.data.pip)
    logger.logger.log('')
  } else {
    fs$1.writeFileSync(out, result.data.pip, 'utf8')
  }
}

async function handleManifestConda(target, out, outputKind, cwd, verbose) {
  const data = await convertCondaToRequirements(target, cwd, verbose)
  await outputRequirements(data, outputKind, out)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$u } = constants
const config$x = {
  commandName: 'conda',
  description:
    '[beta] Convert a Conda environment.yml file to a python requirements.txt',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    out: {
      type: 'string',
      default: '-',
      description: 'Output target (use `-` or omit to print to stdout)'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} FILE

    Warning: While we don't support Conda necessarily, this tool extracts the pip
             block from an environment.yml and outputs it as a requirements.txt
             which you can scan as if it were a pypi package.

    USE AT YOUR OWN RISK

    Note: FILE can be a dash (-) to indicate stdin. This way you can pipe the
          contents of a file to have it processed.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples

      $ ${command} ./environment.yml
  `
}
const cmdManifestConda = {
  description: config$x.description,
  hidden: config$x.hidden,
  run: run$x
}
async function run$x(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$x,
    importMeta,
    parentName
  })
  const {
    cwd = process.cwd(),
    json = false,
    markdown = false,
    out = '-',
    verbose = false
  } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown) // TODO: impl json/md further

  const [target = ''] = cli.input
  if (verbose) {
    logger.logger.group('- ', parentName, config$x.commandName, ':')
    logger.logger.group('- flags:', cli.flags)
    logger.logger.groupEnd()
    logger.logger.log('- target:', target)
    logger.logger.log('- output:', out)
    logger.logger.groupEnd()
  }
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: !!target,
      message: 'The FILE arg is required',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: cli.input.length <= 1,
      message: 'Can only accept one DIR (make sure to escape spaces!)',
      pass: 'ok',
      fail: 'received ' + cli.input.length
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    }
  )
  if (!wasValidInput) {
    return
  }
  logger.logger.error(
    'Warning: This will approximate your Conda dependencies using PyPI. We do not yet officially support Conda. Use at your own risk.'
  )
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$u)
    return
  }
  await handleManifestConda(
    target,
    String(out || ''),
    json ? 'json' : markdown ? 'markdown' : 'text',
    String(cwd),
    Boolean(verbose)
  )
}

async function convertGradleToMaven(target, bin, cwd, verbose, gradleOpts) {
  // TODO: impl json/md
  if (verbose) {
    logger.logger.log('[VERBOSE] Resolving:', [cwd, bin])
  }
  const rbin = path.resolve(cwd, bin)
  if (verbose) {
    logger.logger.log('[VERBOSE] Resolving:', [cwd, target])
  }
  const rtarget = path.resolve(cwd, target)
  const binExists = fs$1.existsSync(rbin)
  const targetExists = fs$1.existsSync(rtarget)
  logger.logger.group('gradle2maven:')
  if (verbose || debug.isDebug()) {
    logger.logger.log(
      `[VERBOSE] - Absolute bin path: \`${rbin}\` (${binExists ? 'found' : vendor.yoctocolorsCjsExports.red('not found!')})`
    )
    logger.logger.log(
      `[VERBOSE] - Absolute target path: \`${rtarget}\` (${targetExists ? 'found' : vendor.yoctocolorsCjsExports.red('not found!')})`
    )
  } else {
    logger.logger.log(`- executing: \`${rbin}\``)
    if (!binExists) {
      logger.logger.warn(
        'Warning: It appears the executable could not be found at this location. An error might be printed later because of that.'
      )
    }
    logger.logger.log(`- src dir: \`${rtarget}\``)
    if (!targetExists) {
      logger.logger.warn(
        'Warning: It appears the src dir could not be found at this location. An error might be printed later because of that.'
      )
    }
  }
  logger.logger.groupEnd()
  try {
    // Run gradlew with the init script we provide which should yield zero or more
    // pom files. We have to figure out where to store those pom files such that
    // we can upload them and predict them through the GitHub API. We could do a
    // .socket folder. We could do a socket.pom.gz with all the poms, although
    // I'd prefer something plain-text if it is to be committed.

    // Note: init.gradle will be exported by .config/rollup.dist.config.mjs
    const initLocation = path.join(constants.distPath, 'init.gradle')
    const commandArgs = ['--init-script', initLocation, ...gradleOpts, 'pom']
    if (verbose) {
      logger.logger.log('[VERBOSE] Executing:', [bin], ', args:', commandArgs)
    }
    logger.logger.log(
      `Converting gradle to maven from \`${bin}\` on \`${target}\` ...`
    )
    const output = await execGradleWithSpinner(rbin, commandArgs, rtarget, cwd)
    if (verbose) {
      logger.logger.group('[VERBOSE] gradle stdout:')
      logger.logger.log(output)
      logger.logger.groupEnd()
    }
    if (output.code !== 0) {
      process.exitCode = 1
      logger.logger.fail(`Gradle exited with exit code ${output.code}`)
      // (In verbose mode, stderr was printed above, no need to repeat it)
      if (!verbose) {
        logger.logger.group('stderr:')
        logger.logger.error(output.stderr)
        logger.logger.groupEnd()
      }
      return
    }
    logger.logger.success('Executed gradle successfully')
    logger.logger.log('Reported exports:')
    output.stdout.replace(/^POM file copied to: (.*)/gm, (_all, fn) => {
      logger.logger.log('- ', fn)
      return fn
    })
    logger.logger.log('')
    logger.logger.log(
      'Next step is to generate a Scan by running the `socket scan create` command on the same directory'
    )
  } catch (e) {
    process.exitCode = 1
    logger.logger.fail(
      'There was an unexpected error while generating manifests' +
        (verbose ? '' : '  (use --verbose for details)')
    )
    if (verbose) {
      logger.logger.group('[VERBOSE] error:')
      logger.logger.log(e)
      logger.logger.groupEnd()
    }
  }
}
async function execGradleWithSpinner(bin, commandArgs, target, cwd) {
  // Lazily access constants.spinner.
  const { spinner } = constants
  let pass = false
  try {
    spinner.start(
      `Running gradlew... (this can take a while, it depends on how long gradlew has to run)`
    )
    const output = await spawn.spawn(bin, commandArgs, {
      // We can pipe the output through to have the user see the result
      // of running gradlew, but then we can't (easily) gather the output
      // to discover the generated files... probably a flag we should allow?
      // stdio: isDebug() ? 'inherit' : undefined,
      cwd: target || cwd
    })
    pass = true
    const { code, stderr, stdout } = output
    return {
      code,
      stdout,
      stderr
    }
  } finally {
    if (pass) {
      spinner.successAndStop('Completed gradlew execution')
    } else {
      spinner.failAndStop('There was an error while trying to run gradlew.')
    }
  }
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$t } = constants
const config$w = {
  commandName: 'gradle',
  description:
    '[beta] Use Gradle to generate a manifest file (`pom.xml`) for a Gradle/Java/Kotlin/etc project',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    bin: {
      type: 'string',
      description: 'Location of gradlew binary to use, default: CWD/gradlew'
    },
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    gradleOpts: {
      type: 'string',
      default: '',
      description:
        'Additional options to pass on to ./gradlew, see `./gradlew --help`'
    },
    task: {
      type: 'string',
      default: 'all',
      description: 'Task to target. By default targets all'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [--bin=path/to/gradle/binary] [--out=path/to/result] DIR

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Uses gradle, preferably through your local project \`gradlew\`, to generate a
    \`pom.xml\` file for each task. If you have no \`gradlew\` you can try the
    global \`gradle\` binary but that may not work (hard to predict).

    The \`pom.xml\` is a manifest file similar to \`package.json\` for npm or
    or requirements.txt for PyPi), but specifically for Maven, which is Java's
    dependency repository. Languages like Kotlin and Scala piggy back on it too.

    There are some caveats with the gradle to \`pom.xml\` conversion:

    - each task will generate its own xml file and by default it generates one xml
      for every task.

    - it's possible certain features don't translate well into the xml. If you
      think something is missing that could be supported please reach out.

    - it works with your \`gradlew\` from your repo and local settings and config

    Support is beta. Please report issues or give us feedback on what's missing.

    Examples

      $ ${command} .
      $ ${command} --bin=../gradlew .
  `
}
const cmdManifestGradle = {
  description: config$w.description,
  hidden: config$w.hidden,
  run: run$w
}
async function run$w(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$w,
    importMeta,
    parentName
  })
  const verbose = Boolean(cli.flags['verbose'])
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown) // TODO: impl json/md further

  if (verbose) {
    logger.logger.group('- ', parentName, config$w.commandName, ':')
    logger.logger.group('- flags:', cli.flags)
    logger.logger.groupEnd()
    logger.logger.log('- input:', cli.input)
    logger.logger.groupEnd()
  }
  const [target = ''] = cli.input

  // TODO: I'm not sure it's feasible to parse source file from stdin. We could
  //       try, store contents in a file in some folder, target that folder... what
  //       would the file name be?

  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: !!target && target !== '-',
      message: 'The DIR arg is required',
      pass: 'ok',
      fail: target === '-' ? 'stdin is not supported' : 'missing'
    },
    {
      nook: true,
      test: cli.input.length <= 1,
      message: 'Can only accept one DIR (make sure to escape spaces!)',
      pass: 'ok',
      fail: 'received ' + cli.input.length
    }
  )
  if (!wasValidInput) {
    return
  }
  const { bin = path.join(target, 'gradlew'), cwd = process.cwd() } = cli.flags
  if (verbose) {
    logger.logger.group()
    logger.logger.log('- target:', target)
    logger.logger.log('- gradle bin:', bin)
    logger.logger.groupEnd()
  }
  let gradleOpts = []
  if (cli.flags['gradleOpts']) {
    gradleOpts = cli.flags['gradleOpts']
      .split(' ')
      .map(s => s.trim())
      .filter(Boolean)
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$t)
    return
  }
  await convertGradleToMaven(
    target,
    String(bin),
    String(cwd),
    verbose,
    gradleOpts
  )
}

async function convertSbtToMaven(target, bin, out, verbose, sbtOpts) {
  // TODO: impl json/md

  // Lazily access constants.spinner.
  const { spinner } = constants
  const rbin = path.resolve(bin)
  const rtarget = path.resolve(target)
  if (verbose) {
    logger.logger.group('sbt2maven:')
    logger.logger.log(`[VERBOSE] - Absolute bin path: \`${rbin}\``)
    logger.logger.log(`[VERBOSE] - Absolute target path: \`${rtarget}\``)
    // logger.log(`[VERBOSE] - Absolute out path: \`${rout}\``)
    logger.logger.groupEnd()
  } else {
    logger.logger.group('sbt2maven:')
    logger.logger.log(`- executing: \`${bin}\``)
    logger.logger.log(`- src dir: \`${target}\``)
    // logger.log(`- dst dir: \`${out}\``)
    logger.logger.groupEnd()
  }
  try {
    spinner.start(`Converting sbt to maven from \`${bin}\` on \`${target}\`...`)

    // Run sbt with the init script we provide which should yield zero or more
    // pom files. We have to figure out where to store those pom files such that
    // we can upload them and predict them through the GitHub API. We could do a
    // .socket folder. We could do a socket.pom.gz with all the poms, although
    // I'd prefer something plain-text if it is to be committed.
    const output = await spawn.spawn(bin, ['makePom'].concat(sbtOpts), {
      cwd: target || '.'
    })
    spinner.stop()
    if (verbose) {
      logger.logger.group('[VERBOSE] sbt stdout:')
      logger.logger.log(output)
      logger.logger.groupEnd()
    }
    if (output.stderr) {
      process.exitCode = 1
      logger.logger.fail('There were errors while running sbt')
      // (In verbose mode, stderr was printed above, no need to repeat it)
      if (!verbose) {
        logger.logger.group('[VERBOSE] stderr:')
        logger.logger.error(output.stderr)
        logger.logger.groupEnd()
      }
      return
    }
    const poms = []
    output.stdout.replace(/Wrote (.*?.pom)\n/g, (_all, fn) => {
      poms.push(fn)
      return fn
    })
    if (!poms.length) {
      process.exitCode = 1
      logger.logger.fail(
        'There were no errors from sbt but it seems to not have generated any poms either'
      )
      return
    }
    // Move the pom file to ...? initial cwd? loc will be an absolute path, or dump to stdout
    // TODO: what to do with multiple output files? Do we want to dump them to stdout? Raw or with separators or ?
    // TODO: maybe we can add an option to target a specific file to dump to stdout
    if (out === '-' && poms.length === 1) {
      logger.logger.log('Result:\n```')
      logger.logger.log(await utils.safeReadFile(poms[0]))
      logger.logger.log('```')
      logger.logger.success(`OK`)
    } else if (out === '-') {
      process.exitCode = 1
      logger.logger.fail(
        'Requested out target was stdout but there are multiple generated files'
      )
      poms.forEach(fn => logger.logger.error('-', fn))
      logger.logger.error('Exiting now...')
      return
    } else {
      // if (verbose) {
      //   logger.log(
      //     `Moving manifest file from \`${loc.replace(/^\/home\/[^/]*?\//, '~/')}\` to \`${out}\``
      //   )
      // } else {
      //   logger.log('Moving output pom file')
      // }
      // TODO: do we prefer fs-extra? renaming can be gnarly on windows and fs-extra's version is better
      // await renamep(loc, out)
      logger.logger.success(`Generated ${poms.length} pom files`)
      poms.forEach(fn => logger.logger.log('-', fn))
      logger.logger.success(`OK`)
    }
  } catch (e) {
    process.exitCode = 1
    spinner.stop()
    logger.logger.fail(
      'There was an unexpected error while running this' +
        (verbose ? '' : ' (use --verbose for details)')
    )
    if (verbose) {
      logger.logger.group('[VERBOSE] error:')
      logger.logger.log(e)
      logger.logger.groupEnd()
    }
  }
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$s } = constants
const config$v = {
  commandName: 'scala',
  description:
    "[beta] Generate a manifest file (`pom.xml`) from Scala's `build.sbt` file",
  hidden: false,
  flags: {
    ...utils.commonFlags,
    bin: {
      type: 'string',
      default: 'sbt',
      description: 'Location of sbt binary to use'
    },
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    out: {
      type: 'string',
      default: './socket.pom.xml',
      description:
        'Path of output file; where to store the resulting manifest, see also --stdout'
    },
    stdout: {
      type: 'boolean',
      description: 'Print resulting pom.xml to stdout (supersedes --out)'
    },
    sbtOpts: {
      type: 'string',
      default: '',
      description: 'Additional options to pass on to sbt, as per `sbt --help`'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [--bin=path/to/sbt/binary] [--out=path/to/result] FILE|DIR

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Uses \`sbt makePom\` to generate a \`pom.xml\` from your \`build.sbt\` file.
    This xml file is the dependency manifest (like a package.json
    for Node.js or requirements.txt for PyPi), but specifically for Scala.

    There are some caveats with \`build.sbt\` to \`pom.xml\` conversion:

    - the xml is exported as socket.pom.xml as to not confuse existing build tools
      but it will first hit your /target/sbt<version> folder (as a different name)

    - the pom.xml format (standard by Scala) does not support certain sbt features
      - \`excludeAll()\`, \`dependencyOverrides\`, \`force()\`, \`relativePath\`
      - For details: https://www.scala-sbt.org/1.x/docs/Library-Management.html

    - it uses your sbt settings and local configuration verbatim

    - it can only export one target per run, so if you have multiple targets like
      development and production, you must run them separately.

    You can optionally configure the path to the \`sbt\` bin to invoke.

    Support is beta. Please report issues or give us feedback on what's missing.

    This is only for SBT. If your Scala setup uses gradle, please see the help
    sections for \`socket manifest gradle\` or \`socket cdxgen\`.

    Examples

      $ ${command} ./build.sbt
      $ ${command} --bin=/usr/bin/sbt ./build.sbt
  `
}
const cmdManifestScala = {
  description: config$v.description,
  hidden: config$v.hidden,
  run: run$v
}
async function run$v(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$v,
    importMeta,
    parentName
  })
  const verbose = Boolean(cli.flags['verbose'])
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown) // TODO: impl json/md further

  if (verbose) {
    logger.logger.group('- ', parentName, config$v.commandName, ':')
    logger.logger.group('- flags:', cli.flags)
    logger.logger.groupEnd()
    logger.logger.log('- input:', cli.input)
    logger.logger.groupEnd()
  }
  const [target = ''] = cli.input

  // TODO: I'm not sure it's feasible to parse source file from stdin. We could
  //       try, store contents in a file in some folder, target that folder... what
  //       would the file name be?

  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: !!target && target !== '-',
      message: 'The DIR arg is required',
      pass: 'ok',
      fail: target === '-' ? 'stdin is not supported' : 'missing'
    },
    {
      nook: true,
      test: cli.input.length <= 1,
      message: 'Can only accept one DIR (make sure to escape spaces!)',
      pass: 'ok',
      fail: 'received ' + cli.input.length
    }
  )
  if (!wasValidInput) {
    return
  }
  let bin = 'sbt'
  if (cli.flags['bin']) {
    bin = cli.flags['bin']
  }
  let out = './socket.pom.xml'
  if (cli.flags['out']) {
    out = cli.flags['out']
  }
  if (cli.flags['stdout']) {
    out = '-'
  }
  if (verbose) {
    logger.logger.group()
    logger.logger.log('- target:', target)
    logger.logger.log('- gradle bin:', bin)
    logger.logger.log('- out:', out)
    logger.logger.groupEnd()
  }
  let sbtOpts = []
  if (cli.flags['sbtOpts']) {
    sbtOpts = cli.flags['sbtOpts']
      .split(' ')
      .map(s => s.trim())
      .filter(Boolean)
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$s)
    return
  }
  await convertSbtToMaven(target, bin, out, verbose, sbtOpts)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$r } = constants
const config$u = {
  commandName: 'auto',
  description: 'Auto-detect build and attempt to generate manifest file',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    verbose: {
      type: 'boolean',
      default: false,
      description: 'Enable debug output, may help when running into errors'
    }
    // TODO: support output flags
  },
  help: (command, config) => `
    Usage
      $ ${command}

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Tries to figure out what language your current repo uses. If it finds a
    supported case then it will try to generate the manifest file for that
    language with the default or detected settings.
  `
}
const cmdManifestAuto = {
  description: config$u.description,
  hidden: config$u.hidden,
  run: run$u
}
async function run$u(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$u,
    importMeta,
    parentName
  })
  const verbose = !!cli.flags['verbose']
  const cwd = cli.flags['cwd'] ?? process.cwd()
  // TODO: impl json/md

  if (verbose) {
    logger.logger.group('- ', parentName, config$u.commandName, ':')
    logger.logger.group('- flags:', cli.flags)
    logger.logger.groupEnd()
    logger.logger.log('- input:', cli.input)
    logger.logger.log('- cwd:', cwd)
    logger.logger.groupEnd()
  }
  const subArgs = []
  if (verbose) {
    subArgs.push('--verbose')
  }
  const dir = cwd
  if (fs$1.existsSync(path.join(dir, 'build.sbt'))) {
    logger.logger.log(
      'Detected a Scala sbt build, running default Scala generator...'
    )
    if (cwd) {
      subArgs.push('--cwd', cwd)
    }
    subArgs.push(dir)
    if (cli.flags['dryRun']) {
      logger.logger.log(DRY_RUN_BAILING_NOW$r)
      return
    }
    await cmdManifestScala.run(subArgs, importMeta, {
      parentName
    })
    return
  }
  if (fs$1.existsSync(path.join(dir, 'gradlew'))) {
    logger.logger.log(
      'Detected a gradle build, running default gradle generator...'
    )
    if (cwd) {
      // This command takes the cwd as first arg.
      subArgs.push(cwd)
    }
    if (cli.flags['dryRun']) {
      logger.logger.log(DRY_RUN_BAILING_NOW$r)
      return
    }
    await cmdManifestGradle.run(subArgs, importMeta, {
      parentName
    })
    return
  }
  const envyml = path.join(dir, 'environment.yml')
  const hasEnvyml = fs$1.existsSync(envyml)
  const envyaml = path.join(dir, 'environment.yaml')
  const hasEnvyaml = !hasEnvyml && fs$1.existsSync(envyaml)
  if (hasEnvyml || hasEnvyaml) {
    logger.logger.log(
      'Detected an environment.yml file, running default Conda generator...'
    )
    // This command takes the TARGET as first arg.
    subArgs.push(hasEnvyml ? envyml : hasEnvyaml ? envyaml : '')
    if (cli.flags['dryRun']) {
      logger.logger.log(DRY_RUN_BAILING_NOW$r)
      return
    }
    await cmdManifestConda.run(subArgs, importMeta, {
      parentName
    })
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$r)
    return
  }

  // Show new help screen and exit.
  vendor
    .meow(
      `
    $ ${parentName} ${config$u.commandName}

    Unfortunately this script did not discover a supported language in the
    current folder.

    - Make sure this script would work with your target build
    - Make sure to run it from the correct folder
    - Make sure the necessary build tools are available (\`PATH\`)

    If that doesn't work, see \`${parentName} <lang> --help\` for config details for
    your target language.
  `,
      {
        argv: [],
        description: config$u.description,
        importMeta
      }
    )
    .showHelp()
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$q } = constants

// TODO: we may want to dedupe some pieces for all gradle languages. I think it
//       makes sense to have separate commands for them and I think it makes
//       sense for the help panels to note the requested language, rather than
//       `socket manifest kotlin` to print help screens with `gradle` as the
//       command. Room for improvement.
const config$t = {
  commandName: 'kotlin',
  description:
    '[beta] Use Gradle to generate a manifest file (`pom.xml`) for a Kotlin project',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    bin: {
      type: 'string',
      description: 'Location of gradlew binary to use, default: CWD/gradlew'
    },
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    gradleOpts: {
      type: 'string',
      default: '',
      description:
        'Additional options to pass on to ./gradlew, see `./gradlew --help`'
    },
    task: {
      type: 'string',
      default: 'all',
      description: 'Task to target. By default targets all'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [--bin=path/to/gradle/binary] [--out=path/to/result] DIR

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Uses gradle, preferably through your local project \`gradlew\`, to generate a
    \`pom.xml\` file for each task. If you have no \`gradlew\` you can try the
    global \`gradle\` binary but that may not work (hard to predict).

    The \`pom.xml\` is a manifest file similar to \`package.json\` for npm or
    or requirements.txt for PyPi), but specifically for Maven, which is Java's
    dependency repository. Languages like Kotlin and Scala piggy back on it too.

    There are some caveats with the gradle to \`pom.xml\` conversion:

    - each task will generate its own xml file and by default it generates one xml
      for every task. (This may be a good thing!)

    - it's possible certain features don't translate well into the xml. If you
      think something is missing that could be supported please reach out.

    - it works with your \`gradlew\` from your repo and local settings and config

    Support is beta. Please report issues or give us feedback on what's missing.

    Examples

      $ ${command} .
      $ ${command} --bin=../gradlew .
  `
}
const cmdManifestKotlin = {
  description: config$t.description,
  hidden: config$t.hidden,
  run: run$t
}
async function run$t(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$t,
    importMeta,
    parentName
  })
  const verbose = Boolean(cli.flags['verbose'])
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown) // TODO: impl json/md further

  if (verbose) {
    logger.logger.group('- ', parentName, config$t.commandName, ':')
    logger.logger.group('- flags:', cli.flags)
    logger.logger.groupEnd()
    logger.logger.log('- input:', cli.input)
    logger.logger.groupEnd()
  }
  const [target = ''] = cli.input

  // TODO: I'm not sure it's feasible to parse source file from stdin. We could
  //       try, store contents in a file in some folder, target that folder... what
  //       would the file name be?

  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: !!target && target !== '-',
      message: 'The DIR arg is required',
      pass: 'ok',
      fail: target === '-' ? 'stdin is not supported' : 'missing'
    },
    {
      nook: true,
      test: cli.input.length <= 1,
      message: 'Can only accept one DIR (make sure to escape spaces!)',
      pass: 'ok',
      fail: 'received ' + cli.input.length
    }
  )
  if (!wasValidInput) {
    return
  }
  const { bin = path.join(target, 'gradlew'), cwd = process.cwd() } = cli.flags
  if (verbose) {
    logger.logger.group()
    logger.logger.log('- target:', target)
    logger.logger.log('- gradle bin:', bin)
    logger.logger.groupEnd()
  }
  let gradleOpts = []
  if (cli.flags['gradleOpts']) {
    gradleOpts = cli.flags['gradleOpts']
      .split(' ')
      .map(s => s.trim())
      .filter(Boolean)
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$q)
    return
  }
  await convertGradleToMaven(
    target,
    String(bin),
    String(cwd),
    verbose,
    gradleOpts
  )
}

const config$s = {
  commandName: 'manifest',
  description: 'Generate a dependency manifest for given file or dir',
  hidden: false,
  flags: {
    ...utils.commonFlags
  }
}
const cmdManifest = {
  description: config$s.description,
  hidden: config$s.hidden,
  run: run$s
}
async function run$s(argv, importMeta, { parentName }) {
  await utils.meowWithSubcommands(
    {
      auto: cmdManifestAuto,
      conda: cmdManifestConda,
      scala: cmdManifestScala,
      gradle: cmdManifestGradle,
      kotlin: cmdManifestKotlin
    },
    {
      argv,
      aliases: {
        yolo: {
          description: config$s.description,
          hidden: true,
          argv: ['auto']
        }
      },
      description: config$s.description,
      importMeta,
      flags: config$s.flags,
      name: `${parentName} ${config$s.commandName}`
    }
  )
}

const require$3 = Module.createRequire(
  require$$0.pathToFileURL(__filename).href
)
const { NPM: NPM$8 } = constants
async function wrapNpm(argv) {
  // Lazily access constants.distShadowNpmBinPath.
  const shadowBin = require$3(constants.distShadowNpmBinPath)
  await shadowBin(NPM$8, argv)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$p, NPM: NPM$7 } = constants
const config$r = {
  commandName: 'npm',
  description: `${NPM$7} wrapper functionality`,
  hidden: false,
  flags: {
    ...utils.commonFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}
  `
}
const cmdNpm = {
  description: config$r.description,
  hidden: config$r.hidden,
  run: run$r
}
async function run$r(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$r,
    importMeta,
    parentName
  })
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$p)
    return
  }
  await wrapNpm(argv)
}

const require$2 = Module.createRequire(
  require$$0.pathToFileURL(__filename).href
)
const { NPX: NPX$2 } = constants
async function wrapNpx(argv) {
  // Lazily access constants.distShadowNpmBinPath.
  const shadowBin = require$2(constants.distShadowNpmBinPath)
  await shadowBin(NPX$2, argv)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$o, NPX: NPX$1 } = constants
const config$q = {
  commandName: 'npx',
  description: `${NPX$1} wrapper functionality`,
  hidden: false,
  flags: {
    ...utils.commonFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}
  `
}
const cmdNpx = {
  description: config$q.description,
  hidden: config$q.hidden,
  run: run$q
}
async function run$q(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$q,
    importMeta,
    parentName
  })
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$o)
    return
  }
  await wrapNpx(argv)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$n } = constants
const config$p = {
  commandName: 'oops',
  description: 'Trigger an intentional error (for development)',
  hidden: true,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (parentName, config) => `
    Usage
      $ ${parentName} ${config.commandName}

    Don't run me.
  `
}
const cmdOops = {
  description: config$p.description,
  hidden: config$p.hidden,
  run: run$p
}
async function run$p(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$p,
    importMeta,
    parentName
  })
  const { json, markdown } = cli.flags
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$n)
    return
  }
  if (json) {
    process.exitCode = 1
    logger.logger.log(
      utils.serializeResultJson({
        ok: false,
        message: 'Oops',
        cause: 'This error was intentionally left blank'
      })
    )
  }
  if (markdown) {
    process.exitCode = 1
    logger.logger.fail(
      utils.failMsgWithBadge('Oops', 'This error was intentionally left blank')
    )
    return
  }
  throw new Error('This error was intentionally left blank')
}

const {
  BUN: BUN$4,
  NPM: NPM$6,
  PNPM: PNPM$5,
  VLT: VLT$4,
  YARN_BERRY: YARN_BERRY$4,
  YARN_CLASSIC: YARN_CLASSIC$5
} = constants
function matchLsCmdViewHumanStdout(stdout, name) {
  return stdout.includes(` ${name}@`)
}
function matchQueryCmdStdout(stdout, name) {
  return stdout.includes(`"${name}"`)
}
const depsIncludesByAgent = new Map([
  [BUN$4, matchLsCmdViewHumanStdout],
  [NPM$6, matchQueryCmdStdout],
  [PNPM$5, matchQueryCmdStdout],
  [VLT$4, matchQueryCmdStdout],
  [YARN_BERRY$4, matchLsCmdViewHumanStdout],
  [YARN_CLASSIC$5, matchLsCmdViewHumanStdout]
])

function getDependencyEntries(pkgEnvDetails) {
  const {
    dependencies,
    devDependencies,
    optionalDependencies,
    peerDependencies
  } = pkgEnvDetails.editablePkgJson.content
  return [
    [
      'dependencies',
      dependencies
        ? {
            __proto__: null,
            ...dependencies
          }
        : undefined
    ],
    [
      'devDependencies',
      devDependencies
        ? {
            __proto__: null,
            ...devDependencies
          }
        : undefined
    ],
    [
      'peerDependencies',
      peerDependencies
        ? {
            __proto__: null,
            ...peerDependencies
          }
        : undefined
    ],
    [
      'optionalDependencies',
      optionalDependencies
        ? {
            __proto__: null,
            ...optionalDependencies
          }
        : undefined
    ]
  ].filter(({ 1: o }) => o)
}

const {
  BUN: BUN$3,
  NPM: NPM$5,
  OVERRIDES: OVERRIDES$1,
  PNPM: PNPM$4,
  RESOLUTIONS: RESOLUTIONS$1,
  VLT: VLT$3,
  YARN_BERRY: YARN_BERRY$3,
  YARN_CLASSIC: YARN_CLASSIC$4
} = constants
function getOverridesDataBun(pkgEnvDetails) {
  const overrides = pkgEnvDetails.editablePkgJson.content?.[RESOLUTIONS$1] ?? {}
  return {
    type: YARN_BERRY$3,
    overrides
  }
}

// npm overrides documentation:
// https://docs.npmjs.com/cli/v10/configuring-npm/package-json#overrides
function getOverridesDataNpm(pkgEnvDetails) {
  const overrides = pkgEnvDetails.editablePkgJson.content?.[OVERRIDES$1] ?? {}
  return {
    type: NPM$5,
    overrides
  }
}

// pnpm overrides documentation:
// https://pnpm.io/package_json#pnpmoverrides
function getOverridesDataPnpm(pkgEnvDetails) {
  const overrides =
    pkgEnvDetails.editablePkgJson.content?.[PNPM$4]?.[OVERRIDES$1] ?? {}
  return {
    type: PNPM$4,
    overrides
  }
}
function getOverridesDataVlt(pkgEnvDetails) {
  const overrides = pkgEnvDetails.editablePkgJson.content?.[OVERRIDES$1] ?? {}
  return {
    type: VLT$3,
    overrides
  }
}

// Yarn resolutions documentation:
// https://yarnpkg.com/configuration/manifest#resolutions
function getOverridesDataYarn(pkgEnvDetails) {
  const overrides = pkgEnvDetails.editablePkgJson.content?.[RESOLUTIONS$1] ?? {}
  return {
    type: YARN_BERRY$3,
    overrides
  }
}

// Yarn resolutions documentation:
// https://classic.yarnpkg.com/en/docs/selective-version-resolutions
function getOverridesDataYarnClassic(pkgEnvDetails) {
  const overrides = pkgEnvDetails.editablePkgJson.content?.[RESOLUTIONS$1] ?? {}
  return {
    type: YARN_CLASSIC$4,
    overrides
  }
}
const overridesDataByAgent = new Map([
  [BUN$3, getOverridesDataBun],
  [NPM$5, getOverridesDataNpm],
  [PNPM$4, getOverridesDataPnpm],
  [VLT$3, getOverridesDataVlt],
  [YARN_BERRY$3, getOverridesDataYarn],
  [YARN_CLASSIC$4, getOverridesDataYarnClassic]
])

const {
  BUN: BUN$2,
  LOCK_EXT,
  NPM: NPM$4,
  PNPM: PNPM$3,
  VLT: VLT$2,
  YARN_BERRY: YARN_BERRY$2,
  YARN_CLASSIC: YARN_CLASSIC$3
} = constants
function includesNpm(lockSrc, name) {
  // Detects the package name in the following cases:
  //   "name":
  return lockSrc.includes(`"${name}":`)
}
function includesBun(lockSrc, name, lockName) {
  // This is a bit counterintuitive. When lockName ends with a .lockb
  // we treat it as a yarn.lock. When lockName ends with a .lock we
  // treat it as a package-lock.json. The bun.lock format is not identical
  // package-lock.json, however it close enough for npmLockIncludes to work.
  const lockfileScanner = lockName?.endsWith(LOCK_EXT)
    ? includesNpm
    : includesYarn
  return lockfileScanner(lockSrc, name)
}
function includesPnpm(lockSrc, name) {
  const escapedName = regexps.escapeRegExp(name)
  return new RegExp(
    // Detects the package name in the following cases:
    //   /name/
    //   'name'
    //   name:
    //   name@
    `(?<=^\\s*)(?:(['/])${escapedName}\\1|${escapedName}(?=[:@]))`,
    'm'
  ).test(lockSrc)
}
function includesVlt(lockSrc, name) {
  // Detects the package name in the following cases:
  //   "name"
  return lockSrc.includes(`"${name}"`)
}
function includesYarn(lockSrc, name) {
  const escapedName = regexps.escapeRegExp(name)
  return new RegExp(
    // Detects the package name in the following cases:
    //   "name@
    //   , "name@
    //   name@
    //   , name@
    `(?<=(?:^\\s*|,\\s*)"?)${escapedName}(?=@)`,
    'm'
  ).test(lockSrc)
}
const lockfileIncludesByAgent = new Map([
  [BUN$2, includesBun],
  [NPM$4, includesNpm],
  [PNPM$3, includesPnpm],
  [VLT$2, includesVlt],
  [YARN_BERRY$2, includesYarn],
  [YARN_CLASSIC$3, includesYarn]
])

const {
  BUN: BUN$1,
  NPM: NPM$3,
  PNPM: PNPM$2,
  VLT: VLT$1,
  YARN_BERRY: YARN_BERRY$1,
  YARN_CLASSIC: YARN_CLASSIC$2
} = constants
function cleanupQueryStdout(stdout) {
  if (stdout === '') {
    return ''
  }
  let pkgs
  try {
    pkgs = JSON.parse(stdout)
  } catch {}
  if (!Array.isArray(pkgs)) {
    return ''
  }
  const names = new Set()
  for (const { _id, name, pkgid } of pkgs) {
    // `npm query` results may not have a "name" property, in which case we
    // fallback to "_id" and then "pkgid".
    // `vlt ls --view json` results always have a "name" property.
    const fallback = _id ?? pkgid ?? ''
    const resolvedName = name ?? fallback.slice(0, fallback.indexOf('@', 1))
    // Add package names, except for those under the `@types` scope as those
    // are known to only be dev dependencies.
    if (resolvedName && !resolvedName.startsWith('@types/')) {
      names.add(resolvedName)
    }
  }
  return JSON.stringify([...names], null, 2)
}
function parsableToQueryStdout(stdout) {
  if (stdout === '') {
    return ''
  }
  // Convert the parsable stdout into a json array of unique names.
  // The matchAll regexp looks for a forward (posix) or backward (win32) slash
  // and matches one or more non-slashes until the newline.
  const names = new Set(stdout.matchAll(/(?<=[/\\])[^/\\]+(?=\n)/g))
  return JSON.stringify([...names], null, 2)
}
async function npmQuery(npmExecPath, cwd) {
  let stdout = ''
  try {
    stdout = (
      await spawn.spawn(npmExecPath, ['query', ':not(.dev)'], {
        cwd,
        // Lazily access constants.WIN32.
        shell: constants.WIN32
      })
    ).stdout
  } catch {}
  return cleanupQueryStdout(stdout)
}
async function lsBun(pkgEnvDetails, cwd) {
  try {
    // Bun does not support filtering by production packages yet.
    // https://github.com/oven-sh/bun/issues/8283
    return (
      await spawn.spawn(pkgEnvDetails.agentExecPath, ['pm', 'ls', '--all'], {
        cwd,
        // Lazily access constants.WIN32.
        shell: constants.WIN32
      })
    ).stdout
  } catch {}
  return ''
}
async function lsNpm(pkgEnvDetails, cwd) {
  return await npmQuery(pkgEnvDetails.agentExecPath, cwd)
}
async function lsPnpm(pkgEnvDetails, cwd, options) {
  const npmExecPath = options?.npmExecPath
  if (npmExecPath && npmExecPath !== NPM$3) {
    const result = await npmQuery(npmExecPath, cwd)
    if (result) {
      return result
    }
  }
  let stdout = ''
  try {
    stdout = (
      await spawn.spawn(
        pkgEnvDetails.agentExecPath,
        // Pnpm uses the alternative spelling of parsable.
        // https://en.wiktionary.org/wiki/parsable
        ['ls', '--parseable', '--prod', '--depth', 'Infinity'],
        {
          cwd,
          // Lazily access constants.WIN32.
          shell: constants.WIN32
        }
      )
    ).stdout
  } catch {}
  return parsableToQueryStdout(stdout)
}
async function lsVlt(pkgEnvDetails, cwd) {
  let stdout = ''
  try {
    // See https://docs.vlt.sh/cli/commands/list#options.
    stdout = (
      await spawn.spawn(
        pkgEnvDetails.agentExecPath,
        ['ls', '--view', 'human', ':not(.dev)'],
        {
          cwd,
          // Lazily access constants.WIN32.
          shell: constants.WIN32
        }
      )
    ).stdout
  } catch {}
  return cleanupQueryStdout(stdout)
}
async function lsYarnBerry(pkgEnvDetails, cwd) {
  try {
    return (
      // Yarn Berry does not support filtering by production packages yet.
      // https://github.com/yarnpkg/berry/issues/5117
      (
        await spawn.spawn(
          pkgEnvDetails.agentExecPath,
          ['info', '--recursive', '--name-only'],
          {
            cwd,
            // Lazily access constants.WIN32.
            shell: constants.WIN32
          }
        )
      ).stdout.trim()
    )
  } catch {}
  return ''
}
async function lsYarnClassic(pkgEnvDetails, cwd) {
  try {
    // However, Yarn Classic does support it.
    // https://github.com/yarnpkg/yarn/releases/tag/v1.0.0
    // > Fix: Excludes dev dependencies from the yarn list output when the
    //   environment is production
    return (
      await spawn.spawn(pkgEnvDetails.agentExecPath, ['list', '--prod'], {
        cwd,
        // Lazily access constants.WIN32.
        shell: constants.WIN32
      })
    ).stdout.trim()
  } catch {}
  return ''
}
const lsByAgent = new Map([
  [BUN$1, lsBun],
  [NPM$3, lsNpm],
  [PNPM$2, lsPnpm],
  [VLT$1, lsVlt],
  [YARN_BERRY$1, lsYarnBerry],
  [YARN_CLASSIC$2, lsYarnClassic]
])

const CMD_NAME = 'socket optimize'

const {
  BUN,
  NPM: NPM$2,
  OVERRIDES,
  PNPM: PNPM$1,
  RESOLUTIONS,
  VLT,
  YARN_BERRY,
  YARN_CLASSIC: YARN_CLASSIC$1
} = constants
const depFields = [
  'dependencies',
  'devDependencies',
  'peerDependencies',
  'peerDependenciesMeta',
  'optionalDependencies',
  'bundleDependencies'
]
function getEntryIndexes(entries, keys) {
  return keys
    .map(n => entries.findIndex(p => p[0] === n))
    .filter(n => n !== -1)
    .sort((a, b) => a - b)
}
function getLowestEntryIndex(entries, keys) {
  return getEntryIndexes(entries, keys)?.[0] ?? -1
}
function getHighestEntryIndex(entries, keys) {
  return getEntryIndexes(entries, keys).at(-1) ?? -1
}
function updatePkgJsonField(editablePkgJson, field, value) {
  const oldValue = editablePkgJson.content[field]
  if (oldValue) {
    // The field already exists so we simply update the field value.
    if (field === PNPM$1) {
      const isPnpmObj = objects.isObject(oldValue)
      if (objects.hasKeys(value)) {
        editablePkgJson.update({
          [field]: {
            ...(isPnpmObj ? oldValue : {}),
            overrides: {
              ...(isPnpmObj ? oldValue[OVERRIDES] : {}),
              ...value
            }
          }
        })
      } else {
        // Properties with undefined values are omitted when saved as JSON.
        editablePkgJson.update(
          objects.hasKeys(oldValue)
            ? {
                [field]: {
                  ...(isPnpmObj ? oldValue : {}),
                  overrides: undefined
                }
              }
            : {
                [field]: undefined
              }
        )
      }
    } else if (field === OVERRIDES || field === RESOLUTIONS) {
      // Properties with undefined values are omitted when saved as JSON.
      editablePkgJson.update({
        [field]: objects.hasKeys(value) ? value : undefined
      })
    } else {
      editablePkgJson.update({
        [field]: value
      })
    }
    return
  }
  if (
    (field === OVERRIDES || field === PNPM$1 || field === RESOLUTIONS) &&
    !objects.hasKeys(value)
  ) {
    return
  }
  // Since the field doesn't exist we want to insert it into the package.json
  // in a place that makes sense, e.g. close to the "dependencies" field. If
  // we can't find a place to insert the field we'll add it to the bottom.
  const entries = Object.entries(editablePkgJson.content)
  let insertIndex = -1
  let isPlacingHigher = false
  if (field === OVERRIDES) {
    insertIndex = getLowestEntryIndex(entries, [RESOLUTIONS])
    if (insertIndex === -1) {
      isPlacingHigher = true
      insertIndex = getHighestEntryIndex(entries, [...depFields, PNPM$1])
    }
  } else if (field === RESOLUTIONS) {
    isPlacingHigher = true
    insertIndex = getHighestEntryIndex(entries, [
      ...depFields,
      OVERRIDES,
      PNPM$1
    ])
  } else if (field === PNPM$1) {
    insertIndex = getLowestEntryIndex(entries, [OVERRIDES, RESOLUTIONS])
    if (insertIndex === -1) {
      isPlacingHigher = true
      insertIndex = getHighestEntryIndex(entries, depFields)
    }
  }
  if (insertIndex === -1) {
    insertIndex = getLowestEntryIndex(entries, ['engines', 'files'])
  }
  if (insertIndex === -1) {
    isPlacingHigher = true
    insertIndex = getHighestEntryIndex(entries, ['exports', 'imports', 'main'])
  }
  if (insertIndex === -1) {
    insertIndex = entries.length
  } else if (isPlacingHigher) {
    insertIndex += 1
  }
  entries.splice(insertIndex, 0, [
    field,
    field === PNPM$1
      ? {
          [OVERRIDES]: value
        }
      : value
  ])
  editablePkgJson.fromJSON(
    `${JSON.stringify(Object.fromEntries(entries), null, 2)}\n`
  )
}
function updateOverridesField(pkgEnvDetails, overrides) {
  updatePkgJsonField(pkgEnvDetails.editablePkgJson, OVERRIDES, overrides)
}
function updateResolutionsField(pkgEnvDetails, overrides) {
  updatePkgJsonField(pkgEnvDetails.editablePkgJson, RESOLUTIONS, overrides)
}
function updatePnpmField(pkgEnvDetails, overrides) {
  updatePkgJsonField(pkgEnvDetails.editablePkgJson, PNPM$1, overrides)
}
const updateManifestByAgent = new Map([
  [BUN, updateResolutionsField],
  [NPM$2, updateOverridesField],
  [PNPM$1, updatePnpmField],
  [VLT, updateOverridesField],
  [YARN_BERRY, updateResolutionsField],
  [YARN_CLASSIC$1, updateResolutionsField]
])

const { NPM: NPM$1, PNPM, YARN_CLASSIC } = constants
const manifestNpmOverrides = registry.getManifestData(NPM$1)
async function addOverrides(pkgEnvDetails, pkgPath, options) {
  const {
    agent,
    lockName,
    lockSrc,
    npmExecPath,
    pkgPath: rootPath
  } = pkgEnvDetails
  const {
    logger,
    pin,
    prod,
    spinner,
    state = {
      added: new Set(),
      addedInWorkspaces: new Set(),
      updated: new Set(),
      updatedInWorkspaces: new Set(),
      warnedPnpmWorkspaceRequiresNpm: false
    }
  } = {
    __proto__: null,
    ...options
  }
  const workspacePkgJsonPaths = await utils.globWorkspace(agent, pkgPath)
  const isWorkspace = workspacePkgJsonPaths.length > 0
  const isWorkspaceRoot = pkgPath === rootPath
  const isLockScanned = isWorkspaceRoot && !prod
  const workspaceName = isWorkspaceRoot
    ? 'root'
    : path.relative(rootPath, pkgPath)
  if (
    isWorkspace &&
    agent === PNPM &&
    // npmExecPath will === the agent name IF it CANNOT be resolved.
    npmExecPath === NPM$1 &&
    !state.warnedPnpmWorkspaceRequiresNpm
  ) {
    state.warnedPnpmWorkspaceRequiresNpm = true
    logger?.warn(
      utils.cmdPrefixMessage(
        CMD_NAME,
        `${agent} workspace support requires \`npm ls\`, falling back to \`${agent} list\``
      )
    )
  }
  const overridesDataObjects = []
  if (isWorkspace || pkgEnvDetails.editablePkgJson.content['private']) {
    overridesDataObjects.push(overridesDataByAgent.get(agent)(pkgEnvDetails))
  } else {
    overridesDataObjects.push(
      overridesDataByAgent.get(NPM$1)(pkgEnvDetails),
      overridesDataByAgent.get(YARN_CLASSIC)(pkgEnvDetails)
    )
  }
  spinner?.setText(`Adding overrides to ${workspaceName}...`)
  const depAliasMap = new Map()
  const depEntries = getDependencyEntries(pkgEnvDetails)
  const manifestEntries = manifestNpmOverrides.filter(({ 1: data }) =>
    vendor.semverExports.satisfies(
      // Roughly check Node range as semver.coerce will strip leading
      // v's, carets (^), comparators (<,<=,>,>=,=), and tildes (~).
      vendor.semverExports.coerce(data.engines.node),
      pkgEnvDetails.pkgRequirements.node
    )
  )

  // Chunk package names to process them in parallel 3 at a time.
  await promises.pEach(manifestEntries, 3, async ({ 1: data }) => {
    const { name: sockRegPkgName, package: origPkgName, version } = data
    const major = vendor.semverExports.major(version)
    const sockOverridePrefix = `${NPM$1}:${sockRegPkgName}@`
    const sockOverrideSpec = `${sockOverridePrefix}${pin ? version : `^${major}`}`
    for (const { 1: depObj } of depEntries) {
      const sockSpec = objects.hasOwn(depObj, sockRegPkgName)
        ? depObj[sockRegPkgName]
        : undefined
      if (sockSpec) {
        depAliasMap.set(sockRegPkgName, sockSpec)
      }
      const origSpec = objects.hasOwn(depObj, origPkgName)
        ? depObj[origPkgName]
        : undefined
      if (origSpec) {
        let thisSpec = origSpec
        // Add package aliases for direct dependencies to avoid npm EOVERRIDE
        // errors...
        // https://docs.npmjs.com/cli/v8/using-npm/package-spec#aliases
        if (
          // ...if the spec doesn't start with a valid Socket override.
          !(
            thisSpec.startsWith(sockOverridePrefix) &&
            // Check the validity of the spec by passing it through npa and
            // seeing if it will coerce to a version.
            vendor.semverExports.coerce(vendor.npaExports(thisSpec).rawSpec)
              ?.version
          )
        ) {
          thisSpec = sockOverrideSpec
          depObj[origPkgName] = thisSpec
          state.added.add(sockRegPkgName)
          if (!isWorkspaceRoot) {
            state.addedInWorkspaces.add(workspaceName)
          }
        }
        depAliasMap.set(origPkgName, thisSpec)
      }
    }
    if (isWorkspaceRoot) {
      // The AgentDepsIncludesFn and AgentLockIncludesFn types overlap in their
      // first two parameters. AgentLockIncludesFn accepts an optional third
      // parameter which AgentDepsIncludesFn will ignore so we cast thingScanner
      // as an AgentLockIncludesFn type.
      const thingScanner = isLockScanned
        ? lockfileIncludesByAgent.get(agent)
        : depsIncludesByAgent.get(agent)
      const thingToScan = isLockScanned
        ? lockSrc
        : await lsByAgent.get(agent)(pkgEnvDetails, pkgPath, {
            npmExecPath
          })
      // Chunk package names to process them in parallel 3 at a time.
      await promises.pEach(
        overridesDataObjects,
        3,
        async ({ overrides, type }) => {
          const overrideExists = objects.hasOwn(overrides, origPkgName)
          if (
            overrideExists ||
            thingScanner(thingToScan, origPkgName, lockName)
          ) {
            const oldSpec = overrideExists ? overrides[origPkgName] : undefined
            const origDepAlias = depAliasMap.get(origPkgName)
            const sockRegDepAlias = depAliasMap.get(sockRegPkgName)
            const depAlias = sockRegDepAlias ?? origDepAlias
            let newSpec = sockOverrideSpec
            if (type === NPM$1 && depAlias) {
              // With npm one may not set an override for a package that one directly
              // depends on unless both the dependency and the override itself share
              // the exact same spec. To make this limitation easier to deal with,
              // overrides may also be defined as a reference to a spec for a direct
              // dependency by prefixing the name of the package to match the version
              // of with a $.
              // https://docs.npmjs.com/cli/v8/configuring-npm/package-json#overrides
              newSpec = `$${sockRegDepAlias ? sockRegPkgName : origPkgName}`
            } else if (typeof oldSpec === 'string') {
              const thisSpec = oldSpec.startsWith('$')
                ? depAlias || newSpec
                : oldSpec || newSpec
              if (thisSpec.startsWith(sockOverridePrefix)) {
                if (
                  pin &&
                  vendor.semverExports.major(
                    // Check the validity of the spec by passing it through npa
                    // and seeing if it will coerce to a version. semver.coerce
                    // will strip leading v's, carets (^), comparators (<,<=,>,>=,=),
                    // and tildes (~). If not coerced to a valid version then
                    // default to the manifest entry version.
                    vendor.semverExports.coerce(
                      vendor.npaExports(thisSpec).rawSpec
                    )?.version ?? version
                  ) !== major
                ) {
                  const otherVersion = (
                    await packages.fetchPackageManifest(thisSpec)
                  )?.version
                  if (otherVersion && otherVersion !== version) {
                    newSpec = `${sockOverridePrefix}${pin ? otherVersion : `^${vendor.semverExports.major(otherVersion)}`}`
                  }
                }
              } else {
                newSpec = oldSpec
              }
            }
            if (newSpec !== oldSpec) {
              overrides[origPkgName] = newSpec
              const addedOrUpdated = overrideExists ? 'updated' : 'added'
              state[addedOrUpdated].add(sockRegPkgName)
            }
          }
        }
      )
    }
  })
  if (isWorkspace) {
    // Chunk package names to process them in parallel 3 at a time.
    await promises.pEach(
      workspacePkgJsonPaths,
      3,
      async workspacePkgJsonPath => {
        const otherState = await addOverrides(
          pkgEnvDetails,
          path.dirname(workspacePkgJsonPath),
          {
            logger,
            pin,
            prod,
            spinner
          }
        )
        for (const key of [
          'added',
          'addedInWorkspaces',
          'updated',
          'updatedInWorkspaces'
        ]) {
          for (const value of otherState[key]) {
            state[key].add(value)
          }
        }
      }
    )
  }
  if (state.added.size > 0 || state.updated.size > 0) {
    pkgEnvDetails.editablePkgJson.update(Object.fromEntries(depEntries))
    for (const { overrides, type } of overridesDataObjects) {
      updateManifestByAgent.get(type)(
        pkgEnvDetails,
        objects.toSortedObject(overrides)
      )
    }
    await pkgEnvDetails.editablePkgJson.save()
  }
  return state
}

const { NPM_BUGGY_OVERRIDES_PATCHED_VERSION } = constants
async function updateLockfile(pkgEnvDetails, options) {
  const {
    cmdName = '',
    logger,
    spinner
  } = {
    __proto__: null,
    ...options
  }
  const isSpinning = !!spinner?.['isSpinning']
  if (!isSpinning) {
    spinner?.start()
  }
  spinner?.setText(`Updating ${pkgEnvDetails.lockName}...`)
  try {
    await utils.runAgentInstall(pkgEnvDetails, {
      spinner
    })
    if (pkgEnvDetails.features.npmBuggyOverrides) {
      spinner?.stop()
      logger?.log(
        `💡 Re-run ${cmdName ? `${cmdName} ` : ''}whenever ${pkgEnvDetails.lockName} changes.\n   This can be skipped for ${pkgEnvDetails.agent} >=${NPM_BUGGY_OVERRIDES_PATCHED_VERSION}.`
      )
    }
  } catch (e) {
    spinner?.stop()
    logger?.fail(
      utils.cmdPrefixMessage(
        cmdName,
        `${pkgEnvDetails.agent} install failed to update ${pkgEnvDetails.lockName}`
      )
    )
    logger?.error(e)
  }
  if (isSpinning) {
    spinner?.start()
  } else {
    spinner?.stop()
  }
}

function createActionMessage(verb, overrideCount, workspaceCount) {
  return `${verb} ${overrideCount} Socket.dev optimized ${words.pluralize('override', overrideCount)}${workspaceCount ? ` in ${workspaceCount} ${words.pluralize('workspace', workspaceCount)}` : ''}`
}
async function applyOptimization(cwd, pin, prod) {
  const pkgEnvDetails = await utils.detectAndValidatePackageEnvironment(cwd, {
    cmdName: CMD_NAME,
    logger: logger.logger,
    prod
  })
  if (!pkgEnvDetails) {
    return
  }
  // Lazily access constants.spinner.
  const { spinner } = constants
  spinner.start('Socket optimizing...')
  const state = await addOverrides(pkgEnvDetails, pkgEnvDetails.pkgPath, {
    logger: logger.logger,
    pin,
    prod,
    spinner
  })
  const addedCount = state.added.size
  const updatedCount = state.updated.size
  const pkgJsonChanged = addedCount > 0 || updatedCount > 0
  if (pkgJsonChanged || pkgEnvDetails.features.npmBuggyOverrides) {
    await updateLockfile(pkgEnvDetails, {
      cmdName: CMD_NAME,
      logger: logger.logger,
      spinner
    })
  }
  spinner.stop()
  if (pkgJsonChanged) {
    if (updatedCount > 0) {
      logger.logger?.log(
        `${createActionMessage('Updated', updatedCount, state.updatedInWorkspaces.size)}${addedCount ? '.' : '🚀'}`
      )
    }
    if (addedCount > 0) {
      logger.logger?.log(
        `${createActionMessage('Added', addedCount, state.addedInWorkspaces.size)} 🚀`
      )
    }
  } else {
    logger.logger?.log('Congratulations! Already Socket.dev optimized 🎉')
  }
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$m } = constants
const config$o = {
  commandName: 'optimize',
  description: 'Optimize dependencies with @socketregistry overrides',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    pin: {
      type: 'boolean',
      default: false,
      description: 'Pin overrides to their latest version'
    },
    prod: {
      type: 'boolean',
      default: false,
      description: 'Only add overrides for production dependencies'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}
      $ ${command} --pin
  `
}
const cmdOptimize = {
  description: config$o.description,
  hidden: config$o.hidden,
  run: run$o
}
async function run$o(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$o,
    importMeta,
    parentName
  })

  // TODO: impl json/md

  const cwd = process.cwd()
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$m)
    return
  }
  await applyOptimization(
    cwd,
    Boolean(cli.flags['pin']),
    Boolean(cli.flags['prod'])
  )
}

async function fetchOrganization() {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.getOrganizations(),
    'organization list'
  )
}

async function outputOrganizationList(result, outputKind = 'text') {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  const organizations = Object.values(result.data.organizations)
  const visibleTokenPrefix = utils.getVisibleTokenPrefix()
  switch (outputKind) {
    case 'markdown': {
      // | Syntax      | Description |
      // | ----------- | ----------- |
      // | Header      | Title       |
      // | Paragraph   | Text        |
      let mw1 = 4
      let mw2 = 2
      let mw3 = 4
      for (const o of organizations) {
        mw1 = Math.max(mw1, o.name?.length ?? 0)
        mw2 = Math.max(mw2, o.id.length)
        mw3 = Math.max(mw3, o.plan.length)
      }
      logger.logger.log('# Organizations\n')
      logger.logger.log(
        `List of organizations associated with your API key, starting with: ${vendor.yoctocolorsCjsExports.italic(visibleTokenPrefix)}\n`
      )
      logger.logger.log(
        `| Name${' '.repeat(mw1 - 4)} | ID${' '.repeat(mw2 - 2)} | Plan${' '.repeat(mw3 - 4)} |`
      )
      logger.logger.log(
        `| ${'-'.repeat(mw1)} | ${'-'.repeat(mw2)} | ${'-'.repeat(mw3)} |`
      )
      for (const o of organizations) {
        logger.logger.log(
          `| ${(o.name || '').padEnd(mw1, ' ')} | ${(o.id || '').padEnd(mw2, ' ')} | ${(o.plan || '').padEnd(mw3, ' ')} |`
        )
      }
      logger.logger.log(
        `| ${'-'.repeat(mw1)} | ${'-'.repeat(mw2)} | ${'-'.repeat(mw3)} |`
      )
      return
    }
    default: {
      logger.logger.log(
        `List of organizations associated with your API key, starting with: ${vendor.yoctocolorsCjsExports.italic(visibleTokenPrefix)}\n`
      )
      // Just dump
      for (const o of organizations) {
        logger.logger.log(
          `- Name: ${vendor.yoctocolorsCjsExports.bold(o.name ?? 'undefined')}, ID: ${vendor.yoctocolorsCjsExports.bold(o.id)}, Plan: ${vendor.yoctocolorsCjsExports.bold(o.plan)}`
        )
      }
    }
  }
}

async function handleOrganizationList(outputKind = 'text') {
  const data = await fetchOrganization()
  await outputOrganizationList(data, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$l } = constants
const config$n = {
  commandName: 'list',
  description: 'List organizations associated with the API key used',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: none (does need a token)

    Options
      ${utils.getFlagListOutput(config$n.flags, 6)}
  `
}
const cmdOrganizationList = {
  description: config$n.description,
  hidden: config$n.hidden,
  run: run$n
}
async function run$n(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$n,
    importMeta,
    parentName
  })
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$l)
    return
  }
  await handleOrganizationList(outputKind)
}

async function fetchLicensePolicy(orgSlug) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.getOrgLicensePolicy(orgSlug),
    'organization license policy'
  )
}

async function outputLicensePolicy(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  logger.logger.error('Use --json to get the full result')
  logger.logger.log('# License policy')
  logger.logger.log('')
  logger.logger.log('This is the license policy for your organization:')
  logger.logger.log('')
  const rules = result.data['license_policy']
  const entries = rules ? Object.entries(rules) : []
  const mapped = entries.map(([key, value]) => [
    key,
    value?.['allowed'] ? ' yes' : ' no'
  ])
  mapped.sort(([a], [b]) => (a < b ? -1 : a > b ? 1 : 0))
  logger.logger.log(utils.mdTableOfPairs(mapped, ['License Name', 'Allowed']))
  logger.logger.log('')
}

async function handleLicensePolicy(orgSlug, outputKind) {
  const data = await fetchLicensePolicy(orgSlug)
  await outputLicensePolicy(data, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$k } = constants

// TODO: secret toplevel alias `socket license policy`?
const config$m = {
  commandName: 'license',
  description: 'Retrieve the license policy of an organization',
  hidden: true,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, _config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: license-policy:read

    Options
      ${utils.getFlagListOutput(config$m.flags, 6)}

    Your API token will need the \`license-policy:read\` permission otherwise
    the request will fail with an authentication error.

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' mycorp'}
      $ ${command}${utils.isTestingV1() ? '' : ' mycorp'} --json
  `
}
const cmdOrganizationPolicyLicense = {
  description: config$m.description,
  hidden: config$m.hidden,
  run: run$m
}
async function run$m(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$m,
    importMeta,
    parentName
  })
  const { dryRun, interactive, json, markdown, org: orgFlag } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [orgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !!orgSlug,
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message: 'The json and markdown flags cannot be both set, pick one',
      pass: 'ok',
      fail: 'omit one'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$k)
    return
  }
  await handleLicensePolicy(orgSlug, outputKind)
}

async function fetchSecurityPolicy(orgSlug) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.getOrgSecurityPolicy(orgSlug),
    'organization security policy'
  )
}

async function outputSecurityPolicy(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  logger.logger.log('# Security policy')
  logger.logger.log('')
  logger.logger.log(
    `The default security policy setting is: "${result.data.securityPolicyDefault}"`
  )
  logger.logger.log('')
  logger.logger.log(
    'These are the security policies per setting for your organization:'
  )
  logger.logger.log('')
  const rules = result.data.securityPolicyRules
  const entries = rules ? Object.entries(rules) : []
  const mapped = entries.map(([key, value]) => [key, value.action])
  mapped.sort(([a], [b]) => (a < b ? -1 : a > b ? 1 : 0))
  logger.logger.log(utils.mdTableOfPairs(mapped, ['name', 'action']))
  logger.logger.log('')
}

async function handleSecurityPolicy(orgSlug, outputKind) {
  const data = await fetchSecurityPolicy(orgSlug)
  await outputSecurityPolicy(data, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$j } = constants

// TODO: secret toplevel alias `socket security policy`?
const config$l = {
  commandName: 'security',
  description: 'Retrieve the security policy of an organization',
  hidden: true,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, _config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: security-policy:read

    Options
      ${utils.getFlagListOutput(config$l.flags, 6)}

    Your API token will need the \`security-policy:read\` permission otherwise
    the request will fail with an authentication error.

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' mycorp'}
      $ ${command}${utils.isTestingV1() ? '' : ' mycorp'} --json
  `
}
const cmdOrganizationPolicyPolicy = {
  description: config$l.description,
  hidden: config$l.hidden,
  run: run$l
}
async function run$l(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$l,
    importMeta,
    parentName
  })
  const { dryRun, interactive, json, markdown, org: orgFlag } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [orgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !!orgSlug,
      message: 'Org name as the first argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message: 'The json and markdown flags cannot be both set, pick one',
      pass: 'ok',
      fail: 'omit one'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$j)
    return
  }
  await handleSecurityPolicy(orgSlug, outputKind)
}

const description$5 = 'Organization policy details'
const cmdOrganizationPolicy = {
  description: description$5,
  // Hidden because it was broken all this time (nobody could be using it)
  // and we're not sure if it's useful to anyone in its current state.
  // Until we do, we'll hide this to keep the help tidier.
  // And later, we may simply move this under `scan`, anyways.
  hidden: true,
  async run(argv, importMeta, { parentName }) {
    await utils.meowWithSubcommands(
      {
        security: cmdOrganizationPolicyPolicy,
        license: cmdOrganizationPolicyLicense
      },
      {
        argv,
        description: description$5,
        defaultSub: 'list',
        // Backwards compat
        importMeta,
        name: parentName + ' policy'
      }
    )
  }
}

async function fetchQuota() {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(sockSdk.getQuota(), 'token quota')
}

async function outputQuota(result, outputKind = 'text') {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  if (outputKind === 'markdown') {
    logger.logger.log('# Quota')
    logger.logger.log('')
    logger.logger.log(
      `Quota left on the current API token: ${result.data.quota}`
    )
    logger.logger.log('')
    return
  }
  logger.logger.log(`Quota left on the current API token: ${result.data.quota}`)
  logger.logger.log('')
}

async function handleQuota(outputKind = 'text') {
  const data = await fetchQuota()
  await outputQuota(data, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$i } = constants
const config$k = {
  commandName: 'quota',
  description: 'List organizations associated with the API key used',
  hidden: true,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}

    Options
      ${utils.getFlagListOutput(config$k.flags, 6)}
  `
}
const cmdOrganizationQuota = {
  description: config$k.description,
  hidden: config$k.hidden,
  run: run$k
}
async function run$k(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$k,
    importMeta,
    parentName
  })
  const json = Boolean(cli.flags['json'])
  const markdown = Boolean(cli.flags['markdown'])
  const outputKind = utils.getOutputKind(json, markdown)
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !json || !markdown,
      message: 'The json and markdown flags cannot be both set, pick one',
      pass: 'ok',
      fail: 'omit one'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$i)
    return
  }
  await handleQuota(outputKind)
}

const description$4 = 'Account details'
const cmdOrganization = {
  description: description$4,
  // Hidden because it was broken all this time (nobody could be using it)
  // and we're not sure if it's useful to anyone in its current state.
  // Until we do, we'll hide this to keep the help tidier.
  // And later, we may simply move this under `scan`, anyways.
  hidden: true,
  async run(argv, importMeta, { parentName }) {
    await utils.meowWithSubcommands(
      {
        list: cmdOrganizationList,
        quota: cmdOrganizationQuota,
        policy: cmdOrganizationPolicy
      },
      {
        argv,
        description: description$4,
        defaultSub: 'list',
        // Backwards compat
        importMeta,
        name: parentName + ' organization'
      }
    )
  }
}

async function fetchPurlDeepScore(purl) {
  logger.logger.error(`Requesting deep score data for this purl: ${purl}`)
  return await utils.queryApiSafeJson(
    `purl/score/${encodeURIComponent(purl)}`,
    'the deep package scores'
  )
}

async function outputPurlScore(purl, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  if (outputKind === 'markdown') {
    const {
      purl: requestedPurl,
      self: {
        alerts: selfAlerts,
        capabilities: selfCaps,
        purl,
        score: selfScore
      },
      transitively: {
        alerts,
        capabilities,
        dependencyCount,
        func,
        lowest,
        score
      }
    } = result.data
    logger.logger.error(`Score report for "${requestedPurl}" ("${purl}"):\n`)
    logger.logger.log('# Complete Package Score')
    logger.logger.log('')
    if (dependencyCount) {
      logger.logger.log(
        `This is a Socket report for the package *"${purl}"* and its *${dependencyCount}* direct/transitive dependencies.`
      )
    } else {
      logger.logger.log(
        `This is a Socket report for the package *"${purl}"*. It has *no dependencies*.`
      )
    }
    logger.logger.log('')
    if (dependencyCount) {
      logger.logger.log(
        `It will show you the shallow score for just the package itself and a deep score for all the transitives combined. Additionally you can see which capabilities were found and the top alerts as well as a package that was responsible for it.`
      )
    } else {
      logger.logger.log(
        `It will show you the shallow score for the package itself, which capabilities were found, and its top alerts.`
      )
      logger.logger.log('')
      logger.logger.log(
        'Since it has no dependencies, the shallow score is also the deep score.'
      )
    }
    logger.logger.log('')
    if (dependencyCount) {
      // This doesn't make much sense if there are no dependencies. Better to omit it.
      logger.logger.log(
        'The report should give you a good insight into the status of this package.'
      )
      logger.logger.log('')
      logger.logger.log('## Package itself')
      logger.logger.log('')
      logger.logger.log(
        'Here are results for the package itself (excluding data from dependencies).'
      )
    } else {
      logger.logger.log('## Report')
      logger.logger.log('')
      logger.logger.log(
        'The report should give you a good insight into the status of this package.'
      )
    }
    logger.logger.log('')
    logger.logger.log('### Shallow Score')
    logger.logger.log('')
    logger.logger.log('This score is just for the package itself:')
    logger.logger.log('')
    logger.logger.log('- Overall: ' + selfScore.overall)
    logger.logger.log('- Maintenance: ' + selfScore.maintenance)
    logger.logger.log('- Quality: ' + selfScore.quality)
    logger.logger.log('- Supply Chain: ' + selfScore.supplyChain)
    logger.logger.log('- Vulnerability: ' + selfScore.vulnerability)
    logger.logger.log('- License: ' + selfScore.license)
    logger.logger.log('')
    logger.logger.log('### Capabilities')
    logger.logger.log('')
    if (selfCaps.length) {
      logger.logger.log(
        'These are the capabilities detected in the package itself:'
      )
      logger.logger.log('')
      selfCaps.forEach(cap => {
        logger.logger.log(`- ${cap}`)
      })
    } else {
      logger.logger.log('No capabilities were found in the package.')
    }
    logger.logger.log('')
    logger.logger.log('### Alerts for this package')
    logger.logger.log('')
    if (selfAlerts.length) {
      if (dependencyCount) {
        logger.logger.log('These are the alerts found for the package itself:')
      } else {
        logger.logger.log('These are the alerts found for this package:')
      }
      logger.logger.log('')
      logger.logger.log(
        utils.mdTable(
          selfAlerts,
          ['severity', 'name'],
          ['Severity', 'Alert Name']
        )
      )
    } else {
      logger.logger.log('There are currently no alerts for this package.')
    }
    logger.logger.log('')
    if (dependencyCount) {
      logger.logger.log('## Transitive Package Results')
      logger.logger.log('')
      logger.logger.log(
        'Here are results for the package and its direct/transitive dependencies.'
      )
      logger.logger.log('')
      logger.logger.log('### Deep Score')
      logger.logger.log('')
      logger.logger.log(
        'This score represents the package and and its direct/transitive dependencies:'
      )
      logger.logger.log(
        `The function used to calculate the values in aggregate is: *"${func}"*`
      )
      logger.logger.log('')
      logger.logger.log('- Overall: ' + score.overall)
      logger.logger.log('- Maintenance: ' + score.maintenance)
      logger.logger.log('- Quality: ' + score.quality)
      logger.logger.log('- Supply Chain: ' + score.supplyChain)
      logger.logger.log('- Vulnerability: ' + score.vulnerability)
      logger.logger.log('- License: ' + score.license)
      logger.logger.log('')
      logger.logger.log('### Capabilities')
      logger.logger.log('')
      logger.logger.log(
        'These are the packages with the lowest recorded score. If there is more than one with the lowest score, just one is shown here. This may help you figure out the source of low scores.'
      )
      logger.logger.log('')
      logger.logger.log('- Overall: ' + lowest.overall)
      logger.logger.log('- Maintenance: ' + lowest.maintenance)
      logger.logger.log('- Quality: ' + lowest.quality)
      logger.logger.log('- Supply Chain: ' + lowest.supplyChain)
      logger.logger.log('- Vulnerability: ' + lowest.vulnerability)
      logger.logger.log('- License: ' + lowest.license)
      logger.logger.log('')
      logger.logger.log('### Capabilities')
      logger.logger.log('')
      if (capabilities.length) {
        logger.logger.log(
          'These are the capabilities detected in at least one package:'
        )
        logger.logger.log('')
        capabilities.forEach(cap => {
          logger.logger.log(`- ${cap}`)
        })
      } else {
        logger.logger.log(
          'This package had no capabilities and neither did any of its direct/transitive dependencies.'
        )
      }
      logger.logger.log('')
      logger.logger.log('### Alerts')
      logger.logger.log('')
      if (alerts.length) {
        logger.logger.log('These are the alerts found:')
        logger.logger.log('')
        logger.logger.log(
          utils.mdTable(
            alerts,
            ['severity', 'name', 'example'],
            ['Severity', 'Alert Name', 'Example package reporting it']
          )
        )
      } else {
        logger.logger.log(
          'This package had no alerts and neither did any of its direct/transitive dependencies'
        )
      }
      logger.logger.log('')
    }
    return
  }
  logger.logger.log(
    `Score report for "${purl}" (use --json for raw and --markdown for formatted reports):`
  )
  logger.logger.log(result.data)
  logger.logger.log('')
}

async function handlePurlDeepScore(purl, outputKind) {
  const result = await fetchPurlDeepScore(purl)
  await outputPurlScore(purl, result, outputKind)
}

// Either an ecosystem was given or all args must be (namespaced) purls
// The `pkg:` part is optional here. We'll scan for `eco/name@version`.
// Not hardcoding the namespace since we don't know what the server accepts.
// The ecosystem is considered as the first package if it is not an a-z string.
function parsePackageSpecifiers(ecosystem, pkgs) {
  let valid = true
  const purls = []
  if (!ecosystem) {
    valid = false
  } else if (/^[a-zA-Z]+$/.test(ecosystem)) {
    for (let i = 0; i < pkgs.length; ++i) {
      const pkg = pkgs[i] ?? ''
      if (!pkg) {
        valid = false
        break
      } else if (pkg.startsWith('pkg:')) {
        // keep
        purls.push(pkg)
      } else {
        purls.push('pkg:' + ecosystem + '/' + pkg)
      }
    }
    if (!purls.length) {
      valid = false
    }
  } else {
    // Assume ecosystem is a purl, too
    pkgs.unshift(ecosystem)
    for (let i = 0; i < pkgs.length; ++i) {
      const pkg = pkgs[i] ?? ''
      if (!/^(?:pkg:)?[a-zA-Z]+\/./.test(pkg)) {
        // At least one purl did not start with `pkg:eco/x` or `eco/x`
        valid = false
        break
      } else if (pkg.startsWith('pkg:')) {
        purls.push(pkg)
      } else {
        purls.push('pkg:' + pkg)
      }
    }
    if (!purls.length) {
      valid = false
    }
  }
  return {
    purls,
    valid
  }
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$h } = constants
const config$j = {
  commandName: 'score',
  description:
    '[beta] Look up score for one package which reflects all of its transitive dependencies as well',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <<ecosystem> <name> | <purl>>

    API Token Requirements
      - Quota: 100 units
      - Permissions: packages:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Show deep scoring details for one package. The score will reflect the package
    itself, any of its dependencies, and any of its transitive dependencies.

    When you want to know whether to trust a package, this is the command to run.

    See also the \`socket package shallow\` command, which returns the shallow
    score for any number of packages. That will not reflect the dependency scores.

    Only a few ecosystems are supported like npm, golang, and maven.

    A "purl" is a standard package name formatting: \`pkg:eco/name@version\`
    This command will automatically prepend "pkg:" when not present.

    The version is optional but when given should be a direct match.

    Examples
      $ ${command} npm babel-cli
      $ ${command} npm babel-cli@1.9.1
      $ ${command} npm/babel-cli@1.9.1
      $ ${command} pkg:npm/babel-cli@1.9.1
  `
}
const cmdPackageScore = {
  description: config$j.description,
  hidden: config$j.hidden,
  run: run$j
}
async function run$j(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$j,
    importMeta,
    parentName
  })
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [ecosystem = '', purl] = cli.input
  const hasApiToken = utils.hasDefaultToken()
  const { purls, valid } = parsePackageSpecifiers(ecosystem, purl ? [purl] : [])
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: valid,
      message: 'First parameter must be an ecosystem or the whole purl',
      pass: 'ok',
      fail: 'bad'
    },
    {
      test: purls.length === 1,
      message: 'Expecting at least one package',
      pass: 'ok',
      fail: purls.length === 0 ? 'missing' : 'too many'
    },
    {
      nook: true,
      test: !json || !markdown,
      message: 'The json and markdown flags cannot be both set, pick one',
      pass: 'ok',
      fail: 'omit one'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$h)
    return
  }
  await handlePurlDeepScore(purls[0] || '', outputKind)
}

async function fetchPurlsShallowScore(purls) {
  logger.logger.error(
    `Requesting shallow score data for ${purls.length} package urls (purl): ${purls.join(', ')}`
  )
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  const result = await utils.handleApiCall(
    sockSdk.batchPackageFetch(
      {
        alerts: 'true'
      },
      {
        components: purls.map(purl => ({
          purl
        }))
      }
    ),
    'looking up package'
  )
  if (!result.ok) {
    return result
  }

  // TODO: seems like there's a bug in the typing since we absolutely have to return the .data here
  return {
    ok: true,
    data: result.data
  }
}

function outputPurlsShallowScore(purls, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }

  // Make some effort to match the requested data with the response

  const set = new Set()
  result.data.forEach(data => {
    set.add('pkg:' + data.type + '/' + data.name + '@' + data.version)
    set.add('pkg:' + data.type + '/' + data.name)
  })
  const missing = purls.filter(purl => {
    if (set.has(purl)) {
      return false
    }
    if (purl.endsWith('@latest') && set.has(purl.slice(0, -'@latest'.length))) {
      return false
    }
    return true // not found
  })
  if (outputKind === 'markdown') {
    logger.logger.log(
      `
# Shallow Package Report

This report contains the response for requesting data on some package url(s).

Please note: The listed scores are ONLY for the package itself. It does NOT
             reflect the scores of any dependencies, transitive or otherwise.

${missing.length ? `\n## Missing response\n\nAt least one package had no response or the purl was not canonical:\n\n${missing.map(purl => '- ' + purl + '\n').join('')}` : ''}

${result.data.map(data => '## ' + formatReportCard(data, false)).join('\n\n\n')}
    `.trim()
    )
    return
  }
  logger.logger.log(
    '\n' + vendor.yoctocolorsCjsExports.bold('Shallow Package Score') + '\n'
  )
  logger.logger.log(
    'Please note: The listed scores are ONLY for the package itself. It does NOT\n' +
      '             reflect the scores of any dependencies, transitive or otherwise.'
  )
  if (missing.length) {
    logger.logger.log(
      `\nAt least one package had no response or the purl was not canonical:\n${missing.map(purl => '\n- ' + vendor.yoctocolorsCjsExports.bold(purl)).join('')}`
    )
  }
  result.data.forEach(data => {
    logger.logger.log('\n')
    logger.logger.log(formatReportCard(data, true))
  })
  logger.logger.log('')
}
function formatReportCard(data, color) {
  const scoreResult = {
    'Supply Chain Risk': Math.floor((data.score?.supplyChain ?? 0) * 100),
    Maintenance: Math.floor((data.score?.maintenance ?? 0) * 100),
    Quality: Math.floor((data.score?.quality ?? 0) * 100),
    Vulnerabilities: Math.floor((data.score?.vulnerability ?? 0) * 100),
    License: Math.floor((data.score?.license ?? 0) * 100)
  }
  const alertString = getAlertString(data.alerts, !color)
  const purl = 'pkg:' + data.type + '/' + data.name + '@' + data.version
  return [
    'Package: ' + (color ? vendor.yoctocolorsCjsExports.bold(purl) : purl),
    '',
    ...Object.entries(scoreResult).map(
      score =>
        `- ${score[0]}:`.padEnd(20, ' ') +
        `  ${formatScore(score[1], !color, true)}`
    ),
    alertString
  ].join('\n')
}
function formatScore(score, noColor = false, pad = false) {
  const padded = String(score).padStart(pad ? 3 : 0, ' ')
  if (noColor) {
    return padded
  }
  if (score >= 80) {
    return vendor.yoctocolorsCjsExports.green(padded)
  }
  if (score >= 60) {
    return vendor.yoctocolorsCjsExports.yellow(padded)
  }
  return vendor.yoctocolorsCjsExports.red(padded)
}
function getAlertString(alerts, noColor = false) {
  if (!alerts?.length) {
    return noColor
      ? `- Alerts: none!`
      : `- Alerts: ${vendor.yoctocolorsCjsExports.green('none')}!`
  }
  const bad = alerts
    .filter(alert => alert.severity !== 'low' && alert.severity !== 'middle')
    .sort((a, b) => (a.type < b.type ? -1 : a.type > b.type ? 1 : 0))
  const mid = alerts
    .filter(alert => alert.severity === 'middle')
    .sort((a, b) => (a.type < b.type ? -1 : a.type > b.type ? 1 : 0))
  const low = alerts
    .filter(alert => alert.severity === 'low')
    .sort((a, b) => (a.type < b.type ? -1 : a.type > b.type ? 1 : 0))

  // We need to create the no-color string regardless because the actual string
  // contains a bunch of invisible ANSI chars which would screw up length checks.
  const colorless = `- Alerts (${bad.length}/${mid.length.toString()}/${low.length}):`
  if (noColor) {
    return (
      colorless +
      ' '.repeat(Math.max(0, 20 - colorless.length)) +
      '  ' +
      [
        bad.map(alert => `[${alert.severity}] ` + alert.type).join(', '),
        mid.map(alert => `[${alert.severity}] ` + alert.type).join(', '),
        low.map(alert => `[${alert.severity}] ` + alert.type).join(', ')
      ]
        .filter(Boolean)
        .join(', ')
    )
  }
  return (
    `- Alerts (${vendor.yoctocolorsCjsExports.red(bad.length.toString())}/${vendor.yoctocolorsCjsExports.yellow(mid.length.toString())}/${low.length}):` +
    ' '.repeat(Math.max(0, 20 - colorless.length)) +
    '  ' +
    [
      bad
        .map(alert =>
          vendor.yoctocolorsCjsExports.red(
            vendor.yoctocolorsCjsExports.dim(`[${alert.severity}] `) +
              alert.type
          )
        )
        .join(', '),
      mid
        .map(alert =>
          vendor.yoctocolorsCjsExports.yellow(
            vendor.yoctocolorsCjsExports.dim(`[${alert.severity}] `) +
              alert.type
          )
        )
        .join(', '),
      low
        .map(
          alert =>
            vendor.yoctocolorsCjsExports.dim(`[${alert.severity}] `) +
            alert.type
        )
        .join(', ')
    ]
      .filter(Boolean)
      .join(', ')
  )
}

async function handlePurlsShallowScore({ outputKind, purls }) {
  const packageData = await fetchPurlsShallowScore(purls)
  outputPurlsShallowScore(purls, packageData, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$g } = constants
const config$i = {
  commandName: 'shallow',
  description:
    '[beta] Look up info regarding one or more packages but not their transitives',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <<ecosystem> <name> [<name> ...] | <purl> [<purl> ...]>

    API Token Requirements
      - Quota: 100 units
      - Permissions: packages:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Show scoring details for one or more packages purely based on their own package.
    This means that any dependency scores are not reflected by the score. You can
    use the \`socket package score <pkg>\` command to get its full transitive score.

    Only a few ecosystems are supported like npm, golang, and maven.

    A "purl" is a standard package name formatting: \`pkg:eco/name@version\`
    This command will automatically prepend "pkg:" when not present.

    If the first arg is an ecosystem, remaining args that are not a purl are
    assumed to be scoped to that ecosystem.

    Examples
      $ ${command} npm webtorrent
      $ ${command} npm webtorrent@1.9.1
      $ ${command} npm/webtorrent@1.9.1
      $ ${command} pkg:npm/webtorrent@1.9.1
      $ ${command} maven webtorrent babel
      $ ${command} npm/webtorrent golang/babel
      $ ${command} npm npm/webtorrent@1.0.1 babel
  `
}
const cmdPackageShallow = {
  description: config$i.description,
  hidden: config$i.hidden,
  alias: {
    shallowScore: {
      description: config$i.description,
      hidden: true,
      argv: []
    }
  },
  run: run$i
}
async function run$i(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$i,
    importMeta,
    parentName
  })
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [ecosystem = '', ...pkgs] = cli.input
  const { purls, valid } = parsePackageSpecifiers(ecosystem, pkgs)
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: valid,
      message:
        'First parameter should be an ecosystem or all args must be purls',
      pass: 'ok',
      fail: 'bad'
    },
    {
      test: purls.length > 0,
      message: 'Expecting at least one package',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message: 'The json and markdown flags cannot be both set, pick one',
      pass: 'ok',
      fail: 'omit one'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$g)
    return
  }
  await handlePurlsShallowScore({
    outputKind,
    purls
  })
}

const description$3 = 'Commands relating to looking up published packages'
const cmdPackage = {
  description: description$3,
  hidden: false,
  async run(argv, importMeta, { parentName }) {
    await utils.meowWithSubcommands(
      {
        score: cmdPackageScore,
        shallow: cmdPackageShallow
      },
      {
        aliases: {
          deep: {
            description: description$3,
            hidden: true,
            argv: ['score']
          }
        },
        argv,
        description: description$3,
        importMeta,
        name: parentName + ' package'
      }
    )
  }
}

async function runRawNpm(argv) {
  const spawnPromise = spawn.spawn(utils.getNpmBinPath(), argv, {
    // Lazily access constants.WIN32.
    shell: constants.WIN32,
    stdio: 'inherit'
  })
  // See https://nodejs.org/api/all.html#all_child_process_event-exit.
  spawnPromise.process.on('exit', (code, signalName) => {
    if (signalName) {
      process.kill(process.pid, signalName)
    } else if (code !== null) {
      // eslint-disable-next-line n/no-process-exit
      process.exit(code)
    }
  })
  await spawnPromise
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$f, NPM } = constants
const config$h = {
  commandName: 'raw-npm',
  description: `Temporarily disable the Socket ${NPM} wrapper`,
  hidden: false,
  flags: {},
  help: command => `
    Usage
      $ ${command} <command>

    Examples
      $ ${command} install
  `
}
const cmdRawNpm = {
  description: config$h.description,
  hidden: config$h.hidden,
  run: run$h
}
async function run$h(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$h,
    importMeta,
    parentName
  })
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$f)
    return
  }
  await runRawNpm(argv)
}

async function runRawNpx(argv) {
  const spawnPromise = spawn.spawn(utils.getNpxBinPath(), argv, {
    // Lazily access constants.WIN32.
    shell: constants.WIN32,
    stdio: 'inherit'
  })
  // See https://nodejs.org/api/all.html#all_child_process_event-exit.
  spawnPromise.process.on('exit', (code, signalName) => {
    if (signalName) {
      process.kill(process.pid, signalName)
    } else if (code !== null) {
      // eslint-disable-next-line n/no-process-exit
      process.exit(code)
    }
  })
  await spawnPromise
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$e, NPX } = constants
const config$g = {
  commandName: 'raw-npx',
  description: `Temporarily disable the Socket ${NPX} wrapper`,
  hidden: false,
  flags: {},
  help: command => `
    Usage
      $ ${command} <command>

    Examples
      $ ${command} install
  `
}
const cmdRawNpx = {
  description: config$g.description,
  hidden: config$g.hidden,
  run: run$g
}
async function run$g(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$g,
    importMeta,
    parentName
  })
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$e)
    return
  }
  await runRawNpx(argv)
}

const config$f = {
  commandName: 'create',
  description: '[Deprecated] Create a project report',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: () => `
    This command is deprecated in favor of \`socket scan view\`.
    It will be removed in the next major release of the CLI.
  `
}
const cmdReportCreate = {
  description: config$f.description,
  hidden: config$f.hidden,
  run: run$f
}
async function run$f(argv, importMeta, { parentName }) {
  utils.meowOrExit({
    argv,
    config: config$f,
    importMeta,
    parentName
  })
  logger.logger.fail(
    'This command has been sunset. Instead, please look at `socket scan create` to create scans and `socket scan report` to view a report of your scans.'
  )
  process.exitCode = 1
}

const config$e = {
  commandName: 'view',
  description: '[Deprecated] View a project report',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: () => `
    This command is deprecated in favor of \`socket scan view\`.
    It will be removed in the next major release of the CLI.
  `
}
const cmdReportView = {
  description: config$e.description,
  hidden: config$e.hidden,
  run: run$e
}
async function run$e(argv, importMeta, { parentName }) {
  utils.meowOrExit({
    argv,
    config: config$e,
    importMeta,
    parentName
  })
  logger.logger.fail(
    'This command has been sunset. Instead, please look at `socket scan create` to create scans and `socket scan report` to view a report of your scans.'
  )
  process.exitCode = 1
}

const description$2 = '[Deprecated] Project report related commands'
const cmdReport = {
  description: description$2,
  hidden: true,
  // Deprecated in favor of `scan`
  async run(argv, importMeta, { parentName }) {
    await utils.meowWithSubcommands(
      {
        create: cmdReportCreate,
        view: cmdReportView
      },
      {
        argv,
        description: description$2,
        importMeta,
        name: parentName + ' report'
      }
    )
  }
}

async function fetchCreateRepo({
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.createOrgRepo(orgSlug, {
      name: repoName,
      description,
      homepage,
      default_branch,
      visibility
    }),
    'to create a repository'
  )
}

function outputCreateRepo(result, requestedName, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  const { slug } = result.data
  logger.logger.success(
    `OK. Repository created successfully, slug: \`${slug}\`${slug !== requestedName ? ' (Warning: slug is not the same as name that was requested!)' : ''}`
  )
}

async function handleCreateRepo(
  { default_branch, description, homepage, orgSlug, repoName, visibility },
  outputKind
) {
  const data = await fetchCreateRepo({
    default_branch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  })
  outputCreateRepo(data, repoName, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$d } = constants
const config$d = {
  commandName: 'create',
  description: 'Create a repository in an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    defaultBranch: {
      type: 'string',
      shortFlag: 'b',
      default: 'main',
      description: 'Repository default branch'
    },
    homepage: {
      type: 'string',
      shortFlag: 'h',
      default: '',
      description: 'Repository url'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    },
    repoDescription: {
      type: 'string',
      shortFlag: 'd',
      default: '',
      description: 'Repository description'
    },
    repoName: {
      type: 'string',
      shortFlag: 'n',
      default: '',
      description: 'Repository name'
    },
    visibility: {
      type: 'string',
      shortFlag: 'v',
      default: 'private',
      description: 'Repository visibility (Default Private)'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '<repo>' : '<org slug> --repo-name=<name>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: repo:create

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? 'test-repo' : 'FakeOrg --repoName=test-repo'}
  `
}
const cmdReposCreate = {
  description: config$d.description,
  hidden: config$d.hidden,
  run: run$d
}
async function run$d(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$d,
    importMeta,
    parentName
  })
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag,
    repoName: repoNameFlag
  } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown) // TODO: impl json/md further

  const [orgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const repoName = (utils.isTestingV1() ? cli.input[0] : repoNameFlag) || ''
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !!orgSlug,
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      test: !!repoName,
      message: utils.isTestingV1()
        ? 'Repository name as first argument'
        : 'Repository name using --repoName',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    },
    {
      nook: true,
      test: !utils.isTestingV1() || !repoNameFlag,
      message: 'In v1 the first arg should be the repo, not the flag',
      pass: 'ok',
      fail: 'received --repo-name flag'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (dryRun) {
    logger.logger.log(DRY_RUN_BAILING_NOW$d)
    return
  }
  await handleCreateRepo(
    {
      orgSlug,
      repoName: String(repoName),
      description: String(cli.flags['repoDescription'] || ''),
      homepage: String(cli.flags['homepage'] || ''),
      default_branch: String(cli.flags['defaultBranch'] || ''),
      visibility: String(cli.flags['visibility'] || 'private')
    },
    outputKind
  )
}

async function fetchDeleteRepo(orgSlug, repoName) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.deleteOrgRepo(orgSlug, repoName),
    'to delete a repository'
  )
}

async function outputDeleteRepo(result, repoName, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  logger.logger.success(`OK. Repository \`${repoName}\` deleted successfully`)
}

async function handleDeleteRepo(orgSlug, repoName, outputKind) {
  const data = await fetchDeleteRepo(orgSlug, repoName)
  await outputDeleteRepo(data, repoName, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$c } = constants
const config$c = {
  commandName: 'del',
  description: 'Delete a repository in an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '<repo>' : '<org slug> --repo-name=<name>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: repo:delete

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? 'test-repo' : 'FakeOrg test-repo'}
  `
}
const cmdReposDel = {
  description: config$c.description,
  hidden: config$c.hidden,
  run: run$c
}
async function run$c(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$c,
    importMeta,
    parentName
  })
  const { dryRun, interactive, json, markdown, org: orgFlag } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const repoName =
    (defaultOrgSlug || utils.isTestingV1() ? cli.input[0] : cli.input[1]) || ''
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !!orgSlug,
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      test: !!repoName,
      message: utils.isTestingV1()
        ? 'Repository name as first argument'
        : 'Repository name using --repoName',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (dryRun) {
    logger.logger.log(DRY_RUN_BAILING_NOW$c)
    return
  }
  await handleDeleteRepo(orgSlug, repoName, outputKind)
}

async function fetchListRepos({ direction, orgSlug, page, per_page, sort }) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.getOrgRepoList(orgSlug, {
      sort,
      direction,
      per_page: String(per_page),
      page: String(page)
    }),
    'list of repositories'
  )
}

// @ts-ignore
async function outputListRepos(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  const options = {
    columns: [
      {
        field: 'id',
        name: vendor.yoctocolorsCjsExports.magenta('ID')
      },
      {
        field: 'name',
        name: vendor.yoctocolorsCjsExports.magenta('Name')
      },
      {
        field: 'visibility',
        name: vendor.yoctocolorsCjsExports.magenta('Visibility')
      },
      {
        field: 'default_branch',
        name: vendor.yoctocolorsCjsExports.magenta('Default branch')
      },
      {
        field: 'archived',
        name: vendor.yoctocolorsCjsExports.magenta('Archived')
      }
    ]
  }
  logger.logger.log(vendor.srcExports(options, result.data.results))
}

async function handleListRepos({
  direction,
  orgSlug,
  outputKind,
  page,
  per_page,
  sort
}) {
  const data = await fetchListRepos({
    direction,
    orgSlug,
    page,
    per_page,
    sort
  })
  await outputListRepos(data, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$b } = constants
const config$b = {
  commandName: 'list',
  description: 'List repositories in an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    sort: {
      type: 'string',
      shortFlag: 's',
      default: 'created_at',
      description: 'Sorting option'
    },
    direction: {
      type: 'string',
      default: 'desc',
      description: 'Direction option'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    },
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Number of results per page'
    },
    page: {
      type: 'number',
      shortFlag: 'p',
      default: 1,
      description: 'Page number'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '' : '<org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: repo:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? '' : '<org slug>'}
  `
}
const cmdReposList = {
  description: config$b.description,
  hidden: config$b.hidden,
  run: run$b
}
async function run$b(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$b,
    importMeta,
    parentName
  })
  const { json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const { dryRun, interactive, org: orgFlag } = cli.flags
  const [orgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !!orgSlug,
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$b)
    return
  }
  await handleListRepos({
    direction: cli.flags['direction'] === 'asc' ? 'asc' : 'desc',
    orgSlug,
    outputKind,
    page: Number(cli.flags['page']) || 1,
    per_page: Number(cli.flags['perPage']) || 30,
    sort: String(cli.flags['sort'] || 'created_at')
  })
}

async function fetchUpdateRepo({
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.updateOrgRepo(orgSlug, repoName, {
      orgSlug,
      name: repoName,
      description,
      homepage,
      default_branch,
      visibility
    }),
    'to update a repository'
  )
}

async function outputUpdateRepo(result, repoName, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  logger.logger.success(`Repository \`${repoName}\` updated successfully`)
}

async function handleUpdateRepo(
  { default_branch, description, homepage, orgSlug, repoName, visibility },
  outputKind
) {
  const data = await fetchUpdateRepo({
    default_branch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  })
  await outputUpdateRepo(data, repoName, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$a } = constants
const config$a = {
  commandName: 'update',
  description: 'Update a repository in an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    defaultBranch: {
      type: 'string',
      shortFlag: 'b',
      default: 'main',
      description: 'Repository default branch'
    },
    homepage: {
      type: 'string',
      shortFlag: 'h',
      default: '',
      description: 'Repository url'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    },
    repoName: {
      type: 'string',
      shortFlag: 'n',
      default: '',
      description: 'Repository name'
    },
    repoDescription: {
      type: 'string',
      shortFlag: 'd',
      default: '',
      description: 'Repository description'
    },
    visibility: {
      type: 'string',
      shortFlag: 'v',
      default: 'private',
      description: 'Repository visibility (Default Private)'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '<repo>' : '<org slug> --repo-name=<name>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: repo:update

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? 'test-repo' : 'FakeOrg test-repo'}
  `
}
const cmdReposUpdate = {
  description: config$a.description,
  hidden: config$a.hidden,
  run: run$a
}
async function run$a(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$a,
    importMeta,
    parentName
  })
  const { dryRun, interactive, json, markdown, org: orgFlag } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown) // TODO: impl json/md further

  const [orgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const repoNameFlag = cli.flags['repoName']
  const repoName = (utils.isTestingV1() ? cli.input[0] : repoNameFlag) || ''
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !!orgSlug,
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      test: !!repoName,
      message: utils.isTestingV1()
        ? 'Repository name as first argument'
        : 'Repository name using --repoName',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    },
    {
      nook: true,
      test: !utils.isTestingV1() || !repoNameFlag,
      message: 'In v1 the first arg should be the repo, not the flag',
      pass: 'ok',
      fail: 'received --repo-name flag'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$a)
    return
  }
  await handleUpdateRepo(
    {
      orgSlug,
      repoName: String(repoName),
      description: String(cli.flags['repoDescription'] || ''),
      homepage: String(cli.flags['homepage'] || ''),
      default_branch: String(cli.flags['defaultBranch'] || ''),
      visibility: String(cli.flags['visibility'] || 'private')
    },
    outputKind
  )
}

async function fetchViewRepo(orgSlug, repoName) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.getOrgRepo(orgSlug, repoName),
    'repository data'
  )
}

// @ts-ignore
async function outputViewRepo(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  const options = {
    columns: [
      {
        field: 'id',
        name: vendor.yoctocolorsCjsExports.magenta('ID')
      },
      {
        field: 'name',
        name: vendor.yoctocolorsCjsExports.magenta('Name')
      },
      {
        field: 'visibility',
        name: vendor.yoctocolorsCjsExports.magenta('Visibility')
      },
      {
        field: 'default_branch',
        name: vendor.yoctocolorsCjsExports.magenta('Default branch')
      },
      {
        field: 'homepage',
        name: vendor.yoctocolorsCjsExports.magenta('Homepage')
      },
      {
        field: 'archived',
        name: vendor.yoctocolorsCjsExports.magenta('Archived')
      },
      {
        field: 'created_at',
        name: vendor.yoctocolorsCjsExports.magenta('Created at')
      }
    ]
  }
  logger.logger.log(vendor.srcExports(options, [result.data]))
}

async function handleViewRepo(orgSlug, repoName, outputKind) {
  const data = await fetchViewRepo(orgSlug, repoName)
  await outputViewRepo(data, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$9 } = constants
const config$9 = {
  commandName: 'view',
  description: 'View repositories in an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    },
    repoName: {
      description: 'The repository to check',
      default: '',
      type: 'string'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '<repo>' : '<org slug> --repo-name=<name>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: repo:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? 'test-repo' : 'FakeOrg test-repo'}
  `
}
const cmdReposView = {
  description: config$9.description,
  hidden: config$9.hidden,
  run: run$9
}
async function run$9(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$9,
    importMeta,
    parentName
  })
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag,
    repoName: repoNameFlag
  } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [orgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const repoName = (utils.isTestingV1() ? cli.input[0] : repoNameFlag) || ''
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !!orgSlug,
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      test: !!repoName,
      message: utils.isTestingV1()
        ? 'Repository name as first argument'
        : 'Repository name using --repoName',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    },
    {
      nook: true,
      test: !utils.isTestingV1() || !repoNameFlag,
      message: 'In v1 the first arg should be the repo, not the flag',
      pass: 'ok',
      fail: 'received --repo-name flag'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$9)
    return
  }
  await handleViewRepo(orgSlug, String(repoName), outputKind)
}

const description$1 = 'Repositories related commands'
const cmdRepos = {
  description: description$1,
  async run(argv, importMeta, { parentName }) {
    await utils.meowWithSubcommands(
      {
        create: cmdReposCreate,
        view: cmdReposView,
        list: cmdReposList,
        del: cmdReposDel,
        update: cmdReposUpdate
      },
      {
        argv,
        description: description$1,
        importMeta,
        name: `${parentName} repos`
      }
    )
  }
}

async function suggestTarget() {
  // We could prefill this with sub-dirs of the current
  // dir ... but is that going to be useful?
  const proceed = await prompts.select({
    message: 'No TARGET given. Do you want to use the current directory?',
    choices: [
      {
        name: 'Yes',
        value: true,
        description: 'Target the current directory'
      },
      {
        name: 'No',
        value: false,
        description:
          'Do not use the current directory (this will end in a no-op)'
      }
    ]
  })
  if (proceed) {
    return ['.']
  }
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$8 } = constants
const config$8 = {
  commandName: 'create',
  description: 'Create a scan',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    branch: {
      type: 'string',
      shortFlag: 'b',
      default: 'socket-default-branch',
      description: 'Branch name'
    },
    commitMessage: {
      type: 'string',
      shortFlag: 'm',
      default: '',
      description: 'Commit message'
    },
    commitHash: {
      type: 'string',
      shortFlag: 'ch',
      default: '',
      description: 'Commit hash'
    },
    committers: {
      type: 'string',
      shortFlag: 'c',
      default: '',
      description: 'Committers'
    },
    cwd: {
      type: 'string',
      description: 'working directory, defaults to process.cwd()'
    },
    defaultBranch: {
      type: 'boolean',
      default: false,
      description:
        'Set the default branch of the repository to the branch of this full-scan. Should only need to be done once, for example for the "main" or "master" branch.'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    pendingHead: {
      type: 'boolean',
      default: true,
      description:
        'Designate this full-scan as the latest scan of a given branch. This must be set to have it show up in the dashboard.'
    },
    pullRequest: {
      type: 'number',
      shortFlag: 'pr',
      description: 'Commit hash'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    },
    readOnly: {
      type: 'boolean',
      default: false,
      description:
        'Similar to --dry-run except it can read from remote, stops before it would create an actual report'
    },
    repo: {
      type: 'string',
      shortFlag: 'r',
      default: 'socket-default-repository',
      description: 'Repository name'
    },
    report: {
      type: 'boolean',
      default: false,
      description:
        'Wait for the scan creation to complete, then basically run `socket scan report` on it'
    },
    tmp: {
      type: 'boolean',
      shortFlag: 't',
      default: false,
      description:
        'Set the visibility (true/false) of the scan in your dashboard. Can not be used when --pendingHead is set.'
    }
  },
  // TODO: your project's "socket.yml" file's "projectIgnorePaths"
  help: (command, config) => `
    Usage
      $ ${command} [...options]${utils.isTestingV1() ? '' : ' <org>'} <TARGET> [TARGET...]

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:create

    Uploads the specified "package.json" and lock files for JavaScript, Python,
    Go, Scala, Gradle, and Kotlin dependency manifests.
    If any folder is specified, the ones found in there recursively are uploaded.

    Supports globbing such as "**/package.json", "**/requirements.txt", etc.

    Ignores any file specified in your project's ".gitignore" and also has a
    sensible set of default ignores from the "ignore-by-default" module.

    TARGET should be a FILE or DIR that _must_ be inside the CWD.

    When a FILE is given only that FILE is targeted. Otherwise any eligible
    files in the given DIR will be considered.

    The --repo and --branch flags tell Socket to associate this Scan with that
    repo/branch. The names will show up on your dashboard on the Socket website.

    Note: for a first run you probably want to set --defaultBranch to indicate
          the default branch name, like "main" or "master".

    Note: --pendingHead is enabled by default and makes a scan show up in your
          dashboard. You can use \`--no-pendingHead\` to have it not show up.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} .
      $ ${command} --repo=test-repo --branch=main${utils.isTestingV1() ? '' : ' FakeOrg'} ./package.json
  `
}
const cmdScanCreate = {
  description: config$8.description,
  hidden: config$8.hidden,
  run: run$8
}
async function run$8(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$8,
    importMeta,
    parentName
  })
  const {
    branch: branchName = 'socket-default-branch',
    commitHash,
    commitMessage,
    committers,
    cwd: cwdOverride,
    defaultBranch,
    dryRun = false,
    interactive = true,
    json,
    markdown,
    org: orgFlag,
    pendingHead,
    pullRequest,
    readOnly,
    repo: repoName = 'socket-default-repository',
    report,
    tmp
  } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  let [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    interactive,
    dryRun
  )
  if (!defaultOrgSlug) {
    // Tmp. just for TS. will drop this later.
    defaultOrgSlug = ''
  }
  let targets = cli.input.slice(utils.isTestingV1() || defaultOrgSlug ? 0 : 1)
  const cwd =
    cwdOverride && cwdOverride !== 'process.cwd()'
      ? String(cwdOverride)
      : process.cwd()

  // We're going to need an api token to suggest data because those suggestions
  // must come from data we already know. Don't error on missing api token yet.
  // If the api-token is not set, ignore it for the sake of suggestions.
  const hasApiToken = utils.hasDefaultToken()

  // If we updated any inputs then we should print the command line to repeat
  // the command without requiring user input, as a suggestion.
  let updatedInput = false
  if (!targets.length && !dryRun && interactive) {
    const received = await suggestTarget()
    targets = received ?? []
    updatedInput = true
  }

  // If the current cwd is unknown and is used as a repo slug anyways, we will
  // first need to register the slug before we can use it.
  // Only do suggestions with an apiToken and when not in dryRun mode
  if (hasApiToken && !dryRun && interactive) {
    if (!orgSlug) {
      const suggestion = await utils.suggestOrgSlug()
      if (suggestion) {
        orgSlug = suggestion
      }
      updatedInput = true
    }
  }
  if (updatedInput && orgSlug && targets?.length) {
    logger.logger.error(
      'Note: You can invoke this command next time to skip the interactive questions:'
    )
    logger.logger.error('```')
    logger.logger.error(
      `    socket scan create [other flags...] ${defaultOrgSlug ? '' : orgSlug} ${targets.join(' ')}`
    )
    logger.logger.error('```\n')
  }
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: !utils.isTestingV1() && !!defaultOrgSlug,
      test: !!orgSlug && orgSlug !== '.',
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail:
        orgSlug === '.'
          ? 'dot is an invalid org, most likely you forgot the org name here?'
          : 'missing'
    },
    {
      test: !!targets.length,
      message: 'At least one TARGET (e.g. `.` or `./package.json`)',
      pass: 'ok',
      fail: 'missing (or perhaps you forgot the org slug?)'
    },
    {
      nook: true,
      test: !json || !markdown,
      message: 'The json and markdown flags cannot be both set, pick one',
      pass: 'ok',
      fail: 'omit one'
    },
    {
      nook: true,
      test: hasApiToken,
      message: 'This command requires an API token for access',
      pass: 'ok',
      fail: 'missing (try `socket login`)'
    },
    {
      nook: true,
      test: !pendingHead || !tmp,
      message: 'Can not use --pendingHead and --tmp at the same time',
      pass: 'ok',
      fail: 'remove at least one flag'
    },
    {
      nook: true,
      test: !pendingHead || !!branchName,
      message: 'When --pendingHead is set, --branch is mandatory',
      pass: 'ok',
      fail: 'missing branch name'
    },
    {
      nook: true,
      test: !defaultBranch || !!branchName,
      message: 'When --defaultBranch is set, --branch is mandatory',
      pass: 'ok',
      fail: 'missing branch name'
    }
  )
  if (!wasValidInput) {
    return
  }

  // Note exiting earlier to skirt a hidden auth requirement
  if (dryRun) {
    logger.logger.log(DRY_RUN_BAILING_NOW$8)
    return
  }
  await handleCreateNewScan({
    branchName: branchName,
    commitHash: (commitHash && String(commitHash)) || '',
    commitMessage: (commitMessage && String(commitMessage)) || '',
    committers: (committers && String(committers)) || '',
    cwd,
    defaultBranch: Boolean(defaultBranch),
    interactive: Boolean(interactive),
    orgSlug,
    outputKind,
    pendingHead: Boolean(pendingHead),
    pullRequest: Number(pullRequest),
    readOnly: Boolean(readOnly),
    repoName: repoName,
    report,
    targets,
    tmp: Boolean(tmp)
  })
}

async function fetchDeleteOrgFullScan(orgSlug, scanId) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.deleteOrgFullScan(orgSlug, scanId),
    'to delete a scan'
  )
}

async function outputDeleteScan(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  logger.logger.success('Scan deleted successfully')
}

async function handleDeleteScan(orgSlug, scanId, outputKind) {
  const data = await fetchDeleteOrgFullScan(orgSlug, scanId)
  await outputDeleteScan(data, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$7 } = constants
const config$7 = {
  commandName: 'del',
  description: 'Delete a scan',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'} <scan ID>

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:delete

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} 000aaaa1-0000-0a0a-00a0-00a0000000a0
  `
}
const cmdScanDel = {
  description: config$7.description,
  hidden: config$7.hidden,
  run: run$7
}
async function run$7(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$7,
    importMeta,
    parentName
  })
  const { dryRun, interactive, json, markdown, org: orgFlag } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const scanId =
    (utils.isTestingV1() || defaultOrgSlug ? cli.input[0] : cli.input[1]) || ''
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: !!defaultOrgSlug,
      test: !!orgSlug && orgSlug !== '.',
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail:
        orgSlug === '.'
          ? 'dot is an invalid org, most likely you forgot the org name here?'
          : 'missing'
    },
    {
      test: !!scanId,
      message: 'Scan ID to delete',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$7)
    return
  }
  await handleDeleteScan(orgSlug, scanId, outputKind)
}

async function fetchDiffScan({ id1, id2, orgSlug }) {
  logger.logger.error('Scan ID 1:', id1)
  logger.logger.error('Scan ID 2:', id2)
  logger.logger.error(
    'Note: this request may take some time if the scans are big'
  )
  return await utils.queryApiSafeJson(
    `orgs/${orgSlug}/full-scans/diff?before=${encodeURIComponent(id1)}&after=${encodeURIComponent(id2)}`,
    'a scan diff'
  )
}

const SOCKET_SBOM_URL_PREFIX$1 =
  'https://socket.dev/dashboard/org/SocketDev/sbom/'
async function outputDiffScan(result, { depth, file, outputKind }) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result))
      return
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  const dashboardUrl = result.data.diff_report_url
  const dashboardMessage = dashboardUrl
    ? `\n View this diff scan in the Socket dashboard: ${vendor.yoctocolorsCjsExports.cyan(dashboardUrl)}`
    : ''

  // When forcing json, or dumping to file, serialize to string such that it
  // won't get truncated. The only way to dump the full raw JSON to stdout is
  // to use `--json --file -` (the dash is a standard notation for stdout)
  if (outputKind === 'json' || file) {
    await handleJson(result, file, dashboardMessage)
    return
  }
  if (outputKind === 'markdown') {
    await handleMarkdown(result.data)
    return
  }

  // In this case neither the --json nor the --file flag was passed
  // Dump the JSON to CLI and let NodeJS deal with truncation

  logger.logger.log('Diff scan result:')
  logger.logger.log(
    util.inspect(result.data, {
      showHidden: false,
      depth: depth > 0 ? depth : null,
      colors: true,
      maxArrayLength: null
    })
  )
  logger.logger.error(
    `\n 📝 To display the detailed report in the terminal, use the --json flag. For a friendlier report, use the --markdown flag.\n`
  )
  logger.logger.log(dashboardMessage)
}
async function handleJson(data, file, dashboardMessage) {
  const json = utils.serializeResultJson(data)
  if (file && file !== '-') {
    logger.logger.log(`Writing json to \`${file}\``)
    fs$1.writeFile(file, json, err => {
      if (err) {
        logger.logger.fail(`Writing to \`${file}\` failed...`)
        logger.logger.error(err)
      } else {
        logger.logger.log(`Data successfully written to \`${file}\``)
      }
      logger.logger.error(dashboardMessage)
    })
  } else {
    // TODO: expose different method for writing to stderr when simply dodging stdout
    logger.logger.error(`\n Diff scan result: \n`)
    logger.logger.log(json)
    logger.logger.error(dashboardMessage)
  }
}
async function handleMarkdown(data) {
  logger.logger.log('# Scan diff result')
  logger.logger.log('')
  logger.logger.log(
    'This Socket.dev report shows the changes between two scans:'
  )
  logger.logger.log(
    `- [${data.before.id}](${SOCKET_SBOM_URL_PREFIX$1}${data.before.id})`
  )
  logger.logger.log(
    `- [${data.after.id}](${SOCKET_SBOM_URL_PREFIX$1}${data.after.id})`
  )
  logger.logger.log('')
  logger.logger.log(
    `You can [view this report in your dashboard](${data.diff_report_url})`
  )
  logger.logger.log('')
  logger.logger.log('## Changes')
  logger.logger.log('')
  logger.logger.log(
    `- directDependenciesChanged: ${data.directDependenciesChanged}`
  )
  logger.logger.log(`- Added packages: ${data.artifacts.added.length}`)
  if (data.artifacts.added.length > 0) {
    data.artifacts.added.slice(0, 10).forEach(artifact => {
      logger.logger.log(
        `  - ${artifact.type} ${artifact.name}@${artifact.version}`
      )
    })
    if (data.artifacts.added.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.added.length - 10} more`)
    }
  }
  logger.logger.log(`- Removed packages: ${data.artifacts.removed.length}`)
  if (data.artifacts.removed.length > 0) {
    data.artifacts.removed.slice(0, 10).forEach(artifact => {
      logger.logger.log(
        `  - ${artifact.type} ${artifact.name}@${artifact.version}`
      )
    })
    if (data.artifacts.removed.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.removed.length - 10} more`)
    }
  }
  logger.logger.log(`- Replaced packages: ${data.artifacts.replaced.length}`)
  if (data.artifacts.replaced.length > 0) {
    data.artifacts.replaced.slice(0, 10).forEach(artifact => {
      logger.logger.log(
        `  - ${artifact.type} ${artifact.name}@${artifact.version}`
      )
    })
    if (data.artifacts.replaced.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.replaced.length - 10} more`)
    }
  }
  logger.logger.log(`- Updated packages: ${data.artifacts.updated.length}`)
  if (data.artifacts.updated.length > 0) {
    data.artifacts.updated.slice(0, 10).forEach(artifact => {
      logger.logger.log(
        `  - ${artifact.type} ${artifact.name}@${artifact.version}`
      )
    })
    if (data.artifacts.updated.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.updated.length - 10} more`)
    }
  }
  logger.logger.log(`- Unchanged packages: ${data.artifacts.unchanged.length}`)
  if (data.artifacts.unchanged.length > 0) {
    data.artifacts.unchanged.slice(0, 10).forEach(artifact => {
      logger.logger.log(
        `  - ${artifact.type} ${artifact.name}@${artifact.version}`
      )
    })
    if (data.artifacts.unchanged.length > 10) {
      logger.logger.log(
        `  ... and ${data.artifacts.unchanged.length - 10} more`
      )
    }
  }
  logger.logger.log('')
  logger.logger.log(`## Scan ${data.before.id}`)
  logger.logger.log('')
  logger.logger.log(
    'This Scan was considered to be the "base" / "from" / "before" Scan.'
  )
  logger.logger.log('')
  for (const [key, value] of Object.entries(data.before)) {
    if (key === 'pull_request' && !value) {
      continue
    }
    if (!['id', 'organization_id', 'repository_id'].includes(key)) {
      logger.logger.group(
        `- ${key === 'repository_slug' ? 'repo' : key === 'organization_slug' ? 'org' : key}: ${value}`
      )
      logger.logger.groupEnd()
    }
  }
  logger.logger.log('')
  logger.logger.log(`## Scan ${data.after.id}`)
  logger.logger.log('')
  logger.logger.log(
    'This Scan was considered to be the "head" / "to" / "after" Scan.'
  )
  logger.logger.log('')
  for (const [key, value] of Object.entries(data.after)) {
    if (key === 'pull_request' && !value) {
      continue
    }
    if (!['id', 'organization_id', 'repository_id'].includes(key)) {
      logger.logger.group(
        `- ${key === 'repository_slug' ? 'repo' : key === 'organization_slug' ? 'org' : key}: ${value}`
      )
      logger.logger.groupEnd()
    }
  }
  logger.logger.log('')
}

async function handleDiffScan({ depth, file, id1, id2, orgSlug, outputKind }) {
  const data = await fetchDiffScan({
    id1,
    id2,
    orgSlug
  })
  await outputDiffScan(data, {
    depth,
    file,
    outputKind
  })
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$6 } = constants
const SOCKET_SBOM_URL_PREFIX =
  'https://socket.dev/dashboard/org/SocketDev/sbom/'
const config$6 = {
  commandName: 'diff',
  description: 'See what changed between two Scans',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    depth: {
      type: 'number',
      default: 2,
      description:
        'Max depth of JSON to display before truncating, use zero for no limit (without --json/--file)'
    },
    file: {
      type: 'string',
      shortFlag: 'f',
      default: '',
      description:
        'Path to a local file where the output should be saved. Use `-` to force stdout.'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'} <ID1> <ID2>

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:list

    This command displays the package changes between two scans. The full output
    can be pretty large depending on the size of your repo and time range. It is
    best stored to disk (with --json) to be further analyzed by other tools.

    Note: First Scan ID is assumed to be the older ID. This is only relevant for
          the added/removed list (similar to diffing two files with git).

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} aaa0aa0a-aaaa-0000-0a0a-0000000a00a0 aaa1aa1a-aaaa-1111-1a1a-1111111a11a1
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} aaa0aa0a-aaaa-0000-0a0a-0000000a00a0 aaa1aa1a-aaaa-1111-1a1a-1111111a11a1 --json
  `
}
const cmdScanDiff = {
  description: config$6.description,
  hidden: config$6.hidden,
  run: run$6
}
async function run$6(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$6,
    importMeta,
    parentName
  })
  const {
    depth,
    dryRun,
    file,
    interactive,
    json,
    markdown,
    org: orgFlag
  } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [orgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  let id1 = cli.input[utils.isTestingV1() || orgSlug ? 0 : 1] || ''
  let id2 = cli.input[utils.isTestingV1() || orgSlug ? 1 : 2] || ''
  if (id1.startsWith(SOCKET_SBOM_URL_PREFIX)) {
    id1 = id1.slice(SOCKET_SBOM_URL_PREFIX.length)
  }
  if (id2.startsWith(SOCKET_SBOM_URL_PREFIX)) {
    id2 = id2.slice(SOCKET_SBOM_URL_PREFIX.length)
  }
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: !!(id1 && id2),
      message:
        'Specify two Scan IDs.\nA Scan ID looks like `aaa0aa0a-aaaa-0000-0a0a-0000000a00a0`.',
      pass: 'ok',
      fail:
        !id1 && !id2
          ? 'missing both Scan IDs'
          : !id2
            ? 'missing second Scan ID'
            : 'missing first Scan ID' // Not sure how this can happen but ok.
    },
    {
      test: !!orgSlug,
      nook: true,
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$6)
    return
  }
  await handleDiffScan({
    id1: String(id1 || ''),
    id2: String(id2 || ''),
    depth: Number(depth),
    orgSlug,
    outputKind,
    file: String(file || '')
  })
}

async function fetchListScans({
  branch,
  direction,
  from_time,
  orgSlug,
  page,
  per_page,
  repo,
  sort
}) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.getOrgFullScanList(orgSlug, {
      ...(branch
        ? {
            branch
          }
        : {}),
      ...(repo
        ? {
            repo
          }
        : {}),
      sort,
      direction,
      per_page: String(per_page),
      page: String(page),
      from: from_time
    }),
    'list of scans'
  )
}

// @ts-ignore
async function outputListScans(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  const options = {
    columns: [
      {
        field: 'id',
        name: vendor.yoctocolorsCjsExports.magenta('ID')
      },
      {
        field: 'report_url',
        name: vendor.yoctocolorsCjsExports.magenta('Scan URL')
      },
      {
        field: 'repo',
        name: vendor.yoctocolorsCjsExports.magenta('Repo')
      },
      {
        field: 'branch',
        name: vendor.yoctocolorsCjsExports.magenta('Branch')
      },
      {
        field: 'created_at',
        name: vendor.yoctocolorsCjsExports.magenta('Created at')
      }
    ]
  }
  const formattedResults = result.data.results.map(d => {
    return {
      id: d.id,
      report_url: vendor.yoctocolorsCjsExports.underline(
        `${d.html_report_url}`
      ),
      created_at: d.created_at
        ? new Date(d.created_at).toLocaleDateString('en-us', {
            year: 'numeric',
            month: 'numeric',
            day: 'numeric'
          })
        : '',
      repo: d.repo,
      branch: d.branch
    }
  })
  logger.logger.log(vendor.srcExports(options, formattedResults))
}

async function handleListScans({
  branch,
  direction,
  from_time,
  orgSlug,
  outputKind,
  page,
  per_page,
  repo,
  sort
}) {
  const data = await fetchListScans({
    branch,
    direction,
    from_time,
    orgSlug,
    page,
    per_page,
    repo,
    sort
  })
  await outputListScans(data, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$5 } = constants
const config$5 = {
  commandName: 'list',
  description: 'List the scans for an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    branch: {
      type: 'string',
      description: 'Filter to show only scans with this branch name'
    },
    direction: {
      type: 'string',
      shortFlag: 'd',
      default: 'desc',
      description: 'Direction option (`desc` or `asc`) - Default is `desc`'
    },
    fromTime: {
      type: 'string',
      shortFlag: 'f',
      default: '',
      description: 'From time - as a unix timestamp'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    page: {
      type: 'number',
      shortFlag: 'p',
      default: 1,
      description: 'Page number - Default is 1'
    },
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Results per page - Default is 30'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    },
    repo: {
      type: 'string',
      description: 'Filter to show only scans with this repository name'
    },
    sort: {
      type: 'string',
      shortFlag: 's',
      default: 'created_at',
      description:
        'Sorting option (`name` or `created_at`) - default is `created_at`'
    },
    untilTime: {
      type: 'string',
      shortFlag: 'u',
      default: '',
      description: 'Until time - as a unix timestamp'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'}
  `
}
const cmdScanList = {
  description: config$5.description,
  hidden: config$5.hidden,
  run: run$5
}
async function run$5(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$5,
    importMeta,
    parentName
  })
  const {
    branch,
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag,
    repo
  } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: !!defaultOrgSlug,
      test: !!orgSlug && orgSlug !== '.',
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail:
        orgSlug === '.'
          ? 'dot is an invalid org, most likely you forgot the org name here?'
          : 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message: 'The json and markdown flags cannot be both set, pick one',
      pass: 'ok',
      fail: 'omit one'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$5)
    return
  }
  await handleListScans({
    branch: branch ? String(branch) : '',
    direction: String(cli.flags['direction'] || ''),
    from_time: String(cli.flags['fromTime'] || ''),
    orgSlug,
    outputKind,
    page: Number(cli.flags['page'] || 1),
    per_page: Number(cli.flags['perPage'] || 30),
    repo: repo ? String(repo) : '',
    sort: String(cli.flags['sort'] || '')
  })
}

async function fetchScanMetadata(orgSlug, scanId) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  return await utils.handleApiCall(
    sockSdk.getOrgFullScanMetadata(orgSlug, scanId),
    'meta data for a full scan'
  )
}

async function outputScanMetadata(result, scanId, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  if (outputKind === 'markdown') {
    logger.logger.log('# Scan meta data\n')
  }
  logger.logger.log(`Scan ID: ${scanId}\n`)
  for (const [key, value] of Object.entries(result.data)) {
    if (
      [
        'id',
        'updated_at',
        'organization_id',
        'repository_id',
        'commit_hash',
        'html_report_url'
      ].includes(key)
    ) {
      continue
    }
    logger.logger.log(`- ${key}:`, value)
  }
  if (outputKind === 'markdown') {
    logger.logger.log(
      `\nYou can view this report at: [${result.data.html_report_url}](${result.data.html_report_url})\n`
    )
  } else {
    logger.logger.log(
      `\nYou can view this report at: ${result.data.html_report_url}]\n`
    )
  }
}

async function handleOrgScanMetadata(orgSlug, scanId, outputKind) {
  const data = await fetchScanMetadata(orgSlug, scanId)
  await outputScanMetadata(data, scanId, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$4 } = constants
const config$4 = {
  commandName: 'metadata',
  description: "Get a scan's metadata",
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'} <scan ID>

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} 000aaaa1-0000-0a0a-00a0-00a0000000a0
  `
}
const cmdScanMetadata = {
  description: config$4.description,
  hidden: config$4.hidden,
  run: run$4
}
async function run$4(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$4,
    importMeta,
    parentName
  })
  const { dryRun, interactive, json, markdown, org: orgFlag } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const scanId =
    (utils.isTestingV1() || defaultOrgSlug ? cli.input[0] : cli.input[1]) || ''
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: !!defaultOrgSlug,
      test: !!orgSlug && orgSlug !== '.',
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail:
        orgSlug === '.'
          ? 'dot is an invalid org, most likely you forgot the org name here?'
          : 'missing'
    },
    {
      test: !!scanId,
      message: 'Scan ID to inspect as argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message: 'The json and markdown flags cannot be both set, pick one',
      pass: 'ok',
      fail: 'omit one'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$4)
    return
  }
  await handleOrgScanMetadata(orgSlug, scanId, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$3 } = constants
const config$3 = {
  commandName: 'report',
  description:
    'Check whether a scan result passes the organizational policies (security, license)',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    fold: {
      type: 'string',
      default: 'none',
      description: 'Fold reported alerts to some degree'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    },
    reportLevel: {
      type: 'string',
      default: 'warn',
      description: 'Which policy level alerts should be reported'
    },
    short: {
      type: 'boolean',
      default: false,
      description: 'Report only the healthy status'
    },
    license: {
      type: 'boolean',
      default: false,
      description: 'Also report the license policy status. Default: false'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'} <scan ID> [path to output file]

    API Token Requirements
      - Quota: 2 units
      - Permissions: full-scans:list security-policy:read

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    By default the result is a nested object that looks like this:
      \`{[ecosystem]: {[pkgName]: {[version]: {[file]: {[type:loc]: policy}}}}\`
    You can fold this up to given level: 'pkg', 'version', 'file', and 'none'.

    By default only the warn and error policy level alerts are reported. You can
    override this and request more ('defer' < 'ignore' < 'monitor' < 'warn' < 'error')

    Short responses: JSON: \`{healthy:bool}\`, markdown: \`healthy = bool\`, text: \`OK/ERR\`

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} 000aaaa1-0000-0a0a-00a0-00a0000000a0 --json --fold=version
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} 000aaaa1-0000-0a0a-00a0-00a0000000a0 --license --markdown --short
  `
}
const cmdScanReport = {
  description: config$3.description,
  hidden: config$3.hidden,
  run: run$3
}
async function run$3(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$3,
    importMeta,
    parentName
  })
  const {
    fold = 'none',
    json,
    license,
    markdown,
    reportLevel = 'warn'
  } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const { dryRun, interactive, org: orgFlag } = cli.flags
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const scanId =
    (utils.isTestingV1() || defaultOrgSlug ? cli.input[0] : cli.input[1]) || ''
  const file =
    (utils.isTestingV1() || defaultOrgSlug ? cli.input[1] : cli.input[2]) || '-'
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: !!defaultOrgSlug,
      test: !!orgSlug && orgSlug !== '.',
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail:
        orgSlug === '.'
          ? 'dot is an invalid org, most likely you forgot the org name here?'
          : 'missing'
    },
    {
      test: !!scanId,
      message: 'Scan ID to report on',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message: 'The json and markdown flags cannot be both set, pick one',
      pass: 'ok',
      fail: 'omit one'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$3)
    return
  }
  await handleScanReport({
    orgSlug,
    scanId: scanId,
    includeLicensePolicy: !!license,
    outputKind,
    filePath: file,
    fold: fold,
    short: !!cli.flags['short'],
    reportLevel: reportLevel
  })
}

async function fetchScan(orgSlug, scanId) {
  const result = await utils.queryApiSafeText(
    `orgs/${orgSlug}/full-scans/${encodeURIComponent(scanId)}`,
    'a scan'
  )
  if (!result.ok) {
    return result
  }
  const jsonsString = result.data

  // This is nd-json; each line is a json object
  const lines = jsonsString.split('\n').filter(Boolean)
  let ok = true
  const data = lines.map(line => {
    try {
      return JSON.parse(line)
    } catch {
      ok = false
      debug.debugLog('ndjson failed to parse the following line:')
      debug.debugLog(line)
      return null
    }
  })
  if (ok) {
    return {
      ok: true,
      data
    }
  }
  return {
    ok: false,
    message: 'Invalid API response',
    cause:
      'The API responded with at least one line that was not valid JSON. Please report if this persists.'
  }
}

async function outputScanView(result, orgSlug, scanId, filePath, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result))
      return
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  if (
    outputKind === 'json' ||
    (outputKind === 'text' && filePath && filePath.endsWith('.json'))
  ) {
    const json = utils.serializeResultJson(result)
    if (filePath !== '-') {
      logger.logger.info('Writing json results to', filePath)
      try {
        await fs.writeFile(filePath, json, 'utf8')
        logger.logger.info(`Data successfully written to ${filePath}`)
      } catch (e) {
        process.exitCode = 1
        logger.logger.fail(
          'There was an error trying to write the markdown to disk'
        )
        logger.logger.error(e)
        logger.logger.log(
          utils.serializeResultJson({
            ok: false,
            message: 'File Write Failure',
            cause: 'Failed to write json to disk'
          })
        )
      }
      return
    }
    logger.logger.log(json)
    return
  }
  const display = result.data.map(art => {
    const author = Array.isArray(art.author)
      ? `${art.author[0]}${art.author.length > 1 ? ' et.al.' : ''}`
      : art.author
    return {
      type: art.type,
      name: art.name,
      version: art.version,
      author,
      score: JSON.stringify(art.score)
    }
  })
  const md = utils.mdTable(display, [
    'type',
    'version',
    'name',
    'author',
    'score'
  ])
  const report =
    `
# Scan Details

These are the artifacts and their scores found.

Scan ID: ${scanId}

${md}

View this report at: https://socket.dev/dashboard/org/${orgSlug}/sbom/${scanId}
  `.trim() + '\n'
  if (filePath !== '-') {
    try {
      await fs.writeFile(filePath, report, 'utf8')
      logger.logger.log(`Data successfully written to ${filePath}`)
    } catch (e) {
      process.exitCode = 1
      logger.logger.fail(
        'There was an error trying to write the markdown to disk'
      )
      logger.logger.error(e)
    }
  } else {
    logger.logger.log(report)
  }
}

async function handleScanView(orgSlug, scanId, filePath, outputKind) {
  const data = await fetchScan(orgSlug, scanId)
  await outputScanView(data, orgSlug, scanId, filePath, outputKind)
}

async function streamScan(orgSlug, scanId, file) {
  const sockSdkResult = await utils.setupSdk()
  if (!sockSdkResult.ok) {
    return sockSdkResult
  }
  const sockSdk = sockSdkResult.data
  logger.logger.error('Requesting data from API...')

  // Note: this will write to stdout or target file. It's not a noop
  return await utils.handleApiCall(
    sockSdk.getOrgFullScan(orgSlug, scanId, file === '-' ? undefined : file),
    'a scan'
  )
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$2 } = constants
const config$2 = {
  commandName: 'view',
  description: 'View the raw results of a scan',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    stream: {
      type: 'boolean',
      default: false,
      description:
        'Only valid with --json. Streams the response as "ndjson" (chunks of valid json blobs).'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'} <scan ID> [path to output file]

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:list

    When no output path is given the contents is sent to stdout.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} 000aaaa1-0000-0a0a-00a0-00a0000000a0 ./stream.txt
  `
}
const cmdScanView = {
  description: config$2.description,
  hidden: config$2.hidden,
  run: run$2
}
async function run$2(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$2,
    importMeta,
    parentName
  })
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag,
    stream
  } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const scanId =
    (utils.isTestingV1() || defaultOrgSlug ? cli.input[0] : cli.input[1]) || ''
  const file =
    (utils.isTestingV1() || defaultOrgSlug ? cli.input[1] : cli.input[2]) || '-'
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: !!defaultOrgSlug,
      test: !!orgSlug && orgSlug !== '.',
      message: utils.isTestingV1()
        ? 'Org name by default setting, --org, or auto-discovered'
        : 'Org name must be the first argument',
      pass: 'ok',
      fail:
        orgSlug === '.'
          ? 'dot is an invalid org, most likely you forgot the org name here?'
          : 'missing'
    },
    {
      test: !!scanId,
      message: 'Scan ID to view',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message:
        'The `--json` and `--markdown` flags can not be used at the same time',
      pass: 'ok',
      fail: 'bad'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    },
    {
      nook: true,
      test: !stream || !!json,
      message: 'You can only use --stream when using --json',
      pass: 'ok',
      fail: 'Either remove --stream or add --json'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$2)
    return
  }
  if (json && stream) {
    await streamScan(orgSlug, scanId, file)
  } else {
    await handleScanView(orgSlug, scanId, file, outputKind)
  }
}

const description = 'Scan related commands'
const cmdScan = {
  description,
  async run(argv, importMeta, { parentName }) {
    await utils.meowWithSubcommands(
      {
        create: cmdScanCreate,
        list: cmdScanList,
        del: cmdScanDel,
        diff: cmdScanDiff,
        metadata: cmdScanMetadata,
        report: cmdScanReport,
        view: cmdScanView
      },
      {
        aliases: {
          // Backwards compat. TODO: Drop next major bump
          stream: {
            description: cmdScanView.description,
            hidden: true,
            argv: ['view'] // Original args will be appended (!)
          }
        },
        argv,
        description,
        importMeta,
        name: parentName + ' scan'
      }
    )
  }
}

async function fetchThreatFeed({
  direction,
  ecosystem,
  filter,
  page,
  perPage
}) {
  const queryParams = new URLSearchParams([
    ['direction', direction],
    ['ecosystem', ecosystem],
    ['filter', filter],
    ['page', page],
    ['per_page', String(perPage)]
  ])
  return await utils.queryApiSafeJson(
    `threat-feed?${queryParams}`,
    'the Threat Feed data'
  )
}

const require$1 = Module.createRequire(
  require$$0.pathToFileURL(__filename).href
)
async function outputThreatFeed(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result))
    return
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause))
    return
  }
  if (!result.data?.results?.length) {
    logger.logger.error('Did not receive any data to display...')
    return
  }
  const formattedOutput = formatResults(result.data.results)
  const descriptions = result.data.results.map(d => d.description)

  // Note: this temporarily takes over the terminal (just like `man` does).
  const ScreenWidget = require$1('../external/blessed/lib/widgets/screen.js')
  // Lazily access constants.blessedOptions.
  const screen = new ScreenWidget({
    ...constants.blessedOptions
  })
  // Register these keys first so you can always exit, even when it gets stuck
  // If we don't do this and the code crashes, the user must hard-kill the
  // node process just to exit it. That's very bad UX.
  // eslint-disable-next-line n/no-process-exit
  screen.key(['escape', 'q', 'C-c'], () => process.exit(0))
  const TableWidget = require$1(
    '../external/blessed-contrib/lib/widget/table.js'
  )
  const table = new TableWidget({
    keys: 'true',
    fg: 'white',
    selectedFg: 'white',
    selectedBg: 'magenta',
    interactive: 'true',
    label: 'Threat feed',
    width: '100%',
    height: '70%',
    // Changed from 100% to 70%
    border: {
      type: 'line',
      fg: 'cyan'
    },
    columnWidth: [10, 30, 20, 18, 15, 200],
    // TODO: the truncation doesn't seem to work too well yet but when we add
    //       `pad` alignment fails, when we extend columnSpacing alignment fails
    columnSpacing: 1,
    truncate: '_'
  })

  // Create details box at the bottom
  const BoxWidget = require$1('../external/blessed/lib/widgets/box.js')
  const detailsBox = new BoxWidget({
    bottom: 0,
    height: '30%',
    width: '100%',
    border: {
      type: 'line',
      fg: 'cyan'
    },
    label: 'Details',
    content:
      'Use arrow keys to navigate. Press Enter to select a threat. Press q to exit.',
    style: {
      fg: 'white'
    }
  })
  table.setData({
    headers: [
      ' Ecosystem',
      ' Name',
      '  Version',
      '  Threat type',
      '  Detected at',
      ' Details'
    ],
    data: formattedOutput
  })

  // allow control the table with the keyboard
  table.focus()
  screen.append(table)
  screen.append(detailsBox)

  // Update details box when selection changes
  table.rows.on('select item', () => {
    const selectedIndex = table.rows.selected
    if (selectedIndex !== undefined && selectedIndex >= 0) {
      const selectedRow = formattedOutput[selectedIndex]
      if (selectedRow) {
        // Note: the spacing works around issues with the table; it refuses to pad!
        detailsBox.setContent(
          `Ecosystem: ${selectedRow[0]}\n` +
            `Name: ${selectedRow[1]}\n` +
            `Version:${selectedRow[2]}\n` +
            `Threat type:${selectedRow[3]}\n` +
            `Detected at:${selectedRow[4]}\n` +
            `Details: ${selectedRow[5]}\n` +
            `Description: ${descriptions[selectedIndex]}`
        )
        screen.render()
      }
    }
  })
  screen.render()
  screen.key(['return'], () => {
    const selectedIndex = table.rows.selected
    screen.destroy()
    const selectedRow = formattedOutput[selectedIndex]
    logger.logger.log('Last selection:\n', selectedRow)
  })
}
function formatResults(data) {
  return data.map(d => {
    const ecosystem = d.purl.split('pkg:')[1].split('/')[0]
    const name = d.purl.split('/')[1].split('@')[0]
    const version = d.purl.split('@')[1]
    const timeDiff = msAtHome(d.createdAt)

    // Note: the spacing works around issues with the table; it refuses to pad!
    return [
      ecosystem,
      decodeURIComponent(name),
      ` ${version}`,
      ` ${d.threatType}`,
      ` ${timeDiff}`,
      d.locationHtmlUrl
    ]
  })
}
function msAtHome(isoTimeStamp) {
  const timeStart = Date.parse(isoTimeStamp)
  const timeEnd = Date.now()
  const rtf = new Intl.RelativeTimeFormat('en', {
    numeric: 'always',
    style: 'short'
  })
  const delta = timeEnd - timeStart
  if (delta < 60 * 60 * 1000) {
    return rtf.format(-Math.round(delta / (60 * 1000)), 'minute')
    // return Math.round(delta / (60 * 1000)) + ' min ago'
  } else if (delta < 24 * 60 * 60 * 1000) {
    return rtf.format(-(delta / (60 * 60 * 1000)).toFixed(1), 'hour')
    // return (delta / (60 * 60 * 1000)).toFixed(1) + ' hr ago'
  } else if (delta < 7 * 24 * 60 * 60 * 1000) {
    return rtf.format(-(delta / (24 * 60 * 60 * 1000)).toFixed(1), 'day')
    // return (delta / (24 * 60 * 60 * 1000)).toFixed(1) + ' day ago'
  } else {
    return isoTimeStamp.slice(0, 10)
  }
}

async function handleThreatFeed({
  direction,
  ecosystem,
  filter,
  outputKind,
  page,
  perPage
}) {
  const data = await fetchThreatFeed({
    direction,
    ecosystem,
    filter,
    page,
    perPage
  })
  await outputThreatFeed(data, outputKind)
}

const { DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$1 } = constants
const config$1 = {
  commandName: 'threat-feed',
  description: '[beta] View the threat feed',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description:
        'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description:
        'Force override the organization slug, overrides the default org from config'
    },
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Number of items per page'
    },
    page: {
      type: 'string',
      shortFlag: 'p',
      default: '1',
      description: 'Page token'
    },
    direction: {
      type: 'string',
      shortFlag: 'd',
      default: 'desc',
      description: 'Order asc or desc by the createdAt attribute'
    },
    eco: {
      type: 'string',
      shortFlag: 'e',
      default: '',
      description: 'Only show threats for a particular ecosystem'
    },
    filter: {
      type: 'string',
      shortFlag: 'f',
      default: 'mal',
      description: 'Filter what type of threats to return'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: threat-feed:list
      - Special access

    This feature requires a Threat Feed license. Please contact
    sales@socket.dev if you are interested in purchasing this access.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Valid filters:

      - anom    Anomaly
      - c       Do not filter
      - fp      False Positives
      - joke    Joke / Fake
      - mal     Malware and Possible Malware [default]
      - secret  Secrets
      - spy     Telemetry
      - tp      False Positives and Unreviewed
      - typo    Typo-squat
      - u       Unreviewed
      - vuln    Vulnerability

    Valid ecosystems:

      - gem
      - golang
      - maven
      - npm
      - nuget
      - pypi

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'}
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} --perPage=5 --page=2 --direction=asc --filter=joke
  `
}
const cmdThreatFeed = {
  description: config$1.description,
  hidden: config$1.hidden,
  run: run$1
}
async function run$1(argv, importMeta, { parentName }) {
  const cli = utils.meowOrExit({
    argv,
    config: config$1,
    importMeta,
    parentName
  })
  const { dryRun, interactive, json, markdown, org: orgFlag } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown)
  const [orgSlug] = await utils.determineOrgSlug(
    String(orgFlag || ''),
    cli.input[0] || '',
    !!interactive,
    !!dryRun
  )
  const hasApiToken = utils.hasDefaultToken()
  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      nook: true,
      test: !!orgSlug,
      message: 'Org name as the first argument',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !json || !markdown,
      message: 'The json and markdown flags cannot be both set, pick one',
      pass: 'ok',
      fail: 'omit one'
    },
    {
      nook: true,
      test: hasApiToken,
      message:
        'You need to be logged in to use this command. See `socket login`.',
      pass: 'ok',
      fail: 'missing API token'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$1)
    return
  }
  await handleThreatFeed({
    direction: String(cli.flags['direction'] || 'desc'),
    ecosystem: String(cli.flags['eco'] || ''),
    filter: String(cli.flags['filter'] || 'mal'),
    outputKind,
    page: String(cli.flags['page'] || '1'),
    perPage: Number(cli.flags['perPage']) || 30
  })
}

function addSocketWrapper(file) {
  return fs$1.appendFile(
    file,
    'alias npm="socket npm"\nalias npx="socket npx"\n',
    err => {
      if (err) {
        return new Error(`There was an error setting up the alias: ${err}`)
      }
      // TODO: pretty sure you need to source the file or restart
      //       any terminal session before changes are reflected.
      logger.logger.log(
        `
The alias was added to ${file}. Running 'npm install' will now be wrapped in Socket's "safe npm" 🎉
If you want to disable it at any time, run \`socket wrapper --disable\`
      `.trim()
      )
    }
  )
}

function checkSocketWrapperSetup(file) {
  const fileContent = fs$1.readFileSync(file, 'utf8')
  const linesWithSocketAlias = fileContent
    .split('\n')
    .filter(
      l => l === 'alias npm="socket npm"' || l === 'alias npx="socket npx"'
    )
  if (linesWithSocketAlias.length) {
    logger.logger.log(
      `The Socket npm/npx wrapper is set up in your bash profile (${file})`
    )
    return true
  }
  return false
}

async function postinstallWrapper() {
  // Lazily access constants.bashRcPath and constants.zshRcPath.
  const { bashRcPath, zshRcPath } = constants
  const socketWrapperEnabled =
    (fs$1.existsSync(bashRcPath) && checkSocketWrapperSetup(bashRcPath)) ||
    (fs$1.existsSync(zshRcPath) && checkSocketWrapperSetup(zshRcPath))
  if (!socketWrapperEnabled) {
    await installSafeNpm(
      `
The Socket CLI is now successfully installed! 🎉

To better protect yourself against supply-chain attacks, our "safe npm" wrapper can warn you about malicious packages whenever you run 'npm install'.

Do you want to install "safe npm" (this will create an alias to the socket-npm command)?
    `.trim()
    )
  }
}
async function installSafeNpm(query) {
  logger.logger.log(`
 _____         _       _
|   __|___ ___| |_ ___| |_
|__   | . |  _| '_| -_|  _|
|_____|___|___|_,_|___|_|

`)
  if (
    await prompts.confirm({
      message: query,
      default: true
    })
  ) {
    // Lazily access constants.bashRcPath and constants.zshRcPath.
    const { bashRcPath, zshRcPath } = constants
    try {
      if (fs$1.existsSync(bashRcPath)) {
        addSocketWrapper(bashRcPath)
      }
      if (fs$1.existsSync(zshRcPath)) {
        addSocketWrapper(zshRcPath)
      }
    } catch (e) {
      throw new Error(
        `There was an issue setting up the alias: ${e?.['message']}`
      )
    }
  }
}

function removeSocketWrapper(file) {
  return fs$1.readFile(file, 'utf8', function (err, data) {
    if (err) {
      logger.logger.fail('There was an error removing the alias:')
      logger.logger.error(err)
      return
    }
    const linesWithoutSocketAlias = data
      .split('\n')
      .filter(
        l => l !== 'alias npm="socket npm"' && l !== 'alias npx="socket npx"'
      )
    const updatedFileContent = linesWithoutSocketAlias.join('\n')
    fs$1.writeFile(file, updatedFileContent, function (err) {
      if (err) {
        logger.logger.error(err)
        return
      }
      // TODO: pretty sure you need to source the file or restart
      //       any terminal session before changes are reflected.
      logger.logger.log(
        `The alias was removed from ${file}. Running 'npm install' will now run the standard npm command.`
      )
    })
  })
}

const { DRY_RUN_BAILING_NOW } = constants
const config = {
  commandName: 'wrapper',
  description: 'Enable or disable the Socket npm/npx wrapper',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    enable: {
      type: 'boolean',
      default: false,
      description: 'Enables the Socket npm/npx wrapper'
    },
    disable: {
      type: 'boolean',
      default: false,
      description: 'Disables the Socket npm/npx wrapper'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} <flag>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} --enable
      $ ${command} --disable
  `
}
const cmdWrapper = {
  description: config.description,
  hidden: config.hidden,
  run
}
async function run(argv, importMeta, { parentName }) {
  // I don't think meow would mess with this but ...
  if (argv[0] === '--postinstall') {
    await postinstallWrapper()
    return
  }
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  })
  const { disable, enable, json, markdown } = cli.flags
  const outputKind = utils.getOutputKind(json, markdown) // TODO: impl json/md further

  const wasValidInput = utils.checkCommandInput(
    outputKind,
    {
      test: !!(enable || disable),
      message: 'Must use --enabled or --disable',
      pass: 'ok',
      fail: 'missing'
    },
    {
      nook: true,
      test: !enable || !disable,
      message: 'Do not use both --enable and --disable',
      pass: 'ok',
      fail: 'missing'
    }
  )
  if (!wasValidInput) {
    return
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW)
    return
  }

  // Lazily access constants.bashRcPath and constants.zshRcPath.
  const { bashRcPath, zshRcPath } = constants
  if (enable) {
    if (fs$1.existsSync(bashRcPath) && !checkSocketWrapperSetup(bashRcPath)) {
      addSocketWrapper(bashRcPath)
    }
    if (fs$1.existsSync(zshRcPath) && !checkSocketWrapperSetup(zshRcPath)) {
      addSocketWrapper(zshRcPath)
    }
  } else {
    if (fs$1.existsSync(bashRcPath)) {
      removeSocketWrapper(bashRcPath)
    }
    if (fs$1.existsSync(zshRcPath)) {
      removeSocketWrapper(zshRcPath)
    }
  }
  if (!fs$1.existsSync(bashRcPath) && !fs$1.existsSync(zshRcPath)) {
    logger.logger.fail(
      'There was an issue setting up the alias in your bash profile'
    )
  }
}

const __filename$1 = require$$0.fileURLToPath(
  typeof document === 'undefined'
    ? require$$0.pathToFileURL(__filename).href
    : (_documentCurrentScript &&
        _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' &&
        _documentCurrentScript.src) ||
        new URL('cli.js', document.baseURI).href
)
const { SOCKET_CLI_BIN_NAME } = constants

// TODO: Add autocompletion using https://socket.dev/npm/package/omelette
void (async () => {
  await vendor.updater({
    name: SOCKET_CLI_BIN_NAME,
    // Lazily access constants.ENV.INLINED_SOCKET_CLI_VERSION.
    version: constants.ENV.INLINED_SOCKET_CLI_VERSION,
    ttl: 86_400_000 /* 24 hours in milliseconds */
  })
  try {
    await utils.meowWithSubcommands(
      {
        cdxgen: cmdCdxgen,
        ci: cmdCI,
        config: cmdConfig,
        fix: cmdFix,
        info: cmdInfo,
        login: cmdLogin,
        logout: cmdLogout,
        npm: cmdNpm,
        npx: cmdNpx,
        oops: cmdOops,
        optimize: cmdOptimize,
        organization: cmdOrganization,
        package: cmdPackage,
        'raw-npm': cmdRawNpm,
        'raw-npx': cmdRawNpx,
        report: cmdReport,
        wrapper: cmdWrapper,
        scan: cmdScan,
        'audit-log': cmdAuditLog,
        repos: cmdRepos,
        dependencies: cmdScanCreate$1,
        analytics: cmdAnalytics,
        'diff-scan': cmdDiffScan,
        'threat-feed': cmdThreatFeed,
        manifest: cmdManifest
      },
      {
        aliases: {},
        argv: process.argv.slice(2),
        name: SOCKET_CLI_BIN_NAME,
        importMeta: {
          url: `${require$$0.pathToFileURL(__filename$1)}`
        }
      }
    )
  } catch (e) {
    process.exitCode = 1
    let errorBody
    let errorTitle
    let errorMessage = ''
    if (e instanceof utils.AuthError) {
      errorTitle = 'Authentication error'
      errorMessage = e.message
    } else if (e instanceof utils.InputError) {
      errorTitle = 'Invalid input'
      errorMessage = e.message
      errorBody = e.body
    } else if (e instanceof Error) {
      errorTitle = 'Unexpected error'
      errorMessage = vendor.messageWithCauses(e)
      errorBody = vendor.stackWithCauses(e)
    } else {
      errorTitle = 'Unexpected error with no details'
    }
    logger.logger.error('\n') // Any-spinner-newline
    logger.logger.fail(utils.failMsgWithBadge(errorTitle, errorMessage))
    if (errorBody) {
      debug.debugLog(`${errorBody}`)
    }
    await utils.captureException(e)
  }
})()
//# debugId=a4b81e94-18e0-4900-a5c2-a2b66c92bf6c
//# sourceMappingURL=cli.js.map
